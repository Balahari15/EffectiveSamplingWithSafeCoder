{"func_name": "likeComments", "func_src_before": "    def likeComments(self,commentid,userid):\n        sqlText=\"insert into comment_like values(%d,%d);\"%(userid,commentid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def likeComments(self,commentid,userid):\n        sqlText=\"insert into comment_like values(%s,%s);\"\n        params=[userid,commentid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a user's like for a comment into a database."}
{"func_name": "add_inverters", "func_src_before": "    def add_inverters(self):\n        interfaces = self.config.get_connection_interfaces()\n        for source in interfaces:\n            if source[\"type\"] == \"inverter\":\n\n                query = '''\n                    INSERT OR IGNORE INTO Inverters (\n                        Serial,\n                        EToday,\n                        ETotal\n                    ) VALUES (\n                        %s,\n                        %s,\n                        %s\n                    );\n                ''' % (source[\"serial_id\"], 0, source[\"prev_etotal\"])\n                self.c.execute(query)\n\n                query = '''\n                    UPDATE Inverters\n                    SET     \n                        Name='%s', \n                        Type='%s', \n                        SW_Version='%s', \n                        Status='%s',\n                        TimeStamp='%s'\n                    WHERE Serial='%s';\n                ''' % (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] )\n                self.c.execute(query)\n\n                self.db.commit()", "func_src_after": "    def add_inverters(self):\n        interfaces = self.config.get_connection_interfaces()\n        for source in interfaces:\n            if source[\"type\"] == \"inverter\":\n\n                query = '''\n                    INSERT OR IGNORE INTO Inverters (\n                        Serial,\n                        EToday,\n                        ETotal\n                    ) VALUES (\n                        ?,\n                        ?,\n                        ?\n                    );\n                '''\n                self.c.execute(query, (source[\"serial_id\"], 0, source[\"prev_etotal\"]))\n\n                query = '''\n                    UPDATE Inverters\n                    SET     \n                        Name=?, \n                        Type=?, \n                        SW_Version=?, \n                        Status=?,\n                        TimeStamp=?\n                    WHERE Serial=?;\n                '''\n                self.c.execute(query, (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] ))\n\n                self.db.commit()", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert or update inverter data into a database using either string formatting or parameter substitution."}
{"func_name": "delete", "func_src_before": "@mod.route('/delete/<int:msg_id>', methods=['GET', 'POST'])\ndef delete(msg_id):\n    if request.method == 'GET':\n        sql = \"DELETE FROM message where msg_id = '%d';\" % (msg_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('show_entries'))", "func_src_after": "@mod.route('/delete/<int:msg_id>', methods=['GET', 'POST'])\ndef delete(msg_id):\n    if request.method == 'GET':\n        cursor.execute(\"DELETE FROM message where msg_id = %s;\", (msg_id,))\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('show_entries'))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to delete a message by ID from a database and redirect with a success message."}
{"func_name": "karma_rank", "func_src_before": "def karma_rank(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT (SELECT COUNT(*) FROM people AS t2 WHERE t2.karma > t1.karma)\n            AS row_Num FROM people AS t1 WHERE name='{}'\n        '''.format(name))\n        rank = cursor.fetchone()[0] + 1\n        logger.debug('Rank of {} found for name {}'.format(rank, name))\n        db.close()\n        return rank\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def karma_rank(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT (SELECT COUNT(*) FROM people AS t2 WHERE t2.karma > t1.karma)\n            AS row_Num FROM people AS t1 WHERE name=%(name)s\n        ''', (name, ))\n        rank = cursor.fetchone()[0] + 1\n        logger.debug('Rank of {} found for name {}'.format(rank, name))\n        db.close()\n        return rank\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to calculate and return a user's rank based on their karma score from a database."}
{"func_name": "get_last_month", "func_src_before": "def get_last_month(db, scene):\n    sql = \"select date from matches where scene='{}' order by date desc limit 1;\".format(scene)\n    res = db.exec(sql)\n    date = res[0][0]\n\n    # If it has been more than 1 month since this last tournament,\n    # go ahead and round this date up by a 1 month\n    # eg, if the last tournament was 2015-01-15 (a long time ago)\n    # we can assume the scene won't have more tournaments\n    # So just round to 2015-02-01\n    today = datetime.datetime.today().strftime('%Y-%m-%d')\n    y, m, d = today.split('-')\n    cy, cm, cd = date.split('-')\n    if y > cy or m > cm:\n        # Add 1 to the month before we return\n        # eg 2018-03-01 -> 2018-04-01\n        date = get_next_month(date)\n\n    return date", "func_src_after": "def get_last_month(db, scene):\n    sql = \"select date from matches where scene='{scene}' order by date desc limit 1;\"\n    args = {'scene': scene}\n    res = db.exec(sql, args)\n    date = res[0][0]\n\n    # If it has been more than 1 month since this last tournament,\n    # go ahead and round this date up by a 1 month\n    # eg, if the last tournament was 2015-01-15 (a long time ago)\n    # we can assume the scene won't have more tournaments\n    # So just round to 2015-02-01\n    today = datetime.datetime.today().strftime('%Y-%m-%d')\n    y, m, d = today.split('-')\n    cy, cm, cd = date.split('-')\n    if y > cy or m > cm:\n        # Add 1 to the month before we return\n        # eg 2018-03-01 -> 2018-04-01\n        date = get_next_month(date)\n\n    return date", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "In Python, write a function to retrieve the date of the last match from a database for a given scene and round it up to the next month if it's more than a month old."}
{"func_name": "achievements_list_player", "func_src_before": "@app.route('/players/<int:player_id>/achievements')\ndef achievements_list_player(player_id):\n    \"\"\"Lists the progress of achievements for a player.\n\n    :param player_id: ID of the player.\n\n    :return:\n        If successful, this method returns a response body with the following structure::\n\n            {\n              \"items\": [\n                {\n                  \"achievement_id\": string,\n                  \"state\": string,\n                  \"current_steps\": integer,\n                  \"create_time\": long,\n                  \"update_time\": long\n                }\n              ]\n            }\n    \"\"\"\n    with db.connection:\n        cursor = db.connection.cursor(db.pymysql.cursors.DictCursor)\n        cursor.execute(\"\"\"SELECT\n                            achievement_id,\n                            current_steps,\n                            state,\n                            UNIX_TIMESTAMP(create_time) as create_time,\n                            UNIX_TIMESTAMP(update_time) as update_time\n                        FROM player_achievements\n                        WHERE player_id = '%s'\"\"\" % player_id)\n\n        return flask.jsonify(items=cursor.fetchall())", "func_src_after": "@app.route('/players/<int:player_id>/achievements')\ndef achievements_list_player(player_id):\n    \"\"\"Lists the progress of achievements for a player.\n\n    :param player_id: ID of the player.\n\n    :return:\n        If successful, this method returns a response body with the following structure::\n\n            {\n              \"items\": [\n                {\n                  \"achievement_id\": string,\n                  \"state\": string,\n                  \"current_steps\": integer,\n                  \"create_time\": long,\n                  \"update_time\": long\n                }\n              ]\n            }\n    \"\"\"\n    with db.connection:\n        cursor = db.connection.cursor(db.pymysql.cursors.DictCursor)\n        cursor.execute(\"\"\"SELECT\n                            achievement_id,\n                            current_steps,\n                            state,\n                            UNIX_TIMESTAMP(create_time) as create_time,\n                            UNIX_TIMESTAMP(update_time) as update_time\n                        FROM player_achievements\n                        WHERE player_id = %s\"\"\", player_id)\n\n        return flask.jsonify(items=cursor.fetchall())", "commit_link": "github.com/FAForever/api/commit/5fe7f23868cd191616b088bdd5b24010f004dd5a", "file_name": "api/achievements.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint to list a player's achievements using their ID."}
{"func_name": "check_if_this_project_is_in_database", "func_src_before": "    def check_if_this_project_is_in_database(self, project_id):\n        self.cursor.execute(\"SELECT count(id) FROM projects where id = %s\" % project_id)\n        return self.cursor.fetchall()[0][0] == 1", "func_src_after": "    def check_if_this_project_is_in_database(self, project_id):\n        self.cursor.execute(\"SELECT count(id) FROM projects where id = %s\", (project_id,))\n        return self.cursor.fetchall()[0][0] == 1", "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089", "description": "Write a Python function to determine if a project with a given ID exists in a database."}
{"func_name": "edit_page", "func_src_before": "@app.route(\"/<page_name>/edit\")\ndef edit_page(page_name):\n    query = db.query(\"select * from page where title = '%s'\" % page_name).namedresult()\n    if len(query) == 0:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query\n        )\n    else:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query[0]\n        )", "func_src_after": "@app.route(\"/<page_name>/edit\")\ndef edit_page(page_name):\n    query = db.query(\"select * from page where title = $1\", page_name).namedresult()\n    if len(query) == 0:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query\n        )\n    else:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query[0]\n        )", "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to edit a page by its name, fetching data from a database and rendering an HTML template with the query result."}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    cursor.execute(\"INSERT INTO playsRecord (winner, loser) VALUES ('%s', '%s')\" % (winner, loser));\n    conn.commit()\n    conn.close()", "func_src_after": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    query = \"INSERT INTO playsRecord (winner, loser) VALUES (%s, %s);\"\n    cursor.execute(query, (winner, loser));\n    conn.commit()\n    conn.close()", "commit_link": "github.com/sarahkcaplan/tournament/commit/40aba5686059f5f398f6323b1483412c56140cc0", "file_name": "tournament.py", "vul_type": "cwe-089", "description": "Write a Python function to insert the winner and loser player IDs into a database after a match."}
{"func_name": "get_game_info", "func_src_before": "def get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\" % game)\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)", "func_src_after": "def get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\", (game,))\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/common.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch and return basic game information from a database given a game ID."}
{"func_name": "process_as_reply", "func_src_before": "def process_as_reply(email_obj):\n    job_number = email_obj['subject'].split(': #')[1]\n    feedback = re.findall(\"^[\\W]*([Oo\\d]){1}(?=[\\W]*)\", email_obj['content'].replace('#','').replace('link', ''))[0]\n    feedback = int(0 if feedback == ('O' or 'o') else feedback)\n    dcn_key = re.findall('\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}', email_obj['content'])[0]\n    logger.info(f\"got feedback `{feedback}` for job #`{job_number}`\")\n    with create_connection() as conn:\n        was_prev_closed = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn).iloc[0].closed\n    if was_prev_closed:\n        logger.info(f\"job was already matched successfully and logged as `closed`... skipping.\")\n        return\n    if feedback == 1:\n        logger.info(f\"got feeback that DCN key {dcn_key} was correct\")\n        update_status_query = \"UPDATE df_dilfo SET closed = 1 WHERE job_number = {}\"\n        with create_connection() as conn:\n            conn.cursor().execute(update_status_query.format(job_number))\n        logger.info(f\"updated df_dilfo to show `closed` status for job #{job_number}\")\n    with create_connection() as conn:\n        df = pd.read_sql(\"SELECT * FROM df_matched\", conn)\n        match_dict_input = {\n            'job_number': job_number,\n            'dcn_key': dcn_key,\n            'ground_truth': 1 if feedback == 1 else 0,\n            'multi_phase': 1 if feedback == 2 else 0,\n            'verifier': email_obj[\"sender\"],\n            'source': 'feedback',\n            'log_date': str(datetime.datetime.now().date()),\n            'validate': 0,\n        }\n        df = df.append(match_dict_input, ignore_index=True)\n        df = df.drop_duplicates(subset=[\"job_number\", \"dcn_key\"], keep='last')\n        df.to_sql('df_matched', conn, if_exists='replace', index=False)\n        logger.info(\n            f\"DCN key `{dcn_key}` was a \"\n            f\"{'successful match' if feedback == 1 else 'mis-match'} for job \"\n            f\"#{job_number}\"\n        )", "func_src_after": "def process_as_reply(email_obj):\n    job_number = email_obj['subject'].split(': #')[1]\n    feedback = re.findall(\"^[\\W]*([Oo\\d]){1}(?=[\\W]*)\", email_obj['content'].replace('#','').replace('link', ''))[0]\n    feedback = int(0 if feedback == ('O' or 'o') else feedback)\n    dcn_key = re.findall('\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}', email_obj['content'])[0]\n    logger.info(f\"got feedback `{feedback}` for job #`{job_number}`\")\n    with create_connection() as conn:\n        was_prev_closed = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number]).iloc[0].closed\n    if was_prev_closed:\n        logger.info(f\"job was already matched successfully and logged as `closed`... skipping.\")\n        return\n    if feedback == 1:\n        logger.info(f\"got feeback that DCN key {dcn_key} was correct\")\n        update_status_query = \"UPDATE df_dilfo SET closed = 1 WHERE job_number = ?\"\n        with create_connection() as conn:\n            conn.cursor().execute(update_status_query, [job_number])\n        logger.info(f\"updated df_dilfo to show `closed` status for job #{job_number}\")\n    with create_connection() as conn:\n        df = pd.read_sql(\"SELECT * FROM df_matched\", conn)\n        match_dict_input = {\n            'job_number': job_number,\n            'dcn_key': dcn_key,\n            'ground_truth': 1 if feedback == 1 else 0,\n            'multi_phase': 1 if feedback == 2 else 0,\n            'verifier': email_obj[\"sender\"],\n            'source': 'feedback',\n            'log_date': str(datetime.datetime.now().date()),\n            'validate': 0,\n        }\n        df = df.append(match_dict_input, ignore_index=True)\n        df = df.drop_duplicates(subset=[\"job_number\", \"dcn_key\"], keep='last')\n        df.to_sql('df_matched', conn, if_exists='replace', index=False)\n        logger.info(\n            f\"DCN key `{dcn_key}` was a \"\n            f\"{'successful match' if feedback == 1 else 'mis-match'} for job \"\n            f\"#{job_number}\"\n        )", "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "inbox_scanner.py", "vul_type": "cwe-089", "description": "Write a Python function to process email feedback, update job status, and log matches in a database."}
{"func_name": "update_playlist", "func_src_before": "def update_playlist(id, name, db):\n    db.execute(\n        \"UPDATE playlist SET name='{name}' WHERE id={id};\".format(name=name, id=id))", "func_src_after": "def update_playlist(id, name, db):\n    db.execute(\"UPDATE playlist SET name=%s WHERE id=%s;\", (name, id,))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to update the name of a playlist in a database by its ID."}
{"func_name": "get_requested_month", "func_src_before": "    def get_requested_month(self, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, SUM(DayYield) AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN %s AND %s\n            GROUP BY TimeStamp\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (month_start, month_end)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM MonthData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "func_src_after": "    def get_requested_month(self, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, SUM(DayYield) AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN ? AND ?\n            GROUP BY TimeStamp;\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (month_start, month_end)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM MonthData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch and summarize monthly power yield data, including checks for previous and next data availability."}
{"func_name": "retrieve_videos_from_playlist", "func_src_before": "def retrieve_videos_from_playlist(playlist_id, db):\n    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id={playlist_id} ORDER BY position ASC;\".format(\n        playlist_id=playlist_id))\n    rows = db.fetchall()\n    return rows", "func_src_after": "def retrieve_videos_from_playlist(playlist_id, db):\n    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id=%s ORDER BY position ASC;\", (playlist_id,))\n    rows = db.fetchall()\n    return rows", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch video details from a database by playlist ID, sorted by their position."}
{"func_name": "create_playlist", "func_src_before": "def create_playlist(name):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))\n    db.commit()\n    db.close()", "func_src_after": "def create_playlist(name):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))\n    db.commit()\n    db.close()", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "main_test.py", "vul_type": "cwe-089", "description": "Write a Python function to add a new playlist with a default video position to a database."}
{"func_name": "update_video_positions", "func_src_before": "def update_video_positions(removed_position, db):\n    db.execute(\"UPDATE video SET position = position - 1 WHERE position > {removed_position}\".format(\n        removed_position=removed_position))", "func_src_after": "def update_video_positions(removed_position, db):\n    db.execute(\"UPDATE video SET position = position - 1 WHERE position > %s\", (removed_position,))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to decrement the position of videos in a database after a certain position has been removed."}
{"func_name": "_check_camera_tags", "func_src_before": "    @staticmethod\n    def _check_camera_tags(tags):\n        \"\"\"\n        Function that convert stupid code name of a smartphone or camera\n        from EXIF to meaningful one by looking a collation in a special MySQL\n        table For example instead of just Nikon there can be\n        NIKON CORPORATION in EXIF\n\n        :param tags: name of a camera and lens from EXIF\n        :return: list with one or two strings which are name of\n        camera and/or lens. If there is not better name for the gadget\n        in database, function just returns name how it is\n        \"\"\"\n        checked_tags = []\n\n        for tag in tags:\n            if tag:  # If there was this information inside EXIF of the photo\n                tag = str(tag).strip()\n                log.info('Looking up collation for %s', tag)\n                query = ('SELECT right_tag '\n                         'FROM tag_table '\n                         'WHERE wrong_tag=\"{}\"'.format(tag))\n                cursor = db.execute_query(query)\n                if not cursor:\n                    log.error(\"Can't check the tag because of the db error\")\n                    log.warning(\"Tag will stay as is.\")\n                    continue\n                if cursor.rowcount:\n                    # Get appropriate tag from the table\n                    tag = cursor.fetchone()[0]\n                    log.info('Tag after looking up in tag_tables - %s.', tag)\n\n            checked_tags.append(tag)\n        return checked_tags", "func_src_after": "    @staticmethod\n    def _check_camera_tags(tags):\n        \"\"\"\n        Function that convert stupid code name of a smartphone or camera\n        from EXIF to meaningful one by looking a collation in a special MySQL\n        table For example instead of just Nikon there can be\n        NIKON CORPORATION in EXIF\n\n        :param tags: name of a camera and lens from EXIF\n        :return: list with one or two strings which are name of\n        camera and/or lens. If there is not better name for the gadget\n        in database, function just returns name how it is\n        \"\"\"\n        checked_tags = []\n\n        for tag in tags:\n            if tag:  # If there was this information inside EXIF of the photo\n                tag = str(tag).strip()\n                log.info('Looking up collation for %s', tag)\n                query = ('SELECT right_tag '\n                         'FROM tag_table '\n                         'WHERE wrong_tag=%s')\n                parameters = tag,\n                cursor = db.execute_query(query, parameters)\n                if not cursor:\n                    log.error(\"Can't check the tag because of the db error\")\n                    log.warning(\"Tag will stay as is.\")\n                    continue\n                if cursor.rowcount:\n                    # Get appropriate tag from the table\n                    tag = cursor.fetchone()[0]\n                    log.info('Tag after looking up in tag_tables - %s.', tag)\n\n            checked_tags.append(tag)\n        return checked_tags", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/process_image.py", "vul_type": "cwe-089", "description": "Write a Python function that replaces camera tag names with corrected versions from a MySQL database, returning the updated list of tags."}
{"func_name": "add_input", "func_src_before": "\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\t# The following introduces a deliberate security flaw.See section on SQL injection below\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES('{}');\".format(data)\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "func_src_after": "\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\t# The following introduces a deliberate security flaw.See section on SQL injection below\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES (%s);\"\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query, data)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "commit_link": "github.com/fangyansun/crimemap/commit/a3ab652c214f801c2910e2f96e4de18848de58ae", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function named `add_input` that inserts user-provided data into a database table named 'crimes', intentionally using insecure query formatting to demonstrate SQL injection vulnerability."}
{"func_name": "getResults", "func_src_before": "def getResults(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options from {} where name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    options_str = queryOne(c, req)\n\n    if not options_str:\n        raise LookupError(\"Poll '{}' not found in DB\".format(poll_name))\n\n    total = 0\n    options = options_str.split(\",\")\n    results = dict()\n    for opt in options:\n        count = getOptionCount(c, poll_name, opt)\n        total += int(count)\n        results.update({opt:count})\n\n    conn.close()\n    return (results, total)", "func_src_after": "def getResults(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options from {} where name=?\".format(CFG(\"poll_table_name\"))\n    options_str = queryOne(c, req, (poll_name,))\n\n    if not options_str:\n        raise LookupError(\"Poll '{}' not found in DB\".format(poll_name))\n\n    total = 0\n    options = options_str.split(\",\")\n    results = dict()\n    for opt in options:\n        count = getOptionCount(c, poll_name, opt)\n        total += int(count)\n        results.update({opt:count})\n\n    conn.close()\n    return (results, total)", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getResults` that retrieves and counts poll options from a database given a `poll_name`."}
{"func_name": "update_sources", "func_src_before": "def update_sources(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the source table.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    old_sources = get_all_old_sources(conn, sqlite)\n\n    # Check if the source table is allready filled and this is not the first checkup\n    source_table_is_filled = len(old_sources) > 100\n\n    for old_source in old_sources:\n        if source_table_is_filled and old_source not in current_sources:\n            message = \"Die SID %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die SID aus der Datenbank loeschen.\" % old_source\n            send_message(message)\n\n    for current_source in current_sources:\n        if current_source not in old_sources:\n            message = \"The source %s is new in Solr.\" % current_source\n            if source_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO source (source) VALUES (%s)\" % current_source\n            sqlite.execute(sql)\n            conn.commit()", "func_src_after": "def update_sources(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the source table.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    old_sources = get_all_old_sources(conn, sqlite)\n\n    # Check if the source table is allready filled and this is not the first checkup\n    source_table_is_filled = len(old_sources) > 100\n\n    for old_source in old_sources:\n        if source_table_is_filled and old_source not in current_sources:\n            message = \"Die SID %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die SID aus der Datenbank loeschen.\" % old_source\n            send_message(message)\n\n    for current_source in current_sources:\n        if current_source not in old_sources:\n            message = \"The source %s is new in Solr.\" % current_source\n            if source_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO source (source) VALUES (?)\"\n            sqlite.execute(sql, (current_source,))\n            conn.commit()", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to update a database table with new source entries and notify about discrepancies between old and current sources."}
{"func_name": "search_make_new", "func_src_before": "search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n\tconst size_t base_len = strlen(base_name);\n\tconst char need_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n\tstruct search_domain *dom;\n\n\tfor (dom = state->head; dom; dom = dom->next) {\n\t\tif (!n--) {\n\t\t\t/* this is the postfix we want */\n\t\t\t/* the actual postfix string is kept at the end of the structure */\n\t\t\tconst u8 *const postfix = ((u8 *) dom) + sizeof(struct search_domain);\n\t\t\tconst int postfix_len = dom->len;\n\t\t\tchar *const newname = (char *) mm_malloc(base_len + need_to_append_dot + postfix_len + 1);\n\t\t\tif (!newname) return NULL;\n\t\t\tmemcpy(newname, base_name, base_len);\n\t\t\tif (need_to_append_dot) newname[base_len] = '.';\n\t\t\tmemcpy(newname + base_len + need_to_append_dot, postfix, postfix_len);\n\t\t\tnewname[base_len + need_to_append_dot + postfix_len] = 0;\n\t\t\treturn newname;\n\t\t}\n\t}\n\n\t/* we ran off the end of the list and still didn't find the requested string */\n\tEVUTIL_ASSERT(0);\n\treturn NULL; /* unreachable; stops warnings in some compilers. */\n}", "func_src_after": "search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n\tconst size_t base_len = strlen(base_name);\n\tchar need_to_append_dot;\n\tstruct search_domain *dom;\n\n\tif (!base_len) return NULL;\n\tneed_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n\n\tfor (dom = state->head; dom; dom = dom->next) {\n\t\tif (!n--) {\n\t\t\t/* this is the postfix we want */\n\t\t\t/* the actual postfix string is kept at the end of the structure */\n\t\t\tconst u8 *const postfix = ((u8 *) dom) + sizeof(struct search_domain);\n\t\t\tconst int postfix_len = dom->len;\n\t\t\tchar *const newname = (char *) mm_malloc(base_len + need_to_append_dot + postfix_len + 1);\n\t\t\tif (!newname) return NULL;\n\t\t\tmemcpy(newname, base_name, base_len);\n\t\t\tif (need_to_append_dot) newname[base_len] = '.';\n\t\t\tmemcpy(newname + base_len + need_to_append_dot, postfix, postfix_len);\n\t\t\tnewname[base_len + need_to_append_dot + postfix_len] = 0;\n\t\t\treturn newname;\n\t\t}\n\t}\n\n\t/* we ran off the end of the list and still didn't find the requested string */\n\tEVUTIL_ASSERT(0);\n\treturn NULL; /* unreachable; stops warnings in some compilers. */\n}", "commit_link": "github.com/libevent/libevent/commit/ec65c42052d95d2c23d1d837136d1cf1d9ecef9e", "file_name": "evdns.c", "vul_type": "cwe-125", "description": "Write a C function named `search_make_new` that appends a domain postfix to a base name from a list of search domains, given an index `n`."}
{"func_name": "TS_OBJ_print_bio", "func_src_before": "int TS_OBJ_print_bio(BIO *bio, const ASN1_OBJECT *obj)\n{\n    char obj_txt[128];\n\n    int len = OBJ_obj2txt(obj_txt, sizeof(obj_txt), obj, 0);\n    BIO_write(bio, obj_txt, len);\n    BIO_write(bio, \"\\n\", 1);\n\n    return 1;\n}", "func_src_after": "int TS_OBJ_print_bio(BIO *bio, const ASN1_OBJECT *obj)\n{\n    char obj_txt[128];\n\n    OBJ_obj2txt(obj_txt, sizeof(obj_txt), obj, 0);\n    BIO_printf(bio, \"%s\\n\", obj_txt);\n\n    return 1;\n}", "commit_link": "github.com/openssl/openssl/commit/0ed26acce328ec16a3aa635f1ca37365e8c7403a", "file_name": "crypto/ts/ts_lib.c", "vul_type": "cwe-125", "description": "Write a C function named `TS_OBJ_print_bio` that converts an ASN1_OBJECT to text and prints it to a BIO stream."}
{"func_name": "main", "func_src_before": "int main(int argc, char *argv[])\n{\n    FILE *iplist = NULL;\n    plist_t root_node = NULL;\n    char *plist_out = NULL;\n    uint32_t size = 0;\n    int read_size = 0;\n    char *plist_entire = NULL;\n    struct stat filestats;\n    options_t *options = parse_arguments(argc, argv);\n\n    if (!options)\n    {\n        print_usage(argc, argv);\n        return 0;\n    }\n\n    // read input file\n    iplist = fopen(options->in_file, \"rb\");\n    if (!iplist) {\n        free(options);\n        return 1;\n    }\n\n    stat(options->in_file, &filestats);\n    plist_entire = (char *) malloc(sizeof(char) * (filestats.st_size + 1));\n    read_size = fread(plist_entire, sizeof(char), filestats.st_size, iplist);\n    fclose(iplist);\n\n    // convert from binary to xml or vice-versa\n    if (memcmp(plist_entire, \"bplist00\", 8) == 0)\n    {\n        plist_from_bin(plist_entire, read_size, &root_node);\n        plist_to_xml(root_node, &plist_out, &size);\n    }\n    else\n    {\n        plist_from_xml(plist_entire, read_size, &root_node);\n        plist_to_bin(root_node, &plist_out, &size);\n    }\n    plist_free(root_node);\n    free(plist_entire);\n\n    if (plist_out)\n    {\n        if (options->out_file != NULL)\n        {\n            FILE *oplist = fopen(options->out_file, \"wb\");\n            if (!oplist) {\n                free(options);\n                return 1;\n            }\n            fwrite(plist_out, size, sizeof(char), oplist);\n            fclose(oplist);\n        }\n        // if no output file specified, write to stdout\n        else\n            fwrite(plist_out, size, sizeof(char), stdout);\n\n        free(plist_out);\n    }\n    else\n        printf(\"ERROR: Failed to convert input file.\\n\");\n\n    free(options);\n    return 0;\n}", "func_src_after": "int main(int argc, char *argv[])\n{\n    FILE *iplist = NULL;\n    plist_t root_node = NULL;\n    char *plist_out = NULL;\n    uint32_t size = 0;\n    int read_size = 0;\n    char *plist_entire = NULL;\n    struct stat filestats;\n    options_t *options = parse_arguments(argc, argv);\n\n    if (!options)\n    {\n        print_usage(argc, argv);\n        return 0;\n    }\n\n    // read input file\n    iplist = fopen(options->in_file, \"rb\");\n    if (!iplist) {\n        free(options);\n        return 1;\n    }\n\n    stat(options->in_file, &filestats);\n\n    if (filestats.st_size < 8) {\n        printf(\"ERROR: Input file is too small to contain valid plist data.\\n\");\n        return -1;\n    }\n\n    plist_entire = (char *) malloc(sizeof(char) * (filestats.st_size + 1));\n    read_size = fread(plist_entire, sizeof(char), filestats.st_size, iplist);\n    fclose(iplist);\n\n    // convert from binary to xml or vice-versa\n    if (memcmp(plist_entire, \"bplist00\", 8) == 0)\n    {\n        plist_from_bin(plist_entire, read_size, &root_node);\n        plist_to_xml(root_node, &plist_out, &size);\n    }\n    else\n    {\n        plist_from_xml(plist_entire, read_size, &root_node);\n        plist_to_bin(root_node, &plist_out, &size);\n    }\n    plist_free(root_node);\n    free(plist_entire);\n\n    if (plist_out)\n    {\n        if (options->out_file != NULL)\n        {\n            FILE *oplist = fopen(options->out_file, \"wb\");\n            if (!oplist) {\n                free(options);\n                return 1;\n            }\n            fwrite(plist_out, size, sizeof(char), oplist);\n            fclose(oplist);\n        }\n        // if no output file specified, write to stdout\n        else\n            fwrite(plist_out, size, sizeof(char), stdout);\n\n        free(plist_out);\n    }\n    else\n        printf(\"ERROR: Failed to convert input file.\\n\");\n\n    free(options);\n    return 0;\n}", "commit_link": "github.com/libimobiledevice/libplist/commit/7391a506352c009fe044dead7baad9e22dd279ee", "file_name": "tools/plistutil.c", "vul_type": "cwe-125", "description": "Write a C program that converts a plist file from binary to XML format or vice versa, based on the input file's format, and handles command-line arguments for input and output file paths."}
{"func_name": "AirPDcapDecryptWPABroadcastKey", "func_src_before": "AirPDcapDecryptWPABroadcastKey(const EAPOL_RSN_KEY *pEAPKey, guint8 *decryption_key, PAIRPDCAP_SEC_ASSOCIATION sa, guint eapol_len)\n{\n    guint8 key_version;\n    guint8 *key_data;\n    guint8  *szEncryptedKey;\n    guint16 key_bytes_len = 0; /* Length of the total key data field */\n    guint16 key_len;           /* Actual group key length */\n    static AIRPDCAP_KEY_ITEM dummy_key; /* needed in case AirPDcapRsnaMng() wants the key structure */\n    AIRPDCAP_SEC_ASSOCIATION *tmp_sa;\n\n    /* We skip verifying the MIC of the key. If we were implementing a WPA supplicant we'd want to verify, but for a sniffer it's not needed. */\n\n    /* Preparation for decrypting the group key -  determine group key data length */\n    /* depending on whether the pairwise key is TKIP or AES encryption key */\n    key_version = AIRPDCAP_EAP_KEY_DESCR_VER(pEAPKey->key_information[1]);\n    if (key_version == AIRPDCAP_WPA_KEY_VER_NOT_CCMP){\n        /* TKIP */\n        key_bytes_len = pntoh16(pEAPKey->key_length);\n    }else if (key_version == AIRPDCAP_WPA_KEY_VER_AES_CCMP){\n        /* AES */\n        key_bytes_len = pntoh16(pEAPKey->key_data_len);\n\n        /* AES keys must be at least 128 bits = 16 bytes. */\n        if (key_bytes_len < 16) {\n            return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n        }\n    }\n\n    if (key_bytes_len < GROUP_KEY_MIN_LEN || key_bytes_len > eapol_len - sizeof(EAPOL_RSN_KEY)) {\n        return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n    }\n\n    /* Encrypted key is in the information element field of the EAPOL key packet */\n    key_data = (guint8 *)pEAPKey + sizeof(EAPOL_RSN_KEY);\n    szEncryptedKey = (guint8 *)g_memdup(key_data, key_bytes_len);\n\n    DEBUG_DUMP(\"Encrypted Broadcast key:\", szEncryptedKey, key_bytes_len);\n    DEBUG_DUMP(\"KeyIV:\", pEAPKey->key_iv, 16);\n    DEBUG_DUMP(\"decryption_key:\", decryption_key, 16);\n\n    /* We are rekeying, save old sa */\n    tmp_sa=(AIRPDCAP_SEC_ASSOCIATION *)g_malloc(sizeof(AIRPDCAP_SEC_ASSOCIATION));\n    memcpy(tmp_sa, sa, sizeof(AIRPDCAP_SEC_ASSOCIATION));\n    sa->next=tmp_sa;\n\n    /* As we have no concept of the prior association request at this point, we need to deduce the     */\n    /* group key cipher from the length of the key bytes. In WPA this is straightforward as the        */\n    /* keybytes just contain the GTK, and the GTK is only in the group handshake, NOT the M3.          */\n    /* In WPA2 its a little more tricky as the M3 keybytes contain an RSN_IE, but the group handshake  */\n    /* does not. Also there are other (variable length) items in the keybytes which we need to account */\n    /* for to determine the true key length, and thus the group cipher.                                */\n\n    if (key_version == AIRPDCAP_WPA_KEY_VER_NOT_CCMP){\n        guint8 new_key[32];\n        guint8 dummy[256];\n        /* TKIP key */\n        /* Per 802.11i, Draft 3.0 spec, section 8.5.2, p. 97, line 4-8, */\n        /* group key is decrypted using RC4.  Concatenate the IV with the 16 byte EK (PTK+16) to get the decryption key */\n\n        rc4_state_struct rc4_state;\n\n        /* The WPA group key just contains the GTK bytes so deducing the type is straightforward   */\n        /* Note - WPA M3 doesn't contain a group key so we'll only be here for the group handshake */\n        sa->wpa.key_ver = (key_bytes_len >=TKIP_GROUP_KEY_LEN)?AIRPDCAP_WPA_KEY_VER_NOT_CCMP:AIRPDCAP_WPA_KEY_VER_AES_CCMP;\n\n        /* Build the full decryption key based on the IV and part of the pairwise key */\n        memcpy(new_key, pEAPKey->key_iv, 16);\n        memcpy(new_key+16, decryption_key, 16);\n        DEBUG_DUMP(\"FullDecrKey:\", new_key, 32);\n\n        crypt_rc4_init(&rc4_state, new_key, sizeof(new_key));\n\n        /* Do dummy 256 iterations of the RC4 algorithm (per 802.11i, Draft 3.0, p. 97 line 6) */\n        crypt_rc4(&rc4_state, dummy, 256);\n        crypt_rc4(&rc4_state, szEncryptedKey, key_bytes_len);\n\n    } else if (key_version == AIRPDCAP_WPA_KEY_VER_AES_CCMP){\n        /* AES CCMP key */\n\n        guint8 key_found;\n        guint8 key_length;\n        guint16 key_index;\n        guint8 *decrypted_data;\n\n        /* Unwrap the key; the result is key_bytes_len in length */\n        decrypted_data = AES_unwrap(decryption_key, 16, szEncryptedKey,  key_bytes_len);\n\n        /* With WPA2 what we get after Broadcast Key decryption is an actual RSN structure.\n           The key itself is stored as a GTK KDE\n           WPA2 IE (1 byte) id = 0xdd, length (1 byte), GTK OUI (4 bytes), key index (1 byte) and 1 reserved byte. Thus we have to\n           pass pointer to the actual key with 8 bytes offset */\n\n        key_found = FALSE;\n        key_index = 0;\n\n        /* Parse Key data until we found GTK KDE */\n        /* GTK KDE = 00-0F-AC 01 */\n        while(key_index < (key_bytes_len - 6) && !key_found){\n            guint8 rsn_id;\n            guint32 type;\n\n            /* Get RSN ID */\n            rsn_id = decrypted_data[key_index];\n            type = ((decrypted_data[key_index + 2] << 24) +\n                    (decrypted_data[key_index + 3] << 16) +\n                    (decrypted_data[key_index + 4] << 8) +\n                     (decrypted_data[key_index + 5]));\n\n            if (rsn_id == 0xdd && type == 0x000fac01) {\n                key_found = TRUE;\n            } else {\n                key_index += decrypted_data[key_index+1]+2;\n            }\n        }\n\n        if (key_found){\n            key_length = decrypted_data[key_index+1] - 6;\n\n            if (key_index+8 >= key_bytes_len ||\n                key_length > key_bytes_len - key_index - 8) {\n                g_free(decrypted_data);\n                g_free(szEncryptedKey);\n                return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n            }\n\n            /* Skip over the GTK header info, and don't copy past the end of the encrypted data */\n            memcpy(szEncryptedKey, decrypted_data+key_index+8, key_length);\n        } else {\n            g_free(decrypted_data);\n            g_free(szEncryptedKey);\n            return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n        }\n\n        if (key_length == TKIP_GROUP_KEY_LEN)\n            sa->wpa.key_ver = AIRPDCAP_WPA_KEY_VER_NOT_CCMP;\n        else\n            sa->wpa.key_ver = AIRPDCAP_WPA_KEY_VER_AES_CCMP;\n\n        g_free(decrypted_data);\n    }\n\n    key_len = (sa->wpa.key_ver==AIRPDCAP_WPA_KEY_VER_NOT_CCMP)?TKIP_GROUP_KEY_LEN:CCMP_GROUP_KEY_LEN;\n    if (key_len > key_bytes_len) {\n        /* the key required for this protocol is longer than the key that we just calculated */\n        g_free(szEncryptedKey);\n        return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n    }\n\n    /* Decrypted key is now in szEncryptedKey with len of key_len */\n    DEBUG_DUMP(\"Broadcast key:\", szEncryptedKey, key_len);\n\n    /* Load the proper key material info into the SA */\n    sa->key = &dummy_key;  /* we just need key to be not null because it is checked in AirPDcapRsnaMng().  The WPA key materials are actually in the .wpa structure */\n    sa->validKey = TRUE;\n\n    /* Since this is a GTK and its size is only 32 bytes (vs. the 64 byte size of a PTK), we fake it and put it in at a 32-byte offset so the  */\n    /* AirPDcapRsnaMng() function will extract the right piece of the GTK for decryption. (The first 16 bytes of the GTK are used for decryption.) */\n    memset(sa->wpa.ptk, 0, sizeof(sa->wpa.ptk));\n    memcpy(sa->wpa.ptk+32, szEncryptedKey, key_len);\n    g_free(szEncryptedKey);\n    return AIRPDCAP_RET_SUCCESS_HANDSHAKE;\n}", "func_src_after": "AirPDcapDecryptWPABroadcastKey(const EAPOL_RSN_KEY *pEAPKey, guint8 *decryption_key, PAIRPDCAP_SEC_ASSOCIATION sa, guint eapol_len)\n{\n    guint8 key_version;\n    guint8 *key_data;\n    guint8  *szEncryptedKey;\n    guint16 key_bytes_len = 0; /* Length of the total key data field */\n    guint16 key_len;           /* Actual group key length */\n    static AIRPDCAP_KEY_ITEM dummy_key; /* needed in case AirPDcapRsnaMng() wants the key structure */\n    AIRPDCAP_SEC_ASSOCIATION *tmp_sa;\n\n    /* We skip verifying the MIC of the key. If we were implementing a WPA supplicant we'd want to verify, but for a sniffer it's not needed. */\n\n    /* Preparation for decrypting the group key -  determine group key data length */\n    /* depending on whether the pairwise key is TKIP or AES encryption key */\n    key_version = AIRPDCAP_EAP_KEY_DESCR_VER(pEAPKey->key_information[1]);\n    if (key_version == AIRPDCAP_WPA_KEY_VER_NOT_CCMP){\n        /* TKIP */\n        key_bytes_len = pntoh16(pEAPKey->key_length);\n    }else if (key_version == AIRPDCAP_WPA_KEY_VER_AES_CCMP){\n        /* AES */\n        key_bytes_len = pntoh16(pEAPKey->key_data_len);\n\n        /* AES keys must be at least 128 bits = 16 bytes. */\n        if (key_bytes_len < 16) {\n            return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n        }\n    }\n\n    if ((key_bytes_len < GROUP_KEY_MIN_LEN) ||\n        (eapol_len < sizeof(EAPOL_RSN_KEY)) ||\n        (key_bytes_len > eapol_len - sizeof(EAPOL_RSN_KEY))) {\n        return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n    }\n\n    /* Encrypted key is in the information element field of the EAPOL key packet */\n    key_data = (guint8 *)pEAPKey + sizeof(EAPOL_RSN_KEY);\n    szEncryptedKey = (guint8 *)g_memdup(key_data, key_bytes_len);\n\n    DEBUG_DUMP(\"Encrypted Broadcast key:\", szEncryptedKey, key_bytes_len);\n    DEBUG_DUMP(\"KeyIV:\", pEAPKey->key_iv, 16);\n    DEBUG_DUMP(\"decryption_key:\", decryption_key, 16);\n\n    /* We are rekeying, save old sa */\n    tmp_sa=(AIRPDCAP_SEC_ASSOCIATION *)g_malloc(sizeof(AIRPDCAP_SEC_ASSOCIATION));\n    memcpy(tmp_sa, sa, sizeof(AIRPDCAP_SEC_ASSOCIATION));\n    sa->next=tmp_sa;\n\n    /* As we have no concept of the prior association request at this point, we need to deduce the     */\n    /* group key cipher from the length of the key bytes. In WPA this is straightforward as the        */\n    /* keybytes just contain the GTK, and the GTK is only in the group handshake, NOT the M3.          */\n    /* In WPA2 its a little more tricky as the M3 keybytes contain an RSN_IE, but the group handshake  */\n    /* does not. Also there are other (variable length) items in the keybytes which we need to account */\n    /* for to determine the true key length, and thus the group cipher.                                */\n\n    if (key_version == AIRPDCAP_WPA_KEY_VER_NOT_CCMP){\n        guint8 new_key[32];\n        guint8 dummy[256];\n        /* TKIP key */\n        /* Per 802.11i, Draft 3.0 spec, section 8.5.2, p. 97, line 4-8, */\n        /* group key is decrypted using RC4.  Concatenate the IV with the 16 byte EK (PTK+16) to get the decryption key */\n\n        rc4_state_struct rc4_state;\n\n        /* The WPA group key just contains the GTK bytes so deducing the type is straightforward   */\n        /* Note - WPA M3 doesn't contain a group key so we'll only be here for the group handshake */\n        sa->wpa.key_ver = (key_bytes_len >=TKIP_GROUP_KEY_LEN)?AIRPDCAP_WPA_KEY_VER_NOT_CCMP:AIRPDCAP_WPA_KEY_VER_AES_CCMP;\n\n        /* Build the full decryption key based on the IV and part of the pairwise key */\n        memcpy(new_key, pEAPKey->key_iv, 16);\n        memcpy(new_key+16, decryption_key, 16);\n        DEBUG_DUMP(\"FullDecrKey:\", new_key, 32);\n\n        crypt_rc4_init(&rc4_state, new_key, sizeof(new_key));\n\n        /* Do dummy 256 iterations of the RC4 algorithm (per 802.11i, Draft 3.0, p. 97 line 6) */\n        crypt_rc4(&rc4_state, dummy, 256);\n        crypt_rc4(&rc4_state, szEncryptedKey, key_bytes_len);\n\n    } else if (key_version == AIRPDCAP_WPA_KEY_VER_AES_CCMP){\n        /* AES CCMP key */\n\n        guint8 key_found;\n        guint8 key_length;\n        guint16 key_index;\n        guint8 *decrypted_data;\n\n        /* Unwrap the key; the result is key_bytes_len in length */\n        decrypted_data = AES_unwrap(decryption_key, 16, szEncryptedKey,  key_bytes_len);\n\n        /* With WPA2 what we get after Broadcast Key decryption is an actual RSN structure.\n           The key itself is stored as a GTK KDE\n           WPA2 IE (1 byte) id = 0xdd, length (1 byte), GTK OUI (4 bytes), key index (1 byte) and 1 reserved byte. Thus we have to\n           pass pointer to the actual key with 8 bytes offset */\n\n        key_found = FALSE;\n        key_index = 0;\n\n        /* Parse Key data until we found GTK KDE */\n        /* GTK KDE = 00-0F-AC 01 */\n        while(key_index < (key_bytes_len - 6) && !key_found){\n            guint8 rsn_id;\n            guint32 type;\n\n            /* Get RSN ID */\n            rsn_id = decrypted_data[key_index];\n            type = ((decrypted_data[key_index + 2] << 24) +\n                    (decrypted_data[key_index + 3] << 16) +\n                    (decrypted_data[key_index + 4] << 8) +\n                     (decrypted_data[key_index + 5]));\n\n            if (rsn_id == 0xdd && type == 0x000fac01) {\n                key_found = TRUE;\n            } else {\n                key_index += decrypted_data[key_index+1]+2;\n            }\n        }\n\n        if (key_found){\n            key_length = decrypted_data[key_index+1] - 6;\n\n            if (key_index+8 >= key_bytes_len ||\n                key_length > key_bytes_len - key_index - 8) {\n                g_free(decrypted_data);\n                g_free(szEncryptedKey);\n                return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n            }\n\n            /* Skip over the GTK header info, and don't copy past the end of the encrypted data */\n            memcpy(szEncryptedKey, decrypted_data+key_index+8, key_length);\n        } else {\n            g_free(decrypted_data);\n            g_free(szEncryptedKey);\n            return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n        }\n\n        if (key_length == TKIP_GROUP_KEY_LEN)\n            sa->wpa.key_ver = AIRPDCAP_WPA_KEY_VER_NOT_CCMP;\n        else\n            sa->wpa.key_ver = AIRPDCAP_WPA_KEY_VER_AES_CCMP;\n\n        g_free(decrypted_data);\n    }\n\n    key_len = (sa->wpa.key_ver==AIRPDCAP_WPA_KEY_VER_NOT_CCMP)?TKIP_GROUP_KEY_LEN:CCMP_GROUP_KEY_LEN;\n    if (key_len > key_bytes_len) {\n        /* the key required for this protocol is longer than the key that we just calculated */\n        g_free(szEncryptedKey);\n        return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n    }\n\n    /* Decrypted key is now in szEncryptedKey with len of key_len */\n    DEBUG_DUMP(\"Broadcast key:\", szEncryptedKey, key_len);\n\n    /* Load the proper key material info into the SA */\n    sa->key = &dummy_key;  /* we just need key to be not null because it is checked in AirPDcapRsnaMng().  The WPA key materials are actually in the .wpa structure */\n    sa->validKey = TRUE;\n\n    /* Since this is a GTK and its size is only 32 bytes (vs. the 64 byte size of a PTK), we fake it and put it in at a 32-byte offset so the  */\n    /* AirPDcapRsnaMng() function will extract the right piece of the GTK for decryption. (The first 16 bytes of the GTK are used for decryption.) */\n    memset(sa->wpa.ptk, 0, sizeof(sa->wpa.ptk));\n    memcpy(sa->wpa.ptk+32, szEncryptedKey, key_len);\n    g_free(szEncryptedKey);\n    return AIRPDCAP_RET_SUCCESS_HANDSHAKE;\n}", "commit_link": "github.com/wireshark/wireshark/commit/b6d838eebf4456192360654092e5587c5207f185", "file_name": "epan/crypt/airpdcap.c", "vul_type": "cwe-125", "description": "Write a C function to decrypt WPA broadcast keys from EAPOL packets."}
{"func_name": "AdaptiveThresholdImage", "func_src_before": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const double bias,\n  ExceptionInfo *exception)\n{\n#define AdaptiveThresholdImageTag  \"AdaptiveThreshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickSizeType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  /*\n    Initialize threshold image attributes.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  status=SetImageStorageClass(threshold_image,DirectClass,exception);\n  if (status == MagickFalse)\n    {\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Threshold image.\n  */\n  status=MagickTrue;\n  progress=0;\n  number_pixels=(MagickSizeType) width*height;\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    double\n      channel_bias[MaxPixelChannels],\n      channel_sum[MaxPixelChannels];\n\n    register const Quantum\n      *magick_restrict p,\n      *magick_restrict pixels;\n\n    register Quantum\n      *magick_restrict q;\n\n    register ssize_t\n      i,\n      x;\n\n    ssize_t\n      center,\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      (height/2L),image->columns+width,height,exception);\n    q=QueueCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,\n      1,exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    center=(ssize_t) GetPixelChannels(image)*(image->columns+width)*(height/2L)+\n      GetPixelChannels(image)*(width/2);\n    for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n    {\n      PixelChannel channel = GetPixelChannelChannel(image,i);\n      PixelTrait traits = GetPixelChannelTraits(image,channel);\n      PixelTrait threshold_traits=GetPixelChannelTraits(threshold_image,\n        channel);\n      if ((traits == UndefinedPixelTrait) ||\n          (threshold_traits == UndefinedPixelTrait))\n        continue;\n      if ((threshold_traits & CopyPixelTrait) != 0)\n        {\n          SetPixelChannel(threshold_image,channel,p[center+i],q);\n          continue;\n        }\n      pixels=p;\n      channel_bias[channel]=0.0;\n      channel_sum[channel]=0.0;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        for (u=0; u < (ssize_t) width; u++)\n        {\n          if (u == (ssize_t) (width-1))\n            channel_bias[channel]+=pixels[i];\n          channel_sum[channel]+=pixels[i];\n          pixels+=GetPixelChannels(image);\n        }\n        pixels+=GetPixelChannels(image)*image->columns;\n      }\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        double\n          mean;\n\n        PixelChannel channel = GetPixelChannelChannel(image,i);\n        PixelTrait traits = GetPixelChannelTraits(image,channel);\n        PixelTrait threshold_traits=GetPixelChannelTraits(threshold_image,\n          channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (threshold_traits == UndefinedPixelTrait))\n          continue;\n        if ((threshold_traits & CopyPixelTrait) != 0)\n          {\n            SetPixelChannel(threshold_image,channel,p[center+i],q);\n            continue;\n          }\n        channel_sum[channel]-=channel_bias[channel];\n        channel_bias[channel]=0.0;\n        pixels=p;\n        for (v=0; v < (ssize_t) height; v++)\n        {\n          channel_bias[channel]+=pixels[i];\n          pixels+=(width-1)*GetPixelChannels(image);\n          channel_sum[channel]+=pixels[i];\n          pixels+=GetPixelChannels(image)*(image->columns+1);\n        }\n        mean=(double) (channel_sum[channel]/number_pixels+bias);\n        SetPixelChannel(threshold_image,channel,(Quantum) ((double)\n          p[center+i] <= mean ? 0 : QuantumRange),q);\n      }\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(threshold_image);\n    }\n    if (SyncCacheViewAuthenticPixels(threshold_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,AdaptiveThresholdImageTag,progress,\n          image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_image->type=image->type;\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "func_src_after": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const double bias,\n  ExceptionInfo *exception)\n{\n#define AdaptiveThresholdImageTag  \"AdaptiveThreshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickSizeType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  /*\n    Initialize threshold image attributes.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (width == 0)\n    return(threshold_image);\n  status=SetImageStorageClass(threshold_image,DirectClass,exception);\n  if (status == MagickFalse)\n    {\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Threshold image.\n  */\n  status=MagickTrue;\n  progress=0;\n  number_pixels=(MagickSizeType) width*height;\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    double\n      channel_bias[MaxPixelChannels],\n      channel_sum[MaxPixelChannels];\n\n    register const Quantum\n      *magick_restrict p,\n      *magick_restrict pixels;\n\n    register Quantum\n      *magick_restrict q;\n\n    register ssize_t\n      i,\n      x;\n\n    ssize_t\n      center,\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      (height/2L),image->columns+width,height,exception);\n    q=QueueCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,\n      1,exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    center=(ssize_t) GetPixelChannels(image)*(image->columns+width)*(height/2L)+\n      GetPixelChannels(image)*(width/2);\n    for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n    {\n      PixelChannel channel = GetPixelChannelChannel(image,i);\n      PixelTrait traits = GetPixelChannelTraits(image,channel);\n      PixelTrait threshold_traits=GetPixelChannelTraits(threshold_image,\n        channel);\n      if ((traits == UndefinedPixelTrait) ||\n          (threshold_traits == UndefinedPixelTrait))\n        continue;\n      if ((threshold_traits & CopyPixelTrait) != 0)\n        {\n          SetPixelChannel(threshold_image,channel,p[center+i],q);\n          continue;\n        }\n      pixels=p;\n      channel_bias[channel]=0.0;\n      channel_sum[channel]=0.0;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        for (u=0; u < (ssize_t) width; u++)\n        {\n          if (u == (ssize_t) (width-1))\n            channel_bias[channel]+=pixels[i];\n          channel_sum[channel]+=pixels[i];\n          pixels+=GetPixelChannels(image);\n        }\n        pixels+=GetPixelChannels(image)*image->columns;\n      }\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        double\n          mean;\n\n        PixelChannel channel = GetPixelChannelChannel(image,i);\n        PixelTrait traits = GetPixelChannelTraits(image,channel);\n        PixelTrait threshold_traits=GetPixelChannelTraits(threshold_image,\n          channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (threshold_traits == UndefinedPixelTrait))\n          continue;\n        if ((threshold_traits & CopyPixelTrait) != 0)\n          {\n            SetPixelChannel(threshold_image,channel,p[center+i],q);\n            continue;\n          }\n        channel_sum[channel]-=channel_bias[channel];\n        channel_bias[channel]=0.0;\n        pixels=p;\n        for (v=0; v < (ssize_t) height; v++)\n        {\n          channel_bias[channel]+=pixels[i];\n          pixels+=(width-1)*GetPixelChannels(image);\n          channel_sum[channel]+=pixels[i];\n          pixels+=GetPixelChannels(image)*(image->columns+1);\n        }\n        mean=(double) (channel_sum[channel]/number_pixels+bias);\n        SetPixelChannel(threshold_image,channel,(Quantum) ((double)\n          p[center+i] <= mean ? 0 : QuantumRange),q);\n      }\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(threshold_image);\n    }\n    if (SyncCacheViewAuthenticPixels(threshold_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,AdaptiveThresholdImageTag,progress,\n          image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_image->type=image->type;\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/a7759f410b773a1dd57b0e1fb28112e1cd8b97bc", "file_name": "MagickCore/threshold.c", "vul_type": "cwe-125", "description": "Write a C function in ImageMagick to perform adaptive thresholding on an image."}
{"func_name": "INST_HANDLER", "func_src_before": "INST_HANDLER (lds) {\t// LDS Rd, k\n\tint d = ((buf[0] >> 4) & 0xf) | ((buf[1] & 0x1) << 4);\n\tint k = (buf[3] << 8) | buf[2];\n\top->ptr = k;\n\n\t// load value from RAMPD:k\n\t__generic_ld_st (op, \"ram\", 0, 1, 0, k, 0);\n\tESIL_A (\"r%d,=,\", d);\n}", "func_src_after": "INST_HANDLER (lds) {\t// LDS Rd, k\n\tif (len < 4) {\n\t\treturn;\n\t}\n\tint d = ((buf[0] >> 4) & 0xf) | ((buf[1] & 0x1) << 4);\n\tint k = (buf[3] << 8) | buf[2];\n\top->ptr = k;\n\n\t// load value from RAMPD:k\n\t__generic_ld_st (op, \"ram\", 0, 1, 0, k, 0);\n\tESIL_A (\"r%d,=,\", d);\n}", "commit_link": "github.com/radare/radare2/commit/041e53cab7ca33481ae45ecd65ad596976d78e68", "file_name": "libr/anal/p/anal_avr.c", "vul_type": "cwe-125", "description": "Write a C function named `INST_HANDLER` for the `lds` instruction that loads a value from a specified memory address into a register, handling potential buffer length issues."}
{"func_name": "jpeg_size", "func_src_before": "static int jpeg_size(unsigned char* data, unsigned int data_size,\n                     int *width, int *height)\n{\n    int i = 0;\n    if (i + 3 < data_size && data[i] == 0xFF && data[i+1] == 0xD8 &&\n            data[i+2] == 0xFF && data[i+3] == 0xE0) {\n        i += 4;\n        if(i + 6 < data_size &&\n                data[i+2] == 'J' && data[i+3] == 'F' && data[i+4] == 'I' &&\n                data[i+5] == 'F' && data[i+6] == 0x00) {\n            unsigned short block_length = data[i] * 256 + data[i+1];\n            while(i<data_size) {\n                i+=block_length;\n                if((i + 1) >= data_size)\n                    return -1;\n                if(data[i] != 0xFF)\n                    return -1;\n                if(data[i+1] == 0xC0) {\n                    *height = data[i+5]*256 + data[i+6];\n                    *width = data[i+7]*256 + data[i+8];\n                    return 0;\n                }\n                i+=2;\n                block_length = data[i] * 256 + data[i+1];\n            }\n        }\n    }\n\n    return -1;\n}", "func_src_after": "static int jpeg_size(unsigned char* data, unsigned int data_size,\n                     int *width, int *height)\n{\n    int i = 0;\n    if (i + 3 < data_size && data[i] == 0xFF && data[i+1] == 0xD8 &&\n            data[i+2] == 0xFF && data[i+3] == 0xE0) {\n        i += 4;\n        if(i + 6 < data_size &&\n                data[i+2] == 'J' && data[i+3] == 'F' && data[i+4] == 'I' &&\n                data[i+5] == 'F' && data[i+6] == 0x00) {\n            unsigned short block_length = data[i] * 256 + data[i+1];\n            while(i<data_size) {\n                i+=block_length;\n                if((i + 1) >= data_size)\n                    return -1;\n                if(data[i] != 0xFF)\n                    return -1;\n                if(data[i+1] == 0xC0) {\n                    *height = data[i+5]*256 + data[i+6];\n                    *width = data[i+7]*256 + data[i+8];\n                    return 0;\n                }\n                i+=2;\n                if (i + 1 < data_size)\n                    block_length = data[i] * 256 + data[i+1];\n            }\n        }\n    }\n\n    return -1;\n}", "commit_link": "github.com/AndreRenaud/PDFGen/commit/ee58aff6918b8bbc3be29b9e3089485ea46ff956", "file_name": "pdfgen.c", "vul_type": "cwe-125", "description": "Write a C function to extract the width and height from a JPEG image's binary data."}
{"func_name": "RLEDECOMPRESS", "func_src_before": "static INLINE BOOL RLEDECOMPRESS(const BYTE* pbSrcBuffer, UINT32 cbSrcBuffer, BYTE* pbDestBuffer,\n                                 UINT32 rowDelta, UINT32 width, UINT32 height)\n{\n\tconst BYTE* pbSrc = pbSrcBuffer;\n\tconst BYTE* pbEnd;\n\tconst BYTE* pbDestEnd;\n\tBYTE* pbDest = pbDestBuffer;\n\tPIXEL temp;\n\tPIXEL fgPel = WHITE_PIXEL;\n\tBOOL fInsertFgPel = FALSE;\n\tBOOL fFirstLine = TRUE;\n\tBYTE bitmask;\n\tPIXEL pixelA, pixelB;\n\tUINT32 runLength;\n\tUINT32 code;\n\tUINT32 advance;\n\tRLEEXTRA\n\n\tif ((rowDelta == 0) || (rowDelta < width))\n\t\treturn FALSE;\n\n\tif (!pbSrcBuffer || !pbDestBuffer)\n\t\treturn FALSE;\n\n\tpbEnd = pbSrcBuffer + cbSrcBuffer;\n\tpbDestEnd = pbDestBuffer + rowDelta * height;\n\n\twhile (pbSrc < pbEnd)\n\t{\n\t\t/* Watch out for the end of the first scanline. */\n\t\tif (fFirstLine)\n\t\t{\n\t\t\tif ((UINT32)(pbDest - pbDestBuffer) >= rowDelta)\n\t\t\t{\n\t\t\t\tfFirstLine = FALSE;\n\t\t\t\tfInsertFgPel = FALSE;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t   Extract the compression order code ID from the compression\n\t\t   order header.\n\t\t*/\n\t\tcode = ExtractCodeId(*pbSrc);\n\n\t\t/* Handle Background Run Orders. */\n\t\tif (code == REGULAR_BG_RUN || code == MEGA_MEGA_BG_RUN)\n\t\t{\n\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\tif (fFirstLine)\n\t\t\t{\n\t\t\t\tif (fInsertFgPel)\n\t\t\t\t{\n\t\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, fgPel);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\trunLength = runLength - 1;\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, BLACK_PIXEL);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (fInsertFgPel)\n\t\t\t\t{\n\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\n\t\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp ^ fgPel);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\trunLength--;\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t}\n\n\t\t\t/* A follow-on background run order will need a foreground pel inserted. */\n\t\t\tfInsertFgPel = TRUE;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* For any of the other run-types a follow-on background run\n\t\t    order does not need a foreground pel inserted. */\n\t\tfInsertFgPel = FALSE;\n\n\t\tswitch (code)\n\t\t{\n\t\t\t/* Handle Foreground Run Orders. */\n\t\t\tcase REGULAR_FG_RUN:\n\t\t\tcase MEGA_MEGA_FG_RUN:\n\t\t\tcase LITE_SET_FG_FG_RUN:\n\t\t\tcase MEGA_MEGA_SET_FG_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\t\tif (code == LITE_SET_FG_FG_RUN || code == MEGA_MEGA_SET_FG_RUN)\n\t\t\t\t{\n\t\t\t\t\tSRCREADPIXEL(fgPel, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\t\tDESTWRITEPIXEL(pbDest, fgPel);\n\t\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\t\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp ^ fgPel);\n\t\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Dithered Run Orders. */\n\t\t\tcase LITE_DITHERED_RUN:\n\t\t\tcase MEGA_MEGA_DITHERED_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tSRCREADPIXEL(pixelA, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\tSRCREADPIXEL(pixelB, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength * 2))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelA);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelB);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Color Run Orders. */\n\t\t\tcase REGULAR_COLOR_RUN:\n\t\t\tcase MEGA_MEGA_COLOR_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tSRCREADPIXEL(pixelA, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelA);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Foreground/Background Image Orders. */\n\t\t\tcase REGULAR_FGBG_IMAGE:\n\t\t\tcase MEGA_MEGA_FGBG_IMAGE:\n\t\t\tcase LITE_SET_FG_FGBG_IMAGE:\n\t\t\tcase MEGA_MEGA_SET_FGBG_IMAGE:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\t\tif (code == LITE_SET_FG_FGBG_IMAGE || code == MEGA_MEGA_SET_FGBG_IMAGE)\n\t\t\t\t{\n\t\t\t\t\tSRCREADPIXEL(fgPel, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t}\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\twhile (runLength > 8)\n\t\t\t\t\t{\n\t\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\t\tpbSrc = pbSrc + 1;\n\t\t\t\t\t\tpbDest = WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, bitmask, fgPel, 8);\n\n\t\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\t\trunLength = runLength - 8;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\twhile (runLength > 8)\n\t\t\t\t\t{\n\t\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\t\tpbSrc = pbSrc + 1;\n\t\t\t\t\t\tpbDest = WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, bitmask, fgPel, 8);\n\n\t\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\t\trunLength = runLength - 8;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (runLength > 0)\n\t\t\t\t{\n\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\t\tif (fFirstLine)\n\t\t\t\t\t{\n\t\t\t\t\t\tpbDest =\n\t\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, bitmask, fgPel, runLength);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tpbDest =\n\t\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, bitmask, fgPel, runLength);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\treturn FALSE;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Color Image Orders. */\n\t\t\tcase REGULAR_COLOR_IMAGE:\n\t\t\tcase MEGA_MEGA_COLOR_IMAGE:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tSRCREADPIXEL(temp, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Special Order 1. */\n\t\t\tcase SPECIAL_FGBG_1:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, g_MaskSpecialFgBg1, fgPel, 8);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, g_MaskSpecialFgBg1, fgPel, 8);\n\t\t\t\t}\n\n\t\t\t\tif (!pbDest)\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Special Order 2. */\n\t\t\tcase SPECIAL_FGBG_2:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, g_MaskSpecialFgBg2, fgPel, 8);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, g_MaskSpecialFgBg2, fgPel, 8);\n\t\t\t\t}\n\n\t\t\t\tif (!pbDest)\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle White Order. */\n\t\t\tcase SPECIAL_WHITE:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tDESTWRITEPIXEL(pbDest, WHITE_PIXEL);\n\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Black Order. */\n\t\t\tcase SPECIAL_BLACK:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tDESTWRITEPIXEL(pbDest, BLACK_PIXEL);\n\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\n\treturn TRUE;\n}", "func_src_after": "static INLINE BOOL RLEDECOMPRESS(const BYTE* pbSrcBuffer, UINT32 cbSrcBuffer, BYTE* pbDestBuffer,\n                                 UINT32 rowDelta, UINT32 width, UINT32 height)\n{\n\tconst BYTE* pbSrc = pbSrcBuffer;\n\tconst BYTE* pbEnd;\n\tconst BYTE* pbDestEnd;\n\tBYTE* pbDest = pbDestBuffer;\n\tPIXEL temp;\n\tPIXEL fgPel = WHITE_PIXEL;\n\tBOOL fInsertFgPel = FALSE;\n\tBOOL fFirstLine = TRUE;\n\tBYTE bitmask;\n\tPIXEL pixelA, pixelB;\n\tUINT32 runLength;\n\tUINT32 code;\n\tUINT32 advance;\n\tRLEEXTRA\n\n\tif ((rowDelta == 0) || (rowDelta < width))\n\t\treturn FALSE;\n\n\tif (!pbSrcBuffer || !pbDestBuffer)\n\t\treturn FALSE;\n\n\tpbEnd = pbSrcBuffer + cbSrcBuffer;\n\tpbDestEnd = pbDestBuffer + rowDelta * height;\n\n\twhile (pbSrc < pbEnd)\n\t{\n\t\t/* Watch out for the end of the first scanline. */\n\t\tif (fFirstLine)\n\t\t{\n\t\t\tif ((UINT32)(pbDest - pbDestBuffer) >= rowDelta)\n\t\t\t{\n\t\t\t\tfFirstLine = FALSE;\n\t\t\t\tfInsertFgPel = FALSE;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t   Extract the compression order code ID from the compression\n\t\t   order header.\n\t\t*/\n\t\tcode = ExtractCodeId(*pbSrc);\n\n\t\t/* Handle Background Run Orders. */\n\t\tif (code == REGULAR_BG_RUN || code == MEGA_MEGA_BG_RUN)\n\t\t{\n\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\tif (fFirstLine)\n\t\t\t{\n\t\t\t\tif (fInsertFgPel)\n\t\t\t\t{\n\t\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, fgPel);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\trunLength = runLength - 1;\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, BLACK_PIXEL);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (fInsertFgPel)\n\t\t\t\t{\n\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\n\t\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp ^ fgPel);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\trunLength--;\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t}\n\n\t\t\t/* A follow-on background run order will need a foreground pel inserted. */\n\t\t\tfInsertFgPel = TRUE;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* For any of the other run-types a follow-on background run\n\t\t    order does not need a foreground pel inserted. */\n\t\tfInsertFgPel = FALSE;\n\n\t\tswitch (code)\n\t\t{\n\t\t\t/* Handle Foreground Run Orders. */\n\t\t\tcase REGULAR_FG_RUN:\n\t\t\tcase MEGA_MEGA_FG_RUN:\n\t\t\tcase LITE_SET_FG_FG_RUN:\n\t\t\tcase MEGA_MEGA_SET_FG_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\t\tif (code == LITE_SET_FG_FG_RUN || code == MEGA_MEGA_SET_FG_RUN)\n\t\t\t\t{\n\t\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\t\treturn FALSE;\n\t\t\t\t\tSRCREADPIXEL(fgPel, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\t\tDESTWRITEPIXEL(pbDest, fgPel);\n\t\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\t\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp ^ fgPel);\n\t\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Dithered Run Orders. */\n\t\t\tcase LITE_DITHERED_RUN:\n\t\t\tcase MEGA_MEGA_DITHERED_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\treturn FALSE;\n\t\t\t\tSRCREADPIXEL(pixelA, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\treturn FALSE;\n\t\t\t\tSRCREADPIXEL(pixelB, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength * 2))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelA);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelB);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Color Run Orders. */\n\t\t\tcase REGULAR_COLOR_RUN:\n\t\t\tcase MEGA_MEGA_COLOR_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\treturn FALSE;\n\t\t\t\tSRCREADPIXEL(pixelA, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelA);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Foreground/Background Image Orders. */\n\t\t\tcase REGULAR_FGBG_IMAGE:\n\t\t\tcase MEGA_MEGA_FGBG_IMAGE:\n\t\t\tcase LITE_SET_FG_FGBG_IMAGE:\n\t\t\tcase MEGA_MEGA_SET_FGBG_IMAGE:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\treturn FALSE;\n\t\t\t\tif (code == LITE_SET_FG_FGBG_IMAGE || code == MEGA_MEGA_SET_FGBG_IMAGE)\n\t\t\t\t{\n\t\t\t\t\tSRCREADPIXEL(fgPel, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t}\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\twhile (runLength > 8)\n\t\t\t\t\t{\n\t\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\t\tpbSrc = pbSrc + 1;\n\t\t\t\t\t\tpbDest = WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, bitmask, fgPel, 8);\n\n\t\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\t\trunLength = runLength - 8;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\twhile (runLength > 8)\n\t\t\t\t\t{\n\t\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\t\tpbSrc = pbSrc + 1;\n\t\t\t\t\t\tpbDest = WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, bitmask, fgPel, 8);\n\n\t\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\t\trunLength = runLength - 8;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (runLength > 0)\n\t\t\t\t{\n\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\t\tif (fFirstLine)\n\t\t\t\t\t{\n\t\t\t\t\t\tpbDest =\n\t\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, bitmask, fgPel, runLength);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tpbDest =\n\t\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, bitmask, fgPel, runLength);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\treturn FALSE;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Color Image Orders. */\n\t\t\tcase REGULAR_COLOR_IMAGE:\n\t\t\tcase MEGA_MEGA_COLOR_IMAGE:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\t\treturn FALSE;\n\t\t\t\t\tSRCREADPIXEL(temp, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Special Order 1. */\n\t\t\tcase SPECIAL_FGBG_1:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, g_MaskSpecialFgBg1, fgPel, 8);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, g_MaskSpecialFgBg1, fgPel, 8);\n\t\t\t\t}\n\n\t\t\t\tif (!pbDest)\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Special Order 2. */\n\t\t\tcase SPECIAL_FGBG_2:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, g_MaskSpecialFgBg2, fgPel, 8);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, g_MaskSpecialFgBg2, fgPel, 8);\n\t\t\t\t}\n\n\t\t\t\tif (!pbDest)\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle White Order. */\n\t\t\tcase SPECIAL_WHITE:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tDESTWRITEPIXEL(pbDest, WHITE_PIXEL);\n\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Black Order. */\n\t\t\tcase SPECIAL_BLACK:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tDESTWRITEPIXEL(pbDest, BLACK_PIXEL);\n\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/0a98c450c58ec150e44781c89aa6f8e7e0f571f5", "file_name": "libfreerdp/codec/include/bitmap.c", "vul_type": "cwe-125", "description": "Write a C function for run-length decoding of compressed image data."}
{"func_name": "jp2_decode", "func_src_before": "jas_image_t *jp2_decode(jas_stream_t *in, const char *optstr)\n{\n\tjp2_box_t *box;\n\tint found;\n\tjas_image_t *image;\n\tjp2_dec_t *dec;\n\tbool samedtype;\n\tint dtype;\n\tunsigned int i;\n\tjp2_cmap_t *cmapd;\n\tjp2_pclr_t *pclrd;\n\tjp2_cdef_t *cdefd;\n\tunsigned int channo;\n\tint newcmptno;\n\tint_fast32_t *lutents;\n#if 0\n\tjp2_cdefchan_t *cdefent;\n\tint cmptno;\n#endif\n\tjp2_cmapent_t *cmapent;\n\tjas_icchdr_t icchdr;\n\tjas_iccprof_t *iccprof;\n\n\tdec = 0;\n\tbox = 0;\n\timage = 0;\n\n\tJAS_DBGLOG(100, (\"jp2_decode(%p, \\\"%s\\\")\\n\", in, optstr));\n\n\tif (!(dec = jp2_dec_create())) {\n\t\tgoto error;\n\t}\n\n\t/* Get the first box.  This should be a JP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tjas_eprintf(\"error: cannot get box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_JP) {\n\t\tjas_eprintf(\"error: expecting signature box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->data.jp.magic != JP2_JP_MAGIC) {\n\t\tjas_eprintf(\"incorrect magic number\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get the second box.  This should be a FTYP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_FTYP) {\n\t\tjas_eprintf(\"expecting file type box\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get more boxes... */\n\tfound = 0;\n\twhile ((box = jp2_box_get(in))) {\n\t\tif (jas_getdbglevel() >= 1) {\n\t\t\tjas_eprintf(\"got box type %s\\n\", box->info->name);\n\t\t}\n\t\tswitch (box->type) {\n\t\tcase JP2_BOX_JP2C:\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\tcase JP2_BOX_IHDR:\n\t\t\tif (!dec->ihdr) {\n\t\t\t\tdec->ihdr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_BPCC:\n\t\t\tif (!dec->bpcc) {\n\t\t\t\tdec->bpcc = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CDEF:\n\t\t\tif (!dec->cdef) {\n\t\t\t\tdec->cdef = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_PCLR:\n\t\t\tif (!dec->pclr) {\n\t\t\t\tdec->pclr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CMAP:\n\t\t\tif (!dec->cmap) {\n\t\t\t\tdec->cmap = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_COLR:\n\t\t\tif (!dec->colr) {\n\t\t\t\tdec->colr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (box) {\n\t\t\tjp2_box_destroy(box);\n\t\t\tbox = 0;\n\t\t}\n\t\tif (found) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\tjas_eprintf(\"error: no code stream found\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!(dec->image = jpc_decode(in, optstr))) {\n\t\tjas_eprintf(\"error: cannot decode code stream\\n\");\n\t\tgoto error;\n\t}\n\n\t/* An IHDR box must be present. */\n\tif (!dec->ihdr) {\n\t\tjas_eprintf(\"error: missing IHDR box\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Does the number of components indicated in the IHDR box match\n\t  the value specified in the code stream? */\n\tif (dec->ihdr->data.ihdr.numcmpts != JAS_CAST(jas_uint,\n\t  jas_image_numcmpts(dec->image))) {\n\t\tjas_eprintf(\"warning: number of components mismatch\\n\");\n\t}\n\n\t/* At least one component must be present. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Determine if all components have the same data type. */\n\tsamedtype = true;\n\tdtype = jas_image_cmptdtype(dec->image, 0);\n\tfor (i = 1; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tif (jas_image_cmptdtype(dec->image, i) != dtype) {\n\t\t\tsamedtype = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Is the component data type indicated in the IHDR box consistent\n\t  with the data in the code stream? */\n\tif ((samedtype && dec->ihdr->data.ihdr.bpc != JP2_DTYPETOBPC(dtype)) ||\n\t  (!samedtype && dec->ihdr->data.ihdr.bpc != JP2_IHDR_BPCNULL)) {\n\t\tjas_eprintf(\"warning: component data type mismatch (IHDR)\\n\");\n\t}\n\n\t/* Is the compression type supported? */\n\tif (dec->ihdr->data.ihdr.comptype != JP2_IHDR_COMPTYPE) {\n\t\tjas_eprintf(\"error: unsupported compression type\\n\");\n\t\tgoto error;\n\t}\n\n\tif (dec->bpcc) {\n\t\t/* Is the number of components indicated in the BPCC box\n\t\t  consistent with the code stream data? */\n\t\tif (dec->bpcc->data.bpcc.numcmpts != JAS_CAST(jas_uint, jas_image_numcmpts(\n\t\t  dec->image))) {\n\t\t\tjas_eprintf(\"warning: number of components mismatch\\n\");\n\t\t}\n\t\t/* Is the component data type information indicated in the BPCC\n\t\t  box consistent with the code stream data? */\n\t\tif (!samedtype) {\n\t\t\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\t\t\t  ++i) {\n\t\t\t\tif (jas_image_cmptdtype(dec->image, i) !=\n\t\t\t\t  JP2_BPCTODTYPE(dec->bpcc->data.bpcc.bpcs[i])) {\n\t\t\t\t\tjas_eprintf(\"warning: component data type mismatch (BPCC)\\n\");\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tjas_eprintf(\"warning: superfluous BPCC box\\n\");\n\t\t}\n\t}\n\n\t/* A COLR box must be present. */\n\tif (!dec->colr) {\n\t\tjas_eprintf(\"error: no COLR box\\n\");\n\t\tgoto error;\n\t}\n\n\tswitch (dec->colr->data.colr.method) {\n\tcase JP2_COLR_ENUM:\n\t\tjas_image_setclrspc(dec->image, jp2_getcs(&dec->colr->data.colr));\n\t\tbreak;\n\tcase JP2_COLR_ICC:\n\t\ticcprof = jas_iccprof_createfrombuf(dec->colr->data.colr.iccp,\n\t\t  dec->colr->data.colr.iccplen);\n\t\tif (!iccprof) {\n\t\t\tjas_eprintf(\"error: failed to parse ICC profile\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_gethdr(iccprof, &icchdr);\n\t\tjas_eprintf(\"ICC Profile CS %08x\\n\", icchdr.colorspc);\n\t\tjas_image_setclrspc(dec->image, fromiccpcs(icchdr.colorspc));\n\t\tdec->image->cmprof_ = jas_cmprof_createfromiccprof(iccprof);\n\t\tif (!dec->image->cmprof_) {\n\t\t\tjas_iccprof_destroy(iccprof);\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_destroy(iccprof);\n\t\tbreak;\n\t}\n\n\t/* If a CMAP box is present, a PCLR box must also be present. */\n\tif (dec->cmap && !dec->pclr) {\n\t\tjas_eprintf(\"warning: missing PCLR box or superfluous CMAP box\\n\");\n\t\tjp2_box_destroy(dec->cmap);\n\t\tdec->cmap = 0;\n\t}\n\n\t/* If a CMAP box is not present, a PCLR box must not be present. */\n\tif (!dec->cmap && dec->pclr) {\n\t\tjas_eprintf(\"warning: missing CMAP box or superfluous PCLR box\\n\");\n\t\tjp2_box_destroy(dec->pclr);\n\t\tdec->pclr = 0;\n\t}\n\n\t/* Determine the number of channels (which is essentially the number\n\t  of components after any palette mappings have been applied). */\n\tdec->numchans = dec->cmap ? dec->cmap->data.cmap.numchans :\n\t  JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\n\t/* Perform a basic sanity check on the CMAP box if present. */\n\tif (dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\t/* Is the component number reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].cmptno >= JAS_CAST(jas_uint,\n\t\t\t  jas_image_numcmpts(dec->image))) {\n\t\t\t\tjas_eprintf(\"error: invalid component number in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\t/* Is the LUT index reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].pcol >=\n\t\t\t  dec->pclr->data.pclr.numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid CMAP LUT index\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Allocate space for the channel-number to component-number LUT. */\n\tif (!(dec->chantocmptlut = jas_alloc2(dec->numchans,\n\t  sizeof(uint_fast16_t)))) {\n\t\tjas_eprintf(\"error: no memory\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tdec->chantocmptlut[i] = i;\n\t\t}\n\t} else {\n\t\tcmapd = &dec->cmap->data.cmap;\n\t\tpclrd = &dec->pclr->data.pclr;\n\t\tcdefd = &dec->cdef->data.cdef;\n\t\tfor (channo = 0; channo < cmapd->numchans; ++channo) {\n\t\t\tcmapent = &cmapd->ents[channo];\n\t\t\tif (cmapent->map == JP2_CMAP_DIRECT) {\n\t\t\t\tdec->chantocmptlut[channo] = channo;\n\t\t\t} else if (cmapent->map == JP2_CMAP_PALETTE) {\n\t\t\t\tif (!pclrd->numlutents) {\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t\tlutents = jas_alloc2(pclrd->numlutents, sizeof(int_fast32_t));\n\t\t\t\tif (!lutents) {\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t\tfor (i = 0; i < pclrd->numlutents; ++i) {\n\t\t\t\t\tlutents[i] = pclrd->lutdata[cmapent->pcol + i * pclrd->numchans];\n\t\t\t\t}\n\t\t\t\tnewcmptno = jas_image_numcmpts(dec->image);\n\t\t\t\tjas_image_depalettize(dec->image, cmapent->cmptno,\n\t\t\t\t  pclrd->numlutents, lutents,\n\t\t\t\t  JP2_BPCTODTYPE(pclrd->bpc[cmapent->pcol]), newcmptno);\n\t\t\t\tdec->chantocmptlut[channo] = newcmptno;\n\t\t\t\tjas_free(lutents);\n#if 0\n\t\t\t\tif (dec->cdef) {\n\t\t\t\t\tcdefent = jp2_cdef_lookup(cdefd, channo);\n\t\t\t\t\tif (!cdefent) {\n\t\t\t\t\t\tabort();\n\t\t\t\t\t}\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), cdefent->type, cdefent->assoc));\n\t\t\t\t} else {\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), 0, channo + 1));\n\t\t\t\t}\n#else\n\t\t\t\t/* suppress -Wunused-but-set-variable */\n\t\t\t\t(void)cdefd;\n#endif\n\t\t\t} else {\n\t\t\t\tjas_eprintf(\"error: invalid MTYP in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Ensure that the number of channels being used by the decoder\n\t  matches the number of image components. */\n\tif (dec->numchans != jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: mismatch in number of components (%d != %d)\\n\",\n\t\t  dec->numchans, jas_image_numcmpts(dec->image));\n\t\tgoto error;\n\t}\n\n\t/* Mark all components as being of unknown type. */\n\n\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tjas_image_setcmpttype(dec->image, i, JAS_IMAGE_CT_UNKNOWN);\n\t}\n\n\t/* Determine the type of each component. */\n\tif (dec->cdef) {\n\t\tfor (i = 0; i < dec->cdef->data.cdef.numchans; ++i) {\n\t\t\t/* Is the channel number reasonable? */\n\t\t\tif (dec->cdef->data.cdef.ents[i].channo >= dec->numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid channel number in CDEF box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tjas_image_setcmpttype(dec->image,\n\t\t\t  dec->chantocmptlut[dec->cdef->data.cdef.ents[i].channo],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image),\n\t\t\t  dec->cdef->data.cdef.ents[i].type,\n\t\t\t  dec->cdef->data.cdef.ents[i].assoc));\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tjas_image_setcmpttype(dec->image, dec->chantocmptlut[i],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image), 0, i + 1));\n\t\t}\n\t}\n\n\t/* Delete any components that are not of interest. */\n\tfor (i = jas_image_numcmpts(dec->image); i > 0; --i) {\n\t\tif (jas_image_cmpttype(dec->image, i - 1) == JAS_IMAGE_CT_UNKNOWN) {\n\t\t\tjas_image_delcmpt(dec->image, i - 1);\n\t\t}\n\t}\n\n\t/* Ensure that some components survived. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n#if 0\njas_eprintf(\"no of components is %d\\n\", jas_image_numcmpts(dec->image));\n#endif\n\n\t/* Prevent the image from being destroyed later. */\n\timage = dec->image;\n\tdec->image = 0;\n\n\tjp2_dec_destroy(dec);\n\n\treturn image;\n\nerror:\n\tif (box) {\n\t\tjp2_box_destroy(box);\n\t}\n\tif (dec) {\n\t\tjp2_dec_destroy(dec);\n\t}\n\treturn 0;\n}", "func_src_after": "jas_image_t *jp2_decode(jas_stream_t *in, const char *optstr)\n{\n\tjp2_box_t *box;\n\tint found;\n\tjas_image_t *image;\n\tjp2_dec_t *dec;\n\tbool samedtype;\n\tint dtype;\n\tunsigned int i;\n\tjp2_cmap_t *cmapd;\n\tjp2_pclr_t *pclrd;\n\tjp2_cdef_t *cdefd;\n\tunsigned int channo;\n\tint newcmptno;\n\tint_fast32_t *lutents;\n#if 0\n\tjp2_cdefchan_t *cdefent;\n\tint cmptno;\n#endif\n\tjp2_cmapent_t *cmapent;\n\tjas_icchdr_t icchdr;\n\tjas_iccprof_t *iccprof;\n\n\tdec = 0;\n\tbox = 0;\n\timage = 0;\n\n\tJAS_DBGLOG(100, (\"jp2_decode(%p, \\\"%s\\\")\\n\", in, optstr));\n\n\tif (!(dec = jp2_dec_create())) {\n\t\tgoto error;\n\t}\n\n\t/* Get the first box.  This should be a JP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tjas_eprintf(\"error: cannot get box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_JP) {\n\t\tjas_eprintf(\"error: expecting signature box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->data.jp.magic != JP2_JP_MAGIC) {\n\t\tjas_eprintf(\"incorrect magic number\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get the second box.  This should be a FTYP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_FTYP) {\n\t\tjas_eprintf(\"expecting file type box\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get more boxes... */\n\tfound = 0;\n\twhile ((box = jp2_box_get(in))) {\n\t\tif (jas_getdbglevel() >= 1) {\n\t\t\tjas_eprintf(\"got box type %s\\n\", box->info->name);\n\t\t}\n\t\tswitch (box->type) {\n\t\tcase JP2_BOX_JP2C:\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\tcase JP2_BOX_IHDR:\n\t\t\tif (!dec->ihdr) {\n\t\t\t\tdec->ihdr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_BPCC:\n\t\t\tif (!dec->bpcc) {\n\t\t\t\tdec->bpcc = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CDEF:\n\t\t\tif (!dec->cdef) {\n\t\t\t\tdec->cdef = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_PCLR:\n\t\t\tif (!dec->pclr) {\n\t\t\t\tdec->pclr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CMAP:\n\t\t\tif (!dec->cmap) {\n\t\t\t\tdec->cmap = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_COLR:\n\t\t\tif (!dec->colr) {\n\t\t\t\tdec->colr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (box) {\n\t\t\tjp2_box_destroy(box);\n\t\t\tbox = 0;\n\t\t}\n\t\tif (found) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\tjas_eprintf(\"error: no code stream found\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!(dec->image = jpc_decode(in, optstr))) {\n\t\tjas_eprintf(\"error: cannot decode code stream\\n\");\n\t\tgoto error;\n\t}\n\n\t/* An IHDR box must be present. */\n\tif (!dec->ihdr) {\n\t\tjas_eprintf(\"error: missing IHDR box\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Does the number of components indicated in the IHDR box match\n\t  the value specified in the code stream? */\n\tif (dec->ihdr->data.ihdr.numcmpts != JAS_CAST(jas_uint,\n\t  jas_image_numcmpts(dec->image))) {\n\t\tjas_eprintf(\"error: number of components mismatch (IHDR)\\n\");\n\t\tgoto error;\n\t}\n\n\t/* At least one component must be present. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Determine if all components have the same data type. */\n\tsamedtype = true;\n\tdtype = jas_image_cmptdtype(dec->image, 0);\n\tfor (i = 1; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tif (jas_image_cmptdtype(dec->image, i) != dtype) {\n\t\t\tsamedtype = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Is the component data type indicated in the IHDR box consistent\n\t  with the data in the code stream? */\n\tif ((samedtype && dec->ihdr->data.ihdr.bpc != JP2_DTYPETOBPC(dtype)) ||\n\t  (!samedtype && dec->ihdr->data.ihdr.bpc != JP2_IHDR_BPCNULL)) {\n\t\tjas_eprintf(\"error: component data type mismatch (IHDR)\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Is the compression type supported? */\n\tif (dec->ihdr->data.ihdr.comptype != JP2_IHDR_COMPTYPE) {\n\t\tjas_eprintf(\"error: unsupported compression type\\n\");\n\t\tgoto error;\n\t}\n\n\tif (dec->bpcc) {\n\t\t/* Is the number of components indicated in the BPCC box\n\t\t  consistent with the code stream data? */\n\t\tif (dec->bpcc->data.bpcc.numcmpts !=\n\t\t  JAS_CAST(jas_uint, jas_image_numcmpts(dec->image))) {\n\t\t\tjas_eprintf(\"error: number of components mismatch (BPCC)\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\t/* Is the component data type information indicated in the BPCC\n\t\t  box consistent with the code stream data? */\n\t\tif (!samedtype) {\n\t\t\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\t\t\t  ++i) {\n\t\t\t\tif (jas_image_cmptdtype(dec->image, i) !=\n\t\t\t\t  JP2_BPCTODTYPE(dec->bpcc->data.bpcc.bpcs[i])) {\n\t\t\t\t\tjas_eprintf(\"error: component data type mismatch (BPCC)\\n\");\n\t\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tjas_eprintf(\"warning: superfluous BPCC box\\n\");\n\t\t}\n\t}\n\n\t/* A COLR box must be present. */\n\tif (!dec->colr) {\n\t\tjas_eprintf(\"error: no COLR box\\n\");\n\t\tgoto error;\n\t}\n\n\tswitch (dec->colr->data.colr.method) {\n\tcase JP2_COLR_ENUM:\n\t\tjas_image_setclrspc(dec->image, jp2_getcs(&dec->colr->data.colr));\n\t\tbreak;\n\tcase JP2_COLR_ICC:\n\t\ticcprof = jas_iccprof_createfrombuf(dec->colr->data.colr.iccp,\n\t\t  dec->colr->data.colr.iccplen);\n\t\tif (!iccprof) {\n\t\t\tjas_eprintf(\"error: failed to parse ICC profile\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_gethdr(iccprof, &icchdr);\n\t\tjas_eprintf(\"ICC Profile CS %08x\\n\", icchdr.colorspc);\n\t\tjas_image_setclrspc(dec->image, fromiccpcs(icchdr.colorspc));\n\t\tdec->image->cmprof_ = jas_cmprof_createfromiccprof(iccprof);\n\t\tif (!dec->image->cmprof_) {\n\t\t\tjas_iccprof_destroy(iccprof);\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_destroy(iccprof);\n\t\tbreak;\n\t}\n\n\t/* If a CMAP box is present, a PCLR box must also be present. */\n\tif (dec->cmap && !dec->pclr) {\n\t\tjas_eprintf(\"warning: missing PCLR box or superfluous CMAP box\\n\");\n\t\tjp2_box_destroy(dec->cmap);\n\t\tdec->cmap = 0;\n\t}\n\n\t/* If a CMAP box is not present, a PCLR box must not be present. */\n\tif (!dec->cmap && dec->pclr) {\n\t\tjas_eprintf(\"warning: missing CMAP box or superfluous PCLR box\\n\");\n\t\tjp2_box_destroy(dec->pclr);\n\t\tdec->pclr = 0;\n\t}\n\n\t/* Determine the number of channels (which is essentially the number\n\t  of components after any palette mappings have been applied). */\n\tdec->numchans = dec->cmap ? dec->cmap->data.cmap.numchans :\n\t  JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\n\t/* Perform a basic sanity check on the CMAP box if present. */\n\tif (dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\t/* Is the component number reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].cmptno >= JAS_CAST(jas_uint,\n\t\t\t  jas_image_numcmpts(dec->image))) {\n\t\t\t\tjas_eprintf(\"error: invalid component number in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\t/* Is the LUT index reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].pcol >=\n\t\t\t  dec->pclr->data.pclr.numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid CMAP LUT index\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Allocate space for the channel-number to component-number LUT. */\n\tif (!(dec->chantocmptlut = jas_alloc2(dec->numchans,\n\t  sizeof(uint_fast16_t)))) {\n\t\tjas_eprintf(\"error: no memory\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tdec->chantocmptlut[i] = i;\n\t\t}\n\t} else {\n\t\tcmapd = &dec->cmap->data.cmap;\n\t\tpclrd = &dec->pclr->data.pclr;\n\t\tcdefd = &dec->cdef->data.cdef;\n\t\tfor (channo = 0; channo < cmapd->numchans; ++channo) {\n\t\t\tcmapent = &cmapd->ents[channo];\n\t\t\tif (cmapent->map == JP2_CMAP_DIRECT) {\n\t\t\t\tdec->chantocmptlut[channo] = channo;\n\t\t\t} else if (cmapent->map == JP2_CMAP_PALETTE) {\n\t\t\t\tif (!pclrd->numlutents) {\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t\tlutents = jas_alloc2(pclrd->numlutents, sizeof(int_fast32_t));\n\t\t\t\tif (!lutents) {\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t\tfor (i = 0; i < pclrd->numlutents; ++i) {\n\t\t\t\t\tlutents[i] = pclrd->lutdata[cmapent->pcol + i * pclrd->numchans];\n\t\t\t\t}\n\t\t\t\tnewcmptno = jas_image_numcmpts(dec->image);\n\t\t\t\tjas_image_depalettize(dec->image, cmapent->cmptno,\n\t\t\t\t  pclrd->numlutents, lutents,\n\t\t\t\t  JP2_BPCTODTYPE(pclrd->bpc[cmapent->pcol]), newcmptno);\n\t\t\t\tdec->chantocmptlut[channo] = newcmptno;\n\t\t\t\tjas_free(lutents);\n#if 0\n\t\t\t\tif (dec->cdef) {\n\t\t\t\t\tcdefent = jp2_cdef_lookup(cdefd, channo);\n\t\t\t\t\tif (!cdefent) {\n\t\t\t\t\t\tabort();\n\t\t\t\t\t}\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), cdefent->type, cdefent->assoc));\n\t\t\t\t} else {\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), 0, channo + 1));\n\t\t\t\t}\n#else\n\t\t\t\t/* suppress -Wunused-but-set-variable */\n\t\t\t\t(void)cdefd;\n#endif\n\t\t\t} else {\n\t\t\t\tjas_eprintf(\"error: invalid MTYP in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Ensure that the number of channels being used by the decoder\n\t  matches the number of image components. */\n\tif (dec->numchans != jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: mismatch in number of components (%d != %d)\\n\",\n\t\t  dec->numchans, jas_image_numcmpts(dec->image));\n\t\tgoto error;\n\t}\n\n\t/* Mark all components as being of unknown type. */\n\n\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tjas_image_setcmpttype(dec->image, i, JAS_IMAGE_CT_UNKNOWN);\n\t}\n\n\t/* Determine the type of each component. */\n\tif (dec->cdef) {\n\t\tfor (i = 0; i < dec->cdef->data.cdef.numchans; ++i) {\n\t\t\t/* Is the channel number reasonable? */\n\t\t\tif (dec->cdef->data.cdef.ents[i].channo >= dec->numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid channel number in CDEF box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tjas_image_setcmpttype(dec->image,\n\t\t\t  dec->chantocmptlut[dec->cdef->data.cdef.ents[i].channo],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image),\n\t\t\t  dec->cdef->data.cdef.ents[i].type,\n\t\t\t  dec->cdef->data.cdef.ents[i].assoc));\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tjas_image_setcmpttype(dec->image, dec->chantocmptlut[i],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image), 0, i + 1));\n\t\t}\n\t}\n\n\t/* Delete any components that are not of interest. */\n\tfor (i = jas_image_numcmpts(dec->image); i > 0; --i) {\n\t\tif (jas_image_cmpttype(dec->image, i - 1) == JAS_IMAGE_CT_UNKNOWN) {\n\t\t\tjas_image_delcmpt(dec->image, i - 1);\n\t\t}\n\t}\n\n\t/* Ensure that some components survived. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n#if 0\njas_eprintf(\"no of components is %d\\n\", jas_image_numcmpts(dec->image));\n#endif\n\n\t/* Prevent the image from being destroyed later. */\n\timage = dec->image;\n\tdec->image = 0;\n\n\tjp2_dec_destroy(dec);\n\n\treturn image;\n\nerror:\n\tif (box) {\n\t\tjp2_box_destroy(box);\n\t}\n\tif (dec) {\n\t\tjp2_dec_destroy(dec);\n\t}\n\treturn 0;\n}", "commit_link": "github.com/jasper-software/jasper/commit/41f214b121b837fa30d9ca5f2430212110f5cd9b", "file_name": "src/libjasper/jp2/jp2_dec.c", "vul_type": "cwe-125", "description": "Write a C function named `jp2_decode` that decodes a JPEG 2000 image from a given input stream and returns a pointer to the decoded image structure."}
{"func_name": "get_conn_text", "func_src_before": "static inline void get_conn_text(const conn *c, const int af,\n                char* addr, struct sockaddr *sock_addr) {\n    char addr_text[MAXPATHLEN];\n    addr_text[0] = '\\0';\n    const char *protoname = \"?\";\n    unsigned short port = 0;\n\n    switch (af) {\n        case AF_INET:\n            (void) inet_ntop(af,\n                    &((struct sockaddr_in *)sock_addr)->sin_addr,\n                    addr_text,\n                    sizeof(addr_text) - 1);\n            port = ntohs(((struct sockaddr_in *)sock_addr)->sin_port);\n            protoname = IS_UDP(c->transport) ? \"udp\" : \"tcp\";\n            break;\n\n        case AF_INET6:\n            addr_text[0] = '[';\n            addr_text[1] = '\\0';\n            if (inet_ntop(af,\n                    &((struct sockaddr_in6 *)sock_addr)->sin6_addr,\n                    addr_text + 1,\n                    sizeof(addr_text) - 2)) {\n                strcat(addr_text, \"]\");\n            }\n            port = ntohs(((struct sockaddr_in6 *)sock_addr)->sin6_port);\n            protoname = IS_UDP(c->transport) ? \"udp6\" : \"tcp6\";\n            break;\n\n        case AF_UNIX:\n            strncpy(addr_text,\n                    ((struct sockaddr_un *)sock_addr)->sun_path,\n                    sizeof(addr_text) - 1);\n            addr_text[sizeof(addr_text)-1] = '\\0';\n            protoname = \"unix\";\n            break;\n    }\n\n    if (strlen(addr_text) < 2) {\n        /* Most likely this is a connected UNIX-domain client which\n         * has no peer socket address, but there's no portable way\n         * to tell for sure.\n         */\n        sprintf(addr_text, \"<AF %d>\", af);\n    }\n\n    if (port) {\n        sprintf(addr, \"%s:%s:%u\", protoname, addr_text, port);\n    } else {\n        sprintf(addr, \"%s:%s\", protoname, addr_text);\n    }\n}", "func_src_after": "static inline void get_conn_text(const conn *c, const int af,\n                char* addr, struct sockaddr *sock_addr) {\n    char addr_text[MAXPATHLEN];\n    addr_text[0] = '\\0';\n    const char *protoname = \"?\";\n    unsigned short port = 0;\n    size_t pathlen = 0;\n\n    switch (af) {\n        case AF_INET:\n            (void) inet_ntop(af,\n                    &((struct sockaddr_in *)sock_addr)->sin_addr,\n                    addr_text,\n                    sizeof(addr_text) - 1);\n            port = ntohs(((struct sockaddr_in *)sock_addr)->sin_port);\n            protoname = IS_UDP(c->transport) ? \"udp\" : \"tcp\";\n            break;\n\n        case AF_INET6:\n            addr_text[0] = '[';\n            addr_text[1] = '\\0';\n            if (inet_ntop(af,\n                    &((struct sockaddr_in6 *)sock_addr)->sin6_addr,\n                    addr_text + 1,\n                    sizeof(addr_text) - 2)) {\n                strcat(addr_text, \"]\");\n            }\n            port = ntohs(((struct sockaddr_in6 *)sock_addr)->sin6_port);\n            protoname = IS_UDP(c->transport) ? \"udp6\" : \"tcp6\";\n            break;\n\n        case AF_UNIX:\n            // this strncpy call originally could piss off an address\n            // sanitizer; we supplied the size of the dest buf as a limiter,\n            // but optimized versions of strncpy could read past the end of\n            // *src while looking for a null terminator. Since buf and\n            // sun_path here are both on the stack they could even overlap,\n            // which is \"undefined\". In all OSS versions of strncpy I could\n            // find this has no effect; it'll still only copy until the first null\n            // terminator is found. Thus it's possible to get the OS to\n            // examine past the end of sun_path but it's unclear to me if this\n            // can cause any actual problem.\n            //\n            // We need a safe_strncpy util function but I'll punt on figuring\n            // that out for now.\n            pathlen = sizeof(((struct sockaddr_un *)sock_addr)->sun_path);\n            if (MAXPATHLEN <= pathlen) {\n                pathlen = MAXPATHLEN - 1;\n            }\n            strncpy(addr_text,\n                    ((struct sockaddr_un *)sock_addr)->sun_path,\n                    pathlen);\n            addr_text[pathlen] = '\\0';\n            protoname = \"unix\";\n            break;\n    }\n\n    if (strlen(addr_text) < 2) {\n        /* Most likely this is a connected UNIX-domain client which\n         * has no peer socket address, but there's no portable way\n         * to tell for sure.\n         */\n        sprintf(addr_text, \"<AF %d>\", af);\n    }\n\n    if (port) {\n        sprintf(addr, \"%s:%s:%u\", protoname, addr_text, port);\n    } else {\n        sprintf(addr, \"%s:%s\", protoname, addr_text);\n    }\n}", "commit_link": "github.com/memcached/memcached/commit/554b56687a19300a75ec24184746b5512580c819", "file_name": "memcached.c", "vul_type": "cwe-125", "description": "Write a C function named `get_conn_text` that formats a socket address into a human-readable string."}
{"func_name": "parse_sec_attr_44", "func_src_before": "static void parse_sec_attr_44(sc_file_t *file, const u8 *buf, size_t len)\n{\n\t/* OpenSc Operation values for each command operation-type */\n\tconst int df_idx[8] = {\t /* byte 1 = OpenSC type of AC Bit0,  byte 2 = OpenSC type of AC Bit1 ...*/\n\t\tSC_AC_OP_DELETE, SC_AC_OP_CREATE, SC_AC_OP_CREATE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\tSC_AC_OP_LOCK, SC_AC_OP_DELETE, -1};\n\tconst int ef_idx[8] = {\n\t\tSC_AC_OP_READ, SC_AC_OP_UPDATE, SC_AC_OP_WRITE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\t-1, SC_AC_OP_ERASE, -1};\n\tconst int efi_idx[8] = { /* internal EF used for RSA keys */\n\t\tSC_AC_OP_READ, SC_AC_OP_ERASE, SC_AC_OP_UPDATE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\t-1, SC_AC_OP_ERASE, -1};\n\n\tu8\t\tbValue;\n\tint\t\ti;\n\tint\t\tiKeyRef = 0;\n\tint\t\tiMethod;\n\tint\t\tiPinCount;\n\tint\t\tiOffset = 0;\n\tint\t\tiOperation;\n\tconst int*\tp_idx;\n\n\t/* Check all sub-AC definitions within the total AC */\n\twhile (len > 1) {\t\t\t\t/* minimum length = 2 */\n\t\tsize_t iACLen   = buf[iOffset] & 0x0F;\n\t\tif (iACLen > len)\n\t\t\tbreak;\n\n\t\tiMethod = SC_AC_NONE;\t\t/* default no authentication required */\n\n\t\tif (buf[iOffset] & 0X80) { /* AC in adaptive coding */\n\t\t\t/* Evaluates only the command-byte, not the optional P1/P2/Option bytes */\n\t\t\tsize_t\tiParmLen = 1;\t\t\t/* command-byte is always present */\n\t\t\tsize_t\tiKeyLen  = 0;\t\t\t/* Encryption key is optional */\n\n\t\t\tif (buf[iOffset]   & 0x20) iKeyLen++;\n\t\t\tif (buf[iOffset+1] & 0x40) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x20) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x10) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x08) iParmLen++;\n\n\t\t\t/* Get KeyNumber if available */\n\t\t\tif(iKeyLen) {\n\t\t\t\tint iSC;\n\t\t\t\tif (len < 1+(size_t)iACLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiSC = buf[iOffset+iACLen];\n\n\t\t\t\tswitch( (iSC>>5) & 0x03 ){\n\t\t\t\tcase 0:\n\t\t\t\t\tiMethod = SC_AC_TERM;\t\t/* key authentication */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 1:\n\t\t\t\t\tiMethod = SC_AC_AUT;\t\t/* key authentication  */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 2:\n\t\t\t\tcase 3:\n\t\t\t\t\tiMethod = SC_AC_PRO;\t\t/* secure messaging */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tiKeyRef = iSC & 0x1F;\t\t\t/* get key number */\n\t\t\t}\n\n\t\t\t/* Get PinNumber if available */\n\t\t\tif (iACLen > (1+iParmLen+iKeyLen)) {  /* check via total length if pin is present */\n\t\t\t\tif (len < 1+1+1+(size_t)iParmLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiKeyRef = buf[iOffset+1+1+iParmLen];  /* PTL + AM-header + parameter-bytes */\n\t\t\t\tiMethod = SC_AC_CHV;\n\t\t\t}\n\n\t\t\t/* Convert SETCOS command to OpenSC command group */\n\t\t\tif (len < 1+2)\n\t\t\t\tbreak;\n\t\t\tswitch(buf[iOffset+2]){\n\t\t\tcase 0x2A:\t\t\t/* crypto operation */\n\t\t\t\tiOperation = SC_AC_OP_CRYPTO;\n\t\t\t\tbreak;\n\t\t\tcase 0x46:\t\t\t/* key-generation operation */\n\t\t\t\tiOperation = SC_AC_OP_UPDATE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tiOperation = SC_AC_OP_SELECT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsc_file_add_acl_entry(file, iOperation, iMethod, iKeyRef);\n\t\t}\n\t\telse { /* AC in simple coding */\n\t\t\t   /* Initial AC is treated as an operational AC */\n\n\t\t\t/* Get specific Cmd groups for specified file-type */\n\t\t\tswitch (file->type) {\n\t\t\tcase SC_FILE_TYPE_DF:            /* DF */\n\t\t\t\tp_idx = df_idx;\n\t\t\t\tbreak;\n\t\t\tcase SC_FILE_TYPE_INTERNAL_EF:   /* EF for RSA keys */\n\t\t\t\tp_idx = efi_idx;\n\t\t\t\tbreak;\n\t\t\tdefault:                         /* EF */\n\t\t\t\tp_idx = ef_idx;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Encryption key present ? */\n\t\t\tiPinCount = iACLen - 1;\t\t\n\n\t\t\tif (buf[iOffset] & 0x20) {\n\t\t\t\tint iSC;\n\t\t\t\tif (len < 1 + (size_t)iACLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiSC = buf[iOffset + iACLen];\n\n\t\t\t\tswitch( (iSC>>5) & 0x03 ) {\n\t\t\t\tcase 0:\n\t\t\t\t\tiMethod = SC_AC_TERM;\t\t/* key authentication */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 1:\n\t\t\t\t\tiMethod = SC_AC_AUT;\t\t/* key authentication  */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 2:\n\t\t\t\tcase 3:\n\t\t\t\t\tiMethod = SC_AC_PRO;\t\t/* secure messaging */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tiKeyRef = iSC & 0x1F;\t\t\t/* get key number */\n\n\t\t\t\tiPinCount--;\t\t\t\t/* one byte used for keyReference  */\n\t\t\t}\n\n\t\t\t/* Pin present ? */\n\t\t\tif ( iPinCount > 0 ) {\n\t\t\t\tif (len < 1 + 2)\n\t\t\t\t\tbreak;\n\t\t\t\tiKeyRef = buf[iOffset + 2];\t/* pin ref */\n\t\t\t\tiMethod = SC_AC_CHV;\n\t\t\t}\n\n\t\t\t/* Add AC for each command-operationType into OpenSc structure */\n\t\t\tbValue = buf[iOffset + 1];\n\t\t\tfor (i = 0; i < 8; i++) {\n\t\t\t\tif((bValue & 1) && (p_idx[i] >= 0))\n\t\t\t\t\tsc_file_add_acl_entry(file, p_idx[i], iMethod, iKeyRef);\n\t\t\t\tbValue >>= 1;\n\t\t\t}\n\t\t}\n\t\t/* Current field treated, get next AC sub-field */\n\t\tiOffset += iACLen +1;\t\t/* AC + PTL-byte */\n\t\tlen     -= iACLen +1;\n\t}\n}", "func_src_after": "static void parse_sec_attr_44(sc_file_t *file, const u8 *buf, size_t len)\n{\n\t/* OpenSc Operation values for each command operation-type */\n\tconst int df_idx[8] = {\t /* byte 1 = OpenSC type of AC Bit0,  byte 2 = OpenSC type of AC Bit1 ...*/\n\t\tSC_AC_OP_DELETE, SC_AC_OP_CREATE, SC_AC_OP_CREATE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\tSC_AC_OP_LOCK, SC_AC_OP_DELETE, -1};\n\tconst int ef_idx[8] = {\n\t\tSC_AC_OP_READ, SC_AC_OP_UPDATE, SC_AC_OP_WRITE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\t-1, SC_AC_OP_ERASE, -1};\n\tconst int efi_idx[8] = { /* internal EF used for RSA keys */\n\t\tSC_AC_OP_READ, SC_AC_OP_ERASE, SC_AC_OP_UPDATE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\t-1, SC_AC_OP_ERASE, -1};\n\n\tu8\t\tbValue;\n\tint\t\ti;\n\tint\t\tiKeyRef = 0;\n\tint\t\tiMethod;\n\tint\t\tiPinCount;\n\tint\t\tiOffset = 0;\n\tint\t\tiOperation;\n\tconst int*\tp_idx;\n\n\t/* Check all sub-AC definitions within the total AC */\n\twhile (len > 1) {\t\t\t\t/* minimum length = 2 */\n\t\tsize_t iACLen   = buf[iOffset] & 0x0F;\n\t\tif (iACLen > len)\n\t\t\tbreak;\n\n\t\tiMethod = SC_AC_NONE;\t\t/* default no authentication required */\n\n\t\tif (buf[iOffset] & 0X80) { /* AC in adaptive coding */\n\t\t\t/* Evaluates only the command-byte, not the optional P1/P2/Option bytes */\n\t\t\tsize_t\tiParmLen = 1;\t\t\t/* command-byte is always present */\n\t\t\tsize_t\tiKeyLen  = 0;\t\t\t/* Encryption key is optional */\n\n\t\t\tif (buf[iOffset]   & 0x20) iKeyLen++;\n\t\t\tif (buf[iOffset+1] & 0x40) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x20) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x10) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x08) iParmLen++;\n\n\t\t\t/* Get KeyNumber if available */\n\t\t\tif(iKeyLen) {\n\t\t\t\tint iSC;\n\t\t\t\tif (len < 1+(size_t)iACLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiSC = buf[iOffset+iACLen];\n\n\t\t\t\tswitch( (iSC>>5) & 0x03 ){\n\t\t\t\tcase 0:\n\t\t\t\t\tiMethod = SC_AC_TERM;\t\t/* key authentication */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 1:\n\t\t\t\t\tiMethod = SC_AC_AUT;\t\t/* key authentication  */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 2:\n\t\t\t\tcase 3:\n\t\t\t\t\tiMethod = SC_AC_PRO;\t\t/* secure messaging */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tiKeyRef = iSC & 0x1F;\t\t\t/* get key number */\n\t\t\t}\n\n\t\t\t/* Get PinNumber if available */\n\t\t\tif (iACLen > (1+iParmLen+iKeyLen)) {  /* check via total length if pin is present */\n\t\t\t\tif (len < 1+1+1+(size_t)iParmLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiKeyRef = buf[iOffset+1+1+iParmLen];  /* PTL + AM-header + parameter-bytes */\n\t\t\t\tiMethod = SC_AC_CHV;\n\t\t\t}\n\n\t\t\t/* Convert SETCOS command to OpenSC command group */\n\t\t\tif (len < 1+2)\n\t\t\t\tbreak;\n\t\t\tswitch(buf[iOffset+2]){\n\t\t\tcase 0x2A:\t\t\t/* crypto operation */\n\t\t\t\tiOperation = SC_AC_OP_CRYPTO;\n\t\t\t\tbreak;\n\t\t\tcase 0x46:\t\t\t/* key-generation operation */\n\t\t\t\tiOperation = SC_AC_OP_UPDATE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tiOperation = SC_AC_OP_SELECT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsc_file_add_acl_entry(file, iOperation, iMethod, iKeyRef);\n\t\t}\n\t\telse { /* AC in simple coding */\n\t\t\t   /* Initial AC is treated as an operational AC */\n\n\t\t\t/* Get specific Cmd groups for specified file-type */\n\t\t\tswitch (file->type) {\n\t\t\tcase SC_FILE_TYPE_DF:            /* DF */\n\t\t\t\tp_idx = df_idx;\n\t\t\t\tbreak;\n\t\t\tcase SC_FILE_TYPE_INTERNAL_EF:   /* EF for RSA keys */\n\t\t\t\tp_idx = efi_idx;\n\t\t\t\tbreak;\n\t\t\tdefault:                         /* EF */\n\t\t\t\tp_idx = ef_idx;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Encryption key present ? */\n\t\t\tiPinCount = iACLen > 0 ? iACLen - 1 : 0;\n\n\t\t\tif (buf[iOffset] & 0x20) {\n\t\t\t\tint iSC;\n\t\t\t\tif (len < 1 + (size_t)iACLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiSC = buf[iOffset + iACLen];\n\n\t\t\t\tswitch( (iSC>>5) & 0x03 ) {\n\t\t\t\tcase 0:\n\t\t\t\t\tiMethod = SC_AC_TERM;\t\t/* key authentication */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 1:\n\t\t\t\t\tiMethod = SC_AC_AUT;\t\t/* key authentication  */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 2:\n\t\t\t\tcase 3:\n\t\t\t\t\tiMethod = SC_AC_PRO;\t\t/* secure messaging */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tiKeyRef = iSC & 0x1F;\t\t\t/* get key number */\n\n\t\t\t\tiPinCount--;\t\t\t\t/* one byte used for keyReference  */\n\t\t\t}\n\n\t\t\t/* Pin present ? */\n\t\t\tif ( iPinCount > 0 ) {\n\t\t\t\tif (len < 1 + 2)\n\t\t\t\t\tbreak;\n\t\t\t\tiKeyRef = buf[iOffset + 2];\t/* pin ref */\n\t\t\t\tiMethod = SC_AC_CHV;\n\t\t\t}\n\n\t\t\t/* Add AC for each command-operationType into OpenSc structure */\n\t\t\tbValue = buf[iOffset + 1];\n\t\t\tfor (i = 0; i < 8; i++) {\n\t\t\t\tif((bValue & 1) && (p_idx[i] >= 0))\n\t\t\t\t\tsc_file_add_acl_entry(file, p_idx[i], iMethod, iKeyRef);\n\t\t\t\tbValue >>= 1;\n\t\t\t}\n\t\t}\n\t\t/* Current field treated, get next AC sub-field */\n\t\tiOffset += iACLen +1;\t\t/* AC + PTL-byte */\n\t\tlen     -= iACLen +1;\n\t}\n}", "commit_link": "github.com/OpenSC/OpenSC/commit/c3f23b836e5a1766c36617fe1da30d22f7b63de2", "file_name": "src/libopensc/card-setcos.c", "vul_type": "cwe-125", "description": "Write a C function named `parse_sec_attr_44` that processes security attributes from a buffer and updates an OpenSC file structure with access control entries."}
{"func_name": "do_core_note", "func_src_before": "do_core_note(struct magic_set *ms, unsigned char *nbuf, uint32_t type,\n    int swap, uint32_t namesz, uint32_t descsz,\n    size_t noff, size_t doff, int *flags, size_t size, int clazz)\n{\n#ifdef ELFCORE\n\tint os_style = -1;\n\t/*\n\t * Sigh.  The 2.0.36 kernel in Debian 2.1, at\n\t * least, doesn't correctly implement name\n\t * sections, in core dumps, as specified by\n\t * the \"Program Linking\" section of \"UNIX(R) System\n\t * V Release 4 Programmer's Guide: ANSI C and\n\t * Programming Support Tools\", because my copy\n\t * clearly says \"The first 'namesz' bytes in 'name'\n\t * contain a *null-terminated* [emphasis mine]\n\t * character representation of the entry's owner\n\t * or originator\", but the 2.0.36 kernel code\n\t * doesn't include the terminating null in the\n\t * name....\n\t */\n\tif ((namesz == 4 && strncmp((char *)&nbuf[noff], \"CORE\", 4) == 0) ||\n\t    (namesz == 5 && strcmp((char *)&nbuf[noff], \"CORE\") == 0)) {\n\t\tos_style = OS_STYLE_SVR4;\n\t} \n\n\tif ((namesz == 8 && strcmp((char *)&nbuf[noff], \"FreeBSD\") == 0)) {\n\t\tos_style = OS_STYLE_FREEBSD;\n\t}\n\n\tif ((namesz >= 11 && strncmp((char *)&nbuf[noff], \"NetBSD-CORE\", 11)\n\t    == 0)) {\n\t\tos_style = OS_STYLE_NETBSD;\n\t}\n\n\tif (os_style != -1 && (*flags & FLAGS_DID_CORE_STYLE) == 0) {\n\t\tif (file_printf(ms, \", %s-style\", os_style_names[os_style])\n\t\t    == -1)\n\t\t\treturn 1;\n\t\t*flags |= FLAGS_DID_CORE_STYLE;\n\t\t*flags |= os_style;\n\t}\n\n\tswitch (os_style) {\n\tcase OS_STYLE_NETBSD:\n\t\tif (type == NT_NETBSD_CORE_PROCINFO) {\n\t\t\tchar sbuf[512];\n\t\t\tstruct NetBSD_elfcore_procinfo pi;\n\t\t\tmemset(&pi, 0, sizeof(pi));\n\t\t\tmemcpy(&pi, nbuf + doff, descsz);\n\n\t\t\tif (file_printf(ms, \", from '%.31s', pid=%u, uid=%u, \"\n\t\t\t    \"gid=%u, nlwps=%u, lwp=%u (signal %u/code %u)\",\n\t\t\t    file_printable(sbuf, sizeof(sbuf),\n\t\t\t    CAST(char *, pi.cpi_name)),\n\t\t\t    elf_getu32(swap, (uint32_t)pi.cpi_pid),\n\t\t\t    elf_getu32(swap, pi.cpi_euid),\n\t\t\t    elf_getu32(swap, pi.cpi_egid),\n\t\t\t    elf_getu32(swap, pi.cpi_nlwps),\n\t\t\t    elf_getu32(swap, (uint32_t)pi.cpi_siglwp),\n\t\t\t    elf_getu32(swap, pi.cpi_signo),\n\t\t\t    elf_getu32(swap, pi.cpi_sigcode)) == -1)\n\t\t\t\treturn 1;\n\n\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tif (type == NT_PRPSINFO && *flags & FLAGS_IS_CORE) {\n\t\t\tsize_t i, j;\n\t\t\tunsigned char c;\n\t\t\t/*\n\t\t\t * Extract the program name.  We assume\n\t\t\t * it to be 16 characters (that's what it\n\t\t\t * is in SunOS 5.x and Linux).\n\t\t\t *\n\t\t\t * Unfortunately, it's at a different offset\n\t\t\t * in various OSes, so try multiple offsets.\n\t\t\t * If the characters aren't all printable,\n\t\t\t * reject it.\n\t\t\t */\n\t\t\tfor (i = 0; i < NOFFSETS; i++) {\n\t\t\t\tunsigned char *cname, *cp;\n\t\t\t\tsize_t reloffset = prpsoffsets(i);\n\t\t\t\tsize_t noffset = doff + reloffset;\n\t\t\t\tsize_t k;\n\t\t\t\tfor (j = 0; j < 16; j++, noffset++,\n\t\t\t\t    reloffset++) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the buffer; if\n\t\t\t\t\t * we are, just give up.\n\t\t\t\t\t */\n\t\t\t\t\tif (noffset >= size)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the contents;\n\t\t\t\t\t * if we are, this obviously\n\t\t\t\t\t * isn't the right offset.\n\t\t\t\t\t */\n\t\t\t\t\tif (reloffset >= descsz)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\tc = nbuf[noffset];\n\t\t\t\t\tif (c == '\\0') {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A '\\0' at the\n\t\t\t\t\t\t * beginning is\n\t\t\t\t\t\t * obviously wrong.\n\t\t\t\t\t\t * Any other '\\0'\n\t\t\t\t\t\t * means we're done.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (j == 0)\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A nonprintable\n\t\t\t\t\t\t * character is also\n\t\t\t\t\t\t * wrong.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (!isprint(c) || isquote(c))\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Well, that worked.\n\t\t\t\t */\n\n\t\t\t\t/*\n\t\t\t\t * Try next offsets, in case this match is\n\t\t\t\t * in the middle of a string.\n\t\t\t\t */\n\t\t\t\tfor (k = i + 1 ; k < NOFFSETS; k++) {\n\t\t\t\t\tsize_t no;\n\t\t\t\t\tint adjust = 1;\n\t\t\t\t\tif (prpsoffsets(k) >= prpsoffsets(i))\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tfor (no = doff + prpsoffsets(k);\n\t\t\t\t\t     no < doff + prpsoffsets(i); no++)\n\t\t\t\t\t\tadjust = adjust\n\t\t\t\t\t\t         && isprint(nbuf[no]);\n\t\t\t\t\tif (adjust)\n\t\t\t\t\t\ti = k;\n\t\t\t\t}\n\n\t\t\t\tcname = (unsigned char *)\n\t\t\t\t    &nbuf[doff + prpsoffsets(i)];\n\t\t\t\tfor (cp = cname; *cp && isprint(*cp); cp++)\n\t\t\t\t\tcontinue;\n\t\t\t\t/*\n\t\t\t\t * Linux apparently appends a space at the end\n\t\t\t\t * of the command line: remove it.\n\t\t\t\t */\n\t\t\t\twhile (cp > cname && isspace(cp[-1]))\n\t\t\t\t\tcp--;\n\t\t\t\tif (file_printf(ms, \", from '%.*s'\",\n\t\t\t\t    (int)(cp - cname), cname) == -1)\n\t\t\t\t\treturn 1;\n\t\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\t\treturn 1;\n\n\t\t\ttryanother:\n\t\t\t\t;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n#endif\n\treturn 0;\n}", "func_src_after": "do_core_note(struct magic_set *ms, unsigned char *nbuf, uint32_t type,\n    int swap, uint32_t namesz, uint32_t descsz,\n    size_t noff, size_t doff, int *flags, size_t size, int clazz)\n{\n#ifdef ELFCORE\n\tint os_style = -1;\n\t/*\n\t * Sigh.  The 2.0.36 kernel in Debian 2.1, at\n\t * least, doesn't correctly implement name\n\t * sections, in core dumps, as specified by\n\t * the \"Program Linking\" section of \"UNIX(R) System\n\t * V Release 4 Programmer's Guide: ANSI C and\n\t * Programming Support Tools\", because my copy\n\t * clearly says \"The first 'namesz' bytes in 'name'\n\t * contain a *null-terminated* [emphasis mine]\n\t * character representation of the entry's owner\n\t * or originator\", but the 2.0.36 kernel code\n\t * doesn't include the terminating null in the\n\t * name....\n\t */\n\tif ((namesz == 4 && strncmp((char *)&nbuf[noff], \"CORE\", 4) == 0) ||\n\t    (namesz == 5 && strcmp((char *)&nbuf[noff], \"CORE\") == 0)) {\n\t\tos_style = OS_STYLE_SVR4;\n\t} \n\n\tif ((namesz == 8 && strcmp((char *)&nbuf[noff], \"FreeBSD\") == 0)) {\n\t\tos_style = OS_STYLE_FREEBSD;\n\t}\n\n\tif ((namesz >= 11 && strncmp((char *)&nbuf[noff], \"NetBSD-CORE\", 11)\n\t    == 0)) {\n\t\tos_style = OS_STYLE_NETBSD;\n\t}\n\n\tif (os_style != -1 && (*flags & FLAGS_DID_CORE_STYLE) == 0) {\n\t\tif (file_printf(ms, \", %s-style\", os_style_names[os_style])\n\t\t    == -1)\n\t\t\treturn 1;\n\t\t*flags |= FLAGS_DID_CORE_STYLE;\n\t\t*flags |= os_style;\n\t}\n\n\tswitch (os_style) {\n\tcase OS_STYLE_NETBSD:\n\t\tif (type == NT_NETBSD_CORE_PROCINFO) {\n\t\t\tchar sbuf[512];\n\t\t\tstruct NetBSD_elfcore_procinfo pi;\n\t\t\tmemset(&pi, 0, sizeof(pi));\n\t\t\tmemcpy(&pi, nbuf + doff, descsz);\n\n\t\t\tif (file_printf(ms, \", from '%.31s', pid=%u, uid=%u, \"\n\t\t\t    \"gid=%u, nlwps=%u, lwp=%u (signal %u/code %u)\",\n\t\t\t    file_printable(sbuf, sizeof(sbuf),\n\t\t\t    CAST(char *, pi.cpi_name)),\n\t\t\t    elf_getu32(swap, (uint32_t)pi.cpi_pid),\n\t\t\t    elf_getu32(swap, pi.cpi_euid),\n\t\t\t    elf_getu32(swap, pi.cpi_egid),\n\t\t\t    elf_getu32(swap, pi.cpi_nlwps),\n\t\t\t    elf_getu32(swap, (uint32_t)pi.cpi_siglwp),\n\t\t\t    elf_getu32(swap, pi.cpi_signo),\n\t\t\t    elf_getu32(swap, pi.cpi_sigcode)) == -1)\n\t\t\t\treturn 1;\n\n\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tif (type == NT_PRPSINFO && *flags & FLAGS_IS_CORE) {\n\t\t\tsize_t i, j;\n\t\t\tunsigned char c;\n\t\t\t/*\n\t\t\t * Extract the program name.  We assume\n\t\t\t * it to be 16 characters (that's what it\n\t\t\t * is in SunOS 5.x and Linux).\n\t\t\t *\n\t\t\t * Unfortunately, it's at a different offset\n\t\t\t * in various OSes, so try multiple offsets.\n\t\t\t * If the characters aren't all printable,\n\t\t\t * reject it.\n\t\t\t */\n\t\t\tfor (i = 0; i < NOFFSETS; i++) {\n\t\t\t\tunsigned char *cname, *cp;\n\t\t\t\tsize_t reloffset = prpsoffsets(i);\n\t\t\t\tsize_t noffset = doff + reloffset;\n\t\t\t\tsize_t k;\n\t\t\t\tfor (j = 0; j < 16; j++, noffset++,\n\t\t\t\t    reloffset++) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the buffer; if\n\t\t\t\t\t * we are, just give up.\n\t\t\t\t\t */\n\t\t\t\t\tif (noffset >= size)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the contents;\n\t\t\t\t\t * if we are, this obviously\n\t\t\t\t\t * isn't the right offset.\n\t\t\t\t\t */\n\t\t\t\t\tif (reloffset >= descsz)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\tc = nbuf[noffset];\n\t\t\t\t\tif (c == '\\0') {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A '\\0' at the\n\t\t\t\t\t\t * beginning is\n\t\t\t\t\t\t * obviously wrong.\n\t\t\t\t\t\t * Any other '\\0'\n\t\t\t\t\t\t * means we're done.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (j == 0)\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A nonprintable\n\t\t\t\t\t\t * character is also\n\t\t\t\t\t\t * wrong.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (!isprint(c) || isquote(c))\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Well, that worked.\n\t\t\t\t */\n\n\t\t\t\t/*\n\t\t\t\t * Try next offsets, in case this match is\n\t\t\t\t * in the middle of a string.\n\t\t\t\t */\n\t\t\t\tfor (k = i + 1 ; k < NOFFSETS; k++) {\n\t\t\t\t\tsize_t no;\n\t\t\t\t\tint adjust = 1;\n\t\t\t\t\tif (prpsoffsets(k) >= prpsoffsets(i))\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tfor (no = doff + prpsoffsets(k);\n\t\t\t\t\t     no < doff + prpsoffsets(i); no++)\n\t\t\t\t\t\tadjust = adjust\n\t\t\t\t\t\t         && isprint(nbuf[no]);\n\t\t\t\t\tif (adjust)\n\t\t\t\t\t\ti = k;\n\t\t\t\t}\n\n\t\t\t\tcname = (unsigned char *)\n\t\t\t\t    &nbuf[doff + prpsoffsets(i)];\n\t\t\t\tfor (cp = cname; cp < nbuf + size && *cp\n\t\t\t\t    && isprint(*cp); cp++)\n\t\t\t\t\tcontinue;\n\t\t\t\t/*\n\t\t\t\t * Linux apparently appends a space at the end\n\t\t\t\t * of the command line: remove it.\n\t\t\t\t */\n\t\t\t\twhile (cp > cname && isspace(cp[-1]))\n\t\t\t\t\tcp--;\n\t\t\t\tif (file_printf(ms, \", from '%.*s'\",\n\t\t\t\t    (int)(cp - cname), cname) == -1)\n\t\t\t\t\treturn 1;\n\t\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\t\treturn 1;\n\n\t\t\ttryanother:\n\t\t\t\t;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n#endif\n\treturn 0;\n}", "commit_link": "github.com/file/file/commit/a642587a9c9e2dd7feacdf513c3643ce26ad3c22", "file_name": "src/readelf.c", "vul_type": "cwe-125", "description": "Write a C function named `do_core_note` that processes core dump note segments to determine the originating OS and program details."}
{"func_name": "gst_asf_demux_process_ext_content_desc", "func_src_before": "gst_asf_demux_process_ext_content_desc (GstASFDemux * demux, guint8 * data,\n    guint64 size)\n{\n  /* Other known (and unused) 'text/unicode' metadata available :\n   *\n   *   WM/Lyrics =\n   *   WM/MediaPrimaryClassID = {D1607DBC-E323-4BE2-86A1-48A42A28441E}\n   *   WMFSDKVersion = 9.00.00.2980\n   *   WMFSDKNeeded = 0.0.0.0000\n   *   WM/UniqueFileIdentifier = AMGa_id=R    15334;AMGp_id=P     5149;AMGt_id=T  2324984\n   *   WM/Publisher = 4AD\n   *   WM/Provider = AMG\n   *   WM/ProviderRating = 8\n   *   WM/ProviderStyle = Rock (similar to WM/Genre)\n   *   WM/GenreID (similar to WM/Genre)\n   *   WM/TrackNumber (same as WM/Track but as a string)\n   *\n   * Other known (and unused) 'non-text' metadata available :\n   *\n   *   WM/EncodingTime\n   *   WM/MCDI\n   *   IsVBR\n   *\n   * We might want to read WM/TrackNumber and use atoi() if we don't have\n   * WM/Track\n   */\n\n  GstTagList *taglist;\n  guint16 blockcount, i;\n  gboolean content3D = FALSE;\n\n  struct\n  {\n    const gchar *interleave_name;\n    GstASF3DMode interleaving_type;\n  } stereoscopic_layout_map[] = {\n    {\n    \"SideBySideRF\", GST_ASF_3D_SIDE_BY_SIDE_HALF_RL}, {\n    \"SideBySideLF\", GST_ASF_3D_SIDE_BY_SIDE_HALF_LR}, {\n    \"OverUnderRT\", GST_ASF_3D_TOP_AND_BOTTOM_HALF_RL}, {\n    \"OverUnderLT\", GST_ASF_3D_TOP_AND_BOTTOM_HALF_LR}, {\n    \"DualStream\", GST_ASF_3D_DUAL_STREAM}\n  };\n  GST_INFO_OBJECT (demux, \"object is an extended content description\");\n\n  taglist = gst_tag_list_new_empty ();\n\n  /* Content Descriptor Count */\n  if (size < 2)\n    goto not_enough_data;\n\n  blockcount = gst_asf_demux_get_uint16 (&data, &size);\n\n  for (i = 1; i <= blockcount; ++i) {\n    const gchar *gst_tag_name;\n    guint16 datatype;\n    guint16 value_len;\n    guint16 name_len;\n    GValue tag_value = { 0, };\n    gsize in, out;\n    gchar *name;\n    gchar *name_utf8 = NULL;\n    gchar *value;\n\n    /* Descriptor */\n    if (!gst_asf_demux_get_string (&name, &name_len, &data, &size))\n      goto not_enough_data;\n\n    if (size < 2) {\n      g_free (name);\n      goto not_enough_data;\n    }\n    /* Descriptor Value Data Type */\n    datatype = gst_asf_demux_get_uint16 (&data, &size);\n\n    /* Descriptor Value (not really a string, but same thing reading-wise) */\n    if (!gst_asf_demux_get_string (&value, &value_len, &data, &size)) {\n      g_free (name);\n      goto not_enough_data;\n    }\n\n    name_utf8 =\n        g_convert (name, name_len, \"UTF-8\", \"UTF-16LE\", &in, &out, NULL);\n\n    if (name_utf8 != NULL) {\n      GST_DEBUG (\"Found tag/metadata %s\", name_utf8);\n\n      gst_tag_name = gst_asf_demux_get_gst_tag_from_tag_name (name_utf8);\n      GST_DEBUG (\"gst_tag_name %s\", GST_STR_NULL (gst_tag_name));\n\n      switch (datatype) {\n        case ASF_DEMUX_DATA_TYPE_UTF16LE_STRING:{\n          gchar *value_utf8;\n\n          value_utf8 = g_convert (value, value_len, \"UTF-8\", \"UTF-16LE\",\n              &in, &out, NULL);\n\n          /* get rid of tags with empty value */\n          if (value_utf8 != NULL && *value_utf8 != '\\0') {\n            GST_DEBUG (\"string value %s\", value_utf8);\n\n            value_utf8[out] = '\\0';\n\n            if (gst_tag_name != NULL) {\n              if (strcmp (gst_tag_name, GST_TAG_DATE_TIME) == 0) {\n                guint year = atoi (value_utf8);\n\n                if (year > 0) {\n                  g_value_init (&tag_value, GST_TYPE_DATE_TIME);\n                  g_value_take_boxed (&tag_value, gst_date_time_new_y (year));\n                }\n              } else if (strcmp (gst_tag_name, GST_TAG_GENRE) == 0) {\n                guint id3v1_genre_id;\n                const gchar *genre_str;\n\n                if (sscanf (value_utf8, \"(%u)\", &id3v1_genre_id) == 1 &&\n                    ((genre_str = gst_tag_id3_genre_get (id3v1_genre_id)))) {\n                  GST_DEBUG (\"Genre: %s -> %s\", value_utf8, genre_str);\n                  g_free (value_utf8);\n                  value_utf8 = g_strdup (genre_str);\n                }\n              } else {\n                GType tag_type;\n\n                /* convert tag from string to other type if required */\n                tag_type = gst_tag_get_type (gst_tag_name);\n                g_value_init (&tag_value, tag_type);\n                if (!gst_value_deserialize (&tag_value, value_utf8)) {\n                  GValue from_val = { 0, };\n\n                  g_value_init (&from_val, G_TYPE_STRING);\n                  g_value_set_string (&from_val, value_utf8);\n                  if (!g_value_transform (&from_val, &tag_value)) {\n                    GST_WARNING_OBJECT (demux,\n                        \"Could not transform string tag to \" \"%s tag type %s\",\n                        gst_tag_name, g_type_name (tag_type));\n                    g_value_unset (&tag_value);\n                  }\n                  g_value_unset (&from_val);\n                }\n              }\n            } else {\n              /* metadata ! */\n              GST_DEBUG (\"Setting metadata\");\n              g_value_init (&tag_value, G_TYPE_STRING);\n              g_value_set_string (&tag_value, value_utf8);\n              /* If we found a stereoscopic marker, look for StereoscopicLayout\n               * metadata */\n              if (content3D) {\n                guint i;\n                if (strncmp (\"StereoscopicLayout\", name_utf8,\n                        strlen (name_utf8)) == 0) {\n                  for (i = 0; i < G_N_ELEMENTS (stereoscopic_layout_map); i++) {\n                    if (g_str_equal (stereoscopic_layout_map[i].interleave_name,\n                            value_utf8)) {\n                      demux->asf_3D_mode =\n                          stereoscopic_layout_map[i].interleaving_type;\n                      GST_INFO (\"find interleave type %u\", demux->asf_3D_mode);\n                    }\n                  }\n                }\n                GST_INFO_OBJECT (demux, \"3d type is %u\", demux->asf_3D_mode);\n              } else {\n                demux->asf_3D_mode = GST_ASF_3D_NONE;\n                GST_INFO_OBJECT (demux, \"None 3d type\");\n              }\n            }\n          } else if (value_utf8 == NULL) {\n            GST_WARNING (\"Failed to convert string value to UTF8, skipping\");\n          } else {\n            GST_DEBUG (\"Skipping empty string value for %s\",\n                GST_STR_NULL (gst_tag_name));\n          }\n          g_free (value_utf8);\n          break;\n        }\n        case ASF_DEMUX_DATA_TYPE_BYTE_ARRAY:{\n          if (gst_tag_name) {\n            if (!g_str_equal (gst_tag_name, GST_TAG_IMAGE)) {\n              GST_FIXME (\"Unhandled byte array tag %s\",\n                  GST_STR_NULL (gst_tag_name));\n              break;\n            } else {\n              asf_demux_parse_picture_tag (taglist, (guint8 *) value,\n                  value_len);\n            }\n          }\n          break;\n        }\n        case ASF_DEMUX_DATA_TYPE_DWORD:{\n          guint uint_val = GST_READ_UINT32_LE (value);\n\n          /* this is the track number */\n          g_value_init (&tag_value, G_TYPE_UINT);\n\n          /* WM/Track counts from 0 */\n          if (!strcmp (name_utf8, \"WM/Track\"))\n            ++uint_val;\n\n          g_value_set_uint (&tag_value, uint_val);\n          break;\n        }\n          /* Detect 3D */\n        case ASF_DEMUX_DATA_TYPE_BOOL:{\n          gboolean bool_val = GST_READ_UINT32_LE (value);\n\n          if (strncmp (\"Stereoscopic\", name_utf8, strlen (name_utf8)) == 0) {\n            if (bool_val) {\n              GST_INFO_OBJECT (demux, \"This is 3D contents\");\n              content3D = TRUE;\n            } else {\n              GST_INFO_OBJECT (demux, \"This is not 3D contenst\");\n              content3D = FALSE;\n            }\n          }\n\n          break;\n        }\n        default:{\n          GST_DEBUG (\"Skipping tag %s of type %d\", gst_tag_name, datatype);\n          break;\n        }\n      }\n\n      if (G_IS_VALUE (&tag_value)) {\n        if (gst_tag_name) {\n          GstTagMergeMode merge_mode = GST_TAG_MERGE_APPEND;\n\n          /* WM/TrackNumber is more reliable than WM/Track, since the latter\n           * is supposed to have a 0 base but is often wrongly written to start\n           * from 1 as well, so prefer WM/TrackNumber when we have it: either\n           * replace the value added earlier from WM/Track or put it first in\n           * the list, so that it will get picked up by _get_uint() */\n          if (strcmp (name_utf8, \"WM/TrackNumber\") == 0)\n            merge_mode = GST_TAG_MERGE_REPLACE;\n\n          gst_tag_list_add_values (taglist, merge_mode, gst_tag_name,\n              &tag_value, NULL);\n        } else {\n          GST_DEBUG (\"Setting global metadata %s\", name_utf8);\n          gst_structure_set_value (demux->global_metadata, name_utf8,\n              &tag_value);\n        }\n\n        g_value_unset (&tag_value);\n      }\n    }\n\n    g_free (name);\n    g_free (value);\n    g_free (name_utf8);\n  }\n\n  gst_asf_demux_add_global_tags (demux, taglist);\n\n  return GST_FLOW_OK;\n\n  /* Errors */\nnot_enough_data:\n  {\n    GST_WARNING (\"Unexpected end of data parsing ext content desc object\");\n    gst_tag_list_unref (taglist);\n    return GST_FLOW_OK;         /* not really fatal */\n  }\n}", "func_src_after": "gst_asf_demux_process_ext_content_desc (GstASFDemux * demux, guint8 * data,\n    guint64 size)\n{\n  /* Other known (and unused) 'text/unicode' metadata available :\n   *\n   *   WM/Lyrics =\n   *   WM/MediaPrimaryClassID = {D1607DBC-E323-4BE2-86A1-48A42A28441E}\n   *   WMFSDKVersion = 9.00.00.2980\n   *   WMFSDKNeeded = 0.0.0.0000\n   *   WM/UniqueFileIdentifier = AMGa_id=R    15334;AMGp_id=P     5149;AMGt_id=T  2324984\n   *   WM/Publisher = 4AD\n   *   WM/Provider = AMG\n   *   WM/ProviderRating = 8\n   *   WM/ProviderStyle = Rock (similar to WM/Genre)\n   *   WM/GenreID (similar to WM/Genre)\n   *   WM/TrackNumber (same as WM/Track but as a string)\n   *\n   * Other known (and unused) 'non-text' metadata available :\n   *\n   *   WM/EncodingTime\n   *   WM/MCDI\n   *   IsVBR\n   *\n   * We might want to read WM/TrackNumber and use atoi() if we don't have\n   * WM/Track\n   */\n\n  GstTagList *taglist;\n  guint16 blockcount, i;\n  gboolean content3D = FALSE;\n\n  struct\n  {\n    const gchar *interleave_name;\n    GstASF3DMode interleaving_type;\n  } stereoscopic_layout_map[] = {\n    {\n    \"SideBySideRF\", GST_ASF_3D_SIDE_BY_SIDE_HALF_RL}, {\n    \"SideBySideLF\", GST_ASF_3D_SIDE_BY_SIDE_HALF_LR}, {\n    \"OverUnderRT\", GST_ASF_3D_TOP_AND_BOTTOM_HALF_RL}, {\n    \"OverUnderLT\", GST_ASF_3D_TOP_AND_BOTTOM_HALF_LR}, {\n    \"DualStream\", GST_ASF_3D_DUAL_STREAM}\n  };\n  GST_INFO_OBJECT (demux, \"object is an extended content description\");\n\n  taglist = gst_tag_list_new_empty ();\n\n  /* Content Descriptor Count */\n  if (size < 2)\n    goto not_enough_data;\n\n  blockcount = gst_asf_demux_get_uint16 (&data, &size);\n\n  for (i = 1; i <= blockcount; ++i) {\n    const gchar *gst_tag_name;\n    guint16 datatype;\n    guint16 value_len;\n    guint16 name_len;\n    GValue tag_value = { 0, };\n    gsize in, out;\n    gchar *name;\n    gchar *name_utf8 = NULL;\n    gchar *value;\n\n    /* Descriptor */\n    if (!gst_asf_demux_get_string (&name, &name_len, &data, &size))\n      goto not_enough_data;\n\n    if (size < 2) {\n      g_free (name);\n      goto not_enough_data;\n    }\n    /* Descriptor Value Data Type */\n    datatype = gst_asf_demux_get_uint16 (&data, &size);\n\n    /* Descriptor Value (not really a string, but same thing reading-wise) */\n    if (!gst_asf_demux_get_string (&value, &value_len, &data, &size)) {\n      g_free (name);\n      goto not_enough_data;\n    }\n\n    name_utf8 =\n        g_convert (name, name_len, \"UTF-8\", \"UTF-16LE\", &in, &out, NULL);\n\n    if (name_utf8 != NULL) {\n      GST_DEBUG (\"Found tag/metadata %s\", name_utf8);\n\n      gst_tag_name = gst_asf_demux_get_gst_tag_from_tag_name (name_utf8);\n      GST_DEBUG (\"gst_tag_name %s\", GST_STR_NULL (gst_tag_name));\n\n      switch (datatype) {\n        case ASF_DEMUX_DATA_TYPE_UTF16LE_STRING:{\n          gchar *value_utf8;\n\n          value_utf8 = g_convert (value, value_len, \"UTF-8\", \"UTF-16LE\",\n              &in, &out, NULL);\n\n          /* get rid of tags with empty value */\n          if (value_utf8 != NULL && *value_utf8 != '\\0') {\n            GST_DEBUG (\"string value %s\", value_utf8);\n\n            value_utf8[out] = '\\0';\n\n            if (gst_tag_name != NULL) {\n              if (strcmp (gst_tag_name, GST_TAG_DATE_TIME) == 0) {\n                guint year = atoi (value_utf8);\n\n                if (year > 0) {\n                  g_value_init (&tag_value, GST_TYPE_DATE_TIME);\n                  g_value_take_boxed (&tag_value, gst_date_time_new_y (year));\n                }\n              } else if (strcmp (gst_tag_name, GST_TAG_GENRE) == 0) {\n                guint id3v1_genre_id;\n                const gchar *genre_str;\n\n                if (sscanf (value_utf8, \"(%u)\", &id3v1_genre_id) == 1 &&\n                    ((genre_str = gst_tag_id3_genre_get (id3v1_genre_id)))) {\n                  GST_DEBUG (\"Genre: %s -> %s\", value_utf8, genre_str);\n                  g_free (value_utf8);\n                  value_utf8 = g_strdup (genre_str);\n                }\n              } else {\n                GType tag_type;\n\n                /* convert tag from string to other type if required */\n                tag_type = gst_tag_get_type (gst_tag_name);\n                g_value_init (&tag_value, tag_type);\n                if (!gst_value_deserialize (&tag_value, value_utf8)) {\n                  GValue from_val = { 0, };\n\n                  g_value_init (&from_val, G_TYPE_STRING);\n                  g_value_set_string (&from_val, value_utf8);\n                  if (!g_value_transform (&from_val, &tag_value)) {\n                    GST_WARNING_OBJECT (demux,\n                        \"Could not transform string tag to \" \"%s tag type %s\",\n                        gst_tag_name, g_type_name (tag_type));\n                    g_value_unset (&tag_value);\n                  }\n                  g_value_unset (&from_val);\n                }\n              }\n            } else {\n              /* metadata ! */\n              GST_DEBUG (\"Setting metadata\");\n              g_value_init (&tag_value, G_TYPE_STRING);\n              g_value_set_string (&tag_value, value_utf8);\n              /* If we found a stereoscopic marker, look for StereoscopicLayout\n               * metadata */\n              if (content3D) {\n                guint i;\n                if (strncmp (\"StereoscopicLayout\", name_utf8,\n                        strlen (name_utf8)) == 0) {\n                  for (i = 0; i < G_N_ELEMENTS (stereoscopic_layout_map); i++) {\n                    if (g_str_equal (stereoscopic_layout_map[i].interleave_name,\n                            value_utf8)) {\n                      demux->asf_3D_mode =\n                          stereoscopic_layout_map[i].interleaving_type;\n                      GST_INFO (\"find interleave type %u\", demux->asf_3D_mode);\n                    }\n                  }\n                }\n                GST_INFO_OBJECT (demux, \"3d type is %u\", demux->asf_3D_mode);\n              } else {\n                demux->asf_3D_mode = GST_ASF_3D_NONE;\n                GST_INFO_OBJECT (demux, \"None 3d type\");\n              }\n            }\n          } else if (value_utf8 == NULL) {\n            GST_WARNING (\"Failed to convert string value to UTF8, skipping\");\n          } else {\n            GST_DEBUG (\"Skipping empty string value for %s\",\n                GST_STR_NULL (gst_tag_name));\n          }\n          g_free (value_utf8);\n          break;\n        }\n        case ASF_DEMUX_DATA_TYPE_BYTE_ARRAY:{\n          if (gst_tag_name) {\n            if (!g_str_equal (gst_tag_name, GST_TAG_IMAGE)) {\n              GST_FIXME (\"Unhandled byte array tag %s\",\n                  GST_STR_NULL (gst_tag_name));\n              break;\n            } else {\n              asf_demux_parse_picture_tag (taglist, (guint8 *) value,\n                  value_len);\n            }\n          }\n          break;\n        }\n        case ASF_DEMUX_DATA_TYPE_DWORD:{\n          guint uint_val;\n\n          if (value_len < 4)\n            break;\n\n          uint_val = GST_READ_UINT32_LE (value);\n\n          /* this is the track number */\n          g_value_init (&tag_value, G_TYPE_UINT);\n\n          /* WM/Track counts from 0 */\n          if (!strcmp (name_utf8, \"WM/Track\"))\n            ++uint_val;\n\n          g_value_set_uint (&tag_value, uint_val);\n          break;\n        }\n          /* Detect 3D */\n        case ASF_DEMUX_DATA_TYPE_BOOL:{\n          gboolean bool_val;\n\n          if (value_len < 4)\n            break;\n\n          bool_val = GST_READ_UINT32_LE (value);\n\n          if (strncmp (\"Stereoscopic\", name_utf8, strlen (name_utf8)) == 0) {\n            if (bool_val) {\n              GST_INFO_OBJECT (demux, \"This is 3D contents\");\n              content3D = TRUE;\n            } else {\n              GST_INFO_OBJECT (demux, \"This is not 3D contenst\");\n              content3D = FALSE;\n            }\n          }\n\n          break;\n        }\n        default:{\n          GST_DEBUG (\"Skipping tag %s of type %d\", gst_tag_name, datatype);\n          break;\n        }\n      }\n\n      if (G_IS_VALUE (&tag_value)) {\n        if (gst_tag_name) {\n          GstTagMergeMode merge_mode = GST_TAG_MERGE_APPEND;\n\n          /* WM/TrackNumber is more reliable than WM/Track, since the latter\n           * is supposed to have a 0 base but is often wrongly written to start\n           * from 1 as well, so prefer WM/TrackNumber when we have it: either\n           * replace the value added earlier from WM/Track or put it first in\n           * the list, so that it will get picked up by _get_uint() */\n          if (strcmp (name_utf8, \"WM/TrackNumber\") == 0)\n            merge_mode = GST_TAG_MERGE_REPLACE;\n\n          gst_tag_list_add_values (taglist, merge_mode, gst_tag_name,\n              &tag_value, NULL);\n        } else {\n          GST_DEBUG (\"Setting global metadata %s\", name_utf8);\n          gst_structure_set_value (demux->global_metadata, name_utf8,\n              &tag_value);\n        }\n\n        g_value_unset (&tag_value);\n      }\n    }\n\n    g_free (name);\n    g_free (value);\n    g_free (name_utf8);\n  }\n\n  gst_asf_demux_add_global_tags (demux, taglist);\n\n  return GST_FLOW_OK;\n\n  /* Errors */\nnot_enough_data:\n  {\n    GST_WARNING (\"Unexpected end of data parsing ext content desc object\");\n    gst_tag_list_unref (taglist);\n    return GST_FLOW_OK;         /* not really fatal */\n  }\n}", "commit_link": "github.com/GStreamer/gst-plugins-ugly/commit/d21017b52a585f145e8d62781bcc1c5fefc7ee37", "file_name": "gst/asfdemux/gstasfdemux.c", "vul_type": "cwe-125", "description": "Write a C function in GStreamer for processing extended content descriptors in ASF demuxing."}
{"func_name": "enc_untrusted_recvmsg", "func_src_before": "ssize_t enc_untrusted_recvmsg(int sockfd, struct msghdr *msg, int flags) {\n  size_t total_buffer_size = CalculateTotalMessageSize(msg);\n\n  MessageWriter input;\n  input.Push(sockfd);\n  input.Push<uint64_t>(msg->msg_namelen);\n  input.Push<uint64_t>(total_buffer_size);\n  input.Push<uint64_t>(msg->msg_controllen);\n  input.Push(msg->msg_flags);\n  input.Push(flags);\n\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvMsgHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvmsg\", 2,\n                           /*match_exact_params=*/false);\n\n  ssize_t result = output.next<ssize_t>();\n  int klinux_errno = output.next<int>();\n\n  // recvmsg() returns the number of characters received. On error, -1 is\n  // returned, with errno set to indicate the cause of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  auto msg_name_extent = output.next();\n  // The returned |msg_namelen| should not exceed the buffer size.\n  if (msg_name_extent.size() <= msg->msg_namelen) {\n    msg->msg_namelen = msg_name_extent.size();\n  }\n  memcpy(msg->msg_name, msg_name_extent.As<char>(), msg->msg_namelen);\n\n  // A single buffer is passed from the untrusted side, copy it into the\n  // scattered buffers inside the enclave.\n  auto msg_iov_extent = output.next();\n  size_t total_bytes = msg_iov_extent.size();\n  size_t bytes_copied = 0;\n  for (int i = 0; i < msg->msg_iovlen && bytes_copied < total_bytes; ++i) {\n    size_t bytes_to_copy =\n        std::min(msg->msg_iov[i].iov_len, total_bytes - bytes_copied);\n    memcpy(msg->msg_iov[i].iov_base, msg_iov_extent.As<char>() + bytes_copied,\n           bytes_to_copy);\n    bytes_copied += bytes_to_copy;\n  }\n\n  auto msg_control_extent = output.next();\n  // The returned |msg_controllen| should not exceed the buffer size.\n  if (msg_control_extent.size() <= msg->msg_controllen) {\n    msg->msg_controllen = msg_control_extent.size();\n  }\n  memcpy(msg->msg_control, msg_control_extent.As<char>(), msg->msg_controllen);\n\n  return result;\n}", "func_src_after": "ssize_t enc_untrusted_recvmsg(int sockfd, struct msghdr *msg, int flags) {\n  size_t total_buffer_size = CalculateTotalMessageSize(msg);\n\n  MessageWriter input;\n  input.Push(sockfd);\n  input.Push<uint64_t>(msg->msg_namelen);\n  input.Push<uint64_t>(total_buffer_size);\n  input.Push<uint64_t>(msg->msg_controllen);\n  input.Push(msg->msg_flags);\n  input.Push(flags);\n\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvMsgHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvmsg\", 2,\n                           /*match_exact_params=*/false);\n\n  ssize_t result = output.next<ssize_t>();\n  int klinux_errno = output.next<int>();\n\n  // recvmsg() returns the number of characters received. On error, -1 is\n  // returned, with errno set to indicate the cause of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  if (result > total_buffer_size) {\n    ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n        \"enc_untrusted_recvmsg: result exceeds requested\");\n  }\n\n  auto msg_name_extent = output.next();\n  // The returned |msg_namelen| should not exceed the buffer size.\n  if (msg_name_extent.size() <= msg->msg_namelen) {\n    msg->msg_namelen = msg_name_extent.size();\n  }\n  memcpy(msg->msg_name, msg_name_extent.As<char>(), msg->msg_namelen);\n\n  // A single buffer is passed from the untrusted side, copy it into the\n  // scattered buffers inside the enclave.\n  auto msg_iov_extent = output.next();\n  size_t total_bytes = msg_iov_extent.size();\n  size_t bytes_copied = 0;\n  for (int i = 0; i < msg->msg_iovlen && bytes_copied < total_bytes; ++i) {\n    size_t bytes_to_copy =\n        std::min(msg->msg_iov[i].iov_len, total_bytes - bytes_copied);\n    memcpy(msg->msg_iov[i].iov_base, msg_iov_extent.As<char>() + bytes_copied,\n           bytes_to_copy);\n    bytes_copied += bytes_to_copy;\n  }\n\n  auto msg_control_extent = output.next();\n  // The returned |msg_controllen| should not exceed the buffer size.\n  if (msg_control_extent.size() <= msg->msg_controllen) {\n    msg->msg_controllen = msg_control_extent.size();\n  }\n  memcpy(msg->msg_control, msg_control_extent.As<char>(), msg->msg_controllen);\n\n  return result;\n}", "commit_link": "github.com/google/asylo/commit/fa6485c5d16a7355eab047d4a44345a73bc9131e", "file_name": "asylo/platform/host_call/trusted/host_calls.cc", "vul_type": "cwe-125", "description": "Write a C++ function `enc_untrusted_recvmsg` that wraps a system call to receive a message on a socket within an enclave, handling message structure and error conversion."}
{"func_name": "HPHP::HHVM_METHOD", "func_src_before": "static Array HHVM_METHOD(Memcache, getextendedstats,\n                         const String& /*type*/ /* = null_string */,\n                         int /*slabid*/ /* = 0 */, int /*limit*/ /* = 100 */) {\n  auto data = Native::data<MemcacheData>(this_);\n  memcached_return_t ret;\n  memcached_stat_st *stats;\n\n  stats = memcached_stat(&data->m_memcache, nullptr, &ret);\n  if (ret != MEMCACHED_SUCCESS) {\n    return Array();\n  }\n\n  int server_count = memcached_server_count(&data->m_memcache);\n\n  Array return_val;\n\n  for (int server_id = 0; server_id < server_count; server_id++) {\n    memcached_stat_st *stat;\n    char stats_key[30] = {0};\n    size_t key_len;\n\n    LMCD_SERVER_POSITION_INSTANCE_TYPE instance =\n      memcached_server_instance_by_position(&data->m_memcache, server_id);\n    const char *hostname = LMCD_SERVER_HOSTNAME(instance);\n    in_port_t port = LMCD_SERVER_PORT(instance);\n\n    stat = stats + server_id;\n\n    Array server_stats = memcache_build_stats(&data->m_memcache, stat, &ret);\n    if (ret != MEMCACHED_SUCCESS) {\n      continue;\n    }\n\n    key_len = snprintf(stats_key, sizeof(stats_key), \"%s:%d\", hostname, port);\n\n    return_val.set(String(stats_key, key_len, CopyString), server_stats);\n  }\n\n  free(stats);\n  return return_val;\n}", "func_src_after": "static Array HHVM_METHOD(Memcache, getextendedstats,\n                         const String& /*type*/ /* = null_string */,\n                         int /*slabid*/ /* = 0 */, int /*limit*/ /* = 100 */) {\n  auto data = Native::data<MemcacheData>(this_);\n  memcached_return_t ret;\n  memcached_stat_st *stats;\n\n  stats = memcached_stat(&data->m_memcache, nullptr, &ret);\n  if (ret != MEMCACHED_SUCCESS) {\n    return Array();\n  }\n\n  int server_count = memcached_server_count(&data->m_memcache);\n\n  Array return_val;\n\n  for (int server_id = 0; server_id < server_count; server_id++) {\n    memcached_stat_st *stat;\n    LMCD_SERVER_POSITION_INSTANCE_TYPE instance =\n      memcached_server_instance_by_position(&data->m_memcache, server_id);\n    const char *hostname = LMCD_SERVER_HOSTNAME(instance);\n    in_port_t port = LMCD_SERVER_PORT(instance);\n\n    stat = stats + server_id;\n\n    Array server_stats = memcache_build_stats(&data->m_memcache, stat, &ret);\n    if (ret != MEMCACHED_SUCCESS) {\n      continue;\n    }\n\n    auto const port_str = folly::to<std::string>(port);\n    auto const key_len = strlen(hostname) + 1 + port_str.length();\n    auto key = String(key_len, ReserveString);\n    key += hostname;\n    key += \":\";\n    key += port_str;\n    return_val.set(key, server_stats);\n  }\n\n  free(stats);\n  return return_val;\n}", "commit_link": "github.com/facebook/hhvm/commit/4bff3bfbe90d10451e4638c2118d1ad1117bb3e3", "file_name": "hphp/runtime/ext/memcache/ext_memcache.cpp", "vul_type": "cwe-125", "description": "Write a function in HHVM to retrieve extended statistics from all Memcache servers."}
{"func_name": "_get_3par_host", "func_src_before": "    def _get_3par_host(self, hostname):\n        out = self._cli_run('showhost -verbose %s' % (hostname), None)\n        LOG.debug(\"OUTPUT = \\n%s\" % (pprint.pformat(out)))\n        host = {'id': None, 'name': None,\n                'domain': None,\n                'descriptors': {},\n                'iSCSIPaths': [],\n                'FCPaths': []}\n\n        if out:\n            err = out[0]\n            if err == 'no hosts listed':\n                msg = {'code': 'NON_EXISTENT_HOST',\n                       'desc': \"HOST '%s' was not found\" % hostname}\n                raise hpexceptions.HTTPNotFound(msg)\n\n            # start parsing the lines after the header line\n            for line in out[1:]:\n                if line == '':\n                    break\n                tmp = line.split(',')\n                paths = {}\n\n                LOG.debug(\"line = %s\" % (pprint.pformat(tmp)))\n                host['id'] = tmp[0]\n                host['name'] = tmp[1]\n\n                portPos = tmp[4]\n                LOG.debug(\"portPos = %s\" % (pprint.pformat(portPos)))\n                if portPos == '---':\n                    portPos = None\n                else:\n                    port = portPos.split(':')\n                    portPos = {'node': int(port[0]), 'slot': int(port[1]),\n                               'cardPort': int(port[2])}\n\n                paths['portPos'] = portPos\n\n                # If FC entry\n                if tmp[5] == 'n/a':\n                    paths['wwn'] = tmp[3]\n                    host['FCPaths'].append(paths)\n                # else iSCSI entry\n                else:\n                    paths['name'] = tmp[3]\n                    paths['ipAddr'] = tmp[5]\n                    host['iSCSIPaths'].append(paths)\n\n            # find the offset to the description stuff\n            offset = 0\n            for line in out:\n                if line[:15] == '---------- Host':\n                    break\n                else:\n                    offset += 1\n\n            info = out[offset + 2]\n            tmp = info.split(':')\n            host['domain'] = tmp[1]\n\n            info = out[offset + 4]\n            tmp = info.split(':')\n            host['descriptors']['location'] = tmp[1]\n\n            info = out[offset + 5]\n            tmp = info.split(':')\n            host['descriptors']['ipAddr'] = tmp[1]\n\n            info = out[offset + 6]\n            tmp = info.split(':')\n            host['descriptors']['os'] = tmp[1]\n\n            info = out[offset + 7]\n            tmp = info.split(':')\n            host['descriptors']['model'] = tmp[1]\n\n            info = out[offset + 8]\n            tmp = info.split(':')\n            host['descriptors']['contact'] = tmp[1]\n\n            info = out[offset + 9]\n            tmp = info.split(':')\n            host['descriptors']['comment'] = tmp[1]\n\n        return host", "func_src_after": "    def _get_3par_host(self, hostname):\n        out = self._cli_run(['showhost', '-verbose', hostname])\n        LOG.debug(\"OUTPUT = \\n%s\" % (pprint.pformat(out)))\n        host = {'id': None, 'name': None,\n                'domain': None,\n                'descriptors': {},\n                'iSCSIPaths': [],\n                'FCPaths': []}\n\n        if out:\n            err = out[0]\n            if err == 'no hosts listed':\n                msg = {'code': 'NON_EXISTENT_HOST',\n                       'desc': \"HOST '%s' was not found\" % hostname}\n                raise hpexceptions.HTTPNotFound(msg)\n\n            # start parsing the lines after the header line\n            for line in out[1:]:\n                if line == '':\n                    break\n                tmp = line.split(',')\n                paths = {}\n\n                LOG.debug(\"line = %s\" % (pprint.pformat(tmp)))\n                host['id'] = tmp[0]\n                host['name'] = tmp[1]\n\n                portPos = tmp[4]\n                LOG.debug(\"portPos = %s\" % (pprint.pformat(portPos)))\n                if portPos == '---':\n                    portPos = None\n                else:\n                    port = portPos.split(':')\n                    portPos = {'node': int(port[0]), 'slot': int(port[1]),\n                               'cardPort': int(port[2])}\n\n                paths['portPos'] = portPos\n\n                # If FC entry\n                if tmp[5] == 'n/a':\n                    paths['wwn'] = tmp[3]\n                    host['FCPaths'].append(paths)\n                # else iSCSI entry\n                else:\n                    paths['name'] = tmp[3]\n                    paths['ipAddr'] = tmp[5]\n                    host['iSCSIPaths'].append(paths)\n\n            # find the offset to the description stuff\n            offset = 0\n            for line in out:\n                if line[:15] == '---------- Host':\n                    break\n                else:\n                    offset += 1\n\n            info = out[offset + 2]\n            tmp = info.split(':')\n            host['domain'] = tmp[1]\n\n            info = out[offset + 4]\n            tmp = info.split(':')\n            host['descriptors']['location'] = tmp[1]\n\n            info = out[offset + 5]\n            tmp = info.split(':')\n            host['descriptors']['ipAddr'] = tmp[1]\n\n            info = out[offset + 6]\n            tmp = info.split(':')\n            host['descriptors']['os'] = tmp[1]\n\n            info = out[offset + 7]\n            tmp = info.split(':')\n            host['descriptors']['model'] = tmp[1]\n\n            info = out[offset + 8]\n            tmp = info.split(':')\n            host['descriptors']['contact'] = tmp[1]\n\n            info = out[offset + 9]\n            tmp = info.split(':')\n            host['descriptors']['comment'] = tmp[1]\n\n        return host", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "In Python, write a function to parse detailed host information from CLI output."}
{"func_name": "_get_vdisk_attributes", "func_src_before": "    def _get_vdisk_attributes(self, vdisk_name):\n        \"\"\"Return vdisk attributes, or None if vdisk does not exist\n\n        Exception is raised if the information from system can not be\n        parsed/matched to a single vdisk.\n        \"\"\"\n\n        ssh_cmd = 'svcinfo lsvdisk -bytes -delim ! %s ' % vdisk_name\n        return self._execute_command_and_parse_attributes(ssh_cmd)", "func_src_after": "    def _get_vdisk_attributes(self, vdisk_name):\n        \"\"\"Return vdisk attributes, or None if vdisk does not exist\n\n        Exception is raised if the information from system can not be\n        parsed/matched to a single vdisk.\n        \"\"\"\n\n        ssh_cmd = ['svcinfo', 'lsvdisk', '-bytes', '-delim', '!', vdisk_name]\n        return self._execute_command_and_parse_attributes(ssh_cmd)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch virtual disk attributes using an SSH command, handling non-existence and parsing exceptions."}
{"func_name": "git_hook", "func_src_before": "def git_hook(strict=False, modify=False):\n    \"\"\"\n    Git pre-commit hook to check staged files for isort errors\n\n    :param bool strict - if True, return number of errors on exit,\n        causing the hook to fail. If False, return zero so it will\n        just act as a warning.\n    :param bool modify - if True, fix the sources if they are not\n        sorted properly. If False, only report result without\n        modifying anything.\n\n    :return number of errors if in strict mode, 0 otherwise.\n    \"\"\"\n\n    # Get list of files modified and staged\n    diff_cmd = \"git diff-index --cached --name-only --diff-filter=ACMRTUXB HEAD\"\n    files_modified = get_lines(diff_cmd)\n\n    errors = 0\n    for filename in files_modified:\n        if filename.endswith('.py'):\n            # Get the staged contents of the file\n            staged_cmd = \"git show :%s\" % filename\n            staged_contents = get_output(staged_cmd)\n\n            sort = SortImports(\n                file_path=filename,\n                file_contents=staged_contents.decode(),\n                check=True\n            )\n\n            if sort.incorrectly_sorted:\n                errors += 1\n                if modify:\n                    SortImports(\n                        file_path=filename,\n                        file_contents=staged_contents.decode(),\n                        check=False,\n                    )\n\n    return errors if strict else 0", "func_src_after": "def git_hook(strict=False, modify=False):\n    \"\"\"\n    Git pre-commit hook to check staged files for isort errors\n\n    :param bool strict - if True, return number of errors on exit,\n        causing the hook to fail. If False, return zero so it will\n        just act as a warning.\n    :param bool modify - if True, fix the sources if they are not\n        sorted properly. If False, only report result without\n        modifying anything.\n\n    :return number of errors if in strict mode, 0 otherwise.\n    \"\"\"\n\n    # Get list of files modified and staged\n    diff_cmd = [\"git\", \"diff-index\", \"--cached\", \"--name-only\", \"--diff-filter=ACMRTUXB HEAD\"]\n    files_modified = get_lines(diff_cmd)\n\n    errors = 0\n    for filename in files_modified:\n        if filename.endswith('.py'):\n            # Get the staged contents of the file\n            staged_cmd = [\"git\", \"show\", \":%s\" % filename]\n            staged_contents = get_output(staged_cmd)\n\n            sort = SortImports(\n                file_path=filename,\n                file_contents=staged_contents,\n                check=True\n            )\n\n            if sort.incorrectly_sorted:\n                errors += 1\n                if modify:\n                    SortImports(\n                        file_path=filename,\n                        file_contents=staged_contents,\n                        check=False,\n                    )\n\n    return errors if strict else 0", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "isort/hooks.py", "vul_type": "cwe-078", "description": "Write a Python function named `git_hook` that acts as a pre-commit hook to check if Python files are correctly sorted by `isort`, with options to either strictly enforce sorting or just warn, and to modify files if needed."}
{"func_name": "test_create_modify_host", "func_src_before": "    def test_create_modify_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_NO_HOST_RET), ''])\n\n        create_host_cmd = ('createhost -iscsi -add fakehost '\n                           'iqn.1993-08.org.debian:01:222')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_modify_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_NO_HOST_RET), ''])\n\n        create_host_cmd = ['createhost', '-iscsi', '-add', 'fakehost',\n                           'iqn.1993-08.org.debian:01:222']\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying an iSCSI host."}
{"func_name": "_run_ssh", "func_src_before": "    def _run_ssh(self, command, check_exit_code=True, attempts=1):\n        if not self.sshpool:\n            password = self.configuration.san_password\n            privatekey = self.configuration.san_private_key\n            min_size = self.configuration.ssh_min_pool_conn\n            max_size = self.configuration.ssh_max_pool_conn\n            self.sshpool = utils.SSHPool(self.configuration.san_ip,\n                                         self.configuration.san_ssh_port,\n                                         self.configuration.ssh_conn_timeout,\n                                         self.configuration.san_login,\n                                         password=password,\n                                         privatekey=privatekey,\n                                         min_size=min_size,\n                                         max_size=max_size)\n        last_exception = None\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return utils.ssh_execute(\n                            ssh,\n                            command,\n                            check_exit_code=check_exit_code)\n                    except Exception as e:\n                        LOG.error(e)\n                        last_exception = e\n                        greenthread.sleep(random.randint(20, 500) / 100.0)\n                try:\n                    raise exception.ProcessExecutionError(\n                        exit_code=last_exception.exit_code,\n                        stdout=last_exception.stdout,\n                        stderr=last_exception.stderr,\n                        cmd=last_exception.cmd)\n                except AttributeError:\n                    raise exception.ProcessExecutionError(\n                        exit_code=-1,\n                        stdout=\"\",\n                        stderr=\"Error running SSH command\",\n                        cmd=command)\n\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running SSH command: %s\") % command)", "func_src_after": "    def _run_ssh(self, cmd_list, check_exit_code=True, attempts=1):\n        utils.check_ssh_injection(cmd_list)\n        command = ' '. join(cmd_list)\n\n        if not self.sshpool:\n            password = self.configuration.san_password\n            privatekey = self.configuration.san_private_key\n            min_size = self.configuration.ssh_min_pool_conn\n            max_size = self.configuration.ssh_max_pool_conn\n            self.sshpool = utils.SSHPool(self.configuration.san_ip,\n                                         self.configuration.san_ssh_port,\n                                         self.configuration.ssh_conn_timeout,\n                                         self.configuration.san_login,\n                                         password=password,\n                                         privatekey=privatekey,\n                                         min_size=min_size,\n                                         max_size=max_size)\n        last_exception = None\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return utils.ssh_execute(\n                            ssh,\n                            command,\n                            check_exit_code=check_exit_code)\n                    except Exception as e:\n                        LOG.error(e)\n                        last_exception = e\n                        greenthread.sleep(random.randint(20, 500) / 100.0)\n                try:\n                    raise exception.ProcessExecutionError(\n                        exit_code=last_exception.exit_code,\n                        stdout=last_exception.stdout,\n                        stderr=last_exception.stderr,\n                        cmd=last_exception.cmd)\n                except AttributeError:\n                    raise exception.ProcessExecutionError(\n                        exit_code=-1,\n                        stdout=\"\",\n                        stderr=\"Error running SSH command\",\n                        cmd=command)\n\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running SSH command: %s\") % command)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/san/san.py", "vul_type": "cwe-078", "description": "Write a Python function to execute SSH commands with retry logic and connection pooling."}
{"func_name": "view", "func_src_before": "@app.route('/view/<sid>')\ndef view(sid):\n    if '/' not in sid:\n        path = os.path.join(app.config['UPLOAD_FOLDER'], sid)\n        if os.path.isdir(path):\n            using_firebase = 'true' if app.config['FIREBASE'] else 'false'\n            return render_template('view.html',\n            sid=sid, title=\"Progress for %s\" % sid, using_firebase=using_firebase)\n        else:\n            abort(404)\n    else:\n        abort(403)", "func_src_after": "@app.route('/view/<sid>')\ndef view(sid):\n    if utils.sid_is_valid(sid):\n        path = join(app.config['UPLOAD_FOLDER'], sid)\n        if os.path.isdir(path):\n            using_firebase = 'true' if app.config['FIREBASE'] else 'false'\n            return render_template('view.html', sid=sid,\n                                    title=\"Progress for %s\" % sid,\n                                    using_firebase=using_firebase)\n        else:\n            abort(404)\n    else:\n        abort(403)", "commit_link": "github.com/cheukyin699/genset-demo-site/commit/abb55b1a6786b0a995c2cdf77a7977a1d51cfc0d", "file_name": "app/views.py", "vul_type": "cwe-078", "description": "Create a Python Flask route handler that checks if a provided 'sid' is valid and serves a directory if it exists, or aborts with an error if not."}
{"func_name": "get_title_from_youtube_url", "func_src_before": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output('youtube-dl --get-title %s --no-warnings' % url, stderr=subprocess.STDOUT,\n                                             shell=True)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "func_src_after": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output(['youtube-dl', '--get-title', url, '--no-warnings'],\n                                             stderr=subprocess.STDOUT)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "commit_link": "github.com/w-martin/mindfulness/commit/62e1d5ce9deb57468cf917ce0ce838120ec84c46", "file_name": "src/util.py", "vul_type": "cwe-078", "description": "Write a Python function that extracts the title of a YouTube video from its URL using the `youtube-dl` command-line program, handling any potential errors."}
{"func_name": "test_get_ports", "func_src_before": "    def test_get_ports(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI),\n                                                    ''])\n        self.mox.ReplayAll()\n\n        ports = self.driver.common.get_ports()\n        self.assertEqual(ports['FC'][0], '20210002AC00383D')\n        self.assertEqual(ports['iSCSI']['10.10.120.252']['nsp'], '0:8:2')", "func_src_after": "    def test_get_ports(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI),\n                                                    ''])\n        self.mox.ReplayAll()\n\n        ports = self.driver.common.get_ports()\n        self.assertEqual(ports['FC'][0], '20210002AC00383D')\n        self.assertEqual(ports['iSCSI']['10.10.120.252']['nsp'], '0:8:2')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands to retrieve port information and asserts the results."}
{"func_name": "_create_3par_vlun", "func_src_before": "    def _create_3par_vlun(self, volume, hostname):\n        out = self._cli_run('createvlun %s auto %s' % (volume, hostname), None)\n        if out and len(out) > 1:\n            if \"must be in the same domain\" in out[0]:\n                err = out[0].strip()\n                err = err + \" \" + out[1].strip()\n                raise exception.Invalid3PARDomain(err=err)", "func_src_after": "    def _create_3par_vlun(self, volume, hostname):\n        out = self._cli_run(['createvlun', volume, 'auto', hostname])\n        if out and len(out) > 1:\n            if \"must be in the same domain\" in out[0]:\n                err = out[0].strip()\n                err = err + \" \" + out[1].strip()\n                raise exception.Invalid3PARDomain(err=err)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to create a 3PAR VLUN, handling domain mismatch errors."}
{"func_name": "_set_connections", "func_src_before": "    def _set_connections(self):\n        \"\"\"Set the number of concurrent connections.\n\n        The 3PAR WS API server has a limit of concurrent connections.\n        This is setting the number to the highest allowed, 15 connections.\n        \"\"\"\n        self._cli_run(\"setwsapi -sru high\", None)", "func_src_after": "    def _set_connections(self):\n        \"\"\"Set the number of concurrent connections.\n\n        The 3PAR WS API server has a limit of concurrent connections.\n        This is setting the number to the highest allowed, 15 connections.\n        \"\"\"\n        self._cli_run(['setwsapi', '-sru', 'high'])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to configure the maximum number of concurrent connections for a 3PAR WS API server."}
{"func_name": "_get_chap_secret_for_host", "func_src_before": "    def _get_chap_secret_for_host(self, host_name):\n        \"\"\"Return the CHAP secret for the given host.\"\"\"\n\n        LOG.debug(_('enter: _get_chap_secret_for_host: host name %s')\n                  % host_name)\n\n        ssh_cmd = 'svcinfo lsiscsiauth -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        host_lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(host_lines), '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n\n        header = host_lines.pop(0).split('!')\n        self._assert_ssh_return('name' in header, '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n        self._assert_ssh_return('iscsi_auth_method' in header,\n                                '_get_chap_secret_for_host', ssh_cmd, out, err)\n        self._assert_ssh_return('iscsi_chap_secret' in header,\n                                '_get_chap_secret_for_host', ssh_cmd, out, err)\n        name_index = header.index('name')\n        method_index = header.index('iscsi_auth_method')\n        secret_index = header.index('iscsi_chap_secret')\n\n        chap_secret = None\n        host_found = False\n        for line in host_lines:\n            info = line.split('!')\n            if info[name_index] == host_name:\n                host_found = True\n                if info[method_index] == 'chap':\n                    chap_secret = info[secret_index]\n\n        self._assert_ssh_return(host_found, '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _get_chap_secret_for_host: host name '\n                    '%(host_name)s with secret %(chap_secret)s')\n                  % {'host_name': host_name, 'chap_secret': chap_secret})\n\n        return chap_secret", "func_src_after": "    def _get_chap_secret_for_host(self, host_name):\n        \"\"\"Return the CHAP secret for the given host.\"\"\"\n\n        LOG.debug(_('enter: _get_chap_secret_for_host: host name %s')\n                  % host_name)\n\n        ssh_cmd = ['svcinfo', 'lsiscsiauth', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        host_lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(host_lines), '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n\n        header = host_lines.pop(0).split('!')\n        self._assert_ssh_return('name' in header, '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n        self._assert_ssh_return('iscsi_auth_method' in header,\n                                '_get_chap_secret_for_host', ssh_cmd, out, err)\n        self._assert_ssh_return('iscsi_chap_secret' in header,\n                                '_get_chap_secret_for_host', ssh_cmd, out, err)\n        name_index = header.index('name')\n        method_index = header.index('iscsi_auth_method')\n        secret_index = header.index('iscsi_chap_secret')\n\n        chap_secret = None\n        host_found = False\n        for line in host_lines:\n            info = line.split('!')\n            if info[name_index] == host_name:\n                host_found = True\n                if info[method_index] == 'chap':\n                    chap_secret = info[secret_index]\n\n        self._assert_ssh_return(host_found, '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _get_chap_secret_for_host: host name '\n                    '%(host_name)s with secret %(chap_secret)s')\n                  % {'host_name': host_name, 'chap_secret': chap_secret})\n\n        return chap_secret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve the CHAP secret for a specified host by executing an SSH command and parsing the output."}
{"func_name": "tensorflow::KernelAndDeviceOp::Run", "func_src_before": "Status KernelAndDeviceOp::Run(\n    ScopedStepContainer* step_container, const EagerKernelArgs& inputs,\n    std::vector<EagerKernelRet>* outputs,\n    CancellationManager* cancellation_manager,\n    const absl::optional<EagerRemoteFunctionParams>& remote_func_params) {\n  OpKernelContext::Params params;\n  params.device = device_;\n  params.frame_iter = FrameAndIter(0, 0);\n  params.inputs = inputs.GetTensorValues();\n  params.op_kernel = kernel_.get();\n  params.resource_manager = device_->resource_manager();\n  params.input_alloc_attrs = &input_alloc_attrs_;\n  params.output_attr_array = output_alloc_attrs_.data();\n  params.function_library = flr_;\n  params.slice_reader_cache = &slice_reader_cache_;\n  params.rendezvous = rendezvous_;\n  OpExecutionState* op_execution_state = nullptr;\n\n  CancellationManager default_cancellation_manager;\n  if (cancellation_manager) {\n    params.cancellation_manager = cancellation_manager;\n  } else if (kernel_->is_deferred()) {\n    op_execution_state = new OpExecutionState;\n    params.cancellation_manager = &op_execution_state->cancellation_manager;\n    params.inc_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Ref();\n    };\n    params.dec_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Unref();\n    };\n  } else {\n    params.cancellation_manager = &default_cancellation_manager;\n  }\n\n  params.log_memory = log_memory_;\n\n  params.runner = get_runner();\n\n  params.step_container =\n      step_container == nullptr ? &step_container_ : step_container;\n  auto step_container_cleanup = gtl::MakeCleanup([step_container, this] {\n    if (step_container == nullptr) {\n      this->step_container_.CleanUp();\n    }\n  });\n\n  params.collective_executor =\n      collective_executor_ ? collective_executor_->get() : nullptr;\n\n  OpKernelContext context(&params);\n\n  {\n    port::ScopedFlushDenormal flush;\n    port::ScopedSetRound round(FE_TONEAREST);\n    // 'AnnotatedTraceMe' will trace both scheduling time on host and execution\n    // time on device of the OpKernel.\n    profiler::AnnotatedTraceMe activity(\n        [&] { return kernel_->TraceString(context, /*verbose=*/false); },\n        profiler::TraceMeLevel::kInfo);\n    device_->Compute(kernel_.get(), &context);\n  }\n\n  // Clean up execution op_execution_state if deferred ops aren't running.\n  if (op_execution_state != nullptr) {\n    op_execution_state->Unref();\n  }\n\n  if (!context.status().ok()) return context.status();\n\n  if (outputs != nullptr) {\n    outputs->clear();\n    for (int i = 0; i < context.num_outputs(); ++i) {\n      outputs->push_back(Tensor(*context.mutable_output(i)));\n    }\n  }\n  return Status::OK();\n}", "func_src_after": "Status KernelAndDeviceOp::Run(\n    ScopedStepContainer* step_container, const EagerKernelArgs& inputs,\n    std::vector<EagerKernelRet>* outputs,\n    CancellationManager* cancellation_manager,\n    const absl::optional<EagerRemoteFunctionParams>& remote_func_params) {\n  OpKernelContext::Params params;\n  params.device = device_;\n  params.frame_iter = FrameAndIter(0, 0);\n  params.inputs = inputs.GetTensorValues();\n  params.op_kernel = kernel_.get();\n  params.resource_manager = device_->resource_manager();\n  params.input_alloc_attrs = &input_alloc_attrs_;\n  params.output_attr_array = output_alloc_attrs_.data();\n  params.function_library = flr_;\n  params.slice_reader_cache = &slice_reader_cache_;\n  params.rendezvous = rendezvous_;\n  OpExecutionState* op_execution_state = nullptr;\n\n  CancellationManager default_cancellation_manager;\n  if (cancellation_manager) {\n    params.cancellation_manager = cancellation_manager;\n  } else if (kernel_->is_deferred()) {\n    op_execution_state = new OpExecutionState;\n    params.cancellation_manager = &op_execution_state->cancellation_manager;\n    params.inc_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Ref();\n    };\n    params.dec_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Unref();\n    };\n  } else {\n    params.cancellation_manager = &default_cancellation_manager;\n  }\n\n  params.log_memory = log_memory_;\n\n  params.runner = get_runner();\n\n  params.step_container =\n      step_container == nullptr ? &step_container_ : step_container;\n  auto step_container_cleanup = gtl::MakeCleanup([step_container, this] {\n    if (step_container == nullptr) {\n      this->step_container_.CleanUp();\n    }\n  });\n\n  params.collective_executor =\n      collective_executor_ ? collective_executor_->get() : nullptr;\n\n  OpKernelContext context(&params);\n\n  {\n    port::ScopedFlushDenormal flush;\n    port::ScopedSetRound round(FE_TONEAREST);\n    // 'AnnotatedTraceMe' will trace both scheduling time on host and execution\n    // time on device of the OpKernel.\n    profiler::AnnotatedTraceMe activity(\n        [&] { return kernel_->TraceString(context, /*verbose=*/false); },\n        profiler::TraceMeLevel::kInfo);\n    device_->Compute(kernel_.get(), &context);\n  }\n\n  // Clean up execution op_execution_state if deferred ops aren't running.\n  if (op_execution_state != nullptr) {\n    op_execution_state->Unref();\n  }\n\n  if (!context.status().ok()) return context.status();\n\n  if (outputs != nullptr) {\n    outputs->clear();\n    for (int i = 0; i < context.num_outputs(); ++i) {\n      const auto* output_tensor = context.mutable_output(i);\n      if (output_tensor != nullptr) {\n        outputs->push_back(Tensor(*output_tensor));\n      } else {\n        outputs->push_back(Tensor());\n      }\n    }\n  }\n  return Status::OK();\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/da8558533d925694483d2c136a9220d6d49d843c", "file_name": "tensorflow/core/common_runtime/eager/kernel_and_device.cc", "vul_type": "cwe-476", "description": "Write a C++ function to execute a kernel operation with input arguments, output handling, and cancellation support."}
{"func_name": "check_client_passwd", "func_src_before": "static bool check_client_passwd(PgSocket *client, const char *passwd)\n{\n\tchar md5[MD5_PASSWD_LEN + 1];\n\tconst char *correct;\n\tPgUser *user = client->auth_user;\n\n\t/* disallow empty passwords */\n\tif (!*passwd || !*user->passwd)\n\t\treturn false;\n\n\tswitch (cf_auth_type) {\n\tcase AUTH_PLAIN:\n\t\treturn strcmp(user->passwd, passwd) == 0;\n\tcase AUTH_CRYPT:\n\t\tcorrect = crypt(user->passwd, (char *)client->tmp_login_salt);\n\t\treturn correct && strcmp(correct, passwd) == 0;\n\tcase AUTH_MD5:\n\t\tif (strlen(passwd) != MD5_PASSWD_LEN)\n\t\t\treturn false;\n\t\tif (!isMD5(user->passwd))\n\t\t\tpg_md5_encrypt(user->passwd, user->name, strlen(user->name), user->passwd);\n\t\tpg_md5_encrypt(user->passwd + 3, (char *)client->tmp_login_salt, 4, md5);\n\t\treturn strcmp(md5, passwd) == 0;\n\t}\n\treturn false;\n}", "func_src_after": "static bool check_client_passwd(PgSocket *client, const char *passwd)\n{\n\tchar md5[MD5_PASSWD_LEN + 1];\n\tconst char *correct;\n\tPgUser *user = client->auth_user;\n\n\t/* auth_user may be missing */\n\tif (!user) {\n\t\tslog_error(client, \"Password packet before auth packet?\");\n\t\treturn false;\n\t}\n\n\t/* disallow empty passwords */\n\tif (!*passwd || !*user->passwd)\n\t\treturn false;\n\n\tswitch (cf_auth_type) {\n\tcase AUTH_PLAIN:\n\t\treturn strcmp(user->passwd, passwd) == 0;\n\tcase AUTH_CRYPT:\n\t\tcorrect = crypt(user->passwd, (char *)client->tmp_login_salt);\n\t\treturn correct && strcmp(correct, passwd) == 0;\n\tcase AUTH_MD5:\n\t\tif (strlen(passwd) != MD5_PASSWD_LEN)\n\t\t\treturn false;\n\t\tif (!isMD5(user->passwd))\n\t\t\tpg_md5_encrypt(user->passwd, user->name, strlen(user->name), user->passwd);\n\t\tpg_md5_encrypt(user->passwd + 3, (char *)client->tmp_login_salt, 4, md5);\n\t\treturn strcmp(md5, passwd) == 0;\n\t}\n\treturn false;\n}", "commit_link": "github.com/pgbouncer/pgbouncer/commit/edab5be6665b9e8de66c25ba527509b229468573", "file_name": "src/client.c", "vul_type": "cwe-476", "description": "In C, write a function to validate a client's password using different authentication methods (plain, crypt, MD5)."}
{"func_name": "rds_tcp_kill_sock", "func_src_before": "static void rds_tcp_kill_sock(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tstruct sock *sk;\n\tLIST_HEAD(tmp_list);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_listen_stop(rtn->rds_tcp_listen_sock);\n\trtn->rds_tcp_listen_sock = NULL;\n\tflush_work(&rtn->rds_tcp_accept_w);\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->conn->c_net);\n\n\t\tif (net != c_net)\n\t\t\tcontinue;\n\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node) {\n\t\tsk = tc->t_sock->sk;\n\t\tsk->sk_prot->disconnect(sk, 0);\n\t\ttcp_done(sk);\n\t\tif (tc->conn->c_passive)\n\t\t\trds_conn_destroy(tc->conn->c_passive);\n\t\trds_conn_destroy(tc->conn);\n\t}\n}", "func_src_after": "static void rds_tcp_kill_sock(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tstruct sock *sk;\n\tLIST_HEAD(tmp_list);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_listen_stop(rtn->rds_tcp_listen_sock);\n\trtn->rds_tcp_listen_sock = NULL;\n\tflush_work(&rtn->rds_tcp_accept_w);\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->conn->c_net);\n\n\t\tif (net != c_net)\n\t\t\tcontinue;\n\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node) {\n\t\tif (tc->t_sock) {\n\t\t\tsk = tc->t_sock->sk;\n\t\t\tsk->sk_prot->disconnect(sk, 0);\n\t\t\ttcp_done(sk);\n\t\t}\n\t\tif (tc->conn->c_passive)\n\t\t\trds_conn_destroy(tc->conn->c_passive);\n\t\trds_conn_destroy(tc->conn);\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/91573ae4aed0a49660abdad4d42f2a0db995ee5e", "file_name": "net/rds/tcp.c", "vul_type": "cwe-476", "description": "Write a C function named `rds_tcp_kill_sock` that disconnects and cleans up TCP connections in a given network namespace."}
{"func_name": "ReadXCFImage", "func_src_before": "static Image *ReadXCFImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  char\n    magick[14];\n\n  Image\n    *image;\n\n  int\n    foundPropEnd = 0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  register ssize_t\n    i;\n\n  size_t\n    image_type,\n    length;\n\n  ssize_t\n    count;\n\n  XCFDocInfo\n    doc_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  count=ReadBlob(image,14,(unsigned char *) magick);\n  if ((count != 14) ||\n      (LocaleNCompare((char *) magick,\"gimp xcf\",8) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ResetMagickMemory(&doc_info,0,sizeof(XCFDocInfo));\n  doc_info.exception=exception;\n  doc_info.width=ReadBlobMSBLong(image);\n  doc_info.height=ReadBlobMSBLong(image);\n  if ((doc_info.width > 262144) || (doc_info.height > 262144))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  doc_info.image_type=ReadBlobMSBLong(image);\n  /*\n    Initialize image attributes.\n  */\n  image->columns=doc_info.width;\n  image->rows=doc_info.height;\n  image_type=doc_info.image_type;\n  doc_info.file_size=GetBlobSize(image);\n  image->compression=NoCompression;\n  image->depth=8;\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  if (image_type == GIMP_RGB)\n    ;\n  else\n    if (image_type == GIMP_GRAY)\n      image->colorspace=GRAYColorspace;\n    else\n      if (image_type == GIMP_INDEXED)\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n  (void) SetImageOpacity(image,OpaqueOpacity); \n  (void) SetImageBackgroundColor(image);\n  /*\n    Read properties.\n  */\n  while ((foundPropEnd == MagickFalse) && (EOFBlob(image) == MagickFalse))\n  {\n    PropType prop_type = (PropType) ReadBlobMSBLong(image);\n    size_t prop_size = ReadBlobMSBLong(image);\n\n    switch (prop_type)\n    {\n      case PROP_END:\n        foundPropEnd=1;\n        break;\n      case PROP_COLORMAP:\n      {\n        /* Cannot rely on prop_size here--the value is set incorrectly\n           by some Gimp versions.\n        */\n        size_t num_colours = ReadBlobMSBLong(image);\n        if (DiscardBlobBytes(image,3*num_colours) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n    /*\n      if (info->file_version == 0)\n      {\n        gint i;\n\n        g_message (_(\"XCF warning: version 0 of XCF file format\\n\"\n           \"did not save indexed colormaps correctly.\\n\"\n           \"Substituting grayscale map.\"));\n        info->cp +=\n          xcf_read_int32 (info->fp, (guint32*) &gimage->num_cols, 1);\n        gimage->cmap = g_new (guchar, gimage->num_cols*3);\n        xcf_seek_pos (info, info->cp + gimage->num_cols);\n        for (i = 0; i<gimage->num_cols; i++)\n          {\n            gimage->cmap[i*3+0] = i;\n            gimage->cmap[i*3+1] = i;\n            gimage->cmap[i*3+2] = i;\n          }\n      }\n      else\n      {\n        info->cp +=\n          xcf_read_int32 (info->fp, (guint32*) &gimage->num_cols, 1);\n        gimage->cmap = g_new (guchar, gimage->num_cols*3);\n        info->cp +=\n          xcf_read_int8 (info->fp,\n                   (guint8*) gimage->cmap, gimage->num_cols*3);\n      }\n     */\n        break;\n      }\n      case PROP_COMPRESSION:\n      {\n        doc_info.compression = ReadBlobByte(image);\n        if ((doc_info.compression != COMPRESS_NONE) &&\n            (doc_info.compression != COMPRESS_RLE) &&\n            (doc_info.compression != COMPRESS_ZLIB) &&\n            (doc_info.compression != COMPRESS_FRACTAL))\n          ThrowReaderException(CorruptImageError,\"UnrecognizedImageCompression\");\n      }\n      break;\n\n      case PROP_GUIDES:\n      {\n         /* just skip it - we don't care about guides */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n      }\n      break;\n\n    case PROP_RESOLUTION:\n      {\n        /* float xres = (float) */ (void) ReadBlobMSBLong(image);\n        /* float yres = (float) */ (void) ReadBlobMSBLong(image);\n\n        /*\n        if (xres < GIMP_MIN_RESOLUTION || xres > GIMP_MAX_RESOLUTION ||\n            yres < GIMP_MIN_RESOLUTION || yres > GIMP_MAX_RESOLUTION)\n        {\n        g_message (\"Warning, resolution out of range in XCF file\");\n        xres = gimage->gimp->config->default_xresolution;\n        yres = gimage->gimp->config->default_yresolution;\n        }\n        */\n\n\n        /* BOGUS: we don't write these yet because we aren't\n              reading them properly yet :(\n              image->x_resolution = xres;\n              image->y_resolution = yres;\n        */\n      }\n      break;\n\n    case PROP_TATTOO:\n      {\n        /* we need to read it, even if we ignore it */\n        /*size_t  tattoo_state = */ (void) ReadBlobMSBLong(image);\n      }\n      break;\n\n    case PROP_PARASITES:\n      {\n        /* BOGUS: we may need these for IPTC stuff */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n        /*\n      gssize_t         base = info->cp;\n      GimpParasite *p;\n\n      while (info->cp - base < prop_size)\n        {\n          p = xcf_load_parasite (info);\n          gimp_image_parasite_attach (gimage, p);\n          gimp_parasite_free (p);\n        }\n      if (info->cp - base != prop_size)\n        g_message (\"Error detected while loading an image's parasites\");\n      */\n          }\n      break;\n\n    case PROP_UNIT:\n      {\n        /* BOGUS: ignore for now... */\n      /*size_t unit =  */ (void) ReadBlobMSBLong(image);\n      }\n      break;\n\n    case PROP_PATHS:\n      {\n      /* BOGUS: just skip it for now */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n\n        /*\n      PathList *paths = xcf_load_bzpaths (gimage, info);\n      gimp_image_set_paths (gimage, paths);\n      */\n      }\n      break;\n\n    case PROP_USER_UNIT:\n      {\n        char  unit_string[1000];\n        /*BOGUS: ignored for now */\n        /*float  factor = (float) */ (void) ReadBlobMSBLong(image);\n        /* size_t digits =  */ (void) ReadBlobMSBLong(image);\n        for (i=0; i<5; i++)\n         (void) ReadBlobStringWithLongSize(image, unit_string,\n           sizeof(unit_string));\n      }\n     break;\n\n      default:\n      {\n        int buf[16];\n        ssize_t amount;\n\n      /* read over it... */\n      while ((prop_size > 0) && (EOFBlob(image) == MagickFalse))\n      {\n        amount=(ssize_t) MagickMin(16, prop_size);\n        amount=(ssize_t) ReadBlob(image,(size_t) amount,(unsigned char *) &buf);\n        if (!amount)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n        prop_size -= (size_t) MagickMin(16,(size_t) amount);\n      }\n    }\n    break;\n  }\n  }\n  if (foundPropEnd == MagickFalse)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n    {\n      ; /* do nothing, were just pinging! */\n    }\n  else\n    {\n      int\n        current_layer = 0,\n        foundAllLayers = MagickFalse,\n        number_layers = 0;\n\n      MagickOffsetType\n        oldPos=TellBlob(image);\n\n      XCFLayerInfo\n        *layer_info;\n\n      /*\n        The read pointer.\n      */\n      do\n      {\n        ssize_t offset = ReadBlobMSBSignedLong(image);\n        if (offset == 0)\n          foundAllLayers=MagickTrue;\n        else\n          number_layers++;\n        if (EOFBlob(image) != MagickFalse)\n          {\n            ThrowFileException(exception,CorruptImageError,\n              \"UnexpectedEndOfFile\",image->filename);\n            break;\n          }\n    } while (foundAllLayers == MagickFalse);\n    doc_info.number_layers=number_layers;\n    offset=SeekBlob(image,oldPos,SEEK_SET); /* restore the position! */\n    if (offset < 0)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    /* allocate our array of layer info blocks */\n    length=(size_t) number_layers;\n    layer_info=(XCFLayerInfo *) AcquireQuantumMemory(length,\n      sizeof(*layer_info));\n    if (layer_info == (XCFLayerInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(layer_info,0,number_layers*sizeof(XCFLayerInfo));\n    for ( ; ; )\n    {\n      MagickBooleanType\n        layer_ok;\n\n      MagickOffsetType\n        offset,\n        saved_pos;\n\n      /* read in the offset of the next layer */\n      offset=(MagickOffsetType) ReadBlobMSBLong(image);\n      /* if the offset is 0 then we are at the end\n      *  of the layer list.\n      */\n      if (offset == 0)\n        break;\n      /* save the current position as it is where the\n      *  next layer offset is stored.\n      */\n      saved_pos=TellBlob(image);\n      /* seek to the layer offset */\n      if (SeekBlob(image,offset,SEEK_SET) != offset)\n        ThrowReaderException(ResourceLimitError,\"NotEnoughPixelData\");\n      /* read in the layer */\n      layer_ok=ReadOneLayer(image_info,image,&doc_info,\n        &layer_info[current_layer],current_layer);\n      if (layer_ok == MagickFalse)\n        {\n          int j;\n\n          for (j=0; j < current_layer; j++)\n            layer_info[j].image=DestroyImage(layer_info[j].image);\n          layer_info=(XCFLayerInfo *) RelinquishMagickMemory(layer_info);\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        }\n      /* restore the saved position so we'll be ready to\n      *  read the next offset.\n      */\n      offset=SeekBlob(image, saved_pos, SEEK_SET);\n      current_layer++;\n    }\n#if 0\n        {\n        /* NOTE: XCF layers are REVERSED from composite order! */\n        signed int  j;\n        for (j=number_layers-1; j>=0; j--) {\n          /* BOGUS: need to consider layer blending modes!! */\n\n          if ( layer_info[j].visible ) { /* only visible ones, please! */\n            CompositeImage(image, OverCompositeOp, layer_info[j].image,\n                     layer_info[j].offset_x, layer_info[j].offset_y );\n             layer_info[j].image =DestroyImage( layer_info[j].image );\n\n            /* If we do this, we'll get REAL gray images! */\n            if ( image_type == GIMP_GRAY ) {\n              QuantizeInfo  qi;\n              GetQuantizeInfo(&qi);\n              qi.colorspace = GRAYColorspace;\n              QuantizeImage( &qi, layer_info[j].image );\n            }\n          }\n        }\n      }\n#else\n      {\n        /* NOTE: XCF layers are REVERSED from composite order! */\n        ssize_t  j;\n\n        /* now reverse the order of the layers as they are put\n           into subimages\n        */\n        for (j=(long) number_layers-1; j >= 0; j--)\n          AppendImageToList(&image,layer_info[j].image);\n      }\n#endif\n\n    layer_info=(XCFLayerInfo *) RelinquishMagickMemory(layer_info);\n\n#if 0  /* BOGUS: do we need the channels?? */\n    while (MagickTrue)\n    {\n      /* read in the offset of the next channel */\n      info->cp += xcf_read_int32 (info->fp, &offset, 1);\n\n      /* if the offset is 0 then we are at the end\n      *  of the channel list.\n      */\n      if (offset == 0)\n        break;\n\n      /* save the current position as it is where the\n      *  next channel offset is stored.\n      */\n      saved_pos = info->cp;\n\n      /* seek to the channel offset */\n      xcf_seek_pos (info, offset);\n\n      /* read in the layer */\n      channel = xcf_load_channel (info, gimage);\n      if (channel == 0)\n        goto error;\n\n      num_successful_elements++;\n\n      /* add the channel to the image if its not the selection */\n      if (channel != gimage->selection_mask)\n        gimp_image_add_channel (gimage, channel, -1);\n\n      /* restore the saved position so we'll be ready to\n      *  read the next offset.\n      */\n      xcf_seek_pos (info, saved_pos);\n    }\n#endif\n  }\n\n  (void) CloseBlob(image);\n  DestroyImage(RemoveFirstImageFromList(&image));\n  if (image_type == GIMP_GRAY)\n    image->type=GrayscaleType;\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadXCFImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  char\n    magick[14];\n\n  Image\n    *image;\n\n  int\n    foundPropEnd = 0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  register ssize_t\n    i;\n\n  size_t\n    image_type,\n    length;\n\n  ssize_t\n    count;\n\n  XCFDocInfo\n    doc_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  count=ReadBlob(image,14,(unsigned char *) magick);\n  if ((count != 14) ||\n      (LocaleNCompare((char *) magick,\"gimp xcf\",8) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ResetMagickMemory(&doc_info,0,sizeof(XCFDocInfo));\n  doc_info.exception=exception;\n  doc_info.width=ReadBlobMSBLong(image);\n  doc_info.height=ReadBlobMSBLong(image);\n  if ((doc_info.width > 262144) || (doc_info.height > 262144))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  doc_info.image_type=ReadBlobMSBLong(image);\n  /*\n    Initialize image attributes.\n  */\n  image->columns=doc_info.width;\n  image->rows=doc_info.height;\n  image_type=doc_info.image_type;\n  doc_info.file_size=GetBlobSize(image);\n  image->compression=NoCompression;\n  image->depth=8;\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  if (image_type == GIMP_RGB)\n    ;\n  else\n    if (image_type == GIMP_GRAY)\n      image->colorspace=GRAYColorspace;\n    else\n      if (image_type == GIMP_INDEXED)\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n  (void) SetImageOpacity(image,OpaqueOpacity); \n  (void) SetImageBackgroundColor(image);\n  /*\n    Read properties.\n  */\n  while ((foundPropEnd == MagickFalse) && (EOFBlob(image) == MagickFalse))\n  {\n    PropType prop_type = (PropType) ReadBlobMSBLong(image);\n    size_t prop_size = ReadBlobMSBLong(image);\n\n    switch (prop_type)\n    {\n      case PROP_END:\n        foundPropEnd=1;\n        break;\n      case PROP_COLORMAP:\n      {\n        /* Cannot rely on prop_size here--the value is set incorrectly\n           by some Gimp versions.\n        */\n        size_t num_colours = ReadBlobMSBLong(image);\n        if (DiscardBlobBytes(image,3*num_colours) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n    /*\n      if (info->file_version == 0)\n      {\n        gint i;\n\n        g_message (_(\"XCF warning: version 0 of XCF file format\\n\"\n           \"did not save indexed colormaps correctly.\\n\"\n           \"Substituting grayscale map.\"));\n        info->cp +=\n          xcf_read_int32 (info->fp, (guint32*) &gimage->num_cols, 1);\n        gimage->cmap = g_new (guchar, gimage->num_cols*3);\n        xcf_seek_pos (info, info->cp + gimage->num_cols);\n        for (i = 0; i<gimage->num_cols; i++)\n          {\n            gimage->cmap[i*3+0] = i;\n            gimage->cmap[i*3+1] = i;\n            gimage->cmap[i*3+2] = i;\n          }\n      }\n      else\n      {\n        info->cp +=\n          xcf_read_int32 (info->fp, (guint32*) &gimage->num_cols, 1);\n        gimage->cmap = g_new (guchar, gimage->num_cols*3);\n        info->cp +=\n          xcf_read_int8 (info->fp,\n                   (guint8*) gimage->cmap, gimage->num_cols*3);\n      }\n     */\n        break;\n      }\n      case PROP_COMPRESSION:\n      {\n        doc_info.compression = ReadBlobByte(image);\n        if ((doc_info.compression != COMPRESS_NONE) &&\n            (doc_info.compression != COMPRESS_RLE) &&\n            (doc_info.compression != COMPRESS_ZLIB) &&\n            (doc_info.compression != COMPRESS_FRACTAL))\n          ThrowReaderException(CorruptImageError,\"UnrecognizedImageCompression\");\n      }\n      break;\n\n      case PROP_GUIDES:\n      {\n         /* just skip it - we don't care about guides */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n      }\n      break;\n\n    case PROP_RESOLUTION:\n      {\n        /* float xres = (float) */ (void) ReadBlobMSBLong(image);\n        /* float yres = (float) */ (void) ReadBlobMSBLong(image);\n\n        /*\n        if (xres < GIMP_MIN_RESOLUTION || xres > GIMP_MAX_RESOLUTION ||\n            yres < GIMP_MIN_RESOLUTION || yres > GIMP_MAX_RESOLUTION)\n        {\n        g_message (\"Warning, resolution out of range in XCF file\");\n        xres = gimage->gimp->config->default_xresolution;\n        yres = gimage->gimp->config->default_yresolution;\n        }\n        */\n\n\n        /* BOGUS: we don't write these yet because we aren't\n              reading them properly yet :(\n              image->x_resolution = xres;\n              image->y_resolution = yres;\n        */\n      }\n      break;\n\n    case PROP_TATTOO:\n      {\n        /* we need to read it, even if we ignore it */\n        /*size_t  tattoo_state = */ (void) ReadBlobMSBLong(image);\n      }\n      break;\n\n    case PROP_PARASITES:\n      {\n        /* BOGUS: we may need these for IPTC stuff */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n        /*\n      gssize_t         base = info->cp;\n      GimpParasite *p;\n\n      while (info->cp - base < prop_size)\n        {\n          p = xcf_load_parasite (info);\n          gimp_image_parasite_attach (gimage, p);\n          gimp_parasite_free (p);\n        }\n      if (info->cp - base != prop_size)\n        g_message (\"Error detected while loading an image's parasites\");\n      */\n          }\n      break;\n\n    case PROP_UNIT:\n      {\n        /* BOGUS: ignore for now... */\n      /*size_t unit =  */ (void) ReadBlobMSBLong(image);\n      }\n      break;\n\n    case PROP_PATHS:\n      {\n      /* BOGUS: just skip it for now */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n\n        /*\n      PathList *paths = xcf_load_bzpaths (gimage, info);\n      gimp_image_set_paths (gimage, paths);\n      */\n      }\n      break;\n\n    case PROP_USER_UNIT:\n      {\n        char  unit_string[1000];\n        /*BOGUS: ignored for now */\n        /*float  factor = (float) */ (void) ReadBlobMSBLong(image);\n        /* size_t digits =  */ (void) ReadBlobMSBLong(image);\n        for (i=0; i<5; i++)\n         (void) ReadBlobStringWithLongSize(image, unit_string,\n           sizeof(unit_string));\n      }\n     break;\n\n      default:\n      {\n        int buf[16];\n        ssize_t amount;\n\n      /* read over it... */\n      while ((prop_size > 0) && (EOFBlob(image) == MagickFalse))\n      {\n        amount=(ssize_t) MagickMin(16, prop_size);\n        amount=(ssize_t) ReadBlob(image,(size_t) amount,(unsigned char *) &buf);\n        if (!amount)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n        prop_size -= (size_t) MagickMin(16,(size_t) amount);\n      }\n    }\n    break;\n  }\n  }\n  if (foundPropEnd == MagickFalse)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n    {\n      ; /* do nothing, were just pinging! */\n    }\n  else\n    {\n      int\n        current_layer = 0,\n        foundAllLayers = MagickFalse,\n        number_layers = 0;\n\n      MagickOffsetType\n        oldPos=TellBlob(image);\n\n      XCFLayerInfo\n        *layer_info;\n\n      /*\n        The read pointer.\n      */\n      do\n      {\n        ssize_t offset = ReadBlobMSBSignedLong(image);\n        if (offset == 0)\n          foundAllLayers=MagickTrue;\n        else\n          number_layers++;\n        if (EOFBlob(image) != MagickFalse)\n          {\n            ThrowFileException(exception,CorruptImageError,\n              \"UnexpectedEndOfFile\",image->filename);\n            break;\n          }\n    } while (foundAllLayers == MagickFalse);\n    doc_info.number_layers=number_layers;\n    offset=SeekBlob(image,oldPos,SEEK_SET); /* restore the position! */\n    if (offset < 0)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    /* allocate our array of layer info blocks */\n    length=(size_t) number_layers;\n    layer_info=(XCFLayerInfo *) AcquireQuantumMemory(length,\n      sizeof(*layer_info));\n    if (layer_info == (XCFLayerInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(layer_info,0,number_layers*sizeof(XCFLayerInfo));\n    for ( ; ; )\n    {\n      MagickBooleanType\n        layer_ok;\n\n      MagickOffsetType\n        offset,\n        saved_pos;\n\n      /* read in the offset of the next layer */\n      offset=(MagickOffsetType) ReadBlobMSBLong(image);\n      /* if the offset is 0 then we are at the end\n      *  of the layer list.\n      */\n      if (offset == 0)\n        break;\n      /* save the current position as it is where the\n      *  next layer offset is stored.\n      */\n      saved_pos=TellBlob(image);\n      /* seek to the layer offset */\n      if (SeekBlob(image,offset,SEEK_SET) != offset)\n        ThrowReaderException(ResourceLimitError,\"NotEnoughPixelData\");\n      /* read in the layer */\n      layer_ok=ReadOneLayer(image_info,image,&doc_info,\n        &layer_info[current_layer],current_layer);\n      if (layer_ok == MagickFalse)\n        {\n          int j;\n\n          for (j=0; j < current_layer; j++)\n            layer_info[j].image=DestroyImage(layer_info[j].image);\n          layer_info=(XCFLayerInfo *) RelinquishMagickMemory(layer_info);\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        }\n      /* restore the saved position so we'll be ready to\n      *  read the next offset.\n      */\n      offset=SeekBlob(image, saved_pos, SEEK_SET);\n      current_layer++;\n    }\n#if 0\n        {\n        /* NOTE: XCF layers are REVERSED from composite order! */\n        signed int  j;\n        for (j=number_layers-1; j>=0; j--) {\n          /* BOGUS: need to consider layer blending modes!! */\n\n          if ( layer_info[j].visible ) { /* only visible ones, please! */\n            CompositeImage(image, OverCompositeOp, layer_info[j].image,\n                     layer_info[j].offset_x, layer_info[j].offset_y );\n             layer_info[j].image =DestroyImage( layer_info[j].image );\n\n            /* If we do this, we'll get REAL gray images! */\n            if ( image_type == GIMP_GRAY ) {\n              QuantizeInfo  qi;\n              GetQuantizeInfo(&qi);\n              qi.colorspace = GRAYColorspace;\n              QuantizeImage( &qi, layer_info[j].image );\n            }\n          }\n        }\n      }\n#else\n      {\n        /* NOTE: XCF layers are REVERSED from composite order! */\n        ssize_t  j;\n\n        /* now reverse the order of the layers as they are put\n           into subimages\n        */\n        for (j=(long) number_layers-1; j >= 0; j--)\n          AppendImageToList(&image,layer_info[j].image);\n      }\n#endif\n\n    layer_info=(XCFLayerInfo *) RelinquishMagickMemory(layer_info);\n\n#if 0  /* BOGUS: do we need the channels?? */\n    while (MagickTrue)\n    {\n      /* read in the offset of the next channel */\n      info->cp += xcf_read_int32 (info->fp, &offset, 1);\n\n      /* if the offset is 0 then we are at the end\n      *  of the channel list.\n      */\n      if (offset == 0)\n        break;\n\n      /* save the current position as it is where the\n      *  next channel offset is stored.\n      */\n      saved_pos = info->cp;\n\n      /* seek to the channel offset */\n      xcf_seek_pos (info, offset);\n\n      /* read in the layer */\n      channel = xcf_load_channel (info, gimage);\n      if (channel == 0)\n        goto error;\n\n      num_successful_elements++;\n\n      /* add the channel to the image if its not the selection */\n      if (channel != gimage->selection_mask)\n        gimp_image_add_channel (gimage, channel, -1);\n\n      /* restore the saved position so we'll be ready to\n      *  read the next offset.\n      */\n      xcf_seek_pos (info, saved_pos);\n    }\n#endif\n  }\n\n  (void) CloseBlob(image);\n  if (GetNextImageInList(image) != (Image *) NULL)\n    DestroyImage(RemoveFirstImageFromList(&image));\n  if (image_type == GIMP_GRAY)\n    image->type=GrayscaleType;\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/d31fec57e9dfb0516deead2053a856e3c71e9751", "file_name": "coders/xcf.c", "vul_type": "cwe-476", "description": "Write a function in C to read and process XCF image files."}
{"func_name": "CopyKeyAliasesToKeymap", "func_src_before": "CopyKeyAliasesToKeymap(struct xkb_keymap *keymap, KeyNamesInfo *info)\n{\n    AliasInfo *alias;\n    unsigned i, num_key_aliases;\n    struct xkb_key_alias *key_aliases;\n\n    /*\n     * Do some sanity checking on the aliases. We can't do it before\n     * because keys and their aliases may be added out-of-order.\n     */\n    num_key_aliases = 0;\n    darray_foreach(alias, info->aliases) {\n        /* Check that ->real is a key. */\n        if (!XkbKeyByName(keymap, alias->real, false)) {\n            log_vrb(info->ctx, 5,\n                    \"Attempt to alias %s to non-existent key %s; Ignored\\n\",\n                    KeyNameText(info->ctx, alias->alias),\n                    KeyNameText(info->ctx, alias->real));\n            alias->real = XKB_ATOM_NONE;\n            continue;\n        }\n\n        /* Check that ->alias is not a key. */\n        if (XkbKeyByName(keymap, alias->alias, false)) {\n            log_vrb(info->ctx, 5,\n                    \"Attempt to create alias with the name of a real key; \"\n                    \"Alias \\\"%s = %s\\\" ignored\\n\",\n                    KeyNameText(info->ctx, alias->alias),\n                    KeyNameText(info->ctx, alias->real));\n            alias->real = XKB_ATOM_NONE;\n            continue;\n        }\n\n        num_key_aliases++;\n    }\n\n    /* Copy key aliases. */\n    key_aliases = NULL;\n    if (num_key_aliases > 0) {\n        key_aliases = calloc(num_key_aliases, sizeof(*key_aliases));\n        if (!key_aliases)\n            return false;\n    }\n\n    i = 0;\n    darray_foreach(alias, info->aliases) {\n        if (alias->real != XKB_ATOM_NONE) {\n            key_aliases[i].alias = alias->alias;\n            key_aliases[i].real = alias->real;\n            i++;\n        }\n    }\n\n    keymap->num_key_aliases = num_key_aliases;\n    keymap->key_aliases = key_aliases;\n    return true;\n}", "func_src_after": "CopyKeyAliasesToKeymap(struct xkb_keymap *keymap, KeyNamesInfo *info)\n{\n    AliasInfo *alias;\n    unsigned i, num_key_aliases;\n    struct xkb_key_alias *key_aliases;\n\n    /*\n     * Do some sanity checking on the aliases. We can't do it before\n     * because keys and their aliases may be added out-of-order.\n     */\n    num_key_aliases = 0;\n    darray_foreach(alias, info->aliases) {\n        /* Check that ->real is a key. */\n        if (!XkbKeyByName(keymap, alias->real, false)) {\n            log_vrb(info->ctx, 5,\n                    \"Attempt to alias %s to non-existent key %s; Ignored\\n\",\n                    KeyNameText(info->ctx, alias->alias),\n                    KeyNameText(info->ctx, alias->real));\n            alias->real = XKB_ATOM_NONE;\n            continue;\n        }\n\n        /* Check that ->alias is not a key. */\n        if (XkbKeyByName(keymap, alias->alias, false)) {\n            log_vrb(info->ctx, 5,\n                    \"Attempt to create alias with the name of a real key; \"\n                    \"Alias \\\"%s = %s\\\" ignored\\n\",\n                    KeyNameText(info->ctx, alias->alias),\n                    KeyNameText(info->ctx, alias->real));\n            alias->real = XKB_ATOM_NONE;\n            continue;\n        }\n\n        num_key_aliases++;\n    }\n\n    /* Copy key aliases. */\n    key_aliases = NULL;\n    if (num_key_aliases > 0) {\n        key_aliases = calloc(num_key_aliases, sizeof(*key_aliases));\n        if (!key_aliases)\n            return false;\n\n        i = 0;\n        darray_foreach(alias, info->aliases) {\n            if (alias->real != XKB_ATOM_NONE) {\n                key_aliases[i].alias = alias->alias;\n                key_aliases[i].real = alias->real;\n                i++;\n            }\n        }\n    }\n\n    keymap->num_key_aliases = num_key_aliases;\n    keymap->key_aliases = key_aliases;\n    return true;\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/badb428e63387140720f22486b3acbd3d738859f", "file_name": "src/xkbcomp/keycodes.c", "vul_type": "cwe-476", "description": "Write a C function to validate and copy key aliases into a keymap structure."}
{"func_name": "tensorflow::GetSessionHandleOp::Compute", "func_src_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& val = ctx->input(0);\n    int64 id = ctx->session_state()->GetNewId();\n    TensorStore::TensorAndKey tk{val, id, requested_device()};\n    OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n\n    Tensor* handle = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &handle));\n    if (ctx->expected_output_dtype(0) == DT_RESOURCE) {\n      ResourceHandle resource_handle = MakeResourceHandle<Tensor>(\n          ctx, SessionState::kTensorHandleResourceTypeName,\n          tk.GetHandle(name()));\n      resource_handle.set_maybe_type_name(\n          SessionState::kTensorHandleResourceTypeName);\n      handle->scalar<ResourceHandle>()() = resource_handle;\n    } else {\n      // Legacy behavior in V1.\n      handle->flat<tstring>().setConstant(tk.GetHandle(name()));\n    }\n  }", "func_src_after": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& val = ctx->input(0);\n    auto session_state = ctx->session_state();\n    OP_REQUIRES(ctx, session_state != nullptr,\n                errors::FailedPrecondition(\n                    \"GetSessionHandle called on null session state\"));\n    int64 id = session_state->GetNewId();\n    TensorStore::TensorAndKey tk{val, id, requested_device()};\n    OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n\n    Tensor* handle = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &handle));\n    if (ctx->expected_output_dtype(0) == DT_RESOURCE) {\n      ResourceHandle resource_handle = MakeResourceHandle<Tensor>(\n          ctx, SessionState::kTensorHandleResourceTypeName,\n          tk.GetHandle(name()));\n      resource_handle.set_maybe_type_name(\n          SessionState::kTensorHandleResourceTypeName);\n      handle->scalar<ResourceHandle>()() = resource_handle;\n    } else {\n      // Legacy behavior in V1.\n      handle->flat<tstring>().setConstant(tk.GetHandle(name()));\n    }\n  }", "commit_link": "github.com/tensorflow/tensorflow/commit/9a133d73ae4b4664d22bd1aa6d654fec13c52ee1", "file_name": "tensorflow/core/kernels/session_ops.cc", "vul_type": "cwe-476", "description": "Write a C++ function to store a tensor and return a handle to it, handling both V2 and legacy V1 behaviors."}
{"func_name": "tun_set_iff", "func_src_before": "static int tun_set_iff(struct net *net, struct file *file, struct ifreq *ifr)\n{\n\tstruct tun_struct *tun;\n\tstruct tun_file *tfile = file->private_data;\n\tstruct net_device *dev;\n\tint err;\n\n\tif (tfile->detached)\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_name(net, ifr->ifr_name);\n\tif (dev) {\n\t\tif (ifr->ifr_flags & IFF_TUN_EXCL)\n\t\t\treturn -EBUSY;\n\t\tif ((ifr->ifr_flags & IFF_TUN) && dev->netdev_ops == &tun_netdev_ops)\n\t\t\ttun = netdev_priv(dev);\n\t\telse if ((ifr->ifr_flags & IFF_TAP) && dev->netdev_ops == &tap_netdev_ops)\n\t\t\ttun = netdev_priv(dev);\n\t\telse\n\t\t\treturn -EINVAL;\n\n\t\tif (!!(ifr->ifr_flags & IFF_MULTI_QUEUE) !=\n\t\t    !!(tun->flags & IFF_MULTI_QUEUE))\n\t\t\treturn -EINVAL;\n\n\t\tif (tun_not_capable(tun))\n\t\t\treturn -EPERM;\n\t\terr = security_tun_dev_open(tun->security);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = tun_attach(tun, file, ifr->ifr_flags & IFF_NOFILTER);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (tun->flags & IFF_MULTI_QUEUE &&\n\t\t    (tun->numqueues + tun->numdisabled > 1)) {\n\t\t\t/* One or more queue has already been attached, no need\n\t\t\t * to initialize the device again.\n\t\t\t */\n\t\t\treturn 0;\n\t\t}\n\t}\n\telse {\n\t\tchar *name;\n\t\tunsigned long flags = 0;\n\t\tint queues = ifr->ifr_flags & IFF_MULTI_QUEUE ?\n\t\t\t     MAX_TAP_QUEUES : 1;\n\n\t\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\n\t\t\treturn -EPERM;\n\t\terr = security_tun_dev_create();\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\t/* Set dev type */\n\t\tif (ifr->ifr_flags & IFF_TUN) {\n\t\t\t/* TUN device */\n\t\t\tflags |= IFF_TUN;\n\t\t\tname = \"tun%d\";\n\t\t} else if (ifr->ifr_flags & IFF_TAP) {\n\t\t\t/* TAP device */\n\t\t\tflags |= IFF_TAP;\n\t\t\tname = \"tap%d\";\n\t\t} else\n\t\t\treturn -EINVAL;\n\n\t\tif (*ifr->ifr_name)\n\t\t\tname = ifr->ifr_name;\n\n\t\tdev = alloc_netdev_mqs(sizeof(struct tun_struct), name,\n\t\t\t\t       NET_NAME_UNKNOWN, tun_setup, queues,\n\t\t\t\t       queues);\n\n\t\tif (!dev)\n\t\t\treturn -ENOMEM;\n\t\terr = dev_get_valid_name(net, dev, name);\n\t\tif (err)\n\t\t\tgoto err_free_dev;\n\n\t\tdev_net_set(dev, net);\n\t\tdev->rtnl_link_ops = &tun_link_ops;\n\t\tdev->ifindex = tfile->ifindex;\n\t\tdev->sysfs_groups[0] = &tun_attr_group;\n\n\t\ttun = netdev_priv(dev);\n\t\ttun->dev = dev;\n\t\ttun->flags = flags;\n\t\ttun->txflt.count = 0;\n\t\ttun->vnet_hdr_sz = sizeof(struct virtio_net_hdr);\n\n\t\ttun->align = NET_SKB_PAD;\n\t\ttun->filter_attached = false;\n\t\ttun->sndbuf = tfile->socket.sk->sk_sndbuf;\n\t\ttun->rx_batched = 0;\n\n\t\ttun->pcpu_stats = netdev_alloc_pcpu_stats(struct tun_pcpu_stats);\n\t\tif (!tun->pcpu_stats) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_free_dev;\n\t\t}\n\n\t\tspin_lock_init(&tun->lock);\n\n\t\terr = security_tun_dev_alloc_security(&tun->security);\n\t\tif (err < 0)\n\t\t\tgoto err_free_stat;\n\n\t\ttun_net_init(dev);\n\t\ttun_flow_init(tun);\n\n\t\tdev->hw_features = NETIF_F_SG | NETIF_F_FRAGLIST |\n\t\t\t\t   TUN_USER_FEATURES | NETIF_F_HW_VLAN_CTAG_TX |\n\t\t\t\t   NETIF_F_HW_VLAN_STAG_TX;\n\t\tdev->features = dev->hw_features | NETIF_F_LLTX;\n\t\tdev->vlan_features = dev->features &\n\t\t\t\t     ~(NETIF_F_HW_VLAN_CTAG_TX |\n\t\t\t\t       NETIF_F_HW_VLAN_STAG_TX);\n\n\t\tINIT_LIST_HEAD(&tun->disabled);\n\t\terr = tun_attach(tun, file, false);\n\t\tif (err < 0)\n\t\t\tgoto err_free_flow;\n\n\t\terr = register_netdevice(tun->dev);\n\t\tif (err < 0)\n\t\t\tgoto err_detach;\n\t}\n\n\tnetif_carrier_on(tun->dev);\n\n\ttun_debug(KERN_INFO, tun, \"tun_set_iff\\n\");\n\n\ttun->flags = (tun->flags & ~TUN_FEATURES) |\n\t\t(ifr->ifr_flags & TUN_FEATURES);\n\n\t/* Make sure persistent devices do not get stuck in\n\t * xoff state.\n\t */\n\tif (netif_running(tun->dev))\n\t\tnetif_tx_wake_all_queues(tun->dev);\n\n\tstrcpy(ifr->ifr_name, tun->dev->name);\n\treturn 0;\n\nerr_detach:\n\ttun_detach_all(dev);\n\t/* register_netdevice() already called tun_free_netdev() */\n\tgoto err_free_dev;\n\nerr_free_flow:\n\ttun_flow_uninit(tun);\n\tsecurity_tun_dev_free_security(tun->security);\nerr_free_stat:\n\tfree_percpu(tun->pcpu_stats);\nerr_free_dev:\n\tfree_netdev(dev);\n\treturn err;\n}", "func_src_after": "static int tun_set_iff(struct net *net, struct file *file, struct ifreq *ifr)\n{\n\tstruct tun_struct *tun;\n\tstruct tun_file *tfile = file->private_data;\n\tstruct net_device *dev;\n\tint err;\n\n\tif (tfile->detached)\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_name(net, ifr->ifr_name);\n\tif (dev) {\n\t\tif (ifr->ifr_flags & IFF_TUN_EXCL)\n\t\t\treturn -EBUSY;\n\t\tif ((ifr->ifr_flags & IFF_TUN) && dev->netdev_ops == &tun_netdev_ops)\n\t\t\ttun = netdev_priv(dev);\n\t\telse if ((ifr->ifr_flags & IFF_TAP) && dev->netdev_ops == &tap_netdev_ops)\n\t\t\ttun = netdev_priv(dev);\n\t\telse\n\t\t\treturn -EINVAL;\n\n\t\tif (!!(ifr->ifr_flags & IFF_MULTI_QUEUE) !=\n\t\t    !!(tun->flags & IFF_MULTI_QUEUE))\n\t\t\treturn -EINVAL;\n\n\t\tif (tun_not_capable(tun))\n\t\t\treturn -EPERM;\n\t\terr = security_tun_dev_open(tun->security);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = tun_attach(tun, file, ifr->ifr_flags & IFF_NOFILTER);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (tun->flags & IFF_MULTI_QUEUE &&\n\t\t    (tun->numqueues + tun->numdisabled > 1)) {\n\t\t\t/* One or more queue has already been attached, no need\n\t\t\t * to initialize the device again.\n\t\t\t */\n\t\t\treturn 0;\n\t\t}\n\t}\n\telse {\n\t\tchar *name;\n\t\tunsigned long flags = 0;\n\t\tint queues = ifr->ifr_flags & IFF_MULTI_QUEUE ?\n\t\t\t     MAX_TAP_QUEUES : 1;\n\n\t\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\n\t\t\treturn -EPERM;\n\t\terr = security_tun_dev_create();\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\t/* Set dev type */\n\t\tif (ifr->ifr_flags & IFF_TUN) {\n\t\t\t/* TUN device */\n\t\t\tflags |= IFF_TUN;\n\t\t\tname = \"tun%d\";\n\t\t} else if (ifr->ifr_flags & IFF_TAP) {\n\t\t\t/* TAP device */\n\t\t\tflags |= IFF_TAP;\n\t\t\tname = \"tap%d\";\n\t\t} else\n\t\t\treturn -EINVAL;\n\n\t\tif (*ifr->ifr_name)\n\t\t\tname = ifr->ifr_name;\n\n\t\tdev = alloc_netdev_mqs(sizeof(struct tun_struct), name,\n\t\t\t\t       NET_NAME_UNKNOWN, tun_setup, queues,\n\t\t\t\t       queues);\n\n\t\tif (!dev)\n\t\t\treturn -ENOMEM;\n\t\terr = dev_get_valid_name(net, dev, name);\n\t\tif (err < 0)\n\t\t\tgoto err_free_dev;\n\n\t\tdev_net_set(dev, net);\n\t\tdev->rtnl_link_ops = &tun_link_ops;\n\t\tdev->ifindex = tfile->ifindex;\n\t\tdev->sysfs_groups[0] = &tun_attr_group;\n\n\t\ttun = netdev_priv(dev);\n\t\ttun->dev = dev;\n\t\ttun->flags = flags;\n\t\ttun->txflt.count = 0;\n\t\ttun->vnet_hdr_sz = sizeof(struct virtio_net_hdr);\n\n\t\ttun->align = NET_SKB_PAD;\n\t\ttun->filter_attached = false;\n\t\ttun->sndbuf = tfile->socket.sk->sk_sndbuf;\n\t\ttun->rx_batched = 0;\n\n\t\ttun->pcpu_stats = netdev_alloc_pcpu_stats(struct tun_pcpu_stats);\n\t\tif (!tun->pcpu_stats) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_free_dev;\n\t\t}\n\n\t\tspin_lock_init(&tun->lock);\n\n\t\terr = security_tun_dev_alloc_security(&tun->security);\n\t\tif (err < 0)\n\t\t\tgoto err_free_stat;\n\n\t\ttun_net_init(dev);\n\t\ttun_flow_init(tun);\n\n\t\tdev->hw_features = NETIF_F_SG | NETIF_F_FRAGLIST |\n\t\t\t\t   TUN_USER_FEATURES | NETIF_F_HW_VLAN_CTAG_TX |\n\t\t\t\t   NETIF_F_HW_VLAN_STAG_TX;\n\t\tdev->features = dev->hw_features | NETIF_F_LLTX;\n\t\tdev->vlan_features = dev->features &\n\t\t\t\t     ~(NETIF_F_HW_VLAN_CTAG_TX |\n\t\t\t\t       NETIF_F_HW_VLAN_STAG_TX);\n\n\t\tINIT_LIST_HEAD(&tun->disabled);\n\t\terr = tun_attach(tun, file, false);\n\t\tif (err < 0)\n\t\t\tgoto err_free_flow;\n\n\t\terr = register_netdevice(tun->dev);\n\t\tif (err < 0)\n\t\t\tgoto err_detach;\n\t}\n\n\tnetif_carrier_on(tun->dev);\n\n\ttun_debug(KERN_INFO, tun, \"tun_set_iff\\n\");\n\n\ttun->flags = (tun->flags & ~TUN_FEATURES) |\n\t\t(ifr->ifr_flags & TUN_FEATURES);\n\n\t/* Make sure persistent devices do not get stuck in\n\t * xoff state.\n\t */\n\tif (netif_running(tun->dev))\n\t\tnetif_tx_wake_all_queues(tun->dev);\n\n\tstrcpy(ifr->ifr_name, tun->dev->name);\n\treturn 0;\n\nerr_detach:\n\ttun_detach_all(dev);\n\t/* register_netdevice() already called tun_free_netdev() */\n\tgoto err_free_dev;\n\nerr_free_flow:\n\ttun_flow_uninit(tun);\n\tsecurity_tun_dev_free_security(tun->security);\nerr_free_stat:\n\tfree_percpu(tun->pcpu_stats);\nerr_free_dev:\n\tfree_netdev(dev);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/5c25f65fd1e42685f7ccd80e0621829c105785d9", "file_name": "drivers/net/tun.c", "vul_type": "cwe-476", "description": "Write a C function named `tun_set_iff` that configures a network TUN/TAP device based on provided settings."}
{"func_name": "WriteImages", "func_src_before": "MagickExport MagickBooleanType WriteImages(const ImageInfo *image_info,\n  Image *images,const char *filename,ExceptionInfo *exception)\n{\n#define WriteImageTag  \"Write/Image\"\n\n  ExceptionInfo\n    *sans_exception;\n\n  ImageInfo\n    *write_info;\n\n  MagickBooleanType\n    proceed;\n\n  MagickOffsetType\n    progress;\n\n  MagickProgressMonitor\n    progress_monitor;\n\n  MagickSizeType\n    number_images;\n\n  MagickStatusType\n    status;\n\n  register Image\n    *p;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  write_info=CloneImageInfo(image_info);\n  *write_info->magick='\\0';\n  images=GetFirstImageInList(images);\n  if (filename != (const char *) NULL)\n    for (p=images; p != (Image *) NULL; p=GetNextImageInList(p))\n      (void) CopyMagickString(p->filename,filename,MagickPathExtent);\n  (void) CopyMagickString(write_info->filename,images->filename,MagickPathExtent);\n  sans_exception=AcquireExceptionInfo();\n  (void) SetImageInfo(write_info,(unsigned int) GetImageListLength(images),\n    sans_exception);\n  sans_exception=DestroyExceptionInfo(sans_exception);\n  if (*write_info->magick == '\\0')\n    (void) CopyMagickString(write_info->magick,images->magick,MagickPathExtent);\n  p=images;\n  for ( ; GetNextImageInList(p) != (Image *) NULL; p=GetNextImageInList(p))\n    if (p->scene >= GetNextImageInList(p)->scene)\n      {\n        register ssize_t\n          i;\n\n        /*\n          Generate consistent scene numbers.\n        */\n        i=(ssize_t) images->scene;\n        for (p=images; p != (Image *) NULL; p=GetNextImageInList(p))\n          p->scene=(size_t) i++;\n        break;\n      }\n  /*\n    Write images.\n  */\n  status=MagickTrue;\n  progress_monitor=(MagickProgressMonitor) NULL;\n  progress=0;\n  number_images=GetImageListLength(images);\n  for (p=images; p != (Image *) NULL; p=GetNextImageInList(p))\n  {\n    if (number_images != 1)\n      progress_monitor=SetImageProgressMonitor(p,(MagickProgressMonitor) NULL,\n        p->client_data);\n    status&=WriteImage(write_info,p,exception);\n    if (number_images != 1)\n      (void) SetImageProgressMonitor(p,progress_monitor,p->client_data);\n    if (write_info->adjoin != MagickFalse)\n      break;\n    if (number_images != 1)\n      {\n        proceed=SetImageProgress(p,WriteImageTag,progress++,number_images);\n        if (proceed == MagickFalse)\n          break;\n      }\n  }\n  write_info=DestroyImageInfo(write_info);\n  return(status != 0 ? MagickTrue : MagickFalse);\n}", "func_src_after": "MagickExport MagickBooleanType WriteImages(const ImageInfo *image_info,\n  Image *images,const char *filename,ExceptionInfo *exception)\n{\n#define WriteImageTag  \"Write/Image\"\n\n  ExceptionInfo\n    *sans_exception;\n\n  ImageInfo\n    *write_info;\n\n  MagickBooleanType\n    proceed;\n\n  MagickOffsetType\n    progress;\n\n  MagickProgressMonitor\n    progress_monitor;\n\n  MagickSizeType\n    number_images;\n\n  MagickStatusType\n    status;\n\n  register Image\n    *p;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  write_info=CloneImageInfo(image_info);\n  *write_info->magick='\\0';\n  images=GetFirstImageInList(images);\n  if (filename != (const char *) NULL)\n    for (p=images; p != (Image *) NULL; p=GetNextImageInList(p))\n      (void) CopyMagickString(p->filename,filename,MagickPathExtent);\n  (void) CopyMagickString(write_info->filename,images->filename,MagickPathExtent);\n  sans_exception=AcquireExceptionInfo();\n  (void) SetImageInfo(write_info,(unsigned int) GetImageListLength(images),\n    sans_exception);\n  sans_exception=DestroyExceptionInfo(sans_exception);\n  if (*write_info->magick == '\\0')\n    (void) CopyMagickString(write_info->magick,images->magick,MagickPathExtent);\n  p=images;\n  for ( ; GetNextImageInList(p) != (Image *) NULL; p=GetNextImageInList(p))\n  {\n    register Image\n      *next;\n    \n    next=GetNextImageInList(p);\n    if (next == (Image *) NULL)\n      break;\n    if (p->scene >= next->scene)\n      {\n        register ssize_t\n          i;\n\n        /*\n          Generate consistent scene numbers.\n        */\n        i=(ssize_t) images->scene;\n        for (p=images; p != (Image *) NULL; p=GetNextImageInList(p))\n          p->scene=(size_t) i++;\n        break;\n      }\n  }\n  /*\n    Write images.\n  */\n  status=MagickTrue;\n  progress_monitor=(MagickProgressMonitor) NULL;\n  progress=0;\n  number_images=GetImageListLength(images);\n  for (p=images; p != (Image *) NULL; p=GetNextImageInList(p))\n  {\n    if (number_images != 1)\n      progress_monitor=SetImageProgressMonitor(p,(MagickProgressMonitor) NULL,\n        p->client_data);\n    status&=WriteImage(write_info,p,exception);\n    if (number_images != 1)\n      (void) SetImageProgressMonitor(p,progress_monitor,p->client_data);\n    if (write_info->adjoin != MagickFalse)\n      break;\n    if (number_images != 1)\n      {\n        proceed=SetImageProgress(p,WriteImageTag,progress++,number_images);\n        if (proceed == MagickFalse)\n          break;\n      }\n  }\n  write_info=DestroyImageInfo(write_info);\n  return(status != 0 ? MagickTrue : MagickFalse);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/5b4bebaa91849c592a8448bc353ab25a54ff8c44", "file_name": "MagickCore/constitute.c", "vul_type": "cwe-476", "description": "In C, write a function to export and write a sequence of images to a file using ImageMagick's API."}
{"func_name": "__oom_reap_task_mm", "func_src_before": "static bool __oom_reap_task_mm(struct task_struct *tsk, struct mm_struct *mm)\n{\n\tstruct mmu_gather tlb;\n\tstruct vm_area_struct *vma;\n\tbool ret = true;\n\n\t/*\n\t * We have to make sure to not race with the victim exit path\n\t * and cause premature new oom victim selection:\n\t * __oom_reap_task_mm\t\texit_mm\n\t *   mmget_not_zero\n\t *\t\t\t\t  mmput\n\t *\t\t\t\t    atomic_dec_and_test\n\t *\t\t\t\t  exit_oom_victim\n\t *\t\t\t\t[...]\n\t *\t\t\t\tout_of_memory\n\t *\t\t\t\t  select_bad_process\n\t *\t\t\t\t    # no TIF_MEMDIE task selects new victim\n\t *  unmap_page_range # frees some memory\n\t */\n\tmutex_lock(&oom_lock);\n\n\tif (!down_read_trylock(&mm->mmap_sem)) {\n\t\tret = false;\n\t\ttrace_skip_task_reaping(tsk->pid);\n\t\tgoto unlock_oom;\n\t}\n\n\t/*\n\t * If the mm has notifiers then we would need to invalidate them around\n\t * unmap_page_range and that is risky because notifiers can sleep and\n\t * what they do is basically undeterministic.  So let's have a short\n\t * sleep to give the oom victim some more time.\n\t * TODO: we really want to get rid of this ugly hack and make sure that\n\t * notifiers cannot block for unbounded amount of time and add\n\t * mmu_notifier_invalidate_range_{start,end} around unmap_page_range\n\t */\n\tif (mm_has_notifiers(mm)) {\n\t\tup_read(&mm->mmap_sem);\n\t\tschedule_timeout_idle(HZ);\n\t\tgoto unlock_oom;\n\t}\n\n\t/*\n\t * MMF_OOM_SKIP is set by exit_mmap when the OOM reaper can't\n\t * work on the mm anymore. The check for MMF_OOM_SKIP must run\n\t * under mmap_sem for reading because it serializes against the\n\t * down_write();up_write() cycle in exit_mmap().\n\t */\n\tif (test_bit(MMF_OOM_SKIP, &mm->flags)) {\n\t\tup_read(&mm->mmap_sem);\n\t\ttrace_skip_task_reaping(tsk->pid);\n\t\tgoto unlock_oom;\n\t}\n\n\ttrace_start_task_reaping(tsk->pid);\n\n\t/*\n\t * Tell all users of get_user/copy_from_user etc... that the content\n\t * is no longer stable. No barriers really needed because unmapping\n\t * should imply barriers already and the reader would hit a page fault\n\t * if it stumbled over a reaped memory.\n\t */\n\tset_bit(MMF_UNSTABLE, &mm->flags);\n\n\ttlb_gather_mmu(&tlb, mm, 0, -1);\n\tfor (vma = mm->mmap ; vma; vma = vma->vm_next) {\n\t\tif (!can_madv_dontneed_vma(vma))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Only anonymous pages have a good chance to be dropped\n\t\t * without additional steps which we cannot afford as we\n\t\t * are OOM already.\n\t\t *\n\t\t * We do not even care about fs backed pages because all\n\t\t * which are reclaimable have already been reclaimed and\n\t\t * we do not want to block exit_mmap by keeping mm ref\n\t\t * count elevated without a good reason.\n\t\t */\n\t\tif (vma_is_anonymous(vma) || !(vma->vm_flags & VM_SHARED))\n\t\t\tunmap_page_range(&tlb, vma, vma->vm_start, vma->vm_end,\n\t\t\t\t\t NULL);\n\t}\n\ttlb_finish_mmu(&tlb, 0, -1);\n\tpr_info(\"oom_reaper: reaped process %d (%s), now anon-rss:%lukB, file-rss:%lukB, shmem-rss:%lukB\\n\",\n\t\t\ttask_pid_nr(tsk), tsk->comm,\n\t\t\tK(get_mm_counter(mm, MM_ANONPAGES)),\n\t\t\tK(get_mm_counter(mm, MM_FILEPAGES)),\n\t\t\tK(get_mm_counter(mm, MM_SHMEMPAGES)));\n\tup_read(&mm->mmap_sem);\n\n\ttrace_finish_task_reaping(tsk->pid);\nunlock_oom:\n\tmutex_unlock(&oom_lock);\n\treturn ret;\n}", "func_src_after": "static bool __oom_reap_task_mm(struct task_struct *tsk, struct mm_struct *mm)\n{\n\tstruct mmu_gather tlb;\n\tstruct vm_area_struct *vma;\n\tbool ret = true;\n\n\t/*\n\t * We have to make sure to not race with the victim exit path\n\t * and cause premature new oom victim selection:\n\t * __oom_reap_task_mm\t\texit_mm\n\t *   mmget_not_zero\n\t *\t\t\t\t  mmput\n\t *\t\t\t\t    atomic_dec_and_test\n\t *\t\t\t\t  exit_oom_victim\n\t *\t\t\t\t[...]\n\t *\t\t\t\tout_of_memory\n\t *\t\t\t\t  select_bad_process\n\t *\t\t\t\t    # no TIF_MEMDIE task selects new victim\n\t *  unmap_page_range # frees some memory\n\t */\n\tmutex_lock(&oom_lock);\n\n\tif (!down_read_trylock(&mm->mmap_sem)) {\n\t\tret = false;\n\t\ttrace_skip_task_reaping(tsk->pid);\n\t\tgoto unlock_oom;\n\t}\n\n\t/*\n\t * If the mm has notifiers then we would need to invalidate them around\n\t * unmap_page_range and that is risky because notifiers can sleep and\n\t * what they do is basically undeterministic.  So let's have a short\n\t * sleep to give the oom victim some more time.\n\t * TODO: we really want to get rid of this ugly hack and make sure that\n\t * notifiers cannot block for unbounded amount of time and add\n\t * mmu_notifier_invalidate_range_{start,end} around unmap_page_range\n\t */\n\tif (mm_has_notifiers(mm)) {\n\t\tup_read(&mm->mmap_sem);\n\t\tschedule_timeout_idle(HZ);\n\t\tgoto unlock_oom;\n\t}\n\n\t/*\n\t * MMF_OOM_SKIP is set by exit_mmap when the OOM reaper can't\n\t * work on the mm anymore. The check for MMF_OOM_SKIP must run\n\t * under mmap_sem for reading because it serializes against the\n\t * down_write();up_write() cycle in exit_mmap().\n\t */\n\tif (test_bit(MMF_OOM_SKIP, &mm->flags)) {\n\t\tup_read(&mm->mmap_sem);\n\t\ttrace_skip_task_reaping(tsk->pid);\n\t\tgoto unlock_oom;\n\t}\n\n\ttrace_start_task_reaping(tsk->pid);\n\n\t/*\n\t * Tell all users of get_user/copy_from_user etc... that the content\n\t * is no longer stable. No barriers really needed because unmapping\n\t * should imply barriers already and the reader would hit a page fault\n\t * if it stumbled over a reaped memory.\n\t */\n\tset_bit(MMF_UNSTABLE, &mm->flags);\n\n\tfor (vma = mm->mmap ; vma; vma = vma->vm_next) {\n\t\tif (!can_madv_dontneed_vma(vma))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Only anonymous pages have a good chance to be dropped\n\t\t * without additional steps which we cannot afford as we\n\t\t * are OOM already.\n\t\t *\n\t\t * We do not even care about fs backed pages because all\n\t\t * which are reclaimable have already been reclaimed and\n\t\t * we do not want to block exit_mmap by keeping mm ref\n\t\t * count elevated without a good reason.\n\t\t */\n\t\tif (vma_is_anonymous(vma) || !(vma->vm_flags & VM_SHARED)) {\n\t\t\ttlb_gather_mmu(&tlb, mm, vma->vm_start, vma->vm_end);\n\t\t\tunmap_page_range(&tlb, vma, vma->vm_start, vma->vm_end,\n\t\t\t\t\t NULL);\n\t\t\ttlb_finish_mmu(&tlb, vma->vm_start, vma->vm_end);\n\t\t}\n\t}\n\tpr_info(\"oom_reaper: reaped process %d (%s), now anon-rss:%lukB, file-rss:%lukB, shmem-rss:%lukB\\n\",\n\t\t\ttask_pid_nr(tsk), tsk->comm,\n\t\t\tK(get_mm_counter(mm, MM_ANONPAGES)),\n\t\t\tK(get_mm_counter(mm, MM_FILEPAGES)),\n\t\t\tK(get_mm_counter(mm, MM_SHMEMPAGES)));\n\tup_read(&mm->mmap_sem);\n\n\ttrace_finish_task_reaping(tsk->pid);\nunlock_oom:\n\tmutex_unlock(&oom_lock);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/687cb0884a714ff484d038e9190edc874edcf146", "file_name": "mm/oom_kill.c", "vul_type": "cwe-416", "description": "Write a C function named `__oom_reap_task_mm` that attempts to free memory by reaping a task's memory mappings in a Linux kernel context."}
{"func_name": "gf_m2ts_process_pat", "func_src_before": "static void gf_m2ts_process_pat(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *ses, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tGF_M2TS_Program *prog;\n\tGF_M2TS_SECTION_ES *pmt;\n\tu32 i, nb_progs, evt_type;\n\tu32 nb_sections;\n\tu32 data_size;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\t/*skip if already received*/\n\tif (status&GF_M2TS_TABLE_REPEAT) {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PAT_REPEAT, NULL);\n\t\treturn;\n\t}\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PAT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tif (!(status&GF_M2TS_TABLE_UPDATE) && gf_list_count(ts->programs)) {\n\t\tif (ts->pat->demux_restarted) {\n\t\t\tts->pat->demux_restarted = 0;\n\t\t} else {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"Multiple different PAT on single TS found, ignoring new PAT declaration (table id %d - extended table id %d)\\n\", table_id, ex_table_id));\n\t\t}\n\t\treturn;\n\t}\n\tnb_progs = data_size / 4;\n\n\tfor (i=0; i<nb_progs; i++) {\n\t\tu16 number, pid;\n\t\tnumber = (data[0]<<8) | data[1];\n\t\tpid = (data[2]&0x1f)<<8 | data[3];\n\t\tdata += 4;\n\t\tif (number==0) {\n\t\t\tif (!ts->nit) {\n\t\t\t\tts->nit = gf_m2ts_section_filter_new(gf_m2ts_process_nit, 0);\n\t\t\t}\n\t\t} else {\n\t\t\tGF_SAFEALLOC(prog, GF_M2TS_Program);\n\t\t\tif (!prog) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"Fail to allocate program for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tprog->streams = gf_list_new();\n\t\t\tprog->pmt_pid = pid;\n\t\t\tprog->number = number;\n\t\t\tprog->ts = ts;\n\t\t\tgf_list_add(ts->programs, prog);\n\t\t\tGF_SAFEALLOC(pmt, GF_M2TS_SECTION_ES);\n\t\t\tif (!pmt) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"Fail to allocate pmt filter for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpmt->flags = GF_M2TS_ES_IS_SECTION;\n\t\t\tgf_list_add(prog->streams, pmt);\n\t\t\tpmt->pid = prog->pmt_pid;\n\t\t\tpmt->program = prog;\n\t\t\tts->ess[pmt->pid] = (GF_M2TS_ES *)pmt;\n\t\t\tpmt->sec = gf_m2ts_section_filter_new(gf_m2ts_process_pmt, 0);\n\t\t}\n\t}\n\n\tevt_type = (status&GF_M2TS_TABLE_UPDATE) ? GF_M2TS_EVT_PAT_UPDATE : GF_M2TS_EVT_PAT_FOUND;\n\tif (ts->on_event) ts->on_event(ts, evt_type, NULL);\n}", "func_src_after": "static void gf_m2ts_process_pat(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *ses, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tGF_M2TS_Program *prog;\n\tGF_M2TS_SECTION_ES *pmt;\n\tu32 i, nb_progs, evt_type;\n\tu32 nb_sections;\n\tu32 data_size;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\t/*skip if already received*/\n\tif (status&GF_M2TS_TABLE_REPEAT) {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PAT_REPEAT, NULL);\n\t\treturn;\n\t}\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PAT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tif (!(status&GF_M2TS_TABLE_UPDATE) && gf_list_count(ts->programs)) {\n\t\tif (ts->pat->demux_restarted) {\n\t\t\tts->pat->demux_restarted = 0;\n\t\t} else {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"Multiple different PAT on single TS found, ignoring new PAT declaration (table id %d - extended table id %d)\\n\", table_id, ex_table_id));\n\t\t}\n\t\treturn;\n\t}\n\tnb_progs = data_size / 4;\n\n\tfor (i=0; i<nb_progs; i++) {\n\t\tu16 number, pid;\n\t\tnumber = (data[0]<<8) | data[1];\n\t\tpid = (data[2]&0x1f)<<8 | data[3];\n\t\tdata += 4;\n\t\tif (number==0) {\n\t\t\tif (!ts->nit) {\n\t\t\t\tts->nit = gf_m2ts_section_filter_new(gf_m2ts_process_nit, 0);\n\t\t\t}\n\t\t} else if (!pid) {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"Broken PAT found reserved PID 0, ignoring\\n\", pid));\n\t\t} else if (! ts->ess[pid]) {\n\t\t\tGF_SAFEALLOC(prog, GF_M2TS_Program);\n\t\t\tif (!prog) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"Fail to allocate program for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tprog->streams = gf_list_new();\n\t\t\tprog->pmt_pid = pid;\n\t\t\tprog->number = number;\n\t\t\tprog->ts = ts;\n\t\t\tgf_list_add(ts->programs, prog);\n\t\t\tGF_SAFEALLOC(pmt, GF_M2TS_SECTION_ES);\n\t\t\tif (!pmt) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"Fail to allocate pmt filter for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpmt->flags = GF_M2TS_ES_IS_SECTION;\n\t\t\tgf_list_add(prog->streams, pmt);\n\t\t\tpmt->pid = prog->pmt_pid;\n\t\t\tpmt->program = prog;\n\t\t\tts->ess[pmt->pid] = (GF_M2TS_ES *)pmt;\n\t\t\tpmt->sec = gf_m2ts_section_filter_new(gf_m2ts_process_pmt, 0);\n\t\t}\n\t}\n\n\tevt_type = (status&GF_M2TS_TABLE_UPDATE) ? GF_M2TS_EVT_PAT_UPDATE : GF_M2TS_EVT_PAT_FOUND;\n\tif (ts->on_event) ts->on_event(ts, evt_type, NULL);\n}", "commit_link": "github.com/gpac/gpac/commit/98b727637e32d1d4824101d8947e2dbd573d4fc8", "file_name": "src/media_tools/mpegts.c", "vul_type": "cwe-416", "description": "Write a C function to process Program Association Table (PAT) sections in an MPEG-2 transport stream demuxer."}
{"func_name": "ReadPWPImage", "func_src_before": "static Image *ReadPWPImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  FILE\n    *file;\n\n  Image\n    *image,\n    *next_image,\n    *pwp_image;\n\n  ImageInfo\n    *read_info;\n\n  int\n    c,\n    unique_file;\n\n  MagickBooleanType\n    status;\n\n  register Image\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    filesize,\n    length;\n\n  ssize_t\n    count;\n\n  unsigned char\n    magick[MaxTextExtent];\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  pwp_image=AcquireImage(image_info);\n  image=pwp_image;\n  status=OpenBlob(image_info,pwp_image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return((Image *) NULL);\n  count=ReadBlob(pwp_image,5,magick);\n  if ((count != 5) || (LocaleNCompare((char *) magick,\"SFW95\",5) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  read_info=CloneImageInfo(image_info);\n  (void) SetImageInfoProgressMonitor(read_info,(MagickProgressMonitor) NULL,\n    (void *) NULL);\n  SetImageInfoBlob(read_info,(void *) NULL,0);\n  unique_file=AcquireUniqueFileResource(read_info->filename);\n  for ( ; ; )\n  {\n    for (c=ReadBlobByte(pwp_image); c != EOF; c=ReadBlobByte(pwp_image))\n    {\n      for (i=0; i < 17; i++)\n        magick[i]=magick[i+1];\n      magick[17]=(unsigned char) c;\n      if (LocaleNCompare((char *) (magick+12),\"SFW94A\",6) == 0)\n        break;\n    }\n    if (c == EOF)\n      break;\n    if (LocaleNCompare((char *) (magick+12),\"SFW94A\",6) != 0)\n      {\n        (void) RelinquishUniqueFileResource(read_info->filename);\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n    /*\n      Dump SFW image to a temporary file.\n    */\n    file=(FILE *) NULL;\n    if (unique_file != -1)\n      file=fdopen(unique_file,\"wb\");\n    if ((unique_file == -1) || (file == (FILE *) NULL))\n      {\n        (void) RelinquishUniqueFileResource(read_info->filename);\n        ThrowFileException(exception,FileOpenError,\"UnableToWriteFile\",\n          image->filename);\n        image=DestroyImageList(image);\n        return((Image *) NULL);\n      }\n    length=fwrite(\"SFW94A\",1,6,file);\n    (void) length;\n    filesize=65535UL*magick[2]+256L*magick[1]+magick[0];\n    for (i=0; i < (ssize_t) filesize; i++)\n    {\n      c=ReadBlobByte(pwp_image);\n      (void) fputc(c,file);\n    }\n    (void) fclose(file);\n    next_image=ReadImage(read_info,exception);\n    if (next_image == (Image *) NULL)\n      break;\n    (void) FormatLocaleString(next_image->filename,MaxTextExtent,\n      \"slide_%02ld.sfw\",(long) next_image->scene);\n    if (image == (Image *) NULL)\n      image=next_image;\n    else\n      {\n        /*\n          Link image into image list.\n        */\n        for (p=image; p->next != (Image *) NULL; p=GetNextImageInList(p)) ;\n        next_image->previous=p;\n        next_image->scene=p->scene+1;\n        p->next=next_image;\n      }\n    if (image_info->number_scenes != 0)\n      if (next_image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageProgress(image,LoadImagesTag,TellBlob(pwp_image),\n      GetBlobSize(pwp_image));\n    if (status == MagickFalse)\n      break;\n  }\n  if (unique_file != -1)\n    (void) close(unique_file);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  read_info=DestroyImageInfo(read_info);\n  (void) CloseBlob(pwp_image);\n  pwp_image=DestroyImage(pwp_image);\n  if (EOFBlob(image) != MagickFalse)\n    {\n      char\n        *message;\n\n      message=GetExceptionMessage(errno);\n      (void) ThrowMagickException(exception,GetMagickModule(),CorruptImageError,\n        \"UnexpectedEndOfFile\",\"`%s': %s\",image->filename,message);\n      message=DestroyString(message);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadPWPImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  FILE\n    *file;\n\n  Image\n    *image,\n    *next_image,\n    *pwp_image;\n\n  ImageInfo\n    *read_info;\n\n  int\n    c,\n    unique_file;\n\n  MagickBooleanType\n    status;\n\n  register Image\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    filesize,\n    length;\n\n  ssize_t\n    count;\n\n  unsigned char\n    magick[MaxTextExtent];\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  pwp_image=AcquireImage(image_info);\n  image=pwp_image;\n  status=OpenBlob(image_info,pwp_image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return((Image *) NULL);\n  count=ReadBlob(pwp_image,5,magick);\n  if ((count != 5) || (LocaleNCompare((char *) magick,\"SFW95\",5) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  read_info=CloneImageInfo(image_info);\n  (void) SetImageInfoProgressMonitor(read_info,(MagickProgressMonitor) NULL,\n    (void *) NULL);\n  SetImageInfoBlob(read_info,(void *) NULL,0);\n  unique_file=AcquireUniqueFileResource(read_info->filename);\n  for ( ; ; )\n  {\n    for (c=ReadBlobByte(pwp_image); c != EOF; c=ReadBlobByte(pwp_image))\n    {\n      for (i=0; i < 17; i++)\n        magick[i]=magick[i+1];\n      magick[17]=(unsigned char) c;\n      if (LocaleNCompare((char *) (magick+12),\"SFW94A\",6) == 0)\n        break;\n    }\n    if (c == EOF)\n      break;\n    if (LocaleNCompare((char *) (magick+12),\"SFW94A\",6) != 0)\n      {\n        (void) RelinquishUniqueFileResource(read_info->filename);\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n    /*\n      Dump SFW image to a temporary file.\n    */\n    file=(FILE *) NULL;\n    if (unique_file != -1)\n      file=fdopen(unique_file,\"wb\");\n    if ((unique_file == -1) || (file == (FILE *) NULL))\n      {\n        (void) RelinquishUniqueFileResource(read_info->filename);\n        ThrowFileException(exception,FileOpenError,\"UnableToWriteFile\",\n          image->filename);\n        image=DestroyImageList(image);\n        return((Image *) NULL);\n      }\n    length=fwrite(\"SFW94A\",1,6,file);\n    (void) length;\n    filesize=65535UL*magick[2]+256L*magick[1]+magick[0];\n    for (i=0; i < (ssize_t) filesize; i++)\n    {\n      c=ReadBlobByte(pwp_image);\n      (void) fputc(c,file);\n    }\n    (void) fclose(file);\n    next_image=ReadImage(read_info,exception);\n    if (next_image == (Image *) NULL)\n      break;\n    (void) FormatLocaleString(next_image->filename,MaxTextExtent,\n      \"slide_%02ld.sfw\",(long) next_image->scene);\n    if (image == (Image *) NULL)\n      image=next_image;\n    else\n      {\n        /*\n          Link image into image list.\n        */\n        for (p=image; p->next != (Image *) NULL; p=GetNextImageInList(p)) ;\n        next_image->previous=p;\n        next_image->scene=p->scene+1;\n        p->next=next_image;\n      }\n    if (image_info->number_scenes != 0)\n      if (next_image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageProgress(image,LoadImagesTag,TellBlob(pwp_image),\n      GetBlobSize(pwp_image));\n    if (status == MagickFalse)\n      break;\n  }\n  if (unique_file != -1)\n    (void) close(unique_file);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  read_info=DestroyImageInfo(read_info);\n  if (EOFBlob(image) != MagickFalse)\n    {\n      char\n        *message;\n\n      message=GetExceptionMessage(errno);\n      (void) ThrowMagickException(exception,GetMagickModule(),CorruptImageError,\n        \"UnexpectedEndOfFile\",\"`%s': %s\",image->filename,message);\n      message=DestroyString(message);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ecc03a2518c2b7dd375fde3a040fdae0bdf6a521", "file_name": "coders/pwp.c", "vul_type": "cwe-416", "description": "Write a C function named `ReadPWPImage` that reads a PWP image file and returns an Image pointer."}
{"func_name": "skb_segment", "func_src_before": "struct sk_buff *skb_segment(struct sk_buff *head_skb,\n\t\t\t    netdev_features_t features)\n{\n\tstruct sk_buff *segs = NULL;\n\tstruct sk_buff *tail = NULL;\n\tstruct sk_buff *list_skb = skb_shinfo(head_skb)->frag_list;\n\tskb_frag_t *frag = skb_shinfo(head_skb)->frags;\n\tunsigned int mss = skb_shinfo(head_skb)->gso_size;\n\tunsigned int doffset = head_skb->data - skb_mac_header(head_skb);\n\tunsigned int offset = doffset;\n\tunsigned int tnl_hlen = skb_tnl_header_len(head_skb);\n\tunsigned int headroom;\n\tunsigned int len;\n\t__be16 proto;\n\tbool csum;\n\tint sg = !!(features & NETIF_F_SG);\n\tint nfrags = skb_shinfo(head_skb)->nr_frags;\n\tint err = -ENOMEM;\n\tint i = 0;\n\tint pos;\n\n\tproto = skb_network_protocol(head_skb);\n\tif (unlikely(!proto))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcsum = !!can_checksum_protocol(features, proto);\n\t__skb_push(head_skb, doffset);\n\theadroom = skb_headroom(head_skb);\n\tpos = skb_headlen(head_skb);\n\n\tdo {\n\t\tstruct sk_buff *nskb;\n\t\tskb_frag_t *nskb_frag;\n\t\tint hsize;\n\t\tint size;\n\n\t\tlen = head_skb->len - offset;\n\t\tif (len > mss)\n\t\t\tlen = mss;\n\n\t\thsize = skb_headlen(head_skb) - offset;\n\t\tif (hsize < 0)\n\t\t\thsize = 0;\n\t\tif (hsize > len || !sg)\n\t\t\thsize = len;\n\n\t\tif (!hsize && i >= nfrags && skb_headlen(list_skb) &&\n\t\t    (skb_headlen(list_skb) == len || sg)) {\n\t\t\tBUG_ON(skb_headlen(list_skb) > len);\n\n\t\t\ti = 0;\n\t\t\tnfrags = skb_shinfo(list_skb)->nr_frags;\n\t\t\tfrag = skb_shinfo(list_skb)->frags;\n\t\t\tpos += skb_headlen(list_skb);\n\n\t\t\twhile (pos < offset + len) {\n\t\t\t\tBUG_ON(i >= nfrags);\n\n\t\t\t\tsize = skb_frag_size(frag);\n\t\t\t\tif (pos + size > offset + len)\n\t\t\t\t\tbreak;\n\n\t\t\t\ti++;\n\t\t\t\tpos += size;\n\t\t\t\tfrag++;\n\t\t\t}\n\n\t\t\tnskb = skb_clone(list_skb, GFP_ATOMIC);\n\t\t\tlist_skb = list_skb->next;\n\n\t\t\tif (unlikely(!nskb))\n\t\t\t\tgoto err;\n\n\t\t\tif (unlikely(pskb_trim(nskb, len))) {\n\t\t\t\tkfree_skb(nskb);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\thsize = skb_end_offset(nskb);\n\t\t\tif (skb_cow_head(nskb, doffset + headroom)) {\n\t\t\t\tkfree_skb(nskb);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tnskb->truesize += skb_end_offset(nskb) - hsize;\n\t\t\tskb_release_head_state(nskb);\n\t\t\t__skb_push(nskb, doffset);\n\t\t} else {\n\t\t\tnskb = __alloc_skb(hsize + doffset + headroom,\n\t\t\t\t\t   GFP_ATOMIC, skb_alloc_rx_flag(head_skb),\n\t\t\t\t\t   NUMA_NO_NODE);\n\n\t\t\tif (unlikely(!nskb))\n\t\t\t\tgoto err;\n\n\t\t\tskb_reserve(nskb, headroom);\n\t\t\t__skb_put(nskb, doffset);\n\t\t}\n\n\t\tif (segs)\n\t\t\ttail->next = nskb;\n\t\telse\n\t\t\tsegs = nskb;\n\t\ttail = nskb;\n\n\t\t__copy_skb_header(nskb, head_skb);\n\t\tnskb->mac_len = head_skb->mac_len;\n\n\t\tskb_headers_offset_update(nskb, skb_headroom(nskb) - headroom);\n\n\t\tskb_copy_from_linear_data_offset(head_skb, -tnl_hlen,\n\t\t\t\t\t\t nskb->data - tnl_hlen,\n\t\t\t\t\t\t doffset + tnl_hlen);\n\n\t\tif (nskb->len == len + doffset)\n\t\t\tgoto perform_csum_check;\n\n\t\tif (!sg) {\n\t\t\tnskb->ip_summed = CHECKSUM_NONE;\n\t\t\tnskb->csum = skb_copy_and_csum_bits(head_skb, offset,\n\t\t\t\t\t\t\t    skb_put(nskb, len),\n\t\t\t\t\t\t\t    len, 0);\n\t\t\tcontinue;\n\t\t}\n\n\t\tnskb_frag = skb_shinfo(nskb)->frags;\n\n\t\tskb_copy_from_linear_data_offset(head_skb, offset,\n\t\t\t\t\t\t skb_put(nskb, hsize), hsize);\n\n\t\tskb_shinfo(nskb)->tx_flags = skb_shinfo(head_skb)->tx_flags &\n\t\t\tSKBTX_SHARED_FRAG;\n\n\t\twhile (pos < offset + len) {\n\t\t\tif (i >= nfrags) {\n\t\t\t\tBUG_ON(skb_headlen(list_skb));\n\n\t\t\t\ti = 0;\n\t\t\t\tnfrags = skb_shinfo(list_skb)->nr_frags;\n\t\t\t\tfrag = skb_shinfo(list_skb)->frags;\n\n\t\t\t\tBUG_ON(!nfrags);\n\n\t\t\t\tlist_skb = list_skb->next;\n\t\t\t}\n\n\t\t\tif (unlikely(skb_shinfo(nskb)->nr_frags >=\n\t\t\t\t     MAX_SKB_FRAGS)) {\n\t\t\t\tnet_warn_ratelimited(\n\t\t\t\t\t\"skb_segment: too many frags: %u %u\\n\",\n\t\t\t\t\tpos, mss);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\t*nskb_frag = *frag;\n\t\t\t__skb_frag_ref(nskb_frag);\n\t\t\tsize = skb_frag_size(nskb_frag);\n\n\t\t\tif (pos < offset) {\n\t\t\t\tnskb_frag->page_offset += offset - pos;\n\t\t\t\tskb_frag_size_sub(nskb_frag, offset - pos);\n\t\t\t}\n\n\t\t\tskb_shinfo(nskb)->nr_frags++;\n\n\t\t\tif (pos + size <= offset + len) {\n\t\t\t\ti++;\n\t\t\t\tfrag++;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tskb_frag_size_sub(nskb_frag, pos + size - (offset + len));\n\t\t\t\tgoto skip_fraglist;\n\t\t\t}\n\n\t\t\tnskb_frag++;\n\t\t}\n\nskip_fraglist:\n\t\tnskb->data_len = len - hsize;\n\t\tnskb->len += nskb->data_len;\n\t\tnskb->truesize += nskb->data_len;\n\nperform_csum_check:\n\t\tif (!csum) {\n\t\t\tnskb->csum = skb_checksum(nskb, doffset,\n\t\t\t\t\t\t  nskb->len - doffset, 0);\n\t\t\tnskb->ip_summed = CHECKSUM_NONE;\n\t\t}\n\t} while ((offset += len) < head_skb->len);\n\n\treturn segs;\n\nerr:\n\tkfree_skb_list(segs);\n\treturn ERR_PTR(err);\n}", "func_src_after": "struct sk_buff *skb_segment(struct sk_buff *head_skb,\n\t\t\t    netdev_features_t features)\n{\n\tstruct sk_buff *segs = NULL;\n\tstruct sk_buff *tail = NULL;\n\tstruct sk_buff *list_skb = skb_shinfo(head_skb)->frag_list;\n\tskb_frag_t *frag = skb_shinfo(head_skb)->frags;\n\tunsigned int mss = skb_shinfo(head_skb)->gso_size;\n\tunsigned int doffset = head_skb->data - skb_mac_header(head_skb);\n\tstruct sk_buff *frag_skb = head_skb;\n\tunsigned int offset = doffset;\n\tunsigned int tnl_hlen = skb_tnl_header_len(head_skb);\n\tunsigned int headroom;\n\tunsigned int len;\n\t__be16 proto;\n\tbool csum;\n\tint sg = !!(features & NETIF_F_SG);\n\tint nfrags = skb_shinfo(head_skb)->nr_frags;\n\tint err = -ENOMEM;\n\tint i = 0;\n\tint pos;\n\n\tproto = skb_network_protocol(head_skb);\n\tif (unlikely(!proto))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcsum = !!can_checksum_protocol(features, proto);\n\t__skb_push(head_skb, doffset);\n\theadroom = skb_headroom(head_skb);\n\tpos = skb_headlen(head_skb);\n\n\tdo {\n\t\tstruct sk_buff *nskb;\n\t\tskb_frag_t *nskb_frag;\n\t\tint hsize;\n\t\tint size;\n\n\t\tlen = head_skb->len - offset;\n\t\tif (len > mss)\n\t\t\tlen = mss;\n\n\t\thsize = skb_headlen(head_skb) - offset;\n\t\tif (hsize < 0)\n\t\t\thsize = 0;\n\t\tif (hsize > len || !sg)\n\t\t\thsize = len;\n\n\t\tif (!hsize && i >= nfrags && skb_headlen(list_skb) &&\n\t\t    (skb_headlen(list_skb) == len || sg)) {\n\t\t\tBUG_ON(skb_headlen(list_skb) > len);\n\n\t\t\ti = 0;\n\t\t\tnfrags = skb_shinfo(list_skb)->nr_frags;\n\t\t\tfrag = skb_shinfo(list_skb)->frags;\n\t\t\tfrag_skb = list_skb;\n\t\t\tpos += skb_headlen(list_skb);\n\n\t\t\twhile (pos < offset + len) {\n\t\t\t\tBUG_ON(i >= nfrags);\n\n\t\t\t\tsize = skb_frag_size(frag);\n\t\t\t\tif (pos + size > offset + len)\n\t\t\t\t\tbreak;\n\n\t\t\t\ti++;\n\t\t\t\tpos += size;\n\t\t\t\tfrag++;\n\t\t\t}\n\n\t\t\tnskb = skb_clone(list_skb, GFP_ATOMIC);\n\t\t\tlist_skb = list_skb->next;\n\n\t\t\tif (unlikely(!nskb))\n\t\t\t\tgoto err;\n\n\t\t\tif (unlikely(pskb_trim(nskb, len))) {\n\t\t\t\tkfree_skb(nskb);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\thsize = skb_end_offset(nskb);\n\t\t\tif (skb_cow_head(nskb, doffset + headroom)) {\n\t\t\t\tkfree_skb(nskb);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tnskb->truesize += skb_end_offset(nskb) - hsize;\n\t\t\tskb_release_head_state(nskb);\n\t\t\t__skb_push(nskb, doffset);\n\t\t} else {\n\t\t\tnskb = __alloc_skb(hsize + doffset + headroom,\n\t\t\t\t\t   GFP_ATOMIC, skb_alloc_rx_flag(head_skb),\n\t\t\t\t\t   NUMA_NO_NODE);\n\n\t\t\tif (unlikely(!nskb))\n\t\t\t\tgoto err;\n\n\t\t\tskb_reserve(nskb, headroom);\n\t\t\t__skb_put(nskb, doffset);\n\t\t}\n\n\t\tif (segs)\n\t\t\ttail->next = nskb;\n\t\telse\n\t\t\tsegs = nskb;\n\t\ttail = nskb;\n\n\t\t__copy_skb_header(nskb, head_skb);\n\t\tnskb->mac_len = head_skb->mac_len;\n\n\t\tskb_headers_offset_update(nskb, skb_headroom(nskb) - headroom);\n\n\t\tskb_copy_from_linear_data_offset(head_skb, -tnl_hlen,\n\t\t\t\t\t\t nskb->data - tnl_hlen,\n\t\t\t\t\t\t doffset + tnl_hlen);\n\n\t\tif (nskb->len == len + doffset)\n\t\t\tgoto perform_csum_check;\n\n\t\tif (!sg) {\n\t\t\tnskb->ip_summed = CHECKSUM_NONE;\n\t\t\tnskb->csum = skb_copy_and_csum_bits(head_skb, offset,\n\t\t\t\t\t\t\t    skb_put(nskb, len),\n\t\t\t\t\t\t\t    len, 0);\n\t\t\tcontinue;\n\t\t}\n\n\t\tnskb_frag = skb_shinfo(nskb)->frags;\n\n\t\tskb_copy_from_linear_data_offset(head_skb, offset,\n\t\t\t\t\t\t skb_put(nskb, hsize), hsize);\n\n\t\tskb_shinfo(nskb)->tx_flags = skb_shinfo(head_skb)->tx_flags &\n\t\t\tSKBTX_SHARED_FRAG;\n\n\t\twhile (pos < offset + len) {\n\t\t\tif (i >= nfrags) {\n\t\t\t\tBUG_ON(skb_headlen(list_skb));\n\n\t\t\t\ti = 0;\n\t\t\t\tnfrags = skb_shinfo(list_skb)->nr_frags;\n\t\t\t\tfrag = skb_shinfo(list_skb)->frags;\n\t\t\t\tfrag_skb = list_skb;\n\n\t\t\t\tBUG_ON(!nfrags);\n\n\t\t\t\tlist_skb = list_skb->next;\n\t\t\t}\n\n\t\t\tif (unlikely(skb_shinfo(nskb)->nr_frags >=\n\t\t\t\t     MAX_SKB_FRAGS)) {\n\t\t\t\tnet_warn_ratelimited(\n\t\t\t\t\t\"skb_segment: too many frags: %u %u\\n\",\n\t\t\t\t\tpos, mss);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tif (unlikely(skb_orphan_frags(frag_skb, GFP_ATOMIC)))\n\t\t\t\tgoto err;\n\n\t\t\t*nskb_frag = *frag;\n\t\t\t__skb_frag_ref(nskb_frag);\n\t\t\tsize = skb_frag_size(nskb_frag);\n\n\t\t\tif (pos < offset) {\n\t\t\t\tnskb_frag->page_offset += offset - pos;\n\t\t\t\tskb_frag_size_sub(nskb_frag, offset - pos);\n\t\t\t}\n\n\t\t\tskb_shinfo(nskb)->nr_frags++;\n\n\t\t\tif (pos + size <= offset + len) {\n\t\t\t\ti++;\n\t\t\t\tfrag++;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tskb_frag_size_sub(nskb_frag, pos + size - (offset + len));\n\t\t\t\tgoto skip_fraglist;\n\t\t\t}\n\n\t\t\tnskb_frag++;\n\t\t}\n\nskip_fraglist:\n\t\tnskb->data_len = len - hsize;\n\t\tnskb->len += nskb->data_len;\n\t\tnskb->truesize += nskb->data_len;\n\nperform_csum_check:\n\t\tif (!csum) {\n\t\t\tnskb->csum = skb_checksum(nskb, doffset,\n\t\t\t\t\t\t  nskb->len - doffset, 0);\n\t\t\tnskb->ip_summed = CHECKSUM_NONE;\n\t\t}\n\t} while ((offset += len) < head_skb->len);\n\n\treturn segs;\n\nerr:\n\tkfree_skb_list(segs);\n\treturn ERR_PTR(err);\n}", "commit_link": "github.com/torvalds/linux/commit/1fd819ecb90cc9b822cd84d3056ddba315d3340f", "file_name": "net/core/skbuff.c", "vul_type": "cwe-416", "description": "Write a C function named `skb_segment` that segments an `sk_buff` packet according to given network device features."}
{"func_name": "usb_serial_console_disconnect", "func_src_before": "void usb_serial_console_disconnect(struct usb_serial *serial)\n{\n\tif (serial->port[0] == usbcons_info.port) {\n\t\tusb_serial_console_exit();\n\t\tusb_serial_put(serial);\n\t}\n}", "func_src_after": "void usb_serial_console_disconnect(struct usb_serial *serial)\n{\n\tif (serial->port[0] && serial->port[0] == usbcons_info.port) {\n\t\tusb_serial_console_exit();\n\t\tusb_serial_put(serial);\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/bd998c2e0df0469707503023d50d46cf0b10c787", "file_name": "drivers/usb/serial/console.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_serial_console_disconnect` that disconnects a USB serial console if the first port matches a specified port."}
{"func_name": "blk_init_allocated_queue", "func_src_before": "int blk_init_allocated_queue(struct request_queue *q)\n{\n\tWARN_ON_ONCE(q->mq_ops);\n\n\tq->fq = blk_alloc_flush_queue(q, NUMA_NO_NODE, q->cmd_size);\n\tif (!q->fq)\n\t\treturn -ENOMEM;\n\n\tif (q->init_rq_fn && q->init_rq_fn(q, q->fq->flush_rq, GFP_KERNEL))\n\t\tgoto out_free_flush_queue;\n\n\tif (blk_init_rl(&q->root_rl, q, GFP_KERNEL))\n\t\tgoto out_exit_flush_rq;\n\n\tINIT_WORK(&q->timeout_work, blk_timeout_work);\n\tq->queue_flags\t\t|= QUEUE_FLAG_DEFAULT;\n\n\t/*\n\t * This also sets hw/phys segments, boundary and size\n\t */\n\tblk_queue_make_request(q, blk_queue_bio);\n\n\tq->sg_reserved_size = INT_MAX;\n\n\tif (elevator_init(q))\n\t\tgoto out_exit_flush_rq;\n\treturn 0;\n\nout_exit_flush_rq:\n\tif (q->exit_rq_fn)\n\t\tq->exit_rq_fn(q, q->fq->flush_rq);\nout_free_flush_queue:\n\tblk_free_flush_queue(q->fq);\n\treturn -ENOMEM;\n}", "func_src_after": "int blk_init_allocated_queue(struct request_queue *q)\n{\n\tWARN_ON_ONCE(q->mq_ops);\n\n\tq->fq = blk_alloc_flush_queue(q, NUMA_NO_NODE, q->cmd_size);\n\tif (!q->fq)\n\t\treturn -ENOMEM;\n\n\tif (q->init_rq_fn && q->init_rq_fn(q, q->fq->flush_rq, GFP_KERNEL))\n\t\tgoto out_free_flush_queue;\n\n\tif (blk_init_rl(&q->root_rl, q, GFP_KERNEL))\n\t\tgoto out_exit_flush_rq;\n\n\tINIT_WORK(&q->timeout_work, blk_timeout_work);\n\tq->queue_flags\t\t|= QUEUE_FLAG_DEFAULT;\n\n\t/*\n\t * This also sets hw/phys segments, boundary and size\n\t */\n\tblk_queue_make_request(q, blk_queue_bio);\n\n\tq->sg_reserved_size = INT_MAX;\n\n\tif (elevator_init(q))\n\t\tgoto out_exit_flush_rq;\n\treturn 0;\n\nout_exit_flush_rq:\n\tif (q->exit_rq_fn)\n\t\tq->exit_rq_fn(q, q->fq->flush_rq);\nout_free_flush_queue:\n\tblk_free_flush_queue(q->fq);\n\tq->fq = NULL;\n\treturn -ENOMEM;\n}", "commit_link": "github.com/torvalds/linux/commit/54648cf1ec2d7f4b6a71767799c45676a138ca24", "file_name": "block/blk-core.c", "vul_type": "cwe-416", "description": "Write a C function named `blk_init_allocated_queue` that initializes a block device queue structure."}
{"func_name": "snd_timer_open", "func_src_before": "int snd_timer_open(struct snd_timer_instance **ti,\n\t\t   char *owner, struct snd_timer_id *tid,\n\t\t   unsigned int slave_id)\n{\n\tstruct snd_timer *timer;\n\tstruct snd_timer_instance *timeri = NULL;\n\tstruct device *card_dev_to_put = NULL;\n\tint err;\n\n\tmutex_lock(&register_mutex);\n\tif (tid->dev_class == SNDRV_TIMER_CLASS_SLAVE) {\n\t\t/* open a slave instance */\n\t\tif (tid->dev_sclass <= SNDRV_TIMER_SCLASS_NONE ||\n\t\t    tid->dev_sclass > SNDRV_TIMER_SCLASS_OSS_SEQUENCER) {\n\t\t\tpr_debug(\"ALSA: timer: invalid slave class %i\\n\",\n\t\t\t\t tid->dev_sclass);\n\t\t\terr = -EINVAL;\n\t\t\tgoto unlock;\n\t\t}\n\t\ttimeri = snd_timer_instance_new(owner, NULL);\n\t\tif (!timeri) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto unlock;\n\t\t}\n\t\ttimeri->slave_class = tid->dev_sclass;\n\t\ttimeri->slave_id = tid->device;\n\t\ttimeri->flags |= SNDRV_TIMER_IFLG_SLAVE;\n\t\tlist_add_tail(&timeri->open_list, &snd_timer_slave_list);\n\t\terr = snd_timer_check_slave(timeri);\n\t\tif (err < 0) {\n\t\t\tsnd_timer_close_locked(timeri, &card_dev_to_put);\n\t\t\ttimeri = NULL;\n\t\t}\n\t\tgoto unlock;\n\t}\n\n\t/* open a master instance */\n\ttimer = snd_timer_find(tid);\n#ifdef CONFIG_MODULES\n\tif (!timer) {\n\t\tmutex_unlock(&register_mutex);\n\t\tsnd_timer_request(tid);\n\t\tmutex_lock(&register_mutex);\n\t\ttimer = snd_timer_find(tid);\n\t}\n#endif\n\tif (!timer) {\n\t\terr = -ENODEV;\n\t\tgoto unlock;\n\t}\n\tif (!list_empty(&timer->open_list_head)) {\n\t\ttimeri = list_entry(timer->open_list_head.next,\n\t\t\t\t    struct snd_timer_instance, open_list);\n\t\tif (timeri->flags & SNDRV_TIMER_IFLG_EXCLUSIVE) {\n\t\t\terr = -EBUSY;\n\t\t\ttimeri = NULL;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\tif (timer->num_instances >= timer->max_instances) {\n\t\terr = -EBUSY;\n\t\tgoto unlock;\n\t}\n\ttimeri = snd_timer_instance_new(owner, timer);\n\tif (!timeri) {\n\t\terr = -ENOMEM;\n\t\tgoto unlock;\n\t}\n\t/* take a card refcount for safe disconnection */\n\tif (timer->card)\n\t\tget_device(&timer->card->card_dev);\n\ttimeri->slave_class = tid->dev_sclass;\n\ttimeri->slave_id = slave_id;\n\n\tif (list_empty(&timer->open_list_head) && timer->hw.open) {\n\t\terr = timer->hw.open(timer);\n\t\tif (err) {\n\t\t\tkfree(timeri->owner);\n\t\t\tkfree(timeri);\n\t\t\ttimeri = NULL;\n\n\t\t\tif (timer->card)\n\t\t\t\tcard_dev_to_put = &timer->card->card_dev;\n\t\t\tmodule_put(timer->module);\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\tlist_add_tail(&timeri->open_list, &timer->open_list_head);\n\ttimer->num_instances++;\n\terr = snd_timer_check_master(timeri);\n\tif (err < 0) {\n\t\tsnd_timer_close_locked(timeri, &card_dev_to_put);\n\t\ttimeri = NULL;\n\t}\n\n unlock:\n\tmutex_unlock(&register_mutex);\n\t/* put_device() is called after unlock for avoiding deadlock */\n\tif (card_dev_to_put)\n\t\tput_device(card_dev_to_put);\n\t*ti = timeri;\n\treturn err;\n}", "func_src_after": "int snd_timer_open(struct snd_timer_instance **ti,\n\t\t   char *owner, struct snd_timer_id *tid,\n\t\t   unsigned int slave_id)\n{\n\tstruct snd_timer *timer;\n\tstruct snd_timer_instance *timeri = NULL;\n\tstruct device *card_dev_to_put = NULL;\n\tint err;\n\n\tmutex_lock(&register_mutex);\n\tif (tid->dev_class == SNDRV_TIMER_CLASS_SLAVE) {\n\t\t/* open a slave instance */\n\t\tif (tid->dev_sclass <= SNDRV_TIMER_SCLASS_NONE ||\n\t\t    tid->dev_sclass > SNDRV_TIMER_SCLASS_OSS_SEQUENCER) {\n\t\t\tpr_debug(\"ALSA: timer: invalid slave class %i\\n\",\n\t\t\t\t tid->dev_sclass);\n\t\t\terr = -EINVAL;\n\t\t\tgoto unlock;\n\t\t}\n\t\ttimeri = snd_timer_instance_new(owner, NULL);\n\t\tif (!timeri) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto unlock;\n\t\t}\n\t\ttimeri->slave_class = tid->dev_sclass;\n\t\ttimeri->slave_id = tid->device;\n\t\ttimeri->flags |= SNDRV_TIMER_IFLG_SLAVE;\n\t\tlist_add_tail(&timeri->open_list, &snd_timer_slave_list);\n\t\terr = snd_timer_check_slave(timeri);\n\t\tif (err < 0) {\n\t\t\tsnd_timer_close_locked(timeri, &card_dev_to_put);\n\t\t\ttimeri = NULL;\n\t\t}\n\t\tgoto unlock;\n\t}\n\n\t/* open a master instance */\n\ttimer = snd_timer_find(tid);\n#ifdef CONFIG_MODULES\n\tif (!timer) {\n\t\tmutex_unlock(&register_mutex);\n\t\tsnd_timer_request(tid);\n\t\tmutex_lock(&register_mutex);\n\t\ttimer = snd_timer_find(tid);\n\t}\n#endif\n\tif (!timer) {\n\t\terr = -ENODEV;\n\t\tgoto unlock;\n\t}\n\tif (!list_empty(&timer->open_list_head)) {\n\t\tstruct snd_timer_instance *t =\n\t\t\tlist_entry(timer->open_list_head.next,\n\t\t\t\t    struct snd_timer_instance, open_list);\n\t\tif (t->flags & SNDRV_TIMER_IFLG_EXCLUSIVE) {\n\t\t\terr = -EBUSY;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\tif (timer->num_instances >= timer->max_instances) {\n\t\terr = -EBUSY;\n\t\tgoto unlock;\n\t}\n\ttimeri = snd_timer_instance_new(owner, timer);\n\tif (!timeri) {\n\t\terr = -ENOMEM;\n\t\tgoto unlock;\n\t}\n\t/* take a card refcount for safe disconnection */\n\tif (timer->card)\n\t\tget_device(&timer->card->card_dev);\n\ttimeri->slave_class = tid->dev_sclass;\n\ttimeri->slave_id = slave_id;\n\n\tif (list_empty(&timer->open_list_head) && timer->hw.open) {\n\t\terr = timer->hw.open(timer);\n\t\tif (err) {\n\t\t\tkfree(timeri->owner);\n\t\t\tkfree(timeri);\n\t\t\ttimeri = NULL;\n\n\t\t\tif (timer->card)\n\t\t\t\tcard_dev_to_put = &timer->card->card_dev;\n\t\t\tmodule_put(timer->module);\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\tlist_add_tail(&timeri->open_list, &timer->open_list_head);\n\ttimer->num_instances++;\n\terr = snd_timer_check_master(timeri);\n\tif (err < 0) {\n\t\tsnd_timer_close_locked(timeri, &card_dev_to_put);\n\t\ttimeri = NULL;\n\t}\n\n unlock:\n\tmutex_unlock(&register_mutex);\n\t/* put_device() is called after unlock for avoiding deadlock */\n\tif (card_dev_to_put)\n\t\tput_device(card_dev_to_put);\n\t*ti = timeri;\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/e7af6307a8a54f0b873960b32b6a644f2d0fbd97", "file_name": "sound/core/timer.c", "vul_type": "cwe-416", "description": "Write a C function named `snd_timer_open` that opens a new sound timer instance, either as a master or a slave, based on the provided timer ID."}
{"func_name": "getKey", "func_src_before": "def getKey(client):\n\t\"\"\"Retrieves the specified key for the specified client\n\tReturns an error if the key doesn't exist, obviously.\n\t\"\"\"\n\tglobal SERVER_JWT_PRIVATE_KEY\n\tglobal BAD_REQUEST\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\n\t# Keys may only have alpha-numeric names\n\ttry:\n\t\tif re.search('[^a-zA-Z0-9]', token_data['key']):\n\t\t\traise FoxlockError(BAD_REQUEST, 'Invalid key requested')\n\t\trequested_key = open('keys/%s/%s.key' % (client, token_data['key']), 'r').read()\n\texcept KeyError:\n\t\traise FoxlockError(BAD_REQUEST, \"JWT did not contain attribute 'key'\")\n\texcept IOError:\n\t\traise FoxlockError(BAD_REQUEST, \"Key '%s' not found\" % token_data['key'])\n\n\t# Key is returned in a JWT encrypted with the client's public key, so only they can decrypt it\n\tkeytoken = packJWT({'key': requested_key}, SERVER_JWT_PRIVATE_KEY, client_pub_key)\n\n\treturn keytoken", "func_src_after": "def getKey(client):\n\t\"\"\"Retrieves the specified key for the specified client\n\tReturns an error if the key doesn't exist, obviously.\n\t\"\"\"\n\tglobal SERVER_JWT_PRIVATE_KEY\n\tglobal BAD_REQUEST\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateKeyName(token_data['key'])\n\n\t# Keys may only have alpha-numeric names\n\ttry:\n\t\trequested_key = open('keys/%s/%s.key' % (client, token_data['key']), 'r').read()\n\texcept KeyError:\n\t\traise FoxlockError(BAD_REQUEST, \"JWT did not contain attribute 'key'\")\n\texcept IOError:\n\t\traise FoxlockError(BAD_REQUEST, \"Key '%s' not found\" % token_data['key'])\n\n\t# Key is returned in a JWT encrypted with the client's public key, so only they can decrypt it\n\tkeytoken = packJWT({'key': requested_key}, SERVER_JWT_PRIVATE_KEY, client_pub_key)\n\n\treturn keytoken", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function to retrieve and return a client's key from a server, handling potential errors and ensuring the key name is alphanumeric."}
{"func_name": "ImportEPUB::ExtractContainer", "func_src_before": "void ImportEPUB::ExtractContainer()\n{\n    int res = 0;\n    if (!cp437) {\n        cp437 = new QCodePage437Codec();\n    }\n#ifdef Q_OS_WIN32\n    zlib_filefunc64_def ffunc;\n    fill_win32_filefunc64W(&ffunc);\n    unzFile zfile = unzOpen2_64(Utility::QStringToStdWString(QDir::toNativeSeparators(m_FullFilePath)).c_str(), &ffunc);\n#else\n    unzFile zfile = unzOpen64(QDir::toNativeSeparators(m_FullFilePath).toUtf8().constData());\n#endif\n\n    if (zfile == NULL) {\n        throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot unzip EPUB: %1\")).arg(QDir::toNativeSeparators(m_FullFilePath)).toStdString()));\n    }\n\n    res = unzGoToFirstFile(zfile);\n\n    if (res == UNZ_OK) {\n        do {\n            // Get the name of the file in the archive.\n            char file_name[MAX_PATH] = {0};\n            unz_file_info64 file_info;\n            unzGetCurrentFileInfo64(zfile, &file_info, file_name, MAX_PATH, NULL, 0, NULL, 0);\n            QString qfile_name;\n            QString cp437_file_name;\n            qfile_name = QString::fromUtf8(file_name);\n            if (!(file_info.flag & (1<<11))) {\n                // General purpose bit 11 says the filename is utf-8 encoded. If not set then\n                // IBM 437 encoding might be used.\n                cp437_file_name = cp437->toUnicode(file_name);\n            }\n\n            // If there is no file name then we can't do anything with it.\n            if (!qfile_name.isEmpty()) {\n                // We use the dir object to create the path in the temporary directory.\n                // Unfortunately, we need a dir ojbect to do this as it's not a static function.\n                QDir dir(m_ExtractedFolderPath);\n                // Full file path in the temporary directory.\n                QString file_path = m_ExtractedFolderPath + \"/\" + qfile_name;\n                QFileInfo qfile_info(file_path);\n\n                // Is this entry a directory?\n                if (file_info.uncompressed_size == 0 && qfile_name.endsWith('/')) {\n                    dir.mkpath(qfile_name);\n                    continue;\n                } else {\n                    dir.mkpath(qfile_info.path());\n\t\t    // add it to the list of files found inside the zip\n\t\t    if (cp437_file_name.isEmpty()) {\n\t\t        m_ZipFilePaths << qfile_name;\n\t\t    } else {\n                        m_ZipFilePaths << cp437_file_name;\n\t\t    }\n                }\n\n                // Open the file entry in the archive for reading.\n                if (unzOpenCurrentFile(zfile) != UNZ_OK) {\n                    unzClose(zfile);\n                    throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot extract file: %1\")).arg(qfile_name).toStdString()));\n                }\n\n                // Open the file on disk to write the entry in the archive to.\n                QFile entry(file_path);\n\n                if (!entry.open(QIODevice::WriteOnly | QIODevice::Truncate)) {\n                    unzCloseCurrentFile(zfile);\n                    unzClose(zfile);\n                    throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot extract file: %1\")).arg(qfile_name).toStdString()));\n                }\n\n                // Buffered reading and writing.\n                char buff[BUFF_SIZE] = {0};\n                int read = 0;\n\n                while ((read = unzReadCurrentFile(zfile, buff, BUFF_SIZE)) > 0) {\n                    entry.write(buff, read);\n                }\n\n                entry.close();\n\n                // Read errors are marked by a negative read amount.\n                if (read < 0) {\n                    unzCloseCurrentFile(zfile);\n                    unzClose(zfile);\n                    throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot extract file: %1\")).arg(qfile_name).toStdString()));\n                }\n\n                // The file was read but the CRC did not match.\n                // We don't check the read file size vs the uncompressed file size\n                // because if they're different there should be a CRC error.\n                if (unzCloseCurrentFile(zfile) == UNZ_CRCERROR) {\n                    unzClose(zfile);\n                    throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot extract file: %1\")).arg(qfile_name).toStdString()));\n                }\n                if (!cp437_file_name.isEmpty() && cp437_file_name != qfile_name) {\n                    QString cp437_file_path = m_ExtractedFolderPath + \"/\" + cp437_file_name;\n                    QFile::copy(file_path, cp437_file_path);\n                }\n            }\n        } while ((res = unzGoToNextFile(zfile)) == UNZ_OK);\n    }\n\n    if (res != UNZ_END_OF_LIST_OF_FILE) {\n        unzClose(zfile);\n        throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot open EPUB: %1\")).arg(QDir::toNativeSeparators(m_FullFilePath)).toStdString()));\n    }\n\n    unzClose(zfile);\n}", "func_src_after": "void ImportEPUB::ExtractContainer()\n{\n    int res = 0;\n    if (!cp437) {\n        cp437 = new QCodePage437Codec();\n    }\n#ifdef Q_OS_WIN32\n    zlib_filefunc64_def ffunc;\n    fill_win32_filefunc64W(&ffunc);\n    unzFile zfile = unzOpen2_64(Utility::QStringToStdWString(QDir::toNativeSeparators(m_FullFilePath)).c_str(), &ffunc);\n#else\n    unzFile zfile = unzOpen64(QDir::toNativeSeparators(m_FullFilePath).toUtf8().constData());\n#endif\n\n    if (zfile == NULL) {\n        throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot unzip EPUB: %1\")).arg(QDir::toNativeSeparators(m_FullFilePath)).toStdString()));\n    }\n\n    res = unzGoToFirstFile(zfile);\n\n    if (res == UNZ_OK) {\n        do {\n            // Get the name of the file in the archive.\n            char file_name[MAX_PATH] = {0};\n            unz_file_info64 file_info;\n            unzGetCurrentFileInfo64(zfile, &file_info, file_name, MAX_PATH, NULL, 0, NULL, 0);\n            QString qfile_name;\n            QString cp437_file_name;\n            qfile_name = QString::fromUtf8(file_name);\n            if (!(file_info.flag & (1<<11))) {\n                // General purpose bit 11 says the filename is utf-8 encoded. If not set then\n                // IBM 437 encoding might be used.\n                cp437_file_name = cp437->toUnicode(file_name);\n            }\n\n            // If there is no file name then we can't do anything with it.\n            if (!qfile_name.isEmpty()) {\n\n\t        // for security reasons we need the file path to always be inside the \n                // target folder and not outside, so we will remove all relative upward \n                // paths segments \"..\" from the file path before prepending the target \n                // folder to create the final target path\n\t        qfile_name = qfile_name.replace(\"../\",\"\");\n                cp437_file_name = cp437_file_name.replace(\"../\",\"\");\n\n                // We use the dir object to create the path in the temporary directory.\n                // Unfortunately, we need a dir ojbect to do this as it's not a static function.\n                QDir dir(m_ExtractedFolderPath);\n                // Full file path in the temporary directory.\n                QString file_path = m_ExtractedFolderPath + \"/\" + qfile_name;\n                QFileInfo qfile_info(file_path);\n\n                // Is this entry a directory?\n                if (file_info.uncompressed_size == 0 && qfile_name.endsWith('/')) {\n                    dir.mkpath(qfile_name);\n                    continue;\n                } else {\n                    dir.mkpath(qfile_info.path());\n\t\t    // add it to the list of files found inside the zip\n\t\t    if (cp437_file_name.isEmpty()) {\n\t\t        m_ZipFilePaths << qfile_name;\n\t\t    } else {\n                        m_ZipFilePaths << cp437_file_name;\n\t\t    }\n                }\n\n                // Open the file entry in the archive for reading.\n                if (unzOpenCurrentFile(zfile) != UNZ_OK) {\n                    unzClose(zfile);\n                    throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot extract file: %1\")).arg(qfile_name).toStdString()));\n                }\n\n                // Open the file on disk to write the entry in the archive to.\n                QFile entry(file_path);\n\n                if (!entry.open(QIODevice::WriteOnly | QIODevice::Truncate)) {\n                    unzCloseCurrentFile(zfile);\n                    unzClose(zfile);\n                    throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot extract file: %1\")).arg(qfile_name).toStdString()));\n                }\n\n                // Buffered reading and writing.\n                char buff[BUFF_SIZE] = {0};\n                int read = 0;\n\n                while ((read = unzReadCurrentFile(zfile, buff, BUFF_SIZE)) > 0) {\n                    entry.write(buff, read);\n                }\n\n                entry.close();\n\n                // Read errors are marked by a negative read amount.\n                if (read < 0) {\n                    unzCloseCurrentFile(zfile);\n                    unzClose(zfile);\n                    throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot extract file: %1\")).arg(qfile_name).toStdString()));\n                }\n\n                // The file was read but the CRC did not match.\n                // We don't check the read file size vs the uncompressed file size\n                // because if they're different there should be a CRC error.\n                if (unzCloseCurrentFile(zfile) == UNZ_CRCERROR) {\n                    unzClose(zfile);\n                    throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot extract file: %1\")).arg(qfile_name).toStdString()));\n                }\n                if (!cp437_file_name.isEmpty() && cp437_file_name != qfile_name) {\n                    QString cp437_file_path = m_ExtractedFolderPath + \"/\" + cp437_file_name;\n                    QFile::copy(file_path, cp437_file_path);\n                }\n            }\n        } while ((res = unzGoToNextFile(zfile)) == UNZ_OK);\n    }\n\n    if (res != UNZ_END_OF_LIST_OF_FILE) {\n        unzClose(zfile);\n        throw (EPUBLoadParseError(QString(QObject::tr(\"Cannot open EPUB: %1\")).arg(QDir::toNativeSeparators(m_FullFilePath)).toStdString()));\n    }\n\n    unzClose(zfile);\n}", "commit_link": "github.com/Sigil-Ebook/Sigil/commit/369eebe936e4a8c83cc54662a3412ce8bef189e4", "file_name": "src/Importers/ImportEPUB.cpp", "vul_type": "cwe-022", "description": "Write a C++ function to extract the contents of an EPUB file, handling different character encodings and ensuring file paths are secure."}
{"func_name": "GetMagickModulePath", "func_src_before": "static MagickBooleanType GetMagickModulePath(const char *filename,\n  MagickModuleType module_type,char *path,ExceptionInfo *exception)\n{\n  char\n    *module_path;\n\n  assert(filename != (const char *) NULL);\n  (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",filename);\n  assert(path != (char *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  (void) CopyMagickString(path,filename,MaxTextExtent);\n  module_path=(char *) NULL;\n  switch (module_type)\n  {\n    case MagickImageCoderModule:\n    default:\n    {\n      (void) LogMagickEvent(ModuleEvent,GetMagickModule(),\n        \"Searching for coder module file \\\"%s\\\" ...\",filename);\n      module_path=GetEnvironmentValue(\"MAGICK_CODER_MODULE_PATH\");\n#if defined(MAGICKCORE_CODER_PATH)\n      if (module_path == (char *) NULL)\n        module_path=AcquireString(MAGICKCORE_CODER_PATH);\n#endif\n      break;\n    }\n    case MagickImageFilterModule:\n    {\n      (void) LogMagickEvent(ModuleEvent,GetMagickModule(),\n        \"Searching for filter module file \\\"%s\\\" ...\",filename);\n      module_path=GetEnvironmentValue(\"MAGICK_CODER_FILTER_PATH\");\n#if defined(MAGICKCORE_FILTER_PATH)\n      if (module_path == (char *) NULL)\n        module_path=AcquireString(MAGICKCORE_FILTER_PATH);\n#endif\n      break;\n    }\n  }\n  if (module_path != (char *) NULL)\n    {\n      register char\n        *p,\n        *q;\n\n      for (p=module_path-1; p != (char *) NULL; )\n      {\n        (void) CopyMagickString(path,p+1,MaxTextExtent);\n        q=strchr(path,DirectoryListSeparator);\n        if (q != (char *) NULL)\n          *q='\\0';\n        q=path+strlen(path)-1;\n        if ((q >= path) && (*q != *DirectorySeparator))\n          (void) ConcatenateMagickString(path,DirectorySeparator,MaxTextExtent);\n        (void) ConcatenateMagickString(path,filename,MaxTextExtent);\n        if (IsPathAccessible(path) != MagickFalse)\n          {\n            module_path=DestroyString(module_path);\n            return(MagickTrue);\n          }\n        p=strchr(p+1,DirectoryListSeparator);\n      }\n      module_path=DestroyString(module_path);\n    }\n#if defined(MAGICKCORE_INSTALLED_SUPPORT)\n  else\n#if defined(MAGICKCORE_CODER_PATH)\n    {\n      const char\n        *directory;\n\n      /*\n        Search hard coded paths.\n      */\n      switch (module_type)\n      {\n        case MagickImageCoderModule:\n        default:\n        {\n          directory=MAGICKCORE_CODER_PATH;\n          break;\n        }\n        case MagickImageFilterModule:\n        {\n          directory=MAGICKCORE_FILTER_PATH;\n          break;\n        }\n      }\n      (void) FormatLocaleString(path,MaxTextExtent,\"%s%s\",directory,filename);\n      if (IsPathAccessible(path) == MagickFalse)\n        {\n          ThrowFileException(exception,ConfigureWarning,\n            \"UnableToOpenModuleFile\",path);\n          return(MagickFalse);\n        }\n      return(MagickTrue);\n    }\n#else\n#if defined(MAGICKCORE_WINDOWS_SUPPORT)\n    {\n      const char\n        *registery_key;\n\n      unsigned char\n        *key_value;\n\n      /*\n        Locate path via registry key.\n      */\n      switch (module_type)\n      {\n        case MagickImageCoderModule:\n        default:\n        {\n          registery_key=\"CoderModulesPath\";\n          break;\n        }\n        case MagickImageFilterModule:\n        {\n          registery_key=\"FilterModulesPath\";\n          break;\n        }\n      }\n      key_value=NTRegistryKeyLookup(registery_key);\n      if (key_value == (unsigned char *) NULL)\n        {\n          ThrowMagickException(exception,GetMagickModule(),ConfigureError,\n            \"RegistryKeyLookupFailed\",\"`%s'\",registery_key);\n          return(MagickFalse);\n        }\n      (void) FormatLocaleString(path,MaxTextExtent,\"%s%s%s\",(char *) key_value,\n        DirectorySeparator,filename);\n      key_value=(unsigned char *) RelinquishMagickMemory(key_value);\n      if (IsPathAccessible(path) == MagickFalse)\n        {\n          ThrowFileException(exception,ConfigureWarning,\n            \"UnableToOpenModuleFile\",path);\n          return(MagickFalse);\n        }\n      return(MagickTrue);\n    }\n#endif\n#endif\n#if !defined(MAGICKCORE_CODER_PATH) && !defined(MAGICKCORE_WINDOWS_SUPPORT)\n# error MAGICKCORE_CODER_PATH or MAGICKCORE_WINDOWS_SUPPORT must be defined when MAGICKCORE_INSTALLED_SUPPORT is defined\n#endif\n#else\n  {\n    char\n      *home;\n\n    home=GetEnvironmentValue(\"MAGICK_HOME\");\n    if (home != (char *) NULL)\n      {\n        /*\n          Search MAGICK_HOME.\n        */\n#if !defined(MAGICKCORE_POSIX_SUPPORT)\n        (void) FormatLocaleString(path,MaxTextExtent,\"%s%s%s\",home,\n          DirectorySeparator,filename);\n#else\n        const char\n          *directory;\n\n        switch (module_type)\n        {\n          case MagickImageCoderModule:\n          default:\n          {\n            directory=MAGICKCORE_CODER_RELATIVE_PATH;\n            break;\n          }\n          case MagickImageFilterModule:\n          {\n            directory=MAGICKCORE_FILTER_RELATIVE_PATH;\n            break;\n          }\n        }\n        (void) FormatLocaleString(path,MaxTextExtent,\"%s/lib/%s/%s\",home,\n          directory,filename);\n#endif\n        home=DestroyString(home);\n        if (IsPathAccessible(path) != MagickFalse)\n          return(MagickTrue);\n      }\n  }\n  if (*GetClientPath() != '\\0')\n    {\n      /*\n        Search based on executable directory.\n      */\n#if !defined(MAGICKCORE_POSIX_SUPPORT)\n      (void) FormatLocaleString(path,MaxTextExtent,\"%s%s%s\",GetClientPath(),\n        DirectorySeparator,filename);\n#else\n      char\n        prefix[MaxTextExtent];\n\n      const char\n        *directory;\n\n      switch (module_type)\n      {\n        case MagickImageCoderModule:\n        default:\n        {\n          directory=\"coders\";\n          break;\n        }\n        case MagickImageFilterModule:\n        {\n          directory=\"filters\";\n          break;\n        }\n      }\n      (void) CopyMagickString(prefix,GetClientPath(),MaxTextExtent);\n      ChopPathComponents(prefix,1);\n      (void) FormatLocaleString(path,MaxTextExtent,\"%s/lib/%s/%s/%s\",prefix,\n        MAGICKCORE_MODULES_RELATIVE_PATH,directory,filename);\n#endif\n      if (IsPathAccessible(path) != MagickFalse)\n        return(MagickTrue);\n    }\n#if defined(MAGICKCORE_WINDOWS_SUPPORT)\n  {\n    /*\n      Search module path.\n    */\n    if ((NTGetModulePath(\"CORE_RL_magick_.dll\",path) != MagickFalse) ||\n        (NTGetModulePath(\"CORE_DB_magick_.dll\",path) != MagickFalse) ||\n        (NTGetModulePath(\"Magick.dll\",path) != MagickFalse))\n      {\n        (void) ConcatenateMagickString(path,DirectorySeparator,MaxTextExtent);\n        (void) ConcatenateMagickString(path,filename,MaxTextExtent);\n        if (IsPathAccessible(path) != MagickFalse)\n          return(MagickTrue);\n      }\n  }\n#endif\n  {\n    char\n      *home;\n\n    home=GetEnvironmentValue(\"XDG_CONFIG_HOME\");\n    if (home == (char *) NULL)\n      home=GetEnvironmentValue(\"LOCALAPPDATA\");\n    if (home == (char *) NULL)\n      home=GetEnvironmentValue(\"APPDATA\");\n    if (home == (char *) NULL)\n      home=GetEnvironmentValue(\"USERPROFILE\");\n    if (home != (char *) NULL)\n      {\n        /*\n          Search $XDG_CONFIG_HOME/ImageMagick.\n        */\n        (void) FormatLocaleString(path,MaxTextExtent,\"%s%sImageMagick%s%s\",\n          home,DirectorySeparator,DirectorySeparator,filename);\n        home=DestroyString(home);\n        if (IsPathAccessible(path) != MagickFalse)\n          return(MagickTrue);\n      }\n    home=GetEnvironmentValue(\"HOME\");\n    if (home != (char *) NULL)\n      {\n        /*\n          Search $HOME/.config/ImageMagick.\n        */\n        (void) FormatLocaleString(path,MaxTextExtent,\n          \"%s%s.config%sImageMagick%s%s\",home,DirectorySeparator,\n          DirectorySeparator,DirectorySeparator,filename);\n        if (IsPathAccessible(path) != MagickFalse)\n          {\n            home=DestroyString(home);\n            return(MagickTrue);\n          }\n        /*\n          Search $HOME/.magick.\n        */\n        (void) FormatLocaleString(path,MaxTextExtent,\"%s%s.magick%s%s\",home,\n          DirectorySeparator,DirectorySeparator,filename);\n        home=DestroyString(home);\n        if (IsPathAccessible(path) != MagickFalse)\n          return(MagickTrue);\n      }\n  }\n  /*\n    Search current directory.\n  */\n  if (IsPathAccessible(path) != MagickFalse)\n    return(MagickTrue);\n  if (exception->severity < ConfigureError)\n    ThrowFileException(exception,ConfigureWarning,\"UnableToOpenModuleFile\",\n      path);\n#endif\n  return(MagickFalse);\n}", "func_src_after": "static MagickBooleanType GetMagickModulePath(const char *filename,\n  MagickModuleType module_type,char *path,ExceptionInfo *exception)\n{\n  char\n    *module_path;\n\n  assert(filename != (const char *) NULL);\n  (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",filename);\n  assert(path != (char *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  (void) CopyMagickString(path,filename,MaxTextExtent);\n#if defined(MAGICKCORE_INSTALLED_SUPPORT)\n  if (strstr(path,\"../\") != (char *) NULL)\n    {\n      errno=EPERM;\n      (void) ThrowMagickException(exception,GetMagickModule(),PolicyError,\n        \"NotAuthorized\",\"`%s'\",path);\n      return(MagickFalse);\n    }\n#endif\n  module_path=(char *) NULL;\n  switch (module_type)\n  {\n    case MagickImageCoderModule:\n    default:\n    {\n      (void) LogMagickEvent(ModuleEvent,GetMagickModule(),\n        \"Searching for coder module file \\\"%s\\\" ...\",filename);\n      module_path=GetEnvironmentValue(\"MAGICK_CODER_MODULE_PATH\");\n#if defined(MAGICKCORE_CODER_PATH)\n      if (module_path == (char *) NULL)\n        module_path=AcquireString(MAGICKCORE_CODER_PATH);\n#endif\n      break;\n    }\n    case MagickImageFilterModule:\n    {\n      (void) LogMagickEvent(ModuleEvent,GetMagickModule(),\n        \"Searching for filter module file \\\"%s\\\" ...\",filename);\n      module_path=GetEnvironmentValue(\"MAGICK_CODER_FILTER_PATH\");\n#if defined(MAGICKCORE_FILTER_PATH)\n      if (module_path == (char *) NULL)\n        module_path=AcquireString(MAGICKCORE_FILTER_PATH);\n#endif\n      break;\n    }\n  }\n  if (module_path != (char *) NULL)\n    {\n      register char\n        *p,\n        *q;\n\n      for (p=module_path-1; p != (char *) NULL; )\n      {\n        (void) CopyMagickString(path,p+1,MaxTextExtent);\n        q=strchr(path,DirectoryListSeparator);\n        if (q != (char *) NULL)\n          *q='\\0';\n        q=path+strlen(path)-1;\n        if ((q >= path) && (*q != *DirectorySeparator))\n          (void) ConcatenateMagickString(path,DirectorySeparator,MaxTextExtent);\n        (void) ConcatenateMagickString(path,filename,MaxTextExtent);\n        if (IsPathAccessible(path) != MagickFalse)\n          {\n            module_path=DestroyString(module_path);\n            return(MagickTrue);\n          }\n        p=strchr(p+1,DirectoryListSeparator);\n      }\n      module_path=DestroyString(module_path);\n    }\n#if defined(MAGICKCORE_INSTALLED_SUPPORT)\n  else\n#if defined(MAGICKCORE_CODER_PATH)\n    {\n      const char\n        *directory;\n\n      /*\n        Search hard coded paths.\n      */\n      switch (module_type)\n      {\n        case MagickImageCoderModule:\n        default:\n        {\n          directory=MAGICKCORE_CODER_PATH;\n          break;\n        }\n        case MagickImageFilterModule:\n        {\n          directory=MAGICKCORE_FILTER_PATH;\n          break;\n        }\n      }\n      (void) FormatLocaleString(path,MaxTextExtent,\"%s%s\",directory,filename);\n      if (IsPathAccessible(path) == MagickFalse)\n        {\n          ThrowFileException(exception,ConfigureWarning,\n            \"UnableToOpenModuleFile\",path);\n          return(MagickFalse);\n        }\n      return(MagickTrue);\n    }\n#else\n#if defined(MAGICKCORE_WINDOWS_SUPPORT)\n    {\n      const char\n        *registery_key;\n\n      unsigned char\n        *key_value;\n\n      /*\n        Locate path via registry key.\n      */\n      switch (module_type)\n      {\n        case MagickImageCoderModule:\n        default:\n        {\n          registery_key=\"CoderModulesPath\";\n          break;\n        }\n        case MagickImageFilterModule:\n        {\n          registery_key=\"FilterModulesPath\";\n          break;\n        }\n      }\n      key_value=NTRegistryKeyLookup(registery_key);\n      if (key_value == (unsigned char *) NULL)\n        {\n          ThrowMagickException(exception,GetMagickModule(),ConfigureError,\n            \"RegistryKeyLookupFailed\",\"`%s'\",registery_key);\n          return(MagickFalse);\n        }\n      (void) FormatLocaleString(path,MaxTextExtent,\"%s%s%s\",(char *) key_value,\n        DirectorySeparator,filename);\n      key_value=(unsigned char *) RelinquishMagickMemory(key_value);\n      if (IsPathAccessible(path) == MagickFalse)\n        {\n          ThrowFileException(exception,ConfigureWarning,\n            \"UnableToOpenModuleFile\",path);\n          return(MagickFalse);\n        }\n      return(MagickTrue);\n    }\n#endif\n#endif\n#if !defined(MAGICKCORE_CODER_PATH) && !defined(MAGICKCORE_WINDOWS_SUPPORT)\n# error MAGICKCORE_CODER_PATH or MAGICKCORE_WINDOWS_SUPPORT must be defined when MAGICKCORE_INSTALLED_SUPPORT is defined\n#endif\n#else\n  {\n    char\n      *home;\n\n    home=GetEnvironmentValue(\"MAGICK_HOME\");\n    if (home != (char *) NULL)\n      {\n        /*\n          Search MAGICK_HOME.\n        */\n#if !defined(MAGICKCORE_POSIX_SUPPORT)\n        (void) FormatLocaleString(path,MaxTextExtent,\"%s%s%s\",home,\n          DirectorySeparator,filename);\n#else\n        const char\n          *directory;\n\n        switch (module_type)\n        {\n          case MagickImageCoderModule:\n          default:\n          {\n            directory=MAGICKCORE_CODER_RELATIVE_PATH;\n            break;\n          }\n          case MagickImageFilterModule:\n          {\n            directory=MAGICKCORE_FILTER_RELATIVE_PATH;\n            break;\n          }\n        }\n        (void) FormatLocaleString(path,MaxTextExtent,\"%s/lib/%s/%s\",home,\n          directory,filename);\n#endif\n        home=DestroyString(home);\n        if (IsPathAccessible(path) != MagickFalse)\n          return(MagickTrue);\n      }\n  }\n  if (*GetClientPath() != '\\0')\n    {\n      /*\n        Search based on executable directory.\n      */\n#if !defined(MAGICKCORE_POSIX_SUPPORT)\n      (void) FormatLocaleString(path,MaxTextExtent,\"%s%s%s\",GetClientPath(),\n        DirectorySeparator,filename);\n#else\n      char\n        prefix[MaxTextExtent];\n\n      const char\n        *directory;\n\n      switch (module_type)\n      {\n        case MagickImageCoderModule:\n        default:\n        {\n          directory=\"coders\";\n          break;\n        }\n        case MagickImageFilterModule:\n        {\n          directory=\"filters\";\n          break;\n        }\n      }\n      (void) CopyMagickString(prefix,GetClientPath(),MaxTextExtent);\n      ChopPathComponents(prefix,1);\n      (void) FormatLocaleString(path,MaxTextExtent,\"%s/lib/%s/%s/%s\",prefix,\n        MAGICKCORE_MODULES_RELATIVE_PATH,directory,filename);\n#endif\n      if (IsPathAccessible(path) != MagickFalse)\n        return(MagickTrue);\n    }\n#if defined(MAGICKCORE_WINDOWS_SUPPORT)\n  {\n    /*\n      Search module path.\n    */\n    if ((NTGetModulePath(\"CORE_RL_magick_.dll\",path) != MagickFalse) ||\n        (NTGetModulePath(\"CORE_DB_magick_.dll\",path) != MagickFalse) ||\n        (NTGetModulePath(\"Magick.dll\",path) != MagickFalse))\n      {\n        (void) ConcatenateMagickString(path,DirectorySeparator,MaxTextExtent);\n        (void) ConcatenateMagickString(path,filename,MaxTextExtent);\n        if (IsPathAccessible(path) != MagickFalse)\n          return(MagickTrue);\n      }\n  }\n#endif\n  {\n    char\n      *home;\n\n    home=GetEnvironmentValue(\"XDG_CONFIG_HOME\");\n    if (home == (char *) NULL)\n      home=GetEnvironmentValue(\"LOCALAPPDATA\");\n    if (home == (char *) NULL)\n      home=GetEnvironmentValue(\"APPDATA\");\n    if (home == (char *) NULL)\n      home=GetEnvironmentValue(\"USERPROFILE\");\n    if (home != (char *) NULL)\n      {\n        /*\n          Search $XDG_CONFIG_HOME/ImageMagick.\n        */\n        (void) FormatLocaleString(path,MaxTextExtent,\"%s%sImageMagick%s%s\",\n          home,DirectorySeparator,DirectorySeparator,filename);\n        home=DestroyString(home);\n        if (IsPathAccessible(path) != MagickFalse)\n          return(MagickTrue);\n      }\n    home=GetEnvironmentValue(\"HOME\");\n    if (home != (char *) NULL)\n      {\n        /*\n          Search $HOME/.config/ImageMagick.\n        */\n        (void) FormatLocaleString(path,MaxTextExtent,\n          \"%s%s.config%sImageMagick%s%s\",home,DirectorySeparator,\n          DirectorySeparator,DirectorySeparator,filename);\n        if (IsPathAccessible(path) != MagickFalse)\n          {\n            home=DestroyString(home);\n            return(MagickTrue);\n          }\n        /*\n          Search $HOME/.magick.\n        */\n        (void) FormatLocaleString(path,MaxTextExtent,\"%s%s.magick%s%s\",home,\n          DirectorySeparator,DirectorySeparator,filename);\n        home=DestroyString(home);\n        if (IsPathAccessible(path) != MagickFalse)\n          return(MagickTrue);\n      }\n  }\n  /*\n    Search current directory.\n  */\n  if (IsPathAccessible(path) != MagickFalse)\n    return(MagickTrue);\n  if (exception->severity < ConfigureError)\n    ThrowFileException(exception,ConfigureWarning,\"UnableToOpenModuleFile\",\n      path);\n#endif\n  return(MagickFalse);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/fc6080f1321fd21e86ef916195cc110b05d9effb", "file_name": "magick/module.c", "vul_type": "cwe-022", "description": "Write a C function named `GetMagickModulePath` that locates a module file path based on its filename and type, handling various search strategies and exceptions."}
{"func_name": "estimate_size", "func_src_before": "    @staticmethod\n    def estimate_size(task_id, taken_dirs, taken_files):\n        report = AnalysisController.get_report(task_id)\n        report = report[\"analysis\"]\n        path = report[\"info\"][\"analysis_path\"]\n\n        size_total = 0\n\n        for directory in taken_dirs:\n            destination = \"%s/%s\" % (path, directory)\n            if os.path.isdir(destination):\n                size_total += get_directory_size(destination)\n\n        for filename in taken_files:\n            destination = \"%s/%s\" % (path, filename)\n            if os.path.isfile(destination):\n                size_total += os.path.getsize(destination)\n\n        # estimate file size after zipping; 60% compression rate typically\n        size_estimated = size_total / 6.5\n\n        return {\n            \"size\": int(size_estimated),\n            \"size_human\": filesizeformat(size_estimated)\n        }", "func_src_after": "    @staticmethod\n    def estimate_size(task_id, taken_dirs, taken_files):\n        report = AnalysisController.get_report(task_id)\n        report = report[\"analysis\"]\n        path = report[\"info\"][\"analysis_path\"]\n\n        size_total = 0\n\n        for directory in taken_dirs:\n            destination = \"%s/%s\" % (path, os.path.basename(directory))\n            if os.path.isdir(destination):\n                size_total += get_directory_size(destination)\n\n        for filename in taken_files:\n            destination = \"%s/%s\" % (path, os.path.basename(filename))\n            if os.path.isfile(destination):\n                size_total += os.path.getsize(destination)\n\n        # estimate file size after zipping; 60% compression rate typically\n        size_estimated = size_total / 6.5\n\n        return {\n            \"size\": int(size_estimated),\n            \"size_human\": filesizeformat(size_estimated)\n        }", "commit_link": "github.com/cuckoosandbox/cuckoo/commit/b90267fe4e5ee266ec3d4310a7b5c92c805b7ea3", "file_name": "cuckoo/web/controllers/analysis/export/export.py", "vul_type": "cwe-022", "description": "Write a Python function to estimate the compressed size of specified directories and files within a task's analysis path."}
{"func_name": "span", "func_src_before": "    def span(self, key):\n        path = os.path.join(self.namespace, key)\n        try:\n            self.etcd.write(path, None, dir=True, prevExist=False)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "func_src_after": "    def span(self, key):\n        path = self._absolute_key(key)\n        try:\n            self.etcd.write(path, None, dir=True, prevExist=False)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `span` that attempts to create a new directory in an etcd store with a given key, and handles exceptions for already existing keys or other etcd errors."}
{"func_name": "_get_settings", "func_src_before": "def _get_settings(view):\n    return {\n        'linters': get_settings(view, 'anaconda_go_linters', []),\n        'lint_test': get_settings(\n            view, 'anaconda_go_lint_test', False),\n        'exclude_regexps': get_settings(\n            view, 'anaconda_go_exclude_regexps', []),\n        'max_line_length': get_settings(\n            view, 'anaconda_go_max_line_length', 120),\n        'gocyclo_threshold': get_settings(\n            view, 'anaconda_go_gocyclo_threshold', 10),\n        'golint_min_confidence': get_settings(\n            view, 'anaconda_go_golint_min_confidence', 0.80),\n        'goconst_min_occurrences': get_settings(\n            view, 'anaconda_go_goconst_min_occurrences', 3),\n        'min_const_length': get_settings(\n            view, 'anaconda_go_min_const_length', 3),\n        'dupl_threshold': get_settings(\n            view, 'anaconda_go_dupl_threshold', 50),\n        'path': get_working_directory(view)\n    }", "func_src_after": "def _get_settings(view):\n    return {\n        'linters': get_settings(view, 'anaconda_go_linters', []),\n        'lint_test': get_settings(\n            view, 'anaconda_go_lint_test', False),\n        'exclude_regexps': get_settings(\n            view, 'anaconda_go_exclude_regexps', []),\n        'max_line_length': get_settings(\n            view, 'anaconda_go_max_line_length', 120),\n        'gocyclo_threshold': get_settings(\n            view, 'anaconda_go_gocyclo_threshold', 10),\n        'golint_min_confidence': get_settings(\n            view, 'anaconda_go_golint_min_confidence', 0.80),\n        'goconst_min_occurrences': get_settings(\n            view, 'anaconda_go_goconst_min_occurrences', 3),\n        'min_const_length': get_settings(\n            view, 'anaconda_go_min_const_length', 3),\n        'dupl_threshold': get_settings(\n            view, 'anaconda_go_dupl_threshold', 50),\n        'path': os.path.dirname(view.file_name())\n    }", "commit_link": "github.com/DamnWidget/anaconda_go/commit/d3db90bb8853d832927818699591b91f56f6413c", "file_name": "lib/_sublime.py", "vul_type": "cwe-022", "description": "Write a Python function to fetch and return a dictionary of settings for the Anaconda plugin in a code editor, using default values if specific settings are not found."}
{"func_name": "WritePSDChannels", "func_src_before": "static ssize_t WritePSDChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  MagickOffsetType size_offset,const MagickBooleanType separate)\n{\n  Image\n    *mask;\n\n  MagickOffsetType\n    rows_offset;\n\n  size_t\n    channels,\n    count,\n    length,\n    offset_length;\n\n  unsigned char\n    *compact_pixels;\n\n  count=0;\n  offset_length=0;\n  rows_offset=0;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=AcquireCompactPixels(image);\n      if (compact_pixels == (unsigned char *) NULL)\n        return(0);\n    }\n  channels=1;\n  if (separate == MagickFalse)\n    {\n      if (next_image->storage_class != PseudoClass)\n        {\n          if (IsGrayImage(next_image,&next_image->exception) == MagickFalse)\n            channels=next_image->colorspace == CMYKColorspace ? 4 : 3;\n          if (next_image->matte != MagickFalse)\n            channels++;\n        }\n      rows_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,channels);\n      offset_length=(next_image->rows*(psd_info->version == 1 ? 2 : 4));\n    }\n  size_offset+=2;\n  if (next_image->storage_class == PseudoClass)\n    {\n      length=WritePSDChannel(psd_info,image_info,image,next_image,\n        IndexQuantum,compact_pixels,rows_offset,separate);\n      if (separate != MagickFalse)\n        size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n      else\n        rows_offset+=offset_length;\n      count+=length;\n    }\n  else\n    {\n      if (IsGrayImage(next_image,&next_image->exception) != MagickFalse)\n        {\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            GrayQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n        }\n      else\n        {\n          if (next_image->colorspace == CMYKColorspace)\n            (void) NegateImage(next_image,MagickFalse);\n\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            RedQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            GreenQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            BlueQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n\n          if (next_image->colorspace == CMYKColorspace)\n            {\n              length=WritePSDChannel(psd_info,image_info,image,next_image,\n                BlackQuantum,compact_pixels,rows_offset,separate);\n              if (separate != MagickFalse)\n                size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n              else\n                rows_offset+=offset_length;\n              count+=length;\n            }\n        }\n      if (next_image->matte != MagickFalse)\n        {\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            AlphaQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n        }\n    }\n  compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  if (next_image->colorspace == CMYKColorspace)\n    (void) NegateImage(next_image,MagickFalse);\n  if (separate != MagickFalse)\n    {\n      const char\n        *property;\n\n      property=GetImageArtifact(next_image,\"psd:opacity-mask\");\n      if (property != (const char *) NULL)\n        {\n          mask=(Image *) GetImageRegistry(ImageRegistryType,property,\n            &image->exception);\n          if (mask != (Image *) NULL)\n            {\n              if (mask->compression == RLECompression)\n                {\n                  compact_pixels=AcquireCompactPixels(mask);\n                  if (compact_pixels == (unsigned char *) NULL)\n                    return(0);\n                }\n              length=WritePSDChannel(psd_info,image_info,image,mask,\n                RedQuantum,compact_pixels,rows_offset,MagickTrue);\n              (void) WritePSDSize(psd_info,image,length,size_offset);\n              count+=length;\n              compact_pixels=(unsigned char *) RelinquishMagickMemory(\n                compact_pixels);\n            }\n        }\n    }\n  return(count);\n}", "func_src_after": "static ssize_t WritePSDChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  MagickOffsetType size_offset,const MagickBooleanType separate)\n{\n  Image\n    *mask;\n\n  MagickOffsetType\n    rows_offset;\n\n  size_t\n    channels,\n    count,\n    length,\n    offset_length;\n\n  unsigned char\n    *compact_pixels;\n\n  count=0;\n  offset_length=0;\n  rows_offset=0;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=AcquireCompactPixels(next_image);\n      if (compact_pixels == (unsigned char *) NULL)\n        return(0);\n    }\n  channels=1;\n  if (separate == MagickFalse)\n    {\n      if (next_image->storage_class != PseudoClass)\n        {\n          if (IsGrayImage(next_image,&next_image->exception) == MagickFalse)\n            channels=next_image->colorspace == CMYKColorspace ? 4 : 3;\n          if (next_image->matte != MagickFalse)\n            channels++;\n        }\n      rows_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,channels);\n      offset_length=(next_image->rows*(psd_info->version == 1 ? 2 : 4));\n    }\n  size_offset+=2;\n  if (next_image->storage_class == PseudoClass)\n    {\n      length=WritePSDChannel(psd_info,image_info,image,next_image,\n        IndexQuantum,compact_pixels,rows_offset,separate);\n      if (separate != MagickFalse)\n        size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n      else\n        rows_offset+=offset_length;\n      count+=length;\n    }\n  else\n    {\n      if (IsGrayImage(next_image,&next_image->exception) != MagickFalse)\n        {\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            GrayQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n        }\n      else\n        {\n          if (next_image->colorspace == CMYKColorspace)\n            (void) NegateImage(next_image,MagickFalse);\n\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            RedQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            GreenQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            BlueQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n\n          if (next_image->colorspace == CMYKColorspace)\n            {\n              length=WritePSDChannel(psd_info,image_info,image,next_image,\n                BlackQuantum,compact_pixels,rows_offset,separate);\n              if (separate != MagickFalse)\n                size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n              else\n                rows_offset+=offset_length;\n              count+=length;\n            }\n        }\n      if (next_image->matte != MagickFalse)\n        {\n          length=WritePSDChannel(psd_info,image_info,image,next_image,\n            AlphaQuantum,compact_pixels,rows_offset,separate);\n          if (separate != MagickFalse)\n            size_offset+=WritePSDSize(psd_info,image,length,size_offset)+2;\n          else\n            rows_offset+=offset_length;\n          count+=length;\n        }\n    }\n  compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  if (next_image->colorspace == CMYKColorspace)\n    (void) NegateImage(next_image,MagickFalse);\n  if (separate != MagickFalse)\n    {\n      const char\n        *property;\n\n      property=GetImageArtifact(next_image,\"psd:opacity-mask\");\n      if (property != (const char *) NULL)\n        {\n          mask=(Image *) GetImageRegistry(ImageRegistryType,property,\n            &image->exception);\n          if (mask != (Image *) NULL)\n            {\n              if (mask->compression == RLECompression)\n                {\n                  compact_pixels=AcquireCompactPixels(mask);\n                  if (compact_pixels == (unsigned char *) NULL)\n                    return(0);\n                }\n              length=WritePSDChannel(psd_info,image_info,image,mask,\n                RedQuantum,compact_pixels,rows_offset,MagickTrue);\n              (void) WritePSDSize(psd_info,image,length,size_offset);\n              count+=length;\n              compact_pixels=(unsigned char *) RelinquishMagickMemory(\n                compact_pixels);\n            }\n        }\n    }\n  return(count);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/37a1710e2dab6ed91128ea648d654a22fbe2a6af", "file_name": "coders/psd.c", "vul_type": "cwe-787", "description": "Write a C function to handle the writing of image channels for PSD files, including support for RLE compression and separate layers."}
{"func_name": "InitialiseRFBConnection", "func_src_before": "InitialiseRFBConnection(rfbClient* client)\n{\n  rfbProtocolVersionMsg pv;\n  int major,minor;\n  uint32_t authScheme;\n  uint32_t subAuthScheme;\n  rfbClientInitMsg ci;\n\n  /* if the connection is immediately closed, don't report anything, so\n       that pmw's monitor can make test connections */\n\n  if (client->listenSpecified)\n    errorMessageOnReadFailure = FALSE;\n\n  if (!ReadFromRFBServer(client, pv, sz_rfbProtocolVersionMsg)) return FALSE;\n  pv[sz_rfbProtocolVersionMsg]=0;\n\n  errorMessageOnReadFailure = TRUE;\n\n  pv[sz_rfbProtocolVersionMsg] = 0;\n\n  if (sscanf(pv,rfbProtocolVersionFormat,&major,&minor) != 2) {\n    rfbClientLog(\"Not a valid VNC server (%s)\\n\",pv);\n    return FALSE;\n  }\n\n\n  DefaultSupportedMessages(client);\n  client->major = major;\n  client->minor = minor;\n\n  /* fall back to viewer supported version */\n  if ((major==rfbProtocolMajorVersion) && (minor>rfbProtocolMinorVersion))\n    client->minor = rfbProtocolMinorVersion;\n\n  /* UltraVNC uses minor codes 4 and 6 for the server */\n  if (major==3 && (minor==4 || minor==6)) {\n      rfbClientLog(\"UltraVNC server detected, enabling UltraVNC specific messages\\n\",pv);\n      DefaultSupportedMessagesUltraVNC(client);\n  }\n\n  /* UltraVNC Single Click uses minor codes 14 and 16 for the server */\n  if (major==3 && (minor==14 || minor==16)) {\n     minor = minor - 10;\n     client->minor = minor;\n     rfbClientLog(\"UltraVNC Single Click server detected, enabling UltraVNC specific messages\\n\",pv);\n     DefaultSupportedMessagesUltraVNC(client);\n  }\n\n  /* TightVNC uses minor codes 5 for the server */\n  if (major==3 && minor==5) {\n      rfbClientLog(\"TightVNC server detected, enabling TightVNC specific messages\\n\",pv);\n      DefaultSupportedMessagesTightVNC(client);\n  }\n\n  /* we do not support > RFB3.8 */\n  if ((major==3 && minor>8) || major>3)\n  {\n    client->major=3;\n    client->minor=8;\n  }\n\n  rfbClientLog(\"VNC server supports protocol version %d.%d (viewer %d.%d)\\n\",\n\t  major, minor, rfbProtocolMajorVersion, rfbProtocolMinorVersion);\n\n  sprintf(pv,rfbProtocolVersionFormat,client->major,client->minor);\n\n  if (!WriteToRFBServer(client, pv, sz_rfbProtocolVersionMsg)) return FALSE;\n\n\n  /* 3.7 and onwards sends a # of security types first */\n  if (client->major==3 && client->minor > 6)\n  {\n    if (!ReadSupportedSecurityType(client, &authScheme, FALSE)) return FALSE;\n  }\n  else\n  {\n    if (!ReadFromRFBServer(client, (char *)&authScheme, 4)) return FALSE;\n    authScheme = rfbClientSwap32IfLE(authScheme);\n  }\n  \n  rfbClientLog(\"Selected Security Scheme %d\\n\", authScheme);\n  client->authScheme = authScheme;\n  \n  switch (authScheme) {\n\n  case rfbConnFailed:\n    ReadReason(client);\n    return FALSE;\n\n  case rfbNoAuth:\n    rfbClientLog(\"No authentication needed\\n\");\n\n    /* 3.8 and upwards sends a Security Result for rfbNoAuth */\n    if ((client->major==3 && client->minor > 7) || client->major>3)\n        if (!rfbHandleAuthResult(client)) return FALSE;        \n\n    break;\n\n  case rfbVncAuth:\n    if (!HandleVncAuth(client)) return FALSE;\n    break;\n\n#ifdef LIBVNCSERVER_HAVE_SASL\n  case rfbSASL:\n    if (!HandleSASLAuth(client)) return FALSE;\n    break;\n#endif /* LIBVNCSERVER_HAVE_SASL */\n\n  case rfbMSLogon:\n    if (!HandleMSLogonAuth(client)) return FALSE;\n    break;\n\n  case rfbARD:\n#ifndef LIBVNCSERVER_WITH_CLIENT_GCRYPT\n    rfbClientLog(\"GCrypt support was not compiled in\\n\");\n    return FALSE;\n#else\n    if (!HandleARDAuth(client)) return FALSE;\n#endif\n    break;\n\n  case rfbTLS:\n    if (!HandleAnonTLSAuth(client)) return FALSE;\n    /* After the TLS session is established, sub auth types are expected.\n     * Note that all following reading/writing are through the TLS session from here.\n     */\n    if (!ReadSupportedSecurityType(client, &subAuthScheme, TRUE)) return FALSE;\n    client->subAuthScheme = subAuthScheme;\n\n    switch (subAuthScheme) {\n\n      case rfbConnFailed:\n        ReadReason(client);\n        return FALSE;\n\n      case rfbNoAuth:\n        rfbClientLog(\"No sub authentication needed\\n\");\n        /* 3.8 and upwards sends a Security Result for rfbNoAuth */\n        if ((client->major==3 && client->minor > 7) || client->major>3)\n            if (!rfbHandleAuthResult(client)) return FALSE;\n        break;\n\n      case rfbVncAuth:\n        if (!HandleVncAuth(client)) return FALSE;\n        break;\n\n#ifdef LIBVNCSERVER_HAVE_SASL\n      case rfbSASL:\n        if (!HandleSASLAuth(client)) return FALSE;\n        break;\n#endif /* LIBVNCSERVER_HAVE_SASL */\n\n      default:\n        rfbClientLog(\"Unknown sub authentication scheme from VNC server: %d\\n\",\n            (int)subAuthScheme);\n        return FALSE;\n    }\n\n    break;\n\n  case rfbVeNCrypt:\n    if (!HandleVeNCryptAuth(client)) return FALSE;\n\n    switch (client->subAuthScheme) {\n\n      case rfbVeNCryptTLSNone:\n      case rfbVeNCryptX509None:\n        rfbClientLog(\"No sub authentication needed\\n\");\n        if (!rfbHandleAuthResult(client)) return FALSE;\n        break;\n\n      case rfbVeNCryptTLSVNC:\n      case rfbVeNCryptX509VNC:\n        if (!HandleVncAuth(client)) return FALSE;\n        break;\n\n      case rfbVeNCryptTLSPlain:\n      case rfbVeNCryptX509Plain:\n        if (!HandlePlainAuth(client)) return FALSE;\n        break;\n\n#ifdef LIBVNCSERVER_HAVE_SASL\n      case rfbVeNCryptX509SASL:\n      case rfbVeNCryptTLSSASL:\n        if (!HandleSASLAuth(client)) return FALSE;\n        break;\n#endif /* LIBVNCSERVER_HAVE_SASL */\n\n      default:\n        rfbClientLog(\"Unknown sub authentication scheme from VNC server: %d\\n\",\n            client->subAuthScheme);\n        return FALSE;\n    }\n\n    break;\n\n  default:\n    {\n      rfbBool authHandled=FALSE;\n      rfbClientProtocolExtension* e;\n      for (e = rfbClientExtensions; e; e = e->next) {\n        uint32_t const* secType;\n        if (!e->handleAuthentication) continue;\n        for (secType = e->securityTypes; secType && *secType; secType++) {\n          if (authScheme==*secType) {\n            if (!e->handleAuthentication(client, authScheme)) return FALSE;\n            if (!rfbHandleAuthResult(client)) return FALSE;\n            authHandled=TRUE;\n          }\n        }\n      }\n      if (authHandled) break;\n    }\n    rfbClientLog(\"Unknown authentication scheme from VNC server: %d\\n\",\n\t    (int)authScheme);\n    return FALSE;\n  }\n\n  ci.shared = (client->appData.shareDesktop ? 1 : 0);\n\n  if (!WriteToRFBServer(client,  (char *)&ci, sz_rfbClientInitMsg)) return FALSE;\n\n  if (!ReadFromRFBServer(client, (char *)&client->si, sz_rfbServerInitMsg)) return FALSE;\n\n  client->si.framebufferWidth = rfbClientSwap16IfLE(client->si.framebufferWidth);\n  client->si.framebufferHeight = rfbClientSwap16IfLE(client->si.framebufferHeight);\n  client->si.format.redMax = rfbClientSwap16IfLE(client->si.format.redMax);\n  client->si.format.greenMax = rfbClientSwap16IfLE(client->si.format.greenMax);\n  client->si.format.blueMax = rfbClientSwap16IfLE(client->si.format.blueMax);\n  client->si.nameLength = rfbClientSwap32IfLE(client->si.nameLength);\n\n  /* To guard against integer wrap-around, si.nameLength is cast to 64 bit */\n  client->desktopName = malloc((uint64_t)client->si.nameLength + 1);\n  if (!client->desktopName) {\n    rfbClientLog(\"Error allocating memory for desktop name, %lu bytes\\n\",\n            (unsigned long)client->si.nameLength);\n    return FALSE;\n  }\n\n  if (!ReadFromRFBServer(client, client->desktopName, client->si.nameLength)) return FALSE;\n\n  client->desktopName[client->si.nameLength] = 0;\n\n  rfbClientLog(\"Desktop name \\\"%s\\\"\\n\",client->desktopName);\n\n  rfbClientLog(\"Connected to VNC server, using protocol version %d.%d\\n\",\n\t  client->major, client->minor);\n\n  rfbClientLog(\"VNC server default format:\\n\");\n  PrintPixelFormat(&client->si.format);\n\n  return TRUE;\n}", "func_src_after": "InitialiseRFBConnection(rfbClient* client)\n{\n  rfbProtocolVersionMsg pv;\n  int major,minor;\n  uint32_t authScheme;\n  uint32_t subAuthScheme;\n  rfbClientInitMsg ci;\n\n  /* if the connection is immediately closed, don't report anything, so\n       that pmw's monitor can make test connections */\n\n  if (client->listenSpecified)\n    errorMessageOnReadFailure = FALSE;\n\n  if (!ReadFromRFBServer(client, pv, sz_rfbProtocolVersionMsg)) return FALSE;\n  pv[sz_rfbProtocolVersionMsg]=0;\n\n  errorMessageOnReadFailure = TRUE;\n\n  pv[sz_rfbProtocolVersionMsg] = 0;\n\n  if (sscanf(pv,rfbProtocolVersionFormat,&major,&minor) != 2) {\n    rfbClientLog(\"Not a valid VNC server (%s)\\n\",pv);\n    return FALSE;\n  }\n\n\n  DefaultSupportedMessages(client);\n  client->major = major;\n  client->minor = minor;\n\n  /* fall back to viewer supported version */\n  if ((major==rfbProtocolMajorVersion) && (minor>rfbProtocolMinorVersion))\n    client->minor = rfbProtocolMinorVersion;\n\n  /* UltraVNC uses minor codes 4 and 6 for the server */\n  if (major==3 && (minor==4 || minor==6)) {\n      rfbClientLog(\"UltraVNC server detected, enabling UltraVNC specific messages\\n\",pv);\n      DefaultSupportedMessagesUltraVNC(client);\n  }\n\n  /* UltraVNC Single Click uses minor codes 14 and 16 for the server */\n  if (major==3 && (minor==14 || minor==16)) {\n     minor = minor - 10;\n     client->minor = minor;\n     rfbClientLog(\"UltraVNC Single Click server detected, enabling UltraVNC specific messages\\n\",pv);\n     DefaultSupportedMessagesUltraVNC(client);\n  }\n\n  /* TightVNC uses minor codes 5 for the server */\n  if (major==3 && minor==5) {\n      rfbClientLog(\"TightVNC server detected, enabling TightVNC specific messages\\n\",pv);\n      DefaultSupportedMessagesTightVNC(client);\n  }\n\n  /* we do not support > RFB3.8 */\n  if ((major==3 && minor>8) || major>3)\n  {\n    client->major=3;\n    client->minor=8;\n  }\n\n  rfbClientLog(\"VNC server supports protocol version %d.%d (viewer %d.%d)\\n\",\n\t  major, minor, rfbProtocolMajorVersion, rfbProtocolMinorVersion);\n\n  sprintf(pv,rfbProtocolVersionFormat,client->major,client->minor);\n\n  if (!WriteToRFBServer(client, pv, sz_rfbProtocolVersionMsg)) return FALSE;\n\n\n  /* 3.7 and onwards sends a # of security types first */\n  if (client->major==3 && client->minor > 6)\n  {\n    if (!ReadSupportedSecurityType(client, &authScheme, FALSE)) return FALSE;\n  }\n  else\n  {\n    if (!ReadFromRFBServer(client, (char *)&authScheme, 4)) return FALSE;\n    authScheme = rfbClientSwap32IfLE(authScheme);\n  }\n  \n  rfbClientLog(\"Selected Security Scheme %d\\n\", authScheme);\n  client->authScheme = authScheme;\n  \n  switch (authScheme) {\n\n  case rfbConnFailed:\n    ReadReason(client);\n    return FALSE;\n\n  case rfbNoAuth:\n    rfbClientLog(\"No authentication needed\\n\");\n\n    /* 3.8 and upwards sends a Security Result for rfbNoAuth */\n    if ((client->major==3 && client->minor > 7) || client->major>3)\n        if (!rfbHandleAuthResult(client)) return FALSE;        \n\n    break;\n\n  case rfbVncAuth:\n    if (!HandleVncAuth(client)) return FALSE;\n    break;\n\n#ifdef LIBVNCSERVER_HAVE_SASL\n  case rfbSASL:\n    if (!HandleSASLAuth(client)) return FALSE;\n    break;\n#endif /* LIBVNCSERVER_HAVE_SASL */\n\n  case rfbMSLogon:\n    if (!HandleMSLogonAuth(client)) return FALSE;\n    break;\n\n  case rfbARD:\n#ifndef LIBVNCSERVER_WITH_CLIENT_GCRYPT\n    rfbClientLog(\"GCrypt support was not compiled in\\n\");\n    return FALSE;\n#else\n    if (!HandleARDAuth(client)) return FALSE;\n#endif\n    break;\n\n  case rfbTLS:\n    if (!HandleAnonTLSAuth(client)) return FALSE;\n    /* After the TLS session is established, sub auth types are expected.\n     * Note that all following reading/writing are through the TLS session from here.\n     */\n    if (!ReadSupportedSecurityType(client, &subAuthScheme, TRUE)) return FALSE;\n    client->subAuthScheme = subAuthScheme;\n\n    switch (subAuthScheme) {\n\n      case rfbConnFailed:\n        ReadReason(client);\n        return FALSE;\n\n      case rfbNoAuth:\n        rfbClientLog(\"No sub authentication needed\\n\");\n        /* 3.8 and upwards sends a Security Result for rfbNoAuth */\n        if ((client->major==3 && client->minor > 7) || client->major>3)\n            if (!rfbHandleAuthResult(client)) return FALSE;\n        break;\n\n      case rfbVncAuth:\n        if (!HandleVncAuth(client)) return FALSE;\n        break;\n\n#ifdef LIBVNCSERVER_HAVE_SASL\n      case rfbSASL:\n        if (!HandleSASLAuth(client)) return FALSE;\n        break;\n#endif /* LIBVNCSERVER_HAVE_SASL */\n\n      default:\n        rfbClientLog(\"Unknown sub authentication scheme from VNC server: %d\\n\",\n            (int)subAuthScheme);\n        return FALSE;\n    }\n\n    break;\n\n  case rfbVeNCrypt:\n    if (!HandleVeNCryptAuth(client)) return FALSE;\n\n    switch (client->subAuthScheme) {\n\n      case rfbVeNCryptTLSNone:\n      case rfbVeNCryptX509None:\n        rfbClientLog(\"No sub authentication needed\\n\");\n        if (!rfbHandleAuthResult(client)) return FALSE;\n        break;\n\n      case rfbVeNCryptTLSVNC:\n      case rfbVeNCryptX509VNC:\n        if (!HandleVncAuth(client)) return FALSE;\n        break;\n\n      case rfbVeNCryptTLSPlain:\n      case rfbVeNCryptX509Plain:\n        if (!HandlePlainAuth(client)) return FALSE;\n        break;\n\n#ifdef LIBVNCSERVER_HAVE_SASL\n      case rfbVeNCryptX509SASL:\n      case rfbVeNCryptTLSSASL:\n        if (!HandleSASLAuth(client)) return FALSE;\n        break;\n#endif /* LIBVNCSERVER_HAVE_SASL */\n\n      default:\n        rfbClientLog(\"Unknown sub authentication scheme from VNC server: %d\\n\",\n            client->subAuthScheme);\n        return FALSE;\n    }\n\n    break;\n\n  default:\n    {\n      rfbBool authHandled=FALSE;\n      rfbClientProtocolExtension* e;\n      for (e = rfbClientExtensions; e; e = e->next) {\n        uint32_t const* secType;\n        if (!e->handleAuthentication) continue;\n        for (secType = e->securityTypes; secType && *secType; secType++) {\n          if (authScheme==*secType) {\n            if (!e->handleAuthentication(client, authScheme)) return FALSE;\n            if (!rfbHandleAuthResult(client)) return FALSE;\n            authHandled=TRUE;\n          }\n        }\n      }\n      if (authHandled) break;\n    }\n    rfbClientLog(\"Unknown authentication scheme from VNC server: %d\\n\",\n\t    (int)authScheme);\n    return FALSE;\n  }\n\n  ci.shared = (client->appData.shareDesktop ? 1 : 0);\n\n  if (!WriteToRFBServer(client,  (char *)&ci, sz_rfbClientInitMsg)) return FALSE;\n\n  if (!ReadFromRFBServer(client, (char *)&client->si, sz_rfbServerInitMsg)) return FALSE;\n\n  client->si.framebufferWidth = rfbClientSwap16IfLE(client->si.framebufferWidth);\n  client->si.framebufferHeight = rfbClientSwap16IfLE(client->si.framebufferHeight);\n  client->si.format.redMax = rfbClientSwap16IfLE(client->si.format.redMax);\n  client->si.format.greenMax = rfbClientSwap16IfLE(client->si.format.greenMax);\n  client->si.format.blueMax = rfbClientSwap16IfLE(client->si.format.blueMax);\n  client->si.nameLength = rfbClientSwap32IfLE(client->si.nameLength);\n\n  if (client->si.nameLength > 1<<20) {\n      rfbClientErr(\"Too big desktop name length sent by server: %u B > 1 MB\\n\", (unsigned int)client->si.nameLength);\n      return FALSE;\n  }\n\n  client->desktopName = malloc(client->si.nameLength + 1);\n  if (!client->desktopName) {\n    rfbClientLog(\"Error allocating memory for desktop name, %lu bytes\\n\",\n            (unsigned long)client->si.nameLength);\n    return FALSE;\n  }\n\n  if (!ReadFromRFBServer(client, client->desktopName, client->si.nameLength)) return FALSE;\n\n  client->desktopName[client->si.nameLength] = 0;\n\n  rfbClientLog(\"Desktop name \\\"%s\\\"\\n\",client->desktopName);\n\n  rfbClientLog(\"Connected to VNC server, using protocol version %d.%d\\n\",\n\t  client->major, client->minor);\n\n  rfbClientLog(\"VNC server default format:\\n\");\n  PrintPixelFormat(&client->si.format);\n\n  return TRUE;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/c2c4b81e6cb3b485fb1ec7ba9e7defeb889f6ba7", "file_name": "libvncclient/rfbproto.c", "vul_type": "cwe-787", "description": "Write a C function to initialize a connection to a VNC server using the RFB protocol."}
{"func_name": "cdf_read_property_info", "func_src_before": "cdf_read_property_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    uint32_t offs, cdf_property_info_t **info, size_t *count, size_t *maxcount)\n{\n\tconst cdf_section_header_t *shp;\n\tcdf_section_header_t sh;\n\tconst uint8_t *p, *q, *e;\n\tsize_t i, o4, nelements, j, slen, left;\n\tcdf_property_info_t *inp;\n\n\tif (offs > UINT32_MAX / 4) {\n\t\terrno = EFTYPE;\n\t\tgoto out;\n\t}\n\tshp = CAST(const cdf_section_header_t *,\n\t    cdf_offset(sst->sst_tab, offs));\n\tif (cdf_check_stream_offset(sst, h, shp, sizeof(*shp), __LINE__) == -1)\n\t\tgoto out;\n\tsh.sh_len = CDF_TOLE4(shp->sh_len);\n\tif (sh.sh_len > CDF_SHLEN_LIMIT) {\n\t\terrno = EFTYPE;\n\t\tgoto out;\n\t}\n\n\tif (cdf_check_stream_offset(sst, h, shp, sh.sh_len, __LINE__) == -1)\n\t\tgoto out;\n\n\tsh.sh_properties = CDF_TOLE4(shp->sh_properties);\n\tDPRINTF((\"section len: %u properties %u\\n\", sh.sh_len,\n\t    sh.sh_properties));\n\tif (sh.sh_properties > CDF_PROP_LIMIT)\n\t\tgoto out;\n\tinp = cdf_grow_info(info, maxcount, sh.sh_properties);\n\tif (inp == NULL)\n\t\tgoto out;\n\tinp += *count;\n\t*count += sh.sh_properties;\n\tp = CAST(const uint8_t *, cdf_offset(sst->sst_tab, offs + sizeof(sh)));\n\te = CAST(const uint8_t *, cdf_offset(shp, sh.sh_len));\n\tif (p >= e || cdf_check_stream_offset(sst, h, e, 0, __LINE__) == -1)\n\t\tgoto out;\n\n\tfor (i = 0; i < sh.sh_properties; i++) {\n\t\tif ((q = cdf_get_property_info_pos(sst, h, p, e, i)) == NULL)\n\t\t\tgoto out;\n\t\tinp[i].pi_id = CDF_GETUINT32(p, i << 1);\n\t\tleft = CAST(size_t, e - q);\n\t\tif (left < sizeof(uint32_t)) {\n\t\t\tDPRINTF((\"short info (no type)_\\n\"));\n\t\t\tgoto out;\n\t\t}\n\t\tinp[i].pi_type = CDF_GETUINT32(q, 0);\n\t\tDPRINTF((\"%\" SIZE_T_FORMAT \"u) id=%#x type=%#x offs=%#tx,%#x\\n\",\n\t\t    i, inp[i].pi_id, inp[i].pi_type, q - p, offs));\n\t\tif (inp[i].pi_type & CDF_VECTOR) {\n\t\t\tif (left < sizeof(uint32_t) * 2) {\n\t\t\t\tDPRINTF((\"missing CDF_VECTOR length\\n\"));\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tnelements = CDF_GETUINT32(q, 1);\n\t\t\tif (nelements == 0) {\n\t\t\t\tDPRINTF((\"CDF_VECTOR with nelements == 0\\n\"));\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tslen = 2;\n\t\t} else {\n\t\t\tnelements = 1;\n\t\t\tslen = 1;\n\t\t}\n\t\to4 = slen * sizeof(uint32_t);\n\t\tif (inp[i].pi_type & (CDF_ARRAY|CDF_BYREF|CDF_RESERVED))\n\t\t\tgoto unknown;\n\t\tswitch (inp[i].pi_type & CDF_TYPEMASK) {\n\t\tcase CDF_NULL:\n\t\tcase CDF_EMPTY:\n\t\t\tbreak;\n\t\tcase CDF_SIGNED16:\n\t\t\tif (!cdf_copy_info(&inp[i], &q[o4], e, sizeof(int16_t)))\n\t\t\t\tgoto unknown;\n\t\t\tbreak;\n\t\tcase CDF_SIGNED32:\n\t\tcase CDF_BOOL:\n\t\tcase CDF_UNSIGNED32:\n\t\tcase CDF_FLOAT:\n\t\t\tif (!cdf_copy_info(&inp[i], &q[o4], e, sizeof(int32_t)))\n\t\t\t\tgoto unknown;\n\t\t\tbreak;\n\t\tcase CDF_SIGNED64:\n\t\tcase CDF_UNSIGNED64:\n\t\tcase CDF_DOUBLE:\n\t\tcase CDF_FILETIME:\n\t\t\tif (!cdf_copy_info(&inp[i], &q[o4], e, sizeof(int64_t)))\n\t\t\t\tgoto unknown;\n\t\t\tbreak;\n\t\tcase CDF_LENGTH32_STRING:\n\t\tcase CDF_LENGTH32_WSTRING:\n\t\t\tif (nelements > 1) {\n\t\t\t\tsize_t nelem = inp - *info;\n\t\t\t\tinp = cdf_grow_info(info, maxcount, nelements);\n\t\t\t\tif (inp == NULL)\n\t\t\t\t\tgoto out;\n\t\t\t\tinp += nelem;\n\t\t\t}\n\t\t\tDPRINTF((\"nelements = %\" SIZE_T_FORMAT \"u\\n\",\n\t\t\t    nelements));\n\t\t\tfor (j = 0; j < nelements && i < sh.sh_properties;\n\t\t\t    j++, i++)\n\t\t\t{\n\t\t\t\tuint32_t l;\n\n\t\t\t\tif (o4 + sizeof(uint32_t) > left)\n\t\t\t\t\tgoto out;\n\n\t\t\t\tl = CDF_GETUINT32(q, slen);\n\t\t\t\to4 += sizeof(uint32_t);\n\t\t\t\tif (o4 + l > left)\n\t\t\t\t\tgoto out;\n\n\t\t\t\tinp[i].pi_str.s_len = l;\n\t\t\t\tinp[i].pi_str.s_buf = CAST(const char *,\n\t\t\t\t    CAST(const void *, &q[o4]));\n\n\t\t\t\tDPRINTF((\"o=%\" SIZE_T_FORMAT \"u l=%d(%\"\n\t\t\t\t    SIZE_T_FORMAT \"u), t=%\" SIZE_T_FORMAT\n\t\t\t\t    \"u s=%s\\n\", o4, l, CDF_ROUND(l, sizeof(l)),\n\t\t\t\t    left, inp[i].pi_str.s_buf));\n\n\t\t\t\tif (l & 1)\n\t\t\t\t\tl++;\n\n\t\t\t\tslen += l >> 1;\n\t\t\t\to4 = slen * sizeof(uint32_t);\n\t\t\t}\n\t\t\ti--;\n\t\t\tbreak;\n\t\tcase CDF_CLIPBOARD:\n\t\t\tif (inp[i].pi_type & CDF_VECTOR)\n\t\t\t\tgoto unknown;\n\t\t\tbreak;\n\t\tdefault:\n\t\tunknown:\n\t\t\tmemset(&inp[i].pi_val, 0, sizeof(inp[i].pi_val));\n\t\t\tDPRINTF((\"Don't know how to deal with %#x\\n\",\n\t\t\t    inp[i].pi_type));\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn 0;\nout:\n\tfree(*info);\n\t*info = NULL;\n\t*count = 0;\n\t*maxcount = 0;\n\terrno = EFTYPE;\n\treturn -1;\n}", "func_src_after": "cdf_read_property_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    uint32_t offs, cdf_property_info_t **info, size_t *count, size_t *maxcount)\n{\n\tconst cdf_section_header_t *shp;\n\tcdf_section_header_t sh;\n\tconst uint8_t *p, *q, *e;\n\tsize_t i, o4, nelements, j, slen, left;\n\tcdf_property_info_t *inp;\n\n\tif (offs > UINT32_MAX / 4) {\n\t\terrno = EFTYPE;\n\t\tgoto out;\n\t}\n\tshp = CAST(const cdf_section_header_t *,\n\t    cdf_offset(sst->sst_tab, offs));\n\tif (cdf_check_stream_offset(sst, h, shp, sizeof(*shp), __LINE__) == -1)\n\t\tgoto out;\n\tsh.sh_len = CDF_TOLE4(shp->sh_len);\n\tif (sh.sh_len > CDF_SHLEN_LIMIT) {\n\t\terrno = EFTYPE;\n\t\tgoto out;\n\t}\n\n\tif (cdf_check_stream_offset(sst, h, shp, sh.sh_len, __LINE__) == -1)\n\t\tgoto out;\n\n\tsh.sh_properties = CDF_TOLE4(shp->sh_properties);\n\tDPRINTF((\"section len: %u properties %u\\n\", sh.sh_len,\n\t    sh.sh_properties));\n\tif (sh.sh_properties > CDF_PROP_LIMIT)\n\t\tgoto out;\n\tinp = cdf_grow_info(info, maxcount, sh.sh_properties);\n\tif (inp == NULL)\n\t\tgoto out;\n\tinp += *count;\n\t*count += sh.sh_properties;\n\tp = CAST(const uint8_t *, cdf_offset(sst->sst_tab, offs + sizeof(sh)));\n\te = CAST(const uint8_t *, cdf_offset(shp, sh.sh_len));\n\tif (p >= e || cdf_check_stream_offset(sst, h, e, 0, __LINE__) == -1)\n\t\tgoto out;\n\n\tfor (i = 0; i < sh.sh_properties; i++) {\n\t\tif ((q = cdf_get_property_info_pos(sst, h, p, e, i)) == NULL)\n\t\t\tgoto out;\n\t\tinp[i].pi_id = CDF_GETUINT32(p, i << 1);\n\t\tleft = CAST(size_t, e - q);\n\t\tif (left < sizeof(uint32_t)) {\n\t\t\tDPRINTF((\"short info (no type)_\\n\"));\n\t\t\tgoto out;\n\t\t}\n\t\tinp[i].pi_type = CDF_GETUINT32(q, 0);\n\t\tDPRINTF((\"%\" SIZE_T_FORMAT \"u) id=%#x type=%#x offs=%#tx,%#x\\n\",\n\t\t    i, inp[i].pi_id, inp[i].pi_type, q - p, offs));\n\t\tif (inp[i].pi_type & CDF_VECTOR) {\n\t\t\tif (left < sizeof(uint32_t) * 2) {\n\t\t\t\tDPRINTF((\"missing CDF_VECTOR length\\n\"));\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tnelements = CDF_GETUINT32(q, 1);\n\t\t\tif (nelements > CDF_ELEMENT_LIMIT || nelements == 0) {\n\t\t\t\tDPRINTF((\"CDF_VECTOR with nelements == %\"\n\t\t\t\t    SIZE_T_FORMAT \"u\\n\", nelements));\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tslen = 2;\n\t\t} else {\n\t\t\tnelements = 1;\n\t\t\tslen = 1;\n\t\t}\n\t\to4 = slen * sizeof(uint32_t);\n\t\tif (inp[i].pi_type & (CDF_ARRAY|CDF_BYREF|CDF_RESERVED))\n\t\t\tgoto unknown;\n\t\tswitch (inp[i].pi_type & CDF_TYPEMASK) {\n\t\tcase CDF_NULL:\n\t\tcase CDF_EMPTY:\n\t\t\tbreak;\n\t\tcase CDF_SIGNED16:\n\t\t\tif (!cdf_copy_info(&inp[i], &q[o4], e, sizeof(int16_t)))\n\t\t\t\tgoto unknown;\n\t\t\tbreak;\n\t\tcase CDF_SIGNED32:\n\t\tcase CDF_BOOL:\n\t\tcase CDF_UNSIGNED32:\n\t\tcase CDF_FLOAT:\n\t\t\tif (!cdf_copy_info(&inp[i], &q[o4], e, sizeof(int32_t)))\n\t\t\t\tgoto unknown;\n\t\t\tbreak;\n\t\tcase CDF_SIGNED64:\n\t\tcase CDF_UNSIGNED64:\n\t\tcase CDF_DOUBLE:\n\t\tcase CDF_FILETIME:\n\t\t\tif (!cdf_copy_info(&inp[i], &q[o4], e, sizeof(int64_t)))\n\t\t\t\tgoto unknown;\n\t\t\tbreak;\n\t\tcase CDF_LENGTH32_STRING:\n\t\tcase CDF_LENGTH32_WSTRING:\n\t\t\tif (nelements > 1) {\n\t\t\t\tsize_t nelem = inp - *info;\n\t\t\t\tinp = cdf_grow_info(info, maxcount, nelements);\n\t\t\t\tif (inp == NULL)\n\t\t\t\t\tgoto out;\n\t\t\t\tinp += nelem;\n\t\t\t}\n\t\t\tfor (j = 0; j < nelements && i < sh.sh_properties;\n\t\t\t    j++, i++)\n\t\t\t{\n\t\t\t\tuint32_t l;\n\n\t\t\t\tif (o4 + sizeof(uint32_t) > left)\n\t\t\t\t\tgoto out;\n\n\t\t\t\tl = CDF_GETUINT32(q, slen);\n\t\t\t\to4 += sizeof(uint32_t);\n\t\t\t\tif (o4 + l > left)\n\t\t\t\t\tgoto out;\n\n\t\t\t\tinp[i].pi_str.s_len = l;\n\t\t\t\tinp[i].pi_str.s_buf = CAST(const char *,\n\t\t\t\t    CAST(const void *, &q[o4]));\n\n\t\t\t\tDPRINTF((\"o=%\" SIZE_T_FORMAT \"u l=%d(%\"\n\t\t\t\t    SIZE_T_FORMAT \"u), t=%\" SIZE_T_FORMAT\n\t\t\t\t    \"u s=%s\\n\", o4, l, CDF_ROUND(l, sizeof(l)),\n\t\t\t\t    left, inp[i].pi_str.s_buf));\n\n\t\t\t\tif (l & 1)\n\t\t\t\t\tl++;\n\n\t\t\t\tslen += l >> 1;\n\t\t\t\to4 = slen * sizeof(uint32_t);\n\t\t\t}\n\t\t\ti--;\n\t\t\tbreak;\n\t\tcase CDF_CLIPBOARD:\n\t\t\tif (inp[i].pi_type & CDF_VECTOR)\n\t\t\t\tgoto unknown;\n\t\t\tbreak;\n\t\tdefault:\n\t\tunknown:\n\t\t\tmemset(&inp[i].pi_val, 0, sizeof(inp[i].pi_val));\n\t\t\tDPRINTF((\"Don't know how to deal with %#x\\n\",\n\t\t\t    inp[i].pi_type));\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn 0;\nout:\n\tfree(*info);\n\t*info = NULL;\n\t*count = 0;\n\t*maxcount = 0;\n\terrno = EFTYPE;\n\treturn -1;\n}", "commit_link": "github.com/file/file/commit/46a8443f76cec4b41ec736eca396984c74664f84", "file_name": "src/cdf.c", "vul_type": "cwe-787", "description": "Write a C function to read property information from a compound file binary format stream."}
{"func_name": "pgxtoimage", "func_src_before": "opj_image_t* pgxtoimage(const char *filename, opj_cparameters_t *parameters)\n{\n    FILE *f = NULL;\n    int w, h, prec;\n    int i, numcomps, max;\n    OPJ_COLOR_SPACE color_space;\n    opj_image_cmptparm_t cmptparm;  /* maximum of 1 component  */\n    opj_image_t * image = NULL;\n    int adjustS, ushift, dshift, force8;\n\n    char endian1, endian2, sign;\n    char signtmp[32];\n\n    char temp[32];\n    int bigendian;\n    opj_image_comp_t *comp = NULL;\n\n    numcomps = 1;\n    color_space = OPJ_CLRSPC_GRAY;\n\n    memset(&cmptparm, 0, sizeof(opj_image_cmptparm_t));\n\n    max = 0;\n\n    f = fopen(filename, \"rb\");\n    if (!f) {\n        fprintf(stderr, \"Failed to open %s for reading !\\n\", filename);\n        return NULL;\n    }\n\n    fseek(f, 0, SEEK_SET);\n    if (fscanf(f, \"PG%[ \\t]%c%c%[ \\t+-]%d%[ \\t]%d%[ \\t]%d\", temp, &endian1,\n               &endian2, signtmp, &prec, temp, &w, temp, &h) != 9) {\n        fclose(f);\n        fprintf(stderr,\n                \"ERROR: Failed to read the right number of element from the fscanf() function!\\n\");\n        return NULL;\n    }\n\n    i = 0;\n    sign = '+';\n    while (signtmp[i] != '\\0') {\n        if (signtmp[i] == '-') {\n            sign = '-';\n        }\n        i++;\n    }\n\n    fgetc(f);\n    if (endian1 == 'M' && endian2 == 'L') {\n        bigendian = 1;\n    } else if (endian2 == 'M' && endian1 == 'L') {\n        bigendian = 0;\n    } else {\n        fclose(f);\n        fprintf(stderr, \"Bad pgx header, please check input file\\n\");\n        return NULL;\n    }\n\n    /* initialize image component */\n\n    cmptparm.x0 = (OPJ_UINT32)parameters->image_offset_x0;\n    cmptparm.y0 = (OPJ_UINT32)parameters->image_offset_y0;\n    cmptparm.w = !cmptparm.x0 ? (OPJ_UINT32)((w - 1) * parameters->subsampling_dx +\n                 1) : cmptparm.x0 + (OPJ_UINT32)(w - 1) * (OPJ_UINT32)parameters->subsampling_dx\n                 + 1;\n    cmptparm.h = !cmptparm.y0 ? (OPJ_UINT32)((h - 1) * parameters->subsampling_dy +\n                 1) : cmptparm.y0 + (OPJ_UINT32)(h - 1) * (OPJ_UINT32)parameters->subsampling_dy\n                 + 1;\n\n    if (sign == '-') {\n        cmptparm.sgnd = 1;\n    } else {\n        cmptparm.sgnd = 0;\n    }\n    if (prec < 8) {\n        force8 = 1;\n        ushift = 8 - prec;\n        dshift = prec - ushift;\n        if (cmptparm.sgnd) {\n            adjustS = (1 << (prec - 1));\n        } else {\n            adjustS = 0;\n        }\n        cmptparm.sgnd = 0;\n        prec = 8;\n    } else {\n        ushift = dshift = force8 = adjustS = 0;\n    }\n\n    cmptparm.prec = (OPJ_UINT32)prec;\n    cmptparm.bpp = (OPJ_UINT32)prec;\n    cmptparm.dx = (OPJ_UINT32)parameters->subsampling_dx;\n    cmptparm.dy = (OPJ_UINT32)parameters->subsampling_dy;\n\n    /* create the image */\n    image = opj_image_create((OPJ_UINT32)numcomps, &cmptparm, color_space);\n    if (!image) {\n        fclose(f);\n        return NULL;\n    }\n    /* set image offset and reference grid */\n    image->x0 = cmptparm.x0;\n    image->y0 = cmptparm.x0;\n    image->x1 = cmptparm.w;\n    image->y1 = cmptparm.h;\n\n    /* set image data */\n\n    comp = &image->comps[0];\n\n    for (i = 0; i < w * h; i++) {\n        int v;\n        if (force8) {\n            v = readuchar(f) + adjustS;\n            v = (v << ushift) + (v >> dshift);\n            comp->data[i] = (unsigned char)v;\n\n            if (v > max) {\n                max = v;\n            }\n\n            continue;\n        }\n        if (comp->prec == 8) {\n            if (!comp->sgnd) {\n                v = readuchar(f);\n            } else {\n                v = (char) readuchar(f);\n            }\n        } else if (comp->prec <= 16) {\n            if (!comp->sgnd) {\n                v = readushort(f, bigendian);\n            } else {\n                v = (short) readushort(f, bigendian);\n            }\n        } else {\n            if (!comp->sgnd) {\n                v = (int)readuint(f, bigendian);\n            } else {\n                v = (int) readuint(f, bigendian);\n            }\n        }\n        if (v > max) {\n            max = v;\n        }\n        comp->data[i] = v;\n    }\n    fclose(f);\n    comp->bpp = (OPJ_UINT32)int_floorlog2(max) + 1;\n\n    return image;\n}", "func_src_after": "opj_image_t* pgxtoimage(const char *filename, opj_cparameters_t *parameters)\n{\n    FILE *f = NULL;\n    int w, h, prec;\n    int i, numcomps, max;\n    OPJ_COLOR_SPACE color_space;\n    opj_image_cmptparm_t cmptparm;  /* maximum of 1 component  */\n    opj_image_t * image = NULL;\n    int adjustS, ushift, dshift, force8;\n\n    char endian1, endian2, sign;\n    char signtmp[32];\n\n    char temp[32];\n    int bigendian;\n    opj_image_comp_t *comp = NULL;\n\n    numcomps = 1;\n    color_space = OPJ_CLRSPC_GRAY;\n\n    memset(&cmptparm, 0, sizeof(opj_image_cmptparm_t));\n\n    max = 0;\n\n    f = fopen(filename, \"rb\");\n    if (!f) {\n        fprintf(stderr, \"Failed to open %s for reading !\\n\", filename);\n        return NULL;\n    }\n\n    fseek(f, 0, SEEK_SET);\n    if (fscanf(f, \"PG%31[ \\t]%c%c%31[ \\t+-]%d%31[ \\t]%d%31[ \\t]%d\", temp, &endian1,\n               &endian2, signtmp, &prec, temp, &w, temp, &h) != 9) {\n        fclose(f);\n        fprintf(stderr,\n                \"ERROR: Failed to read the right number of element from the fscanf() function!\\n\");\n        return NULL;\n    }\n\n    i = 0;\n    sign = '+';\n    while (signtmp[i] != '\\0') {\n        if (signtmp[i] == '-') {\n            sign = '-';\n        }\n        i++;\n    }\n\n    fgetc(f);\n    if (endian1 == 'M' && endian2 == 'L') {\n        bigendian = 1;\n    } else if (endian2 == 'M' && endian1 == 'L') {\n        bigendian = 0;\n    } else {\n        fclose(f);\n        fprintf(stderr, \"Bad pgx header, please check input file\\n\");\n        return NULL;\n    }\n\n    /* initialize image component */\n\n    cmptparm.x0 = (OPJ_UINT32)parameters->image_offset_x0;\n    cmptparm.y0 = (OPJ_UINT32)parameters->image_offset_y0;\n    cmptparm.w = !cmptparm.x0 ? (OPJ_UINT32)((w - 1) * parameters->subsampling_dx +\n                 1) : cmptparm.x0 + (OPJ_UINT32)(w - 1) * (OPJ_UINT32)parameters->subsampling_dx\n                 + 1;\n    cmptparm.h = !cmptparm.y0 ? (OPJ_UINT32)((h - 1) * parameters->subsampling_dy +\n                 1) : cmptparm.y0 + (OPJ_UINT32)(h - 1) * (OPJ_UINT32)parameters->subsampling_dy\n                 + 1;\n\n    if (sign == '-') {\n        cmptparm.sgnd = 1;\n    } else {\n        cmptparm.sgnd = 0;\n    }\n    if (prec < 8) {\n        force8 = 1;\n        ushift = 8 - prec;\n        dshift = prec - ushift;\n        if (cmptparm.sgnd) {\n            adjustS = (1 << (prec - 1));\n        } else {\n            adjustS = 0;\n        }\n        cmptparm.sgnd = 0;\n        prec = 8;\n    } else {\n        ushift = dshift = force8 = adjustS = 0;\n    }\n\n    cmptparm.prec = (OPJ_UINT32)prec;\n    cmptparm.bpp = (OPJ_UINT32)prec;\n    cmptparm.dx = (OPJ_UINT32)parameters->subsampling_dx;\n    cmptparm.dy = (OPJ_UINT32)parameters->subsampling_dy;\n\n    /* create the image */\n    image = opj_image_create((OPJ_UINT32)numcomps, &cmptparm, color_space);\n    if (!image) {\n        fclose(f);\n        return NULL;\n    }\n    /* set image offset and reference grid */\n    image->x0 = cmptparm.x0;\n    image->y0 = cmptparm.x0;\n    image->x1 = cmptparm.w;\n    image->y1 = cmptparm.h;\n\n    /* set image data */\n\n    comp = &image->comps[0];\n\n    for (i = 0; i < w * h; i++) {\n        int v;\n        if (force8) {\n            v = readuchar(f) + adjustS;\n            v = (v << ushift) + (v >> dshift);\n            comp->data[i] = (unsigned char)v;\n\n            if (v > max) {\n                max = v;\n            }\n\n            continue;\n        }\n        if (comp->prec == 8) {\n            if (!comp->sgnd) {\n                v = readuchar(f);\n            } else {\n                v = (char) readuchar(f);\n            }\n        } else if (comp->prec <= 16) {\n            if (!comp->sgnd) {\n                v = readushort(f, bigendian);\n            } else {\n                v = (short) readushort(f, bigendian);\n            }\n        } else {\n            if (!comp->sgnd) {\n                v = (int)readuint(f, bigendian);\n            } else {\n                v = (int) readuint(f, bigendian);\n            }\n        }\n        if (v > max) {\n            max = v;\n        }\n        comp->data[i] = v;\n    }\n    fclose(f);\n    comp->bpp = (OPJ_UINT32)int_floorlog2(max) + 1;\n\n    return image;\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/e5285319229a5d77bf316bb0d3a6cbd3cb8666d9", "file_name": "src/bin/jp2/convert.c", "vul_type": "cwe-787", "description": "Write a C function named `pgxtoimage` that converts a PGX file to an OpenJPEG image structure, taking a filename and decoding parameters as arguments."}
{"func_name": "S_study_chunk", "func_src_before": "STATIC SSize_t\nS_study_chunk(pTHX_ RExC_state_t *pRExC_state, regnode **scanp,\n                        SSize_t *minlenp, SSize_t *deltap,\n\t\t\tregnode *last,\n\t\t\tscan_data_t *data,\n\t\t\tI32 stopparen,\n                        U32 recursed_depth,\n\t\t\tregnode_ssc *and_withp,\n\t\t\tU32 flags, U32 depth)\n\t\t\t/* scanp: Start here (read-write). */\n\t\t\t/* deltap: Write maxlen-minlen here. */\n\t\t\t/* last: Stop before this one. */\n\t\t\t/* data: string data about the pattern */\n\t\t\t/* stopparen: treat close N as END */\n\t\t\t/* recursed: which subroutines have we recursed into */\n\t\t\t/* and_withp: Valid if flags & SCF_DO_STCLASS_OR */\n{\n    dVAR;\n    /* There must be at least this number of characters to match */\n    SSize_t min = 0;\n    I32 pars = 0, code;\n    regnode *scan = *scanp, *next;\n    SSize_t delta = 0;\n    int is_inf = (flags & SCF_DO_SUBSTR) && (data->flags & SF_IS_INF);\n    int is_inf_internal = 0;\t\t/* The studied chunk is infinite */\n    I32 is_par = OP(scan) == OPEN ? ARG(scan) : 0;\n    scan_data_t data_fake;\n    SV *re_trie_maxbuff = NULL;\n    regnode *first_non_open = scan;\n    SSize_t stopmin = SSize_t_MAX;\n    scan_frame *frame = NULL;\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_STUDY_CHUNK;\n    RExC_study_started= 1;\n\n    Zero(&data_fake, 1, scan_data_t);\n\n    if ( depth == 0 ) {\n        while (first_non_open && OP(first_non_open) == OPEN)\n            first_non_open=regnext(first_non_open);\n    }\n\n\n  fake_study_recurse:\n    DEBUG_r(\n        RExC_study_chunk_recursed_count++;\n    );\n    DEBUG_OPTIMISE_MORE_r(\n    {\n        Perl_re_indentf( aTHX_  \"study_chunk stopparen=%ld recursed_count=%lu depth=%lu recursed_depth=%lu scan=%p last=%p\",\n            depth, (long)stopparen,\n            (unsigned long)RExC_study_chunk_recursed_count,\n            (unsigned long)depth, (unsigned long)recursed_depth,\n            scan,\n            last);\n        if (recursed_depth) {\n            U32 i;\n            U32 j;\n            for ( j = 0 ; j < recursed_depth ; j++ ) {\n                for ( i = 0 ; i < (U32)RExC_total_parens ; i++ ) {\n                    if (\n                        PAREN_TEST(RExC_study_chunk_recursed +\n                                   ( j * RExC_study_chunk_recursed_bytes), i )\n                        && (\n                            !j ||\n                            !PAREN_TEST(RExC_study_chunk_recursed +\n                                   (( j - 1 ) * RExC_study_chunk_recursed_bytes), i)\n                        )\n                    ) {\n                        Perl_re_printf( aTHX_ \" %d\",(int)i);\n                        break;\n                    }\n                }\n                if ( j + 1 < recursed_depth ) {\n                    Perl_re_printf( aTHX_  \",\");\n                }\n            }\n        }\n        Perl_re_printf( aTHX_ \"\\n\");\n    }\n    );\n    while ( scan && OP(scan) != END && scan < last ){\n        UV min_subtract = 0;    /* How mmany chars to subtract from the minimum\n                                   node length to get a real minimum (because\n                                   the folded version may be shorter) */\n\tbool unfolded_multi_char = FALSE;\n\t/* Peephole optimizer: */\n        DEBUG_STUDYDATA(\"Peep\", data, depth, is_inf);\n        DEBUG_PEEP(\"Peep\", scan, depth, flags);\n\n\n        /* The reason we do this here is that we need to deal with things like\n         * /(?:f)(?:o)(?:o)/ which cant be dealt with by the normal EXACT\n         * parsing code, as each (?:..) is handled by a different invocation of\n         * reg() -- Yves\n         */\n        JOIN_EXACT(scan,&min_subtract, &unfolded_multi_char, 0);\n\n\t/* Follow the next-chain of the current node and optimize\n\t   away all the NOTHINGs from it.  */\n\tif (OP(scan) != CURLYX) {\n\t    const int max = (reg_off_by_arg[OP(scan)]\n\t\t       ? I32_MAX\n\t\t       /* I32 may be smaller than U16 on CRAYs! */\n\t\t       : (I32_MAX < U16_MAX ? I32_MAX : U16_MAX));\n\t    int off = (reg_off_by_arg[OP(scan)] ? ARG(scan) : NEXT_OFF(scan));\n\t    int noff;\n\t    regnode *n = scan;\n\n\t    /* Skip NOTHING and LONGJMP. */\n\t    while ((n = regnext(n))\n\t\t   && ((PL_regkind[OP(n)] == NOTHING && (noff = NEXT_OFF(n)))\n\t\t       || ((OP(n) == LONGJMP) && (noff = ARG(n))))\n\t\t   && off + noff < max)\n\t\toff += noff;\n\t    if (reg_off_by_arg[OP(scan)])\n\t\tARG(scan) = off;\n\t    else\n\t\tNEXT_OFF(scan) = off;\n\t}\n\n\t/* The principal pseudo-switch.  Cannot be a switch, since we\n\t   look into several different things.  */\n        if ( OP(scan) == DEFINEP ) {\n            SSize_t minlen = 0;\n            SSize_t deltanext = 0;\n            SSize_t fake_last_close = 0;\n            I32 f = SCF_IN_DEFINE;\n\n            StructCopy(&zero_scan_data, &data_fake, scan_data_t);\n            scan = regnext(scan);\n            assert( OP(scan) == IFTHEN );\n            DEBUG_PEEP(\"expect IFTHEN\", scan, depth, flags);\n\n            data_fake.last_closep= &fake_last_close;\n            minlen = *minlenp;\n            next = regnext(scan);\n            scan = NEXTOPER(NEXTOPER(scan));\n            DEBUG_PEEP(\"scan\", scan, depth, flags);\n            DEBUG_PEEP(\"next\", next, depth, flags);\n\n            /* we suppose the run is continuous, last=next...\n             * NOTE we dont use the return here! */\n            /* DEFINEP study_chunk() recursion */\n            (void)study_chunk(pRExC_state, &scan, &minlen,\n                              &deltanext, next, &data_fake, stopparen,\n                              recursed_depth, NULL, f, depth+1);\n\n            scan = next;\n        } else\n        if (\n            OP(scan) == BRANCH  ||\n            OP(scan) == BRANCHJ ||\n            OP(scan) == IFTHEN\n        ) {\n\t    next = regnext(scan);\n\t    code = OP(scan);\n\n            /* The op(next)==code check below is to see if we\n             * have \"BRANCH-BRANCH\", \"BRANCHJ-BRANCHJ\", \"IFTHEN-IFTHEN\"\n             * IFTHEN is special as it might not appear in pairs.\n             * Not sure whether BRANCH-BRANCHJ is possible, regardless\n             * we dont handle it cleanly. */\n\t    if (OP(next) == code || code == IFTHEN) {\n                /* NOTE - There is similar code to this block below for\n                 * handling TRIE nodes on a re-study.  If you change stuff here\n                 * check there too. */\n\t\tSSize_t max1 = 0, min1 = SSize_t_MAX, num = 0;\n\t\tregnode_ssc accum;\n\t\tregnode * const startbranch=scan;\n\n                if (flags & SCF_DO_SUBSTR) {\n                    /* Cannot merge strings after this. */\n                    scan_commit(pRExC_state, data, minlenp, is_inf);\n                }\n\n                if (flags & SCF_DO_STCLASS)\n\t\t    ssc_init_zero(pRExC_state, &accum);\n\n\t\twhile (OP(scan) == code) {\n\t\t    SSize_t deltanext, minnext, fake;\n\t\t    I32 f = 0;\n\t\t    regnode_ssc this_class;\n\n                    DEBUG_PEEP(\"Branch\", scan, depth, flags);\n\n\t\t    num++;\n                    StructCopy(&zero_scan_data, &data_fake, scan_data_t);\n\t\t    if (data) {\n\t\t\tdata_fake.whilem_c = data->whilem_c;\n\t\t\tdata_fake.last_closep = data->last_closep;\n\t\t    }\n\t\t    else\n\t\t\tdata_fake.last_closep = &fake;\n\n\t\t    data_fake.pos_delta = delta;\n\t\t    next = regnext(scan);\n\n                    scan = NEXTOPER(scan); /* everything */\n                    if (code != BRANCH)    /* everything but BRANCH */\n\t\t\tscan = NEXTOPER(scan);\n\n\t\t    if (flags & SCF_DO_STCLASS) {\n\t\t\tssc_init(pRExC_state, &this_class);\n\t\t\tdata_fake.start_class = &this_class;\n\t\t\tf = SCF_DO_STCLASS_AND;\n\t\t    }\n\t\t    if (flags & SCF_WHILEM_VISITED_POS)\n\t\t\tf |= SCF_WHILEM_VISITED_POS;\n\n\t\t    /* we suppose the run is continuous, last=next...*/\n                    /* recurse study_chunk() for each BRANCH in an alternation */\n\t\t    minnext = study_chunk(pRExC_state, &scan, minlenp,\n                                      &deltanext, next, &data_fake, stopparen,\n                                      recursed_depth, NULL, f, depth+1);\n\n\t\t    if (min1 > minnext)\n\t\t\tmin1 = minnext;\n\t\t    if (deltanext == SSize_t_MAX) {\n\t\t\tis_inf = is_inf_internal = 1;\n\t\t\tmax1 = SSize_t_MAX;\n\t\t    } else if (max1 < minnext + deltanext)\n\t\t\tmax1 = minnext + deltanext;\n\t\t    scan = next;\n\t\t    if (data_fake.flags & (SF_HAS_PAR|SF_IN_PAR))\n\t\t\tpars++;\n\t            if (data_fake.flags & SCF_SEEN_ACCEPT) {\n\t                if ( stopmin > minnext)\n\t                    stopmin = min + min1;\n\t                flags &= ~SCF_DO_SUBSTR;\n\t                if (data)\n\t                    data->flags |= SCF_SEEN_ACCEPT;\n\t            }\n\t\t    if (data) {\n\t\t\tif (data_fake.flags & SF_HAS_EVAL)\n\t\t\t    data->flags |= SF_HAS_EVAL;\n\t\t\tdata->whilem_c = data_fake.whilem_c;\n\t\t    }\n\t\t    if (flags & SCF_DO_STCLASS)\n\t\t\tssc_or(pRExC_state, &accum, (regnode_charclass*)&this_class);\n\t\t}\n\t\tif (code == IFTHEN && num < 2) /* Empty ELSE branch */\n\t\t    min1 = 0;\n\t\tif (flags & SCF_DO_SUBSTR) {\n\t\t    data->pos_min += min1;\n\t\t    if (data->pos_delta >= SSize_t_MAX - (max1 - min1))\n\t\t        data->pos_delta = SSize_t_MAX;\n\t\t    else\n\t\t        data->pos_delta += max1 - min1;\n\t\t    if (max1 != min1 || is_inf)\n\t\t\tdata->cur_is_floating = 1;\n\t\t}\n\t\tmin += min1;\n\t\tif (delta == SSize_t_MAX\n\t\t || SSize_t_MAX - delta - (max1 - min1) < 0)\n\t\t    delta = SSize_t_MAX;\n\t\telse\n\t\t    delta += max1 - min1;\n\t\tif (flags & SCF_DO_STCLASS_OR) {\n\t\t    ssc_or(pRExC_state, data->start_class, (regnode_charclass*) &accum);\n\t\t    if (min1) {\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\t\t\tflags &= ~SCF_DO_STCLASS;\n\t\t    }\n\t\t}\n\t\telse if (flags & SCF_DO_STCLASS_AND) {\n\t\t    if (min1) {\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) &accum);\n\t\t\tflags &= ~SCF_DO_STCLASS;\n\t\t    }\n\t\t    else {\n\t\t\t/* Switch to OR mode: cache the old value of\n\t\t\t * data->start_class */\n\t\t\tINIT_AND_WITHP;\n\t\t\tStructCopy(data->start_class, and_withp, regnode_ssc);\n\t\t\tflags &= ~SCF_DO_STCLASS_AND;\n\t\t\tStructCopy(&accum, data->start_class, regnode_ssc);\n\t\t\tflags |= SCF_DO_STCLASS_OR;\n\t\t    }\n\t\t}\n\n                if (PERL_ENABLE_TRIE_OPTIMISATION &&\n                        OP( startbranch ) == BRANCH )\n                {\n\t\t/* demq.\n\n                   Assuming this was/is a branch we are dealing with: 'scan'\n                   now points at the item that follows the branch sequence,\n                   whatever it is. We now start at the beginning of the\n                   sequence and look for subsequences of\n\n\t\t   BRANCH->EXACT=>x1\n\t\t   BRANCH->EXACT=>x2\n\t\t   tail\n\n                   which would be constructed from a pattern like\n                   /A|LIST|OF|WORDS/\n\n\t\t   If we can find such a subsequence we need to turn the first\n\t\t   element into a trie and then add the subsequent branch exact\n\t\t   strings to the trie.\n\n\t\t   We have two cases\n\n                     1. patterns where the whole set of branches can be\n                        converted.\n\n\t\t     2. patterns where only a subset can be converted.\n\n\t\t   In case 1 we can replace the whole set with a single regop\n\t\t   for the trie. In case 2 we need to keep the start and end\n\t\t   branches so\n\n\t\t     'BRANCH EXACT; BRANCH EXACT; BRANCH X'\n\t\t     becomes BRANCH TRIE; BRANCH X;\n\n\t\t  There is an additional case, that being where there is a\n\t\t  common prefix, which gets split out into an EXACT like node\n\t\t  preceding the TRIE node.\n\n\t\t  If x(1..n)==tail then we can do a simple trie, if not we make\n\t\t  a \"jump\" trie, such that when we match the appropriate word\n\t\t  we \"jump\" to the appropriate tail node. Essentially we turn\n\t\t  a nested if into a case structure of sorts.\n\n\t\t*/\n\n\t\t    int made=0;\n\t\t    if (!re_trie_maxbuff) {\n\t\t\tre_trie_maxbuff = get_sv(RE_TRIE_MAXBUF_NAME, 1);\n\t\t\tif (!SvIOK(re_trie_maxbuff))\n\t\t\t    sv_setiv(re_trie_maxbuff, RE_TRIE_MAXBUF_INIT);\n\t\t    }\n                    if ( SvIV(re_trie_maxbuff)>=0  ) {\n                        regnode *cur;\n                        regnode *first = (regnode *)NULL;\n                        regnode *last = (regnode *)NULL;\n                        regnode *tail = scan;\n                        U8 trietype = 0;\n                        U32 count=0;\n\n                        /* var tail is used because there may be a TAIL\n                           regop in the way. Ie, the exacts will point to the\n                           thing following the TAIL, but the last branch will\n                           point at the TAIL. So we advance tail. If we\n                           have nested (?:) we may have to move through several\n                           tails.\n                         */\n\n                        while ( OP( tail ) == TAIL ) {\n                            /* this is the TAIL generated by (?:) */\n                            tail = regnext( tail );\n                        }\n\n\n                        DEBUG_TRIE_COMPILE_r({\n                            regprop(RExC_rx, RExC_mysv, tail, NULL, pRExC_state);\n                            Perl_re_indentf( aTHX_  \"%s %\" UVuf \":%s\\n\",\n                              depth+1,\n                              \"Looking for TRIE'able sequences. Tail node is \",\n                              (UV) REGNODE_OFFSET(tail),\n                              SvPV_nolen_const( RExC_mysv )\n                            );\n                        });\n\n                        /*\n\n                            Step through the branches\n                                cur represents each branch,\n                                noper is the first thing to be matched as part\n                                      of that branch\n                                noper_next is the regnext() of that node.\n\n                            We normally handle a case like this\n                            /FOO[xyz]|BAR[pqr]/ via a \"jump trie\" but we also\n                            support building with NOJUMPTRIE, which restricts\n                            the trie logic to structures like /FOO|BAR/.\n\n                            If noper is a trieable nodetype then the branch is\n                            a possible optimization target. If we are building\n                            under NOJUMPTRIE then we require that noper_next is\n                            the same as scan (our current position in the regex\n                            program).\n\n                            Once we have two or more consecutive such branches\n                            we can create a trie of the EXACT's contents and\n                            stitch it in place into the program.\n\n                            If the sequence represents all of the branches in\n                            the alternation we replace the entire thing with a\n                            single TRIE node.\n\n                            Otherwise when it is a subsequence we need to\n                            stitch it in place and replace only the relevant\n                            branches. This means the first branch has to remain\n                            as it is used by the alternation logic, and its\n                            next pointer, and needs to be repointed at the item\n                            on the branch chain following the last branch we\n                            have optimized away.\n\n                            This could be either a BRANCH, in which case the\n                            subsequence is internal, or it could be the item\n                            following the branch sequence in which case the\n                            subsequence is at the end (which does not\n                            necessarily mean the first node is the start of the\n                            alternation).\n\n                            TRIE_TYPE(X) is a define which maps the optype to a\n                            trietype.\n\n                                optype          |  trietype\n                                ----------------+-----------\n                                NOTHING         | NOTHING\n                                EXACT           | EXACT\n                                EXACT_ONLY8     | EXACT\n                                EXACTFU         | EXACTFU\n                                EXACTFU_ONLY8   | EXACTFU\n                                EXACTFUP        | EXACTFU\n                                EXACTFAA        | EXACTFAA\n                                EXACTL          | EXACTL\n                                EXACTFLU8       | EXACTFLU8\n\n\n                        */\n#define TRIE_TYPE(X) ( ( NOTHING == (X) )                                   \\\n                       ? NOTHING                                            \\\n                       : ( EXACT == (X) || EXACT_ONLY8 == (X) )             \\\n                         ? EXACT                                            \\\n                         : (     EXACTFU == (X)                             \\\n                              || EXACTFU_ONLY8 == (X)                       \\\n                              || EXACTFUP == (X) )                          \\\n                           ? EXACTFU                                        \\\n                           : ( EXACTFAA == (X) )                            \\\n                             ? EXACTFAA                                     \\\n                             : ( EXACTL == (X) )                            \\\n                               ? EXACTL                                     \\\n                               : ( EXACTFLU8 == (X) )                       \\\n                                 ? EXACTFLU8                                \\\n                                 : 0 )\n\n                        /* dont use tail as the end marker for this traverse */\n                        for ( cur = startbranch ; cur != scan ; cur = regnext( cur ) ) {\n                            regnode * const noper = NEXTOPER( cur );\n                            U8 noper_type = OP( noper );\n                            U8 noper_trietype = TRIE_TYPE( noper_type );\n#if defined(DEBUGGING) || defined(NOJUMPTRIE)\n                            regnode * const noper_next = regnext( noper );\n                            U8 noper_next_type = (noper_next && noper_next < tail) ? OP(noper_next) : 0;\n                            U8 noper_next_trietype = (noper_next && noper_next < tail) ? TRIE_TYPE( noper_next_type ) :0;\n#endif\n\n                            DEBUG_TRIE_COMPILE_r({\n                                regprop(RExC_rx, RExC_mysv, cur, NULL, pRExC_state);\n                                Perl_re_indentf( aTHX_  \"- %d:%s (%d)\",\n                                   depth+1,\n                                   REG_NODE_NUM(cur), SvPV_nolen_const( RExC_mysv ), REG_NODE_NUM(cur) );\n\n                                regprop(RExC_rx, RExC_mysv, noper, NULL, pRExC_state);\n                                Perl_re_printf( aTHX_  \" -> %d:%s\",\n                                    REG_NODE_NUM(noper), SvPV_nolen_const(RExC_mysv));\n\n                                if ( noper_next ) {\n                                  regprop(RExC_rx, RExC_mysv, noper_next, NULL, pRExC_state);\n                                  Perl_re_printf( aTHX_ \"\\t=> %d:%s\\t\",\n                                    REG_NODE_NUM(noper_next), SvPV_nolen_const(RExC_mysv));\n                                }\n                                Perl_re_printf( aTHX_  \"(First==%d,Last==%d,Cur==%d,tt==%s,ntt==%s,nntt==%s)\\n\",\n                                   REG_NODE_NUM(first), REG_NODE_NUM(last), REG_NODE_NUM(cur),\n\t\t\t\t   PL_reg_name[trietype], PL_reg_name[noper_trietype], PL_reg_name[noper_next_trietype]\n\t\t\t\t);\n                            });\n\n                            /* Is noper a trieable nodetype that can be merged\n                             * with the current trie (if there is one)? */\n                            if ( noper_trietype\n                                  &&\n                                  (\n                                        ( noper_trietype == NOTHING )\n                                        || ( trietype == NOTHING )\n                                        || ( trietype == noper_trietype )\n                                  )\n#ifdef NOJUMPTRIE\n                                  && noper_next >= tail\n#endif\n                                  && count < U16_MAX)\n                            {\n                                /* Handle mergable triable node Either we are\n                                 * the first node in a new trieable sequence,\n                                 * in which case we do some bookkeeping,\n                                 * otherwise we update the end pointer. */\n                                if ( !first ) {\n                                    first = cur;\n\t\t\t\t    if ( noper_trietype == NOTHING ) {\n#if !defined(DEBUGGING) && !defined(NOJUMPTRIE)\n\t\t\t\t\tregnode * const noper_next = regnext( noper );\n                                        U8 noper_next_type = (noper_next && noper_next < tail) ? OP(noper_next) : 0;\n\t\t\t\t\tU8 noper_next_trietype = noper_next_type ? TRIE_TYPE( noper_next_type ) :0;\n#endif\n\n                                        if ( noper_next_trietype ) {\n\t\t\t\t\t    trietype = noper_next_trietype;\n                                        } else if (noper_next_type)  {\n                                            /* a NOTHING regop is 1 regop wide.\n                                             * We need at least two for a trie\n                                             * so we can't merge this in */\n                                            first = NULL;\n                                        }\n                                    } else {\n                                        trietype = noper_trietype;\n                                    }\n                                } else {\n                                    if ( trietype == NOTHING )\n                                        trietype = noper_trietype;\n                                    last = cur;\n                                }\n\t\t\t\tif (first)\n\t\t\t\t    count++;\n                            } /* end handle mergable triable node */\n                            else {\n                                /* handle unmergable node -\n                                 * noper may either be a triable node which can\n                                 * not be tried together with the current trie,\n                                 * or a non triable node */\n                                if ( last ) {\n                                    /* If last is set and trietype is not\n                                     * NOTHING then we have found at least two\n                                     * triable branch sequences in a row of a\n                                     * similar trietype so we can turn them\n                                     * into a trie. If/when we allow NOTHING to\n                                     * start a trie sequence this condition\n                                     * will be required, and it isn't expensive\n                                     * so we leave it in for now. */\n                                    if ( trietype && trietype != NOTHING )\n                                        make_trie( pRExC_state,\n                                                startbranch, first, cur, tail,\n                                                count, trietype, depth+1 );\n                                    last = NULL; /* note: we clear/update\n                                                    first, trietype etc below,\n                                                    so we dont do it here */\n                                }\n                                if ( noper_trietype\n#ifdef NOJUMPTRIE\n                                     && noper_next >= tail\n#endif\n                                ){\n                                    /* noper is triable, so we can start a new\n                                     * trie sequence */\n                                    count = 1;\n                                    first = cur;\n                                    trietype = noper_trietype;\n                                } else if (first) {\n                                    /* if we already saw a first but the\n                                     * current node is not triable then we have\n                                     * to reset the first information. */\n                                    count = 0;\n                                    first = NULL;\n                                    trietype = 0;\n                                }\n                            } /* end handle unmergable node */\n                        } /* loop over branches */\n                        DEBUG_TRIE_COMPILE_r({\n                            regprop(RExC_rx, RExC_mysv, cur, NULL, pRExC_state);\n                            Perl_re_indentf( aTHX_  \"- %s (%d) <SCAN FINISHED> \",\n                              depth+1, SvPV_nolen_const( RExC_mysv ), REG_NODE_NUM(cur));\n                            Perl_re_printf( aTHX_  \"(First==%d, Last==%d, Cur==%d, tt==%s)\\n\",\n                               REG_NODE_NUM(first), REG_NODE_NUM(last), REG_NODE_NUM(cur),\n                               PL_reg_name[trietype]\n                            );\n\n                        });\n                        if ( last && trietype ) {\n                            if ( trietype != NOTHING ) {\n                                /* the last branch of the sequence was part of\n                                 * a trie, so we have to construct it here\n                                 * outside of the loop */\n                                made= make_trie( pRExC_state, startbranch,\n                                                 first, scan, tail, count,\n                                                 trietype, depth+1 );\n#ifdef TRIE_STUDY_OPT\n                                if ( ((made == MADE_EXACT_TRIE &&\n                                     startbranch == first)\n                                     || ( first_non_open == first )) &&\n                                     depth==0 ) {\n                                    flags |= SCF_TRIE_RESTUDY;\n                                    if ( startbranch == first\n                                         && scan >= tail )\n                                    {\n                                        RExC_seen &=~REG_TOP_LEVEL_BRANCHES_SEEN;\n                                    }\n                                }\n#endif\n                            } else {\n                                /* at this point we know whatever we have is a\n                                 * NOTHING sequence/branch AND if 'startbranch'\n                                 * is 'first' then we can turn the whole thing\n                                 * into a NOTHING\n                                 */\n                                if ( startbranch == first ) {\n                                    regnode *opt;\n                                    /* the entire thing is a NOTHING sequence,\n                                     * something like this: (?:|) So we can\n                                     * turn it into a plain NOTHING op. */\n                                    DEBUG_TRIE_COMPILE_r({\n                                        regprop(RExC_rx, RExC_mysv, cur, NULL, pRExC_state);\n                                        Perl_re_indentf( aTHX_  \"- %s (%d) <NOTHING BRANCH SEQUENCE>\\n\",\n                                          depth+1,\n                                          SvPV_nolen_const( RExC_mysv ), REG_NODE_NUM(cur));\n\n                                    });\n                                    OP(startbranch)= NOTHING;\n                                    NEXT_OFF(startbranch)= tail - startbranch;\n                                    for ( opt= startbranch + 1; opt < tail ; opt++ )\n                                        OP(opt)= OPTIMIZED;\n                                }\n                            }\n                        } /* end if ( last) */\n                    } /* TRIE_MAXBUF is non zero */\n\n                } /* do trie */\n\n\t    }\n\t    else if ( code == BRANCHJ ) {  /* single branch is optimized. */\n\t\tscan = NEXTOPER(NEXTOPER(scan));\n\t    } else\t\t\t/* single branch is optimized. */\n\t\tscan = NEXTOPER(scan);\n\t    continue;\n        } else if (OP(scan) == SUSPEND || OP(scan) == GOSUB) {\n            I32 paren = 0;\n            regnode *start = NULL;\n            regnode *end = NULL;\n            U32 my_recursed_depth= recursed_depth;\n\n            if (OP(scan) != SUSPEND) { /* GOSUB */\n                /* Do setup, note this code has side effects beyond\n                 * the rest of this block. Specifically setting\n                 * RExC_recurse[] must happen at least once during\n                 * study_chunk(). */\n                paren = ARG(scan);\n                RExC_recurse[ARG2L(scan)] = scan;\n                start = REGNODE_p(RExC_open_parens[paren]);\n                end   = REGNODE_p(RExC_close_parens[paren]);\n\n                /* NOTE we MUST always execute the above code, even\n                 * if we do nothing with a GOSUB */\n                if (\n                    ( flags & SCF_IN_DEFINE )\n                    ||\n                    (\n                        (is_inf_internal || is_inf || (data && data->flags & SF_IS_INF))\n                        &&\n                        ( (flags & (SCF_DO_STCLASS | SCF_DO_SUBSTR)) == 0 )\n                    )\n                ) {\n                    /* no need to do anything here if we are in a define. */\n                    /* or we are after some kind of infinite construct\n                     * so we can skip recursing into this item.\n                     * Since it is infinite we will not change the maxlen\n                     * or delta, and if we miss something that might raise\n                     * the minlen it will merely pessimise a little.\n                     *\n                     * Iow /(?(DEFINE)(?<foo>foo|food))a+(?&foo)/\n                     * might result in a minlen of 1 and not of 4,\n                     * but this doesn't make us mismatch, just try a bit\n                     * harder than we should.\n                     * */\n                    scan= regnext(scan);\n                    continue;\n                }\n\n                if (\n                    !recursed_depth\n                    ||\n                    !PAREN_TEST(RExC_study_chunk_recursed + ((recursed_depth-1) * RExC_study_chunk_recursed_bytes), paren)\n                ) {\n                    /* it is quite possible that there are more efficient ways\n                     * to do this. We maintain a bitmap per level of recursion\n                     * of which patterns we have entered so we can detect if a\n                     * pattern creates a possible infinite loop. When we\n                     * recurse down a level we copy the previous levels bitmap\n                     * down. When we are at recursion level 0 we zero the top\n                     * level bitmap. It would be nice to implement a different\n                     * more efficient way of doing this. In particular the top\n                     * level bitmap may be unnecessary.\n                     */\n                    if (!recursed_depth) {\n                        Zero(RExC_study_chunk_recursed, RExC_study_chunk_recursed_bytes, U8);\n                    } else {\n                        Copy(RExC_study_chunk_recursed + ((recursed_depth-1) * RExC_study_chunk_recursed_bytes),\n                             RExC_study_chunk_recursed + (recursed_depth * RExC_study_chunk_recursed_bytes),\n                             RExC_study_chunk_recursed_bytes, U8);\n                    }\n                    /* we havent recursed into this paren yet, so recurse into it */\n                    DEBUG_STUDYDATA(\"gosub-set\", data, depth, is_inf);\n                    PAREN_SET(RExC_study_chunk_recursed + (recursed_depth * RExC_study_chunk_recursed_bytes), paren);\n                    my_recursed_depth= recursed_depth + 1;\n                } else {\n                    DEBUG_STUDYDATA(\"gosub-inf\", data, depth, is_inf);\n                    /* some form of infinite recursion, assume infinite length\n                     * */\n                    if (flags & SCF_DO_SUBSTR) {\n                        scan_commit(pRExC_state, data, minlenp, is_inf);\n                        data->cur_is_floating = 1;\n                    }\n                    is_inf = is_inf_internal = 1;\n                    if (flags & SCF_DO_STCLASS_OR) /* Allow everything */\n                        ssc_anything(data->start_class);\n                    flags &= ~SCF_DO_STCLASS;\n\n                    start= NULL; /* reset start so we dont recurse later on. */\n\t        }\n            } else {\n\t        paren = stopparen;\n                start = scan + 2;\n\t        end = regnext(scan);\n\t    }\n            if (start) {\n                scan_frame *newframe;\n                assert(end);\n                if (!RExC_frame_last) {\n                    Newxz(newframe, 1, scan_frame);\n                    SAVEDESTRUCTOR_X(S_unwind_scan_frames, newframe);\n                    RExC_frame_head= newframe;\n                    RExC_frame_count++;\n                } else if (!RExC_frame_last->next_frame) {\n                    Newxz(newframe, 1, scan_frame);\n                    RExC_frame_last->next_frame= newframe;\n                    newframe->prev_frame= RExC_frame_last;\n                    RExC_frame_count++;\n                } else {\n                    newframe= RExC_frame_last->next_frame;\n                }\n                RExC_frame_last= newframe;\n\n                newframe->next_regnode = regnext(scan);\n                newframe->last_regnode = last;\n                newframe->stopparen = stopparen;\n                newframe->prev_recursed_depth = recursed_depth;\n                newframe->this_prev_frame= frame;\n\n                DEBUG_STUDYDATA(\"frame-new\", data, depth, is_inf);\n                DEBUG_PEEP(\"fnew\", scan, depth, flags);\n\n\t        frame = newframe;\n\t        scan =  start;\n\t        stopparen = paren;\n\t        last = end;\n                depth = depth + 1;\n                recursed_depth= my_recursed_depth;\n\n\t        continue;\n\t    }\n\t}\n\telse if (   OP(scan) == EXACT\n                 || OP(scan) == EXACT_ONLY8\n                 || OP(scan) == EXACTL)\n        {\n\t    SSize_t l = STR_LEN(scan);\n\t    UV uc;\n            assert(l);\n\t    if (UTF) {\n\t\tconst U8 * const s = (U8*)STRING(scan);\n\t\tuc = utf8_to_uvchr_buf(s, s + l, NULL);\n\t\tl = utf8_length(s, s + l);\n\t    } else {\n\t\tuc = *((U8*)STRING(scan));\n\t    }\n\t    min += l;\n\t    if (flags & SCF_DO_SUBSTR) { /* Update longest substr. */\n\t\t/* The code below prefers earlier match for fixed\n\t\t   offset, later match for variable offset.  */\n\t\tif (data->last_end == -1) { /* Update the start info. */\n\t\t    data->last_start_min = data->pos_min;\n \t\t    data->last_start_max = is_inf\n \t\t\t? SSize_t_MAX : data->pos_min + data->pos_delta;\n\t\t}\n\t\tsv_catpvn(data->last_found, STRING(scan), STR_LEN(scan));\n\t\tif (UTF)\n\t\t    SvUTF8_on(data->last_found);\n\t\t{\n\t\t    SV * const sv = data->last_found;\n\t\t    MAGIC * const mg = SvUTF8(sv) && SvMAGICAL(sv) ?\n\t\t\tmg_find(sv, PERL_MAGIC_utf8) : NULL;\n\t\t    if (mg && mg->mg_len >= 0)\n\t\t\tmg->mg_len += utf8_length((U8*)STRING(scan),\n                                              (U8*)STRING(scan)+STR_LEN(scan));\n\t\t}\n\t\tdata->last_end = data->pos_min + l;\n\t\tdata->pos_min += l; /* As in the first entry. */\n\t\tdata->flags &= ~SF_BEFORE_EOL;\n\t    }\n\n            /* ANDing the code point leaves at most it, and not in locale, and\n             * can't match null string */\n\t    if (flags & SCF_DO_STCLASS_AND) {\n                ssc_cp_and(data->start_class, uc);\n                ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n                ssc_clear_locale(data->start_class);\n\t    }\n\t    else if (flags & SCF_DO_STCLASS_OR) {\n                ssc_add_cp(data->start_class, uc);\n\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\n                /* See commit msg 749e076fceedeb708a624933726e7989f2302f6a */\n                ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n\t    }\n\t    flags &= ~SCF_DO_STCLASS;\n\t}\n        else if (PL_regkind[OP(scan)] == EXACT) {\n            /* But OP != EXACT!, so is EXACTFish */\n\t    SSize_t l = STR_LEN(scan);\n            const U8 * s = (U8*)STRING(scan);\n\n\t    /* Search for fixed substrings supports EXACT only. */\n\t    if (flags & SCF_DO_SUBSTR) {\n\t\tassert(data);\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n\t    }\n\t    if (UTF) {\n\t\tl = utf8_length(s, s + l);\n\t    }\n\t    if (unfolded_multi_char) {\n                RExC_seen |= REG_UNFOLDED_MULTI_SEEN;\n\t    }\n\t    min += l - min_subtract;\n            assert (min >= 0);\n            delta += min_subtract;\n\t    if (flags & SCF_DO_SUBSTR) {\n\t\tdata->pos_min += l - min_subtract;\n\t\tif (data->pos_min < 0) {\n                    data->pos_min = 0;\n                }\n                data->pos_delta += min_subtract;\n\t\tif (min_subtract) {\n\t\t    data->cur_is_floating = 1; /* float */\n\t\t}\n\t    }\n\n            if (flags & SCF_DO_STCLASS) {\n                SV* EXACTF_invlist = _make_exactf_invlist(pRExC_state, scan);\n\n                assert(EXACTF_invlist);\n                if (flags & SCF_DO_STCLASS_AND) {\n                    if (OP(scan) != EXACTFL)\n                        ssc_clear_locale(data->start_class);\n                    ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n                    ANYOF_POSIXL_ZERO(data->start_class);\n                    ssc_intersection(data->start_class, EXACTF_invlist, FALSE);\n                }\n                else {  /* SCF_DO_STCLASS_OR */\n                    ssc_union(data->start_class, EXACTF_invlist, FALSE);\n                    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\n                    /* See commit msg 749e076fceedeb708a624933726e7989f2302f6a */\n                    ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n                }\n                flags &= ~SCF_DO_STCLASS;\n                SvREFCNT_dec(EXACTF_invlist);\n            }\n\t}\n\telse if (REGNODE_VARIES(OP(scan))) {\n\t    SSize_t mincount, maxcount, minnext, deltanext, pos_before = 0;\n\t    I32 fl = 0, f = flags;\n\t    regnode * const oscan = scan;\n\t    regnode_ssc this_class;\n\t    regnode_ssc *oclass = NULL;\n\t    I32 next_is_eval = 0;\n\n\t    switch (PL_regkind[OP(scan)]) {\n\t    case WHILEM:\t\t/* End of (?:...)* . */\n\t\tscan = NEXTOPER(scan);\n\t\tgoto finish;\n\t    case PLUS:\n\t\tif (flags & (SCF_DO_SUBSTR | SCF_DO_STCLASS)) {\n\t\t    next = NEXTOPER(scan);\n\t\t    if (   OP(next) == EXACT\n                        || OP(next) == EXACT_ONLY8\n                        || OP(next) == EXACTL\n                        || (flags & SCF_DO_STCLASS))\n                    {\n\t\t\tmincount = 1;\n\t\t\tmaxcount = REG_INFTY;\n\t\t\tnext = regnext(scan);\n\t\t\tscan = NEXTOPER(scan);\n\t\t\tgoto do_curly;\n\t\t    }\n\t\t}\n\t\tif (flags & SCF_DO_SUBSTR)\n\t\t    data->pos_min++;\n\t\tmin++;\n\t\t/* FALLTHROUGH */\n\t    case STAR:\n                next = NEXTOPER(scan);\n\n                /* This temporary node can now be turned into EXACTFU, and\n                 * must, as regexec.c doesn't handle it */\n                if (OP(next) == EXACTFU_S_EDGE) {\n                    OP(next) = EXACTFU;\n                }\n\n                if (     STR_LEN(next) == 1\n                    &&   isALPHA_A(* STRING(next))\n                    && (         OP(next) == EXACTFAA\n                        || (     OP(next) == EXACTFU\n                            && ! HAS_NONLATIN1_SIMPLE_FOLD_CLOSURE(* STRING(next)))))\n                {\n                    /* These differ in just one bit */\n                    U8 mask = ~ ('A' ^ 'a');\n\n                    assert(isALPHA_A(* STRING(next)));\n\n                    /* Then replace it by an ANYOFM node, with\n                    * the mask set to the complement of the\n                    * bit that differs between upper and lower\n                    * case, and the lowest code point of the\n                    * pair (which the '&' forces) */\n                    OP(next) = ANYOFM;\n                    ARG_SET(next, *STRING(next) & mask);\n                    FLAGS(next) = mask;\n                }\n\n\t\tif (flags & SCF_DO_STCLASS) {\n\t\t    mincount = 0;\n\t\t    maxcount = REG_INFTY;\n\t\t    next = regnext(scan);\n\t\t    scan = NEXTOPER(scan);\n\t\t    goto do_curly;\n\t\t}\n\t\tif (flags & SCF_DO_SUBSTR) {\n                    scan_commit(pRExC_state, data, minlenp, is_inf);\n                    /* Cannot extend fixed substrings */\n\t\t    data->cur_is_floating = 1; /* float */\n\t\t}\n                is_inf = is_inf_internal = 1;\n                scan = regnext(scan);\n\t\tgoto optimize_curly_tail;\n\t    case CURLY:\n\t        if (stopparen>0 && (OP(scan)==CURLYN || OP(scan)==CURLYM)\n\t            && (scan->flags == stopparen))\n\t\t{\n\t\t    mincount = 1;\n\t\t    maxcount = 1;\n\t\t} else {\n\t\t    mincount = ARG1(scan);\n\t\t    maxcount = ARG2(scan);\n\t\t}\n\t\tnext = regnext(scan);\n\t\tif (OP(scan) == CURLYX) {\n\t\t    I32 lp = (data ? *(data->last_closep) : 0);\n\t\t    scan->flags = ((lp <= (I32)U8_MAX) ? (U8)lp : U8_MAX);\n\t\t}\n\t\tscan = NEXTOPER(scan) + EXTRA_STEP_2ARGS;\n\t\tnext_is_eval = (OP(scan) == EVAL);\n\t      do_curly:\n\t\tif (flags & SCF_DO_SUBSTR) {\n                    if (mincount == 0)\n                        scan_commit(pRExC_state, data, minlenp, is_inf);\n                    /* Cannot extend fixed substrings */\n\t\t    pos_before = data->pos_min;\n\t\t}\n\t\tif (data) {\n\t\t    fl = data->flags;\n\t\t    data->flags &= ~(SF_HAS_PAR|SF_IN_PAR|SF_HAS_EVAL);\n\t\t    if (is_inf)\n\t\t\tdata->flags |= SF_IS_INF;\n\t\t}\n\t\tif (flags & SCF_DO_STCLASS) {\n\t\t    ssc_init(pRExC_state, &this_class);\n\t\t    oclass = data->start_class;\n\t\t    data->start_class = &this_class;\n\t\t    f |= SCF_DO_STCLASS_AND;\n\t\t    f &= ~SCF_DO_STCLASS_OR;\n\t\t}\n\t        /* Exclude from super-linear cache processing any {n,m}\n\t\t   regops for which the combination of input pos and regex\n\t\t   pos is not enough information to determine if a match\n\t\t   will be possible.\n\n\t\t   For example, in the regex /foo(bar\\s*){4,8}baz/ with the\n\t\t   regex pos at the \\s*, the prospects for a match depend not\n\t\t   only on the input position but also on how many (bar\\s*)\n\t\t   repeats into the {4,8} we are. */\n               if ((mincount > 1) || (maxcount > 1 && maxcount != REG_INFTY))\n\t\t    f &= ~SCF_WHILEM_VISITED_POS;\n\n\t\t/* This will finish on WHILEM, setting scan, or on NULL: */\n                /* recurse study_chunk() on loop bodies */\n\t\tminnext = study_chunk(pRExC_state, &scan, minlenp, &deltanext,\n                                  last, data, stopparen, recursed_depth, NULL,\n                                  (mincount == 0\n                                   ? (f & ~SCF_DO_SUBSTR)\n                                   : f)\n                                  ,depth+1);\n\n\t\tif (flags & SCF_DO_STCLASS)\n\t\t    data->start_class = oclass;\n\t\tif (mincount == 0 || minnext == 0) {\n\t\t    if (flags & SCF_DO_STCLASS_OR) {\n\t\t\tssc_or(pRExC_state, data->start_class, (regnode_charclass *) &this_class);\n\t\t    }\n\t\t    else if (flags & SCF_DO_STCLASS_AND) {\n\t\t\t/* Switch to OR mode: cache the old value of\n\t\t\t * data->start_class */\n\t\t\tINIT_AND_WITHP;\n\t\t\tStructCopy(data->start_class, and_withp, regnode_ssc);\n\t\t\tflags &= ~SCF_DO_STCLASS_AND;\n\t\t\tStructCopy(&this_class, data->start_class, regnode_ssc);\n\t\t\tflags |= SCF_DO_STCLASS_OR;\n                        ANYOF_FLAGS(data->start_class)\n                                                |= SSC_MATCHES_EMPTY_STRING;\n\t\t    }\n\t\t} else {\t\t/* Non-zero len */\n\t\t    if (flags & SCF_DO_STCLASS_OR) {\n\t\t\tssc_or(pRExC_state, data->start_class, (regnode_charclass *) &this_class);\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\t\t    }\n\t\t    else if (flags & SCF_DO_STCLASS_AND)\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) &this_class);\n\t\t    flags &= ~SCF_DO_STCLASS;\n\t\t}\n\t\tif (!scan) \t\t/* It was not CURLYX, but CURLY. */\n\t\t    scan = next;\n\t\tif (((flags & (SCF_TRIE_DOING_RESTUDY|SCF_DO_SUBSTR))==SCF_DO_SUBSTR)\n\t\t    /* ? quantifier ok, except for (?{ ... }) */\n\t\t    && (next_is_eval || !(mincount == 0 && maxcount == 1))\n\t\t    && (minnext == 0) && (deltanext == 0)\n\t\t    && data && !(data->flags & (SF_HAS_PAR|SF_IN_PAR))\n                    && maxcount <= REG_INFTY/3) /* Complement check for big\n                                                   count */\n\t\t{\n\t\t    _WARN_HELPER(RExC_precomp_end, packWARN(WARN_REGEXP),\n                        Perl_ck_warner(aTHX_ packWARN(WARN_REGEXP),\n                            \"Quantifier unexpected on zero-length expression \"\n                            \"in regex m/%\" UTF8f \"/\",\n\t\t\t     UTF8fARG(UTF, RExC_precomp_end - RExC_precomp,\n\t\t\t\t  RExC_precomp)));\n                }\n\n\t\tmin += minnext * mincount;\n\t\tis_inf_internal |= deltanext == SSize_t_MAX\n                         || (maxcount == REG_INFTY && minnext + deltanext > 0);\n\t\tis_inf |= is_inf_internal;\n                if (is_inf) {\n\t\t    delta = SSize_t_MAX;\n                } else {\n\t\t    delta += (minnext + deltanext) * maxcount\n                             - minnext * mincount;\n                }\n\t\t/* Try powerful optimization CURLYX => CURLYN. */\n\t\tif (  OP(oscan) == CURLYX && data\n\t\t      && data->flags & SF_IN_PAR\n\t\t      && !(data->flags & SF_HAS_EVAL)\n\t\t      && !deltanext && minnext == 1 ) {\n\t\t    /* Try to optimize to CURLYN.  */\n\t\t    regnode *nxt = NEXTOPER(oscan) + EXTRA_STEP_2ARGS;\n\t\t    regnode * const nxt1 = nxt;\n#ifdef DEBUGGING\n\t\t    regnode *nxt2;\n#endif\n\n\t\t    /* Skip open. */\n\t\t    nxt = regnext(nxt);\n\t\t    if (!REGNODE_SIMPLE(OP(nxt))\n\t\t\t&& !(PL_regkind[OP(nxt)] == EXACT\n\t\t\t     && STR_LEN(nxt) == 1))\n\t\t\tgoto nogo;\n#ifdef DEBUGGING\n\t\t    nxt2 = nxt;\n#endif\n\t\t    nxt = regnext(nxt);\n\t\t    if (OP(nxt) != CLOSE)\n\t\t\tgoto nogo;\n\t\t    if (RExC_open_parens) {\n\n                        /*open->CURLYM*/\n                        RExC_open_parens[ARG(nxt1)] = REGNODE_OFFSET(oscan);\n\n                        /*close->while*/\n                        RExC_close_parens[ARG(nxt1)] = REGNODE_OFFSET(nxt) + 2;\n\t\t    }\n\t\t    /* Now we know that nxt2 is the only contents: */\n\t\t    oscan->flags = (U8)ARG(nxt);\n\t\t    OP(oscan) = CURLYN;\n\t\t    OP(nxt1) = NOTHING;\t/* was OPEN. */\n\n#ifdef DEBUGGING\n\t\t    OP(nxt1 + 1) = OPTIMIZED; /* was count. */\n\t\t    NEXT_OFF(nxt1+ 1) = 0; /* just for consistency. */\n\t\t    NEXT_OFF(nxt2) = 0;\t/* just for consistency with CURLY. */\n\t\t    OP(nxt) = OPTIMIZED;\t/* was CLOSE. */\n\t\t    OP(nxt + 1) = OPTIMIZED; /* was count. */\n\t\t    NEXT_OFF(nxt+ 1) = 0; /* just for consistency. */\n#endif\n\t\t}\n\t      nogo:\n\n\t\t/* Try optimization CURLYX => CURLYM. */\n\t\tif (  OP(oscan) == CURLYX && data\n\t\t      && !(data->flags & SF_HAS_PAR)\n\t\t      && !(data->flags & SF_HAS_EVAL)\n\t\t      && !deltanext\t/* atom is fixed width */\n\t\t      && minnext != 0\t/* CURLYM can't handle zero width */\n\n                         /* Nor characters whose fold at run-time may be\n                          * multi-character */\n                      && ! (RExC_seen & REG_UNFOLDED_MULTI_SEEN)\n\t\t) {\n\t\t    /* XXXX How to optimize if data == 0? */\n\t\t    /* Optimize to a simpler form.  */\n\t\t    regnode *nxt = NEXTOPER(oscan) + EXTRA_STEP_2ARGS; /* OPEN */\n\t\t    regnode *nxt2;\n\n\t\t    OP(oscan) = CURLYM;\n\t\t    while ( (nxt2 = regnext(nxt)) /* skip over embedded stuff*/\n\t\t\t    && (OP(nxt2) != WHILEM))\n\t\t\tnxt = nxt2;\n\t\t    OP(nxt2)  = SUCCEED; /* Whas WHILEM */\n\t\t    /* Need to optimize away parenths. */\n\t\t    if ((data->flags & SF_IN_PAR) && OP(nxt) == CLOSE) {\n\t\t\t/* Set the parenth number.  */\n\t\t\tregnode *nxt1 = NEXTOPER(oscan) + EXTRA_STEP_2ARGS; /* OPEN*/\n\n\t\t\toscan->flags = (U8)ARG(nxt);\n\t\t\tif (RExC_open_parens) {\n                             /*open->CURLYM*/\n                            RExC_open_parens[ARG(nxt1)] = REGNODE_OFFSET(oscan);\n\n                            /*close->NOTHING*/\n                            RExC_close_parens[ARG(nxt1)] = REGNODE_OFFSET(nxt2)\n                                                         + 1;\n\t\t\t}\n\t\t\tOP(nxt1) = OPTIMIZED;\t/* was OPEN. */\n\t\t\tOP(nxt) = OPTIMIZED;\t/* was CLOSE. */\n\n#ifdef DEBUGGING\n\t\t\tOP(nxt1 + 1) = OPTIMIZED; /* was count. */\n\t\t\tOP(nxt + 1) = OPTIMIZED; /* was count. */\n\t\t\tNEXT_OFF(nxt1 + 1) = 0; /* just for consistency. */\n\t\t\tNEXT_OFF(nxt + 1) = 0; /* just for consistency. */\n#endif\n#if 0\n\t\t\twhile ( nxt1 && (OP(nxt1) != WHILEM)) {\n\t\t\t    regnode *nnxt = regnext(nxt1);\n\t\t\t    if (nnxt == nxt) {\n\t\t\t\tif (reg_off_by_arg[OP(nxt1)])\n\t\t\t\t    ARG_SET(nxt1, nxt2 - nxt1);\n\t\t\t\telse if (nxt2 - nxt1 < U16_MAX)\n\t\t\t\t    NEXT_OFF(nxt1) = nxt2 - nxt1;\n\t\t\t\telse\n\t\t\t\t    OP(nxt) = NOTHING;\t/* Cannot beautify */\n\t\t\t    }\n\t\t\t    nxt1 = nnxt;\n\t\t\t}\n#endif\n\t\t\t/* Optimize again: */\n                        /* recurse study_chunk() on optimised CURLYX => CURLYM */\n\t\t\tstudy_chunk(pRExC_state, &nxt1, minlenp, &deltanext, nxt,\n                                    NULL, stopparen, recursed_depth, NULL, 0,\n                                    depth+1);\n\t\t    }\n\t\t    else\n\t\t\toscan->flags = 0;\n\t\t}\n\t\telse if ((OP(oscan) == CURLYX)\n\t\t\t && (flags & SCF_WHILEM_VISITED_POS)\n\t\t\t /* See the comment on a similar expression above.\n\t\t\t    However, this time it's not a subexpression\n\t\t\t    we care about, but the expression itself. */\n\t\t\t && (maxcount == REG_INFTY)\n\t\t\t && data) {\n\t\t    /* This stays as CURLYX, we can put the count/of pair. */\n\t\t    /* Find WHILEM (as in regexec.c) */\n\t\t    regnode *nxt = oscan + NEXT_OFF(oscan);\n\n\t\t    if (OP(PREVOPER(nxt)) == NOTHING) /* LONGJMP */\n\t\t\tnxt += ARG(nxt);\n                    nxt = PREVOPER(nxt);\n                    if (nxt->flags & 0xf) {\n                        /* we've already set whilem count on this node */\n                    } else if (++data->whilem_c < 16) {\n                        assert(data->whilem_c <= RExC_whilem_seen);\n                        nxt->flags = (U8)(data->whilem_c\n                            | (RExC_whilem_seen << 4)); /* On WHILEM */\n                    }\n\t\t}\n\t\tif (data && fl & (SF_HAS_PAR|SF_IN_PAR))\n\t\t    pars++;\n\t\tif (flags & SCF_DO_SUBSTR) {\n\t\t    SV *last_str = NULL;\n                    STRLEN last_chrs = 0;\n\t\t    int counted = mincount != 0;\n\n                    if (data->last_end > 0 && mincount != 0) { /* Ends with a\n                                                                  string. */\n\t\t\tSSize_t b = pos_before >= data->last_start_min\n\t\t\t    ? pos_before : data->last_start_min;\n\t\t\tSTRLEN l;\n\t\t\tconst char * const s = SvPV_const(data->last_found, l);\n\t\t\tSSize_t old = b - data->last_start_min;\n                        assert(old >= 0);\n\n\t\t\tif (UTF)\n\t\t\t    old = utf8_hop_forward((U8*)s, old,\n                                               (U8 *) SvEND(data->last_found))\n                                - (U8*)s;\n\t\t\tl -= old;\n\t\t\t/* Get the added string: */\n\t\t\tlast_str = newSVpvn_utf8(s  + old, l, UTF);\n                        last_chrs = UTF ? utf8_length((U8*)(s + old),\n                                            (U8*)(s + old + l)) : l;\n\t\t\tif (deltanext == 0 && pos_before == b) {\n\t\t\t    /* What was added is a constant string */\n\t\t\t    if (mincount > 1) {\n\n\t\t\t\tSvGROW(last_str, (mincount * l) + 1);\n\t\t\t\trepeatcpy(SvPVX(last_str) + l,\n\t\t\t\t\t  SvPVX_const(last_str), l,\n                                          mincount - 1);\n\t\t\t\tSvCUR_set(last_str, SvCUR(last_str) * mincount);\n\t\t\t\t/* Add additional parts. */\n\t\t\t\tSvCUR_set(data->last_found,\n\t\t\t\t\t  SvCUR(data->last_found) - l);\n\t\t\t\tsv_catsv(data->last_found, last_str);\n\t\t\t\t{\n\t\t\t\t    SV * sv = data->last_found;\n\t\t\t\t    MAGIC *mg =\n\t\t\t\t\tSvUTF8(sv) && SvMAGICAL(sv) ?\n\t\t\t\t\tmg_find(sv, PERL_MAGIC_utf8) : NULL;\n\t\t\t\t    if (mg && mg->mg_len >= 0)\n\t\t\t\t\tmg->mg_len += last_chrs * (mincount-1);\n\t\t\t\t}\n                                last_chrs *= mincount;\n\t\t\t\tdata->last_end += l * (mincount - 1);\n\t\t\t    }\n\t\t\t} else {\n\t\t\t    /* start offset must point into the last copy */\n\t\t\t    data->last_start_min += minnext * (mincount - 1);\n\t\t\t    data->last_start_max =\n                              is_inf\n                               ? SSize_t_MAX\n\t\t\t       : data->last_start_max +\n                                 (maxcount - 1) * (minnext + data->pos_delta);\n\t\t\t}\n\t\t    }\n\t\t    /* It is counted once already... */\n\t\t    data->pos_min += minnext * (mincount - counted);\n#if 0\nPerl_re_printf( aTHX_  \"counted=%\" UVuf \" deltanext=%\" UVuf\n                              \" SSize_t_MAX=%\" UVuf \" minnext=%\" UVuf\n                              \" maxcount=%\" UVuf \" mincount=%\" UVuf \"\\n\",\n    (UV)counted, (UV)deltanext, (UV)SSize_t_MAX, (UV)minnext, (UV)maxcount,\n    (UV)mincount);\nif (deltanext != SSize_t_MAX)\nPerl_re_printf( aTHX_  \"LHS=%\" UVuf \" RHS=%\" UVuf \"\\n\",\n    (UV)(-counted * deltanext + (minnext + deltanext) * maxcount\n          - minnext * mincount), (UV)(SSize_t_MAX - data->pos_delta));\n#endif\n\t\t    if (deltanext == SSize_t_MAX\n                        || -counted * deltanext + (minnext + deltanext) * maxcount - minnext * mincount >= SSize_t_MAX - data->pos_delta)\n\t\t        data->pos_delta = SSize_t_MAX;\n\t\t    else\n\t\t        data->pos_delta += - counted * deltanext +\n\t\t\t(minnext + deltanext) * maxcount - minnext * mincount;\n\t\t    if (mincount != maxcount) {\n\t\t\t /* Cannot extend fixed substrings found inside\n\t\t\t    the group.  */\n                        scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\t\tif (mincount && last_str) {\n\t\t\t    SV * const sv = data->last_found;\n\t\t\t    MAGIC * const mg = SvUTF8(sv) && SvMAGICAL(sv) ?\n\t\t\t\tmg_find(sv, PERL_MAGIC_utf8) : NULL;\n\n\t\t\t    if (mg)\n\t\t\t\tmg->mg_len = -1;\n\t\t\t    sv_setsv(sv, last_str);\n\t\t\t    data->last_end = data->pos_min;\n\t\t\t    data->last_start_min = data->pos_min - last_chrs;\n\t\t\t    data->last_start_max = is_inf\n\t\t\t\t? SSize_t_MAX\n\t\t\t\t: data->pos_min + data->pos_delta - last_chrs;\n\t\t\t}\n\t\t\tdata->cur_is_floating = 1; /* float */\n\t\t    }\n\t\t    SvREFCNT_dec(last_str);\n\t\t}\n\t\tif (data && (fl & SF_HAS_EVAL))\n\t\t    data->flags |= SF_HAS_EVAL;\n\t      optimize_curly_tail:\n\t\tif (OP(oscan) != CURLYX) {\n\t\t    while (PL_regkind[OP(next = regnext(oscan))] == NOTHING\n\t\t\t   && NEXT_OFF(next))\n\t\t\tNEXT_OFF(oscan) += NEXT_OFF(next);\n\t\t}\n\t\tcontinue;\n\n\t    default:\n#ifdef DEBUGGING\n                Perl_croak(aTHX_ \"panic: unexpected varying REx opcode %d\",\n                                                                    OP(scan));\n#endif\n            case REF:\n            case CLUMP:\n\t\tif (flags & SCF_DO_SUBSTR) {\n                    /* Cannot expect anything... */\n                    scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\t    data->cur_is_floating = 1; /* float */\n\t\t}\n\t\tis_inf = is_inf_internal = 1;\n\t\tif (flags & SCF_DO_STCLASS_OR) {\n                    if (OP(scan) == CLUMP) {\n                        /* Actually is any start char, but very few code points\n                         * aren't start characters */\n                        ssc_match_all_cp(data->start_class);\n                    }\n                    else {\n                        ssc_anything(data->start_class);\n                    }\n                }\n\t\tflags &= ~SCF_DO_STCLASS;\n\t\tbreak;\n\t    }\n\t}\n\telse if (OP(scan) == LNBREAK) {\n\t    if (flags & SCF_DO_STCLASS) {\n    \t        if (flags & SCF_DO_STCLASS_AND) {\n                    ssc_intersection(data->start_class,\n                                    PL_XPosix_ptrs[_CC_VERTSPACE], FALSE);\n                    ssc_clear_locale(data->start_class);\n                    ANYOF_FLAGS(data->start_class)\n                                                &= ~SSC_MATCHES_EMPTY_STRING;\n                }\n                else if (flags & SCF_DO_STCLASS_OR) {\n                    ssc_union(data->start_class,\n                              PL_XPosix_ptrs[_CC_VERTSPACE],\n                              FALSE);\n\t\t    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\n                    /* See commit msg for\n                     * 749e076fceedeb708a624933726e7989f2302f6a */\n                    ANYOF_FLAGS(data->start_class)\n                                                &= ~SSC_MATCHES_EMPTY_STRING;\n                }\n\t\tflags &= ~SCF_DO_STCLASS;\n            }\n\t    min++;\n            if (delta != SSize_t_MAX)\n                delta++;    /* Because of the 2 char string cr-lf */\n            if (flags & SCF_DO_SUBSTR) {\n                /* Cannot expect anything... */\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n    \t        data->pos_min += 1;\n                if (data->pos_delta != SSize_t_MAX) {\n                    data->pos_delta += 1;\n                }\n\t\tdata->cur_is_floating = 1; /* float */\n    \t    }\n\t}\n\telse if (REGNODE_SIMPLE(OP(scan))) {\n\n\t    if (flags & SCF_DO_SUBSTR) {\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\tdata->pos_min++;\n\t    }\n\t    min++;\n\t    if (flags & SCF_DO_STCLASS) {\n                bool invert = 0;\n                SV* my_invlist = NULL;\n                U8 namedclass;\n\n                /* See commit msg 749e076fceedeb708a624933726e7989f2302f6a */\n                ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n\n\t\t/* Some of the logic below assumes that switching\n\t\t   locale on will only add false positives. */\n\t\tswitch (OP(scan)) {\n\n\t\tdefault:\n#ifdef DEBUGGING\n                   Perl_croak(aTHX_ \"panic: unexpected simple REx opcode %d\",\n                                                                     OP(scan));\n#endif\n\t\tcase SANY:\n\t\t    if (flags & SCF_DO_STCLASS_OR) /* Allow everything */\n\t\t\tssc_match_all_cp(data->start_class);\n\t\t    break;\n\n\t\tcase REG_ANY:\n                    {\n                        SV* REG_ANY_invlist = _new_invlist(2);\n                        REG_ANY_invlist = add_cp_to_invlist(REG_ANY_invlist,\n                                                            '\\n');\n                        if (flags & SCF_DO_STCLASS_OR) {\n                            ssc_union(data->start_class,\n                                      REG_ANY_invlist,\n                                      TRUE /* TRUE => invert, hence all but \\n\n                                            */\n                                      );\n                        }\n                        else if (flags & SCF_DO_STCLASS_AND) {\n                            ssc_intersection(data->start_class,\n                                             REG_ANY_invlist,\n                                             TRUE  /* TRUE => invert */\n                                             );\n                            ssc_clear_locale(data->start_class);\n                        }\n                        SvREFCNT_dec_NN(REG_ANY_invlist);\n\t\t    }\n\t\t    break;\n\n                case ANYOFD:\n                case ANYOFL:\n                case ANYOFPOSIXL:\n                case ANYOFH:\n                case ANYOF:\n\t\t    if (flags & SCF_DO_STCLASS_AND)\n\t\t\tssc_and(pRExC_state, data->start_class,\n                                (regnode_charclass *) scan);\n\t\t    else\n\t\t\tssc_or(pRExC_state, data->start_class,\n                                                          (regnode_charclass *) scan);\n\t\t    break;\n\n                case NANYOFM:\n                case ANYOFM:\n                  {\n                    SV* cp_list = get_ANYOFM_contents(scan);\n\n                    if (flags & SCF_DO_STCLASS_OR) {\n                        ssc_union(data->start_class, cp_list, invert);\n                    }\n                    else if (flags & SCF_DO_STCLASS_AND) {\n                        ssc_intersection(data->start_class, cp_list, invert);\n                    }\n\n                    SvREFCNT_dec_NN(cp_list);\n                    break;\n                  }\n\n\t\tcase NPOSIXL:\n                    invert = 1;\n                    /* FALLTHROUGH */\n\n\t\tcase POSIXL:\n                    namedclass = classnum_to_namedclass(FLAGS(scan)) + invert;\n                    if (flags & SCF_DO_STCLASS_AND) {\n                        bool was_there = cBOOL(\n                                          ANYOF_POSIXL_TEST(data->start_class,\n                                                                 namedclass));\n                        ANYOF_POSIXL_ZERO(data->start_class);\n                        if (was_there) {    /* Do an AND */\n                            ANYOF_POSIXL_SET(data->start_class, namedclass);\n                        }\n                        /* No individual code points can now match */\n                        data->start_class->invlist\n                                                = sv_2mortal(_new_invlist(0));\n                    }\n                    else {\n                        int complement = namedclass + ((invert) ? -1 : 1);\n\n                        assert(flags & SCF_DO_STCLASS_OR);\n\n                        /* If the complement of this class was already there,\n                         * the result is that they match all code points,\n                         * (\\d + \\D == everything).  Remove the classes from\n                         * future consideration.  Locale is not relevant in\n                         * this case */\n                        if (ANYOF_POSIXL_TEST(data->start_class, complement)) {\n                            ssc_match_all_cp(data->start_class);\n                            ANYOF_POSIXL_CLEAR(data->start_class, namedclass);\n                            ANYOF_POSIXL_CLEAR(data->start_class, complement);\n                        }\n                        else {  /* The usual case; just add this class to the\n                                   existing set */\n                            ANYOF_POSIXL_SET(data->start_class, namedclass);\n                        }\n                    }\n                    break;\n\n                case NPOSIXA:   /* For these, we always know the exact set of\n                                   what's matched */\n                    invert = 1;\n                    /* FALLTHROUGH */\n\t\tcase POSIXA:\n                    my_invlist = invlist_clone(PL_Posix_ptrs[FLAGS(scan)], NULL);\n                    goto join_posix_and_ascii;\n\n\t\tcase NPOSIXD:\n\t\tcase NPOSIXU:\n                    invert = 1;\n                    /* FALLTHROUGH */\n\t\tcase POSIXD:\n\t\tcase POSIXU:\n                    my_invlist = invlist_clone(PL_XPosix_ptrs[FLAGS(scan)], NULL);\n\n                    /* NPOSIXD matches all upper Latin1 code points unless the\n                     * target string being matched is UTF-8, which is\n                     * unknowable until match time.  Since we are going to\n                     * invert, we want to get rid of all of them so that the\n                     * inversion will match all */\n                    if (OP(scan) == NPOSIXD) {\n                        _invlist_subtract(my_invlist, PL_UpperLatin1,\n                                          &my_invlist);\n                    }\n\n                  join_posix_and_ascii:\n\n                    if (flags & SCF_DO_STCLASS_AND) {\n                        ssc_intersection(data->start_class, my_invlist, invert);\n                        ssc_clear_locale(data->start_class);\n                    }\n                    else {\n                        assert(flags & SCF_DO_STCLASS_OR);\n                        ssc_union(data->start_class, my_invlist, invert);\n                    }\n                    SvREFCNT_dec(my_invlist);\n\t\t}\n\t\tif (flags & SCF_DO_STCLASS_OR)\n\t\t    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\t\tflags &= ~SCF_DO_STCLASS;\n\t    }\n\t}\n\telse if (PL_regkind[OP(scan)] == EOL && flags & SCF_DO_SUBSTR) {\n\t    data->flags |= (OP(scan) == MEOL\n\t\t\t    ? SF_BEFORE_MEOL\n\t\t\t    : SF_BEFORE_SEOL);\n            scan_commit(pRExC_state, data, minlenp, is_inf);\n\n\t}\n\telse if (  PL_regkind[OP(scan)] == BRANCHJ\n\t\t /* Lookbehind, or need to calculate parens/evals/stclass: */\n\t\t   && (scan->flags || data || (flags & SCF_DO_STCLASS))\n\t\t   && (OP(scan) == IFMATCH || OP(scan) == UNLESSM))\n        {\n            if ( !PERL_ENABLE_POSITIVE_ASSERTION_STUDY\n                || OP(scan) == UNLESSM )\n            {\n                /* Negative Lookahead/lookbehind\n                   In this case we can't do fixed string optimisation.\n                */\n\n                SSize_t deltanext, minnext, fake = 0;\n                regnode *nscan;\n                regnode_ssc intrnl;\n                int f = 0;\n\n                StructCopy(&zero_scan_data, &data_fake, scan_data_t);\n                if (data) {\n                    data_fake.whilem_c = data->whilem_c;\n                    data_fake.last_closep = data->last_closep;\n\t\t}\n                else\n                    data_fake.last_closep = &fake;\n\t\tdata_fake.pos_delta = delta;\n                if ( flags & SCF_DO_STCLASS && !scan->flags\n                     && OP(scan) == IFMATCH ) { /* Lookahead */\n                    ssc_init(pRExC_state, &intrnl);\n                    data_fake.start_class = &intrnl;\n                    f |= SCF_DO_STCLASS_AND;\n\t\t}\n                if (flags & SCF_WHILEM_VISITED_POS)\n                    f |= SCF_WHILEM_VISITED_POS;\n                next = regnext(scan);\n                nscan = NEXTOPER(NEXTOPER(scan));\n\n                /* recurse study_chunk() for lookahead body */\n                minnext = study_chunk(pRExC_state, &nscan, minlenp, &deltanext,\n                                      last, &data_fake, stopparen,\n                                      recursed_depth, NULL, f, depth+1);\n                if (scan->flags) {\n                    if (   deltanext < 0\n                        || deltanext > (I32) U8_MAX\n                        || minnext > (I32)U8_MAX\n                        || minnext + deltanext > (I32)U8_MAX)\n                    {\n\t\t\tFAIL2(\"Lookbehind longer than %\" UVuf \" not implemented\",\n                              (UV)U8_MAX);\n                    }\n\n                    /* The 'next_off' field has been repurposed to count the\n                     * additional starting positions to try beyond the initial\n                     * one.  (This leaves it at 0 for non-variable length\n                     * matches to avoid breakage for those not using this\n                     * extension) */\n                    if (deltanext) {\n                        scan->next_off = deltanext;\n                        ckWARNexperimental(RExC_parse,\n                            WARN_EXPERIMENTAL__VLB,\n                            \"Variable length lookbehind is experimental\");\n                    }\n                    scan->flags = (U8)minnext + deltanext;\n                }\n                if (data) {\n                    if (data_fake.flags & (SF_HAS_PAR|SF_IN_PAR))\n                        pars++;\n                    if (data_fake.flags & SF_HAS_EVAL)\n                        data->flags |= SF_HAS_EVAL;\n                    data->whilem_c = data_fake.whilem_c;\n                }\n                if (f & SCF_DO_STCLASS_AND) {\n\t\t    if (flags & SCF_DO_STCLASS_OR) {\n\t\t\t/* OR before, AND after: ideally we would recurse with\n\t\t\t * data_fake to get the AND applied by study of the\n\t\t\t * remainder of the pattern, and then derecurse;\n\t\t\t * *** HACK *** for now just treat as \"no information\".\n\t\t\t * See [perl #56690].\n\t\t\t */\n\t\t\tssc_init(pRExC_state, data->start_class);\n\t\t    }  else {\n                        /* AND before and after: combine and continue.  These\n                         * assertions are zero-length, so can match an EMPTY\n                         * string */\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) &intrnl);\n                        ANYOF_FLAGS(data->start_class)\n                                                   |= SSC_MATCHES_EMPTY_STRING;\n\t\t    }\n                }\n\t    }\n#if PERL_ENABLE_POSITIVE_ASSERTION_STUDY\n            else {\n                /* Positive Lookahead/lookbehind\n                   In this case we can do fixed string optimisation,\n                   but we must be careful about it. Note in the case of\n                   lookbehind the positions will be offset by the minimum\n                   length of the pattern, something we won't know about\n                   until after the recurse.\n                */\n                SSize_t deltanext, fake = 0;\n                regnode *nscan;\n                regnode_ssc intrnl;\n                int f = 0;\n                /* We use SAVEFREEPV so that when the full compile\n                    is finished perl will clean up the allocated\n                    minlens when it's all done. This way we don't\n                    have to worry about freeing them when we know\n                    they wont be used, which would be a pain.\n                 */\n                SSize_t *minnextp;\n                Newx( minnextp, 1, SSize_t );\n                SAVEFREEPV(minnextp);\n\n                if (data) {\n                    StructCopy(data, &data_fake, scan_data_t);\n                    if ((flags & SCF_DO_SUBSTR) && data->last_found) {\n                        f |= SCF_DO_SUBSTR;\n                        if (scan->flags)\n                            scan_commit(pRExC_state, &data_fake, minlenp, is_inf);\n                        data_fake.last_found=newSVsv(data->last_found);\n                    }\n                }\n                else\n                    data_fake.last_closep = &fake;\n                data_fake.flags = 0;\n                data_fake.substrs[0].flags = 0;\n                data_fake.substrs[1].flags = 0;\n\t\tdata_fake.pos_delta = delta;\n                if (is_inf)\n\t            data_fake.flags |= SF_IS_INF;\n                if ( flags & SCF_DO_STCLASS && !scan->flags\n                     && OP(scan) == IFMATCH ) { /* Lookahead */\n                    ssc_init(pRExC_state, &intrnl);\n                    data_fake.start_class = &intrnl;\n                    f |= SCF_DO_STCLASS_AND;\n                }\n                if (flags & SCF_WHILEM_VISITED_POS)\n                    f |= SCF_WHILEM_VISITED_POS;\n                next = regnext(scan);\n                nscan = NEXTOPER(NEXTOPER(scan));\n\n                /* positive lookahead study_chunk() recursion */\n                *minnextp = study_chunk(pRExC_state, &nscan, minnextp,\n                                        &deltanext, last, &data_fake,\n                                        stopparen, recursed_depth, NULL,\n                                        f, depth+1);\n                if (scan->flags) {\n                    assert(0);  /* This code has never been tested since this\n                                   is normally not compiled */\n                    if (   deltanext < 0\n                        || deltanext > (I32) U8_MAX\n                        || *minnextp > (I32)U8_MAX\n                        || *minnextp + deltanext > (I32)U8_MAX)\n                    {\n\t\t\tFAIL2(\"Lookbehind longer than %\" UVuf \" not implemented\",\n                              (UV)U8_MAX);\n                    }\n\n                    if (deltanext) {\n                        scan->next_off = deltanext;\n                    }\n                    scan->flags = (U8)*minnextp + deltanext;\n                }\n\n                *minnextp += min;\n\n                if (f & SCF_DO_STCLASS_AND) {\n                    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) &intrnl);\n                    ANYOF_FLAGS(data->start_class) |= SSC_MATCHES_EMPTY_STRING;\n                }\n                if (data) {\n                    if (data_fake.flags & (SF_HAS_PAR|SF_IN_PAR))\n                        pars++;\n                    if (data_fake.flags & SF_HAS_EVAL)\n                        data->flags |= SF_HAS_EVAL;\n                    data->whilem_c = data_fake.whilem_c;\n                    if ((flags & SCF_DO_SUBSTR) && data_fake.last_found) {\n                        int i;\n                        if (RExC_rx->minlen<*minnextp)\n                            RExC_rx->minlen=*minnextp;\n                        scan_commit(pRExC_state, &data_fake, minnextp, is_inf);\n                        SvREFCNT_dec_NN(data_fake.last_found);\n\n                        for (i = 0; i < 2; i++) {\n                            if (data_fake.substrs[i].minlenp != minlenp) {\n                                data->substrs[i].min_offset =\n                                            data_fake.substrs[i].min_offset;\n                                data->substrs[i].max_offset =\n                                            data_fake.substrs[i].max_offset;\n                                data->substrs[i].minlenp =\n                                            data_fake.substrs[i].minlenp;\n                                data->substrs[i].lookbehind += scan->flags;\n                            }\n                        }\n                    }\n                }\n\t    }\n#endif\n\t}\n\n\telse if (OP(scan) == OPEN) {\n\t    if (stopparen != (I32)ARG(scan))\n\t        pars++;\n\t}\n\telse if (OP(scan) == CLOSE) {\n\t    if (stopparen == (I32)ARG(scan)) {\n\t        break;\n\t    }\n\t    if ((I32)ARG(scan) == is_par) {\n\t\tnext = regnext(scan);\n\n\t\tif ( next && (OP(next) != WHILEM) && next < last)\n\t\t    is_par = 0;\t\t/* Disable optimization */\n\t    }\n\t    if (data)\n\t\t*(data->last_closep) = ARG(scan);\n\t}\n\telse if (OP(scan) == EVAL) {\n\t\tif (data)\n\t\t    data->flags |= SF_HAS_EVAL;\n\t}\n\telse if ( PL_regkind[OP(scan)] == ENDLIKE ) {\n\t    if (flags & SCF_DO_SUBSTR) {\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\tflags &= ~SCF_DO_SUBSTR;\n\t    }\n\t    if (data && OP(scan)==ACCEPT) {\n\t        data->flags |= SCF_SEEN_ACCEPT;\n\t        if (stopmin > min)\n\t            stopmin = min;\n\t    }\n\t}\n\telse if (OP(scan) == LOGICAL && scan->flags == 2) /* Embedded follows */\n\t{\n\t\tif (flags & SCF_DO_SUBSTR) {\n                    scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\t    data->cur_is_floating = 1; /* float */\n\t\t}\n\t\tis_inf = is_inf_internal = 1;\n\t\tif (flags & SCF_DO_STCLASS_OR) /* Allow everything */\n\t\t    ssc_anything(data->start_class);\n\t\tflags &= ~SCF_DO_STCLASS;\n\t}\n\telse if (OP(scan) == GPOS) {\n            if (!(RExC_rx->intflags & PREGf_GPOS_FLOAT) &&\n\t        !(delta || is_inf || (data && data->pos_delta)))\n\t    {\n                if (!(RExC_rx->intflags & PREGf_ANCH) && (flags & SCF_DO_SUBSTR))\n                    RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t        if (RExC_rx->gofs < (STRLEN)min)\n\t\t    RExC_rx->gofs = min;\n            } else {\n                RExC_rx->intflags |= PREGf_GPOS_FLOAT;\n                RExC_rx->gofs = 0;\n            }\n\t}\n#ifdef TRIE_STUDY_OPT\n#ifdef FULL_TRIE_STUDY\n        else if (PL_regkind[OP(scan)] == TRIE) {\n            /* NOTE - There is similar code to this block above for handling\n               BRANCH nodes on the initial study.  If you change stuff here\n               check there too. */\n            regnode *trie_node= scan;\n            regnode *tail= regnext(scan);\n            reg_trie_data *trie = (reg_trie_data*)RExC_rxi->data->data[ ARG(scan) ];\n            SSize_t max1 = 0, min1 = SSize_t_MAX;\n            regnode_ssc accum;\n\n            if (flags & SCF_DO_SUBSTR) { /* XXXX Add !SUSPEND? */\n                /* Cannot merge strings after this. */\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n            }\n            if (flags & SCF_DO_STCLASS)\n                ssc_init_zero(pRExC_state, &accum);\n\n            if (!trie->jump) {\n                min1= trie->minlen;\n                max1= trie->maxlen;\n            } else {\n                const regnode *nextbranch= NULL;\n                U32 word;\n\n                for ( word=1 ; word <= trie->wordcount ; word++)\n                {\n                    SSize_t deltanext=0, minnext=0, f = 0, fake;\n                    regnode_ssc this_class;\n\n                    StructCopy(&zero_scan_data, &data_fake, scan_data_t);\n                    if (data) {\n                        data_fake.whilem_c = data->whilem_c;\n                        data_fake.last_closep = data->last_closep;\n                    }\n                    else\n                        data_fake.last_closep = &fake;\n\t\t    data_fake.pos_delta = delta;\n                    if (flags & SCF_DO_STCLASS) {\n                        ssc_init(pRExC_state, &this_class);\n                        data_fake.start_class = &this_class;\n                        f = SCF_DO_STCLASS_AND;\n                    }\n                    if (flags & SCF_WHILEM_VISITED_POS)\n                        f |= SCF_WHILEM_VISITED_POS;\n\n                    if (trie->jump[word]) {\n                        if (!nextbranch)\n                            nextbranch = trie_node + trie->jump[0];\n                        scan= trie_node + trie->jump[word];\n                        /* We go from the jump point to the branch that follows\n                           it. Note this means we need the vestigal unused\n                           branches even though they arent otherwise used. */\n                        /* optimise study_chunk() for TRIE */\n                        minnext = study_chunk(pRExC_state, &scan, minlenp,\n                            &deltanext, (regnode *)nextbranch, &data_fake,\n                            stopparen, recursed_depth, NULL, f, depth+1);\n                    }\n                    if (nextbranch && PL_regkind[OP(nextbranch)]==BRANCH)\n                        nextbranch= regnext((regnode*)nextbranch);\n\n                    if (min1 > (SSize_t)(minnext + trie->minlen))\n                        min1 = minnext + trie->minlen;\n                    if (deltanext == SSize_t_MAX) {\n                        is_inf = is_inf_internal = 1;\n                        max1 = SSize_t_MAX;\n                    } else if (max1 < (SSize_t)(minnext + deltanext + trie->maxlen))\n                        max1 = minnext + deltanext + trie->maxlen;\n\n                    if (data_fake.flags & (SF_HAS_PAR|SF_IN_PAR))\n                        pars++;\n                    if (data_fake.flags & SCF_SEEN_ACCEPT) {\n                        if ( stopmin > min + min1)\n\t                    stopmin = min + min1;\n\t                flags &= ~SCF_DO_SUBSTR;\n\t                if (data)\n\t                    data->flags |= SCF_SEEN_ACCEPT;\n\t            }\n                    if (data) {\n                        if (data_fake.flags & SF_HAS_EVAL)\n                            data->flags |= SF_HAS_EVAL;\n                        data->whilem_c = data_fake.whilem_c;\n                    }\n                    if (flags & SCF_DO_STCLASS)\n                        ssc_or(pRExC_state, &accum, (regnode_charclass *) &this_class);\n                }\n            }\n            if (flags & SCF_DO_SUBSTR) {\n                data->pos_min += min1;\n                data->pos_delta += max1 - min1;\n                if (max1 != min1 || is_inf)\n                    data->cur_is_floating = 1; /* float */\n            }\n            min += min1;\n            if (delta != SSize_t_MAX) {\n                if (SSize_t_MAX - (max1 - min1) >= delta)\n                    delta += max1 - min1;\n                else\n                    delta = SSize_t_MAX;\n            }\n            if (flags & SCF_DO_STCLASS_OR) {\n                ssc_or(pRExC_state, data->start_class, (regnode_charclass *) &accum);\n                if (min1) {\n                    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n                    flags &= ~SCF_DO_STCLASS;\n                }\n            }\n            else if (flags & SCF_DO_STCLASS_AND) {\n                if (min1) {\n                    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) &accum);\n                    flags &= ~SCF_DO_STCLASS;\n                }\n                else {\n                    /* Switch to OR mode: cache the old value of\n                     * data->start_class */\n\t\t    INIT_AND_WITHP;\n                    StructCopy(data->start_class, and_withp, regnode_ssc);\n                    flags &= ~SCF_DO_STCLASS_AND;\n                    StructCopy(&accum, data->start_class, regnode_ssc);\n                    flags |= SCF_DO_STCLASS_OR;\n                }\n            }\n            scan= tail;\n            continue;\n        }\n#else\n\telse if (PL_regkind[OP(scan)] == TRIE) {\n\t    reg_trie_data *trie = (reg_trie_data*)RExC_rxi->data->data[ ARG(scan) ];\n\t    U8*bang=NULL;\n\n\t    min += trie->minlen;\n\t    delta += (trie->maxlen - trie->minlen);\n\t    flags &= ~SCF_DO_STCLASS; /* xxx */\n            if (flags & SCF_DO_SUBSTR) {\n                /* Cannot expect anything... */\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n    \t        data->pos_min += trie->minlen;\n    \t        data->pos_delta += (trie->maxlen - trie->minlen);\n\t\tif (trie->maxlen != trie->minlen)\n\t\t    data->cur_is_floating = 1; /* float */\n    \t    }\n    \t    if (trie->jump) /* no more substrings -- for now /grr*/\n               flags &= ~SCF_DO_SUBSTR;\n\t}\n#endif /* old or new */\n#endif /* TRIE_STUDY_OPT */\n\n\t/* Else: zero-length, ignore. */\n\tscan = regnext(scan);\n    }\n\n  finish:\n    if (frame) {\n        /* we need to unwind recursion. */\n        depth = depth - 1;\n\n        DEBUG_STUDYDATA(\"frame-end\", data, depth, is_inf);\n        DEBUG_PEEP(\"fend\", scan, depth, flags);\n\n        /* restore previous context */\n        last = frame->last_regnode;\n        scan = frame->next_regnode;\n        stopparen = frame->stopparen;\n        recursed_depth = frame->prev_recursed_depth;\n\n        RExC_frame_last = frame->prev_frame;\n        frame = frame->this_prev_frame;\n        goto fake_study_recurse;\n    }\n\n    assert(!frame);\n    DEBUG_STUDYDATA(\"pre-fin\", data, depth, is_inf);\n\n    *scanp = scan;\n    *deltap = is_inf_internal ? SSize_t_MAX : delta;\n\n    if (flags & SCF_DO_SUBSTR && is_inf)\n\tdata->pos_delta = SSize_t_MAX - data->pos_min;\n    if (is_par > (I32)U8_MAX)\n\tis_par = 0;\n    if (is_par && pars==1 && data) {\n\tdata->flags |= SF_IN_PAR;\n\tdata->flags &= ~SF_HAS_PAR;\n    }\n    else if (pars && data) {\n\tdata->flags |= SF_HAS_PAR;\n\tdata->flags &= ~SF_IN_PAR;\n    }\n    if (flags & SCF_DO_STCLASS_OR)\n\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n    if (flags & SCF_TRIE_RESTUDY)\n        data->flags |= \tSCF_TRIE_RESTUDY;\n\n    DEBUG_STUDYDATA(\"post-fin\", data, depth, is_inf);\n\n    {\n        SSize_t final_minlen= min < stopmin ? min : stopmin;\n\n        if (!(RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN)) {\n            if (final_minlen > SSize_t_MAX - delta)\n                RExC_maxlen = SSize_t_MAX;\n            else if (RExC_maxlen < final_minlen + delta)\n                RExC_maxlen = final_minlen + delta;\n        }\n        return final_minlen;\n    }\n    NOT_REACHED; /* NOTREACHED */", "func_src_after": "STATIC SSize_t\nS_study_chunk(pTHX_ RExC_state_t *pRExC_state, regnode **scanp,\n                        SSize_t *minlenp, SSize_t *deltap,\n\t\t\tregnode *last,\n\t\t\tscan_data_t *data,\n\t\t\tI32 stopparen,\n                        U32 recursed_depth,\n\t\t\tregnode_ssc *and_withp,\n\t\t\tU32 flags, U32 depth)\n\t\t\t/* scanp: Start here (read-write). */\n\t\t\t/* deltap: Write maxlen-minlen here. */\n\t\t\t/* last: Stop before this one. */\n\t\t\t/* data: string data about the pattern */\n\t\t\t/* stopparen: treat close N as END */\n\t\t\t/* recursed: which subroutines have we recursed into */\n\t\t\t/* and_withp: Valid if flags & SCF_DO_STCLASS_OR */\n{\n    dVAR;\n    /* There must be at least this number of characters to match */\n    SSize_t min = 0;\n    I32 pars = 0, code;\n    regnode *scan = *scanp, *next;\n    SSize_t delta = 0;\n    int is_inf = (flags & SCF_DO_SUBSTR) && (data->flags & SF_IS_INF);\n    int is_inf_internal = 0;\t\t/* The studied chunk is infinite */\n    I32 is_par = OP(scan) == OPEN ? ARG(scan) : 0;\n    scan_data_t data_fake;\n    SV *re_trie_maxbuff = NULL;\n    regnode *first_non_open = scan;\n    SSize_t stopmin = SSize_t_MAX;\n    scan_frame *frame = NULL;\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_STUDY_CHUNK;\n    RExC_study_started= 1;\n\n    Zero(&data_fake, 1, scan_data_t);\n\n    if ( depth == 0 ) {\n        while (first_non_open && OP(first_non_open) == OPEN)\n            first_non_open=regnext(first_non_open);\n    }\n\n\n  fake_study_recurse:\n    DEBUG_r(\n        RExC_study_chunk_recursed_count++;\n    );\n    DEBUG_OPTIMISE_MORE_r(\n    {\n        Perl_re_indentf( aTHX_  \"study_chunk stopparen=%ld recursed_count=%lu depth=%lu recursed_depth=%lu scan=%p last=%p\",\n            depth, (long)stopparen,\n            (unsigned long)RExC_study_chunk_recursed_count,\n            (unsigned long)depth, (unsigned long)recursed_depth,\n            scan,\n            last);\n        if (recursed_depth) {\n            U32 i;\n            U32 j;\n            for ( j = 0 ; j < recursed_depth ; j++ ) {\n                for ( i = 0 ; i < (U32)RExC_total_parens ; i++ ) {\n                    if (\n                        PAREN_TEST(RExC_study_chunk_recursed +\n                                   ( j * RExC_study_chunk_recursed_bytes), i )\n                        && (\n                            !j ||\n                            !PAREN_TEST(RExC_study_chunk_recursed +\n                                   (( j - 1 ) * RExC_study_chunk_recursed_bytes), i)\n                        )\n                    ) {\n                        Perl_re_printf( aTHX_ \" %d\",(int)i);\n                        break;\n                    }\n                }\n                if ( j + 1 < recursed_depth ) {\n                    Perl_re_printf( aTHX_  \",\");\n                }\n            }\n        }\n        Perl_re_printf( aTHX_ \"\\n\");\n    }\n    );\n    while ( scan && OP(scan) != END && scan < last ){\n        UV min_subtract = 0;    /* How mmany chars to subtract from the minimum\n                                   node length to get a real minimum (because\n                                   the folded version may be shorter) */\n\tbool unfolded_multi_char = FALSE;\n\t/* Peephole optimizer: */\n        DEBUG_STUDYDATA(\"Peep\", data, depth, is_inf);\n        DEBUG_PEEP(\"Peep\", scan, depth, flags);\n\n\n        /* The reason we do this here is that we need to deal with things like\n         * /(?:f)(?:o)(?:o)/ which cant be dealt with by the normal EXACT\n         * parsing code, as each (?:..) is handled by a different invocation of\n         * reg() -- Yves\n         */\n        JOIN_EXACT(scan,&min_subtract, &unfolded_multi_char, 0);\n\n\t/* Follow the next-chain of the current node and optimize\n\t   away all the NOTHINGs from it.  */\n\tif (OP(scan) != CURLYX) {\n\t    const int max = (reg_off_by_arg[OP(scan)]\n\t\t       ? I32_MAX\n\t\t       /* I32 may be smaller than U16 on CRAYs! */\n\t\t       : (I32_MAX < U16_MAX ? I32_MAX : U16_MAX));\n\t    int off = (reg_off_by_arg[OP(scan)] ? ARG(scan) : NEXT_OFF(scan));\n\t    int noff;\n\t    regnode *n = scan;\n\n\t    /* Skip NOTHING and LONGJMP. */\n\t    while ((n = regnext(n))\n\t\t   && ((PL_regkind[OP(n)] == NOTHING && (noff = NEXT_OFF(n)))\n\t\t       || ((OP(n) == LONGJMP) && (noff = ARG(n))))\n\t\t   && off + noff < max)\n\t\toff += noff;\n\t    if (reg_off_by_arg[OP(scan)])\n\t\tARG(scan) = off;\n\t    else\n\t\tNEXT_OFF(scan) = off;\n\t}\n\n\t/* The principal pseudo-switch.  Cannot be a switch, since we\n\t   look into several different things.  */\n        if ( OP(scan) == DEFINEP ) {\n            SSize_t minlen = 0;\n            SSize_t deltanext = 0;\n            SSize_t fake_last_close = 0;\n            I32 f = SCF_IN_DEFINE;\n\n            StructCopy(&zero_scan_data, &data_fake, scan_data_t);\n            scan = regnext(scan);\n            assert( OP(scan) == IFTHEN );\n            DEBUG_PEEP(\"expect IFTHEN\", scan, depth, flags);\n\n            data_fake.last_closep= &fake_last_close;\n            minlen = *minlenp;\n            next = regnext(scan);\n            scan = NEXTOPER(NEXTOPER(scan));\n            DEBUG_PEEP(\"scan\", scan, depth, flags);\n            DEBUG_PEEP(\"next\", next, depth, flags);\n\n            /* we suppose the run is continuous, last=next...\n             * NOTE we dont use the return here! */\n            /* DEFINEP study_chunk() recursion */\n            (void)study_chunk(pRExC_state, &scan, &minlen,\n                              &deltanext, next, &data_fake, stopparen,\n                              recursed_depth, NULL, f, depth+1);\n\n            scan = next;\n        } else\n        if (\n            OP(scan) == BRANCH  ||\n            OP(scan) == BRANCHJ ||\n            OP(scan) == IFTHEN\n        ) {\n\t    next = regnext(scan);\n\t    code = OP(scan);\n\n            /* The op(next)==code check below is to see if we\n             * have \"BRANCH-BRANCH\", \"BRANCHJ-BRANCHJ\", \"IFTHEN-IFTHEN\"\n             * IFTHEN is special as it might not appear in pairs.\n             * Not sure whether BRANCH-BRANCHJ is possible, regardless\n             * we dont handle it cleanly. */\n\t    if (OP(next) == code || code == IFTHEN) {\n                /* NOTE - There is similar code to this block below for\n                 * handling TRIE nodes on a re-study.  If you change stuff here\n                 * check there too. */\n\t\tSSize_t max1 = 0, min1 = SSize_t_MAX, num = 0;\n\t\tregnode_ssc accum;\n\t\tregnode * const startbranch=scan;\n\n                if (flags & SCF_DO_SUBSTR) {\n                    /* Cannot merge strings after this. */\n                    scan_commit(pRExC_state, data, minlenp, is_inf);\n                }\n\n                if (flags & SCF_DO_STCLASS)\n\t\t    ssc_init_zero(pRExC_state, &accum);\n\n\t\twhile (OP(scan) == code) {\n\t\t    SSize_t deltanext, minnext, fake;\n\t\t    I32 f = 0;\n\t\t    regnode_ssc this_class;\n\n                    DEBUG_PEEP(\"Branch\", scan, depth, flags);\n\n\t\t    num++;\n                    StructCopy(&zero_scan_data, &data_fake, scan_data_t);\n\t\t    if (data) {\n\t\t\tdata_fake.whilem_c = data->whilem_c;\n\t\t\tdata_fake.last_closep = data->last_closep;\n\t\t    }\n\t\t    else\n\t\t\tdata_fake.last_closep = &fake;\n\n\t\t    data_fake.pos_delta = delta;\n\t\t    next = regnext(scan);\n\n                    scan = NEXTOPER(scan); /* everything */\n                    if (code != BRANCH)    /* everything but BRANCH */\n\t\t\tscan = NEXTOPER(scan);\n\n\t\t    if (flags & SCF_DO_STCLASS) {\n\t\t\tssc_init(pRExC_state, &this_class);\n\t\t\tdata_fake.start_class = &this_class;\n\t\t\tf = SCF_DO_STCLASS_AND;\n\t\t    }\n\t\t    if (flags & SCF_WHILEM_VISITED_POS)\n\t\t\tf |= SCF_WHILEM_VISITED_POS;\n\n\t\t    /* we suppose the run is continuous, last=next...*/\n                    /* recurse study_chunk() for each BRANCH in an alternation */\n\t\t    minnext = study_chunk(pRExC_state, &scan, minlenp,\n                                      &deltanext, next, &data_fake, stopparen,\n                                      recursed_depth, NULL, f, depth+1);\n\n\t\t    if (min1 > minnext)\n\t\t\tmin1 = minnext;\n\t\t    if (deltanext == SSize_t_MAX) {\n\t\t\tis_inf = is_inf_internal = 1;\n\t\t\tmax1 = SSize_t_MAX;\n\t\t    } else if (max1 < minnext + deltanext)\n\t\t\tmax1 = minnext + deltanext;\n\t\t    scan = next;\n\t\t    if (data_fake.flags & (SF_HAS_PAR|SF_IN_PAR))\n\t\t\tpars++;\n\t            if (data_fake.flags & SCF_SEEN_ACCEPT) {\n\t                if ( stopmin > minnext)\n\t                    stopmin = min + min1;\n\t                flags &= ~SCF_DO_SUBSTR;\n\t                if (data)\n\t                    data->flags |= SCF_SEEN_ACCEPT;\n\t            }\n\t\t    if (data) {\n\t\t\tif (data_fake.flags & SF_HAS_EVAL)\n\t\t\t    data->flags |= SF_HAS_EVAL;\n\t\t\tdata->whilem_c = data_fake.whilem_c;\n\t\t    }\n\t\t    if (flags & SCF_DO_STCLASS)\n\t\t\tssc_or(pRExC_state, &accum, (regnode_charclass*)&this_class);\n\t\t}\n\t\tif (code == IFTHEN && num < 2) /* Empty ELSE branch */\n\t\t    min1 = 0;\n\t\tif (flags & SCF_DO_SUBSTR) {\n\t\t    data->pos_min += min1;\n\t\t    if (data->pos_delta >= SSize_t_MAX - (max1 - min1))\n\t\t        data->pos_delta = SSize_t_MAX;\n\t\t    else\n\t\t        data->pos_delta += max1 - min1;\n\t\t    if (max1 != min1 || is_inf)\n\t\t\tdata->cur_is_floating = 1;\n\t\t}\n\t\tmin += min1;\n\t\tif (delta == SSize_t_MAX\n\t\t || SSize_t_MAX - delta - (max1 - min1) < 0)\n\t\t    delta = SSize_t_MAX;\n\t\telse\n\t\t    delta += max1 - min1;\n\t\tif (flags & SCF_DO_STCLASS_OR) {\n\t\t    ssc_or(pRExC_state, data->start_class, (regnode_charclass*) &accum);\n\t\t    if (min1) {\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\t\t\tflags &= ~SCF_DO_STCLASS;\n\t\t    }\n\t\t}\n\t\telse if (flags & SCF_DO_STCLASS_AND) {\n\t\t    if (min1) {\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) &accum);\n\t\t\tflags &= ~SCF_DO_STCLASS;\n\t\t    }\n\t\t    else {\n\t\t\t/* Switch to OR mode: cache the old value of\n\t\t\t * data->start_class */\n\t\t\tINIT_AND_WITHP;\n\t\t\tStructCopy(data->start_class, and_withp, regnode_ssc);\n\t\t\tflags &= ~SCF_DO_STCLASS_AND;\n\t\t\tStructCopy(&accum, data->start_class, regnode_ssc);\n\t\t\tflags |= SCF_DO_STCLASS_OR;\n\t\t    }\n\t\t}\n\n                if (PERL_ENABLE_TRIE_OPTIMISATION &&\n                        OP( startbranch ) == BRANCH )\n                {\n\t\t/* demq.\n\n                   Assuming this was/is a branch we are dealing with: 'scan'\n                   now points at the item that follows the branch sequence,\n                   whatever it is. We now start at the beginning of the\n                   sequence and look for subsequences of\n\n\t\t   BRANCH->EXACT=>x1\n\t\t   BRANCH->EXACT=>x2\n\t\t   tail\n\n                   which would be constructed from a pattern like\n                   /A|LIST|OF|WORDS/\n\n\t\t   If we can find such a subsequence we need to turn the first\n\t\t   element into a trie and then add the subsequent branch exact\n\t\t   strings to the trie.\n\n\t\t   We have two cases\n\n                     1. patterns where the whole set of branches can be\n                        converted.\n\n\t\t     2. patterns where only a subset can be converted.\n\n\t\t   In case 1 we can replace the whole set with a single regop\n\t\t   for the trie. In case 2 we need to keep the start and end\n\t\t   branches so\n\n\t\t     'BRANCH EXACT; BRANCH EXACT; BRANCH X'\n\t\t     becomes BRANCH TRIE; BRANCH X;\n\n\t\t  There is an additional case, that being where there is a\n\t\t  common prefix, which gets split out into an EXACT like node\n\t\t  preceding the TRIE node.\n\n\t\t  If x(1..n)==tail then we can do a simple trie, if not we make\n\t\t  a \"jump\" trie, such that when we match the appropriate word\n\t\t  we \"jump\" to the appropriate tail node. Essentially we turn\n\t\t  a nested if into a case structure of sorts.\n\n\t\t*/\n\n\t\t    int made=0;\n\t\t    if (!re_trie_maxbuff) {\n\t\t\tre_trie_maxbuff = get_sv(RE_TRIE_MAXBUF_NAME, 1);\n\t\t\tif (!SvIOK(re_trie_maxbuff))\n\t\t\t    sv_setiv(re_trie_maxbuff, RE_TRIE_MAXBUF_INIT);\n\t\t    }\n                    if ( SvIV(re_trie_maxbuff)>=0  ) {\n                        regnode *cur;\n                        regnode *first = (regnode *)NULL;\n                        regnode *last = (regnode *)NULL;\n                        regnode *tail = scan;\n                        U8 trietype = 0;\n                        U32 count=0;\n\n                        /* var tail is used because there may be a TAIL\n                           regop in the way. Ie, the exacts will point to the\n                           thing following the TAIL, but the last branch will\n                           point at the TAIL. So we advance tail. If we\n                           have nested (?:) we may have to move through several\n                           tails.\n                         */\n\n                        while ( OP( tail ) == TAIL ) {\n                            /* this is the TAIL generated by (?:) */\n                            tail = regnext( tail );\n                        }\n\n\n                        DEBUG_TRIE_COMPILE_r({\n                            regprop(RExC_rx, RExC_mysv, tail, NULL, pRExC_state);\n                            Perl_re_indentf( aTHX_  \"%s %\" UVuf \":%s\\n\",\n                              depth+1,\n                              \"Looking for TRIE'able sequences. Tail node is \",\n                              (UV) REGNODE_OFFSET(tail),\n                              SvPV_nolen_const( RExC_mysv )\n                            );\n                        });\n\n                        /*\n\n                            Step through the branches\n                                cur represents each branch,\n                                noper is the first thing to be matched as part\n                                      of that branch\n                                noper_next is the regnext() of that node.\n\n                            We normally handle a case like this\n                            /FOO[xyz]|BAR[pqr]/ via a \"jump trie\" but we also\n                            support building with NOJUMPTRIE, which restricts\n                            the trie logic to structures like /FOO|BAR/.\n\n                            If noper is a trieable nodetype then the branch is\n                            a possible optimization target. If we are building\n                            under NOJUMPTRIE then we require that noper_next is\n                            the same as scan (our current position in the regex\n                            program).\n\n                            Once we have two or more consecutive such branches\n                            we can create a trie of the EXACT's contents and\n                            stitch it in place into the program.\n\n                            If the sequence represents all of the branches in\n                            the alternation we replace the entire thing with a\n                            single TRIE node.\n\n                            Otherwise when it is a subsequence we need to\n                            stitch it in place and replace only the relevant\n                            branches. This means the first branch has to remain\n                            as it is used by the alternation logic, and its\n                            next pointer, and needs to be repointed at the item\n                            on the branch chain following the last branch we\n                            have optimized away.\n\n                            This could be either a BRANCH, in which case the\n                            subsequence is internal, or it could be the item\n                            following the branch sequence in which case the\n                            subsequence is at the end (which does not\n                            necessarily mean the first node is the start of the\n                            alternation).\n\n                            TRIE_TYPE(X) is a define which maps the optype to a\n                            trietype.\n\n                                optype          |  trietype\n                                ----------------+-----------\n                                NOTHING         | NOTHING\n                                EXACT           | EXACT\n                                EXACT_ONLY8     | EXACT\n                                EXACTFU         | EXACTFU\n                                EXACTFU_ONLY8   | EXACTFU\n                                EXACTFUP        | EXACTFU\n                                EXACTFAA        | EXACTFAA\n                                EXACTL          | EXACTL\n                                EXACTFLU8       | EXACTFLU8\n\n\n                        */\n#define TRIE_TYPE(X) ( ( NOTHING == (X) )                                   \\\n                       ? NOTHING                                            \\\n                       : ( EXACT == (X) || EXACT_ONLY8 == (X) )             \\\n                         ? EXACT                                            \\\n                         : (     EXACTFU == (X)                             \\\n                              || EXACTFU_ONLY8 == (X)                       \\\n                              || EXACTFUP == (X) )                          \\\n                           ? EXACTFU                                        \\\n                           : ( EXACTFAA == (X) )                            \\\n                             ? EXACTFAA                                     \\\n                             : ( EXACTL == (X) )                            \\\n                               ? EXACTL                                     \\\n                               : ( EXACTFLU8 == (X) )                       \\\n                                 ? EXACTFLU8                                \\\n                                 : 0 )\n\n                        /* dont use tail as the end marker for this traverse */\n                        for ( cur = startbranch ; cur != scan ; cur = regnext( cur ) ) {\n                            regnode * const noper = NEXTOPER( cur );\n                            U8 noper_type = OP( noper );\n                            U8 noper_trietype = TRIE_TYPE( noper_type );\n#if defined(DEBUGGING) || defined(NOJUMPTRIE)\n                            regnode * const noper_next = regnext( noper );\n                            U8 noper_next_type = (noper_next && noper_next < tail) ? OP(noper_next) : 0;\n                            U8 noper_next_trietype = (noper_next && noper_next < tail) ? TRIE_TYPE( noper_next_type ) :0;\n#endif\n\n                            DEBUG_TRIE_COMPILE_r({\n                                regprop(RExC_rx, RExC_mysv, cur, NULL, pRExC_state);\n                                Perl_re_indentf( aTHX_  \"- %d:%s (%d)\",\n                                   depth+1,\n                                   REG_NODE_NUM(cur), SvPV_nolen_const( RExC_mysv ), REG_NODE_NUM(cur) );\n\n                                regprop(RExC_rx, RExC_mysv, noper, NULL, pRExC_state);\n                                Perl_re_printf( aTHX_  \" -> %d:%s\",\n                                    REG_NODE_NUM(noper), SvPV_nolen_const(RExC_mysv));\n\n                                if ( noper_next ) {\n                                  regprop(RExC_rx, RExC_mysv, noper_next, NULL, pRExC_state);\n                                  Perl_re_printf( aTHX_ \"\\t=> %d:%s\\t\",\n                                    REG_NODE_NUM(noper_next), SvPV_nolen_const(RExC_mysv));\n                                }\n                                Perl_re_printf( aTHX_  \"(First==%d,Last==%d,Cur==%d,tt==%s,ntt==%s,nntt==%s)\\n\",\n                                   REG_NODE_NUM(first), REG_NODE_NUM(last), REG_NODE_NUM(cur),\n\t\t\t\t   PL_reg_name[trietype], PL_reg_name[noper_trietype], PL_reg_name[noper_next_trietype]\n\t\t\t\t);\n                            });\n\n                            /* Is noper a trieable nodetype that can be merged\n                             * with the current trie (if there is one)? */\n                            if ( noper_trietype\n                                  &&\n                                  (\n                                        ( noper_trietype == NOTHING )\n                                        || ( trietype == NOTHING )\n                                        || ( trietype == noper_trietype )\n                                  )\n#ifdef NOJUMPTRIE\n                                  && noper_next >= tail\n#endif\n                                  && count < U16_MAX)\n                            {\n                                /* Handle mergable triable node Either we are\n                                 * the first node in a new trieable sequence,\n                                 * in which case we do some bookkeeping,\n                                 * otherwise we update the end pointer. */\n                                if ( !first ) {\n                                    first = cur;\n\t\t\t\t    if ( noper_trietype == NOTHING ) {\n#if !defined(DEBUGGING) && !defined(NOJUMPTRIE)\n\t\t\t\t\tregnode * const noper_next = regnext( noper );\n                                        U8 noper_next_type = (noper_next && noper_next < tail) ? OP(noper_next) : 0;\n\t\t\t\t\tU8 noper_next_trietype = noper_next_type ? TRIE_TYPE( noper_next_type ) :0;\n#endif\n\n                                        if ( noper_next_trietype ) {\n\t\t\t\t\t    trietype = noper_next_trietype;\n                                        } else if (noper_next_type)  {\n                                            /* a NOTHING regop is 1 regop wide.\n                                             * We need at least two for a trie\n                                             * so we can't merge this in */\n                                            first = NULL;\n                                        }\n                                    } else {\n                                        trietype = noper_trietype;\n                                    }\n                                } else {\n                                    if ( trietype == NOTHING )\n                                        trietype = noper_trietype;\n                                    last = cur;\n                                }\n\t\t\t\tif (first)\n\t\t\t\t    count++;\n                            } /* end handle mergable triable node */\n                            else {\n                                /* handle unmergable node -\n                                 * noper may either be a triable node which can\n                                 * not be tried together with the current trie,\n                                 * or a non triable node */\n                                if ( last ) {\n                                    /* If last is set and trietype is not\n                                     * NOTHING then we have found at least two\n                                     * triable branch sequences in a row of a\n                                     * similar trietype so we can turn them\n                                     * into a trie. If/when we allow NOTHING to\n                                     * start a trie sequence this condition\n                                     * will be required, and it isn't expensive\n                                     * so we leave it in for now. */\n                                    if ( trietype && trietype != NOTHING )\n                                        make_trie( pRExC_state,\n                                                startbranch, first, cur, tail,\n                                                count, trietype, depth+1 );\n                                    last = NULL; /* note: we clear/update\n                                                    first, trietype etc below,\n                                                    so we dont do it here */\n                                }\n                                if ( noper_trietype\n#ifdef NOJUMPTRIE\n                                     && noper_next >= tail\n#endif\n                                ){\n                                    /* noper is triable, so we can start a new\n                                     * trie sequence */\n                                    count = 1;\n                                    first = cur;\n                                    trietype = noper_trietype;\n                                } else if (first) {\n                                    /* if we already saw a first but the\n                                     * current node is not triable then we have\n                                     * to reset the first information. */\n                                    count = 0;\n                                    first = NULL;\n                                    trietype = 0;\n                                }\n                            } /* end handle unmergable node */\n                        } /* loop over branches */\n                        DEBUG_TRIE_COMPILE_r({\n                            regprop(RExC_rx, RExC_mysv, cur, NULL, pRExC_state);\n                            Perl_re_indentf( aTHX_  \"- %s (%d) <SCAN FINISHED> \",\n                              depth+1, SvPV_nolen_const( RExC_mysv ), REG_NODE_NUM(cur));\n                            Perl_re_printf( aTHX_  \"(First==%d, Last==%d, Cur==%d, tt==%s)\\n\",\n                               REG_NODE_NUM(first), REG_NODE_NUM(last), REG_NODE_NUM(cur),\n                               PL_reg_name[trietype]\n                            );\n\n                        });\n                        if ( last && trietype ) {\n                            if ( trietype != NOTHING ) {\n                                /* the last branch of the sequence was part of\n                                 * a trie, so we have to construct it here\n                                 * outside of the loop */\n                                made= make_trie( pRExC_state, startbranch,\n                                                 first, scan, tail, count,\n                                                 trietype, depth+1 );\n#ifdef TRIE_STUDY_OPT\n                                if ( ((made == MADE_EXACT_TRIE &&\n                                     startbranch == first)\n                                     || ( first_non_open == first )) &&\n                                     depth==0 ) {\n                                    flags |= SCF_TRIE_RESTUDY;\n                                    if ( startbranch == first\n                                         && scan >= tail )\n                                    {\n                                        RExC_seen &=~REG_TOP_LEVEL_BRANCHES_SEEN;\n                                    }\n                                }\n#endif\n                            } else {\n                                /* at this point we know whatever we have is a\n                                 * NOTHING sequence/branch AND if 'startbranch'\n                                 * is 'first' then we can turn the whole thing\n                                 * into a NOTHING\n                                 */\n                                if ( startbranch == first ) {\n                                    regnode *opt;\n                                    /* the entire thing is a NOTHING sequence,\n                                     * something like this: (?:|) So we can\n                                     * turn it into a plain NOTHING op. */\n                                    DEBUG_TRIE_COMPILE_r({\n                                        regprop(RExC_rx, RExC_mysv, cur, NULL, pRExC_state);\n                                        Perl_re_indentf( aTHX_  \"- %s (%d) <NOTHING BRANCH SEQUENCE>\\n\",\n                                          depth+1,\n                                          SvPV_nolen_const( RExC_mysv ), REG_NODE_NUM(cur));\n\n                                    });\n                                    OP(startbranch)= NOTHING;\n                                    NEXT_OFF(startbranch)= tail - startbranch;\n                                    for ( opt= startbranch + 1; opt < tail ; opt++ )\n                                        OP(opt)= OPTIMIZED;\n                                }\n                            }\n                        } /* end if ( last) */\n                    } /* TRIE_MAXBUF is non zero */\n\n                } /* do trie */\n\n\t    }\n\t    else if ( code == BRANCHJ ) {  /* single branch is optimized. */\n\t\tscan = NEXTOPER(NEXTOPER(scan));\n\t    } else\t\t\t/* single branch is optimized. */\n\t\tscan = NEXTOPER(scan);\n\t    continue;\n        } else if (OP(scan) == SUSPEND || OP(scan) == GOSUB) {\n            I32 paren = 0;\n            regnode *start = NULL;\n            regnode *end = NULL;\n            U32 my_recursed_depth= recursed_depth;\n\n            if (OP(scan) != SUSPEND) { /* GOSUB */\n                /* Do setup, note this code has side effects beyond\n                 * the rest of this block. Specifically setting\n                 * RExC_recurse[] must happen at least once during\n                 * study_chunk(). */\n                paren = ARG(scan);\n                RExC_recurse[ARG2L(scan)] = scan;\n                start = REGNODE_p(RExC_open_parens[paren]);\n                end   = REGNODE_p(RExC_close_parens[paren]);\n\n                /* NOTE we MUST always execute the above code, even\n                 * if we do nothing with a GOSUB */\n                if (\n                    ( flags & SCF_IN_DEFINE )\n                    ||\n                    (\n                        (is_inf_internal || is_inf || (data && data->flags & SF_IS_INF))\n                        &&\n                        ( (flags & (SCF_DO_STCLASS | SCF_DO_SUBSTR)) == 0 )\n                    )\n                ) {\n                    /* no need to do anything here if we are in a define. */\n                    /* or we are after some kind of infinite construct\n                     * so we can skip recursing into this item.\n                     * Since it is infinite we will not change the maxlen\n                     * or delta, and if we miss something that might raise\n                     * the minlen it will merely pessimise a little.\n                     *\n                     * Iow /(?(DEFINE)(?<foo>foo|food))a+(?&foo)/\n                     * might result in a minlen of 1 and not of 4,\n                     * but this doesn't make us mismatch, just try a bit\n                     * harder than we should.\n                     * */\n                    scan= regnext(scan);\n                    continue;\n                }\n\n                if (\n                    !recursed_depth\n                    ||\n                    !PAREN_TEST(RExC_study_chunk_recursed + ((recursed_depth-1) * RExC_study_chunk_recursed_bytes), paren)\n                ) {\n                    /* it is quite possible that there are more efficient ways\n                     * to do this. We maintain a bitmap per level of recursion\n                     * of which patterns we have entered so we can detect if a\n                     * pattern creates a possible infinite loop. When we\n                     * recurse down a level we copy the previous levels bitmap\n                     * down. When we are at recursion level 0 we zero the top\n                     * level bitmap. It would be nice to implement a different\n                     * more efficient way of doing this. In particular the top\n                     * level bitmap may be unnecessary.\n                     */\n                    if (!recursed_depth) {\n                        Zero(RExC_study_chunk_recursed, RExC_study_chunk_recursed_bytes, U8);\n                    } else {\n                        Copy(RExC_study_chunk_recursed + ((recursed_depth-1) * RExC_study_chunk_recursed_bytes),\n                             RExC_study_chunk_recursed + (recursed_depth * RExC_study_chunk_recursed_bytes),\n                             RExC_study_chunk_recursed_bytes, U8);\n                    }\n                    /* we havent recursed into this paren yet, so recurse into it */\n                    DEBUG_STUDYDATA(\"gosub-set\", data, depth, is_inf);\n                    PAREN_SET(RExC_study_chunk_recursed + (recursed_depth * RExC_study_chunk_recursed_bytes), paren);\n                    my_recursed_depth= recursed_depth + 1;\n                } else {\n                    DEBUG_STUDYDATA(\"gosub-inf\", data, depth, is_inf);\n                    /* some form of infinite recursion, assume infinite length\n                     * */\n                    if (flags & SCF_DO_SUBSTR) {\n                        scan_commit(pRExC_state, data, minlenp, is_inf);\n                        data->cur_is_floating = 1;\n                    }\n                    is_inf = is_inf_internal = 1;\n                    if (flags & SCF_DO_STCLASS_OR) /* Allow everything */\n                        ssc_anything(data->start_class);\n                    flags &= ~SCF_DO_STCLASS;\n\n                    start= NULL; /* reset start so we dont recurse later on. */\n\t        }\n            } else {\n\t        paren = stopparen;\n                start = scan + 2;\n\t        end = regnext(scan);\n\t    }\n            if (start) {\n                scan_frame *newframe;\n                assert(end);\n                if (!RExC_frame_last) {\n                    Newxz(newframe, 1, scan_frame);\n                    SAVEDESTRUCTOR_X(S_unwind_scan_frames, newframe);\n                    RExC_frame_head= newframe;\n                    RExC_frame_count++;\n                } else if (!RExC_frame_last->next_frame) {\n                    Newxz(newframe, 1, scan_frame);\n                    RExC_frame_last->next_frame= newframe;\n                    newframe->prev_frame= RExC_frame_last;\n                    RExC_frame_count++;\n                } else {\n                    newframe= RExC_frame_last->next_frame;\n                }\n                RExC_frame_last= newframe;\n\n                newframe->next_regnode = regnext(scan);\n                newframe->last_regnode = last;\n                newframe->stopparen = stopparen;\n                newframe->prev_recursed_depth = recursed_depth;\n                newframe->this_prev_frame= frame;\n\n                DEBUG_STUDYDATA(\"frame-new\", data, depth, is_inf);\n                DEBUG_PEEP(\"fnew\", scan, depth, flags);\n\n\t        frame = newframe;\n\t        scan =  start;\n\t        stopparen = paren;\n\t        last = end;\n                depth = depth + 1;\n                recursed_depth= my_recursed_depth;\n\n\t        continue;\n\t    }\n\t}\n\telse if (   OP(scan) == EXACT\n                 || OP(scan) == EXACT_ONLY8\n                 || OP(scan) == EXACTL)\n        {\n\t    SSize_t l = STR_LEN(scan);\n\t    UV uc;\n            assert(l);\n\t    if (UTF) {\n\t\tconst U8 * const s = (U8*)STRING(scan);\n\t\tuc = utf8_to_uvchr_buf(s, s + l, NULL);\n\t\tl = utf8_length(s, s + l);\n\t    } else {\n\t\tuc = *((U8*)STRING(scan));\n\t    }\n\t    min += l;\n\t    if (flags & SCF_DO_SUBSTR) { /* Update longest substr. */\n\t\t/* The code below prefers earlier match for fixed\n\t\t   offset, later match for variable offset.  */\n\t\tif (data->last_end == -1) { /* Update the start info. */\n\t\t    data->last_start_min = data->pos_min;\n \t\t    data->last_start_max = is_inf\n \t\t\t? SSize_t_MAX : data->pos_min + data->pos_delta;\n\t\t}\n\t\tsv_catpvn(data->last_found, STRING(scan), STR_LEN(scan));\n\t\tif (UTF)\n\t\t    SvUTF8_on(data->last_found);\n\t\t{\n\t\t    SV * const sv = data->last_found;\n\t\t    MAGIC * const mg = SvUTF8(sv) && SvMAGICAL(sv) ?\n\t\t\tmg_find(sv, PERL_MAGIC_utf8) : NULL;\n\t\t    if (mg && mg->mg_len >= 0)\n\t\t\tmg->mg_len += utf8_length((U8*)STRING(scan),\n                                              (U8*)STRING(scan)+STR_LEN(scan));\n\t\t}\n\t\tdata->last_end = data->pos_min + l;\n\t\tdata->pos_min += l; /* As in the first entry. */\n\t\tdata->flags &= ~SF_BEFORE_EOL;\n\t    }\n\n            /* ANDing the code point leaves at most it, and not in locale, and\n             * can't match null string */\n\t    if (flags & SCF_DO_STCLASS_AND) {\n                ssc_cp_and(data->start_class, uc);\n                ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n                ssc_clear_locale(data->start_class);\n\t    }\n\t    else if (flags & SCF_DO_STCLASS_OR) {\n                ssc_add_cp(data->start_class, uc);\n\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\n                /* See commit msg 749e076fceedeb708a624933726e7989f2302f6a */\n                ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n\t    }\n\t    flags &= ~SCF_DO_STCLASS;\n\t}\n        else if (PL_regkind[OP(scan)] == EXACT) {\n            /* But OP != EXACT!, so is EXACTFish */\n\t    SSize_t l = STR_LEN(scan);\n            const U8 * s = (U8*)STRING(scan);\n\n\t    /* Search for fixed substrings supports EXACT only. */\n\t    if (flags & SCF_DO_SUBSTR) {\n\t\tassert(data);\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n\t    }\n\t    if (UTF) {\n\t\tl = utf8_length(s, s + l);\n\t    }\n\t    if (unfolded_multi_char) {\n                RExC_seen |= REG_UNFOLDED_MULTI_SEEN;\n\t    }\n\t    min += l - min_subtract;\n            assert (min >= 0);\n            delta += min_subtract;\n\t    if (flags & SCF_DO_SUBSTR) {\n\t\tdata->pos_min += l - min_subtract;\n\t\tif (data->pos_min < 0) {\n                    data->pos_min = 0;\n                }\n                data->pos_delta += min_subtract;\n\t\tif (min_subtract) {\n\t\t    data->cur_is_floating = 1; /* float */\n\t\t}\n\t    }\n\n            if (flags & SCF_DO_STCLASS) {\n                SV* EXACTF_invlist = _make_exactf_invlist(pRExC_state, scan);\n\n                assert(EXACTF_invlist);\n                if (flags & SCF_DO_STCLASS_AND) {\n                    if (OP(scan) != EXACTFL)\n                        ssc_clear_locale(data->start_class);\n                    ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n                    ANYOF_POSIXL_ZERO(data->start_class);\n                    ssc_intersection(data->start_class, EXACTF_invlist, FALSE);\n                }\n                else {  /* SCF_DO_STCLASS_OR */\n                    ssc_union(data->start_class, EXACTF_invlist, FALSE);\n                    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\n                    /* See commit msg 749e076fceedeb708a624933726e7989f2302f6a */\n                    ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n                }\n                flags &= ~SCF_DO_STCLASS;\n                SvREFCNT_dec(EXACTF_invlist);\n            }\n\t}\n\telse if (REGNODE_VARIES(OP(scan))) {\n\t    SSize_t mincount, maxcount, minnext, deltanext, pos_before = 0;\n\t    I32 fl = 0, f = flags;\n\t    regnode * const oscan = scan;\n\t    regnode_ssc this_class;\n\t    regnode_ssc *oclass = NULL;\n\t    I32 next_is_eval = 0;\n\n\t    switch (PL_regkind[OP(scan)]) {\n\t    case WHILEM:\t\t/* End of (?:...)* . */\n\t\tscan = NEXTOPER(scan);\n\t\tgoto finish;\n\t    case PLUS:\n\t\tif (flags & (SCF_DO_SUBSTR | SCF_DO_STCLASS)) {\n\t\t    next = NEXTOPER(scan);\n\t\t    if (   OP(next) == EXACT\n                        || OP(next) == EXACT_ONLY8\n                        || OP(next) == EXACTL\n                        || (flags & SCF_DO_STCLASS))\n                    {\n\t\t\tmincount = 1;\n\t\t\tmaxcount = REG_INFTY;\n\t\t\tnext = regnext(scan);\n\t\t\tscan = NEXTOPER(scan);\n\t\t\tgoto do_curly;\n\t\t    }\n\t\t}\n\t\tif (flags & SCF_DO_SUBSTR)\n\t\t    data->pos_min++;\n\t\tmin++;\n\t\t/* FALLTHROUGH */\n\t    case STAR:\n                next = NEXTOPER(scan);\n\n                /* This temporary node can now be turned into EXACTFU, and\n                 * must, as regexec.c doesn't handle it */\n                if (OP(next) == EXACTFU_S_EDGE) {\n                    OP(next) = EXACTFU;\n                }\n\n                if (     STR_LEN(next) == 1\n                    &&   isALPHA_A(* STRING(next))\n                    && (         OP(next) == EXACTFAA\n                        || (     OP(next) == EXACTFU\n                            && ! HAS_NONLATIN1_SIMPLE_FOLD_CLOSURE(* STRING(next)))))\n                {\n                    /* These differ in just one bit */\n                    U8 mask = ~ ('A' ^ 'a');\n\n                    assert(isALPHA_A(* STRING(next)));\n\n                    /* Then replace it by an ANYOFM node, with\n                    * the mask set to the complement of the\n                    * bit that differs between upper and lower\n                    * case, and the lowest code point of the\n                    * pair (which the '&' forces) */\n                    OP(next) = ANYOFM;\n                    ARG_SET(next, *STRING(next) & mask);\n                    FLAGS(next) = mask;\n                }\n\n\t\tif (flags & SCF_DO_STCLASS) {\n\t\t    mincount = 0;\n\t\t    maxcount = REG_INFTY;\n\t\t    next = regnext(scan);\n\t\t    scan = NEXTOPER(scan);\n\t\t    goto do_curly;\n\t\t}\n\t\tif (flags & SCF_DO_SUBSTR) {\n                    scan_commit(pRExC_state, data, minlenp, is_inf);\n                    /* Cannot extend fixed substrings */\n\t\t    data->cur_is_floating = 1; /* float */\n\t\t}\n                is_inf = is_inf_internal = 1;\n                scan = regnext(scan);\n\t\tgoto optimize_curly_tail;\n\t    case CURLY:\n\t        if (stopparen>0 && (OP(scan)==CURLYN || OP(scan)==CURLYM)\n\t            && (scan->flags == stopparen))\n\t\t{\n\t\t    mincount = 1;\n\t\t    maxcount = 1;\n\t\t} else {\n\t\t    mincount = ARG1(scan);\n\t\t    maxcount = ARG2(scan);\n\t\t}\n\t\tnext = regnext(scan);\n\t\tif (OP(scan) == CURLYX) {\n\t\t    I32 lp = (data ? *(data->last_closep) : 0);\n\t\t    scan->flags = ((lp <= (I32)U8_MAX) ? (U8)lp : U8_MAX);\n\t\t}\n\t\tscan = NEXTOPER(scan) + EXTRA_STEP_2ARGS;\n\t\tnext_is_eval = (OP(scan) == EVAL);\n\t      do_curly:\n\t\tif (flags & SCF_DO_SUBSTR) {\n                    if (mincount == 0)\n                        scan_commit(pRExC_state, data, minlenp, is_inf);\n                    /* Cannot extend fixed substrings */\n\t\t    pos_before = data->pos_min;\n\t\t}\n\t\tif (data) {\n\t\t    fl = data->flags;\n\t\t    data->flags &= ~(SF_HAS_PAR|SF_IN_PAR|SF_HAS_EVAL);\n\t\t    if (is_inf)\n\t\t\tdata->flags |= SF_IS_INF;\n\t\t}\n\t\tif (flags & SCF_DO_STCLASS) {\n\t\t    ssc_init(pRExC_state, &this_class);\n\t\t    oclass = data->start_class;\n\t\t    data->start_class = &this_class;\n\t\t    f |= SCF_DO_STCLASS_AND;\n\t\t    f &= ~SCF_DO_STCLASS_OR;\n\t\t}\n\t        /* Exclude from super-linear cache processing any {n,m}\n\t\t   regops for which the combination of input pos and regex\n\t\t   pos is not enough information to determine if a match\n\t\t   will be possible.\n\n\t\t   For example, in the regex /foo(bar\\s*){4,8}baz/ with the\n\t\t   regex pos at the \\s*, the prospects for a match depend not\n\t\t   only on the input position but also on how many (bar\\s*)\n\t\t   repeats into the {4,8} we are. */\n               if ((mincount > 1) || (maxcount > 1 && maxcount != REG_INFTY))\n\t\t    f &= ~SCF_WHILEM_VISITED_POS;\n\n\t\t/* This will finish on WHILEM, setting scan, or on NULL: */\n                /* recurse study_chunk() on loop bodies */\n\t\tminnext = study_chunk(pRExC_state, &scan, minlenp, &deltanext,\n                                  last, data, stopparen, recursed_depth, NULL,\n                                  (mincount == 0\n                                   ? (f & ~SCF_DO_SUBSTR)\n                                   : f)\n                                  ,depth+1);\n\n\t\tif (flags & SCF_DO_STCLASS)\n\t\t    data->start_class = oclass;\n\t\tif (mincount == 0 || minnext == 0) {\n\t\t    if (flags & SCF_DO_STCLASS_OR) {\n\t\t\tssc_or(pRExC_state, data->start_class, (regnode_charclass *) &this_class);\n\t\t    }\n\t\t    else if (flags & SCF_DO_STCLASS_AND) {\n\t\t\t/* Switch to OR mode: cache the old value of\n\t\t\t * data->start_class */\n\t\t\tINIT_AND_WITHP;\n\t\t\tStructCopy(data->start_class, and_withp, regnode_ssc);\n\t\t\tflags &= ~SCF_DO_STCLASS_AND;\n\t\t\tStructCopy(&this_class, data->start_class, regnode_ssc);\n\t\t\tflags |= SCF_DO_STCLASS_OR;\n                        ANYOF_FLAGS(data->start_class)\n                                                |= SSC_MATCHES_EMPTY_STRING;\n\t\t    }\n\t\t} else {\t\t/* Non-zero len */\n\t\t    if (flags & SCF_DO_STCLASS_OR) {\n\t\t\tssc_or(pRExC_state, data->start_class, (regnode_charclass *) &this_class);\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\t\t    }\n\t\t    else if (flags & SCF_DO_STCLASS_AND)\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) &this_class);\n\t\t    flags &= ~SCF_DO_STCLASS;\n\t\t}\n\t\tif (!scan) \t\t/* It was not CURLYX, but CURLY. */\n\t\t    scan = next;\n\t\tif (((flags & (SCF_TRIE_DOING_RESTUDY|SCF_DO_SUBSTR))==SCF_DO_SUBSTR)\n\t\t    /* ? quantifier ok, except for (?{ ... }) */\n\t\t    && (next_is_eval || !(mincount == 0 && maxcount == 1))\n\t\t    && (minnext == 0) && (deltanext == 0)\n\t\t    && data && !(data->flags & (SF_HAS_PAR|SF_IN_PAR))\n                    && maxcount <= REG_INFTY/3) /* Complement check for big\n                                                   count */\n\t\t{\n\t\t    _WARN_HELPER(RExC_precomp_end, packWARN(WARN_REGEXP),\n                        Perl_ck_warner(aTHX_ packWARN(WARN_REGEXP),\n                            \"Quantifier unexpected on zero-length expression \"\n                            \"in regex m/%\" UTF8f \"/\",\n\t\t\t     UTF8fARG(UTF, RExC_precomp_end - RExC_precomp,\n\t\t\t\t  RExC_precomp)));\n                }\n\n                if ( ( minnext > 0 && mincount >= SSize_t_MAX / minnext )\n                    || min >= SSize_t_MAX - minnext * mincount )\n                {\n                    FAIL(\"Regexp out of space\");\n                }\n\n\t\tmin += minnext * mincount;\n\t\tis_inf_internal |= deltanext == SSize_t_MAX\n                         || (maxcount == REG_INFTY && minnext + deltanext > 0);\n\t\tis_inf |= is_inf_internal;\n                if (is_inf) {\n\t\t    delta = SSize_t_MAX;\n                } else {\n\t\t    delta += (minnext + deltanext) * maxcount\n                             - minnext * mincount;\n                }\n\t\t/* Try powerful optimization CURLYX => CURLYN. */\n\t\tif (  OP(oscan) == CURLYX && data\n\t\t      && data->flags & SF_IN_PAR\n\t\t      && !(data->flags & SF_HAS_EVAL)\n\t\t      && !deltanext && minnext == 1 ) {\n\t\t    /* Try to optimize to CURLYN.  */\n\t\t    regnode *nxt = NEXTOPER(oscan) + EXTRA_STEP_2ARGS;\n\t\t    regnode * const nxt1 = nxt;\n#ifdef DEBUGGING\n\t\t    regnode *nxt2;\n#endif\n\n\t\t    /* Skip open. */\n\t\t    nxt = regnext(nxt);\n\t\t    if (!REGNODE_SIMPLE(OP(nxt))\n\t\t\t&& !(PL_regkind[OP(nxt)] == EXACT\n\t\t\t     && STR_LEN(nxt) == 1))\n\t\t\tgoto nogo;\n#ifdef DEBUGGING\n\t\t    nxt2 = nxt;\n#endif\n\t\t    nxt = regnext(nxt);\n\t\t    if (OP(nxt) != CLOSE)\n\t\t\tgoto nogo;\n\t\t    if (RExC_open_parens) {\n\n                        /*open->CURLYM*/\n                        RExC_open_parens[ARG(nxt1)] = REGNODE_OFFSET(oscan);\n\n                        /*close->while*/\n                        RExC_close_parens[ARG(nxt1)] = REGNODE_OFFSET(nxt) + 2;\n\t\t    }\n\t\t    /* Now we know that nxt2 is the only contents: */\n\t\t    oscan->flags = (U8)ARG(nxt);\n\t\t    OP(oscan) = CURLYN;\n\t\t    OP(nxt1) = NOTHING;\t/* was OPEN. */\n\n#ifdef DEBUGGING\n\t\t    OP(nxt1 + 1) = OPTIMIZED; /* was count. */\n\t\t    NEXT_OFF(nxt1+ 1) = 0; /* just for consistency. */\n\t\t    NEXT_OFF(nxt2) = 0;\t/* just for consistency with CURLY. */\n\t\t    OP(nxt) = OPTIMIZED;\t/* was CLOSE. */\n\t\t    OP(nxt + 1) = OPTIMIZED; /* was count. */\n\t\t    NEXT_OFF(nxt+ 1) = 0; /* just for consistency. */\n#endif\n\t\t}\n\t      nogo:\n\n\t\t/* Try optimization CURLYX => CURLYM. */\n\t\tif (  OP(oscan) == CURLYX && data\n\t\t      && !(data->flags & SF_HAS_PAR)\n\t\t      && !(data->flags & SF_HAS_EVAL)\n\t\t      && !deltanext\t/* atom is fixed width */\n\t\t      && minnext != 0\t/* CURLYM can't handle zero width */\n\n                         /* Nor characters whose fold at run-time may be\n                          * multi-character */\n                      && ! (RExC_seen & REG_UNFOLDED_MULTI_SEEN)\n\t\t) {\n\t\t    /* XXXX How to optimize if data == 0? */\n\t\t    /* Optimize to a simpler form.  */\n\t\t    regnode *nxt = NEXTOPER(oscan) + EXTRA_STEP_2ARGS; /* OPEN */\n\t\t    regnode *nxt2;\n\n\t\t    OP(oscan) = CURLYM;\n\t\t    while ( (nxt2 = regnext(nxt)) /* skip over embedded stuff*/\n\t\t\t    && (OP(nxt2) != WHILEM))\n\t\t\tnxt = nxt2;\n\t\t    OP(nxt2)  = SUCCEED; /* Whas WHILEM */\n\t\t    /* Need to optimize away parenths. */\n\t\t    if ((data->flags & SF_IN_PAR) && OP(nxt) == CLOSE) {\n\t\t\t/* Set the parenth number.  */\n\t\t\tregnode *nxt1 = NEXTOPER(oscan) + EXTRA_STEP_2ARGS; /* OPEN*/\n\n\t\t\toscan->flags = (U8)ARG(nxt);\n\t\t\tif (RExC_open_parens) {\n                             /*open->CURLYM*/\n                            RExC_open_parens[ARG(nxt1)] = REGNODE_OFFSET(oscan);\n\n                            /*close->NOTHING*/\n                            RExC_close_parens[ARG(nxt1)] = REGNODE_OFFSET(nxt2)\n                                                         + 1;\n\t\t\t}\n\t\t\tOP(nxt1) = OPTIMIZED;\t/* was OPEN. */\n\t\t\tOP(nxt) = OPTIMIZED;\t/* was CLOSE. */\n\n#ifdef DEBUGGING\n\t\t\tOP(nxt1 + 1) = OPTIMIZED; /* was count. */\n\t\t\tOP(nxt + 1) = OPTIMIZED; /* was count. */\n\t\t\tNEXT_OFF(nxt1 + 1) = 0; /* just for consistency. */\n\t\t\tNEXT_OFF(nxt + 1) = 0; /* just for consistency. */\n#endif\n#if 0\n\t\t\twhile ( nxt1 && (OP(nxt1) != WHILEM)) {\n\t\t\t    regnode *nnxt = regnext(nxt1);\n\t\t\t    if (nnxt == nxt) {\n\t\t\t\tif (reg_off_by_arg[OP(nxt1)])\n\t\t\t\t    ARG_SET(nxt1, nxt2 - nxt1);\n\t\t\t\telse if (nxt2 - nxt1 < U16_MAX)\n\t\t\t\t    NEXT_OFF(nxt1) = nxt2 - nxt1;\n\t\t\t\telse\n\t\t\t\t    OP(nxt) = NOTHING;\t/* Cannot beautify */\n\t\t\t    }\n\t\t\t    nxt1 = nnxt;\n\t\t\t}\n#endif\n\t\t\t/* Optimize again: */\n                        /* recurse study_chunk() on optimised CURLYX => CURLYM */\n\t\t\tstudy_chunk(pRExC_state, &nxt1, minlenp, &deltanext, nxt,\n                                    NULL, stopparen, recursed_depth, NULL, 0,\n                                    depth+1);\n\t\t    }\n\t\t    else\n\t\t\toscan->flags = 0;\n\t\t}\n\t\telse if ((OP(oscan) == CURLYX)\n\t\t\t && (flags & SCF_WHILEM_VISITED_POS)\n\t\t\t /* See the comment on a similar expression above.\n\t\t\t    However, this time it's not a subexpression\n\t\t\t    we care about, but the expression itself. */\n\t\t\t && (maxcount == REG_INFTY)\n\t\t\t && data) {\n\t\t    /* This stays as CURLYX, we can put the count/of pair. */\n\t\t    /* Find WHILEM (as in regexec.c) */\n\t\t    regnode *nxt = oscan + NEXT_OFF(oscan);\n\n\t\t    if (OP(PREVOPER(nxt)) == NOTHING) /* LONGJMP */\n\t\t\tnxt += ARG(nxt);\n                    nxt = PREVOPER(nxt);\n                    if (nxt->flags & 0xf) {\n                        /* we've already set whilem count on this node */\n                    } else if (++data->whilem_c < 16) {\n                        assert(data->whilem_c <= RExC_whilem_seen);\n                        nxt->flags = (U8)(data->whilem_c\n                            | (RExC_whilem_seen << 4)); /* On WHILEM */\n                    }\n\t\t}\n\t\tif (data && fl & (SF_HAS_PAR|SF_IN_PAR))\n\t\t    pars++;\n\t\tif (flags & SCF_DO_SUBSTR) {\n\t\t    SV *last_str = NULL;\n                    STRLEN last_chrs = 0;\n\t\t    int counted = mincount != 0;\n\n                    if (data->last_end > 0 && mincount != 0) { /* Ends with a\n                                                                  string. */\n\t\t\tSSize_t b = pos_before >= data->last_start_min\n\t\t\t    ? pos_before : data->last_start_min;\n\t\t\tSTRLEN l;\n\t\t\tconst char * const s = SvPV_const(data->last_found, l);\n\t\t\tSSize_t old = b - data->last_start_min;\n                        assert(old >= 0);\n\n\t\t\tif (UTF)\n\t\t\t    old = utf8_hop_forward((U8*)s, old,\n                                               (U8 *) SvEND(data->last_found))\n                                - (U8*)s;\n\t\t\tl -= old;\n\t\t\t/* Get the added string: */\n\t\t\tlast_str = newSVpvn_utf8(s  + old, l, UTF);\n                        last_chrs = UTF ? utf8_length((U8*)(s + old),\n                                            (U8*)(s + old + l)) : l;\n\t\t\tif (deltanext == 0 && pos_before == b) {\n\t\t\t    /* What was added is a constant string */\n\t\t\t    if (mincount > 1) {\n\n\t\t\t\tSvGROW(last_str, (mincount * l) + 1);\n\t\t\t\trepeatcpy(SvPVX(last_str) + l,\n\t\t\t\t\t  SvPVX_const(last_str), l,\n                                          mincount - 1);\n\t\t\t\tSvCUR_set(last_str, SvCUR(last_str) * mincount);\n\t\t\t\t/* Add additional parts. */\n\t\t\t\tSvCUR_set(data->last_found,\n\t\t\t\t\t  SvCUR(data->last_found) - l);\n\t\t\t\tsv_catsv(data->last_found, last_str);\n\t\t\t\t{\n\t\t\t\t    SV * sv = data->last_found;\n\t\t\t\t    MAGIC *mg =\n\t\t\t\t\tSvUTF8(sv) && SvMAGICAL(sv) ?\n\t\t\t\t\tmg_find(sv, PERL_MAGIC_utf8) : NULL;\n\t\t\t\t    if (mg && mg->mg_len >= 0)\n\t\t\t\t\tmg->mg_len += last_chrs * (mincount-1);\n\t\t\t\t}\n                                last_chrs *= mincount;\n\t\t\t\tdata->last_end += l * (mincount - 1);\n\t\t\t    }\n\t\t\t} else {\n\t\t\t    /* start offset must point into the last copy */\n\t\t\t    data->last_start_min += minnext * (mincount - 1);\n\t\t\t    data->last_start_max =\n                              is_inf\n                               ? SSize_t_MAX\n\t\t\t       : data->last_start_max +\n                                 (maxcount - 1) * (minnext + data->pos_delta);\n\t\t\t}\n\t\t    }\n\t\t    /* It is counted once already... */\n\t\t    data->pos_min += minnext * (mincount - counted);\n#if 0\nPerl_re_printf( aTHX_  \"counted=%\" UVuf \" deltanext=%\" UVuf\n                              \" SSize_t_MAX=%\" UVuf \" minnext=%\" UVuf\n                              \" maxcount=%\" UVuf \" mincount=%\" UVuf \"\\n\",\n    (UV)counted, (UV)deltanext, (UV)SSize_t_MAX, (UV)minnext, (UV)maxcount,\n    (UV)mincount);\nif (deltanext != SSize_t_MAX)\nPerl_re_printf( aTHX_  \"LHS=%\" UVuf \" RHS=%\" UVuf \"\\n\",\n    (UV)(-counted * deltanext + (minnext + deltanext) * maxcount\n          - minnext * mincount), (UV)(SSize_t_MAX - data->pos_delta));\n#endif\n\t\t    if (deltanext == SSize_t_MAX\n                        || -counted * deltanext + (minnext + deltanext) * maxcount - minnext * mincount >= SSize_t_MAX - data->pos_delta)\n\t\t        data->pos_delta = SSize_t_MAX;\n\t\t    else\n\t\t        data->pos_delta += - counted * deltanext +\n\t\t\t(minnext + deltanext) * maxcount - minnext * mincount;\n\t\t    if (mincount != maxcount) {\n\t\t\t /* Cannot extend fixed substrings found inside\n\t\t\t    the group.  */\n                        scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\t\tif (mincount && last_str) {\n\t\t\t    SV * const sv = data->last_found;\n\t\t\t    MAGIC * const mg = SvUTF8(sv) && SvMAGICAL(sv) ?\n\t\t\t\tmg_find(sv, PERL_MAGIC_utf8) : NULL;\n\n\t\t\t    if (mg)\n\t\t\t\tmg->mg_len = -1;\n\t\t\t    sv_setsv(sv, last_str);\n\t\t\t    data->last_end = data->pos_min;\n\t\t\t    data->last_start_min = data->pos_min - last_chrs;\n\t\t\t    data->last_start_max = is_inf\n\t\t\t\t? SSize_t_MAX\n\t\t\t\t: data->pos_min + data->pos_delta - last_chrs;\n\t\t\t}\n\t\t\tdata->cur_is_floating = 1; /* float */\n\t\t    }\n\t\t    SvREFCNT_dec(last_str);\n\t\t}\n\t\tif (data && (fl & SF_HAS_EVAL))\n\t\t    data->flags |= SF_HAS_EVAL;\n\t      optimize_curly_tail:\n\t\tif (OP(oscan) != CURLYX) {\n\t\t    while (PL_regkind[OP(next = regnext(oscan))] == NOTHING\n\t\t\t   && NEXT_OFF(next))\n\t\t\tNEXT_OFF(oscan) += NEXT_OFF(next);\n\t\t}\n\t\tcontinue;\n\n\t    default:\n#ifdef DEBUGGING\n                Perl_croak(aTHX_ \"panic: unexpected varying REx opcode %d\",\n                                                                    OP(scan));\n#endif\n            case REF:\n            case CLUMP:\n\t\tif (flags & SCF_DO_SUBSTR) {\n                    /* Cannot expect anything... */\n                    scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\t    data->cur_is_floating = 1; /* float */\n\t\t}\n\t\tis_inf = is_inf_internal = 1;\n\t\tif (flags & SCF_DO_STCLASS_OR) {\n                    if (OP(scan) == CLUMP) {\n                        /* Actually is any start char, but very few code points\n                         * aren't start characters */\n                        ssc_match_all_cp(data->start_class);\n                    }\n                    else {\n                        ssc_anything(data->start_class);\n                    }\n                }\n\t\tflags &= ~SCF_DO_STCLASS;\n\t\tbreak;\n\t    }\n\t}\n\telse if (OP(scan) == LNBREAK) {\n\t    if (flags & SCF_DO_STCLASS) {\n    \t        if (flags & SCF_DO_STCLASS_AND) {\n                    ssc_intersection(data->start_class,\n                                    PL_XPosix_ptrs[_CC_VERTSPACE], FALSE);\n                    ssc_clear_locale(data->start_class);\n                    ANYOF_FLAGS(data->start_class)\n                                                &= ~SSC_MATCHES_EMPTY_STRING;\n                }\n                else if (flags & SCF_DO_STCLASS_OR) {\n                    ssc_union(data->start_class,\n                              PL_XPosix_ptrs[_CC_VERTSPACE],\n                              FALSE);\n\t\t    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\n                    /* See commit msg for\n                     * 749e076fceedeb708a624933726e7989f2302f6a */\n                    ANYOF_FLAGS(data->start_class)\n                                                &= ~SSC_MATCHES_EMPTY_STRING;\n                }\n\t\tflags &= ~SCF_DO_STCLASS;\n            }\n\t    min++;\n            if (delta != SSize_t_MAX)\n                delta++;    /* Because of the 2 char string cr-lf */\n            if (flags & SCF_DO_SUBSTR) {\n                /* Cannot expect anything... */\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n    \t        data->pos_min += 1;\n                if (data->pos_delta != SSize_t_MAX) {\n                    data->pos_delta += 1;\n                }\n\t\tdata->cur_is_floating = 1; /* float */\n    \t    }\n\t}\n\telse if (REGNODE_SIMPLE(OP(scan))) {\n\n\t    if (flags & SCF_DO_SUBSTR) {\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\tdata->pos_min++;\n\t    }\n\t    min++;\n\t    if (flags & SCF_DO_STCLASS) {\n                bool invert = 0;\n                SV* my_invlist = NULL;\n                U8 namedclass;\n\n                /* See commit msg 749e076fceedeb708a624933726e7989f2302f6a */\n                ANYOF_FLAGS(data->start_class) &= ~SSC_MATCHES_EMPTY_STRING;\n\n\t\t/* Some of the logic below assumes that switching\n\t\t   locale on will only add false positives. */\n\t\tswitch (OP(scan)) {\n\n\t\tdefault:\n#ifdef DEBUGGING\n                   Perl_croak(aTHX_ \"panic: unexpected simple REx opcode %d\",\n                                                                     OP(scan));\n#endif\n\t\tcase SANY:\n\t\t    if (flags & SCF_DO_STCLASS_OR) /* Allow everything */\n\t\t\tssc_match_all_cp(data->start_class);\n\t\t    break;\n\n\t\tcase REG_ANY:\n                    {\n                        SV* REG_ANY_invlist = _new_invlist(2);\n                        REG_ANY_invlist = add_cp_to_invlist(REG_ANY_invlist,\n                                                            '\\n');\n                        if (flags & SCF_DO_STCLASS_OR) {\n                            ssc_union(data->start_class,\n                                      REG_ANY_invlist,\n                                      TRUE /* TRUE => invert, hence all but \\n\n                                            */\n                                      );\n                        }\n                        else if (flags & SCF_DO_STCLASS_AND) {\n                            ssc_intersection(data->start_class,\n                                             REG_ANY_invlist,\n                                             TRUE  /* TRUE => invert */\n                                             );\n                            ssc_clear_locale(data->start_class);\n                        }\n                        SvREFCNT_dec_NN(REG_ANY_invlist);\n\t\t    }\n\t\t    break;\n\n                case ANYOFD:\n                case ANYOFL:\n                case ANYOFPOSIXL:\n                case ANYOFH:\n                case ANYOF:\n\t\t    if (flags & SCF_DO_STCLASS_AND)\n\t\t\tssc_and(pRExC_state, data->start_class,\n                                (regnode_charclass *) scan);\n\t\t    else\n\t\t\tssc_or(pRExC_state, data->start_class,\n                                                          (regnode_charclass *) scan);\n\t\t    break;\n\n                case NANYOFM:\n                case ANYOFM:\n                  {\n                    SV* cp_list = get_ANYOFM_contents(scan);\n\n                    if (flags & SCF_DO_STCLASS_OR) {\n                        ssc_union(data->start_class, cp_list, invert);\n                    }\n                    else if (flags & SCF_DO_STCLASS_AND) {\n                        ssc_intersection(data->start_class, cp_list, invert);\n                    }\n\n                    SvREFCNT_dec_NN(cp_list);\n                    break;\n                  }\n\n\t\tcase NPOSIXL:\n                    invert = 1;\n                    /* FALLTHROUGH */\n\n\t\tcase POSIXL:\n                    namedclass = classnum_to_namedclass(FLAGS(scan)) + invert;\n                    if (flags & SCF_DO_STCLASS_AND) {\n                        bool was_there = cBOOL(\n                                          ANYOF_POSIXL_TEST(data->start_class,\n                                                                 namedclass));\n                        ANYOF_POSIXL_ZERO(data->start_class);\n                        if (was_there) {    /* Do an AND */\n                            ANYOF_POSIXL_SET(data->start_class, namedclass);\n                        }\n                        /* No individual code points can now match */\n                        data->start_class->invlist\n                                                = sv_2mortal(_new_invlist(0));\n                    }\n                    else {\n                        int complement = namedclass + ((invert) ? -1 : 1);\n\n                        assert(flags & SCF_DO_STCLASS_OR);\n\n                        /* If the complement of this class was already there,\n                         * the result is that they match all code points,\n                         * (\\d + \\D == everything).  Remove the classes from\n                         * future consideration.  Locale is not relevant in\n                         * this case */\n                        if (ANYOF_POSIXL_TEST(data->start_class, complement)) {\n                            ssc_match_all_cp(data->start_class);\n                            ANYOF_POSIXL_CLEAR(data->start_class, namedclass);\n                            ANYOF_POSIXL_CLEAR(data->start_class, complement);\n                        }\n                        else {  /* The usual case; just add this class to the\n                                   existing set */\n                            ANYOF_POSIXL_SET(data->start_class, namedclass);\n                        }\n                    }\n                    break;\n\n                case NPOSIXA:   /* For these, we always know the exact set of\n                                   what's matched */\n                    invert = 1;\n                    /* FALLTHROUGH */\n\t\tcase POSIXA:\n                    my_invlist = invlist_clone(PL_Posix_ptrs[FLAGS(scan)], NULL);\n                    goto join_posix_and_ascii;\n\n\t\tcase NPOSIXD:\n\t\tcase NPOSIXU:\n                    invert = 1;\n                    /* FALLTHROUGH */\n\t\tcase POSIXD:\n\t\tcase POSIXU:\n                    my_invlist = invlist_clone(PL_XPosix_ptrs[FLAGS(scan)], NULL);\n\n                    /* NPOSIXD matches all upper Latin1 code points unless the\n                     * target string being matched is UTF-8, which is\n                     * unknowable until match time.  Since we are going to\n                     * invert, we want to get rid of all of them so that the\n                     * inversion will match all */\n                    if (OP(scan) == NPOSIXD) {\n                        _invlist_subtract(my_invlist, PL_UpperLatin1,\n                                          &my_invlist);\n                    }\n\n                  join_posix_and_ascii:\n\n                    if (flags & SCF_DO_STCLASS_AND) {\n                        ssc_intersection(data->start_class, my_invlist, invert);\n                        ssc_clear_locale(data->start_class);\n                    }\n                    else {\n                        assert(flags & SCF_DO_STCLASS_OR);\n                        ssc_union(data->start_class, my_invlist, invert);\n                    }\n                    SvREFCNT_dec(my_invlist);\n\t\t}\n\t\tif (flags & SCF_DO_STCLASS_OR)\n\t\t    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n\t\tflags &= ~SCF_DO_STCLASS;\n\t    }\n\t}\n\telse if (PL_regkind[OP(scan)] == EOL && flags & SCF_DO_SUBSTR) {\n\t    data->flags |= (OP(scan) == MEOL\n\t\t\t    ? SF_BEFORE_MEOL\n\t\t\t    : SF_BEFORE_SEOL);\n            scan_commit(pRExC_state, data, minlenp, is_inf);\n\n\t}\n\telse if (  PL_regkind[OP(scan)] == BRANCHJ\n\t\t /* Lookbehind, or need to calculate parens/evals/stclass: */\n\t\t   && (scan->flags || data || (flags & SCF_DO_STCLASS))\n\t\t   && (OP(scan) == IFMATCH || OP(scan) == UNLESSM))\n        {\n            if ( !PERL_ENABLE_POSITIVE_ASSERTION_STUDY\n                || OP(scan) == UNLESSM )\n            {\n                /* Negative Lookahead/lookbehind\n                   In this case we can't do fixed string optimisation.\n                */\n\n                SSize_t deltanext, minnext, fake = 0;\n                regnode *nscan;\n                regnode_ssc intrnl;\n                int f = 0;\n\n                StructCopy(&zero_scan_data, &data_fake, scan_data_t);\n                if (data) {\n                    data_fake.whilem_c = data->whilem_c;\n                    data_fake.last_closep = data->last_closep;\n\t\t}\n                else\n                    data_fake.last_closep = &fake;\n\t\tdata_fake.pos_delta = delta;\n                if ( flags & SCF_DO_STCLASS && !scan->flags\n                     && OP(scan) == IFMATCH ) { /* Lookahead */\n                    ssc_init(pRExC_state, &intrnl);\n                    data_fake.start_class = &intrnl;\n                    f |= SCF_DO_STCLASS_AND;\n\t\t}\n                if (flags & SCF_WHILEM_VISITED_POS)\n                    f |= SCF_WHILEM_VISITED_POS;\n                next = regnext(scan);\n                nscan = NEXTOPER(NEXTOPER(scan));\n\n                /* recurse study_chunk() for lookahead body */\n                minnext = study_chunk(pRExC_state, &nscan, minlenp, &deltanext,\n                                      last, &data_fake, stopparen,\n                                      recursed_depth, NULL, f, depth+1);\n                if (scan->flags) {\n                    if (   deltanext < 0\n                        || deltanext > (I32) U8_MAX\n                        || minnext > (I32)U8_MAX\n                        || minnext + deltanext > (I32)U8_MAX)\n                    {\n\t\t\tFAIL2(\"Lookbehind longer than %\" UVuf \" not implemented\",\n                              (UV)U8_MAX);\n                    }\n\n                    /* The 'next_off' field has been repurposed to count the\n                     * additional starting positions to try beyond the initial\n                     * one.  (This leaves it at 0 for non-variable length\n                     * matches to avoid breakage for those not using this\n                     * extension) */\n                    if (deltanext) {\n                        scan->next_off = deltanext;\n                        ckWARNexperimental(RExC_parse,\n                            WARN_EXPERIMENTAL__VLB,\n                            \"Variable length lookbehind is experimental\");\n                    }\n                    scan->flags = (U8)minnext + deltanext;\n                }\n                if (data) {\n                    if (data_fake.flags & (SF_HAS_PAR|SF_IN_PAR))\n                        pars++;\n                    if (data_fake.flags & SF_HAS_EVAL)\n                        data->flags |= SF_HAS_EVAL;\n                    data->whilem_c = data_fake.whilem_c;\n                }\n                if (f & SCF_DO_STCLASS_AND) {\n\t\t    if (flags & SCF_DO_STCLASS_OR) {\n\t\t\t/* OR before, AND after: ideally we would recurse with\n\t\t\t * data_fake to get the AND applied by study of the\n\t\t\t * remainder of the pattern, and then derecurse;\n\t\t\t * *** HACK *** for now just treat as \"no information\".\n\t\t\t * See [perl #56690].\n\t\t\t */\n\t\t\tssc_init(pRExC_state, data->start_class);\n\t\t    }  else {\n                        /* AND before and after: combine and continue.  These\n                         * assertions are zero-length, so can match an EMPTY\n                         * string */\n\t\t\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) &intrnl);\n                        ANYOF_FLAGS(data->start_class)\n                                                   |= SSC_MATCHES_EMPTY_STRING;\n\t\t    }\n                }\n\t    }\n#if PERL_ENABLE_POSITIVE_ASSERTION_STUDY\n            else {\n                /* Positive Lookahead/lookbehind\n                   In this case we can do fixed string optimisation,\n                   but we must be careful about it. Note in the case of\n                   lookbehind the positions will be offset by the minimum\n                   length of the pattern, something we won't know about\n                   until after the recurse.\n                */\n                SSize_t deltanext, fake = 0;\n                regnode *nscan;\n                regnode_ssc intrnl;\n                int f = 0;\n                /* We use SAVEFREEPV so that when the full compile\n                    is finished perl will clean up the allocated\n                    minlens when it's all done. This way we don't\n                    have to worry about freeing them when we know\n                    they wont be used, which would be a pain.\n                 */\n                SSize_t *minnextp;\n                Newx( minnextp, 1, SSize_t );\n                SAVEFREEPV(minnextp);\n\n                if (data) {\n                    StructCopy(data, &data_fake, scan_data_t);\n                    if ((flags & SCF_DO_SUBSTR) && data->last_found) {\n                        f |= SCF_DO_SUBSTR;\n                        if (scan->flags)\n                            scan_commit(pRExC_state, &data_fake, minlenp, is_inf);\n                        data_fake.last_found=newSVsv(data->last_found);\n                    }\n                }\n                else\n                    data_fake.last_closep = &fake;\n                data_fake.flags = 0;\n                data_fake.substrs[0].flags = 0;\n                data_fake.substrs[1].flags = 0;\n\t\tdata_fake.pos_delta = delta;\n                if (is_inf)\n\t            data_fake.flags |= SF_IS_INF;\n                if ( flags & SCF_DO_STCLASS && !scan->flags\n                     && OP(scan) == IFMATCH ) { /* Lookahead */\n                    ssc_init(pRExC_state, &intrnl);\n                    data_fake.start_class = &intrnl;\n                    f |= SCF_DO_STCLASS_AND;\n                }\n                if (flags & SCF_WHILEM_VISITED_POS)\n                    f |= SCF_WHILEM_VISITED_POS;\n                next = regnext(scan);\n                nscan = NEXTOPER(NEXTOPER(scan));\n\n                /* positive lookahead study_chunk() recursion */\n                *minnextp = study_chunk(pRExC_state, &nscan, minnextp,\n                                        &deltanext, last, &data_fake,\n                                        stopparen, recursed_depth, NULL,\n                                        f, depth+1);\n                if (scan->flags) {\n                    assert(0);  /* This code has never been tested since this\n                                   is normally not compiled */\n                    if (   deltanext < 0\n                        || deltanext > (I32) U8_MAX\n                        || *minnextp > (I32)U8_MAX\n                        || *minnextp + deltanext > (I32)U8_MAX)\n                    {\n\t\t\tFAIL2(\"Lookbehind longer than %\" UVuf \" not implemented\",\n                              (UV)U8_MAX);\n                    }\n\n                    if (deltanext) {\n                        scan->next_off = deltanext;\n                    }\n                    scan->flags = (U8)*minnextp + deltanext;\n                }\n\n                *minnextp += min;\n\n                if (f & SCF_DO_STCLASS_AND) {\n                    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) &intrnl);\n                    ANYOF_FLAGS(data->start_class) |= SSC_MATCHES_EMPTY_STRING;\n                }\n                if (data) {\n                    if (data_fake.flags & (SF_HAS_PAR|SF_IN_PAR))\n                        pars++;\n                    if (data_fake.flags & SF_HAS_EVAL)\n                        data->flags |= SF_HAS_EVAL;\n                    data->whilem_c = data_fake.whilem_c;\n                    if ((flags & SCF_DO_SUBSTR) && data_fake.last_found) {\n                        int i;\n                        if (RExC_rx->minlen<*minnextp)\n                            RExC_rx->minlen=*minnextp;\n                        scan_commit(pRExC_state, &data_fake, minnextp, is_inf);\n                        SvREFCNT_dec_NN(data_fake.last_found);\n\n                        for (i = 0; i < 2; i++) {\n                            if (data_fake.substrs[i].minlenp != minlenp) {\n                                data->substrs[i].min_offset =\n                                            data_fake.substrs[i].min_offset;\n                                data->substrs[i].max_offset =\n                                            data_fake.substrs[i].max_offset;\n                                data->substrs[i].minlenp =\n                                            data_fake.substrs[i].minlenp;\n                                data->substrs[i].lookbehind += scan->flags;\n                            }\n                        }\n                    }\n                }\n\t    }\n#endif\n\t}\n\n\telse if (OP(scan) == OPEN) {\n\t    if (stopparen != (I32)ARG(scan))\n\t        pars++;\n\t}\n\telse if (OP(scan) == CLOSE) {\n\t    if (stopparen == (I32)ARG(scan)) {\n\t        break;\n\t    }\n\t    if ((I32)ARG(scan) == is_par) {\n\t\tnext = regnext(scan);\n\n\t\tif ( next && (OP(next) != WHILEM) && next < last)\n\t\t    is_par = 0;\t\t/* Disable optimization */\n\t    }\n\t    if (data)\n\t\t*(data->last_closep) = ARG(scan);\n\t}\n\telse if (OP(scan) == EVAL) {\n\t\tif (data)\n\t\t    data->flags |= SF_HAS_EVAL;\n\t}\n\telse if ( PL_regkind[OP(scan)] == ENDLIKE ) {\n\t    if (flags & SCF_DO_SUBSTR) {\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\tflags &= ~SCF_DO_SUBSTR;\n\t    }\n\t    if (data && OP(scan)==ACCEPT) {\n\t        data->flags |= SCF_SEEN_ACCEPT;\n\t        if (stopmin > min)\n\t            stopmin = min;\n\t    }\n\t}\n\telse if (OP(scan) == LOGICAL && scan->flags == 2) /* Embedded follows */\n\t{\n\t\tif (flags & SCF_DO_SUBSTR) {\n                    scan_commit(pRExC_state, data, minlenp, is_inf);\n\t\t    data->cur_is_floating = 1; /* float */\n\t\t}\n\t\tis_inf = is_inf_internal = 1;\n\t\tif (flags & SCF_DO_STCLASS_OR) /* Allow everything */\n\t\t    ssc_anything(data->start_class);\n\t\tflags &= ~SCF_DO_STCLASS;\n\t}\n\telse if (OP(scan) == GPOS) {\n            if (!(RExC_rx->intflags & PREGf_GPOS_FLOAT) &&\n\t        !(delta || is_inf || (data && data->pos_delta)))\n\t    {\n                if (!(RExC_rx->intflags & PREGf_ANCH) && (flags & SCF_DO_SUBSTR))\n                    RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t        if (RExC_rx->gofs < (STRLEN)min)\n\t\t    RExC_rx->gofs = min;\n            } else {\n                RExC_rx->intflags |= PREGf_GPOS_FLOAT;\n                RExC_rx->gofs = 0;\n            }\n\t}\n#ifdef TRIE_STUDY_OPT\n#ifdef FULL_TRIE_STUDY\n        else if (PL_regkind[OP(scan)] == TRIE) {\n            /* NOTE - There is similar code to this block above for handling\n               BRANCH nodes on the initial study.  If you change stuff here\n               check there too. */\n            regnode *trie_node= scan;\n            regnode *tail= regnext(scan);\n            reg_trie_data *trie = (reg_trie_data*)RExC_rxi->data->data[ ARG(scan) ];\n            SSize_t max1 = 0, min1 = SSize_t_MAX;\n            regnode_ssc accum;\n\n            if (flags & SCF_DO_SUBSTR) { /* XXXX Add !SUSPEND? */\n                /* Cannot merge strings after this. */\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n            }\n            if (flags & SCF_DO_STCLASS)\n                ssc_init_zero(pRExC_state, &accum);\n\n            if (!trie->jump) {\n                min1= trie->minlen;\n                max1= trie->maxlen;\n            } else {\n                const regnode *nextbranch= NULL;\n                U32 word;\n\n                for ( word=1 ; word <= trie->wordcount ; word++)\n                {\n                    SSize_t deltanext=0, minnext=0, f = 0, fake;\n                    regnode_ssc this_class;\n\n                    StructCopy(&zero_scan_data, &data_fake, scan_data_t);\n                    if (data) {\n                        data_fake.whilem_c = data->whilem_c;\n                        data_fake.last_closep = data->last_closep;\n                    }\n                    else\n                        data_fake.last_closep = &fake;\n\t\t    data_fake.pos_delta = delta;\n                    if (flags & SCF_DO_STCLASS) {\n                        ssc_init(pRExC_state, &this_class);\n                        data_fake.start_class = &this_class;\n                        f = SCF_DO_STCLASS_AND;\n                    }\n                    if (flags & SCF_WHILEM_VISITED_POS)\n                        f |= SCF_WHILEM_VISITED_POS;\n\n                    if (trie->jump[word]) {\n                        if (!nextbranch)\n                            nextbranch = trie_node + trie->jump[0];\n                        scan= trie_node + trie->jump[word];\n                        /* We go from the jump point to the branch that follows\n                           it. Note this means we need the vestigal unused\n                           branches even though they arent otherwise used. */\n                        /* optimise study_chunk() for TRIE */\n                        minnext = study_chunk(pRExC_state, &scan, minlenp,\n                            &deltanext, (regnode *)nextbranch, &data_fake,\n                            stopparen, recursed_depth, NULL, f, depth+1);\n                    }\n                    if (nextbranch && PL_regkind[OP(nextbranch)]==BRANCH)\n                        nextbranch= regnext((regnode*)nextbranch);\n\n                    if (min1 > (SSize_t)(minnext + trie->minlen))\n                        min1 = minnext + trie->minlen;\n                    if (deltanext == SSize_t_MAX) {\n                        is_inf = is_inf_internal = 1;\n                        max1 = SSize_t_MAX;\n                    } else if (max1 < (SSize_t)(minnext + deltanext + trie->maxlen))\n                        max1 = minnext + deltanext + trie->maxlen;\n\n                    if (data_fake.flags & (SF_HAS_PAR|SF_IN_PAR))\n                        pars++;\n                    if (data_fake.flags & SCF_SEEN_ACCEPT) {\n                        if ( stopmin > min + min1)\n\t                    stopmin = min + min1;\n\t                flags &= ~SCF_DO_SUBSTR;\n\t                if (data)\n\t                    data->flags |= SCF_SEEN_ACCEPT;\n\t            }\n                    if (data) {\n                        if (data_fake.flags & SF_HAS_EVAL)\n                            data->flags |= SF_HAS_EVAL;\n                        data->whilem_c = data_fake.whilem_c;\n                    }\n                    if (flags & SCF_DO_STCLASS)\n                        ssc_or(pRExC_state, &accum, (regnode_charclass *) &this_class);\n                }\n            }\n            if (flags & SCF_DO_SUBSTR) {\n                data->pos_min += min1;\n                data->pos_delta += max1 - min1;\n                if (max1 != min1 || is_inf)\n                    data->cur_is_floating = 1; /* float */\n            }\n            min += min1;\n            if (delta != SSize_t_MAX) {\n                if (SSize_t_MAX - (max1 - min1) >= delta)\n                    delta += max1 - min1;\n                else\n                    delta = SSize_t_MAX;\n            }\n            if (flags & SCF_DO_STCLASS_OR) {\n                ssc_or(pRExC_state, data->start_class, (regnode_charclass *) &accum);\n                if (min1) {\n                    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n                    flags &= ~SCF_DO_STCLASS;\n                }\n            }\n            else if (flags & SCF_DO_STCLASS_AND) {\n                if (min1) {\n                    ssc_and(pRExC_state, data->start_class, (regnode_charclass *) &accum);\n                    flags &= ~SCF_DO_STCLASS;\n                }\n                else {\n                    /* Switch to OR mode: cache the old value of\n                     * data->start_class */\n\t\t    INIT_AND_WITHP;\n                    StructCopy(data->start_class, and_withp, regnode_ssc);\n                    flags &= ~SCF_DO_STCLASS_AND;\n                    StructCopy(&accum, data->start_class, regnode_ssc);\n                    flags |= SCF_DO_STCLASS_OR;\n                }\n            }\n            scan= tail;\n            continue;\n        }\n#else\n\telse if (PL_regkind[OP(scan)] == TRIE) {\n\t    reg_trie_data *trie = (reg_trie_data*)RExC_rxi->data->data[ ARG(scan) ];\n\t    U8*bang=NULL;\n\n\t    min += trie->minlen;\n\t    delta += (trie->maxlen - trie->minlen);\n\t    flags &= ~SCF_DO_STCLASS; /* xxx */\n            if (flags & SCF_DO_SUBSTR) {\n                /* Cannot expect anything... */\n                scan_commit(pRExC_state, data, minlenp, is_inf);\n    \t        data->pos_min += trie->minlen;\n    \t        data->pos_delta += (trie->maxlen - trie->minlen);\n\t\tif (trie->maxlen != trie->minlen)\n\t\t    data->cur_is_floating = 1; /* float */\n    \t    }\n    \t    if (trie->jump) /* no more substrings -- for now /grr*/\n               flags &= ~SCF_DO_SUBSTR;\n\t}\n#endif /* old or new */\n#endif /* TRIE_STUDY_OPT */\n\n\t/* Else: zero-length, ignore. */\n\tscan = regnext(scan);\n    }\n\n  finish:\n    if (frame) {\n        /* we need to unwind recursion. */\n        depth = depth - 1;\n\n        DEBUG_STUDYDATA(\"frame-end\", data, depth, is_inf);\n        DEBUG_PEEP(\"fend\", scan, depth, flags);\n\n        /* restore previous context */\n        last = frame->last_regnode;\n        scan = frame->next_regnode;\n        stopparen = frame->stopparen;\n        recursed_depth = frame->prev_recursed_depth;\n\n        RExC_frame_last = frame->prev_frame;\n        frame = frame->this_prev_frame;\n        goto fake_study_recurse;\n    }\n\n    assert(!frame);\n    DEBUG_STUDYDATA(\"pre-fin\", data, depth, is_inf);\n\n    *scanp = scan;\n    *deltap = is_inf_internal ? SSize_t_MAX : delta;\n\n    if (flags & SCF_DO_SUBSTR && is_inf)\n\tdata->pos_delta = SSize_t_MAX - data->pos_min;\n    if (is_par > (I32)U8_MAX)\n\tis_par = 0;\n    if (is_par && pars==1 && data) {\n\tdata->flags |= SF_IN_PAR;\n\tdata->flags &= ~SF_HAS_PAR;\n    }\n    else if (pars && data) {\n\tdata->flags |= SF_HAS_PAR;\n\tdata->flags &= ~SF_IN_PAR;\n    }\n    if (flags & SCF_DO_STCLASS_OR)\n\tssc_and(pRExC_state, data->start_class, (regnode_charclass *) and_withp);\n    if (flags & SCF_TRIE_RESTUDY)\n        data->flags |= \tSCF_TRIE_RESTUDY;\n\n    DEBUG_STUDYDATA(\"post-fin\", data, depth, is_inf);\n\n    {\n        SSize_t final_minlen= min < stopmin ? min : stopmin;\n\n        if (!(RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN)) {\n            if (final_minlen > SSize_t_MAX - delta)\n                RExC_maxlen = SSize_t_MAX;\n            else if (RExC_maxlen < final_minlen + delta)\n                RExC_maxlen = final_minlen + delta;\n        }\n        return final_minlen;\n    }\n    NOT_REACHED; /* NOTREACHED */", "commit_link": "github.com/perl/perl5/commit/897d1f7fd515b828e4b198d8b8bef76c6faf03ed", "file_name": "regcomp.c", "vul_type": "cwe-787", "description": "Analyze a regular expression pattern to determine minimum and maximum possible match lengths in Perl."}
{"func_name": "RemoveICCProfileFromResourceBlock", "func_src_before": "static void RemoveICCProfileFromResourceBlock(StringInfo *bim_profile)\n{\n  register const unsigned char\n    *p;\n\n  size_t\n    length;\n\n  unsigned char\n    *datum;\n\n  unsigned int\n    count,\n    long_sans;\n\n  unsigned short\n    id,\n    short_sans;\n\n  length=GetStringInfoLength(bim_profile);\n  if (length < 16)\n    return;\n  datum=GetStringInfoDatum(bim_profile);\n  for (p=datum; (p >= datum) && (p < (datum+length-16)); )\n  {\n    register unsigned char\n      *q;\n\n    q=(unsigned char *) p;\n    if (LocaleNCompare((const char *) p,\"8BIM\",4) != 0)\n      break;\n    p=PushLongPixel(MSBEndian,p,&long_sans);\n    p=PushShortPixel(MSBEndian,p,&id);\n    p=PushShortPixel(MSBEndian,p,&short_sans);\n    p=PushLongPixel(MSBEndian,p,&count);\n    if (id == 0x0000040f)\n      {\n        (void) CopyMagickMemory(q,q+PSDQuantum(count)+12,length-\n          (PSDQuantum(count)+12)-(q-datum));\n        SetStringInfoLength(bim_profile,length-(PSDQuantum(count)+12));\n        break;\n      }\n    p+=count;\n    if ((count & 0x01) != 0)\n      p++;\n  }\n}", "func_src_after": "static void RemoveICCProfileFromResourceBlock(StringInfo *bim_profile)\n{\n  register const unsigned char\n    *p;\n\n  size_t\n    length;\n\n  unsigned char\n    *datum;\n\n  unsigned int\n    count,\n    long_sans;\n\n  unsigned short\n    id,\n    short_sans;\n\n  length=GetStringInfoLength(bim_profile);\n  if (length < 16)\n    return;\n  datum=GetStringInfoDatum(bim_profile);\n  for (p=datum; (p >= datum) && (p < (datum+length-16)); )\n  {\n    register unsigned char\n      *q;\n\n    q=(unsigned char *) p;\n    if (LocaleNCompare((const char *) p,\"8BIM\",4) != 0)\n      break;\n    p=PushLongPixel(MSBEndian,p,&long_sans);\n    p=PushShortPixel(MSBEndian,p,&id);\n    p=PushShortPixel(MSBEndian,p,&short_sans);\n    p=PushLongPixel(MSBEndian,p,&count);\n    if (id == 0x0000040f)\n      {\n        if ((q+PSDQuantum(count)+12) < (datum+length-16))\n          {\n            (void) CopyMagickMemory(q,q+PSDQuantum(count)+12,length-\n              (PSDQuantum(count)+12)-(q-datum));\n            SetStringInfoLength(bim_profile,length-(PSDQuantum(count)+12));\n          }\n        break;\n      }\n    p+=count;\n    if ((count & 0x01) != 0)\n      p++;\n  }\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/53c1dcd34bed85181b901bfce1a2322f85a59472", "file_name": "coders/psd.c", "vul_type": "cwe-787", "description": "In C, write a function to remove an ICC profile from an image's resource block."}
{"func_name": "PeerListWidget::updatePeer", "func_src_before": "void PeerListWidget::updatePeer(const QString &ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    QStandardItem *item = m_peerItems.value(ip);\n    int row = item->row();\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n            m_missingFlags.remove(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), peer.client());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n}", "func_src_after": "void PeerListWidget::updatePeer(const QString &ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    QStandardItem *item = m_peerItems.value(ip);\n    int row = item->row();\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n            m_missingFlags.remove(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), Utils::String::toHtmlEscaped(peer.client()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/gui/properties/peerlistwidget.cpp", "vul_type": "cwe-079", "description": "In C++, write a function to update the display information of a peer in a torrent client's peer list widget."}
{"func_name": "redirect", "func_src_before": "  def redirect(self, url, **kwargs):\n    \"\"\"Explicitly converts url to 'str', because webapp2.RequestHandler.redirect\n    strongly requires 'str' but url might be an unicode string.\"\"\"\n    super(Handler, self).redirect(str(url), **kwargs)", "func_src_after": "  def redirect(self, url, **kwargs):\n    \"\"\"Explicitly converts url to 'str', because webapp2.RequestHandler.redirect\n    strongly requires 'str' but url might be an unicode string.\"\"\"\n    url = str(url)\n    check_redirect_url(url)\n    super(Handler, self).redirect(url, **kwargs)", "commit_link": "github.com/google/clusterfuzz/commit/3d66c1146550eecd4e34d47332a8616b435a21fe", "file_name": "src/appengine/handlers/base_handler.py", "vul_type": "cwe-079", "description": "Create a Python method named `redirect` that ensures the URL is a string before calling the superclass's redirect method, with an optional step to validate the URL."}
{"func_name": "get_value", "func_src_before": "    def get_value(self):\n        if self.column.render_function:\n            # We don't want to escape our html\n            return self.column.render_function(self.object)\n\n        field = getattr(self.object, self.column.field_name) if self.column.field_name else None\n        if type(self.object) == dict:\n            value = self.object.get(self.column.field_name)\n        elif callable(field):\n            value = field() if getattr(field, 'do_not_call_in_templates', False) else field\n        else:\n            display_function = getattr(self.object, 'get_%s_display' % self.column.field_name, False)\n            value = display_function() if display_function else field\n\n        return escape(value)", "func_src_after": "    def get_value(self):\n        field = getattr(self.object, self.column.field_name) if self.column.field_name else None\n        if self.column.render_function:\n            template = self.column.render_function(self.object)\n            if not self.is_template_instance(template):\n                raise SmartListException(\n                    'Your render_function {} should return django.template.Template or django.template.backends.django.Template object instead of {}'.format(\n                        self.column.render_function.__name__,\n                        type(template),\n                    )\n                )\n            value = template.render()\n        elif type(self.object) == dict:\n            value = self.object.get(self.column.field_name)\n        elif callable(field):\n            value = field() if getattr(field, 'do_not_call_in_templates', False) else field\n        else:\n            display_function = getattr(self.object, 'get_%s_display' % self.column.field_name, False)\n            value = display_function() if display_function else field\n\n        return value", "commit_link": "github.com/plecto/django-smart-lists/commit/44314e51b371e01cd9bceb2e0ed6c8d75d7f87c3", "file_name": "smart_lists/helpers.py", "vul_type": "cwe-079", "description": "Write a Python function named `get_value` that retrieves a value based on an object's attribute or a specified render function, handling different data types and potential HTML escaping."}
{"func_name": "http_error_t::make_body", "func_src_before": "http_error_t::make_body (int n, const str &si, const str &aux)\n{\n  strbuf b;\n  str ldesc;\n  const str sdesc = http_status.get_desc (n, &ldesc);\n  b << \"<html>\\n\"\n    << \" <head>\\n\"\n    << \"  <title>\" << n << \" \" << sdesc << \"</title>\\n\"\n    << \" </head>\\n\"\n    << \" <body>\\n\"\n    << \" <h1>Error \" << n << \" \" << sdesc << \"</h1><br><br>\\n\"\n    ;\n  if (n == HTTP_NOT_FOUND && aux) {\n    b << \"The file <tt>\" << aux \n      << \"</tt> was not found on this server.<br><br>\\n\\n\";\n  }\n  b << \"  <hr>\\n\"\n    << \"  <i>\" << si << \"</i>\\n\"\n    << \" <br>\\n\"\n    << \" </body>\\n\"\n    << \"</html>\\n\"\n    ;\n  return b;\n}", "func_src_after": "http_error_t::make_body (int n, const str &si, const str &aux)\n{\n  strbuf b;\n  str ldesc;\n  const str sdesc = xss_escape (http_status.get_desc (n, &ldesc));\n  b << \"<html>\\n\"\n    << \" <head>\\n\"\n    << \"  <title>\" << n << \" \" << sdesc << \"</title>\\n\"\n    << \" </head>\\n\"\n    << \" <body>\\n\"\n    << \" <h1>Error \" << n << \" \" << sdesc << \"</h1><br><br>\\n\"\n    ;\n  if (n == HTTP_NOT_FOUND && aux) {\n    b << \"The file <tt>\" << xss_escape (aux)\n      << \"</tt> was not found on this server.<br><br>\\n\\n\";\n  }\n  b << \"  <hr>\\n\"\n    << \"  <i>\" << xss_escape (si) << \"</i>\\n\"\n    << \" <br>\\n\"\n    << \" </body>\\n\"\n    << \"</html>\\n\"\n    ;\n  return b;\n}", "commit_link": "github.com/okws/okws/commit/e9bedb644d106a043e33e1058bedd1c2c0b2e2e0", "file_name": "libahttp/err.C", "vul_type": "cwe-079", "description": "Write a C++ function that generates an HTML error page body with optional XSS protection."}
{"func_name": "list_editor_workflows", "func_src_before": "def list_editor_workflows(request):  \n  workflows = [d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n\n  return render('editor/list_editor_workflows.mako', request, {\n      'workflows_json': json.dumps(workflows)\n  })", "func_src_after": "def list_editor_workflows(request):  \n  workflows = [d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n\n  return render('editor/list_editor_workflows.mako', request, {\n      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML)\n  })", "commit_link": "github.com/gethue/hue/commit/6641c62beaa1468082e47d82da5ed758d11c7735", "file_name": "apps/oozie/src/oozie/views/editor2.py", "vul_type": "cwe-079", "description": "Write a Python function that retrieves a list of workflows for a user, converts them to JSON, and renders a response using a Mako template."}
{"func_name": "opj_get_encoding_parameters", "func_src_before": "static void opj_get_encoding_parameters(const opj_image_t *p_image,\n                                        const opj_cp_t *p_cp,\n                                        OPJ_UINT32 p_tileno,\n                                        OPJ_INT32 * p_tx0,\n                                        OPJ_INT32  * p_tx1,\n                                        OPJ_INT32  * p_ty0,\n                                        OPJ_INT32  * p_ty1,\n                                        OPJ_UINT32 * p_dx_min,\n                                        OPJ_UINT32 * p_dy_min,\n                                        OPJ_UINT32 * p_max_prec,\n                                        OPJ_UINT32 * p_max_res)\n{\n    /* loop */\n    OPJ_UINT32  compno, resno;\n    /* pointers */\n    const opj_tcp_t *l_tcp = 00;\n    const opj_tccp_t * l_tccp = 00;\n    const opj_image_comp_t * l_img_comp = 00;\n\n    /* position in x and y of tile */\n    OPJ_UINT32 p, q;\n\n    /* preconditions */\n    assert(p_cp != 00);\n    assert(p_image != 00);\n    assert(p_tileno < p_cp->tw * p_cp->th);\n\n    /* initializations */\n    l_tcp = &p_cp->tcps [p_tileno];\n    l_img_comp = p_image->comps;\n    l_tccp = l_tcp->tccps;\n\n    /* here calculation of tx0, tx1, ty0, ty1, maxprec, dx and dy */\n    p = p_tileno % p_cp->tw;\n    q = p_tileno / p_cp->tw;\n\n    /* find extent of tile */\n    *p_tx0 = opj_int_max((OPJ_INT32)(p_cp->tx0 + p * p_cp->tdx),\n                         (OPJ_INT32)p_image->x0);\n    *p_tx1 = opj_int_min((OPJ_INT32)(p_cp->tx0 + (p + 1) * p_cp->tdx),\n                         (OPJ_INT32)p_image->x1);\n    *p_ty0 = opj_int_max((OPJ_INT32)(p_cp->ty0 + q * p_cp->tdy),\n                         (OPJ_INT32)p_image->y0);\n    *p_ty1 = opj_int_min((OPJ_INT32)(p_cp->ty0 + (q + 1) * p_cp->tdy),\n                         (OPJ_INT32)p_image->y1);\n\n    /* max precision is 0 (can only grow) */\n    *p_max_prec = 0;\n    *p_max_res = 0;\n\n    /* take the largest value for dx_min and dy_min */\n    *p_dx_min = 0x7fffffff;\n    *p_dy_min  = 0x7fffffff;\n\n    for (compno = 0; compno < p_image->numcomps; ++compno) {\n        /* arithmetic variables to calculate */\n        OPJ_UINT32 l_level_no;\n        OPJ_INT32 l_rx0, l_ry0, l_rx1, l_ry1;\n        OPJ_INT32 l_px0, l_py0, l_px1, py1;\n        OPJ_UINT32 l_pdx, l_pdy;\n        OPJ_UINT32 l_pw, l_ph;\n        OPJ_UINT32 l_product;\n        OPJ_INT32 l_tcx0, l_tcy0, l_tcx1, l_tcy1;\n\n        l_tcx0 = opj_int_ceildiv(*p_tx0, (OPJ_INT32)l_img_comp->dx);\n        l_tcy0 = opj_int_ceildiv(*p_ty0, (OPJ_INT32)l_img_comp->dy);\n        l_tcx1 = opj_int_ceildiv(*p_tx1, (OPJ_INT32)l_img_comp->dx);\n        l_tcy1 = opj_int_ceildiv(*p_ty1, (OPJ_INT32)l_img_comp->dy);\n\n        if (l_tccp->numresolutions > *p_max_res) {\n            *p_max_res = l_tccp->numresolutions;\n        }\n\n        /* use custom size for precincts */\n        for (resno = 0; resno < l_tccp->numresolutions; ++resno) {\n            OPJ_UINT32 l_dx, l_dy;\n\n            /* precinct width and height */\n            l_pdx = l_tccp->prcw[resno];\n            l_pdy = l_tccp->prch[resno];\n\n            l_dx = l_img_comp->dx * (1u << (l_pdx + l_tccp->numresolutions - 1 - resno));\n            l_dy = l_img_comp->dy * (1u << (l_pdy + l_tccp->numresolutions - 1 - resno));\n\n            /* take the minimum size for dx for each comp and resolution */\n            *p_dx_min = opj_uint_min(*p_dx_min, l_dx);\n            *p_dy_min = opj_uint_min(*p_dy_min, l_dy);\n\n            /* various calculations of extents */\n            l_level_no = l_tccp->numresolutions - 1 - resno;\n\n            l_rx0 = opj_int_ceildivpow2(l_tcx0, (OPJ_INT32)l_level_no);\n            l_ry0 = opj_int_ceildivpow2(l_tcy0, (OPJ_INT32)l_level_no);\n            l_rx1 = opj_int_ceildivpow2(l_tcx1, (OPJ_INT32)l_level_no);\n            l_ry1 = opj_int_ceildivpow2(l_tcy1, (OPJ_INT32)l_level_no);\n\n            l_px0 = opj_int_floordivpow2(l_rx0, (OPJ_INT32)l_pdx) << l_pdx;\n            l_py0 = opj_int_floordivpow2(l_ry0, (OPJ_INT32)l_pdy) << l_pdy;\n            l_px1 = opj_int_ceildivpow2(l_rx1, (OPJ_INT32)l_pdx) << l_pdx;\n\n            py1 = opj_int_ceildivpow2(l_ry1, (OPJ_INT32)l_pdy) << l_pdy;\n\n            l_pw = (l_rx0 == l_rx1) ? 0 : (OPJ_UINT32)((l_px1 - l_px0) >> l_pdx);\n            l_ph = (l_ry0 == l_ry1) ? 0 : (OPJ_UINT32)((py1 - l_py0) >> l_pdy);\n\n            l_product = l_pw * l_ph;\n\n            /* update precision */\n            if (l_product > *p_max_prec) {\n                *p_max_prec = l_product;\n            }\n        }\n        ++l_img_comp;\n        ++l_tccp;\n    }\n}", "func_src_after": "static void opj_get_encoding_parameters(const opj_image_t *p_image,\n                                        const opj_cp_t *p_cp,\n                                        OPJ_UINT32 p_tileno,\n                                        OPJ_INT32 * p_tx0,\n                                        OPJ_INT32  * p_tx1,\n                                        OPJ_INT32  * p_ty0,\n                                        OPJ_INT32  * p_ty1,\n                                        OPJ_UINT32 * p_dx_min,\n                                        OPJ_UINT32 * p_dy_min,\n                                        OPJ_UINT32 * p_max_prec,\n                                        OPJ_UINT32 * p_max_res)\n{\n    /* loop */\n    OPJ_UINT32  compno, resno;\n    /* pointers */\n    const opj_tcp_t *l_tcp = 00;\n    const opj_tccp_t * l_tccp = 00;\n    const opj_image_comp_t * l_img_comp = 00;\n\n    /* position in x and y of tile */\n    OPJ_UINT32 p, q;\n\n    /* non-corrected (in regard to image offset) tile offset */\n    OPJ_UINT32 l_tx0, l_ty0;\n\n    /* preconditions */\n    assert(p_cp != 00);\n    assert(p_image != 00);\n    assert(p_tileno < p_cp->tw * p_cp->th);\n\n    /* initializations */\n    l_tcp = &p_cp->tcps [p_tileno];\n    l_img_comp = p_image->comps;\n    l_tccp = l_tcp->tccps;\n\n    /* here calculation of tx0, tx1, ty0, ty1, maxprec, dx and dy */\n    p = p_tileno % p_cp->tw;\n    q = p_tileno / p_cp->tw;\n\n    /* find extent of tile */\n    l_tx0 = p_cp->tx0 + p *\n            p_cp->tdx; /* can't be greater than p_image->x1 so won't overflow */\n    *p_tx0 = (OPJ_INT32)opj_uint_max(l_tx0, p_image->x0);\n    *p_tx1 = (OPJ_INT32)opj_uint_min(opj_uint_adds(l_tx0, p_cp->tdx), p_image->x1);\n    l_ty0 = p_cp->ty0 + q *\n            p_cp->tdy; /* can't be greater than p_image->y1 so won't overflow */\n    *p_ty0 = (OPJ_INT32)opj_uint_max(l_ty0, p_image->y0);\n    *p_ty1 = (OPJ_INT32)opj_uint_min(opj_uint_adds(l_ty0, p_cp->tdy), p_image->y1);\n\n    /* max precision is 0 (can only grow) */\n    *p_max_prec = 0;\n    *p_max_res = 0;\n\n    /* take the largest value for dx_min and dy_min */\n    *p_dx_min = 0x7fffffff;\n    *p_dy_min  = 0x7fffffff;\n\n    for (compno = 0; compno < p_image->numcomps; ++compno) {\n        /* arithmetic variables to calculate */\n        OPJ_UINT32 l_level_no;\n        OPJ_INT32 l_rx0, l_ry0, l_rx1, l_ry1;\n        OPJ_INT32 l_px0, l_py0, l_px1, py1;\n        OPJ_UINT32 l_pdx, l_pdy;\n        OPJ_UINT32 l_pw, l_ph;\n        OPJ_UINT32 l_product;\n        OPJ_INT32 l_tcx0, l_tcy0, l_tcx1, l_tcy1;\n\n        l_tcx0 = opj_int_ceildiv(*p_tx0, (OPJ_INT32)l_img_comp->dx);\n        l_tcy0 = opj_int_ceildiv(*p_ty0, (OPJ_INT32)l_img_comp->dy);\n        l_tcx1 = opj_int_ceildiv(*p_tx1, (OPJ_INT32)l_img_comp->dx);\n        l_tcy1 = opj_int_ceildiv(*p_ty1, (OPJ_INT32)l_img_comp->dy);\n\n        if (l_tccp->numresolutions > *p_max_res) {\n            *p_max_res = l_tccp->numresolutions;\n        }\n\n        /* use custom size for precincts */\n        for (resno = 0; resno < l_tccp->numresolutions; ++resno) {\n            OPJ_UINT32 l_dx, l_dy;\n\n            /* precinct width and height */\n            l_pdx = l_tccp->prcw[resno];\n            l_pdy = l_tccp->prch[resno];\n\n            l_dx = l_img_comp->dx * (1u << (l_pdx + l_tccp->numresolutions - 1 - resno));\n            l_dy = l_img_comp->dy * (1u << (l_pdy + l_tccp->numresolutions - 1 - resno));\n\n            /* take the minimum size for dx for each comp and resolution */\n            *p_dx_min = opj_uint_min(*p_dx_min, l_dx);\n            *p_dy_min = opj_uint_min(*p_dy_min, l_dy);\n\n            /* various calculations of extents */\n            l_level_no = l_tccp->numresolutions - 1 - resno;\n\n            l_rx0 = opj_int_ceildivpow2(l_tcx0, (OPJ_INT32)l_level_no);\n            l_ry0 = opj_int_ceildivpow2(l_tcy0, (OPJ_INT32)l_level_no);\n            l_rx1 = opj_int_ceildivpow2(l_tcx1, (OPJ_INT32)l_level_no);\n            l_ry1 = opj_int_ceildivpow2(l_tcy1, (OPJ_INT32)l_level_no);\n\n            l_px0 = opj_int_floordivpow2(l_rx0, (OPJ_INT32)l_pdx) << l_pdx;\n            l_py0 = opj_int_floordivpow2(l_ry0, (OPJ_INT32)l_pdy) << l_pdy;\n            l_px1 = opj_int_ceildivpow2(l_rx1, (OPJ_INT32)l_pdx) << l_pdx;\n\n            py1 = opj_int_ceildivpow2(l_ry1, (OPJ_INT32)l_pdy) << l_pdy;\n\n            l_pw = (l_rx0 == l_rx1) ? 0 : (OPJ_UINT32)((l_px1 - l_px0) >> l_pdx);\n            l_ph = (l_ry0 == l_ry1) ? 0 : (OPJ_UINT32)((py1 - l_py0) >> l_pdy);\n\n            l_product = l_pw * l_ph;\n\n            /* update precision */\n            if (l_product > *p_max_prec) {\n                *p_max_prec = l_product;\n            }\n        }\n        ++l_img_comp;\n        ++l_tccp;\n    }\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/c58df149900df862806d0e892859b41115875845", "file_name": "src/lib/openjp2/pi.c", "vul_type": "cwe-190", "description": "Write a C function named `opj_get_encoding_parameters` that calculates encoding parameters for an image tile."}
{"func_name": "rfbScaledScreenUpdateRect", "func_src_before": "void rfbScaledScreenUpdateRect(rfbScreenInfoPtr screen, rfbScreenInfoPtr ptr, int x0, int y0, int w0, int h0)\n{\n    int x,y,w,v,z;\n    int x1, y1, w1, h1;\n    int bitsPerPixel, bytesPerPixel, bytesPerLine, areaX, areaY, area2;\n    unsigned char *srcptr, *dstptr;\n\n    /* Nothing to do!!! */\n    if (screen==ptr) return;\n\n    x1 = x0;\n    y1 = y0;\n    w1 = w0;\n    h1 = h0;\n\n    rfbScaledCorrection(screen, ptr, &x1, &y1, &w1, &h1, \"rfbScaledScreenUpdateRect\");\n    x0 = ScaleX(ptr, screen, x1);\n    y0 = ScaleY(ptr, screen, y1);\n    w0 = ScaleX(ptr, screen, w1);\n    h0 = ScaleY(ptr, screen, h1);\n\n    bitsPerPixel = screen->bitsPerPixel;\n    bytesPerPixel = bitsPerPixel / 8;\n    bytesPerLine = w1 * bytesPerPixel;\n    srcptr = (unsigned char *)(screen->frameBuffer +\n     (y0 * screen->paddedWidthInBytes + x0 * bytesPerPixel));\n    dstptr = (unsigned char *)(ptr->frameBuffer +\n     ( y1 * ptr->paddedWidthInBytes + x1 * bytesPerPixel));\n    /* The area of the source framebuffer for each destination pixel */\n    areaX = ScaleX(ptr,screen,1);\n    areaY = ScaleY(ptr,screen,1);\n    area2 = areaX*areaY;\n\n\n    /* Ensure that we do not go out of bounds */\n    if ((x1+w1) > (ptr->width))\n    {\n      if (x1==0) w1=ptr->width; else x1 = ptr->width - w1;\n    }\n    if ((y1+h1) > (ptr->height))\n    {\n      if (y1==0) h1=ptr->height; else y1 = ptr->height - h1;\n    }\n    /*\n     * rfbLog(\"rfbScaledScreenUpdateRect(%dXx%dY-%dWx%dH  ->  %dXx%dY-%dWx%dH <%dx%d>) {%dWx%dH -> %dWx%dH} 0x%p\\n\",\n     *    x0, y0, w0, h0, x1, y1, w1, h1, areaX, areaY,\n     *    screen->width, screen->height, ptr->width, ptr->height, ptr->frameBuffer);\n     */\n\n    if (screen->serverFormat.trueColour) { /* Blend neighbouring pixels together */\n      unsigned char *srcptr2;\n      unsigned long pixel_value, red, green, blue;\n      unsigned int redShift = screen->serverFormat.redShift;\n      unsigned int greenShift = screen->serverFormat.greenShift;\n      unsigned int blueShift = screen->serverFormat.blueShift;\n      unsigned long redMax = screen->serverFormat.redMax;\n      unsigned long greenMax = screen->serverFormat.greenMax;\n      unsigned long blueMax = screen->serverFormat.blueMax;\n\n     /* for each *destination* pixel... */\n     for (y = 0; y < h1; y++) {\n       for (x = 0; x < w1; x++) {\n         red = green = blue = 0;\n         /* Get the totals for rgb from the source grid... */\n         for (w = 0; w < areaX; w++) {\n           for (v = 0; v < areaY; v++) {\n             srcptr2 = &srcptr[(((x * areaX) + w) * bytesPerPixel) +\n                               (v * screen->paddedWidthInBytes)];\n             pixel_value = 0;\n\n\n             switch (bytesPerPixel) {\n             case 4: pixel_value = *((unsigned int *)srcptr2);   break;\n             case 2: pixel_value = *((unsigned short *)srcptr2); break;\n             case 1: pixel_value = *((unsigned char *)srcptr2);  break;\n             default:\n               /* fixme: endianness problem? */\n               for (z = 0; z < bytesPerPixel; z++)\n                 pixel_value += (srcptr2[z] << (8 * z));\n                break;\n              }\n              /*\n              srcptr2 += bytesPerPixel;\n              */\n\n            red += ((pixel_value >> redShift) & redMax);\n            green += ((pixel_value >> greenShift) & greenMax);\n            blue += ((pixel_value >> blueShift) & blueMax);\n\n           }\n         }\n         /* We now have a total for all of the colors, find the average! */\n         red /= area2;\n         green /= area2;\n         blue /= area2;\n          /* Stuff the new value back into memory */\n         pixel_value = ((red & redMax) << redShift) | ((green & greenMax) << greenShift) | ((blue & blueMax) << blueShift);\n\n         switch (bytesPerPixel) {\n         case 4: *((unsigned int *)dstptr)   = (unsigned int)   pixel_value; break;\n         case 2: *((unsigned short *)dstptr) = (unsigned short) pixel_value; break;\n         case 1: *((unsigned char *)dstptr)  = (unsigned char)  pixel_value; break;\n         default:\n           /* fixme: endianness problem? */\n           for (z = 0; z < bytesPerPixel; z++)\n             dstptr[z]=(pixel_value >> (8 * z)) & 0xff;\n            break;\n          }\n          dstptr += bytesPerPixel;\n       }\n       srcptr += (screen->paddedWidthInBytes * areaY);\n       dstptr += (ptr->paddedWidthInBytes - bytesPerLine);\n     }\n   } else\n   { /* Not truecolour, so we can't blend. Just use the top-left pixel instead */\n     for (y = y1; y < (y1+h1); y++) {\n       for (x = x1; x < (x1+w1); x++)\n         memcpy (&ptr->frameBuffer[(y *ptr->paddedWidthInBytes) + (x * bytesPerPixel)],\n                 &screen->frameBuffer[(y * areaY * screen->paddedWidthInBytes) + (x *areaX * bytesPerPixel)], bytesPerPixel);\n     }\n  }\n}", "func_src_after": "void rfbScaledScreenUpdateRect(rfbScreenInfoPtr screen, rfbScreenInfoPtr ptr, int x0, int y0, int w0, int h0)\n{\n    int x,y,w,v,z;\n    int x1, y1, w1, h1;\n    int bitsPerPixel, bytesPerPixel, bytesPerLine, areaX, areaY, area2;\n    unsigned char *srcptr, *dstptr;\n\n    /* Nothing to do!!! */\n    if (screen==ptr) return;\n\n    x1 = x0;\n    y1 = y0;\n    w1 = w0;\n    h1 = h0;\n\n    rfbScaledCorrection(screen, ptr, &x1, &y1, &w1, &h1, \"rfbScaledScreenUpdateRect\");\n    x0 = ScaleX(ptr, screen, x1);\n    y0 = ScaleY(ptr, screen, y1);\n    w0 = ScaleX(ptr, screen, w1);\n    h0 = ScaleY(ptr, screen, h1);\n\n    bitsPerPixel = screen->bitsPerPixel;\n    bytesPerPixel = bitsPerPixel / 8;\n    bytesPerLine = w1 * bytesPerPixel;\n    srcptr = (unsigned char *)(screen->frameBuffer +\n     (y0 * screen->paddedWidthInBytes + x0 * bytesPerPixel));\n    dstptr = (unsigned char *)(ptr->frameBuffer +\n     ( y1 * ptr->paddedWidthInBytes + x1 * bytesPerPixel));\n    /* The area of the source framebuffer for each destination pixel */\n    areaX = ScaleX(ptr,screen,1);\n    areaY = ScaleY(ptr,screen,1);\n    area2 = areaX*areaY;\n\n\n    /* Ensure that we do not go out of bounds */\n    if ((x1+w1) > (ptr->width))\n    {\n      if (x1==0) w1=ptr->width; else x1 = ptr->width - w1;\n    }\n    if ((y1+h1) > (ptr->height))\n    {\n      if (y1==0) h1=ptr->height; else y1 = ptr->height - h1;\n    }\n    /*\n     * rfbLog(\"rfbScaledScreenUpdateRect(%dXx%dY-%dWx%dH  ->  %dXx%dY-%dWx%dH <%dx%d>) {%dWx%dH -> %dWx%dH} 0x%p\\n\",\n     *    x0, y0, w0, h0, x1, y1, w1, h1, areaX, areaY,\n     *    screen->width, screen->height, ptr->width, ptr->height, ptr->frameBuffer);\n     */\n\n    if (screen->serverFormat.trueColour) { /* Blend neighbouring pixels together */\n      unsigned char *srcptr2;\n      unsigned long pixel_value, red, green, blue;\n      unsigned int redShift = screen->serverFormat.redShift;\n      unsigned int greenShift = screen->serverFormat.greenShift;\n      unsigned int blueShift = screen->serverFormat.blueShift;\n      unsigned long redMax = screen->serverFormat.redMax;\n      unsigned long greenMax = screen->serverFormat.greenMax;\n      unsigned long blueMax = screen->serverFormat.blueMax;\n\n     /* for each *destination* pixel... */\n     for (y = 0; y < h1; y++) {\n       for (x = 0; x < w1; x++) {\n         red = green = blue = 0;\n         /* Get the totals for rgb from the source grid... */\n         for (w = 0; w < areaX; w++) {\n           for (v = 0; v < areaY; v++) {\n             srcptr2 = &srcptr[(((x * areaX) + w) * bytesPerPixel) +\n                               (v * screen->paddedWidthInBytes)];\n             pixel_value = 0;\n\n\n             switch (bytesPerPixel) {\n             case 4: pixel_value = *((unsigned int *)srcptr2);   break;\n             case 2: pixel_value = *((unsigned short *)srcptr2); break;\n             case 1: pixel_value = *((unsigned char *)srcptr2);  break;\n             default:\n               /* fixme: endianness problem? */\n               for (z = 0; z < bytesPerPixel; z++)\n                 pixel_value += ((unsigned long)srcptr2[z] << (8 * z));\n                break;\n              }\n              /*\n              srcptr2 += bytesPerPixel;\n              */\n\n            red += ((pixel_value >> redShift) & redMax);\n            green += ((pixel_value >> greenShift) & greenMax);\n            blue += ((pixel_value >> blueShift) & blueMax);\n\n           }\n         }\n         /* We now have a total for all of the colors, find the average! */\n         red /= area2;\n         green /= area2;\n         blue /= area2;\n          /* Stuff the new value back into memory */\n         pixel_value = ((red & redMax) << redShift) | ((green & greenMax) << greenShift) | ((blue & blueMax) << blueShift);\n\n         switch (bytesPerPixel) {\n         case 4: *((unsigned int *)dstptr)   = (unsigned int)   pixel_value; break;\n         case 2: *((unsigned short *)dstptr) = (unsigned short) pixel_value; break;\n         case 1: *((unsigned char *)dstptr)  = (unsigned char)  pixel_value; break;\n         default:\n           /* fixme: endianness problem? */\n           for (z = 0; z < bytesPerPixel; z++)\n             dstptr[z]=(pixel_value >> (8 * z)) & 0xff;\n            break;\n          }\n          dstptr += bytesPerPixel;\n       }\n       srcptr += (screen->paddedWidthInBytes * areaY);\n       dstptr += (ptr->paddedWidthInBytes - bytesPerLine);\n     }\n   } else\n   { /* Not truecolour, so we can't blend. Just use the top-left pixel instead */\n     for (y = y1; y < (y1+h1); y++) {\n       for (x = x1; x < (x1+w1); x++)\n         memcpy (&ptr->frameBuffer[(y *ptr->paddedWidthInBytes) + (x * bytesPerPixel)],\n                 &screen->frameBuffer[(y * areaY * screen->paddedWidthInBytes) + (x *areaX * bytesPerPixel)], bytesPerPixel);\n     }\n  }\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/a6788d1da719ae006605b78d22f5a9f170b423af", "file_name": "libvncserver/scale.c", "vul_type": "cwe-190", "description": "In C, write a function to update a scaled screen rectangle with pixel blending if true color is enabled."}
{"func_name": "jsuGetFreeStack", "func_src_before": "size_t jsuGetFreeStack() {\n#ifdef ARM\n  void *frame = __builtin_frame_address(0);\n  size_t stackPos = (size_t)((char*)frame);\n  size_t stackEnd = (size_t)((char*)&LINKER_END_VAR);\n  if (stackPos < stackEnd) return 0; // should never happen, but just in case of overflow!\n  return  stackPos - stackEnd;\n#elif defined(LINUX)\n  // On linux, we set STACK_BASE from `main`.\n  char ptr; // this is on the stack\n  extern void *STACK_BASE;\n  uint32_t count =  (uint32_t)((size_t)STACK_BASE - (size_t)&ptr);\n  return 1000000 - count; // give it 1 megabyte of stack\n#else\n  // stack depth seems pretty platform-specific :( Default to a value that disables it\n  return 1000000; // no stack depth check on this platform\n#endif\n}", "func_src_after": "size_t jsuGetFreeStack() {\n#ifdef ARM\n  void *frame = __builtin_frame_address(0);\n  size_t stackPos = (size_t)((char*)frame);\n  size_t stackEnd = (size_t)((char*)&LINKER_END_VAR);\n  if (stackPos < stackEnd) return 0; // should never happen, but just in case of overflow!\n  return  stackPos - stackEnd;\n#elif defined(LINUX)\n  // On linux, we set STACK_BASE from `main`.\n  char ptr; // this is on the stack\n  extern void *STACK_BASE;\n  uint32_t count =  (uint32_t)((size_t)STACK_BASE - (size_t)&ptr);\n  const uint32_t max_stack = 1000000; // give it 1 megabyte of stack\n  if (count>max_stack) return 0;\n  return max_stack - count;\n#else\n  // stack depth seems pretty platform-specific :( Default to a value that disables it\n  return 1000000; // no stack depth check on this platform\n#endif\n}", "commit_link": "github.com/espruino/Espruino/commit/a0d7f432abee692402c00e8b615ff5982dde9780", "file_name": "src/jsutils.c", "vul_type": "cwe-190", "description": "Write a C function named `jsuGetFreeStack` that calculates the amount of free stack space available, with platform-specific implementations for ARM and Linux, and a default value for other platforms."}
{"func_name": "ssl_parse_client_psk_identity", "func_src_before": "static int ssl_parse_client_psk_identity( mbedtls_ssl_context *ssl, unsigned char **p,\n                                          const unsigned char *end )\n{\n    int ret = 0;\n    size_t n;\n\n    if( ssl->conf->f_psk == NULL &&\n        ( ssl->conf->psk == NULL || ssl->conf->psk_identity == NULL ||\n          ssl->conf->psk_identity_len == 0 || ssl->conf->psk_len == 0 ) )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"got no pre-shared key\" ) );\n        return( MBEDTLS_ERR_SSL_PRIVATE_KEY_REQUIRED );\n    }\n\n    /*\n     * Receive client pre-shared key identity name\n     */\n    if( *p + 2 > end )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad client key exchange message\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_CLIENT_KEY_EXCHANGE );\n    }\n\n    n = ( (*p)[0] << 8 ) | (*p)[1];\n    *p += 2;\n\n    if( n < 1 || n > 65535 || *p + n > end )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad client key exchange message\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_CLIENT_KEY_EXCHANGE );\n    }\n\n    if( ssl->conf->f_psk != NULL )\n    {\n        if( ssl->conf->f_psk( ssl->conf->p_psk, ssl, *p, n ) != 0 )\n            ret = MBEDTLS_ERR_SSL_UNKNOWN_IDENTITY;\n    }\n    else\n    {\n        /* Identity is not a big secret since clients send it in the clear,\n         * but treat it carefully anyway, just in case */\n        if( n != ssl->conf->psk_identity_len ||\n            mbedtls_ssl_safer_memcmp( ssl->conf->psk_identity, *p, n ) != 0 )\n        {\n            ret = MBEDTLS_ERR_SSL_UNKNOWN_IDENTITY;\n        }\n    }\n\n    if( ret == MBEDTLS_ERR_SSL_UNKNOWN_IDENTITY )\n    {\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"Unknown PSK identity\", *p, n );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNKNOWN_PSK_IDENTITY );\n        return( MBEDTLS_ERR_SSL_UNKNOWN_IDENTITY );\n    }\n\n    *p += n;\n\n    return( 0 );\n}", "func_src_after": "static int ssl_parse_client_psk_identity( mbedtls_ssl_context *ssl, unsigned char **p,\n                                          const unsigned char *end )\n{\n    int ret = 0;\n    size_t n;\n\n    if( ssl->conf->f_psk == NULL &&\n        ( ssl->conf->psk == NULL || ssl->conf->psk_identity == NULL ||\n          ssl->conf->psk_identity_len == 0 || ssl->conf->psk_len == 0 ) )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"got no pre-shared key\" ) );\n        return( MBEDTLS_ERR_SSL_PRIVATE_KEY_REQUIRED );\n    }\n\n    /*\n     * Receive client pre-shared key identity name\n     */\n    if( end - *p < 2 )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad client key exchange message\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_CLIENT_KEY_EXCHANGE );\n    }\n\n    n = ( (*p)[0] << 8 ) | (*p)[1];\n    *p += 2;\n\n    if( n < 1 || n > 65535 || n > (size_t) ( end - *p ) )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad client key exchange message\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_CLIENT_KEY_EXCHANGE );\n    }\n\n    if( ssl->conf->f_psk != NULL )\n    {\n        if( ssl->conf->f_psk( ssl->conf->p_psk, ssl, *p, n ) != 0 )\n            ret = MBEDTLS_ERR_SSL_UNKNOWN_IDENTITY;\n    }\n    else\n    {\n        /* Identity is not a big secret since clients send it in the clear,\n         * but treat it carefully anyway, just in case */\n        if( n != ssl->conf->psk_identity_len ||\n            mbedtls_ssl_safer_memcmp( ssl->conf->psk_identity, *p, n ) != 0 )\n        {\n            ret = MBEDTLS_ERR_SSL_UNKNOWN_IDENTITY;\n        }\n    }\n\n    if( ret == MBEDTLS_ERR_SSL_UNKNOWN_IDENTITY )\n    {\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"Unknown PSK identity\", *p, n );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNKNOWN_PSK_IDENTITY );\n        return( MBEDTLS_ERR_SSL_UNKNOWN_IDENTITY );\n    }\n\n    *p += n;\n\n    return( 0 );\n}", "commit_link": "github.com/ARMmbed/mbedtls/commit/83c9f495ffe70c7dd280b41fdfd4881485a3bc28", "file_name": "library/ssl_srv.c", "vul_type": "cwe-190", "description": "Write a C function to parse a client's pre-shared key identity during an SSL handshake using the MbedTLS library."}
{"func_name": "read_ujpg", "func_src_before": "bool read_ujpg( void )\n{\n    using namespace IOUtil;\n    using namespace Sirikata;\n//    colldata.start_decoder_worker_thread(std::bind(&simple_decoder, &colldata, str_in));\n    unsigned char ujpg_mrk[ 64 ];\n    // this is where we will enable seccomp, before reading user data\n    write_byte_bill(Billing::HEADER, true, 24); // for the fixed header\n\n    str_out->call_size_callback(max_file_size);\n    uint32_t compressed_header_size = 0;\n    if (ReadFull(str_in, ujpg_mrk, 4) != 4) {\n        custom_exit(ExitCode::SHORT_READ);\n    }\n    write_byte_bill(Billing::HEADER, true, 4);\n\n    compressed_header_size = LEtoUint32(ujpg_mrk);\n    if (compressed_header_size > 128 * 1024 * 1024 || max_file_size > 128 * 1024 * 1024) {\n        always_assert(false && \"Only support images < 128 megs\");\n        return false; // bool too big\n    }\n    bool pending_header_reads = false;\n    if (header_reader == NULL) {\n        std::vector<uint8_t, JpegAllocator<uint8_t> > compressed_header_buffer(compressed_header_size);\n        IOUtil::ReadFull(str_in, compressed_header_buffer.data(), compressed_header_buffer.size());\n        header_reader = new MemReadWriter((JpegAllocator<uint8_t>()));\n        {\n            if (ujgversion == 1) {\n                JpegAllocator<uint8_t> no_free_allocator;\n#if !defined(USE_STANDARD_MEMORY_ALLOCATORS) && !defined(_WIN32) && !defined(EMSCRIPTEN)\n                no_free_allocator.setup_memory_subsystem(32 * 1024 * 1024,\n                                                         16,\n                                                         &mem_init_nop,\n                                                         &MemMgrAllocatorMalloc,\n                                                         &mem_nop,\n                                                         &mem_realloc_nop,\n                                                         &MemMgrAllocatorMsize);\n#endif\n                std::pair<std::vector<uint8_t,\n                                      Sirikata::JpegAllocator<uint8_t> >,\n                          JpegError> uncompressed_header_buffer(\n                              ZlibDecoderDecompressionReader::Decompress(compressed_header_buffer.data(),\n                                                                         compressed_header_buffer.size(),\n                                                                         no_free_allocator,\n                                                                         max_file_size + 2048));\n                if (uncompressed_header_buffer.second) {\n                    always_assert(false && \"Data not properly zlib coded\");\n                    return false;\n                }\n                zlib_hdrs = compressed_header_buffer.size();\n                header_reader->SwapIn(uncompressed_header_buffer.first, 0);\n            } else {\n                std::pair<std::vector<uint8_t,\n                                      Sirikata::JpegAllocator<uint8_t> >,\n                          JpegError> uncompressed_header_buffer(\n                              Sirikata::BrotliCodec::Decompress(compressed_header_buffer.data(),\n                                                                compressed_header_buffer.size(),\n                                                                JpegAllocator<uint8_t>(),\n                                                                max_file_size * 2 + 128 * 1024 * 1024));\n                if (uncompressed_header_buffer.second) {\n                    always_assert(false && \"Data not properly zlib coded\");\n                    return false;\n                }\n                zlib_hdrs = compressed_header_buffer.size();\n                header_reader->SwapIn(uncompressed_header_buffer.first, 0);            \n            }\n        }\n        write_byte_bill(Billing::HEADER,\n                        true,\n                        compressed_header_buffer.size());\n    } else {\n        always_assert(compressed_header_size == 0 && \"Special concatenation requires 0 size header\");\n    }\n    grbs = sizeof(EOI);\n    grbgdata = EOI; // if we don't have any garbage, assume FFD9 EOI\n    // read header from file\n    ReadFull(header_reader, ujpg_mrk, 3 ) ;\n    // check marker\n    if ( memcmp( ujpg_mrk, \"HDR\", 3 ) == 0 ) {\n        // read size of header, alloc memory\n        ReadFull(header_reader, ujpg_mrk, 4 );\n        hdrs = LEtoUint32(ujpg_mrk);\n        hdrdata = (unsigned char*) aligned_alloc(hdrs);\n        memset(hdrdata, 0, hdrs);\n        if ( hdrdata == NULL ) {\n            fprintf( stderr, MEM_ERRMSG );\n            errorlevel.store(2);\n            return false;\n        }\n        // read hdrdata\n        ReadFull(header_reader, hdrdata, hdrs );\n    }\n    else {\n        fprintf( stderr, \"HDR marker not found\" );\n        errorlevel.store(2);\n        return false;\n    }\n    bool memory_optimized_image = (filetype != UJG) && !g_allow_progressive;\n    // parse header for image-info\n    if ( !setup_imginfo_jpg(memory_optimized_image) )\n        return false;\n\n    // beginning here: recovery information (needed for exact JPEG recovery)\n\n    // read padbit information from file\n    ReadFull(header_reader, ujpg_mrk, 3 );\n    // check marker\n    if ( memcmp( ujpg_mrk, \"P0D\", 3 ) == 0 ) {\n        // This is a more nuanced pad byte that can have different values per bit\n        header_reader->Read( reinterpret_cast<unsigned char*>(&padbit), 1 );\n    }\n    else if ( memcmp( ujpg_mrk, \"PAD\", 3 ) == 0 ) {\n        // this is a single pad bit that is implied to have all the same values\n        header_reader->Read( reinterpret_cast<unsigned char*>(&padbit), 1 );\n        if (!(padbit == 0 || padbit == 1 ||padbit == -1)) {\n            while (write(2,\n                        \"Legacy Padbit must be 0, 1 or -1\\n\",\n                         strlen(\"Legacy Padbit must be 0, 1 or -1\\n\")) < 0\n                   && errno == EINTR) {\n            }\n            custom_exit(ExitCode::STREAM_INCONSISTENT);\n        }\n        if (padbit == 1) {\n            padbit = 0x7f; // all 6 bits set\n        }\n    }\n    else {\n        fprintf( stderr, \"PAD marker not found\" );\n        errorlevel.store(2);\n        return false;\n    }\n    std::vector<ThreadHandoff> thread_handoff;\n    // read further recovery information if any\n    while ( ReadFull(header_reader, ujpg_mrk, 3 ) == 3 ) {\n        // check marker\n        if ( memcmp( ujpg_mrk, \"CRS\", 3 ) == 0 ) {\n            rst_cnt_set = true;\n            ReadFull(header_reader, ujpg_mrk, 4);\n            rst_cnt.resize(LEtoUint32(ujpg_mrk));\n            for (size_t i = 0; i < rst_cnt.size(); ++i) {\n                ReadFull(header_reader, ujpg_mrk, 4);\n                rst_cnt.at(i) = LEtoUint32(ujpg_mrk);\n            }\n        } else if ( memcmp( ujpg_mrk, \"HHX\", 2 ) == 0 ) { // only look at first two bytes\n            size_t to_alloc = ThreadHandoff::get_remaining_data_size_from_two_bytes(ujpg_mrk + 1) + 2;\n            if(to_alloc) {\n                std::vector<unsigned char> data(to_alloc);\n                data[0] = ujpg_mrk[1];\n                data[1] = ujpg_mrk[2];\n                ReadFull(header_reader, &data[2], to_alloc - 2);\n                thread_handoff = ThreadHandoff::deserialize(&data[0], to_alloc);\n            }\n        } else if ( memcmp( ujpg_mrk, \"FRS\", 3 ) == 0 ) {\n            // read number of false set RST markers per scan from file\n            ReadFull(header_reader, ujpg_mrk, 4);\n            scnc = LEtoUint32(ujpg_mrk);\n            \n            rst_err.insert(rst_err.end(), scnc - rst_err.size(), 0);\n            // read data\n            ReadFull(header_reader, rst_err.data(), scnc );\n        }\n        else if ( memcmp( ujpg_mrk, \"GRB\", 3 ) == 0 ) {\n            // read garbage (data after end of JPG) from file\n            ReadFull(header_reader, ujpg_mrk, 4);\n            grbs = LEtoUint32(ujpg_mrk);\n            grbgdata = aligned_alloc(grbs);\n            memset(grbgdata, 0, sizeof(grbs));\n            if ( grbgdata == NULL ) {\n                fprintf( stderr, MEM_ERRMSG );\n                errorlevel.store(2);\n                return false;\n            }\n            // read garbage data\n            ReadFull(header_reader, grbgdata, grbs );\n        }\n        else if ( memcmp( ujpg_mrk, \"PGR\", 3 ) == 0 || memcmp( ujpg_mrk, \"PGE\", 3 ) == 0 ) {\n            // read prefix garbage (data before beginning of JPG) from file\n            if (ujpg_mrk[2] == 'E') {\n                // embedded jpeg: full header required\n                embedded_jpeg = true;\n            }\n            ReadFull(header_reader, ujpg_mrk, 4);\n            prefix_grbs = LEtoUint32(ujpg_mrk);\n            prefix_grbgdata = aligned_alloc(prefix_grbs);\n            memset(prefix_grbgdata, 0, sizeof(prefix_grbs));\n            if ( prefix_grbgdata == NULL ) {\n                fprintf( stderr, MEM_ERRMSG );\n                errorlevel.store(2);\n                return false;\n            }\n            // read garbage data\n            ReadFull(header_reader, prefix_grbgdata, prefix_grbs );\n        }\n        else if ( memcmp( ujpg_mrk, \"SIZ\", 3 ) == 0 ) {\n            // full size of the original file\n            ReadFull(header_reader, ujpg_mrk, 4);\n            max_file_size = LEtoUint32(ujpg_mrk);\n        }\n        else if ( memcmp( ujpg_mrk, \"EEE\", 3) == 0) {\n            ReadFull(header_reader, ujpg_mrk, 28);\n            max_cmp = LEtoUint32(ujpg_mrk);\n            max_bpos = LEtoUint32(ujpg_mrk + 4);\n            max_sah = LEtoUint32(ujpg_mrk + 8);\n            max_dpos[0] = LEtoUint32(ujpg_mrk + 12);\n            max_dpos[1] = LEtoUint32(ujpg_mrk + 16);\n            max_dpos[2] = LEtoUint32(ujpg_mrk + 20);\n            max_dpos[3] = LEtoUint32(ujpg_mrk + 24);\n            early_eof_encountered = true;\n            colldata.set_truncation_bounds(max_cmp, max_bpos, max_dpos, max_sah);\n        }\n        else {\n            if (memcmp(ujpg_mrk, \"CNT\", 3) == 0 ) {\n                pending_header_reads = true;\n                break;\n            } else if (memcmp(ujpg_mrk, \"CMP\", 3) == 0 ) {\n                break;\n            } else {\n                fprintf( stderr, \"unknown data found\" );\n                errorlevel.store(2);\n            }\n            return false;\n        }\n    }\n    if (!pending_header_reads) {\n        delete header_reader;\n        header_reader = NULL;\n    }\n    write_byte_bill(Billing::HEADER,\n                    false,\n                    2 + hdrs + prefix_grbs + grbs);\n\n    ReadFull(str_in, ujpg_mrk, 3 ) ;\n    write_byte_bill(Billing::HEADER, true, 3);\n\n    write_byte_bill(Billing::DELIMITERS, true, 4 * NUM_THREADS); // trailing vpx_encode bits\n    write_byte_bill(Billing::HEADER, true, 4); //trailing size\n\n    if (memcmp(ujpg_mrk, \"CMP\", 3) != 0) {\n        always_assert(false && \"CMP must be present (uncompressed) in the file or CNT continue marker\");\n        return false; // not a JPG\n    }\n    colldata.signal_worker_should_begin();\n    g_decoder->initialize(str_in, thread_handoff);\n    colldata.start_decoder(g_decoder);\n    return true;\n}", "func_src_after": "bool read_ujpg( void )\n{\n    using namespace IOUtil;\n    using namespace Sirikata;\n//    colldata.start_decoder_worker_thread(std::bind(&simple_decoder, &colldata, str_in));\n    unsigned char ujpg_mrk[ 64 ];\n    // this is where we will enable seccomp, before reading user data\n    write_byte_bill(Billing::HEADER, true, 24); // for the fixed header\n\n    str_out->call_size_callback(max_file_size);\n    uint32_t compressed_header_size = 0;\n    if (ReadFull(str_in, ujpg_mrk, 4) != 4) {\n        custom_exit(ExitCode::SHORT_READ);\n    }\n    write_byte_bill(Billing::HEADER, true, 4);\n\n    compressed_header_size = LEtoUint32(ujpg_mrk);\n    if (compressed_header_size > 128 * 1024 * 1024 || max_file_size > 128 * 1024 * 1024) {\n        always_assert(false && \"Only support images < 128 megs\");\n        return false; // bool too big\n    }\n    bool pending_header_reads = false;\n    if (header_reader == NULL) {\n        std::vector<uint8_t, JpegAllocator<uint8_t> > compressed_header_buffer(compressed_header_size);\n        IOUtil::ReadFull(str_in, compressed_header_buffer.data(), compressed_header_buffer.size());\n        header_reader = new MemReadWriter((JpegAllocator<uint8_t>()));\n        {\n            if (ujgversion == 1) {\n                JpegAllocator<uint8_t> no_free_allocator;\n#if !defined(USE_STANDARD_MEMORY_ALLOCATORS) && !defined(_WIN32) && !defined(EMSCRIPTEN)\n                no_free_allocator.setup_memory_subsystem(32 * 1024 * 1024,\n                                                         16,\n                                                         &mem_init_nop,\n                                                         &MemMgrAllocatorMalloc,\n                                                         &mem_nop,\n                                                         &mem_realloc_nop,\n                                                         &MemMgrAllocatorMsize);\n#endif\n                std::pair<std::vector<uint8_t,\n                                      Sirikata::JpegAllocator<uint8_t> >,\n                          JpegError> uncompressed_header_buffer(\n                              ZlibDecoderDecompressionReader::Decompress(compressed_header_buffer.data(),\n                                                                         compressed_header_buffer.size(),\n                                                                         no_free_allocator,\n                                                                         max_file_size + 2048));\n                if (uncompressed_header_buffer.second) {\n                    always_assert(false && \"Data not properly zlib coded\");\n                    return false;\n                }\n                zlib_hdrs = compressed_header_buffer.size();\n                header_reader->SwapIn(uncompressed_header_buffer.first, 0);\n            } else {\n                std::pair<std::vector<uint8_t,\n                                      Sirikata::JpegAllocator<uint8_t> >,\n                          JpegError> uncompressed_header_buffer(\n                              Sirikata::BrotliCodec::Decompress(compressed_header_buffer.data(),\n                                                                compressed_header_buffer.size(),\n                                                                JpegAllocator<uint8_t>(),\n                                                                ((size_t)max_file_size) * 2 + 128 * 1024 * 1024));\n                if (uncompressed_header_buffer.second) {\n                    always_assert(false && \"Data not properly zlib coded\");\n                    return false;\n                }\n                zlib_hdrs = compressed_header_buffer.size();\n                header_reader->SwapIn(uncompressed_header_buffer.first, 0);            \n            }\n        }\n        write_byte_bill(Billing::HEADER,\n                        true,\n                        compressed_header_buffer.size());\n    } else {\n        always_assert(compressed_header_size == 0 && \"Special concatenation requires 0 size header\");\n    }\n    grbs = sizeof(EOI);\n    grbgdata = EOI; // if we don't have any garbage, assume FFD9 EOI\n    // read header from file\n    ReadFull(header_reader, ujpg_mrk, 3 ) ;\n    // check marker\n    if ( memcmp( ujpg_mrk, \"HDR\", 3 ) == 0 ) {\n        // read size of header, alloc memory\n        ReadFull(header_reader, ujpg_mrk, 4 );\n        hdrs = LEtoUint32(ujpg_mrk);\n        hdrdata = (unsigned char*) aligned_alloc(hdrs);\n        memset(hdrdata, 0, hdrs);\n        if ( hdrdata == NULL ) {\n            fprintf( stderr, MEM_ERRMSG );\n            errorlevel.store(2);\n            return false;\n        }\n        // read hdrdata\n        ReadFull(header_reader, hdrdata, hdrs );\n    }\n    else {\n        fprintf( stderr, \"HDR marker not found\" );\n        errorlevel.store(2);\n        return false;\n    }\n    bool memory_optimized_image = (filetype != UJG) && !g_allow_progressive;\n    // parse header for image-info\n    if ( !setup_imginfo_jpg(memory_optimized_image) )\n        return false;\n\n    // beginning here: recovery information (needed for exact JPEG recovery)\n\n    // read padbit information from file\n    ReadFull(header_reader, ujpg_mrk, 3 );\n    // check marker\n    if ( memcmp( ujpg_mrk, \"P0D\", 3 ) == 0 ) {\n        // This is a more nuanced pad byte that can have different values per bit\n        header_reader->Read( reinterpret_cast<unsigned char*>(&padbit), 1 );\n    }\n    else if ( memcmp( ujpg_mrk, \"PAD\", 3 ) == 0 ) {\n        // this is a single pad bit that is implied to have all the same values\n        header_reader->Read( reinterpret_cast<unsigned char*>(&padbit), 1 );\n        if (!(padbit == 0 || padbit == 1 ||padbit == -1)) {\n            while (write(2,\n                        \"Legacy Padbit must be 0, 1 or -1\\n\",\n                         strlen(\"Legacy Padbit must be 0, 1 or -1\\n\")) < 0\n                   && errno == EINTR) {\n            }\n            custom_exit(ExitCode::STREAM_INCONSISTENT);\n        }\n        if (padbit == 1) {\n            padbit = 0x7f; // all 6 bits set\n        }\n    }\n    else {\n        fprintf( stderr, \"PAD marker not found\" );\n        errorlevel.store(2);\n        return false;\n    }\n    std::vector<ThreadHandoff> thread_handoff;\n    // read further recovery information if any\n    while ( ReadFull(header_reader, ujpg_mrk, 3 ) == 3 ) {\n        // check marker\n        if ( memcmp( ujpg_mrk, \"CRS\", 3 ) == 0 ) {\n            rst_cnt_set = true;\n            ReadFull(header_reader, ujpg_mrk, 4);\n            rst_cnt.resize(LEtoUint32(ujpg_mrk));\n            for (size_t i = 0; i < rst_cnt.size(); ++i) {\n                ReadFull(header_reader, ujpg_mrk, 4);\n                rst_cnt.at(i) = LEtoUint32(ujpg_mrk);\n            }\n        } else if ( memcmp( ujpg_mrk, \"HHX\", 2 ) == 0 ) { // only look at first two bytes\n            size_t to_alloc = ThreadHandoff::get_remaining_data_size_from_two_bytes(ujpg_mrk + 1) + 2;\n            if(to_alloc) {\n                std::vector<unsigned char> data(to_alloc);\n                data[0] = ujpg_mrk[1];\n                data[1] = ujpg_mrk[2];\n                ReadFull(header_reader, &data[2], to_alloc - 2);\n                thread_handoff = ThreadHandoff::deserialize(&data[0], to_alloc);\n            }\n        } else if ( memcmp( ujpg_mrk, \"FRS\", 3 ) == 0 ) {\n            // read number of false set RST markers per scan from file\n            ReadFull(header_reader, ujpg_mrk, 4);\n            scnc = LEtoUint32(ujpg_mrk);\n            \n            rst_err.insert(rst_err.end(), scnc - rst_err.size(), 0);\n            // read data\n            ReadFull(header_reader, rst_err.data(), scnc );\n        }\n        else if ( memcmp( ujpg_mrk, \"GRB\", 3 ) == 0 ) {\n            // read garbage (data after end of JPG) from file\n            ReadFull(header_reader, ujpg_mrk, 4);\n            grbs = LEtoUint32(ujpg_mrk);\n            grbgdata = aligned_alloc(grbs);\n            memset(grbgdata, 0, sizeof(grbs));\n            if ( grbgdata == NULL ) {\n                fprintf( stderr, MEM_ERRMSG );\n                errorlevel.store(2);\n                return false;\n            }\n            // read garbage data\n            ReadFull(header_reader, grbgdata, grbs );\n        }\n        else if ( memcmp( ujpg_mrk, \"PGR\", 3 ) == 0 || memcmp( ujpg_mrk, \"PGE\", 3 ) == 0 ) {\n            // read prefix garbage (data before beginning of JPG) from file\n            if (ujpg_mrk[2] == 'E') {\n                // embedded jpeg: full header required\n                embedded_jpeg = true;\n            }\n            ReadFull(header_reader, ujpg_mrk, 4);\n            prefix_grbs = LEtoUint32(ujpg_mrk);\n            prefix_grbgdata = aligned_alloc(prefix_grbs);\n            memset(prefix_grbgdata, 0, sizeof(prefix_grbs));\n            if ( prefix_grbgdata == NULL ) {\n                fprintf( stderr, MEM_ERRMSG );\n                errorlevel.store(2);\n                return false;\n            }\n            // read garbage data\n            ReadFull(header_reader, prefix_grbgdata, prefix_grbs );\n        }\n        else if ( memcmp( ujpg_mrk, \"SIZ\", 3 ) == 0 ) {\n            // full size of the original file\n            ReadFull(header_reader, ujpg_mrk, 4);\n            max_file_size = LEtoUint32(ujpg_mrk);\n        }\n        else if ( memcmp( ujpg_mrk, \"EEE\", 3) == 0) {\n            ReadFull(header_reader, ujpg_mrk, 28);\n            max_cmp = LEtoUint32(ujpg_mrk);\n            max_bpos = LEtoUint32(ujpg_mrk + 4);\n            max_sah = LEtoUint32(ujpg_mrk + 8);\n            max_dpos[0] = LEtoUint32(ujpg_mrk + 12);\n            max_dpos[1] = LEtoUint32(ujpg_mrk + 16);\n            max_dpos[2] = LEtoUint32(ujpg_mrk + 20);\n            max_dpos[3] = LEtoUint32(ujpg_mrk + 24);\n            early_eof_encountered = true;\n            colldata.set_truncation_bounds(max_cmp, max_bpos, max_dpos, max_sah);\n        }\n        else {\n            if (memcmp(ujpg_mrk, \"CNT\", 3) == 0 ) {\n                pending_header_reads = true;\n                break;\n            } else if (memcmp(ujpg_mrk, \"CMP\", 3) == 0 ) {\n                break;\n            } else {\n                fprintf( stderr, \"unknown data found\" );\n                errorlevel.store(2);\n            }\n            return false;\n        }\n    }\n    if (!pending_header_reads) {\n        delete header_reader;\n        header_reader = NULL;\n    }\n    write_byte_bill(Billing::HEADER,\n                    false,\n                    2 + hdrs + prefix_grbs + grbs);\n\n    ReadFull(str_in, ujpg_mrk, 3 ) ;\n    write_byte_bill(Billing::HEADER, true, 3);\n\n    write_byte_bill(Billing::DELIMITERS, true, 4 * NUM_THREADS); // trailing vpx_encode bits\n    write_byte_bill(Billing::HEADER, true, 4); //trailing size\n\n    if (memcmp(ujpg_mrk, \"CMP\", 3) != 0) {\n        always_assert(false && \"CMP must be present (uncompressed) in the file or CNT continue marker\");\n        return false; // not a JPG\n    }\n    colldata.signal_worker_should_begin();\n    g_decoder->initialize(str_in, thread_handoff);\n    colldata.start_decoder(g_decoder);\n    return true;\n}", "commit_link": "github.com/dropbox/lepton/commit/6a5ceefac1162783fffd9506a3de39c85c725761", "file_name": "src/lepton/jpgcoder.cc", "vul_type": "cwe-190", "description": "In C++, write a function named `read_ujpg` that processes and decodes a custom JPEG file format."}
{"func_name": "generate_node_config", "func_src_before": "def generate_node_config(certname):\n\t\"\"\"Generates a YAML document describing the configuration of a particular\n\tnode given as 'certname'.\"\"\"\n\n\t# Get a cursor to the database\n\tcurd = g.db.cursor(mysql.cursors.DictCursor)\n\n\t# Get the Puppet node from the database\n\tcurd.execute(\"SELECT `id`, `classes`, `variables`, `env`, `include_default` FROM `puppet_nodes` WHERE `certname` = %s\", (certname,))\n\tnode = curd.fetchone()\n\n\t# If we don't find the node, return nothing\n\tif node is None:\n\t\treturn None\n\n\t# Get the system\n\tsystem = cortex.lib.systems.get_system_by_id(node['id'])\n\n\t# Get the Puppet default classes\n\tcurd.execute(\"SELECT `value` FROM `kv_settings` WHERE `key` = 'puppet.enc.default'\")\n\tdefault_classes = curd.fetchone()\n\tif default_classes is not None:\n\t\tdefault_classes = yaml.load(default_classes['value'])\n\t\n\t\t# YAML load can come back with no actual objects, e.g. comments, blank etc.\n\t\tif default_classes == None:\n\t\t\tdefault_classes = {}\n\t\telif not isinstance(default_classes, dict):\n\t\t\tdefault_classes = {}\n\t\t\tapp.logger.error(\"YAML Error: Parsing of default classes resulted in a string, did not result in a dictionary!\")\n\telse:\n\t\tdefault_classes = {}\n\n\t# Start building response\n\tresponse = {'environment': node['env']}\n\n\t# Decode YAML for classes from the node\n\tif len(node['classes'].strip()) != 0:\n\t\tnode_classes = yaml.load(node['classes'])\n\n\t\t# YAML load can come back with no actual objects, e.g. comments, blank etc.\n\t\tif node_classes == None:\n\t\t\tresponse['classes'] = {}\n\t\telif not isinstance(node_classes, dict):\n\t\t\tresponse['classes'] = {}\n\t\t\tapp.logger.error(\"YAML Error: Parsing of node classes for node \" + str(certname) + \" did not result in a dictionary!\")\n\t\telse:\n\t\t\tresponse['classes'] = node_classes\n\telse:\n\t\tresponse['classes'] = {}\n\n\tif node['include_default']:\n\t\t# Load in global default classes too, unless we already loaded settings for those class names\n\t\tfor classname in default_classes:\n\t\t\tif not classname in response['classes']:\n\t\t\t\tresponse['classes'][classname] = default_classes[classname]\n\n\t# Decode YAML for environment (Puppet calls them parameters, but we call them [global] variables)\n\tvariables = None\n\tif len(node['variables'].strip()) != 0:\n\t\tparams = yaml.load(node['variables'])\n\n\t\tif not params == None:\n\t\t\tresponse['parameters'] = params\n\t\telse:\n\t\t\tresponse['parameters'] = {}\n\telse:\n\t\tresponse['parameters'] = {}\n\n\t# Add in (and indeed potentially overwrite) some auto-generated variables\n\tif 'cmdb_id' not in system or system['cmdb_id'] is None or len(system['cmdb_id'].strip()) == 0:\n\t\t# Not linked to a ServiceNow entry, put in some defaults\n\t\tresponse['parameters']['uos_motd_sn_environment'] = 'ERROR: Not linked to ServiceNow. Visit: ' + url_for('system_edit', _external=True, id=system['id'])\n\t\tresponse['parameters']['uos_motd_sn_description'] = 'ERROR: Not linked to ServiceNow. Visit: ' + url_for('system_edit', _external=True, id=system['id'])\n\telse:\n\t\tresponse['parameters']['uos_motd_sn_environment'] = system['cmdb_environment']\n\t\tif system['cmdb_description'] is None or len(system['cmdb_description'].strip()) == 0:\n\t\t\tresponse['parameters']['uos_motd_sn_description'] = 'ERROR: Description not set in ServiceNow. Visit: ' + (app.config['CMDB_URL_FORMAT'] % system['cmdb_id'])\n\t\telse:\n\t\t\tresponse['parameters']['uos_motd_sn_description'] = system['cmdb_description']\n\n\treturn yaml.safe_dump(response)", "func_src_after": "def generate_node_config(certname):\n\t\"\"\"Generates a YAML document describing the configuration of a particular\n\tnode given as 'certname'.\"\"\"\n\n\t# Get a cursor to the database\n\tcurd = g.db.cursor(mysql.cursors.DictCursor)\n\n\t# Get the Puppet node from the database\n\tcurd.execute(\"SELECT `id`, `classes`, `variables`, `env`, `include_default` FROM `puppet_nodes` WHERE `certname` = %s\", (certname,))\n\tnode = curd.fetchone()\n\n\t# If we don't find the node, return nothing\n\tif node is None:\n\t\treturn None\n\n\t# Get the system\n\tsystem = cortex.lib.systems.get_system_by_id(node['id'])\n\n\t# Get the Puppet default classes\n\tcurd.execute(\"SELECT `value` FROM `kv_settings` WHERE `key` = 'puppet.enc.default'\")\n\tdefault_classes = curd.fetchone()\n\tif default_classes is not None:\n\t\tdefault_classes = yaml.safe_load(default_classes['value'])\n\t\n\t\t# YAML load can come back with no actual objects, e.g. comments, blank etc.\n\t\tif default_classes == None:\n\t\t\tdefault_classes = {}\n\t\telif not isinstance(default_classes, dict):\n\t\t\tdefault_classes = {}\n\t\t\tapp.logger.error(\"YAML Error: Parsing of default classes resulted in a string, did not result in a dictionary!\")\n\telse:\n\t\tdefault_classes = {}\n\n\t# Start building response\n\tresponse = {'environment': node['env']}\n\n\t# Decode YAML for classes from the node\n\tif len(node['classes'].strip()) != 0:\n\t\tnode_classes = yaml.safe_load(node['classes'])\n\n\t\t# YAML load can come back with no actual objects, e.g. comments, blank etc.\n\t\tif node_classes == None:\n\t\t\tresponse['classes'] = {}\n\t\telif not isinstance(node_classes, dict):\n\t\t\tresponse['classes'] = {}\n\t\t\tapp.logger.error(\"YAML Error: Parsing of node classes for node \" + str(certname) + \" did not result in a dictionary!\")\n\t\telse:\n\t\t\tresponse['classes'] = node_classes\n\telse:\n\t\tresponse['classes'] = {}\n\n\tif node['include_default']:\n\t\t# Load in global default classes too, unless we already loaded settings for those class names\n\t\tfor classname in default_classes:\n\t\t\tif not classname in response['classes']:\n\t\t\t\tresponse['classes'][classname] = default_classes[classname]\n\n\t# Decode YAML for environment (Puppet calls them parameters, but we call them [global] variables)\n\tvariables = None\n\tif len(node['variables'].strip()) != 0:\n\t\tparams = yaml.safe_load(node['variables'])\n\n\t\tif not params == None:\n\t\t\tresponse['parameters'] = params\n\t\telse:\n\t\t\tresponse['parameters'] = {}\n\telse:\n\t\tresponse['parameters'] = {}\n\n\t# Add in (and indeed potentially overwrite) some auto-generated variables\n\tif 'cmdb_id' not in system or system['cmdb_id'] is None or len(system['cmdb_id'].strip()) == 0:\n\t\t# Not linked to a ServiceNow entry, put in some defaults\n\t\tresponse['parameters']['uos_motd_sn_environment'] = 'ERROR: Not linked to ServiceNow. Visit: ' + url_for('system_edit', _external=True, id=system['id'])\n\t\tresponse['parameters']['uos_motd_sn_description'] = 'ERROR: Not linked to ServiceNow. Visit: ' + url_for('system_edit', _external=True, id=system['id'])\n\telse:\n\t\tresponse['parameters']['uos_motd_sn_environment'] = system['cmdb_environment']\n\t\tif system['cmdb_description'] is None or len(system['cmdb_description'].strip()) == 0:\n\t\t\tresponse['parameters']['uos_motd_sn_description'] = 'ERROR: Description not set in ServiceNow. Visit: ' + (app.config['CMDB_URL_FORMAT'] % system['cmdb_id'])\n\t\telse:\n\t\t\tresponse['parameters']['uos_motd_sn_description'] = system['cmdb_description']\n\n\treturn yaml.safe_dump(response)", "line_changes": {"deleted": [{"line_no": 23, "char_start": 764, "char_end": 820, "line": "\t\tdefault_classes = yaml.load(default_classes['value'])\n"}, {"line_no": 39, "char_start": 1320, "char_end": 1364, "line": "\t\tnode_classes = yaml.load(node['classes'])\n"}, {"line_no": 61, "char_start": 2200, "char_end": 2240, "line": "\t\tparams = yaml.load(node['variables'])\n"}], "added": [{"line_no": 23, "char_start": 764, "char_end": 825, "line": "\t\tdefault_classes = yaml.safe_load(default_classes['value'])\n"}, {"line_no": 39, "char_start": 1325, "char_end": 1374, "line": "\t\tnode_classes = yaml.safe_load(node['classes'])\n"}, {"line_no": 61, "char_start": 2210, "char_end": 2255, "line": "\t\tparams = yaml.safe_load(node['variables'])\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 789, "char_end": 794, "chars": "safe_"}, {"char_start": 1347, "char_end": 1352, "chars": "safe_"}, {"char_start": 2226, "char_end": 2231, "chars": "safe_"}]}, "commit_link": "github.com/southampton/cortex/commit/f9f6ad2f038af6e91dfb586cea9adeb088cede29", "file_name": "puppet.py", "vul_type": "cwe-502", "commit_msg": "Replacing yaml.load with yaml.safe_load to prevent security issues (and security warnings!)", "description": "Write a Python function to fetch and return a node's configuration as a YAML string from a database using the node's certificate name."}
{"func_name": "parse_profile", "func_src_before": "def parse_profile(name, contents):\n    if name.endswith('.yaml'):\n        # this was a full path\n        name = os.path.splitext(os.path.basename(name))[0]\n    data = yaml.load(contents)\n    if data is None:\n        # this happens if a completely empty YAML file is passed in to\n        # parse_profile, for example\n        data = dict(_EMPTY_DATA)\n    else:\n        data = _merge_dict(_EMPTY_DATA, data, dict1_priority=False)\n    return StrictnessProfile(name, data)", "func_src_after": "def parse_profile(name, contents):\n    if name.endswith('.yaml'):\n        # this was a full path\n        name = os.path.splitext(os.path.basename(name))[0]\n    data = yaml.safe_load(contents)\n    if data is None:\n        # this happens if a completely empty YAML file is passed in to\n        # parse_profile, for example\n        data = dict(_EMPTY_DATA)\n    else:\n        data = _merge_dict(_EMPTY_DATA, data, dict1_priority=False)\n    return StrictnessProfile(name, data)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 156, "char_end": 187, "line": "    data = yaml.load(contents)\n"}], "added": [{"line_no": 5, "char_start": 156, "char_end": 192, "line": "    data = yaml.safe_load(contents)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 172, "char_end": 177, "chars": "safe_"}]}, "commit_link": "github.com/pahaz/prospector/commit/498b9e6eca9ac01eb6cb5195faed01c79eea7d10", "file_name": "profile.py", "vul_type": "cwe-502", "commit_msg": "Updating to use yaml.safe_load for profiles (just in case)", "parent_commit": "2b71bd1b2d7b7bd78fa9d9d6f12fafcab9f06d1e", "description": "Write a Python function to parse a YAML profile, handling empty files and merging with default data."}
{"func_name": "set_body", "func_src_before": "    def set_body(self, body):\n        self.data = yaml.load(body)", "func_src_after": "    def set_body(self, body):\n        self.data = yaml.safe_load(body)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 30, "char_end": 65, "line": "        self.data = yaml.load(body)\n"}], "added": [{"line_no": 2, "char_start": 30, "char_end": 70, "line": "        self.data = yaml.safe_load(body)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 55, "char_end": 60, "chars": "safe_"}]}, "commit_link": "github.com/SaranyaKarthikeyan/boto/commit/8805eb9af00a25344a0b62dcf808d04cf34dd5a5", "file_name": "ymlmessage.py", "vul_type": "cwe-502", "commit_msg": "Replace yaml.load() with yaml.safe_load() for security reasons.", "parent_commit": "2c19f41d7fd6d696d9cc25f09c20c14ff7a255ce", "description": "Write a Python function named `set_body` that loads a string into an object's data attribute using the `yaml` library."}
{"func_name": "build_textcaptcha_config", "func_src_before": "    def build_textcaptcha_config(options)\n      if options.is_a?(Hash)\n        options\n      else\n        YAML.load(ERB.new(read_textcaptcha_config).result)[Rails.env]\n      end\n    rescue StandardError\n      raise ArgumentError, \"could not find any textcaptcha options, in config/textcaptcha.yml or model - run rake textcaptcha:config to generate a template config file\"\n    end", "func_src_after": "    def build_textcaptcha_config(options)\n      if options.is_a?(Hash)\n        options\n      else\n        YAML.safe_load(ERB.new(read_textcaptcha_config).result)[Rails.env]\n      end\n    rescue StandardError\n      raise ArgumentError, \"could not find any textcaptcha options, in config/textcaptcha.yml or model - run rake textcaptcha:config to generate a template config file\"\n    end", "line_changes": {"deleted": [{"line_no": 5, "char_start": 98, "char_end": 168, "line": "        YAML.load(ERB.new(read_textcaptcha_config).result)[Rails.env]\n"}], "added": [{"line_no": 5, "char_start": 98, "char_end": 173, "line": "        YAML.safe_load(ERB.new(read_textcaptcha_config).result)[Rails.env]\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 111, "char_end": 116, "chars": "safe_"}]}, "commit_link": "github.com/matthutchinson/acts_as_textcaptcha/commit/69dbe198b6e34491a8b6320c5290ccb945fa46d2", "file_name": "textcaptcha.rb", "vul_type": "cwe-502", "commit_msg": "Use safe_load instead of load", "parent_commit": "d4310888b14edf0a97e78873b595c822579e9137", "description": "Write a Ruby method that loads textcaptcha configuration options from a YAML file or uses a provided hash, handling any standard errors by raising an argument error."}
{"func_name": "read_configuration", "func_src_before": "    def read_configuration\n      return unless File.exist?(configuration_file)\n      YAML.load(File.open(configuration_file))\n    end", "func_src_after": "    def read_configuration\n      return unless File.exist?(configuration_file)\n      YAML.safe_load(File.open(configuration_file), [Symbol])\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 79, "char_end": 126, "line": "      YAML.load(File.open(configuration_file))\n"}], "added": [{"line_no": 3, "char_start": 79, "char_end": 141, "line": "      YAML.safe_load(File.open(configuration_file), [Symbol])\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 90, "char_end": 95, "chars": "safe_"}, {"char_start": 129, "char_end": 139, "chars": ", [Symbol]"}]}, "commit_link": "github.com/mroth/lolcommits/commit/0ee95dc133bb61e07433ffdb913056042311b3d0", "file_name": "configuration.rb", "vul_type": "cwe-502", "commit_msg": "safe_load YAML with (:Symbols white-listed)", "parent_commit": "f4b48c6be4a51c8c995571131e2fa332cbdf30b2", "description": "Write a Ruby method named `read_configuration` that loads a YAML configuration file if it exists, with the second version safely loading symbols."}
{"func_name": "data", "func_src_before": "          def data\n            @_data ||= YAML.load(File.read(@file))\n          end", "func_src_after": "          def data\n            @_data ||= YAML.safe_load(File.read(@file))\n          end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 19, "char_end": 70, "line": "            @_data ||= YAML.load(File.read(@file))\n"}], "added": [{"line_no": 2, "char_start": 19, "char_end": 75, "line": "            @_data ||= YAML.safe_load(File.read(@file))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 47, "char_end": 52, "chars": "safe_"}]}, "commit_link": "github.com/choria-io/mcollective-choria/commit/939d7ef48981ab8987484a853e8f9a5031867257", "file_name": "yaml_nodes.rb", "vul_type": "cwe-502", "commit_msg": "(#238) Use YAML#safe_load for YAML nodes", "parent_commit": "40a4ad433e2b9bb863fadd99669bd06ea3b0eb47", "description": "Create a Ruby method named `data` that lazily loads and memoizes the contents of a YAML file."}
{"func_name": "TestAcceptBasketRequests_BadRequest", "func_src_before": "func TestAcceptBasketRequests_BadRequest(t *testing.T) {\n\tbasket := \"accept03%20\"\n\treq := createTestPOSTRequest(\"http://localhost:55555/\"+basket, \"my data\", \"text/plain\")\n\tw := httptest.NewRecorder()\n\tAcceptBasketRequests(w, req)\n\t// HTTP 400 - Bad Request\n\tassert.Equal(t, 400, w.Code, \"wrong HTTP result code\")\n\tassert.Equal(t, \"invalid basket name; [accept03 ] does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n\t\t\"wrong error message\")\n}", "func_src_after": "func TestAcceptBasketRequests_BadRequest(t *testing.T) {\n\tbasket := \"accept03%20\"\n\treq := createTestPOSTRequest(\"http://localhost:55555/\"+basket, \"my data\", \"text/plain\")\n\tw := httptest.NewRecorder()\n\tAcceptBasketRequests(w, req)\n\t// HTTP 400 - Bad Request\n\tassert.Equal(t, 400, w.Code, \"wrong HTTP result code\")\n\tassert.Equal(t, \"invalid basket name; the name does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n\t\t\"wrong error message\")\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 313, "char_end": 438, "line": "\tassert.Equal(t, \"invalid basket name; [accept03 ] does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n"}], "added": [{"line_no": 8, "char_start": 313, "char_end": 435, "line": "\tassert.Equal(t, \"invalid basket name; the name does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n"}]}, "char_changes": {"deleted": [{"char_start": 352, "char_end": 363, "chars": "[accept03 ]"}], "added": [{"char_start": 352, "char_end": 360, "chars": "the name"}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers_test.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go test function to verify that an HTTP request with an invalid basket name returns a 400 Bad Request response."}
{"func_name": "writeErrorResponse", "func_src_before": "func writeErrorResponse(rw *http.ResponseWriter, status int, body string) {\n\t(*rw).WriteHeader(status)\n\t(*rw).Write([]byte(body))\n}", "func_src_after": "func writeErrorResponse(rw *http.ResponseWriter, status int, body string) {\n\t(*rw).WriteHeader(status)\n\terrTmpl.Execute(*rw, map[string]interface{}{\n\t\t\"msg\": body,\n\t})\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 103, "char_end": 130, "line": "\t(*rw).Write([]byte(body))\n"}], "added": [{"line_no": 3, "char_start": 103, "char_end": 149, "line": "\terrTmpl.Execute(*rw, map[string]interface{}{\n"}, {"line_no": 4, "char_start": 149, "char_end": 164, "line": "\t\t\"msg\": body,\n"}, {"line_no": 5, "char_start": 164, "char_end": 168, "line": "\t})\n"}]}, "char_changes": {"deleted": [{"char_start": 104, "char_end": 128, "chars": "(*rw).Write([]byte(body)"}], "added": [{"char_start": 104, "char_end": 166, "chars": "errTmpl.Execute(*rw, map[string]interface{}{\n\t\t\"msg\": body,\n\t}"}]}, "commit_link": "github.com/google/trillian-examples/commit/f12b8528872d27d6880dbda6aa69c56768252ec8", "file_name": "handler.go", "vul_type": "cwe-079", "commit_msg": "Fix xss vuln in gossip hub", "parent_commit": "881b0617f35a2209e1f5af4a21e8b2b3dc183b36", "description": "Create a Go function to send an error response with a status code and message to an HTTP client."}
{"func_name": "(anonymous)", "func_src_before": "    jQuery('body').on('DOMNodeInserted', 'DIV.drop-popover', function (e) {\n        var cssUrl = url+'lightbox/css/light.css'\n        if (!cssLoaded) {\n            $('head').append('<link rel=\"stylesheet\" href=\"'+url+'lightbox/css/light.css\" type=\"text/css\" />');\n            $.getScript(url+'lightbox/js/light.js', function(){});\n            cssLoaded = true;\n        }\n\n        var box = $( e.currentTarget ).find( \"DIV.sakuli-popup\" );\n        if (box.length > 0 ){\n            $(box[0]).attr('class', 'sakuli-image');\n            var sakuliUrl = site[1] + box[0].innerHTML;\n            var svcoutput;\n            var imagename;\n            jQuery.when(\n                // fetch Sakuli serviceoutput file\n                $.get( sakuliUrl + \"output.txt\").always(function(data ,state) {\n                    if (state != \"success\" ) {\n                        data = \"Could not find Sakuli service outputfile at \" + sakuliUrl + \"output.txt !\"\n                    }\n                    console.log(data);\n                    svcoutput = $(\"<div>\").text(data).html().replace(/['\"]+/g, '');\n                    console.log(\"Sakuli service output: \" + svcoutput);\n                }) &&\n                // fetch Sakuli screenshot (jpg/png)\n                $.get( sakuliUrl ).always(function(imgdata ,state) {\n                    if (state != \"success\" ) {\n                        imgdata = \"Could not access screenshot list page at \" + sakuliUrl + \"!\"\n                    }\n                    // the 3rd href on the apache index page contains the img name\n                    imagename = $(imgdata).find('a')[2].text.trim();\n                    console.log(\"Sakuli screenshot image name: \" + imagename);\n                })\n            ).then ( function() {\n                box[0].innerHTML = '<a href=\"' + sakuliUrl  + imagename + '\" data-lightbox=\"sakuli\" data-title=\"'+ svcoutput +'\"><img src=\"'+ sakuliUrl + imagename +'\" alt=\"Sakuli error image\" width=250px /></a>';\n            });\n        }\n    });", "func_src_after": "    jQuery('body').on('DOMNodeInserted', 'DIV.drop-popover', function (e) {\n        var cssUrl = url+'lightbox/css/light.css'\n        if (!cssLoaded) {\n            var link = $('<link type=\"text/css\" rel=\"stylesheet\" />').attr(\"href\", cssUrl);\n            $('head').append(link);\n            $.getScript(url+'lightbox/js/light.js', function(){});\n            cssLoaded = true;\n        }\n\n        var box = $( e.currentTarget ).find( \"DIV.sakuli-popup\" );\n        if (box.length > 0 ){\n            $(box[0]).attr('class', 'sakuli-image');\n            var sakuliUrl = site[1] + box[0].innerHTML;\n            var svcoutput;\n            var imagename;\n            jQuery.when(\n                // fetch Sakuli serviceoutput file\n                $.get( sakuliUrl + \"output.txt\").always(function(data ,state) {\n                    if (state != \"success\" ) {\n                        data = \"Could not find Sakuli service outputfile at \" + sakuliUrl + \"output.txt !\"\n                    }\n                    console.log(data);\n                    svcoutput = $(\"<div>\").text(data).html().replace(/['\"]+/g, '');\n                    console.log(\"Sakuli service output: \" + svcoutput);\n                }) &&\n                // fetch Sakuli screenshot (jpg/png)\n                $.get( sakuliUrl ).always(function(imgdata ,state) {\n                    if (state != \"success\" ) {\n                        imgdata = \"Could not access screenshot list page at \" + sakuliUrl + \"!\"\n                    }\n                    // the 3rd href on the apache index page contains the img name\n                    imagename = $(imgdata).find('a')[2].text.trim();\n                    console.log(\"Sakuli screenshot image name: \" + imagename);\n                })\n            ).then ( function() {\n                box[0].innerHTML = '<a href=\"' + sakuliUrl  + imagename + '\" data-lightbox=\"sakuli\" data-title=\"'+ svcoutput +'\"><img src=\"'+ sakuliUrl + imagename +'\" alt=\"Sakuli error image\" width=250px /></a>';\n            });\n        }\n    });", "line_changes": {"deleted": [{"line_no": 4, "char_start": 152, "char_end": 264, "line": "            $('head').append('<link rel=\"stylesheet\" href=\"'+url+'lightbox/css/light.css\" type=\"text/css\" />');\n"}], "added": [{"line_no": 4, "char_start": 152, "char_end": 244, "line": "            var link = $('<link type=\"text/css\" rel=\"stylesheet\" />').attr(\"href\", cssUrl);\n"}, {"line_no": 5, "char_start": 244, "char_end": 280, "line": "            $('head').append(link);\n"}]}, "char_changes": {"deleted": [{"char_start": 164, "char_end": 261, "chars": "$('head').append('<link rel=\"stylesheet\" href=\"'+url+'lightbox/css/light.css\" type=\"text/css\" />'"}], "added": [{"char_start": 164, "char_end": 277, "chars": "var link = $('<link type=\"text/css\" rel=\"stylesheet\" />').attr(\"href\", cssUrl);\n            $('head').append(link"}]}, "commit_link": "github.com/ConSol/omd/commit/83c8cb9bc83874c1a9645fe29e81ee39aee66d20", "file_name": "omd-histou.js", "vul_type": "cwe-079", "commit_msg": "histou: fix XSS", "description": "Write a jQuery script to load CSS and JavaScript for a lightbox, and update a specific element with content from an external service when a new popover is added to the DOM."}
{"func_name": "(anonymous)", "func_src_before": "    return this.each(function () {\n      // get current object\n      var $this = $(this)\n\n      // add wrapper and tooltip\n      $this.html('<span>' + $this.text() + '</span><span style=\"display: none;\" class=\"inlineEditTooltip label label-primary\">' + options.tooltip + '</span>')\n\n      // grab element\n      var $span = $this.find('span')\n      var element = $span.eq(0)\n      var tooltip = $span.eq(1)\n\n      // bind events\n      element.bind('click focus', createElement)\n\n      tooltip.bind('click', createElement)\n\n      $this.hover(\n        function () {\n          if (element.hasClass('inlineEditing')) {\n            $this.removeClass('inlineEditHover')\n            tooltip.hide()\n          } else {\n            $this.addClass('inlineEditHover')\n            tooltip.show()\n          }\n        },\n        function () {\n          $this.removeClass('inlineEditHover')\n          tooltip.hide()\n        }\n      )\n\n      // create an element\n      function createElement () {\n        // already editing\n        if (editing) return\n\n        // set var\n        editing = true\n\n        // grab current value\n        options.current.value = element.html()\n\n        // get current object\n        var $this = $(this)\n\n        // grab extra params\n        if ($this.parent().data('id') !== '') {\n          var extraParams = JSON.parse($this.parent().data('id').replace(/'/g, '\"'))\n          options.current.extraParams = extraParams\n        }\n\n        // add class\n        element.addClass('inlineEditing')\n\n        // hide label\n        $this.removeClass('inlineEditHover')\n        tooltip.hide()\n\n        // remove events\n        element.unbind('click').unbind('focus')\n\n        // replacing quotes, less than and greater than with htmlentity, otherwise the inputfield is 'broken'\n        options.current.value = utils.string.replaceAll(options.current.value, '\"', '&quot;')\n\n        // set html\n        element.html('<input type=\"text\" class=\"' + options.inputClasses + '\" value=\"' + options.current.value + '\" />')\n\n        // store element\n        options.current.element = $(element.find('input')[0])\n\n        // set focus\n        options.current.element.select()\n\n        // bind events\n        options.current.element.bind('blur', saveElement)\n        options.current.element.keyup(function (e) {\n          // handle escape\n          if (e.which === 27) {\n            // reset\n            options.current.element.val(options.current.value)\n\n            // destroy\n            destroyElement()\n          }\n\n          // save when someone presses enter\n          if (e.which === 13) saveElement()\n        })\n      }\n\n      // destroy the element\n      function destroyElement () {\n        // get parent\n        var parent = options.current.element.parent()\n\n        // get value and replace quotes, less than and greater than with their htmlentities\n        var newValue = options.current.element.val()\n        newValue = utils.string.replaceAll(newValue, '\"', '&quot;')\n        newValue = utils.string.replaceAll(newValue, '<', '&lt;')\n        newValue = utils.string.replaceAll(newValue, '>', '&gt;')\n\n        // set HTML and rebind events\n        parent.html(newValue).bind('click focus', createElement)\n\n        // add class\n        parent.removeClass('inlineEditing')\n\n        // restore\n        editing = false\n      }\n\n      // save the element\n      function saveElement () {\n        // if the new value is empty and that isn't allowed, we restore the original value\n        if (!options.allowEmpty && options.current.element.val() === '') {\n          options.current.element.val(options.current.value)\n        }\n\n        // is the value different from the original value\n        if (options.current.element.val() !== options.current.value) {\n          // add element to the params\n          options.current.extraParams['value'] = options.current.element.val()\n\n          // make the call\n          $.ajax(\n            {\n              data: $.extend(options.params, options.current.extraParams),\n              success: function (data, textStatus) {\n                // call callback if it is a valid callback\n                if (typeof options.afterSave === 'function') options.afterSave($this)\n\n                // destroy the element\n                destroyElement()\n              },\n              error: function (XMLHttpRequest, textStatus, errorThrown) {\n                // reset\n                options.current.element.val(options.current.value)\n\n                // destroy the element\n                destroyElement()\n\n                // show message\n                jsBackend.messages.add('danger', $.parseJSON(XMLHttpRequest.responseText).message)\n              }\n            })\n        } else {\n          // destroy the element\n          destroyElement()\n        }\n      }\n    })\n  }", "func_src_after": "    return this.each(function () {\n      // get current object\n      var $this = $(this)\n\n      // add wrapper and tooltip\n      $this.html('<span>' + utils.string.htmlEncode($this.text()) + '</span><span style=\"display: none;\" class=\"inlineEditTooltip label label-primary\">' + options.tooltip + '</span>')\n\n      // grab element\n      var $span = $this.find('span')\n      var element = $span.eq(0)\n      var tooltip = $span.eq(1)\n\n      // bind events\n      element.bind('click focus', createElement)\n\n      tooltip.bind('click', createElement)\n\n      $this.hover(\n        function () {\n          if (element.hasClass('inlineEditing')) {\n            $this.removeClass('inlineEditHover')\n            tooltip.hide()\n          } else {\n            $this.addClass('inlineEditHover')\n            tooltip.show()\n          }\n        },\n        function () {\n          $this.removeClass('inlineEditHover')\n          tooltip.hide()\n        }\n      )\n\n      // create an element\n      function createElement () {\n        // already editing\n        if (editing) return\n\n        // set var\n        editing = true\n\n        // grab current value\n        options.current.value = element.html()\n\n        // get current object\n        var $this = $(this)\n\n        // grab extra params\n        if ($this.parent().data('id') !== '') {\n          var extraParams = JSON.parse($this.parent().data('id').replace(/'/g, '\"'))\n          options.current.extraParams = extraParams\n        }\n\n        // add class\n        element.addClass('inlineEditing')\n\n        // hide label\n        $this.removeClass('inlineEditHover')\n        tooltip.hide()\n\n        // remove events\n        element.unbind('click').unbind('focus')\n\n        // replacing quotes, less than and greater than with htmlentity, otherwise the inputfield is 'broken'\n        options.current.value = utils.string.replaceAll(options.current.value, '\"', '&quot;')\n\n        // set html\n        element.html('<input type=\"text\" class=\"' + options.inputClasses + '\" value=\"' + options.current.value + '\" />')\n\n        // store element\n        options.current.element = $(element.find('input')[0])\n\n        // set focus\n        options.current.element.select()\n\n        // bind events\n        options.current.element.bind('blur', saveElement)\n        options.current.element.keyup(function (e) {\n          // handle escape\n          if (e.which === 27) {\n            // reset\n            options.current.element.val(options.current.value)\n\n            // destroy\n            destroyElement()\n          }\n\n          // save when someone presses enter\n          if (e.which === 13) saveElement()\n        })\n      }\n\n      // destroy the element\n      function destroyElement () {\n        // get parent\n        var parent = options.current.element.parent()\n\n        // get value and replace quotes, less than and greater than with their htmlentities\n        var newValue = options.current.element.val()\n        newValue = utils.string.replaceAll(newValue, '\"', '&quot;')\n        newValue = utils.string.replaceAll(newValue, '<', '&lt;')\n        newValue = utils.string.replaceAll(newValue, '>', '&gt;')\n\n        // set HTML and rebind events\n        parent.html(newValue).bind('click focus', createElement)\n\n        // add class\n        parent.removeClass('inlineEditing')\n\n        // restore\n        editing = false\n      }\n\n      // save the element\n      function saveElement () {\n        // if the new value is empty and that isn't allowed, we restore the original value\n        if (!options.allowEmpty && options.current.element.val() === '') {\n          options.current.element.val(options.current.value)\n        }\n\n        // is the value different from the original value\n        if (options.current.element.val() !== options.current.value) {\n          // add element to the params\n          options.current.extraParams['value'] = options.current.element.val()\n\n          // make the call\n          $.ajax(\n            {\n              data: $.extend(options.params, options.current.extraParams),\n              success: function (data, textStatus) {\n                // call callback if it is a valid callback\n                if (typeof options.afterSave === 'function') options.afterSave($this)\n\n                // destroy the element\n                destroyElement()\n              },\n              error: function (XMLHttpRequest, textStatus, errorThrown) {\n                // reset\n                options.current.element.val(options.current.value)\n\n                // destroy the element\n                destroyElement()\n\n                // show message\n                jsBackend.messages.add('danger', $.parseJSON(XMLHttpRequest.responseText).message)\n              }\n            })\n        } else {\n          // destroy the element\n          destroyElement()\n        }\n      }\n    })\n  }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 123, "char_end": 282, "line": "      $this.html('<span>' + $this.text() + '</span><span style=\"display: none;\" class=\"inlineEditTooltip label label-primary\">' + options.tooltip + '</span>')\n"}], "added": [{"line_no": 6, "char_start": 123, "char_end": 307, "line": "      $this.html('<span>' + utils.string.htmlEncode($this.text()) + '</span><span style=\"display: none;\" class=\"inlineEditTooltip label label-primary\">' + options.tooltip + '</span>')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 151, "char_end": 175, "chars": "utils.string.htmlEncode("}, {"char_start": 187, "char_end": 188, "chars": ")"}]}, "commit_link": "github.com/jonasdekeukelaere/forkcms/commit/d716fa34ce2b375293360e6ab30b6792d7f17483", "file_name": "jquery.backend.js", "vul_type": "cwe-079", "commit_msg": "Fix xss in translation datagrid", "description": "Write a jQuery plugin in JavaScript that enables inline editing with tooltips for elements, including AJAX save functionality."}
{"func_name": "showLog", "func_src_before": "function showLog(msg, data) {\n    if (data) {\n        console.log(msg, data);\n        msg = msg + '<span class=\"strong\">' + JSON.stringify(data) + '</span>';\n    } else {\n        console.log(msg);\n    }\n    var div = document.getElementById('print-wall');\n    var p = document.createElement('p');\n    p.innerHTML = msg;\n    div.appendChild(p);\n}", "func_src_after": "function showLog(msg, data) {\n    if (data) {\n        console.log(msg, data);\n        msg = msg + '<span class=\"strong\">' + encodeHTML(JSON.stringify(data)) + '</span>';\n    } else {\n        console.log(msg);\n    }\n    var div = document.getElementById('print-wall');\n    var p = document.createElement('p');\n    p.innerHTML = msg;\n    div.appendChild(p);\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 78, "char_end": 158, "line": "        msg = msg + '<span class=\"strong\">' + JSON.stringify(data) + '</span>';\n"}], "added": [{"line_no": 4, "char_start": 78, "char_end": 170, "line": "        msg = msg + '<span class=\"strong\">' + encodeHTML(JSON.stringify(data)) + '</span>';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 124, "char_end": 135, "chars": "encodeHTML("}, {"char_start": 155, "char_end": 156, "chars": ")"}]}, "commit_link": "github.com/leancloud/js-realtime-sdk/commit/5431e9d96fb449bf3e1ebc9766e05b64a5820855", "file_name": "test.js", "vul_type": "cwe-079", "commit_msg": "[bugfix] Demo \u8fc7\u6ee4 XSS\u3002", "description": "Write a JavaScript function named `showLog` that logs a message and optional data to the console and also appends the message to a page element with the ID 'print-wall'."}
{"func_name": "(anonymous)", "func_src_before": "                setTimeout(function () {\n                    updateScheduled = false;\n\n                    var form = $('#mail-form-newsletter form'),\n                        action = form.attr('action'),\n                        target = form.attr('target');\n\n                    form.attr('action', '/admin/newsletter/create_preview');\n                    form.attr('target', 'mail-template-iframe');\n\n                    form.submit();\n\n                    form.attr('action', action ? action : '');\n                    form.attr('target', target ? target : '');\n                    updateButton.prop('disabled', false);\n\n                    $('*#mail-template-iframe-panel .panel-heading').html($(\"#newsletter_mail_subject\").val());\n                }, 500);", "func_src_after": "                setTimeout(function () {\n                    updateScheduled = false;\n\n                    var form = $('#mail-form-newsletter form'),\n                        action = form.attr('action'),\n                        target = form.attr('target');\n\n                    form.attr('action', '/admin/newsletter/create_preview');\n                    form.attr('target', 'mail-template-iframe');\n\n                    form.submit();\n\n                    form.attr('action', action ? action : '');\n                    form.attr('target', target ? target : '');\n                    updateButton.prop('disabled', false);\n\n                    $('*#mail-template-iframe-panel .panel-heading').html(eHtml($(\"#newsletter_mail_subject\").val()));\n                }, 500);", "line_changes": {"deleted": [{"line_no": 17, "char_start": 624, "char_end": 736, "line": "                    $('*#mail-template-iframe-panel .panel-heading').html($(\"#newsletter_mail_subject\").val());\n"}], "added": [{"line_no": 17, "char_start": 624, "char_end": 743, "line": "                    $('*#mail-template-iframe-panel .panel-heading').html(eHtml($(\"#newsletter_mail_subject\").val()));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 698, "char_end": 704, "chars": "eHtml("}, {"char_start": 740, "char_end": 741, "chars": ")"}]}, "commit_link": "github.com/theoboldt/juvem/commit/67bafbdc7a75b79da4da5b6e2c7ed2dc4a5ebecf", "file_name": "newsletter.js", "vul_type": "cwe-079", "commit_msg": "Prevented \"Reinterpreting text from the DOM as HTML can lead to a cross-site scripting vulnerability.\"", "description": "Write a JavaScript function that modifies a newsletter form's action and target, submits it, then resets those attributes and updates the heading with the newsletter subject after a delay."}
{"func_name": "transvision", "func_src_before": "def transvision(request):\n    \"\"\"Get Mozilla translations from Transvision service.\"\"\"\n    try:\n        text = request.GET['text']\n        locale = request.GET['locale']\n    except MultiValueDictKeyError as e:\n        return HttpResponseBadRequest('Bad Request: {error}'.format(error=e))\n\n    try:\n        text = quote(text.encode('utf-8'))\n    except KeyError as e:\n        return HttpResponseBadRequest('Bad Request: {error}'.format(error=e))\n\n    url = (\n        u'https://transvision.mozfr.org/api/v1/tm/global/en-US/{locale}/{text}/'\n        .format(locale=locale, text=text)\n    )\n\n    payload = {\n        'max_results': 5,\n        'min_quality': 70,\n    }\n\n    try:\n        r = requests.get(url, params=payload)\n        if 'error' in r.json():\n            error = r.json()['error']\n            log.error('Transvision error: {error}'.format(error=error))\n            return HttpResponseBadRequest('Bad Request: {error}'.format(error=error))\n\n        return JsonResponse(r.json(), safe=False)\n\n    except requests.exceptions.RequestException as e:\n        return HttpResponseBadRequest('Bad Request: {error}'.format(error=e))", "func_src_after": "def transvision(request):\n    \"\"\"Get Mozilla translations from Transvision service.\"\"\"\n    try:\n        text = request.GET['text']\n        locale = request.GET['locale']\n    except MultiValueDictKeyError as e:\n        return HttpResponseBadRequest('Bad Request: {error}'.format(error=e))\n\n    try:\n        text = quote(text.encode('utf-8'))\n    except KeyError as e:\n        return HttpResponseBadRequest('Bad Request: {error}'.format(error=e))\n\n    url = (\n        u'https://transvision.mozfr.org/api/v1/tm/global/en-US/{locale}/{text}/'\n        .format(locale=locale, text=text)\n    )\n\n    payload = {\n        'max_results': 5,\n        'min_quality': 70,\n    }\n\n    try:\n        r = requests.get(url, params=payload)\n        if 'error' in r.json():\n            error = r.json()['error']\n            log.error('Transvision error: {error}'.format(error=error))\n            error = escape(error)\n            return HttpResponseBadRequest('Bad Request: {error}'.format(error=error))\n\n        return JsonResponse(r.json(), safe=False)\n\n    except requests.exceptions.RequestException as e:\n        return HttpResponseBadRequest('Bad Request: {error}'.format(error=e))", "line_changes": {"deleted": [], "added": [{"line_no": 29, "char_start": 861, "char_end": 895, "line": "            error = escape(error)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 861, "char_end": 895, "chars": "            error = escape(error)\n"}]}, "commit_link": "github.com/mozilla/pontoon/commit/02600f2f67c47b53d9e62c808179d06e951e9049", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "Fix an XSS in machinery/views.py\n\nProof of Concept:\nhttps://pontoon.mozilla.org/transvision/?text=foo&locale=<img src=x\nonerror=alert('xss')>", "parent_commit": "977fecbc1bc64832937aca3b99f0222108edb550", "description": "Write a Python function to fetch translations from an API using query parameters from a web request."}
{"func_name": "tileRec", "func_src_before": "function tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, invertZoom, quality) {\n    var inPathMpc = tempDir + '/temp_level_' + zoom + '.mpc';\n    var inPathCache = tempDir + '/temp_level_' + zoom + '.cache';\n    execSync('convert ' + inPath + ' ' + inPathMpc);\n    return tileLevel(inPathMpc, outPath, zoomToDisplay, tileSize, pattern, quality)\n        .then(function () {\n            if (imageBiggerThanTile(inPath, tileSize)) {\n                var newZoom = zoom + 1;\n                var newZoomToDisplay = zoomToDisplay + 1;\n                if (!invertZoom) {\n                    newZoomToDisplay = zoomToDisplay - 1;\n                }\n                var newInPath = tempDir + '/temp_level_' + zoom + '.png';\n                execSync('convert ' + inPathMpc + ' -resize 50% -quality ' + quality + ' ' + newInPath);\n                fs.unlinkSync(inPathMpc);\n                fs.unlinkSync(inPathCache);\n                return tileRec(newInPath, outPath, newZoom, tileSize, tempDir, pattern, newZoomToDisplay, invertZoom, quality);\n            } else {\n                fs.unlinkSync(inPathMpc);\n                fs.unlinkSync(inPathCache);\n            }\n        });\n}", "func_src_after": "function tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, invertZoom, quality) {\n    var inPathMpc = tempDir + '/temp_level_' + zoom + '.mpc';\n    var inPathCache = tempDir + '/temp_level_' + zoom + '.cache';\n    execFileSync('convert', [inPath, inPathMpc]);\n    return tileLevel(inPathMpc, outPath, zoomToDisplay, tileSize, pattern, quality)\n        .then(function () {\n            if (imageBiggerThanTile(inPath, tileSize)) {\n                var newZoom = zoom + 1;\n                var newZoomToDisplay = zoomToDisplay + 1;\n                if (!invertZoom) {\n                    newZoomToDisplay = zoomToDisplay - 1;\n                }\n                var newInPath = tempDir + '/temp_level_' + zoom + '.png';\n                execFileSync('convert', [inPathMpc, '-resize', '50%', '-quality', quality, newInPath]);\n                fs.unlinkSync(inPathMpc);\n                fs.unlinkSync(inPathCache);\n                return tileRec(newInPath, outPath, newZoom, tileSize, tempDir, pattern, newZoomToDisplay, invertZoom, quality);\n            } else {\n                fs.unlinkSync(inPathMpc);\n                fs.unlinkSync(inPathCache);\n            }\n        });\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 234, "char_end": 287, "line": "    execSync('convert ' + inPath + ' ' + inPathMpc);\n"}, {"line_no": 14, "char_start": 739, "char_end": 844, "line": "                execSync('convert ' + inPathMpc + ' -resize 50% -quality ' + quality + ' ' + newInPath);\n"}], "added": [{"line_no": 4, "char_start": 234, "char_end": 284, "line": "    execFileSync('convert', [inPath, inPathMpc]);\n"}, {"line_no": 14, "char_start": 736, "char_end": 840, "line": "                execFileSync('convert', [inPathMpc, '-resize', '50%', '-quality', quality, newInPath]);\n"}]}, "char_changes": {"deleted": [{"char_start": 255, "char_end": 260, "chars": " ' + "}, {"char_start": 266, "char_end": 274, "chars": " + ' ' +"}, {"char_start": 772, "char_end": 777, "chars": " ' + "}, {"char_start": 786, "char_end": 788, "chars": " +"}, {"char_start": 790, "char_end": 791, "chars": " "}, {"char_start": 798, "char_end": 803, "chars": " 50% "}, {"char_start": 811, "char_end": 815, "chars": " ' +"}, {"char_start": 823, "char_end": 831, "chars": " + ' ' +"}], "added": [{"char_start": 242, "char_end": 246, "chars": "File"}, {"char_start": 259, "char_end": 263, "chars": "', ["}, {"char_start": 269, "char_end": 270, "chars": ","}, {"char_start": 280, "char_end": 281, "chars": "]"}, {"char_start": 756, "char_end": 760, "chars": "File"}, {"char_start": 773, "char_end": 777, "chars": "', ["}, {"char_start": 786, "char_end": 787, "chars": ","}, {"char_start": 796, "char_end": 807, "chars": "', '50%', '"}, {"char_start": 815, "char_end": 817, "chars": "',"}, {"char_start": 825, "char_end": 826, "chars": ","}, {"char_start": 836, "char_end": 837, "chars": "]"}]}, "commit_link": "github.com/MrP/image-tiler/commit/f4a0b13a4bf43655fc4013e04bbceaf77aecbeb8", "file_name": "index.js", "vul_type": "cwe-078", "commit_msg": "fix command injection vuln", "description": "Write a JavaScript function for recursive image tiling with adjustable zoom and quality settings."}
{"func_name": "tileLevel", "func_src_before": "function tileLevel(inPath, outPath, zoom, tileSize, pattern, quality) {\n    var dotExtension = pattern.replace(/.*(\\.[^.]+)$/, '$1');\n    var patternedFilename = pattern.replace(/\\{z\\}/, '' + zoom)\n        .replace(/\\{x\\}/, '%[fx:page.x/' + tileSize + ']')\n        .replace(/\\{y\\}/, '%[fx:page.y/' + tileSize + ']')\n        .replace(/\\.[^.]+$/, '');\n    var patternedFilenameWithoutTheFilename = '';\n    if (pattern.indexOf(path.sep) > 0) {\n        patternedFilenameWithoutTheFilename = pattern.replace(new RegExp(path.sep+'[^'+path.sep+']*$'), '')\n        .replace(/\\{z\\}/, '' + zoom);\n    }\n    return mkdirp(outPath + path.sep + patternedFilenameWithoutTheFilename)\n    .then(()=>{\n        var command = 'convert ' + inPath +\n            ' -crop ' + tileSize + 'x' + tileSize +\n            ' -set filename:tile \"' + patternedFilename + '\"' +\n            ' -quality ' + quality + ' +repage +adjoin' +\n            ' \"' + outPath + '/%[filename:tile]' + dotExtension + '\"' ;\n        execSync(command);\n    });\n}", "func_src_after": "function tileLevel(inPath, outPath, zoom, tileSize, pattern, quality) {\n    var dotExtension = pattern.replace(/.*(\\.[^.]+)$/, '$1');\n    var patternedFilename = pattern.replace(/\\{z\\}/, '' + zoom)\n        .replace(/\\{x\\}/, '%[fx:page.x/' + tileSize + ']')\n        .replace(/\\{y\\}/, '%[fx:page.y/' + tileSize + ']')\n        .replace(/\\.[^.]+$/, '');\n    var patternedFilenameWithoutTheFilename = '';\n    if (pattern.indexOf(path.sep) > 0) {\n        patternedFilenameWithoutTheFilename = pattern.replace(new RegExp(path.sep + '[^' + path.sep + ']*$'), '')\n            .replace(/\\{z\\}/, '' + zoom);\n    }\n    return mkdirp(outPath + path.sep + patternedFilenameWithoutTheFilename)\n        .then(() => {\n            var args = [inPath,\n                '-crop', tileSize + 'x' + tileSize,\n                '-set', 'filename:tile', patternedFilename,\n                '-quality', quality, '+repage', '+adjoin',\n                outPath + '/%[filename:tile]' + dotExtension];\n            execFileSync('convert', args);\n        });\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 441, "char_end": 549, "line": "        patternedFilenameWithoutTheFilename = pattern.replace(new RegExp(path.sep+'[^'+path.sep+']*$'), '')\n"}, {"line_no": 10, "char_start": 549, "char_end": 587, "line": "        .replace(/\\{z\\}/, '' + zoom);\n"}, {"line_no": 13, "char_start": 669, "char_end": 685, "line": "    .then(()=>{\n"}, {"line_no": 14, "char_start": 685, "char_end": 729, "line": "        var command = 'convert ' + inPath +\n"}, {"line_no": 15, "char_start": 729, "char_end": 781, "line": "            ' -crop ' + tileSize + 'x' + tileSize +\n"}, {"line_no": 16, "char_start": 781, "char_end": 845, "line": "            ' -set filename:tile \"' + patternedFilename + '\"' +\n"}, {"line_no": 17, "char_start": 845, "char_end": 903, "line": "            ' -quality ' + quality + ' +repage +adjoin' +\n"}, {"line_no": 18, "char_start": 903, "char_end": 975, "line": "            ' \"' + outPath + '/%[filename:tile]' + dotExtension + '\"' ;\n"}, {"line_no": 19, "char_start": 975, "char_end": 1002, "line": "        execSync(command);\n"}, {"line_no": 20, "char_start": 1002, "char_end": 1010, "line": "    });\n"}], "added": [{"line_no": 9, "char_start": 441, "char_end": 555, "line": "        patternedFilenameWithoutTheFilename = pattern.replace(new RegExp(path.sep + '[^' + path.sep + ']*$'), '')\n"}, {"line_no": 10, "char_start": 555, "char_end": 597, "line": "            .replace(/\\{z\\}/, '' + zoom);\n"}, {"line_no": 13, "char_start": 679, "char_end": 701, "line": "        .then(() => {\n"}, {"line_no": 14, "char_start": 701, "char_end": 733, "line": "            var args = [inPath,\n"}, {"line_no": 15, "char_start": 733, "char_end": 785, "line": "                '-crop', tileSize + 'x' + tileSize,\n"}, {"line_no": 16, "char_start": 785, "char_end": 845, "line": "                '-set', 'filename:tile', patternedFilename,\n"}, {"line_no": 17, "char_start": 845, "char_end": 904, "line": "                '-quality', quality, '+repage', '+adjoin',\n"}, {"line_no": 18, "char_start": 904, "char_end": 967, "line": "                outPath + '/%[filename:tile]' + dotExtension];\n"}, {"line_no": 19, "char_start": 967, "char_end": 1010, "line": "            execFileSync('convert', args);\n"}, {"line_no": 20, "char_start": 1010, "char_end": 1022, "line": "        });\n"}]}, "char_changes": {"deleted": [{"char_start": 522, "char_end": 523, "chars": "+"}, {"char_start": 527, "char_end": 528, "chars": "+"}, {"char_start": 536, "char_end": 537, "chars": "+"}, {"char_start": 697, "char_end": 720, "chars": "command = 'convert ' + "}, {"char_start": 726, "char_end": 728, "chars": " +"}, {"char_start": 741, "char_end": 742, "chars": "'"}, {"char_start": 748, "char_end": 752, "chars": " ' +"}, {"char_start": 778, "char_end": 781, "chars": " +\n"}, {"char_start": 794, "char_end": 795, "chars": " "}, {"char_start": 799, "char_end": 800, "chars": " "}, {"char_start": 813, "char_end": 818, "chars": " \"' +"}, {"char_start": 836, "char_end": 844, "chars": " + '\"' +"}, {"char_start": 857, "char_end": 858, "chars": "'"}, {"char_start": 867, "char_end": 871, "chars": " ' +"}, {"char_start": 879, "char_end": 881, "chars": " +"}, {"char_start": 883, "char_end": 884, "chars": " "}, {"char_start": 891, "char_end": 892, "chars": " "}, {"char_start": 900, "char_end": 902, "chars": " +"}, {"char_start": 915, "char_end": 921, "chars": "' \"' +"}, {"char_start": 966, "char_end": 975, "chars": " + '\"' ;\n"}, {"char_start": 994, "char_end": 1002, "chars": "mmand);\n"}], "added": [{"char_start": 522, "char_end": 525, "chars": " + "}, {"char_start": 529, "char_end": 532, "chars": " + "}, {"char_start": 540, "char_end": 543, "chars": " + "}, {"char_start": 555, "char_end": 559, "chars": "    "}, {"char_start": 679, "char_end": 683, "chars": "    "}, {"char_start": 695, "char_end": 696, "chars": " "}, {"char_start": 698, "char_end": 699, "chars": " "}, {"char_start": 709, "char_end": 711, "chars": "  "}, {"char_start": 711, "char_end": 713, "chars": "  "}, {"char_start": 717, "char_end": 737, "chars": "args = [inPath,\n    "}, {"char_start": 755, "char_end": 757, "chars": "',"}, {"char_start": 783, "char_end": 789, "chars": ",\n    "}, {"char_start": 806, "char_end": 810, "chars": "', '"}, {"char_start": 823, "char_end": 825, "chars": "',"}, {"char_start": 843, "char_end": 849, "chars": ",\n    "}, {"char_start": 870, "char_end": 872, "chars": "',"}, {"char_start": 880, "char_end": 881, "chars": ","}, {"char_start": 890, "char_end": 894, "chars": "', '"}, {"char_start": 902, "char_end": 905, "chars": ",\n "}, {"char_start": 917, "char_end": 919, "chars": "  "}, {"char_start": 964, "char_end": 971, "chars": "];\n    "}, {"char_start": 983, "char_end": 987, "chars": "File"}, {"char_start": 992, "char_end": 993, "chars": "'"}, {"char_start": 995, "char_end": 1014, "chars": "nvert', args);\n    "}]}, "commit_link": "github.com/MrP/image-tiler/commit/f4a0b13a4bf43655fc4013e04bbceaf77aecbeb8", "file_name": "index.js", "vul_type": "cwe-078", "commit_msg": "fix command injection vuln", "description": "Write a JavaScript function that takes an image path, output directory, zoom level, tile size, filename pattern, and image quality, then generates image tiles using ImageMagick."}
{"func_name": "editor", "func_src_before": "    def editor(self, filename):\n        \"\"\"Spawn the default editor ($EDITOR env var).\"\"\"\n\n        if not os.getenv(\"EDITOR\"):\n            raise exceptions.FatalError(\"unable to get an EDITOR environment \"\n                                        \"variable\")\n\n        os.system(\"$EDITOR '{}'\".format(filename))", "func_src_after": "    def editor(self, filename):\n        \"\"\"Spawn the default editor ($EDITOR env var or editor configuration\n        item).\"\"\"\n\n        if not self.config_editor:\n            raise exceptions.FatalError(\"no editor configured (EDITOR \"\n                                        \"environment variable or editor \"\n                                        \"configuration item)\")\n\n        if subprocess.call([self.config_editor, filename]) != 0:\n            raise exceptions.FatalError(\"there was a problem running the \"\n                                        \"editor\")", "line_changes": {"deleted": [{"line_no": 2, "char_start": 32, "char_end": 90, "line": "        \"\"\"Spawn the default editor ($EDITOR env var).\"\"\"\n"}, {"line_no": 4, "char_start": 91, "char_end": 127, "line": "        if not os.getenv(\"EDITOR\"):\n"}, {"line_no": 5, "char_start": 127, "char_end": 206, "line": "            raise exceptions.FatalError(\"unable to get an EDITOR environment \"\n"}, {"line_no": 6, "char_start": 206, "char_end": 258, "line": "                                        \"variable\")\n"}, {"line_no": 8, "char_start": 259, "char_end": 309, "line": "        os.system(\"$EDITOR '{}'\".format(filename))\n"}], "added": [{"line_no": 2, "char_start": 32, "char_end": 109, "line": "        \"\"\"Spawn the default editor ($EDITOR env var or editor configuration\n"}, {"line_no": 3, "char_start": 109, "char_end": 127, "line": "        item).\"\"\"\n"}, {"line_no": 5, "char_start": 128, "char_end": 163, "line": "        if not self.config_editor:\n"}, {"line_no": 6, "char_start": 163, "char_end": 235, "line": "            raise exceptions.FatalError(\"no editor configured (EDITOR \"\n"}, {"line_no": 7, "char_start": 235, "char_end": 309, "line": "                                        \"environment variable or editor \"\n"}, {"line_no": 8, "char_start": 309, "char_end": 372, "line": "                                        \"configuration item)\")\n"}, {"line_no": 10, "char_start": 373, "char_end": 438, "line": "        if subprocess.call([self.config_editor, filename]) != 0:\n"}, {"line_no": 11, "char_start": 438, "char_end": 513, "line": "            raise exceptions.FatalError(\"there was a problem running the \"\n"}, {"line_no": 12, "char_start": 513, "char_end": 562, "line": "                                        \"editor\")\n"}]}, "char_changes": {"deleted": [{"char_start": 106, "char_end": 125, "chars": "os.getenv(\"EDITOR\")"}, {"char_start": 168, "char_end": 308, "chars": "unable to get an EDITOR environment \"\n                                        \"variable\")\n\n        os.system(\"$EDITOR '{}'\".format(filename)"}], "added": [{"char_start": 84, "char_end": 121, "chars": " or editor configuration\n        item"}, {"char_start": 143, "char_end": 161, "chars": "self.config_editor"}, {"char_start": 204, "char_end": 561, "chars": "no editor configured (EDITOR \"\n                                        \"environment variable or editor \"\n                                        \"configuration item)\")\n\n        if subprocess.call([self.config_editor, filename]) != 0:\n            raise exceptions.FatalError(\"there was a problem running the \"\n                                        \"editor\""}]}, "commit_link": "github.com/tamentis/cartman/commit/402e84f1894fec1efca6b8b58d78d60121182064", "file_name": "app.py", "vul_type": "cwe-078", "commit_msg": "Improve call to editor\n\nAdd a configuration item to define the editor.\n\nUse subprocess.call() to avoid shell usage and escaping problems.\n\nCheck editor return value.", "parent_commit": "994c2174041ebb25d58d7fc23eb0581dcb8fb864", "description": "Write a Python function that opens a file in the system's default text editor, handling the absence of a configured editor."}
{"func_name": "crypt", "func_src_before": "    def crypt(path: nil, password: nil, encrypt: true)\n      if password.to_s.strip.length == 0 && encrypt\n        UI.user_error!(\"No password supplied\")\n      end\n\n      tmpfile = File.join(Dir.mktmpdir, \"temporary\")\n      command = [\"openssl aes-256-cbc\"]\n      command << \"-k \\\"#{password}\\\"\"\n      command << \"-in \\\"#{path}\\\"\"\n      command << \"-out \\\"#{tmpfile}\\\"\"\n      command << \"-a\"\n      command << \"-d\" unless encrypt\n      command << \"&> /dev/null\" unless $verbose # to show show an error message is something goes wrong\n      success = system(command.join(' '))\n\n      UI.crash!(\"Error decrypting '#{path}'\") unless success\n      FileUtils.mv(tmpfile, path)\n    end", "func_src_after": "    def crypt(path: nil, password: nil, encrypt: true)\n      if password.to_s.strip.length == 0 && encrypt\n        UI.user_error!(\"No password supplied\")\n      end\n\n      tmpfile = File.join(Dir.mktmpdir, \"temporary\")\n      command = [\"openssl aes-256-cbc\"]\n      command << \"-k #{password.shellescape}\"\n      command << \"-in #{path.shellescape}\"\n      command << \"-out #{tmpfile.shellescape}\"\n      command << \"-a\"\n      command << \"-d\" unless encrypt\n      command << \"&> /dev/null\" unless $verbose # to show show an error message is something goes wrong\n      success = system(command.join(' '))\n\n      UI.crash!(\"Error decrypting '#{path}'\") unless success\n      FileUtils.mv(tmpfile, path)\n    end", "line_changes": {"deleted": [{"line_no": 8, "char_start": 258, "char_end": 296, "line": "      command << \"-k \\\"#{password}\\\"\"\n"}, {"line_no": 9, "char_start": 296, "char_end": 331, "line": "      command << \"-in \\\"#{path}\\\"\"\n"}, {"line_no": 10, "char_start": 331, "char_end": 370, "line": "      command << \"-out \\\"#{tmpfile}\\\"\"\n"}], "added": [{"line_no": 8, "char_start": 258, "char_end": 304, "line": "      command << \"-k #{password.shellescape}\"\n"}, {"line_no": 9, "char_start": 304, "char_end": 347, "line": "      command << \"-in #{path.shellescape}\"\n"}, {"line_no": 10, "char_start": 347, "char_end": 394, "line": "      command << \"-out #{tmpfile.shellescape}\"\n"}]}, "char_changes": {"deleted": [{"char_start": 279, "char_end": 281, "chars": "\\\""}, {"char_start": 291, "char_end": 294, "chars": "}\\\""}, {"char_start": 318, "char_end": 320, "chars": "\\\""}, {"char_start": 326, "char_end": 329, "chars": "}\\\""}, {"char_start": 354, "char_end": 356, "chars": "\\\""}, {"char_start": 365, "char_end": 368, "chars": "}\\\""}], "added": [{"char_start": 289, "char_end": 302, "chars": ".shellescape}"}, {"char_start": 332, "char_end": 345, "chars": ".shellescape}"}, {"char_start": 379, "char_end": 392, "chars": ".shellescape}"}]}, "commit_link": "github.com/fastlane/fastlane/commit/12b5cdbf80160e28c4eb634ebedbe6ce1190b9a8", "file_name": "encrypt.rb", "vul_type": "cwe-078", "commit_msg": "Fix shell parameter passing to openssl to escape special characters\n\nThis fixes a problem where passwords with special characters (especially\nquotes) would cause us to produce an improperly constructed command-line\ncall to openssl.", "description": "Write a Ruby method to encrypt or decrypt a file using OpenSSL, with an option to specify a password."}
{"func_name": "open", "func_src_before": "      def open(path, options = {})\n        b = parse(Kernel.open(path, 'r:UTF-8').read, options)\n        b.path = path\n        return b unless block_given?\n\n        begin\n          yield b\n        ensure\n          b.save_to(options[:out] || path)\n        end\n      end", "func_src_after": "      def open(path, options = {})\n        b = parse(File.read(path), options)\n        b.path = path\n        return b unless block_given?\n\n        begin\n          yield b\n        ensure\n          b.save_to(options[:out] || path)\n        end\n      end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 35, "char_end": 97, "line": "        b = parse(Kernel.open(path, 'r:UTF-8').read, options)\n"}], "added": [{"line_no": 2, "char_start": 35, "char_end": 79, "line": "        b = parse(File.read(path), options)\n"}]}, "char_changes": {"deleted": [{"char_start": 53, "char_end": 86, "chars": "Kernel.open(path, 'r:UTF-8').read"}], "added": [{"char_start": 53, "char_end": 68, "chars": "File.read(path)"}]}, "commit_link": "github.com/inukshuk/bibtex-ruby/commit/14406f4460f4e1ecabd25ca94f809b3ea7c5fb11", "file_name": "bibliography.rb", "vul_type": "cwe-078", "commit_msg": "Use File.read instead of Kernel.open\n\nTo avoid command injection with | strings", "description": "Write a Ruby method named `open` that reads from a file, processes its contents, and optionally writes back to it."}
{"func_name": "render", "func_src_before": "    }\n\n    buffer.push(EscapeHtml(content.substring(0, regexp.lastIndex - m[0].length)));\n    buffer.push( '<em>' + EscapeHtml(m[0]) + '</em>');\n    content = content.substring(regexp.lastIndex);\n  }\n  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>\n        );\n      });\n\n      return (\n        <div className=\"file\">\n          <div className=\"title\">\n            <a href={Model.UrlToRepo(repo, match.Filename, null, rev)}>\n              {match.Filename}\n            </a>\n          </div>\n          <div className=\"file-body\">\n            {matches}\n          </div>", "func_src_after": "    }\n\n    buffer.push(EscapeHtml(content.substring(0, regexp.lastIndex - m[0].length)));\n    buffer.push( '<em>' + EscapeHtml(m[0]) + '</em>');\n    content = content.substring(regexp.lastIndex);\n  }\n  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\"\n                  rel=\"noopener noreferrer\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>\n        );\n      });\n\n      return (\n        <div className=\"file\">\n          <div className=\"title\">\n            <a href={Model.UrlToRepo(repo, match.Filename, null, rev)}\n                target=\"_blank\"\n                rel=\"noopener noreferrer\">\n              {match.Filename}\n            </a>\n          </div>\n          <div className=\"file-body\">\n            {matches}\n          </div>", "line_changes": {"deleted": [{"line_no": 45, "char_start": 1344, "char_end": 1416, "line": "            <a href={Model.UrlToRepo(repo, match.Filename, null, rev)}>\n"}], "added": [{"line_no": 46, "char_start": 1388, "char_end": 1459, "line": "            <a href={Model.UrlToRepo(repo, match.Filename, null, rev)}\n"}, {"line_no": 47, "char_start": 1459, "char_end": 1491, "line": "                target=\"_blank\"\n"}, {"line_no": 48, "char_start": 1491, "char_end": 1534, "line": "                rel=\"noopener noreferrer\">\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1031, "char_end": 1075, "chars": "\n                  rel=\"noopener noreferrer\""}, {"char_start": 1458, "char_end": 1532, "chars": "\n                target=\"_blank\"\n                rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/etsy/Hound/commit/b8a39b2e8eaa3df3cc0a8e0ab7c4c5174def15db", "file_name": "hound.js", "vul_type": "cwe-200", "commit_msg": "Give repo links a target of blank (#404)\n\nAdd rel=\"noopener noreferrer\" to _blank links", "parent_commit": "ca5c7c8c1dc6753b0bbe2bdd0ad3c934969f7cf6", "description": "Create a React component in JavaScript that displays highlighted search results from a repository with a load more functionality."}
{"func_name": "", "func_src_before": "\tr.HandleFunc(\"/api/totals/last/{num}\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// Grab vars\n\t\tvars := mux.Vars(r)\n\n\t\tvar output string\n\t\t// This is bad... don't do this.... omg\n\t\tquery := fmt.Sprintf(`SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, end_of_day_total from trello.dailytallies order by day DESC limit %s) r;`, vars[\"num\"])\n\t\terr := db.QueryRow(query).Scan(&output)\n\n\t\tif err != nil {\n\t\t\tlog.Println(\"Error retriving from DB, \", err)\n\t\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t\tfmt.Fprintln(w, \"Error retriving from DB, \", err)\n\t\t\treturn\n\t\t}\n\n\t\t// Print out returned\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprint(w, output)\n\t})", "func_src_after": "\tr.HandleFunc(\"/api/totals/last/{num}\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// Grab vars\n\t\tvars := mux.Vars(r)\n\n\t\tvar output string\n\t\t// This is bad... don't do this.... omg\n\t\tquery := `SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, end_of_day_total from trello.dailytallies order by day DESC limit $1) r;`\n\t\terr := db.QueryRow(query, vars[\"num\"]).Scan(&output)\n\n\t\tif err != nil {\n\t\t\tlog.Println(\"Error retriving from DB, \", err)\n\t\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t\tfmt.Fprintln(w, \"Error retriving from DB, \", err)\n\t\t\treturn\n\t\t}\n\n\t\t// Print out returned\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprint(w, output)\n\t})", "line_changes": {"deleted": [{"line_no": 7, "char_start": 187, "char_end": 363, "line": "\t\tquery := fmt.Sprintf(`SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, end_of_day_total from trello.dailytallies order by day DESC limit %s) r;`, vars[\"num\"])\n"}, {"line_no": 8, "char_start": 363, "char_end": 405, "line": "\t\terr := db.QueryRow(query).Scan(&output)\n"}], "added": [{"line_no": 7, "char_start": 187, "char_end": 337, "line": "\t\tquery := `SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, end_of_day_total from trello.dailytallies order by day DESC limit $1) r;`\n"}, {"line_no": 8, "char_start": 337, "char_end": 392, "line": "\t\terr := db.QueryRow(query, vars[\"num\"]).Scan(&output)\n"}]}, "char_changes": {"deleted": [{"char_start": 198, "char_end": 210, "chars": "fmt.Sprintf("}, {"char_start": 341, "char_end": 343, "chars": "%s"}, {"char_start": 348, "char_end": 362, "chars": ", vars[\"num\"])"}], "added": [{"char_start": 329, "char_end": 331, "chars": "$1"}, {"char_start": 363, "char_end": 376, "chars": ", vars[\"num\"]"}]}, "commit_link": "github.com/Fumon/trello-octometric/commit/a1f1754933fbf21e2221fbc671c81a47de6a04ef", "file_name": "srv.go", "vul_type": "cwe-089", "commit_msg": "Fixed sql injection", "parent_commit": "5de98cdcbd44941c195679aefa24ecf36aa06f44", "description": "Create a Go HTTP handler that retrieves and returns the last 'n' daily totals as JSON from a database, using a URL parameter to specify 'n'."}
{"func_name": "(anonymous)", "func_src_before": "    connection.query('SELECT * FROM Occupation WHERE soc = \"' + soc + '\";', function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });", "func_src_after": "    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 106, "line": "    connection.query('SELECT * FROM Occupation WHERE soc = \"' + soc + '\";', function(err, rows, fields) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 101, "line": "    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n"}]}, "char_changes": {"deleted": [{"char_start": 59, "char_end": 74, "chars": "\"' + soc + '\";'"}], "added": [{"char_start": 59, "char_end": 69, "chars": "?;', [soc]"}]}, "commit_link": "github.com/david1hung/P3/commit/0872ff99b9991946f1c71b07d19ca95c71c2a4b8", "file_name": "occupation.js", "vul_type": "cwe-089", "commit_msg": "Improved search, fixed SQL injection vulnerabilities", "description": "Write a JavaScript function that retrieves a single occupation record from a database using the 'soc' code."}
{"func_name": "Database.prototype.register", "func_src_before": "Database.prototype.register = function(attendee) {\n    let query = \"INSERT INTO tb_events (uid, key, value, payload) VALUES \"\n              + \"(\"\n              + \"'\" + attendee.event + \"', \"\n              + \"'attendee', \"\n              + \"'\" + attendee.name + \"', \"\n              + \"'\" + attendee.times + \"'\"\n              + \" );\";\n    this.db.run(query);\n} // end of Database#register", "func_src_after": "Database.prototype.register = function(attendee) {\n    this.db.run(\n      \"INSERT INTO tb_events (uid, key, value, payload) VALUES ( ? , 'attendee', ? , ? );\",\n      [attendee.event, attendee.name, attendee.times]\n    );\n} // end of Database#register", "line_changes": {"deleted": [{"line_no": 2, "char_start": 51, "char_end": 126, "line": "    let query = \"INSERT INTO tb_events (uid, key, value, payload) VALUES \"\n"}, {"line_no": 3, "char_start": 126, "char_end": 146, "line": "              + \"(\"\n"}, {"line_no": 4, "char_start": 146, "char_end": 191, "line": "              + \"'\" + attendee.event + \"', \"\n"}, {"line_no": 5, "char_start": 191, "char_end": 222, "line": "              + \"'attendee', \"\n"}, {"line_no": 6, "char_start": 222, "char_end": 266, "line": "              + \"'\" + attendee.name + \"', \"\n"}, {"line_no": 7, "char_start": 266, "char_end": 309, "line": "              + \"'\" + attendee.times + \"'\"\n"}, {"line_no": 8, "char_start": 309, "char_end": 332, "line": "              + \" );\";\n"}, {"line_no": 9, "char_start": 332, "char_end": 356, "line": "    this.db.run(query);\n"}], "added": [{"line_no": 2, "char_start": 51, "char_end": 68, "line": "    this.db.run(\n"}, {"line_no": 3, "char_start": 68, "char_end": 160, "line": "      \"INSERT INTO tb_events (uid, key, value, payload) VALUES ( ? , 'attendee', ? , ? );\",\n"}, {"line_no": 4, "char_start": 160, "char_end": 214, "line": "      [attendee.event, attendee.name, attendee.times]\n"}, {"line_no": 5, "char_start": 214, "char_end": 221, "line": "    );\n"}]}, "char_changes": {"deleted": [{"char_start": 55, "char_end": 66, "chars": "let query ="}, {"char_start": 124, "char_end": 198, "chars": "\"\n              + \"(\"\n              + \"'\" + attendee.event + \"', \"\n       "}, {"char_start": 204, "char_end": 209, "chars": " + \"'"}, {"char_start": 217, "char_end": 353, "chars": "', \"\n              + \"'\" + attendee.name + \"', \"\n              + \"'\" + attendee.times + \"'\"\n              + \" );\";\n    this.db.run(query"}], "added": [{"char_start": 55, "char_end": 73, "chars": "this.db.run(\n     "}, {"char_start": 131, "char_end": 218, "chars": "( ? , 'attendee', ? , ? );\",\n      [attendee.event, attendee.name, attendee.times]\n    "}]}, "commit_link": "github.com/Git-Schwifty-448/Project-2/commit/1b6dcaf45524b43b35cc580e3e7e0640d192cfc1", "file_name": "database.js", "vul_type": "cwe-089", "commit_msg": "Fix SQL injections (failed on ')", "description": "Write a JavaScript function to insert an attendee's details into a database table using a `Database` object's `register` method."}
{"func_name": "forgot_passwd", "func_src_before": "@app.route('/forgot-password', methods=['GET', 'POST'])\ndef forgot_passwd():\n  \"\"\" Procedure to allow users to reset forgotten passwords. \"\"\"\n  if request.method == 'POST':\n    username = request.form['username']\n    email = request.form['email']\n    query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n    result = connection.execute(query, u=str(username))\n    if result.returns_rows and result.rowcount != 0:\n      result_cols = result.keys()\n      row = result.first()\n      q_dict = dict(zip(result_cols, row))\n      if q_dict['email'] == email:\n        reset_key = auth.reset_key(q_dict['passwd'], q_dict['salt'], username)\n        msg = \"We received a request to reset this account's password.\\n\" \\\n              \"If you didn't request this change, disregard this email.\\n\" \\\n              \"If you do want to change your password, please go to:\\n\" +\\\n              url_for('reset_passwd', u=q_dict['user_id'], r=reset_key,\n                  _external=True) + \\\n              \"\\n\\nThanks,\\nThe Ruddock Website\"\n        sendEmail(str(email), msg, \"[RuddWeb] Forgotten Password\")\n        flash(\"An email has been sent.\")\n        redirect(url_for('home'))\n      else:\n        flash(\"Incorrect email.\")\n        return render_template('forgot_password.html')\n    else:\n      flash(\"Incorrect username.\")\n      return render_template('forgot_password.html')\n  return render_template('forgot_password.html')", "func_src_after": "@app.route('/forgot-password', methods=['GET', 'POST'])\ndef forgot_passwd():\n  \"\"\" Procedure to allow users to reset forgotten passwords. \"\"\"\n  if 'username' in session:\n    flash(\"You're already logged in!\")\n    return redirect(url_for('home'))\n\n  if request.method == 'POST':\n    username = request.form['username']\n    email = request.form['email']\n    query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n    result = connection.execute(query, u=str(username))\n    if result.returns_rows and result.rowcount != 0:\n      result_cols = result.keys()\n      row = result.first()\n      q_dict = dict(zip(result_cols, row))\n      if q_dict['email'] == email:\n        reset_key = auth.reset_key(q_dict['passwd'], q_dict['salt'], username)\n        msg = \"We received a request to reset this account's password.\\n\" \\\n              \"If you didn't request this change, disregard this email.\\n\" \\\n              \"If you do want to change your password, please go to:\\n\" +\\\n              url_for('reset_passwd', u=q_dict['user_id'], r=reset_key,\n                  _external=True) + \\\n              \"\\n\\nThanks,\\nThe Ruddock Website\"\n        sendEmail(str(email), msg, \"[RuddWeb] Forgotten Password\")\n        flash(\"An email has been sent.\")\n        redirect(url_for('home'))\n      else:\n        flash(\"Incorrect email.\")\n        return render_template('forgot_password.html')\n    else:\n      flash(\"Incorrect username.\")\n      return render_template('forgot_password.html')\n  return render_template('forgot_password.html')", "line_changes": {"deleted": [], "added": [{"line_no": 4, "char_start": 142, "char_end": 170, "line": "  if 'username' in session:\n"}, {"line_no": 5, "char_start": 170, "char_end": 209, "line": "    flash(\"You're already logged in!\")\n"}, {"line_no": 6, "char_start": 209, "char_end": 246, "line": "    return redirect(url_for('home'))\n"}, {"line_no": 7, "char_start": 246, "char_end": 247, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 142, "char_end": 247, "chars": "  if 'username' in session:\n    flash(\"You're already logged in!\")\n    return redirect(url_for('home'))\n\n"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "RuddockWebsite.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python Flask function to handle a forgot-password route, allowing users to reset their password via email."}
{"func_name": "verify_token", "func_src_before": "    async def verify_token(self, token):\n        \"\"\" verify session token \"\"\"\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                SELECT aio.{self.manager_type}.id\n                FROM aio.tokens JOIN aio.users ON aio.tokens.user_id = aio.users.id\n                JOIN aio.{self.manager_type} ON aio.{self.manager_type}.user_id = aio.users.id\n                WHERE aio.tokens.token = '{token}'\"\"\"\n                        await cur.execute(query)\n                        async for row in cur:\n                            return row[0]\n        except Exception as err:\n            print(err)\n            raise HTTPForbidden()", "func_src_after": "    async def verify_token(self, token):\n        \"\"\" verify session token \"\"\"\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        table = self.manager_type\n                        query = f\"\"\"\n                SELECT aio.{table}.id\n                FROM aio.tokens JOIN aio.users ON aio.tokens.user_id = aio.users.id\n                JOIN aio.{table} ON aio.{table}.user_id = aio.users.id\n                WHERE aio.tokens.token = %s\"\"\"\n                        await cur.execute(query, (token, ))\n                        async for row in cur:\n                            return row[0]\n        except Exception as err:\n            print(err)\n            raise web.HTTPForbidden()", "line_changes": {"deleted": [{"line_no": 8, "char_start": 292, "char_end": 342, "line": "                SELECT aio.{self.manager_type}.id\n"}, {"line_no": 10, "char_start": 426, "char_end": 521, "line": "                JOIN aio.{self.manager_type} ON aio.{self.manager_type}.user_id = aio.users.id\n"}, {"line_no": 11, "char_start": 521, "char_end": 575, "line": "                WHERE aio.tokens.token = '{token}'\"\"\"\n"}, {"line_no": 12, "char_start": 575, "char_end": 624, "line": "                        await cur.execute(query)\n"}, {"line_no": 17, "char_start": 768, "char_end": 801, "line": "            raise HTTPForbidden()\n"}], "added": [{"line_no": 7, "char_start": 255, "char_end": 305, "line": "                        table = self.manager_type\n"}, {"line_no": 9, "char_start": 342, "char_end": 380, "line": "                SELECT aio.{table}.id\n"}, {"line_no": 11, "char_start": 464, "char_end": 535, "line": "                JOIN aio.{table} ON aio.{table}.user_id = aio.users.id\n"}, {"line_no": 12, "char_start": 535, "char_end": 582, "line": "                WHERE aio.tokens.token = %s\"\"\"\n"}, {"line_no": 13, "char_start": 582, "char_end": 642, "line": "                        await cur.execute(query, (token, ))\n"}, {"line_no": 18, "char_start": 786, "char_end": 823, "line": "            raise web.HTTPForbidden()\n"}]}, "char_changes": {"deleted": [{"char_start": 320, "char_end": 336, "chars": "self.manager_typ"}, {"char_start": 452, "char_end": 495, "chars": "self.manager_type} ON aio.{self.manager_typ"}, {"char_start": 562, "char_end": 571, "chars": "'{token}'"}], "added": [{"char_start": 255, "char_end": 305, "chars": "                        table = self.manager_type\n"}, {"char_start": 370, "char_end": 374, "chars": "tabl"}, {"char_start": 490, "char_end": 509, "chars": "table} ON aio.{tabl"}, {"char_start": 576, "char_end": 578, "chars": "%s"}, {"char_start": 629, "char_end": 640, "chars": ", (token, )"}, {"char_start": 804, "char_end": 808, "chars": "web."}]}, "commit_link": "github.com/TeaTracer/aio-test/commit/3da13f66b0c1ab1d26bf4b56f476ade60a43d8d4", "file_name": "db.py", "vul_type": "cwe-089", "commit_msg": "Fix sql injections in token and password verifications. Fix HTTTPForbidden exception.", "description": "Write a Python function using `aiopg` to asynchronously verify a session token in a PostgreSQL database."}
{"func_name": "sanitize", "func_src_before": "  def sanitize(prefix)\n    # Add \\\\ to escape special characters. Four \\ to escape the backslashes.\n    # Escape anything that isn't in \"a-zA-Z0-9 ._|'/\"\n    prefix.gsub(%r{([^a-zA-Z0-9 ._|'\\/])}, '\\\\\\\\\\1') if prefix\n  end", "func_src_after": "  def sanitize(text)\n    # Add \\\\ to escape special characters. Four \\ to escape the backslashes.\n    # Escape anything that isn't in \"a-zA-Z0-9 ._|'/\"\n    text.gsub(%r{([^a-zA-Z0-9 ._|'\\/])}, '\\\\\\\\\\1') if text\n  end", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 23, "line": "  def sanitize(prefix)\n"}, {"line_no": 4, "char_start": 154, "char_end": 217, "line": "    prefix.gsub(%r{([^a-zA-Z0-9 ._|'\\/])}, '\\\\\\\\\\1') if prefix\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 21, "line": "  def sanitize(text)\n"}, {"line_no": 4, "char_start": 152, "char_end": 211, "line": "    text.gsub(%r{([^a-zA-Z0-9 ._|'\\/])}, '\\\\\\\\\\1') if text\n"}]}, "char_changes": {"deleted": [{"char_start": 15, "char_end": 21, "chars": "prefix"}, {"char_start": 158, "char_end": 164, "chars": "prefix"}, {"char_start": 210, "char_end": 216, "chars": "prefix"}], "added": [{"char_start": 15, "char_end": 19, "chars": "text"}, {"char_start": 156, "char_end": 160, "chars": "text"}, {"char_start": 206, "char_end": 210, "chars": "text"}]}, "commit_link": "github.com/chanzuckerberg/idseq-web/commit/5e0901a9bd161312cf8bb57004830ac32921f976", "file_name": "elasticsearch_helper.rb", "vul_type": "cwe-089", "commit_msg": "[Taxon Search] Search text on any part of the word and avoid SQL injection. (#2372)\n\n* Search text on any part of the word.\r\nSanitize tax_levels to avoid SQL injection.\r\n\r\n* Rubocop", "parent_commit": "22e2cdb38444f81519346b4b0ce35c8e66c3de2d", "description": "Write a Ruby function named `sanitize` that escapes special characters in a string, allowing only alphanumeric characters and a specific set of punctuation."}
{"func_name": "check_in_interaction_ids", "func_src_before": "      def check_in_interaction_ids\n        access_token = Hackbot::Team\n                       .find_by(team_id: team.team_id)\n                       .bot_access_token\n\n        im_id = SlackClient::Chat.open_im(slack_id, access_token)[:channel][:id]\n\n        check_in_interactions = Hackbot::Interactions::CheckIn\n                                .where(\"data->>'channel' = '#{im_id}'\")\n                                .where.not(state: 'finish')\n\n        check_in_interactions.map(&:id)\n      end", "func_src_after": "      def check_in_interaction_ids\n        access_token = Hackbot::Team\n                       .find_by(team_id: team.team_id)\n                       .bot_access_token\n\n        im_id = SlackClient::Chat.open_im(slack_id, access_token)[:channel][:id]\n\n        check_in_interactions = Hackbot::Interactions::CheckIn\n                                .where(\"data->>'channel' = ?\", im_id)\n                                .where.not(state: 'finish')\n\n        check_in_interactions.map(&:id)\n      end", "line_changes": {"deleted": [{"line_no": 9, "char_start": 314, "char_end": 386, "line": "                                .where(\"data->>'channel' = '#{im_id}'\")\n"}], "added": [{"line_no": 9, "char_start": 314, "char_end": 384, "line": "                                .where(\"data->>'channel' = ?\", im_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 373, "char_end": 376, "chars": "'#{"}, {"char_start": 381, "char_end": 384, "chars": "}'\""}], "added": [{"char_start": 373, "char_end": 377, "chars": "?\", "}]}, "commit_link": "github.com/hackclub/api/commit/2323813b545ba8f7de1cfafe36bfdebdecd76611", "file_name": "demo_check_in.rb", "vul_type": "cwe-089", "commit_msg": "Fix sql injection in DemoCheckIn interaction", "description": "Write a Ruby method to retrieve the IDs of ongoing check-in interactions for a specific Slack channel using a bot's access token."}
{"func_name": "set", "func_src_before": "  set: function (key, val) {\n    if (val === undefined) {\n      val = key;\n      key = null;\n    }\n    var path = getPath(key);\n    if (path.length === 0) {\n      // root must be an object\n      if (!val || typeof val !== 'object') {\n        return false;\n      } else {\n        this.store = val;\n        return true;\n      }\n    }\n\n    var target = this.store;\n    while (path.length > 1) {\n      key = path.shift();\n      if (!target[key] || typeof target[key] !== 'object') {\n        target[key] = {};\n      }\n\n      target = target[key];\n    }\n\n    key = path.shift();\n    target[key] = val;\n    return true;\n  },", "func_src_after": "  set: function (key, val) {\n    if (key.includes('__proto__') || key.includes('prototype') || key.includes('constructor')){\n      return undefined;\n    }\n    if (val === undefined) {\n      val = key;\n      key = null;\n    }\n    var path = getPath(key);\n    if (path.length === 0) {\n      // root must be an object\n      if (!val || typeof val !== 'object') {\n        return false;\n      } else {\n        this.store = val;\n        return true;\n      }\n    }\n\n    var target = this.store;\n    while (path.length > 1) {\n      key = path.shift();\n      if (!target[key] || typeof target[key] !== 'object') {\n        target[key] = {};\n      }\n\n      target = target[key];\n    }\n\n    key = path.shift();\n    target[key] = val;\n    return true;\n  },", "line_changes": {"deleted": [], "added": [{"line_no": 2, "char_start": 29, "char_end": 125, "line": "    if (key.includes('__proto__') || key.includes('prototype') || key.includes('constructor')){\n"}, {"line_no": 3, "char_start": 125, "char_end": 149, "line": "      return undefined;\n"}, {"line_no": 4, "char_start": 149, "char_end": 155, "line": "    }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 29, "char_end": 155, "chars": "    if (key.includes('__proto__') || key.includes('prototype') || key.includes('constructor')){\n      return undefined;\n    }\n"}]}, "commit_link": "github.com/tiny-conf/tiny-conf/commit/c1f4181bc3583fff49fe6e34c6e745479c569eb2", "file_name": "tiny-conf.js", "vul_type": "cwe-915", "commit_msg": "Fixed prototype pollution", "parent_commit": "c4d8b44ab53b9810b76a04caec249762d8c7fbc7", "description": "Write a JavaScript function named `set` that assigns a value to a nested object property, optionally creating nested objects if the path does not exist, and handles the case where the property path is not provided."}
{"func_name": "encryptPassword", "func_src_before": "    encryptPassword: function(password) {\n        if (!password) return '';\n        return crypto.createHmac('sha1', this.salt).update(password).digest('hex');\n    }", "func_src_after": "    encryptPassword: function(password) {\n        if (!password) return '';\n        return bcrypt.hashSync(password, 10);\n    }", "line_changes": {"deleted": [{"line_no": 3, "char_start": 76, "char_end": 160, "line": "        return crypto.createHmac('sha1', this.salt).update(password).digest('hex');\n"}], "added": [{"line_no": 3, "char_start": 76, "char_end": 122, "line": "        return bcrypt.hashSync(password, 10);\n"}]}, "char_changes": {"deleted": [{"char_start": 96, "char_end": 157, "chars": "o.createHmac('sha1', this.salt).update(password).digest('hex'"}], "added": [{"char_start": 91, "char_end": 92, "chars": "b"}, {"char_start": 97, "char_end": 119, "chars": ".hashSync(password, 10"}]}, "commit_link": "github.com/aburchette/territory-manager-mean/commit/24620016541089cc0ca316a0dec32ee0db864d98", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Replaced SHA1 password hashing with more bcrypt", "parent_commit": "f944f0a464555f033f01413f24d1cd47ab412ae7", "description": "Create a password encryption function in JavaScript that uses either SHA-1 with a salt or bcrypt."}
{"func_name": "FileStorage::getResourceFile", "func_src_before": "\tFile getResourceFile(String id, Location location) {\n\t\t// package level for migrators\n\t\tif (id==null) {\n\t\t\tthrow new IllegalArgumentException(\"No ID provided for stored resource\");\n\t\t}\n\t\tFile file = new File(getObjectStoreDirectory(location),  id+\".gz\");\n\t\tif (file.exists()) {return file;}\n\t\telse {return new File(getObjectStoreDirectory(location),  id);}\n\t}", "func_src_after": "\tFile getResourceFile(String id, Location location) {\n\t\tid = new File(id).getName(); // make sure we're not doing any directory traversal\n\t\t// package level for migrators\n\t\tif (id==null) {\n\t\t\tthrow new IllegalArgumentException(\"No ID provided for stored resource\");\n\t\t}\n\t\tFile file = new File(getObjectStoreDirectory(location),  id+\".gz\");\n\t\tif (file.exists()) {return file;}\n\t\telse {return new File(getObjectStoreDirectory(location),  id);}\n\t}", "line_changes": {"deleted": [], "added": [{"line_no": 2, "char_start": 54, "char_end": 138, "line": "\t\tid = new File(id).getName(); // make sure we're not doing any directory traversal\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 54, "char_end": 138, "chars": "\t\tid = new File(id).getName(); // make sure we're not doing any directory traversal\n"}]}, "commit_link": "github.com/sgsinclair/trombone/commit/7e3dc054775f94070962ceacb4b5b3a3f54725d7", "file_name": "FileStorage.java", "vul_type": "cwe-022", "commit_msg": "fix for directory traversal vulnerability", "parent_commit": "64dfb72777187e47d3c21c707671ee77bbe4dbea", "description": "Write a Java function that retrieves a resource file based on an identifier and location, handling null IDs and checking for file existence."}
{"func_name": "DefaultSampleFilesService::downloadAndUnpackResource", "func_src_before": "\tprivate void downloadAndUnpackResource(final Location source,\n\t\tfinal File targetFolder) throws InterruptedException, ExecutionException,\n\t\tIOException\n\t{\n\t\t// allocate array\n\t\tfinal ByteArray byteArray = new ByteArray(1024 * 1024);\n\n\t\tlog.debug(\"Started download of \" + source.getURI());\n\t\t// Download the zip file\n\t\tfinal BytesLocation bytes = new BytesLocation(byteArray);\n\t\tfinal Task task = //\n\t\t\tdownloadService.download(source, bytes, sourceCache()).task();\n\t\ttask.waitFor();\n\n\t\t// extract to cache dir\n\t\tfinal byte[] buf = new byte[64 * 1024];\n\t\tfinal ByteArrayInputStream bais = new ByteArrayInputStream(//\n\t\t\tbyteArray.getArray(), 0, byteArray.size());\n\t\ttargetFolder.mkdirs();\n\t\tlog.debug(\"Unpacking files\");\n\t\ttry (final ZipInputStream zis = new ZipInputStream(bais)) {\n\t\t\twhile (true) {\n\t\t\t\tfinal ZipEntry entry = zis.getNextEntry();\n\t\t\t\tif (entry == null) break; // All done!\n\t\t\t\tfinal String name = entry.getName();\n\t\t\t\tfinal File outFile = new File(targetFolder, name);\n\t\t\t\tif (entry.isDirectory()) {\n\t\t\t\t\toutFile.mkdirs();\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tfinal int size = (int) entry.getSize();\n\t\t\t\t\tint len = 0;\n\t\t\t\t\ttry (final FileOutputStream out = new FileOutputStream(outFile)) {\n\t\t\t\t\t\twhile (true) {\n\t\t\t\t\t\t\tlog.debug(\"Unpacking \" + name + \"; completion\" + (double) len /\n\t\t\t\t\t\t\t\tsize * 100 + \"%\");\n\t\t\t\t\t\t\tfinal int r = zis.read(buf);\n\t\t\t\t\t\t\tif (r < 0) break; // end of entry\n\t\t\t\t\t\t\tlen += r;\n\t\t\t\t\t\t\tout.write(buf, 0, r);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tprivate void downloadAndUnpackResource(final Location source,\n\t\tfinal File targetFolder) throws InterruptedException, ExecutionException,\n\t\tIOException\n\t{\n\t\t// allocate array\n\t\tfinal ByteArray byteArray = new ByteArray(1024 * 1024);\n\n\t\tlog.debug(\"Started download of \" + source.getURI());\n\t\t// Download the zip file\n\t\tfinal BytesLocation bytes = new BytesLocation(byteArray);\n\t\tfinal Task task = //\n\t\t\tdownloadService.download(source, bytes, sourceCache()).task();\n\t\ttask.waitFor();\n\n\t\t// extract to cache dir\n\t\tfinal byte[] buf = new byte[64 * 1024];\n\t\tfinal ByteArrayInputStream bais = new ByteArrayInputStream(//\n\t\t\tbyteArray.getArray(), 0, byteArray.size());\n\t\ttargetFolder.mkdirs();\n\t\tlog.debug(\"Unpacking files\");\n\t\ttry (final ZipInputStream zis = new ZipInputStream(bais)) {\n\t\t\twhile (true) {\n\t\t\t\tfinal ZipEntry entry = zis.getNextEntry();\n\t\t\t\tif (entry == null) break; // All done!\n\t\t\t\tfinal String name = entry.getName();\n\t\t\t\tfinal File outFile = new File(targetFolder, name);\n\t\t\t\tif (!outFile.toPath().normalize().startsWith(targetFolder.toPath().normalize())) {\n\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t}\n\t\t\t\tif (entry.isDirectory()) {\n\t\t\t\t\toutFile.mkdirs();\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tfinal int size = (int) entry.getSize();\n\t\t\t\t\tint len = 0;\n\t\t\t\t\ttry (final FileOutputStream out = new FileOutputStream(outFile)) {\n\t\t\t\t\t\twhile (true) {\n\t\t\t\t\t\t\tlog.debug(\"Unpacking \" + name + \"; completion\" + (double) len /\n\t\t\t\t\t\t\t\tsize * 100 + \"%\");\n\t\t\t\t\t\t\tfinal int r = zis.read(buf);\n\t\t\t\t\t\t\tif (r < 0) break; // end of entry\n\t\t\t\t\t\t\tlen += r;\n\t\t\t\t\t\t\tout.write(buf, 0, r);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [], "added": [{"line_no": 27, "char_start": 987, "char_end": 1074, "line": "\t\t\t\tif (!outFile.toPath().normalize().startsWith(targetFolder.toPath().normalize())) {\n"}, {"line_no": 28, "char_start": 1074, "char_end": 1124, "line": "\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 29, "char_start": 1124, "char_end": 1130, "line": "\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 987, "char_end": 1130, "chars": "\t\t\t\tif (!outFile.toPath().normalize().startsWith(targetFolder.toPath().normalize())) {\n\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t}\n"}]}, "commit_link": "github.com/scifio/scifio/commit/fcb0dbca0ec72b22fe0c9ddc8abc9cb188a0ff31", "file_name": "DefaultSampleFilesService.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to download a ZIP file from a given location and extract its contents to a specified directory."}
{"func_name": "(anonymous)", "func_src_before": "\trelease.assets.forEach(function(asset) {\n\t\tvar arch = parseName(asset.name);\n\t\tif (!arch) return;\n\t\t\n\t\tvar dist = {\n\t\t\tname: asset.name,\n\t\t\turl: asset.browser_download_url,\n\t\t\tsize: asset.size,\n\t\t\tos: arch && arch.os,\n\t\t\tarch: arch && arch.arch,\n\t\t\tdownload: function() {\n\t\t\t\tdebug('download: ' + this.name);\n\t\t\t\treturn request(dist.url);\n\t\t\t},\n\t\t\textract: function(dest, options) {\n\t\t\t\toptions = options || {};\n\t\t\t\tvar filter = options.filter || [];\n\t\t\t\tif (!Array.isArray(filter)) {\n\t\t\t\t\tfilter = [filter];\n\t\t\t\t}\n\t\t\t\tdest = dest || '.';\n\n\t\t\t\tdebug('extract: %s -> %s', this.name, dest);\n\n\t\t\t\t// ensure that destination exists\n\t\t\t\tfs.ensureDirSync(dest);\n\n\t\t\t\tvar stream = this.download();\n\t\t\t\tvar zip = stream.pipe(unzip.Parse());\n\t\t\t\tzip.on('entry', function(entry) {\n\t\t\t\t\t// skip directories\n\t\t\t\t\tif (entry.type === 'Directory') {\n\t\t\t\t\t\tentry.autodrain();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tvar dest_file = path.join(dest, entry.path);\n\t\t\t\t\t// skip if path is filtered\n\t\t\t\t\tfor (var i in filter) {\n\t\t\t\t\t\tif (minimatch(entry.path, filter[i], {dot: true})) {\n\t\t\t\t\t\t\tdebug('  skip: %s', entry.path);\n\t\t\t\t\t\t\tentry.autodrain();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tdebug('  write: %s -> %s', entry.path, dest_file);\n\t\t\t\t\tfs.ensureFileSync(dest_file);\n\t\t\t\t\tif (entry.path == 'atom') {\n\t\t\t\t\t\t// make 'atom' executable\n\t\t\t\t\t\tfs.chmodSync(dest_file, '755');\n\t\t\t\t\t}\n\t\t\t\t\tentry.pipe(fs.createWriteStream(dest_file));\n\t\t\t\t});\n\t\t\t\treturn stream;\n\t\t\t}\n\t\t};\n\t\tdists[arch.os + '-' + arch.arch] = dist;\n\t});", "func_src_after": "\trelease.assets.forEach(function(asset) {\n\t\tvar arch = parseName(asset.name);\n\t\tif (!arch) return;\n\n\t\tvar dist = {\n\t\t\tname: asset.name,\n\t\t\turl: asset.browser_download_url,\n\t\t\tsize: asset.size,\n\t\t\tos: arch && arch.os,\n\t\t\tarch: arch && arch.arch,\n\t\t\tdownload: function() {\n\t\t\t\tdebug('download: ' + this.name);\n\t\t\t\treturn request(dist.url);\n\t\t\t},\n\t\t\textract: function(dest, options) {\n\t\t\t\toptions = options || {};\n\t\t\t\tvar filter = options.filter || [];\n\t\t\t\tif (!Array.isArray(filter)) {\n\t\t\t\t\tfilter = [filter];\n\t\t\t\t}\n\t\t\t\tdest = dest || '.';\n\n\t\t\t\tdebug('extract: %s -> %s', this.name, dest);\n\n\t\t\t\t// ensure that destination exists\n\t\t\t\tfs.ensureDirSync(dest);\n\n\t\t\t\tvar stream = this.download();\n\t\t\t\tvar zip = stream.pipe(unzip.Parse());\n\t\t\t\tzip.on('entry', function(entry) {\n\t\t\t\t\t// skip directories\n\t\t\t\t\tif (entry.type === 'Directory') {\n\t\t\t\t\t\tentry.autodrain();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tvar dest_file = path.join(dest, entry.path);\n\t\t\t\t\t// skip if path is filtered\n\t\t\t\t\tfor (var i in filter) {\n\t\t\t\t\t\tif (minimatch(entry.path, filter[i], {dot: true})) {\n\t\t\t\t\t\t\tdebug('  skip: %s', entry.path);\n\t\t\t\t\t\t\tentry.autodrain();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tdebug('  write: %s -> %s', entry.path, dest_file);\n\t\t\t\t\tfs.ensureFileSync(dest_file);\n\t\t\t\t\tif (entry.path == 'atom') {\n\t\t\t\t\t\t// make 'atom' executable\n\t\t\t\t\t\tfs.chmodSync(dest_file, '755');\n\t\t\t\t\t}\n\t\t\t\t\tentry.pipe(fs.createWriteStream(dest_file));\n\t\t\t\t});\n\t\t\t\treturn stream;\n\t\t\t}\n\t\t};\n\t\tdists[arch.os + '-' + arch.arch] = dist;\n\t});", "line_changes": {"deleted": [{"line_no": 4, "char_start": 99, "char_end": 102, "line": "\t\t\n"}], "added": [{"line_no": 4, "char_start": 99, "char_end": 100, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 99, "char_end": 101, "chars": "\t\t"}], "added": []}, "commit_link": "github.com/hakovala/atom-shell-downloader/commit/fa78ab0ea84c685499f738c6646faecffdbc457b", "file_name": "index.js", "vul_type": "cwe-022", "commit_msg": "Change unzip to node-unzip-2\n\nThis fixes the extract issue.\n\nSigned-off-by: Harri Kovalainen <hakovala@gmail.com>", "description": "Write a JavaScript function to process release assets, parse their names for architecture information, and provide methods to download and extract them."}
{"func_name": "_get_obj_absolute_path", "func_src_before": "def _get_obj_absolute_path(obj_path):\n    return os.path.join(DATAROOT, obj_path)", "func_src_after": "def _get_obj_absolute_path(obj_path):\n    return safe_join(DATAROOT, obj_path)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 38, "char_end": 81, "line": "    return os.path.join(DATAROOT, obj_path)\n"}], "added": [{"line_no": 2, "char_start": 38, "char_end": 78, "line": "    return safe_join(DATAROOT, obj_path)\n"}]}, "char_changes": {"deleted": [{"char_start": 49, "char_end": 57, "chars": "os.path."}], "added": [{"char_start": 49, "char_end": 54, "chars": "safe_"}]}, "commit_link": "github.com/cmusatyalab/opendiamond/commit/744e345c078a20b7e8bc5bc34debcf7c7b1f7d4c", "file_name": "augment_store.py", "vul_type": "cwe-022", "commit_msg": "# Absolute Path Traversal due to incorrect use of `send_file` call\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\n\n## Common Weakness Enumeration category\nCWE - 36\n\n## Root Cause Analysis\n\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\n```\n>>> import os.path\n>>> static = \"path/to/mySafeStaticDir\"\n>>> malicious = \"/../../../../../etc/passwd\"\n>>> os.path.join(t,malicious)\n'/../../../../../etc/passwd'\n```\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\n\nIn this case, the problems occurs due to the following code :\nhttps://github.com/cmusatyalab/opendiamond/blob/7ded6b5d243fee3f56c978fc37638f9691e8dfec/opendiamond/dataretriever/augment_store.py#L164\n\nHere, the `obj_path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\n\n## Proof of Concept\n\nThe bug can be verified using a proof of concept similar to the one shown below.\n\n```\ncurl --path-as-is 'http://<domain>/obj//../../../../etc/passwd\"'\n```\n## Remediation\n\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\n\n## Common Vulnerability Scoring System Vector\n\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\n\n(AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L)[https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L&version=3.1]\n\nThis gives it a base score of 9.3/10 and a severity rating of critical.\n\n## References\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\n* github/securitylab#669\n\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*", "description": "Write a Python function named `_get_obj_absolute_path` that concatenates a predefined base path with a given object path to form an absolute path."}
{"func_name": "modname_normalize", "func_src_before": "static inline char *modname_normalize(char *modname, char buf[NAME_MAX],\n\t\t\t\t\t\t\t\tsize_t *len)\n{\n\tchar *c;\n\tsize_t s;\n\n\tif (buf) {\n\t\tbuf[NAME_MAX] = '\\0';\n\t\tmodname = strncpy(buf, modname, NAME_MAX - 1);\n\t}\n\n\tfor (c = modname, s = 0; *c != '\\0' && *c != '.'; c++) {\n\t\tif (*c == '-')\n\t\t\t*c = '_';\n\t\ts++;\n\t}\n\n\tif (len)\n\t\t*len = s;\n\n\t*c = '\\0';\n\n\treturn modname;\n}", "func_src_after": "static inline char *modname_normalize(const char *modname, char buf[NAME_MAX],\n\t\t\t\t\t\t\t\tsize_t *len)\n{\n\tsize_t s;\n\n\tfor (s = 0; s < NAME_MAX - 1; s++) {\n\t\tconst char c = modname[s];\n\t\tif (c == '-')\n\t\t\tbuf[s] = '_';\n\t\telse if (c == '\\0' || c == '.')\n\t\t\tbreak;\n\t\telse\n\t\t\tbuf[s] = c;\n\t}\n\tbuf[s] = '\\0';\n\n\tif (len)\n\t\t*len = s;\n\n\treturn buf;\n}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 73, "line": "static inline char *modname_normalize(char *modname, char buf[NAME_MAX],\n"}, {"line_no": 4, "char_start": 96, "char_end": 106, "line": "\tchar *c;\n"}, {"line_no": 7, "char_start": 118, "char_end": 130, "line": "\tif (buf) {\n"}, {"line_no": 8, "char_start": 130, "char_end": 154, "line": "\t\tbuf[NAME_MAX] = '\\0';\n"}, {"line_no": 9, "char_start": 154, "char_end": 203, "line": "\t\tmodname = strncpy(buf, modname, NAME_MAX - 1);\n"}, {"line_no": 10, "char_start": 203, "char_end": 206, "line": "\t}\n"}, {"line_no": 11, "char_start": 206, "char_end": 207, "line": "\n"}, {"line_no": 12, "char_start": 207, "char_end": 265, "line": "\tfor (c = modname, s = 0; *c != '\\0' && *c != '.'; c++) {\n"}, {"line_no": 13, "char_start": 265, "char_end": 282, "line": "\t\tif (*c == '-')\n"}, {"line_no": 14, "char_start": 282, "char_end": 295, "line": "\t\t\t*c = '_';\n"}, {"line_no": 15, "char_start": 295, "char_end": 302, "line": "\t\ts++;\n"}, {"line_no": 21, "char_start": 329, "char_end": 341, "line": "\t*c = '\\0';\n"}, {"line_no": 22, "char_start": 341, "char_end": 342, "line": "\n"}, {"line_no": 23, "char_start": 342, "char_end": 359, "line": "\treturn modname;\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 79, "line": "static inline char *modname_normalize(const char *modname, char buf[NAME_MAX],\n"}, {"line_no": 6, "char_start": 114, "char_end": 152, "line": "\tfor (s = 0; s < NAME_MAX - 1; s++) {\n"}, {"line_no": 7, "char_start": 152, "char_end": 181, "line": "\t\tconst char c = modname[s];\n"}, {"line_no": 8, "char_start": 181, "char_end": 197, "line": "\t\tif (c == '-')\n"}, {"line_no": 9, "char_start": 197, "char_end": 214, "line": "\t\t\tbuf[s] = '_';\n"}, {"line_no": 10, "char_start": 214, "char_end": 248, "line": "\t\telse if (c == '\\0' || c == '.')\n"}, {"line_no": 11, "char_start": 248, "char_end": 258, "line": "\t\t\tbreak;\n"}, {"line_no": 12, "char_start": 258, "char_end": 265, "line": "\t\telse\n"}, {"line_no": 13, "char_start": 265, "char_end": 280, "line": "\t\t\tbuf[s] = c;\n"}, {"line_no": 15, "char_start": 283, "char_end": 299, "line": "\tbuf[s] = '\\0';\n"}, {"line_no": 20, "char_start": 323, "char_end": 336, "line": "\treturn buf;\n"}]}, "char_changes": {"deleted": [{"char_start": 96, "char_end": 106, "chars": "\tchar *c;\n"}, {"char_start": 119, "char_end": 210, "chars": "if (buf) {\n\t\tbuf[NAME_MAX] = '\\0';\n\t\tmodname = strncpy(buf, modname, NAME_MAX - 1);\n\t}\n\n\tfo"}, {"char_start": 212, "char_end": 213, "chars": "("}, {"char_start": 224, "char_end": 234, "chars": ", s = 0; *"}, {"char_start": 236, "char_end": 237, "chars": "!"}, {"char_start": 240, "char_end": 251, "chars": "\\0' && *c !"}, {"char_start": 254, "char_end": 255, "chars": "."}, {"char_start": 257, "char_end": 267, "chars": " c++) {\n\t\t"}, {"char_start": 271, "char_end": 272, "chars": "*"}, {"char_start": 278, "char_end": 286, "chars": "-')\n\t\t\t*"}, {"char_start": 291, "char_end": 357, "chars": "_';\n\t\ts++;\n\t}\n\n\tif (len)\n\t\t*len = s;\n\n\t*c = '\\0';\n\n\treturn modname"}], "added": [{"char_start": 38, "char_end": 44, "chars": "const "}, {"char_start": 115, "char_end": 163, "chars": "for (s = 0; s < NAME_MAX - 1; s++) {\n\t\tconst cha"}, {"char_start": 176, "char_end": 187, "chars": "[s];\n\t\tif ("}, {"char_start": 189, "char_end": 190, "chars": "="}, {"char_start": 193, "char_end": 207, "chars": "-')\n\t\t\tbuf[s] "}, {"char_start": 210, "char_end": 211, "chars": "_"}, {"char_start": 213, "char_end": 221, "chars": "\n\t\telse "}, {"char_start": 231, "char_end": 238, "chars": "\\0' || "}, {"char_start": 241, "char_end": 242, "chars": "="}, {"char_start": 244, "char_end": 334, "chars": ".')\n\t\t\tbreak;\n\t\telse\n\t\t\tbuf[s] = c;\n\t}\n\tbuf[s] = '\\0';\n\n\tif (len)\n\t\t*len = s;\n\n\treturn buf"}]}, "commit_link": "github.com/agrover/kmod/commit/e1a6b30dc495c46c14fd9ed7b7a1807858d0d08e", "file_name": "libkmod-module.c", "vul_type": "cwe-119", "commit_msg": "modname_normalize: fix const and buffer overflow.\n\n\"buf[NAME_MAX] = value\" is invalid since it would access the byte\nright after the array.\n\nAlso fix the const of modname, do not mess with it to avoid mistakes.", "parent_commit": "8fc83fe1de2941e1eb0cec1b3b68fbcc14f82f02", "description": "Write a C function to normalize a module name by replacing hyphens with underscores and truncating the name at the first period or at a maximum length, returning the normalized name."}
{"func_name": "make_btrfs", "func_src_before": "int make_btrfs(int fd, u64 blocks[4], u64 num_bytes, u32 nodesize,\n\t       u32 leafsize, u32 sectorsize, u32 stripesize)\n{\n\tstruct btrfs_super_block super;\n\tstruct extent_buffer *buf;\n\tstruct btrfs_root_item root_item;\n\tstruct btrfs_disk_key disk_key;\n\tstruct btrfs_extent_ref *extent_ref;\n\tstruct btrfs_extent_item *extent_item;\n\tstruct btrfs_inode_item *inode_item;\n\tint i;\n\tint ret;\n\tu32 itemoff;\n\tu32 nritems = 0;\n\tu64 hash;\n\tu64 first_free;\n\tu64 ref_gen;\n\tu64 ref_root;\n\n\tfirst_free = BTRFS_SUPER_INFO_OFFSET + sectorsize * 2 - 1;\n\tfirst_free &= ~((u64)sectorsize - 1);\n\n\tnum_bytes = (num_bytes / sectorsize) * sectorsize;\n\tuuid_generate(super.fsid);\n\tbtrfs_set_super_bytenr(&super, blocks[0]);\n\tstrcpy((char *)(&super.magic), BTRFS_MAGIC);\n\tbtrfs_set_super_generation(&super, 1);\n\tbtrfs_set_super_root(&super, blocks[1]);\n\tbtrfs_set_super_total_bytes(&super, num_bytes);\n\tbtrfs_set_super_bytes_used(&super, first_free + 3 * leafsize);\n\tbtrfs_set_super_root_dir(&super, 0);\n\tbtrfs_set_super_sectorsize(&super, sectorsize);\n\tbtrfs_set_super_leafsize(&super, leafsize);\n\tbtrfs_set_super_nodesize(&super, nodesize);\n\tbtrfs_set_super_stripesize(&super, stripesize);\n\tbtrfs_set_super_root_level(&super, 0);\n\n\tbuf = malloc(sizeof(*buf) + max(sectorsize, leafsize));\n\n\tBUG_ON(sizeof(super) > sectorsize);\n\tmemset(buf->data, 0, sectorsize);\n\tmemcpy(buf->data, &super, sizeof(super));\n\tret = pwrite(fd, buf->data, sectorsize, blocks[0]);\n\tBUG_ON(ret != sectorsize);\n\n\t/* create the tree of root objects */\n\tmemset(buf->data, 0, leafsize);\n\tbtrfs_set_header_bytenr(buf, blocks[1]);\n\tbtrfs_set_header_nritems(buf, 2);\n\tbtrfs_set_header_generation(buf, 1);\n\tbtrfs_set_header_owner(buf, BTRFS_ROOT_TREE_OBJECTID);\n\twrite_extent_buffer(buf, super.fsid, (unsigned long)\n\t\t\t    btrfs_header_fsid(buf), BTRFS_FSID_SIZE);\n\n\t/* create the items for the root tree */\n\tmemset(&root_item, 0, sizeof(root_item));\n\tinode_item = &root_item.inode;\n\tbtrfs_set_stack_inode_generation(inode_item, 1);\n\tbtrfs_set_stack_inode_size(inode_item, 3);\n\tbtrfs_set_stack_inode_nlink(inode_item, 1);\n\tbtrfs_set_stack_inode_nblocks(inode_item, 1);\n\tbtrfs_set_stack_inode_mode(inode_item, S_IFDIR | 0755);\n\tbtrfs_set_root_refs(&root_item, 1);\n\tbtrfs_set_root_used(&root_item, leafsize);\n\n\tmemset(&disk_key, 0, sizeof(disk_key));\n\tbtrfs_set_disk_key_type(&disk_key, BTRFS_ROOT_ITEM_KEY);\n\tbtrfs_set_disk_key_offset(&disk_key, 0);\n\n\titemoff = __BTRFS_LEAF_DATA_SIZE(leafsize) - sizeof(root_item);\n\tbtrfs_set_root_bytenr(&root_item, blocks[2]);\n\tbtrfs_set_disk_key_objectid(&disk_key, BTRFS_EXTENT_TREE_OBJECTID);\n\tbtrfs_set_item_key(buf, &disk_key, 0);\n\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, 0), itemoff);\n\tbtrfs_set_item_size(buf, btrfs_item_nr(buf, 0), sizeof(root_item));\n\twrite_extent_buffer(buf, &root_item, btrfs_item_ptr_offset(buf, 0),\n\t\t\t    sizeof(root_item));\n\n\titemoff = itemoff - sizeof(root_item);\n\tbtrfs_set_root_bytenr(&root_item, blocks[3]);\n\tbtrfs_set_disk_key_objectid(&disk_key, BTRFS_FS_TREE_OBJECTID);\n\tbtrfs_set_item_key(buf, &disk_key, 1);\n\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, 1), itemoff);\n\tbtrfs_set_item_size(buf, btrfs_item_nr(buf, 1), sizeof(root_item));\n\twrite_extent_buffer(buf, &root_item, btrfs_item_ptr_offset(buf, 1),\n\t\t\t    sizeof(root_item));\n\tret = pwrite(fd, buf->data, leafsize, blocks[1]);\n\tBUG_ON(ret != leafsize);\n\n\t/* create the items for the extent tree */\n\titemoff = __BTRFS_LEAF_DATA_SIZE(leafsize) -\n\t\t  sizeof(struct btrfs_extent_item);\n\tbtrfs_set_disk_key_objectid(&disk_key, 0);\n\tbtrfs_set_disk_key_offset(&disk_key, first_free);\n\tbtrfs_set_disk_key_type(&disk_key, BTRFS_EXTENT_ITEM_KEY);\n\tbtrfs_set_item_key(buf, &disk_key, nritems);\n\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, nritems), itemoff);\n\tbtrfs_set_item_size(buf, btrfs_item_nr(buf,  nritems),\n\t\t\t    sizeof(struct btrfs_extent_item));\n\textent_item = btrfs_item_ptr(buf, nritems, struct btrfs_extent_item);\n\tbtrfs_set_extent_refs(buf, extent_item, 1);\n\tnritems++;\n\tfor (i = 1; i < 4; i++) {\n\t\tBUG_ON(blocks[i] < first_free);\n\t\tBUG_ON(blocks[i] < blocks[i - 1]);\n\n\t\t/* create extent item */\n\t\titemoff = itemoff - sizeof(struct btrfs_extent_item);\n\t\tbtrfs_set_disk_key_objectid(&disk_key, blocks[i]);\n\t\tbtrfs_set_disk_key_offset(&disk_key, leafsize);\n\t\tbtrfs_set_disk_key_type(&disk_key, BTRFS_EXTENT_ITEM_KEY);\n\t\tbtrfs_set_item_key(buf, &disk_key, nritems);\n\t\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, nritems),\n\t\t\t\t      itemoff);\n\t\tbtrfs_set_item_size(buf, btrfs_item_nr(buf, nritems),\n\t\t\t\t    sizeof(struct btrfs_extent_item));\n\t\textent_item = btrfs_item_ptr(buf, nritems,\n\t\t\t\t\t     struct btrfs_extent_item);\n\t\tbtrfs_set_extent_refs(buf, extent_item, 1);\n\t\tnritems++;\n\n\t\t/* create extent ref */\n\t\tref_root = reference_root_table[i];\n\t\tif (ref_root == BTRFS_FS_TREE_OBJECTID)\n\t\t\tref_gen = 1;\n\t\telse\n\t\t\tref_gen = 0;\n\n\t\thash = btrfs_hash_extent_ref(ref_root, ref_gen, 0, 0);\n\t\titemoff = itemoff - sizeof(struct btrfs_extent_ref);\n\t\tbtrfs_set_disk_key_objectid(&disk_key, blocks[i]);\n\t\tbtrfs_set_disk_key_offset(&disk_key, hash);\n\t\tbtrfs_set_disk_key_type(&disk_key, BTRFS_EXTENT_REF_KEY);\n\t\tbtrfs_set_item_key(buf, &disk_key, nritems);\n\t\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, nritems),\n\t\t\t\t      itemoff);\n\t\tbtrfs_set_item_size(buf, btrfs_item_nr(buf, nritems),\n\t\t\t\t    sizeof(struct btrfs_extent_ref));\n\t\textent_ref = btrfs_item_ptr(buf, nritems,\n\t\t\t\t\t     struct btrfs_extent_ref);\n\t\tbtrfs_set_ref_root(buf, extent_ref, ref_root);\n\t\tbtrfs_set_ref_generation(buf, extent_ref, ref_gen);\n\t\tbtrfs_set_ref_objectid(buf, extent_ref, 0);\n\t\tbtrfs_set_ref_offset(buf, extent_ref, 0);\n\t\tnritems++;\n\t}\n\tbtrfs_set_header_bytenr(buf, blocks[2]);\n\tbtrfs_set_header_owner(buf, BTRFS_EXTENT_TREE_OBJECTID);\n\tbtrfs_set_header_nritems(buf, nritems);\n\tret = pwrite(fd, buf->data, leafsize, blocks[2]);\n\tBUG_ON(ret != leafsize);\n\n\t/* finally create the FS root */\n\tbtrfs_set_header_bytenr(buf, blocks[3]);\n\tbtrfs_set_header_owner(buf, BTRFS_FS_TREE_OBJECTID);\n\tbtrfs_set_header_nritems(buf, 0);\n\tret = pwrite(fd, buf->data, leafsize, blocks[3]);\n\tBUG_ON(ret != leafsize);\n\n\tfree(buf);\n\treturn 0;\n}", "func_src_after": "int make_btrfs(int fd, u64 blocks[4], u64 num_bytes, u32 nodesize,\n\t       u32 leafsize, u32 sectorsize, u32 stripesize)\n{\n\tstruct btrfs_super_block super;\n\tstruct extent_buffer *buf;\n\tstruct btrfs_root_item root_item;\n\tstruct btrfs_disk_key disk_key;\n\tstruct btrfs_extent_ref *extent_ref;\n\tstruct btrfs_extent_item *extent_item;\n\tstruct btrfs_inode_item *inode_item;\n\tint i;\n\tint ret;\n\tu32 itemoff;\n\tu32 nritems = 0;\n\tu64 hash;\n\tu64 first_free;\n\tu64 ref_gen;\n\tu64 ref_root;\n\n\tfirst_free = BTRFS_SUPER_INFO_OFFSET + sectorsize * 2 - 1;\n\tfirst_free &= ~((u64)sectorsize - 1);\n\n\tnum_bytes = (num_bytes / sectorsize) * sectorsize;\n\tuuid_generate(super.fsid);\n\tbtrfs_set_super_bytenr(&super, blocks[0]);\n\tstrncpy((char *)&super.magic, BTRFS_MAGIC, sizeof(super.magic));\n\tbtrfs_set_super_generation(&super, 1);\n\tbtrfs_set_super_root(&super, blocks[1]);\n\tbtrfs_set_super_total_bytes(&super, num_bytes);\n\tbtrfs_set_super_bytes_used(&super, first_free + 3 * leafsize);\n\tbtrfs_set_super_root_dir(&super, 0);\n\tbtrfs_set_super_sectorsize(&super, sectorsize);\n\tbtrfs_set_super_leafsize(&super, leafsize);\n\tbtrfs_set_super_nodesize(&super, nodesize);\n\tbtrfs_set_super_stripesize(&super, stripesize);\n\tbtrfs_set_super_root_level(&super, 0);\n\n\tbuf = malloc(sizeof(*buf) + max(sectorsize, leafsize));\n\n\tBUG_ON(sizeof(super) > sectorsize);\n\tmemset(buf->data, 0, sectorsize);\n\tmemcpy(buf->data, &super, sizeof(super));\n\tret = pwrite(fd, buf->data, sectorsize, blocks[0]);\n\tBUG_ON(ret != sectorsize);\n\n\t/* create the tree of root objects */\n\tmemset(buf->data, 0, leafsize);\n\tbtrfs_set_header_bytenr(buf, blocks[1]);\n\tbtrfs_set_header_nritems(buf, 2);\n\tbtrfs_set_header_generation(buf, 1);\n\tbtrfs_set_header_owner(buf, BTRFS_ROOT_TREE_OBJECTID);\n\twrite_extent_buffer(buf, super.fsid, (unsigned long)\n\t\t\t    btrfs_header_fsid(buf), BTRFS_FSID_SIZE);\n\n\t/* create the items for the root tree */\n\tmemset(&root_item, 0, sizeof(root_item));\n\tinode_item = &root_item.inode;\n\tbtrfs_set_stack_inode_generation(inode_item, 1);\n\tbtrfs_set_stack_inode_size(inode_item, 3);\n\tbtrfs_set_stack_inode_nlink(inode_item, 1);\n\tbtrfs_set_stack_inode_nblocks(inode_item, 1);\n\tbtrfs_set_stack_inode_mode(inode_item, S_IFDIR | 0755);\n\tbtrfs_set_root_refs(&root_item, 1);\n\tbtrfs_set_root_used(&root_item, leafsize);\n\n\tmemset(&disk_key, 0, sizeof(disk_key));\n\tbtrfs_set_disk_key_type(&disk_key, BTRFS_ROOT_ITEM_KEY);\n\tbtrfs_set_disk_key_offset(&disk_key, 0);\n\n\titemoff = __BTRFS_LEAF_DATA_SIZE(leafsize) - sizeof(root_item);\n\tbtrfs_set_root_bytenr(&root_item, blocks[2]);\n\tbtrfs_set_disk_key_objectid(&disk_key, BTRFS_EXTENT_TREE_OBJECTID);\n\tbtrfs_set_item_key(buf, &disk_key, 0);\n\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, 0), itemoff);\n\tbtrfs_set_item_size(buf, btrfs_item_nr(buf, 0), sizeof(root_item));\n\twrite_extent_buffer(buf, &root_item, btrfs_item_ptr_offset(buf, 0),\n\t\t\t    sizeof(root_item));\n\n\titemoff = itemoff - sizeof(root_item);\n\tbtrfs_set_root_bytenr(&root_item, blocks[3]);\n\tbtrfs_set_disk_key_objectid(&disk_key, BTRFS_FS_TREE_OBJECTID);\n\tbtrfs_set_item_key(buf, &disk_key, 1);\n\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, 1), itemoff);\n\tbtrfs_set_item_size(buf, btrfs_item_nr(buf, 1), sizeof(root_item));\n\twrite_extent_buffer(buf, &root_item, btrfs_item_ptr_offset(buf, 1),\n\t\t\t    sizeof(root_item));\n\tret = pwrite(fd, buf->data, leafsize, blocks[1]);\n\tBUG_ON(ret != leafsize);\n\n\t/* create the items for the extent tree */\n\titemoff = __BTRFS_LEAF_DATA_SIZE(leafsize) -\n\t\t  sizeof(struct btrfs_extent_item);\n\tbtrfs_set_disk_key_objectid(&disk_key, 0);\n\tbtrfs_set_disk_key_offset(&disk_key, first_free);\n\tbtrfs_set_disk_key_type(&disk_key, BTRFS_EXTENT_ITEM_KEY);\n\tbtrfs_set_item_key(buf, &disk_key, nritems);\n\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, nritems), itemoff);\n\tbtrfs_set_item_size(buf, btrfs_item_nr(buf,  nritems),\n\t\t\t    sizeof(struct btrfs_extent_item));\n\textent_item = btrfs_item_ptr(buf, nritems, struct btrfs_extent_item);\n\tbtrfs_set_extent_refs(buf, extent_item, 1);\n\tnritems++;\n\tfor (i = 1; i < 4; i++) {\n\t\tBUG_ON(blocks[i] < first_free);\n\t\tBUG_ON(blocks[i] < blocks[i - 1]);\n\n\t\t/* create extent item */\n\t\titemoff = itemoff - sizeof(struct btrfs_extent_item);\n\t\tbtrfs_set_disk_key_objectid(&disk_key, blocks[i]);\n\t\tbtrfs_set_disk_key_offset(&disk_key, leafsize);\n\t\tbtrfs_set_disk_key_type(&disk_key, BTRFS_EXTENT_ITEM_KEY);\n\t\tbtrfs_set_item_key(buf, &disk_key, nritems);\n\t\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, nritems),\n\t\t\t\t      itemoff);\n\t\tbtrfs_set_item_size(buf, btrfs_item_nr(buf, nritems),\n\t\t\t\t    sizeof(struct btrfs_extent_item));\n\t\textent_item = btrfs_item_ptr(buf, nritems,\n\t\t\t\t\t     struct btrfs_extent_item);\n\t\tbtrfs_set_extent_refs(buf, extent_item, 1);\n\t\tnritems++;\n\n\t\t/* create extent ref */\n\t\tref_root = reference_root_table[i];\n\t\tif (ref_root == BTRFS_FS_TREE_OBJECTID)\n\t\t\tref_gen = 1;\n\t\telse\n\t\t\tref_gen = 0;\n\n\t\thash = btrfs_hash_extent_ref(ref_root, ref_gen, 0, 0);\n\t\titemoff = itemoff - sizeof(struct btrfs_extent_ref);\n\t\tbtrfs_set_disk_key_objectid(&disk_key, blocks[i]);\n\t\tbtrfs_set_disk_key_offset(&disk_key, hash);\n\t\tbtrfs_set_disk_key_type(&disk_key, BTRFS_EXTENT_REF_KEY);\n\t\tbtrfs_set_item_key(buf, &disk_key, nritems);\n\t\tbtrfs_set_item_offset(buf, btrfs_item_nr(buf, nritems),\n\t\t\t\t      itemoff);\n\t\tbtrfs_set_item_size(buf, btrfs_item_nr(buf, nritems),\n\t\t\t\t    sizeof(struct btrfs_extent_ref));\n\t\textent_ref = btrfs_item_ptr(buf, nritems,\n\t\t\t\t\t     struct btrfs_extent_ref);\n\t\tbtrfs_set_ref_root(buf, extent_ref, ref_root);\n\t\tbtrfs_set_ref_generation(buf, extent_ref, ref_gen);\n\t\tbtrfs_set_ref_objectid(buf, extent_ref, 0);\n\t\tbtrfs_set_ref_offset(buf, extent_ref, 0);\n\t\tnritems++;\n\t}\n\tbtrfs_set_header_bytenr(buf, blocks[2]);\n\tbtrfs_set_header_owner(buf, BTRFS_EXTENT_TREE_OBJECTID);\n\tbtrfs_set_header_nritems(buf, nritems);\n\tret = pwrite(fd, buf->data, leafsize, blocks[2]);\n\tBUG_ON(ret != leafsize);\n\n\t/* finally create the FS root */\n\tbtrfs_set_header_bytenr(buf, blocks[3]);\n\tbtrfs_set_header_owner(buf, BTRFS_FS_TREE_OBJECTID);\n\tbtrfs_set_header_nritems(buf, 0);\n\tret = pwrite(fd, buf->data, leafsize, blocks[3]);\n\tBUG_ON(ret != leafsize);\n\n\tfree(buf);\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 26, "char_start": 700, "char_end": 746, "line": "\tstrcpy((char *)(&super.magic), BTRFS_MAGIC);\n"}], "added": [{"line_no": 26, "char_start": 700, "char_end": 766, "line": "\tstrncpy((char *)&super.magic, BTRFS_MAGIC, sizeof(super.magic));\n"}]}, "char_changes": {"deleted": [{"char_start": 716, "char_end": 717, "chars": "("}, {"char_start": 729, "char_end": 730, "chars": ")"}], "added": [{"char_start": 704, "char_end": 705, "chars": "n"}, {"char_start": 742, "char_end": 763, "chars": ", sizeof(super.magic)"}]}, "commit_link": "github.com/Acidburn0zzz/btrfs-progs/commit/4408248634ecf2b4c1e246b9fd0c770984f69aae", "file_name": "utils.c", "vul_type": "cwe-787", "commit_msg": "btrfs-progs: fix a buffer overflow during mkfs\n\nUsing strncpy avoids a 1 byte overflow into the next field\nof the struct.  The overflow is harmless, but does\ntrip automated tools.\n\nSigned-off-by: Jan Engelhardt <jengelh@computergmbh.de>\n\n---\n utils.c |    2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)", "parent_commit": "7c2844538143aebb26f0436c2760172017901536", "description": "Write a C function to initialize a Btrfs filesystem on a given file descriptor with specified parameters."}
{"func_name": "SecurityConfiguration::configure", "func_src_before": "    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        // Enable CSRF (for h2 console!). This is a vulnerability!\n        http.csrf().disable();\n        http.headers().frameOptions().sameOrigin();\n\n        // Person pages only for authenticated users.\n        http.authorizeRequests()\n                .antMatchers(\"/persons/**\").hasAnyAuthority(\"USER\");\n\n        // Forum pages only for authenticated users.\n        http.authorizeRequests()\n                .antMatchers(\"/forums/**\").hasAnyAuthority(\"USER\");\n\n        http.formLogin()\n                .loginPage(\"/login\")\n                .defaultSuccessUrl(\"/main\")\n                .failureUrl(\"/invalidlogin\")\n                .permitAll()\n                .and()\n                .logout()\n                .logoutUrl(\"/logout\")\n                .logoutSuccessUrl(\"/main\");\n    }", "func_src_after": "    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.headers().frameOptions().sameOrigin();\n\n        // Person pages only for authenticated users.\n        http.authorizeRequests()\n                .antMatchers(\"/persons/**\").hasAnyAuthority(\"USER\");\n\n        // Forum pages only for authenticated users.\n        http.authorizeRequests()\n                .antMatchers(\"/forums/**\").hasAnyAuthority(\"USER\");\n\n        http.formLogin()\n                .loginPage(\"/login\")\n                .defaultSuccessUrl(\"/main\")\n                .failureUrl(\"/invalidlogin\")\n                .permitAll()\n                .and()\n                .logout()\n                .logoutUrl(\"/logout\")\n                .logoutSuccessUrl(\"/main\");\n    }", "line_changes": {"deleted": [{"line_no": 4, "char_start": 148, "char_end": 179, "line": "        http.csrf().disable();\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 81, "char_end": 179, "chars": "        // Enable CSRF (for h2 console!). This is a vulnerability!\n        http.csrf().disable();\n"}], "added": []}, "commit_link": "github.com/nrz/cybersecuritybase-project/commit/b69f58f684627a5ee15904e933451188f0c6d3b7", "file_name": "SecurityConfiguration.java", "vul_type": "cwe-352", "commit_msg": "Enable CSRF protection. CSRF protection is enabled by default.\n\nhttps://docs.spring.io/spring-security/site/docs/current/reference/html/csrf.html\n\n\tmodified:   src/main/java/codechat/config/SecurityConfiguration.java", "parent_commit": "b3c0fb9de065524cdfd87a2061104a89453c12f0", "description": "Write a Java Spring Security configuration method to set up authorization rules for specific URL patterns and configure custom login and logout behavior."}
{"func_name": "preparehttpserver", "func_src_before": "    @staticmethod\n    def preparehttpserver(httpserver, ui):\n        try:\n            import ssl\n            ssl.wrap_socket\n        except ImportError:\n            raise error.Abort(_(\"SSL support is unavailable\"))\n\n        certfile = ui.config('web', 'certificate')\n        httpserver.socket = ssl.wrap_socket(\n            httpserver.socket, server_side=True,\n            certfile=certfile, ssl_version=ssl.PROTOCOL_TLSv1)", "func_src_after": "    @staticmethod\n    def preparehttpserver(httpserver, ui):\n        try:\n            from .. import sslutil\n            sslutil.modernssl\n        except ImportError:\n            raise error.Abort(_(\"SSL support is unavailable\"))\n\n        certfile = ui.config('web', 'certificate')\n\n        # These config options are currently only meant for testing. Use\n        # at your own risk.\n        cafile = ui.config('devel', 'servercafile')\n        reqcert = ui.configbool('devel', 'serverrequirecert')\n\n        httpserver.socket = sslutil.wrapserversocket(httpserver.socket,\n                                                     ui,\n                                                     certfile=certfile,\n                                                     cafile=cafile,\n                                                     requireclientcert=reqcert)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 74, "char_end": 97, "line": "            import ssl\n"}, {"line_no": 5, "char_start": 97, "char_end": 125, "line": "            ssl.wrap_socket\n"}, {"line_no": 10, "char_start": 268, "char_end": 313, "line": "        httpserver.socket = ssl.wrap_socket(\n"}, {"line_no": 11, "char_start": 313, "char_end": 362, "line": "            httpserver.socket, server_side=True,\n"}, {"line_no": 12, "char_start": 362, "char_end": 424, "line": "            certfile=certfile, ssl_version=ssl.PROTOCOL_TLSv1)\n"}], "added": [{"line_no": 4, "char_start": 74, "char_end": 109, "line": "            from .. import sslutil\n"}, {"line_no": 5, "char_start": 109, "char_end": 139, "line": "            sslutil.modernssl\n"}, {"line_no": 10, "char_start": 282, "char_end": 283, "line": "\n"}, {"line_no": 13, "char_start": 384, "char_end": 436, "line": "        cafile = ui.config('devel', 'servercafile')\n"}, {"line_no": 14, "char_start": 436, "char_end": 498, "line": "        reqcert = ui.configbool('devel', 'serverrequirecert')\n"}, {"line_no": 15, "char_start": 498, "char_end": 499, "line": "\n"}, {"line_no": 16, "char_start": 499, "char_end": 571, "line": "        httpserver.socket = sslutil.wrapserversocket(httpserver.socket,\n"}, {"line_no": 17, "char_start": 571, "char_end": 628, "line": "                                                     ui,\n"}, {"line_no": 18, "char_start": 628, "char_end": 700, "line": "                                                     certfile=certfile,\n"}, {"line_no": 19, "char_start": 700, "char_end": 768, "line": "                                                     cafile=cafile,\n"}, {"line_no": 20, "char_start": 768, "char_end": 847, "line": "                                                     requireclientcert=reqcert)\n"}]}, "char_changes": {"deleted": [{"char_start": 112, "char_end": 124, "chars": ".wrap_socket"}, {"char_start": 276, "char_end": 423, "chars": "httpserver.socket = ssl.wrap_socket(\n            httpserver.socket, server_side=True,\n            certfile=certfile, ssl_version=ssl.PROTOCOL_TLSv1"}], "added": [{"char_start": 85, "char_end": 93, "chars": " from .."}, {"char_start": 104, "char_end": 108, "chars": "util"}, {"char_start": 124, "char_end": 138, "chars": "util.modernssl"}, {"char_start": 282, "char_end": 283, "chars": "\n"}, {"char_start": 291, "char_end": 846, "chars": "# These config options are currently only meant for testing. Use\n        # at your own risk.\n        cafile = ui.config('devel', 'servercafile')\n        reqcert = ui.configbool('devel', 'serverrequirecert')\n\n        httpserver.socket = sslutil.wrapserversocket(httpserver.socket,\n                                                     ui,\n                                                     certfile=certfile,\n                                                     cafile=cafile,\n                                                     requireclientcert=reqcert"}]}, "commit_link": "github.com/dscho/hg/commit/3b79d41d484d8f3daf67deea155d224ddd5a046f", "file_name": "server.py", "vul_type": "cwe-327", "commit_msg": "hgweb: use sslutil.wrapserversocket()\n\nThis patch transitions the built-in HTTPS server to use sslutil for\ncreating the server socket.\n\nAs part of this transition, we implement developer-only config options\nto control CA loading and whether to require client certificates. This\neliminates the need for the custom extension in test-https.t to define\nthese.\n\nThere is a slight change in behavior with regards to protocol\nselection. Before, we would always use the TLS 1.0 constant to define\nthe protocol version. This would *only* use TLS 1.0. sslutil defaults\nto TLS 1.0+. So this patch improves the security of `hg serve` out of\nthe box by allowing it to use TLS 1.1 and 1.2 (if available).", "parent_commit": "561dcdd1798eed0fbe203758c11f5cd33f9a38d4", "description": "Write a Python function that configures an HTTP server with SSL using a certificate from the configuration."}
{"func_name": "get_socket", "func_src_before": "    def get_socket(self):\n        if self.use_ssl:\n            cert_path = os.path.join(self.config_path, 'certs', self.host)\n            if not os.path.exists(cert_path):\n                is_new = True\n                s = self.get_simple_socket()\n                if s is None:\n                    return\n                # try with CA first\n                try:\n                    s = ssl.wrap_socket(s, ssl_version=ssl.PROTOCOL_TLSv1, cert_reqs=ssl.CERT_REQUIRED, ca_certs=ca_path, do_handshake_on_connect=True)\n                except ssl.SSLError, e:\n                    s = None\n                if s and self.check_host_name(s.getpeercert(), self.host):\n                    self.print_error(\"SSL certificate signed by CA\")\n                    return s\n\n                # get server certificate.\n                # Do not use ssl.get_server_certificate because it does not work with proxy\n                s = self.get_simple_socket()\n                if s is None:\n                    return\n                try:\n                    s = ssl.wrap_socket(s, ssl_version=ssl.PROTOCOL_TLSv1, cert_reqs=ssl.CERT_NONE, ca_certs=None)\n                except ssl.SSLError, e:\n                    self.print_error(\"SSL error retrieving SSL certificate:\", e)\n                    return\n\n                dercert = s.getpeercert(True)\n                s.close()\n                cert = ssl.DER_cert_to_PEM_cert(dercert)\n                # workaround android bug\n                cert = re.sub(\"([^\\n])-----END CERTIFICATE-----\",\"\\\\1\\n-----END CERTIFICATE-----\",cert)\n                temporary_path = cert_path + '.temp'\n                with open(temporary_path,\"w\") as f:\n                    f.write(cert)\n            else:\n                is_new = False\n\n        s = self.get_simple_socket()\n        if s is None:\n            return\n\n        if self.use_ssl:\n            try:\n                s = ssl.wrap_socket(s,\n                                    ssl_version=ssl.PROTOCOL_TLSv1,\n                                    cert_reqs=ssl.CERT_REQUIRED,\n                                    ca_certs= (temporary_path if is_new else cert_path),\n                                    do_handshake_on_connect=True)\n            except ssl.SSLError, e:\n                self.print_error(\"SSL error:\", e)\n                if e.errno != 1:\n                    return\n                if is_new:\n                    rej = cert_path + '.rej'\n                    if os.path.exists(rej):\n                        os.unlink(rej)\n                    os.rename(temporary_path, rej)\n                else:\n                    with open(cert_path) as f:\n                        cert = f.read()\n                    try:\n                        b = pem.dePem(cert, 'CERTIFICATE')\n                        x = x509.X509(b)\n                    except:\n                        traceback.print_exc(file=sys.stderr)\n                        self.print_error(\"wrong certificate\")\n                        return\n                    try:\n                        x.check_date()\n                    except:\n                        self.print_error(\"certificate has expired:\", cert_path)\n                        os.unlink(cert_path)\n                        return\n                    self.print_error(\"wrong certificate\")\n                return\n            except BaseException, e:\n                self.print_error(e)\n                if e.errno == 104:\n                    return\n                traceback.print_exc(file=sys.stderr)\n                return\n\n            if is_new:\n                self.print_error(\"saving certificate\")\n                os.rename(temporary_path, cert_path)\n\n        return s", "func_src_after": "    def get_socket(self):\n        if self.use_ssl:\n            cert_path = os.path.join(self.config_path, 'certs', self.host)\n            if not os.path.exists(cert_path):\n                is_new = True\n                s = self.get_simple_socket()\n                if s is None:\n                    return\n                # try with CA first\n                try:\n                    s = ssl.wrap_socket(s, ssl_version=ssl.PROTOCOL_SSLv23, cert_reqs=ssl.CERT_REQUIRED, ca_certs=ca_path, do_handshake_on_connect=True)\n                except ssl.SSLError, e:\n                    s = None\n                if s and self.check_host_name(s.getpeercert(), self.host):\n                    self.print_error(\"SSL certificate signed by CA\")\n                    return s\n\n                # get server certificate.\n                # Do not use ssl.get_server_certificate because it does not work with proxy\n                s = self.get_simple_socket()\n                if s is None:\n                    return\n                try:\n                    s = ssl.wrap_socket(s, ssl_version=ssl.PROTOCOL_SSLv23, cert_reqs=ssl.CERT_NONE, ca_certs=None)\n                except ssl.SSLError, e:\n                    self.print_error(\"SSL error retrieving SSL certificate:\", e)\n                    return\n\n                dercert = s.getpeercert(True)\n                s.close()\n                cert = ssl.DER_cert_to_PEM_cert(dercert)\n                # workaround android bug\n                cert = re.sub(\"([^\\n])-----END CERTIFICATE-----\",\"\\\\1\\n-----END CERTIFICATE-----\",cert)\n                temporary_path = cert_path + '.temp'\n                with open(temporary_path,\"w\") as f:\n                    f.write(cert)\n            else:\n                is_new = False\n\n        s = self.get_simple_socket()\n        if s is None:\n            return\n\n        if self.use_ssl:\n            try:\n                s = ssl.wrap_socket(s,\n                                    ssl_version=ssl.PROTOCOL_SSLv23,\n                                    cert_reqs=ssl.CERT_REQUIRED,\n                                    ca_certs= (temporary_path if is_new else cert_path),\n                                    do_handshake_on_connect=True)\n            except ssl.SSLError, e:\n                self.print_error(\"SSL error:\", e)\n                if e.errno != 1:\n                    return\n                if is_new:\n                    rej = cert_path + '.rej'\n                    if os.path.exists(rej):\n                        os.unlink(rej)\n                    os.rename(temporary_path, rej)\n                else:\n                    with open(cert_path) as f:\n                        cert = f.read()\n                    try:\n                        b = pem.dePem(cert, 'CERTIFICATE')\n                        x = x509.X509(b)\n                    except:\n                        traceback.print_exc(file=sys.stderr)\n                        self.print_error(\"wrong certificate\")\n                        return\n                    try:\n                        x.check_date()\n                    except:\n                        self.print_error(\"certificate has expired:\", cert_path)\n                        os.unlink(cert_path)\n                        return\n                    self.print_error(\"wrong certificate\")\n                return\n            except BaseException, e:\n                self.print_error(e)\n                if e.errno == 104:\n                    return\n                traceback.print_exc(file=sys.stderr)\n                return\n\n            if is_new:\n                self.print_error(\"saving certificate\")\n                os.rename(temporary_path, cert_path)\n\n        return s", "line_changes": {"deleted": [{"line_no": 11, "char_start": 361, "char_end": 513, "line": "                    s = ssl.wrap_socket(s, ssl_version=ssl.PROTOCOL_TLSv1, cert_reqs=ssl.CERT_REQUIRED, ca_certs=ca_path, do_handshake_on_connect=True)\n"}, {"line_no": 24, "char_start": 1013, "char_end": 1128, "line": "                    s = ssl.wrap_socket(s, ssl_version=ssl.PROTOCOL_TLSv1, cert_reqs=ssl.CERT_NONE, ca_certs=None)\n"}, {"line_no": 47, "char_start": 1900, "char_end": 1968, "line": "                                    ssl_version=ssl.PROTOCOL_TLSv1,\n"}], "added": [{"line_no": 11, "char_start": 361, "char_end": 514, "line": "                    s = ssl.wrap_socket(s, ssl_version=ssl.PROTOCOL_SSLv23, cert_reqs=ssl.CERT_REQUIRED, ca_certs=ca_path, do_handshake_on_connect=True)\n"}, {"line_no": 24, "char_start": 1014, "char_end": 1130, "line": "                    s = ssl.wrap_socket(s, ssl_version=ssl.PROTOCOL_SSLv23, cert_reqs=ssl.CERT_NONE, ca_certs=None)\n"}, {"line_no": 47, "char_start": 1902, "char_end": 1971, "line": "                                    ssl_version=ssl.PROTOCOL_SSLv23,\n"}]}, "char_changes": {"deleted": [{"char_start": 429, "char_end": 434, "chars": "TLSv1"}, {"char_start": 1081, "char_end": 1086, "chars": "TLSv1"}, {"char_start": 1961, "char_end": 1966, "chars": "TLSv1"}], "added": [{"char_start": 429, "char_end": 435, "chars": "SSLv23"}, {"char_start": 1082, "char_end": 1088, "chars": "SSLv23"}, {"char_start": 1963, "char_end": 1969, "chars": "SSLv23"}]}, "commit_link": "github.com/vialectrum/vialectrum/commit/614f3df4b83bf197e60a510269e71f5a32b36661", "file_name": "interface.py", "vul_type": "cwe-327", "commit_msg": "Revert \"Use ssl.PROTOCOL_TLSv1 on client side to avoid SSLv23\"\n\nThis reverts commit 4731418af9d47084a2b88dad38bf2d279c392d9b.", "description": "In Python, write a function to establish a secure socket connection with SSL, handling certificate verification and errors."}
{"func_name": "testConstructWrapperWithExistingNonEmptyDumpRoot", "func_src_before": "  def testConstructWrapperWithExistingNonEmptyDumpRoot(self):\n    os.mkdir(self._tmp_dir)\n    dir_path = os.path.join(self._tmp_dir, \"foo\")\n    os.mkdir(dir_path)\n    self.assertTrue(os.path.isdir(dir_path))\n\n    with self.assertRaisesRegex(\n        ValueError, \"dump_root path points to a non-empty directory\"):\n      local_cli_wrapper.LocalCLIDebugWrapperSession(\n          session.Session(), dump_root=self._tmp_dir, log_usage=False)", "func_src_after": "  def testConstructWrapperWithExistingNonEmptyDumpRoot(self):\n    dir_path = os.path.join(self._tmp_dir, \"foo\")\n    os.mkdir(dir_path)\n    self.assertTrue(os.path.isdir(dir_path))\n\n    with self.assertRaisesRegex(\n        ValueError, \"dump_root path points to a non-empty directory\"):\n      local_cli_wrapper.LocalCLIDebugWrapperSession(\n          session.Session(), dump_root=self._tmp_dir, log_usage=False)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 62, "char_end": 90, "line": "    os.mkdir(self._tmp_dir)\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 62, "char_end": 90, "chars": "    os.mkdir(self._tmp_dir)\n"}], "added": []}, "commit_link": "github.com/tensorflow/tensorflow/commit/4f93d5f529a732dd533c063ae5b85e03e2006882", "file_name": "local_cli_wrapper_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkdtemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420369603\nChange-Id: I2cf40b13f41cc01000c2c21a483a2d680194dba2", "description": "Write a Python test function that checks if an exception is raised when initializing a debug wrapper session with a non-empty directory."}
{"func_name": "try_compile_and_link", "func_src_before": "def try_compile_and_link(compiler, source='', flags=[], verbose=False):\n    ensure_tmp_dir_exists()\n    with tempfile.NamedTemporaryFile() as sfile:\n        ofile = tempfile.mktemp()\n        try:\n            sfile.file.write(bytes(source, 'utf-8'))\n            sfile.file.flush()\n            ret = subprocess.run([compiler, '-x', 'c++', '-o', ofile, sfile.name] + args.user_cflags.split() + flags,\n                                 capture_output=True)\n            if verbose:\n                print(f\"Compilation failed: {compiler} -x c++ -o {ofile} {sfile.name} {args.user_cflags} {flags}\")\n                print(source)\n                print(ret.stdout.decode('utf-8'))\n                print(ret.stderr.decode('utf-8'))\n            return ret.returncode == 0\n        finally:\n            if os.path.exists(ofile):\n                os.unlink(ofile)", "func_src_after": "def try_compile_and_link(compiler, source='', flags=[], verbose=False):\n    ensure_tmp_dir_exists()\n    with tempfile.NamedTemporaryFile() as sfile:\n        ofd, ofile = tempfile.mkstemp()\n        os.close(ofd)\n        try:\n            sfile.file.write(bytes(source, 'utf-8'))\n            sfile.file.flush()\n            ret = subprocess.run([compiler, '-x', 'c++', '-o', ofile, sfile.name] + args.user_cflags.split() + flags,\n                                 capture_output=True)\n            if verbose:\n                print(f\"Compilation failed: {compiler} -x c++ -o {ofile} {sfile.name} {args.user_cflags} {flags}\")\n                print(source)\n                print(ret.stdout.decode('utf-8'))\n                print(ret.stderr.decode('utf-8'))\n            return ret.returncode == 0\n        finally:\n            if os.path.exists(ofile):\n                os.unlink(ofile)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 149, "char_end": 183, "line": "        ofile = tempfile.mktemp()\n"}], "added": [{"line_no": 4, "char_start": 149, "char_end": 189, "line": "        ofd, ofile = tempfile.mkstemp()\n"}, {"line_no": 5, "char_start": 189, "char_end": 211, "line": "        os.close(ofd)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 156, "char_end": 161, "chars": " ofd,"}, {"char_start": 181, "char_end": 182, "chars": "s"}, {"char_start": 189, "char_end": 211, "chars": "        os.close(ofd)\n"}]}, "commit_link": "github.com/scylladb/scylla/commit/c5f29fe3ea6cd9a61883f2cdabd80ea888ae8b4f", "file_name": "configure.py", "vul_type": "cwe-377", "commit_msg": "configure.py: don't use deprecated mktemp()\n\nconfigure.py uses the deprecated Python function tempfile.mktemp().\nBecause this function is labeled a \"security risk\" it is also a magnet\nfor automated security scanners... So let's replace it with the\nrecommended tempfile.mkstemp() and avoid future complaints.\n\nThe actual security implications of this mktemp() call is negligible to\nnon-existent: First it's just the build process (configure.py), not\nthe build product itself. Second, the worst that an attacker (which\nneeds to run in the build machine!) can do is to cause a compilation\ntest in configure.py to fail because it can't write to its output file.\n\nReported by @srikanthprathi\n\nSigned-off-by: Nadav Har'El <nyh@scylladb.com>\nMessage-Id: <20220111121924.615173-1-nyh@scylladb.com>", "description": "Write a Python function that attempts to compile and link a C++ source code snippet using a specified compiler and optional flags, with an option to print verbose output."}
{"func_name": "_make_asset", "func_src_before": "  def _make_asset(self, contents):\n    filename = tempfile.mktemp(prefix=self.get_temp_dir())\n    with open(filename, \"w\") as f:\n      f.write(contents)\n    return filename", "func_src_after": "  def _make_asset(self, contents):\n    fd, filename = tempfile.mkstemp(prefix=self.get_temp_dir())\n    with os.fdopen(fd, \"w\") as f:\n      f.write(contents)\n    return filename", "line_changes": {"deleted": [{"line_no": 2, "char_start": 35, "char_end": 94, "line": "    filename = tempfile.mktemp(prefix=self.get_temp_dir())\n"}, {"line_no": 3, "char_start": 94, "char_end": 129, "line": "    with open(filename, \"w\") as f:\n"}], "added": [{"line_no": 2, "char_start": 35, "char_end": 99, "line": "    fd, filename = tempfile.mkstemp(prefix=self.get_temp_dir())\n"}, {"line_no": 3, "char_start": 99, "char_end": 133, "line": "    with os.fdopen(fd, \"w\") as f:\n"}]}, "char_changes": {"deleted": [{"char_start": 104, "char_end": 116, "chars": "pen(filename"}], "added": [{"char_start": 38, "char_end": 42, "chars": " fd,"}, {"char_start": 65, "char_end": 66, "chars": "s"}, {"char_start": 109, "char_end": 120, "chars": "s.fdopen(fd"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/b2fec2d450c27ce51bc40c7095b862fe96bfd312", "file_name": "load_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420363556\nChange-Id: I3225120cd6545462174641581a365ead0eb179c3", "description": "Write a Python function to create a temporary file with specified contents and return its filename."}
{"func_name": "testConstructWrapperWithExistingFileDumpRoot", "func_src_before": "  def testConstructWrapperWithExistingFileDumpRoot(self):\n    os.mkdir(self._tmp_dir)\n    file_path = os.path.join(self._tmp_dir, \"foo\")\n    open(file_path, \"a\").close()  # Create the file\n    self.assertTrue(os.path.isfile(file_path))\n    with self.assertRaisesRegex(ValueError, \"dump_root path points to a file\"):\n      local_cli_wrapper.LocalCLIDebugWrapperSession(\n          session.Session(), dump_root=file_path, log_usage=False)", "func_src_after": "  def testConstructWrapperWithExistingFileDumpRoot(self):\n    file_path = os.path.join(self._tmp_dir, \"foo\")\n    open(file_path, \"a\").close()  # Create the file\n    self.assertTrue(os.path.isfile(file_path))\n    with self.assertRaisesRegex(ValueError, \"dump_root path points to a file\"):\n      local_cli_wrapper.LocalCLIDebugWrapperSession(\n          session.Session(), dump_root=file_path, log_usage=False)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 58, "char_end": 86, "line": "    os.mkdir(self._tmp_dir)\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 86, "chars": "    os.mkdir(self._tmp_dir)\n"}], "added": []}, "commit_link": "github.com/tensorflow/tensorflow/commit/4f93d5f529a732dd533c063ae5b85e03e2006882", "file_name": "local_cli_wrapper_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkdtemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420369603\nChange-Id: I2cf40b13f41cc01000c2c21a483a2d680194dba2", "description": "Write a Python function that tests the creation of a debug wrapper session with a file path that already exists, expecting a ValueError."}
{"func_name": "check_inode", "func_src_before": "static bool check_inode(struct exfat_de_iter *iter, struct exfat_inode *node)\n{\n\tstruct exfat *exfat = iter->exfat;\n\tstruct exfat_dentry *dentry;\n\tbool ret = true;\n\tuint16_t checksum;\n\n\tif (check_clus_chain(exfat, node))\n\t\treturn false;\n\n\tif (node->size > le32_to_cpu(exfat->bs->bsx.clu_count) *\n\t\t\t\texfat->clus_size) {\n\t\tresolve_path_parent(&path_resolve_ctx, iter->parent, node);\n\t\texfat_err(\"size %\" PRIu64 \" is greater than cluster heap: %s\\n\",\n\t\t\t\tnode->size, path_resolve_ctx.local_path);\n\t\tret = false;\n\t}\n\n\tif (node->size == 0 && node->is_contiguous) {\n\t\tresolve_path_parent(&path_resolve_ctx, iter->parent, node);\n\t\texfat_err(\"empty, but marked as contiguous: %s\\n\",\n\t\t\t\t\tpath_resolve_ctx.local_path);\n\t\tret = false;\n\t}\n\n\tif ((node->attr & ATTR_SUBDIR) &&\n\t\t\tnode->size % exfat->clus_size != 0) {\n\t\tresolve_path_parent(&path_resolve_ctx, iter->parent, node);\n\t\texfat_err(\"directory size %\" PRIu64 \" is not divisible by %d: %s\\n\",\n\t\t\t\tnode->size, exfat->clus_size,\n\t\t\t\tpath_resolve_ctx.local_path);\n\t\tret = false;\n\t}\n\n\tchecksum = file_calc_checksum(iter);\n\texfat_de_iter_get(iter, 0, &dentry);\n\tif (checksum != le16_to_cpu(dentry->file_checksum)) {\n\t\tif (repair_file_ask(iter, node, ER_DE_CHECKSUM,\n\t\t\t\t\"the checksum of a file is wrong\")) {\n\t\t\texfat_de_iter_get_dirty(iter, 0, &dentry);\n\t\t\tdentry->file_checksum = cpu_to_le16(checksum);\n\t\t} else\n\t\t\tret = false;\n\t}\n\n\treturn ret;\n}", "func_src_after": "static bool check_inode(struct exfat_de_iter *iter, struct exfat_inode *node)\n{\n\tstruct exfat *exfat = iter->exfat;\n\tstruct exfat_dentry *dentry;\n\tbool ret = true;\n\tuint16_t checksum;\n\n\tif (check_clus_chain(exfat, node))\n\t\treturn false;\n\n\tif (node->size > le32_to_cpu(exfat->bs->bsx.clu_count) *\n\t\t\t\t(uint64_t)exfat->clus_size) {\n\t\tresolve_path_parent(&path_resolve_ctx, iter->parent, node);\n\t\texfat_err(\"size %\" PRIu64 \" is greater than cluster heap: %s\\n\",\n\t\t\t\tnode->size, path_resolve_ctx.local_path);\n\t\tret = false;\n\t}\n\n\tif (node->size == 0 && node->is_contiguous) {\n\t\tresolve_path_parent(&path_resolve_ctx, iter->parent, node);\n\t\texfat_err(\"empty, but marked as contiguous: %s\\n\",\n\t\t\t\t\tpath_resolve_ctx.local_path);\n\t\tret = false;\n\t}\n\n\tif ((node->attr & ATTR_SUBDIR) &&\n\t\t\tnode->size % exfat->clus_size != 0) {\n\t\tresolve_path_parent(&path_resolve_ctx, iter->parent, node);\n\t\texfat_err(\"directory size %\" PRIu64 \" is not divisible by %d: %s\\n\",\n\t\t\t\tnode->size, exfat->clus_size,\n\t\t\t\tpath_resolve_ctx.local_path);\n\t\tret = false;\n\t}\n\n\tchecksum = file_calc_checksum(iter);\n\texfat_de_iter_get(iter, 0, &dentry);\n\tif (checksum != le16_to_cpu(dentry->file_checksum)) {\n\t\tif (repair_file_ask(iter, node, ER_DE_CHECKSUM,\n\t\t\t\t\"the checksum of a file is wrong\")) {\n\t\t\texfat_de_iter_get_dirty(iter, 0, &dentry);\n\t\t\tdentry->file_checksum = cpu_to_le16(checksum);\n\t\t} else\n\t\t\tret = false;\n\t}\n\n\treturn ret;\n}", "line_changes": {"deleted": [{"line_no": 12, "char_start": 296, "char_end": 320, "line": "\t\t\t\texfat->clus_size) {\n"}], "added": [{"line_no": 12, "char_start": 296, "char_end": 330, "line": "\t\t\t\t(uint64_t)exfat->clus_size) {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 300, "char_end": 310, "chars": "(uint64_t)"}]}, "commit_link": "github.com/exfatprogs/exfatprogs/commit/c1f48157c38df8d958ab81012abae2470750a785", "file_name": "fsck.c", "vul_type": "cwe-190", "commit_msg": "fsck: fix integer overflow in calculating size\n\nThe size must be 64-bit integer\n\nSigned-off-by: Hyunchul Lee <hyc.lee@gmail.com>", "parent_commit": "edf7a39b7252f4b63915292420aaa63a750f22d9", "description": "Write a C function to validate and potentially repair an inode in an exFAT file system."}
{"func_name": "VerifyMAC", "func_src_before": "func (m *wrappedMAC) VerifyMAC(mac, data []byte) error {\n\t// This also rejects raw MAC with size of 4 bytes or fewer. Those MACs are\n\t// clearly insecure, thus should be discouraged.\n\tprefixSize := cryptofmt.NonRawPrefixSize\n\tif len(mac) <= prefixSize {\n\t\treturn errInvalidMAC\n\t}\n\n\t// try non raw keys\n\tprefix := mac[:prefixSize]\n\tmacNoPrefix := mac[prefixSize:]\n\tentries, err := m.ps.EntriesForPrefix(string(prefix))\n\tif err == nil {\n\t\tfor i := 0; i < len(entries); i++ {\n\t\t\tentry := entries[i]\n\t\t\tp, ok := (entry.Primitive).(tink.MAC)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"mac_factory: not an MAC primitive\")\n\t\t\t}\n\t\t\tif entry.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\t\t\td := data\n\t\t\t\tif len(d) == maxInt {\n\t\t\t\t\treturn fmt.Errorf(\"mac_factory: data too long\")\n\t\t\t\t}\n\t\t\t\tdata = make([]byte, 0, len(d)+1)\n\t\t\t\tdata = append(data, d...)\n\t\t\t\tdata = append(data, byte(0))\n\t\t\t}\n\t\t\tif err = p.VerifyMAC(macNoPrefix, data); err == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// try raw keys\n\tentries, err = m.ps.RawEntries()\n\tif err == nil {\n\t\tfor i := 0; i < len(entries); i++ {\n\t\t\tp, ok := (entries[i].Primitive).(tink.MAC)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"mac_factory: not an MAC primitive\")\n\t\t\t}\n\n\t\t\tif err = p.VerifyMAC(mac, data); err == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// nothing worked\n\treturn errInvalidMAC\n}", "func_src_after": "func (m *wrappedMAC) VerifyMAC(mac, data []byte) error {\n\t// This also rejects raw MAC with size of 4 bytes or fewer. Those MACs are\n\t// clearly insecure, thus should be discouraged.\n\tprefixSize := cryptofmt.NonRawPrefixSize\n\tif len(mac) <= prefixSize {\n\t\treturn errInvalidMAC\n\t}\n\n\t// try non raw keys\n\tprefix := mac[:prefixSize]\n\tmacNoPrefix := mac[prefixSize:]\n\tentries, err := m.ps.EntriesForPrefix(string(prefix))\n\tif err == nil {\n\t\tfor i := 0; i < len(entries); i++ {\n\t\t\tentry := entries[i]\n\t\t\tp, ok := (entry.Primitive).(tink.MAC)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"mac_factory: not an MAC primitive\")\n\t\t\t}\n\t\t\tif entry.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\t\t\td := data\n\t\t\t\tif len(d) >= maxInt {\n\t\t\t\t\treturn fmt.Errorf(\"mac_factory: data too long\")\n\t\t\t\t}\n\t\t\t\tdata = make([]byte, 0, len(d)+1)\n\t\t\t\tdata = append(data, d...)\n\t\t\t\tdata = append(data, byte(0))\n\t\t\t}\n\t\t\tif err = p.VerifyMAC(macNoPrefix, data); err == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// try raw keys\n\tentries, err = m.ps.RawEntries()\n\tif err == nil {\n\t\tfor i := 0; i < len(entries); i++ {\n\t\t\tp, ok := (entries[i].Primitive).(tink.MAC)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"mac_factory: not an MAC primitive\")\n\t\t\t}\n\n\t\t\tif err = p.VerifyMAC(mac, data); err == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// nothing worked\n\treturn errInvalidMAC\n}", "line_changes": {"deleted": [{"line_no": 22, "char_start": 686, "char_end": 712, "line": "\t\t\t\tif len(d) == maxInt {\n"}], "added": [{"line_no": 22, "char_start": 686, "char_end": 712, "line": "\t\t\t\tif len(d) >= maxInt {\n"}]}, "char_changes": {"deleted": [{"char_start": 700, "char_end": 701, "chars": "="}], "added": [{"char_start": 700, "char_end": 701, "chars": ">"}]}, "commit_link": "github.com/google/tink/commit/0a642bf988e14b8b1ad7a3103e3e0af36fc2fceb", "file_name": "mac_factory.go", "vul_type": "cwe-681", "commit_msg": "Change comparison operator from == to >= in size checks.\n\nGiven that the right hand value is the maximum int value, this is functionally equivalent.\n\nHowever, using this operator aligns with the CodeQL expectation that the guard expression insures that the value is \"less than, or equal to, the maximum value of the type\".\n\nReferences:\nhttps://github.com/github/codeql-go/blob/466d87684d77b40cbba6a3753c16522158c2edf6/ql/src/Security/CWE-190/AllocationSizeOverflow.qhelp#L26-L27\n\nhttps://github.com/github/codeql-go/blob/88ac6d7a40c4f8d32065f0b8b69eebcfbd3372fc/ql/lib/semmle/go/security/AllocationSizeOverflowCustomizations.qll#L78\n\nPiperOrigin-RevId: 436411940", "parent_commit": "19ed77922492f1f97abc7876ef5ace8879f2cd9f", "description": "Write a Go function to verify a MAC (Message Authentication Code) against given data."}
{"func_name": "_thp_job_create", "func_src_before": "static thp_job_t *_thp_job_create(thp_fun fun_p, void *arg)\n{\n    thp_job_t *tj = malloc(sizeof(thp_job_t));\n    tj->fun = fun_p;\n    tj->fun_param = arg;\n    return tj;\n}", "func_src_after": "static thp_job_t *_thp_job_create(thp_fun fun_p, void *arg)\n{\n    thp_job_t *tj = malloc(sizeof(thp_job_t));\n\tif ( tj == NULL ) {\n\t\treturn NULL;\n\t}\n    tj->fun = fun_p;\n    tj->fun_param = arg;\n    return tj;\n}", "commit_link": "github.com/paulborile/clibs/commit/2149eb619f203ae91833c0a84f59be9e03c79762", "file_name": "libthp/thp.c", "vul_type": "cwe-476", "description": "Write a C function named `_thp_job_create` that initializes a `thp_job_t` structure with a function pointer and an argument, handling memory allocation."}
