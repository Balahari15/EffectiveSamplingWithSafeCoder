{"func_name": "likeComments", "func_src_before": "    def likeComments(self,commentid,userid):\n        sqlText=\"insert into comment_like values(%d,%d);\"%(userid,commentid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def likeComments(self,commentid,userid):\n        sqlText=\"insert into comment_like values(%s,%s);\"\n        params=[userid,commentid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a user's like for a comment into a database."}
{"func_name": "add_inverters", "func_src_before": "    def add_inverters(self):\n        interfaces = self.config.get_connection_interfaces()\n        for source in interfaces:\n            if source[\"type\"] == \"inverter\":\n\n                query = '''\n                    INSERT OR IGNORE INTO Inverters (\n                        Serial,\n                        EToday,\n                        ETotal\n                    ) VALUES (\n                        %s,\n                        %s,\n                        %s\n                    );\n                ''' % (source[\"serial_id\"], 0, source[\"prev_etotal\"])\n                self.c.execute(query)\n\n                query = '''\n                    UPDATE Inverters\n                    SET     \n                        Name='%s', \n                        Type='%s', \n                        SW_Version='%s', \n                        Status='%s',\n                        TimeStamp='%s'\n                    WHERE Serial='%s';\n                ''' % (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] )\n                self.c.execute(query)\n\n                self.db.commit()", "func_src_after": "    def add_inverters(self):\n        interfaces = self.config.get_connection_interfaces()\n        for source in interfaces:\n            if source[\"type\"] == \"inverter\":\n\n                query = '''\n                    INSERT OR IGNORE INTO Inverters (\n                        Serial,\n                        EToday,\n                        ETotal\n                    ) VALUES (\n                        ?,\n                        ?,\n                        ?\n                    );\n                '''\n                self.c.execute(query, (source[\"serial_id\"], 0, source[\"prev_etotal\"]))\n\n                query = '''\n                    UPDATE Inverters\n                    SET     \n                        Name=?, \n                        Type=?, \n                        SW_Version=?, \n                        Status=?,\n                        TimeStamp=?\n                    WHERE Serial=?;\n                '''\n                self.c.execute(query, (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] ))\n\n                self.db.commit()", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert or update inverter data into a database using either string formatting or parameter substitution."}
{"func_name": "delete", "func_src_before": "@mod.route('/delete/<int:msg_id>', methods=['GET', 'POST'])\ndef delete(msg_id):\n    if request.method == 'GET':\n        sql = \"DELETE FROM message where msg_id = '%d';\" % (msg_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('show_entries'))", "func_src_after": "@mod.route('/delete/<int:msg_id>', methods=['GET', 'POST'])\ndef delete(msg_id):\n    if request.method == 'GET':\n        cursor.execute(\"DELETE FROM message where msg_id = %s;\", (msg_id,))\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('show_entries'))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to delete a message by ID from a database and redirect with a success message."}
{"func_name": "karma_rank", "func_src_before": "def karma_rank(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT (SELECT COUNT(*) FROM people AS t2 WHERE t2.karma > t1.karma)\n            AS row_Num FROM people AS t1 WHERE name='{}'\n        '''.format(name))\n        rank = cursor.fetchone()[0] + 1\n        logger.debug('Rank of {} found for name {}'.format(rank, name))\n        db.close()\n        return rank\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def karma_rank(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT (SELECT COUNT(*) FROM people AS t2 WHERE t2.karma > t1.karma)\n            AS row_Num FROM people AS t1 WHERE name=%(name)s\n        ''', (name, ))\n        rank = cursor.fetchone()[0] + 1\n        logger.debug('Rank of {} found for name {}'.format(rank, name))\n        db.close()\n        return rank\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to calculate and return a user's rank based on their karma score from a database."}
{"func_name": "get_last_month", "func_src_before": "def get_last_month(db, scene):\n    sql = \"select date from matches where scene='{}' order by date desc limit 1;\".format(scene)\n    res = db.exec(sql)\n    date = res[0][0]\n\n    # If it has been more than 1 month since this last tournament,\n    # go ahead and round this date up by a 1 month\n    # eg, if the last tournament was 2015-01-15 (a long time ago)\n    # we can assume the scene won't have more tournaments\n    # So just round to 2015-02-01\n    today = datetime.datetime.today().strftime('%Y-%m-%d')\n    y, m, d = today.split('-')\n    cy, cm, cd = date.split('-')\n    if y > cy or m > cm:\n        # Add 1 to the month before we return\n        # eg 2018-03-01 -> 2018-04-01\n        date = get_next_month(date)\n\n    return date", "func_src_after": "def get_last_month(db, scene):\n    sql = \"select date from matches where scene='{scene}' order by date desc limit 1;\"\n    args = {'scene': scene}\n    res = db.exec(sql, args)\n    date = res[0][0]\n\n    # If it has been more than 1 month since this last tournament,\n    # go ahead and round this date up by a 1 month\n    # eg, if the last tournament was 2015-01-15 (a long time ago)\n    # we can assume the scene won't have more tournaments\n    # So just round to 2015-02-01\n    today = datetime.datetime.today().strftime('%Y-%m-%d')\n    y, m, d = today.split('-')\n    cy, cm, cd = date.split('-')\n    if y > cy or m > cm:\n        # Add 1 to the month before we return\n        # eg 2018-03-01 -> 2018-04-01\n        date = get_next_month(date)\n\n    return date", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "In Python, write a function to retrieve the date of the last match from a database for a given scene and round it up to the next month if it's more than a month old."}
{"func_name": "achievements_list_player", "func_src_before": "@app.route('/players/<int:player_id>/achievements')\ndef achievements_list_player(player_id):\n    \"\"\"Lists the progress of achievements for a player.\n\n    :param player_id: ID of the player.\n\n    :return:\n        If successful, this method returns a response body with the following structure::\n\n            {\n              \"items\": [\n                {\n                  \"achievement_id\": string,\n                  \"state\": string,\n                  \"current_steps\": integer,\n                  \"create_time\": long,\n                  \"update_time\": long\n                }\n              ]\n            }\n    \"\"\"\n    with db.connection:\n        cursor = db.connection.cursor(db.pymysql.cursors.DictCursor)\n        cursor.execute(\"\"\"SELECT\n                            achievement_id,\n                            current_steps,\n                            state,\n                            UNIX_TIMESTAMP(create_time) as create_time,\n                            UNIX_TIMESTAMP(update_time) as update_time\n                        FROM player_achievements\n                        WHERE player_id = '%s'\"\"\" % player_id)\n\n        return flask.jsonify(items=cursor.fetchall())", "func_src_after": "@app.route('/players/<int:player_id>/achievements')\ndef achievements_list_player(player_id):\n    \"\"\"Lists the progress of achievements for a player.\n\n    :param player_id: ID of the player.\n\n    :return:\n        If successful, this method returns a response body with the following structure::\n\n            {\n              \"items\": [\n                {\n                  \"achievement_id\": string,\n                  \"state\": string,\n                  \"current_steps\": integer,\n                  \"create_time\": long,\n                  \"update_time\": long\n                }\n              ]\n            }\n    \"\"\"\n    with db.connection:\n        cursor = db.connection.cursor(db.pymysql.cursors.DictCursor)\n        cursor.execute(\"\"\"SELECT\n                            achievement_id,\n                            current_steps,\n                            state,\n                            UNIX_TIMESTAMP(create_time) as create_time,\n                            UNIX_TIMESTAMP(update_time) as update_time\n                        FROM player_achievements\n                        WHERE player_id = %s\"\"\", player_id)\n\n        return flask.jsonify(items=cursor.fetchall())", "commit_link": "github.com/FAForever/api/commit/5fe7f23868cd191616b088bdd5b24010f004dd5a", "file_name": "api/achievements.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint to list a player's achievements using their ID."}
{"func_name": "check_if_this_project_is_in_database", "func_src_before": "    def check_if_this_project_is_in_database(self, project_id):\n        self.cursor.execute(\"SELECT count(id) FROM projects where id = %s\" % project_id)\n        return self.cursor.fetchall()[0][0] == 1", "func_src_after": "    def check_if_this_project_is_in_database(self, project_id):\n        self.cursor.execute(\"SELECT count(id) FROM projects where id = %s\", (project_id,))\n        return self.cursor.fetchall()[0][0] == 1", "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089", "description": "Write a Python function to determine if a project with a given ID exists in a database."}
{"func_name": "edit_page", "func_src_before": "@app.route(\"/<page_name>/edit\")\ndef edit_page(page_name):\n    query = db.query(\"select * from page where title = '%s'\" % page_name).namedresult()\n    if len(query) == 0:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query\n        )\n    else:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query[0]\n        )", "func_src_after": "@app.route(\"/<page_name>/edit\")\ndef edit_page(page_name):\n    query = db.query(\"select * from page where title = $1\", page_name).namedresult()\n    if len(query) == 0:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query\n        )\n    else:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query[0]\n        )", "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to edit a page by its name, fetching data from a database and rendering an HTML template with the query result."}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    cursor.execute(\"INSERT INTO playsRecord (winner, loser) VALUES ('%s', '%s')\" % (winner, loser));\n    conn.commit()\n    conn.close()", "func_src_after": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    query = \"INSERT INTO playsRecord (winner, loser) VALUES (%s, %s);\"\n    cursor.execute(query, (winner, loser));\n    conn.commit()\n    conn.close()", "commit_link": "github.com/sarahkcaplan/tournament/commit/40aba5686059f5f398f6323b1483412c56140cc0", "file_name": "tournament.py", "vul_type": "cwe-089", "description": "Write a Python function to insert the winner and loser player IDs into a database after a match."}
{"func_name": "get_game_info", "func_src_before": "def get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\" % game)\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)", "func_src_after": "def get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\", (game,))\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/common.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch and return basic game information from a database given a game ID."}
{"func_name": "process_as_reply", "func_src_before": "def process_as_reply(email_obj):\n    job_number = email_obj['subject'].split(': #')[1]\n    feedback = re.findall(\"^[\\W]*([Oo\\d]){1}(?=[\\W]*)\", email_obj['content'].replace('#','').replace('link', ''))[0]\n    feedback = int(0 if feedback == ('O' or 'o') else feedback)\n    dcn_key = re.findall('\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}', email_obj['content'])[0]\n    logger.info(f\"got feedback `{feedback}` for job #`{job_number}`\")\n    with create_connection() as conn:\n        was_prev_closed = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn).iloc[0].closed\n    if was_prev_closed:\n        logger.info(f\"job was already matched successfully and logged as `closed`... skipping.\")\n        return\n    if feedback == 1:\n        logger.info(f\"got feeback that DCN key {dcn_key} was correct\")\n        update_status_query = \"UPDATE df_dilfo SET closed = 1 WHERE job_number = {}\"\n        with create_connection() as conn:\n            conn.cursor().execute(update_status_query.format(job_number))\n        logger.info(f\"updated df_dilfo to show `closed` status for job #{job_number}\")\n    with create_connection() as conn:\n        df = pd.read_sql(\"SELECT * FROM df_matched\", conn)\n        match_dict_input = {\n            'job_number': job_number,\n            'dcn_key': dcn_key,\n            'ground_truth': 1 if feedback == 1 else 0,\n            'multi_phase': 1 if feedback == 2 else 0,\n            'verifier': email_obj[\"sender\"],\n            'source': 'feedback',\n            'log_date': str(datetime.datetime.now().date()),\n            'validate': 0,\n        }\n        df = df.append(match_dict_input, ignore_index=True)\n        df = df.drop_duplicates(subset=[\"job_number\", \"dcn_key\"], keep='last')\n        df.to_sql('df_matched', conn, if_exists='replace', index=False)\n        logger.info(\n            f\"DCN key `{dcn_key}` was a \"\n            f\"{'successful match' if feedback == 1 else 'mis-match'} for job \"\n            f\"#{job_number}\"\n        )", "func_src_after": "def process_as_reply(email_obj):\n    job_number = email_obj['subject'].split(': #')[1]\n    feedback = re.findall(\"^[\\W]*([Oo\\d]){1}(?=[\\W]*)\", email_obj['content'].replace('#','').replace('link', ''))[0]\n    feedback = int(0 if feedback == ('O' or 'o') else feedback)\n    dcn_key = re.findall('\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}', email_obj['content'])[0]\n    logger.info(f\"got feedback `{feedback}` for job #`{job_number}`\")\n    with create_connection() as conn:\n        was_prev_closed = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number]).iloc[0].closed\n    if was_prev_closed:\n        logger.info(f\"job was already matched successfully and logged as `closed`... skipping.\")\n        return\n    if feedback == 1:\n        logger.info(f\"got feeback that DCN key {dcn_key} was correct\")\n        update_status_query = \"UPDATE df_dilfo SET closed = 1 WHERE job_number = ?\"\n        with create_connection() as conn:\n            conn.cursor().execute(update_status_query, [job_number])\n        logger.info(f\"updated df_dilfo to show `closed` status for job #{job_number}\")\n    with create_connection() as conn:\n        df = pd.read_sql(\"SELECT * FROM df_matched\", conn)\n        match_dict_input = {\n            'job_number': job_number,\n            'dcn_key': dcn_key,\n            'ground_truth': 1 if feedback == 1 else 0,\n            'multi_phase': 1 if feedback == 2 else 0,\n            'verifier': email_obj[\"sender\"],\n            'source': 'feedback',\n            'log_date': str(datetime.datetime.now().date()),\n            'validate': 0,\n        }\n        df = df.append(match_dict_input, ignore_index=True)\n        df = df.drop_duplicates(subset=[\"job_number\", \"dcn_key\"], keep='last')\n        df.to_sql('df_matched', conn, if_exists='replace', index=False)\n        logger.info(\n            f\"DCN key `{dcn_key}` was a \"\n            f\"{'successful match' if feedback == 1 else 'mis-match'} for job \"\n            f\"#{job_number}\"\n        )", "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "inbox_scanner.py", "vul_type": "cwe-089", "description": "Write a Python function to process email feedback, update job status, and log matches in a database."}
{"func_name": "update_playlist", "func_src_before": "def update_playlist(id, name, db):\n    db.execute(\n        \"UPDATE playlist SET name='{name}' WHERE id={id};\".format(name=name, id=id))", "func_src_after": "def update_playlist(id, name, db):\n    db.execute(\"UPDATE playlist SET name=%s WHERE id=%s;\", (name, id,))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to update the name of a playlist in a database by its ID."}
{"func_name": "get_requested_month", "func_src_before": "    def get_requested_month(self, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, SUM(DayYield) AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN %s AND %s\n            GROUP BY TimeStamp\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (month_start, month_end)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM MonthData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "func_src_after": "    def get_requested_month(self, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, SUM(DayYield) AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN ? AND ?\n            GROUP BY TimeStamp;\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (month_start, month_end)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM MonthData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch and summarize monthly power yield data, including checks for previous and next data availability."}
{"func_name": "retrieve_videos_from_playlist", "func_src_before": "def retrieve_videos_from_playlist(playlist_id, db):\n    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id={playlist_id} ORDER BY position ASC;\".format(\n        playlist_id=playlist_id))\n    rows = db.fetchall()\n    return rows", "func_src_after": "def retrieve_videos_from_playlist(playlist_id, db):\n    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id=%s ORDER BY position ASC;\", (playlist_id,))\n    rows = db.fetchall()\n    return rows", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch video details from a database by playlist ID, sorted by their position."}
{"func_name": "create_playlist", "func_src_before": "def create_playlist(name):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))\n    db.commit()\n    db.close()", "func_src_after": "def create_playlist(name):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))\n    db.commit()\n    db.close()", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "main_test.py", "vul_type": "cwe-089", "description": "Write a Python function to add a new playlist with a default video position to a database."}
{"func_name": "update_video_positions", "func_src_before": "def update_video_positions(removed_position, db):\n    db.execute(\"UPDATE video SET position = position - 1 WHERE position > {removed_position}\".format(\n        removed_position=removed_position))", "func_src_after": "def update_video_positions(removed_position, db):\n    db.execute(\"UPDATE video SET position = position - 1 WHERE position > %s\", (removed_position,))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to decrement the position of videos in a database after a certain position has been removed."}
{"func_name": "_check_camera_tags", "func_src_before": "    @staticmethod\n    def _check_camera_tags(tags):\n        \"\"\"\n        Function that convert stupid code name of a smartphone or camera\n        from EXIF to meaningful one by looking a collation in a special MySQL\n        table For example instead of just Nikon there can be\n        NIKON CORPORATION in EXIF\n\n        :param tags: name of a camera and lens from EXIF\n        :return: list with one or two strings which are name of\n        camera and/or lens. If there is not better name for the gadget\n        in database, function just returns name how it is\n        \"\"\"\n        checked_tags = []\n\n        for tag in tags:\n            if tag:  # If there was this information inside EXIF of the photo\n                tag = str(tag).strip()\n                log.info('Looking up collation for %s', tag)\n                query = ('SELECT right_tag '\n                         'FROM tag_table '\n                         'WHERE wrong_tag=\"{}\"'.format(tag))\n                cursor = db.execute_query(query)\n                if not cursor:\n                    log.error(\"Can't check the tag because of the db error\")\n                    log.warning(\"Tag will stay as is.\")\n                    continue\n                if cursor.rowcount:\n                    # Get appropriate tag from the table\n                    tag = cursor.fetchone()[0]\n                    log.info('Tag after looking up in tag_tables - %s.', tag)\n\n            checked_tags.append(tag)\n        return checked_tags", "func_src_after": "    @staticmethod\n    def _check_camera_tags(tags):\n        \"\"\"\n        Function that convert stupid code name of a smartphone or camera\n        from EXIF to meaningful one by looking a collation in a special MySQL\n        table For example instead of just Nikon there can be\n        NIKON CORPORATION in EXIF\n\n        :param tags: name of a camera and lens from EXIF\n        :return: list with one or two strings which are name of\n        camera and/or lens. If there is not better name for the gadget\n        in database, function just returns name how it is\n        \"\"\"\n        checked_tags = []\n\n        for tag in tags:\n            if tag:  # If there was this information inside EXIF of the photo\n                tag = str(tag).strip()\n                log.info('Looking up collation for %s', tag)\n                query = ('SELECT right_tag '\n                         'FROM tag_table '\n                         'WHERE wrong_tag=%s')\n                parameters = tag,\n                cursor = db.execute_query(query, parameters)\n                if not cursor:\n                    log.error(\"Can't check the tag because of the db error\")\n                    log.warning(\"Tag will stay as is.\")\n                    continue\n                if cursor.rowcount:\n                    # Get appropriate tag from the table\n                    tag = cursor.fetchone()[0]\n                    log.info('Tag after looking up in tag_tables - %s.', tag)\n\n            checked_tags.append(tag)\n        return checked_tags", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/process_image.py", "vul_type": "cwe-089", "description": "Write a Python function that replaces camera tag names with corrected versions from a MySQL database, returning the updated list of tags."}
{"func_name": "add_input", "func_src_before": "\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\t# The following introduces a deliberate security flaw.See section on SQL injection below\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES('{}');\".format(data)\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "func_src_after": "\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\t# The following introduces a deliberate security flaw.See section on SQL injection below\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES (%s);\"\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query, data)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "commit_link": "github.com/fangyansun/crimemap/commit/a3ab652c214f801c2910e2f96e4de18848de58ae", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function named `add_input` that inserts user-provided data into a database table named 'crimes', intentionally using insecure query formatting to demonstrate SQL injection vulnerability."}
{"func_name": "getResults", "func_src_before": "def getResults(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options from {} where name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    options_str = queryOne(c, req)\n\n    if not options_str:\n        raise LookupError(\"Poll '{}' not found in DB\".format(poll_name))\n\n    total = 0\n    options = options_str.split(\",\")\n    results = dict()\n    for opt in options:\n        count = getOptionCount(c, poll_name, opt)\n        total += int(count)\n        results.update({opt:count})\n\n    conn.close()\n    return (results, total)", "func_src_after": "def getResults(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options from {} where name=?\".format(CFG(\"poll_table_name\"))\n    options_str = queryOne(c, req, (poll_name,))\n\n    if not options_str:\n        raise LookupError(\"Poll '{}' not found in DB\".format(poll_name))\n\n    total = 0\n    options = options_str.split(\",\")\n    results = dict()\n    for opt in options:\n        count = getOptionCount(c, poll_name, opt)\n        total += int(count)\n        results.update({opt:count})\n\n    conn.close()\n    return (results, total)", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getResults` that retrieves and counts poll options from a database given a `poll_name`."}
{"func_name": "update_sources", "func_src_before": "def update_sources(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the source table.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    old_sources = get_all_old_sources(conn, sqlite)\n\n    # Check if the source table is allready filled and this is not the first checkup\n    source_table_is_filled = len(old_sources) > 100\n\n    for old_source in old_sources:\n        if source_table_is_filled and old_source not in current_sources:\n            message = \"Die SID %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die SID aus der Datenbank loeschen.\" % old_source\n            send_message(message)\n\n    for current_source in current_sources:\n        if current_source not in old_sources:\n            message = \"The source %s is new in Solr.\" % current_source\n            if source_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO source (source) VALUES (%s)\" % current_source\n            sqlite.execute(sql)\n            conn.commit()", "func_src_after": "def update_sources(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the source table.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    old_sources = get_all_old_sources(conn, sqlite)\n\n    # Check if the source table is allready filled and this is not the first checkup\n    source_table_is_filled = len(old_sources) > 100\n\n    for old_source in old_sources:\n        if source_table_is_filled and old_source not in current_sources:\n            message = \"Die SID %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die SID aus der Datenbank loeschen.\" % old_source\n            send_message(message)\n\n    for current_source in current_sources:\n        if current_source not in old_sources:\n            message = \"The source %s is new in Solr.\" % current_source\n            if source_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO source (source) VALUES (?)\"\n            sqlite.execute(sql, (current_source,))\n            conn.commit()", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to update a database table with new source entries and notify about discrepancies between old and current sources."}
{"func_name": "search_make_new", "func_src_before": "search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n\tconst size_t base_len = strlen(base_name);\n\tconst char need_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n\tstruct search_domain *dom;\n\n\tfor (dom = state->head; dom; dom = dom->next) {\n\t\tif (!n--) {\n\t\t\t/* this is the postfix we want */\n\t\t\t/* the actual postfix string is kept at the end of the structure */\n\t\t\tconst u8 *const postfix = ((u8 *) dom) + sizeof(struct search_domain);\n\t\t\tconst int postfix_len = dom->len;\n\t\t\tchar *const newname = (char *) mm_malloc(base_len + need_to_append_dot + postfix_len + 1);\n\t\t\tif (!newname) return NULL;\n\t\t\tmemcpy(newname, base_name, base_len);\n\t\t\tif (need_to_append_dot) newname[base_len] = '.';\n\t\t\tmemcpy(newname + base_len + need_to_append_dot, postfix, postfix_len);\n\t\t\tnewname[base_len + need_to_append_dot + postfix_len] = 0;\n\t\t\treturn newname;\n\t\t}\n\t}\n\n\t/* we ran off the end of the list and still didn't find the requested string */\n\tEVUTIL_ASSERT(0);\n\treturn NULL; /* unreachable; stops warnings in some compilers. */\n}", "func_src_after": "search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n\tconst size_t base_len = strlen(base_name);\n\tchar need_to_append_dot;\n\tstruct search_domain *dom;\n\n\tif (!base_len) return NULL;\n\tneed_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n\n\tfor (dom = state->head; dom; dom = dom->next) {\n\t\tif (!n--) {\n\t\t\t/* this is the postfix we want */\n\t\t\t/* the actual postfix string is kept at the end of the structure */\n\t\t\tconst u8 *const postfix = ((u8 *) dom) + sizeof(struct search_domain);\n\t\t\tconst int postfix_len = dom->len;\n\t\t\tchar *const newname = (char *) mm_malloc(base_len + need_to_append_dot + postfix_len + 1);\n\t\t\tif (!newname) return NULL;\n\t\t\tmemcpy(newname, base_name, base_len);\n\t\t\tif (need_to_append_dot) newname[base_len] = '.';\n\t\t\tmemcpy(newname + base_len + need_to_append_dot, postfix, postfix_len);\n\t\t\tnewname[base_len + need_to_append_dot + postfix_len] = 0;\n\t\t\treturn newname;\n\t\t}\n\t}\n\n\t/* we ran off the end of the list and still didn't find the requested string */\n\tEVUTIL_ASSERT(0);\n\treturn NULL; /* unreachable; stops warnings in some compilers. */\n}", "commit_link": "github.com/libevent/libevent/commit/ec65c42052d95d2c23d1d837136d1cf1d9ecef9e", "file_name": "evdns.c", "vul_type": "cwe-125", "description": "Write a C function named `search_make_new` that appends a domain postfix to a base name from a list of search domains, given an index `n`."}
{"func_name": "TS_OBJ_print_bio", "func_src_before": "int TS_OBJ_print_bio(BIO *bio, const ASN1_OBJECT *obj)\n{\n    char obj_txt[128];\n\n    int len = OBJ_obj2txt(obj_txt, sizeof(obj_txt), obj, 0);\n    BIO_write(bio, obj_txt, len);\n    BIO_write(bio, \"\\n\", 1);\n\n    return 1;\n}", "func_src_after": "int TS_OBJ_print_bio(BIO *bio, const ASN1_OBJECT *obj)\n{\n    char obj_txt[128];\n\n    OBJ_obj2txt(obj_txt, sizeof(obj_txt), obj, 0);\n    BIO_printf(bio, \"%s\\n\", obj_txt);\n\n    return 1;\n}", "commit_link": "github.com/openssl/openssl/commit/0ed26acce328ec16a3aa635f1ca37365e8c7403a", "file_name": "crypto/ts/ts_lib.c", "vul_type": "cwe-125", "description": "Write a C function named `TS_OBJ_print_bio` that converts an ASN1_OBJECT to text and prints it to a BIO stream."}
{"func_name": "main", "func_src_before": "int main(int argc, char *argv[])\n{\n    FILE *iplist = NULL;\n    plist_t root_node = NULL;\n    char *plist_out = NULL;\n    uint32_t size = 0;\n    int read_size = 0;\n    char *plist_entire = NULL;\n    struct stat filestats;\n    options_t *options = parse_arguments(argc, argv);\n\n    if (!options)\n    {\n        print_usage(argc, argv);\n        return 0;\n    }\n\n    // read input file\n    iplist = fopen(options->in_file, \"rb\");\n    if (!iplist) {\n        free(options);\n        return 1;\n    }\n\n    stat(options->in_file, &filestats);\n    plist_entire = (char *) malloc(sizeof(char) * (filestats.st_size + 1));\n    read_size = fread(plist_entire, sizeof(char), filestats.st_size, iplist);\n    fclose(iplist);\n\n    // convert from binary to xml or vice-versa\n    if (memcmp(plist_entire, \"bplist00\", 8) == 0)\n    {\n        plist_from_bin(plist_entire, read_size, &root_node);\n        plist_to_xml(root_node, &plist_out, &size);\n    }\n    else\n    {\n        plist_from_xml(plist_entire, read_size, &root_node);\n        plist_to_bin(root_node, &plist_out, &size);\n    }\n    plist_free(root_node);\n    free(plist_entire);\n\n    if (plist_out)\n    {\n        if (options->out_file != NULL)\n        {\n            FILE *oplist = fopen(options->out_file, \"wb\");\n            if (!oplist) {\n                free(options);\n                return 1;\n            }\n            fwrite(plist_out, size, sizeof(char), oplist);\n            fclose(oplist);\n        }\n        // if no output file specified, write to stdout\n        else\n            fwrite(plist_out, size, sizeof(char), stdout);\n\n        free(plist_out);\n    }\n    else\n        printf(\"ERROR: Failed to convert input file.\\n\");\n\n    free(options);\n    return 0;\n}", "func_src_after": "int main(int argc, char *argv[])\n{\n    FILE *iplist = NULL;\n    plist_t root_node = NULL;\n    char *plist_out = NULL;\n    uint32_t size = 0;\n    int read_size = 0;\n    char *plist_entire = NULL;\n    struct stat filestats;\n    options_t *options = parse_arguments(argc, argv);\n\n    if (!options)\n    {\n        print_usage(argc, argv);\n        return 0;\n    }\n\n    // read input file\n    iplist = fopen(options->in_file, \"rb\");\n    if (!iplist) {\n        free(options);\n        return 1;\n    }\n\n    stat(options->in_file, &filestats);\n\n    if (filestats.st_size < 8) {\n        printf(\"ERROR: Input file is too small to contain valid plist data.\\n\");\n        return -1;\n    }\n\n    plist_entire = (char *) malloc(sizeof(char) * (filestats.st_size + 1));\n    read_size = fread(plist_entire, sizeof(char), filestats.st_size, iplist);\n    fclose(iplist);\n\n    // convert from binary to xml or vice-versa\n    if (memcmp(plist_entire, \"bplist00\", 8) == 0)\n    {\n        plist_from_bin(plist_entire, read_size, &root_node);\n        plist_to_xml(root_node, &plist_out, &size);\n    }\n    else\n    {\n        plist_from_xml(plist_entire, read_size, &root_node);\n        plist_to_bin(root_node, &plist_out, &size);\n    }\n    plist_free(root_node);\n    free(plist_entire);\n\n    if (plist_out)\n    {\n        if (options->out_file != NULL)\n        {\n            FILE *oplist = fopen(options->out_file, \"wb\");\n            if (!oplist) {\n                free(options);\n                return 1;\n            }\n            fwrite(plist_out, size, sizeof(char), oplist);\n            fclose(oplist);\n        }\n        // if no output file specified, write to stdout\n        else\n            fwrite(plist_out, size, sizeof(char), stdout);\n\n        free(plist_out);\n    }\n    else\n        printf(\"ERROR: Failed to convert input file.\\n\");\n\n    free(options);\n    return 0;\n}", "commit_link": "github.com/libimobiledevice/libplist/commit/7391a506352c009fe044dead7baad9e22dd279ee", "file_name": "tools/plistutil.c", "vul_type": "cwe-125", "description": "Write a C program that converts a plist file from binary to XML format or vice versa, based on the input file's format, and handles command-line arguments for input and output file paths."}
{"func_name": "AirPDcapDecryptWPABroadcastKey", "func_src_before": "AirPDcapDecryptWPABroadcastKey(const EAPOL_RSN_KEY *pEAPKey, guint8 *decryption_key, PAIRPDCAP_SEC_ASSOCIATION sa, guint eapol_len)\n{\n    guint8 key_version;\n    guint8 *key_data;\n    guint8  *szEncryptedKey;\n    guint16 key_bytes_len = 0; /* Length of the total key data field */\n    guint16 key_len;           /* Actual group key length */\n    static AIRPDCAP_KEY_ITEM dummy_key; /* needed in case AirPDcapRsnaMng() wants the key structure */\n    AIRPDCAP_SEC_ASSOCIATION *tmp_sa;\n\n    /* We skip verifying the MIC of the key. If we were implementing a WPA supplicant we'd want to verify, but for a sniffer it's not needed. */\n\n    /* Preparation for decrypting the group key -  determine group key data length */\n    /* depending on whether the pairwise key is TKIP or AES encryption key */\n    key_version = AIRPDCAP_EAP_KEY_DESCR_VER(pEAPKey->key_information[1]);\n    if (key_version == AIRPDCAP_WPA_KEY_VER_NOT_CCMP){\n        /* TKIP */\n        key_bytes_len = pntoh16(pEAPKey->key_length);\n    }else if (key_version == AIRPDCAP_WPA_KEY_VER_AES_CCMP){\n        /* AES */\n        key_bytes_len = pntoh16(pEAPKey->key_data_len);\n\n        /* AES keys must be at least 128 bits = 16 bytes. */\n        if (key_bytes_len < 16) {\n            return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n        }\n    }\n\n    if (key_bytes_len < GROUP_KEY_MIN_LEN || key_bytes_len > eapol_len - sizeof(EAPOL_RSN_KEY)) {\n        return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n    }\n\n    /* Encrypted key is in the information element field of the EAPOL key packet */\n    key_data = (guint8 *)pEAPKey + sizeof(EAPOL_RSN_KEY);\n    szEncryptedKey = (guint8 *)g_memdup(key_data, key_bytes_len);\n\n    DEBUG_DUMP(\"Encrypted Broadcast key:\", szEncryptedKey, key_bytes_len);\n    DEBUG_DUMP(\"KeyIV:\", pEAPKey->key_iv, 16);\n    DEBUG_DUMP(\"decryption_key:\", decryption_key, 16);\n\n    /* We are rekeying, save old sa */\n    tmp_sa=(AIRPDCAP_SEC_ASSOCIATION *)g_malloc(sizeof(AIRPDCAP_SEC_ASSOCIATION));\n    memcpy(tmp_sa, sa, sizeof(AIRPDCAP_SEC_ASSOCIATION));\n    sa->next=tmp_sa;\n\n    /* As we have no concept of the prior association request at this point, we need to deduce the     */\n    /* group key cipher from the length of the key bytes. In WPA this is straightforward as the        */\n    /* keybytes just contain the GTK, and the GTK is only in the group handshake, NOT the M3.          */\n    /* In WPA2 its a little more tricky as the M3 keybytes contain an RSN_IE, but the group handshake  */\n    /* does not. Also there are other (variable length) items in the keybytes which we need to account */\n    /* for to determine the true key length, and thus the group cipher.                                */\n\n    if (key_version == AIRPDCAP_WPA_KEY_VER_NOT_CCMP){\n        guint8 new_key[32];\n        guint8 dummy[256];\n        /* TKIP key */\n        /* Per 802.11i, Draft 3.0 spec, section 8.5.2, p. 97, line 4-8, */\n        /* group key is decrypted using RC4.  Concatenate the IV with the 16 byte EK (PTK+16) to get the decryption key */\n\n        rc4_state_struct rc4_state;\n\n        /* The WPA group key just contains the GTK bytes so deducing the type is straightforward   */\n        /* Note - WPA M3 doesn't contain a group key so we'll only be here for the group handshake */\n        sa->wpa.key_ver = (key_bytes_len >=TKIP_GROUP_KEY_LEN)?AIRPDCAP_WPA_KEY_VER_NOT_CCMP:AIRPDCAP_WPA_KEY_VER_AES_CCMP;\n\n        /* Build the full decryption key based on the IV and part of the pairwise key */\n        memcpy(new_key, pEAPKey->key_iv, 16);\n        memcpy(new_key+16, decryption_key, 16);\n        DEBUG_DUMP(\"FullDecrKey:\", new_key, 32);\n\n        crypt_rc4_init(&rc4_state, new_key, sizeof(new_key));\n\n        /* Do dummy 256 iterations of the RC4 algorithm (per 802.11i, Draft 3.0, p. 97 line 6) */\n        crypt_rc4(&rc4_state, dummy, 256);\n        crypt_rc4(&rc4_state, szEncryptedKey, key_bytes_len);\n\n    } else if (key_version == AIRPDCAP_WPA_KEY_VER_AES_CCMP){\n        /* AES CCMP key */\n\n        guint8 key_found;\n        guint8 key_length;\n        guint16 key_index;\n        guint8 *decrypted_data;\n\n        /* Unwrap the key; the result is key_bytes_len in length */\n        decrypted_data = AES_unwrap(decryption_key, 16, szEncryptedKey,  key_bytes_len);\n\n        /* With WPA2 what we get after Broadcast Key decryption is an actual RSN structure.\n           The key itself is stored as a GTK KDE\n           WPA2 IE (1 byte) id = 0xdd, length (1 byte), GTK OUI (4 bytes), key index (1 byte) and 1 reserved byte. Thus we have to\n           pass pointer to the actual key with 8 bytes offset */\n\n        key_found = FALSE;\n        key_index = 0;\n\n        /* Parse Key data until we found GTK KDE */\n        /* GTK KDE = 00-0F-AC 01 */\n        while(key_index < (key_bytes_len - 6) && !key_found){\n            guint8 rsn_id;\n            guint32 type;\n\n            /* Get RSN ID */\n            rsn_id = decrypted_data[key_index];\n            type = ((decrypted_data[key_index + 2] << 24) +\n                    (decrypted_data[key_index + 3] << 16) +\n                    (decrypted_data[key_index + 4] << 8) +\n                     (decrypted_data[key_index + 5]));\n\n            if (rsn_id == 0xdd && type == 0x000fac01) {\n                key_found = TRUE;\n            } else {\n                key_index += decrypted_data[key_index+1]+2;\n            }\n        }\n\n        if (key_found){\n            key_length = decrypted_data[key_index+1] - 6;\n\n            if (key_index+8 >= key_bytes_len ||\n                key_length > key_bytes_len - key_index - 8) {\n                g_free(decrypted_data);\n                g_free(szEncryptedKey);\n                return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n            }\n\n            /* Skip over the GTK header info, and don't copy past the end of the encrypted data */\n            memcpy(szEncryptedKey, decrypted_data+key_index+8, key_length);\n        } else {\n            g_free(decrypted_data);\n            g_free(szEncryptedKey);\n            return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n        }\n\n        if (key_length == TKIP_GROUP_KEY_LEN)\n            sa->wpa.key_ver = AIRPDCAP_WPA_KEY_VER_NOT_CCMP;\n        else\n            sa->wpa.key_ver = AIRPDCAP_WPA_KEY_VER_AES_CCMP;\n\n        g_free(decrypted_data);\n    }\n\n    key_len = (sa->wpa.key_ver==AIRPDCAP_WPA_KEY_VER_NOT_CCMP)?TKIP_GROUP_KEY_LEN:CCMP_GROUP_KEY_LEN;\n    if (key_len > key_bytes_len) {\n        /* the key required for this protocol is longer than the key that we just calculated */\n        g_free(szEncryptedKey);\n        return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n    }\n\n    /* Decrypted key is now in szEncryptedKey with len of key_len */\n    DEBUG_DUMP(\"Broadcast key:\", szEncryptedKey, key_len);\n\n    /* Load the proper key material info into the SA */\n    sa->key = &dummy_key;  /* we just need key to be not null because it is checked in AirPDcapRsnaMng().  The WPA key materials are actually in the .wpa structure */\n    sa->validKey = TRUE;\n\n    /* Since this is a GTK and its size is only 32 bytes (vs. the 64 byte size of a PTK), we fake it and put it in at a 32-byte offset so the  */\n    /* AirPDcapRsnaMng() function will extract the right piece of the GTK for decryption. (The first 16 bytes of the GTK are used for decryption.) */\n    memset(sa->wpa.ptk, 0, sizeof(sa->wpa.ptk));\n    memcpy(sa->wpa.ptk+32, szEncryptedKey, key_len);\n    g_free(szEncryptedKey);\n    return AIRPDCAP_RET_SUCCESS_HANDSHAKE;\n}", "func_src_after": "AirPDcapDecryptWPABroadcastKey(const EAPOL_RSN_KEY *pEAPKey, guint8 *decryption_key, PAIRPDCAP_SEC_ASSOCIATION sa, guint eapol_len)\n{\n    guint8 key_version;\n    guint8 *key_data;\n    guint8  *szEncryptedKey;\n    guint16 key_bytes_len = 0; /* Length of the total key data field */\n    guint16 key_len;           /* Actual group key length */\n    static AIRPDCAP_KEY_ITEM dummy_key; /* needed in case AirPDcapRsnaMng() wants the key structure */\n    AIRPDCAP_SEC_ASSOCIATION *tmp_sa;\n\n    /* We skip verifying the MIC of the key. If we were implementing a WPA supplicant we'd want to verify, but for a sniffer it's not needed. */\n\n    /* Preparation for decrypting the group key -  determine group key data length */\n    /* depending on whether the pairwise key is TKIP or AES encryption key */\n    key_version = AIRPDCAP_EAP_KEY_DESCR_VER(pEAPKey->key_information[1]);\n    if (key_version == AIRPDCAP_WPA_KEY_VER_NOT_CCMP){\n        /* TKIP */\n        key_bytes_len = pntoh16(pEAPKey->key_length);\n    }else if (key_version == AIRPDCAP_WPA_KEY_VER_AES_CCMP){\n        /* AES */\n        key_bytes_len = pntoh16(pEAPKey->key_data_len);\n\n        /* AES keys must be at least 128 bits = 16 bytes. */\n        if (key_bytes_len < 16) {\n            return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n        }\n    }\n\n    if ((key_bytes_len < GROUP_KEY_MIN_LEN) ||\n        (eapol_len < sizeof(EAPOL_RSN_KEY)) ||\n        (key_bytes_len > eapol_len - sizeof(EAPOL_RSN_KEY))) {\n        return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n    }\n\n    /* Encrypted key is in the information element field of the EAPOL key packet */\n    key_data = (guint8 *)pEAPKey + sizeof(EAPOL_RSN_KEY);\n    szEncryptedKey = (guint8 *)g_memdup(key_data, key_bytes_len);\n\n    DEBUG_DUMP(\"Encrypted Broadcast key:\", szEncryptedKey, key_bytes_len);\n    DEBUG_DUMP(\"KeyIV:\", pEAPKey->key_iv, 16);\n    DEBUG_DUMP(\"decryption_key:\", decryption_key, 16);\n\n    /* We are rekeying, save old sa */\n    tmp_sa=(AIRPDCAP_SEC_ASSOCIATION *)g_malloc(sizeof(AIRPDCAP_SEC_ASSOCIATION));\n    memcpy(tmp_sa, sa, sizeof(AIRPDCAP_SEC_ASSOCIATION));\n    sa->next=tmp_sa;\n\n    /* As we have no concept of the prior association request at this point, we need to deduce the     */\n    /* group key cipher from the length of the key bytes. In WPA this is straightforward as the        */\n    /* keybytes just contain the GTK, and the GTK is only in the group handshake, NOT the M3.          */\n    /* In WPA2 its a little more tricky as the M3 keybytes contain an RSN_IE, but the group handshake  */\n    /* does not. Also there are other (variable length) items in the keybytes which we need to account */\n    /* for to determine the true key length, and thus the group cipher.                                */\n\n    if (key_version == AIRPDCAP_WPA_KEY_VER_NOT_CCMP){\n        guint8 new_key[32];\n        guint8 dummy[256];\n        /* TKIP key */\n        /* Per 802.11i, Draft 3.0 spec, section 8.5.2, p. 97, line 4-8, */\n        /* group key is decrypted using RC4.  Concatenate the IV with the 16 byte EK (PTK+16) to get the decryption key */\n\n        rc4_state_struct rc4_state;\n\n        /* The WPA group key just contains the GTK bytes so deducing the type is straightforward   */\n        /* Note - WPA M3 doesn't contain a group key so we'll only be here for the group handshake */\n        sa->wpa.key_ver = (key_bytes_len >=TKIP_GROUP_KEY_LEN)?AIRPDCAP_WPA_KEY_VER_NOT_CCMP:AIRPDCAP_WPA_KEY_VER_AES_CCMP;\n\n        /* Build the full decryption key based on the IV and part of the pairwise key */\n        memcpy(new_key, pEAPKey->key_iv, 16);\n        memcpy(new_key+16, decryption_key, 16);\n        DEBUG_DUMP(\"FullDecrKey:\", new_key, 32);\n\n        crypt_rc4_init(&rc4_state, new_key, sizeof(new_key));\n\n        /* Do dummy 256 iterations of the RC4 algorithm (per 802.11i, Draft 3.0, p. 97 line 6) */\n        crypt_rc4(&rc4_state, dummy, 256);\n        crypt_rc4(&rc4_state, szEncryptedKey, key_bytes_len);\n\n    } else if (key_version == AIRPDCAP_WPA_KEY_VER_AES_CCMP){\n        /* AES CCMP key */\n\n        guint8 key_found;\n        guint8 key_length;\n        guint16 key_index;\n        guint8 *decrypted_data;\n\n        /* Unwrap the key; the result is key_bytes_len in length */\n        decrypted_data = AES_unwrap(decryption_key, 16, szEncryptedKey,  key_bytes_len);\n\n        /* With WPA2 what we get after Broadcast Key decryption is an actual RSN structure.\n           The key itself is stored as a GTK KDE\n           WPA2 IE (1 byte) id = 0xdd, length (1 byte), GTK OUI (4 bytes), key index (1 byte) and 1 reserved byte. Thus we have to\n           pass pointer to the actual key with 8 bytes offset */\n\n        key_found = FALSE;\n        key_index = 0;\n\n        /* Parse Key data until we found GTK KDE */\n        /* GTK KDE = 00-0F-AC 01 */\n        while(key_index < (key_bytes_len - 6) && !key_found){\n            guint8 rsn_id;\n            guint32 type;\n\n            /* Get RSN ID */\n            rsn_id = decrypted_data[key_index];\n            type = ((decrypted_data[key_index + 2] << 24) +\n                    (decrypted_data[key_index + 3] << 16) +\n                    (decrypted_data[key_index + 4] << 8) +\n                     (decrypted_data[key_index + 5]));\n\n            if (rsn_id == 0xdd && type == 0x000fac01) {\n                key_found = TRUE;\n            } else {\n                key_index += decrypted_data[key_index+1]+2;\n            }\n        }\n\n        if (key_found){\n            key_length = decrypted_data[key_index+1] - 6;\n\n            if (key_index+8 >= key_bytes_len ||\n                key_length > key_bytes_len - key_index - 8) {\n                g_free(decrypted_data);\n                g_free(szEncryptedKey);\n                return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n            }\n\n            /* Skip over the GTK header info, and don't copy past the end of the encrypted data */\n            memcpy(szEncryptedKey, decrypted_data+key_index+8, key_length);\n        } else {\n            g_free(decrypted_data);\n            g_free(szEncryptedKey);\n            return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n        }\n\n        if (key_length == TKIP_GROUP_KEY_LEN)\n            sa->wpa.key_ver = AIRPDCAP_WPA_KEY_VER_NOT_CCMP;\n        else\n            sa->wpa.key_ver = AIRPDCAP_WPA_KEY_VER_AES_CCMP;\n\n        g_free(decrypted_data);\n    }\n\n    key_len = (sa->wpa.key_ver==AIRPDCAP_WPA_KEY_VER_NOT_CCMP)?TKIP_GROUP_KEY_LEN:CCMP_GROUP_KEY_LEN;\n    if (key_len > key_bytes_len) {\n        /* the key required for this protocol is longer than the key that we just calculated */\n        g_free(szEncryptedKey);\n        return AIRPDCAP_RET_NO_VALID_HANDSHAKE;\n    }\n\n    /* Decrypted key is now in szEncryptedKey with len of key_len */\n    DEBUG_DUMP(\"Broadcast key:\", szEncryptedKey, key_len);\n\n    /* Load the proper key material info into the SA */\n    sa->key = &dummy_key;  /* we just need key to be not null because it is checked in AirPDcapRsnaMng().  The WPA key materials are actually in the .wpa structure */\n    sa->validKey = TRUE;\n\n    /* Since this is a GTK and its size is only 32 bytes (vs. the 64 byte size of a PTK), we fake it and put it in at a 32-byte offset so the  */\n    /* AirPDcapRsnaMng() function will extract the right piece of the GTK for decryption. (The first 16 bytes of the GTK are used for decryption.) */\n    memset(sa->wpa.ptk, 0, sizeof(sa->wpa.ptk));\n    memcpy(sa->wpa.ptk+32, szEncryptedKey, key_len);\n    g_free(szEncryptedKey);\n    return AIRPDCAP_RET_SUCCESS_HANDSHAKE;\n}", "commit_link": "github.com/wireshark/wireshark/commit/b6d838eebf4456192360654092e5587c5207f185", "file_name": "epan/crypt/airpdcap.c", "vul_type": "cwe-125", "description": "Write a C function to decrypt WPA broadcast keys from EAPOL packets."}
{"func_name": "AdaptiveThresholdImage", "func_src_before": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const double bias,\n  ExceptionInfo *exception)\n{\n#define AdaptiveThresholdImageTag  \"AdaptiveThreshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickSizeType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  /*\n    Initialize threshold image attributes.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  status=SetImageStorageClass(threshold_image,DirectClass,exception);\n  if (status == MagickFalse)\n    {\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Threshold image.\n  */\n  status=MagickTrue;\n  progress=0;\n  number_pixels=(MagickSizeType) width*height;\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    double\n      channel_bias[MaxPixelChannels],\n      channel_sum[MaxPixelChannels];\n\n    register const Quantum\n      *magick_restrict p,\n      *magick_restrict pixels;\n\n    register Quantum\n      *magick_restrict q;\n\n    register ssize_t\n      i,\n      x;\n\n    ssize_t\n      center,\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      (height/2L),image->columns+width,height,exception);\n    q=QueueCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,\n      1,exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    center=(ssize_t) GetPixelChannels(image)*(image->columns+width)*(height/2L)+\n      GetPixelChannels(image)*(width/2);\n    for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n    {\n      PixelChannel channel = GetPixelChannelChannel(image,i);\n      PixelTrait traits = GetPixelChannelTraits(image,channel);\n      PixelTrait threshold_traits=GetPixelChannelTraits(threshold_image,\n        channel);\n      if ((traits == UndefinedPixelTrait) ||\n          (threshold_traits == UndefinedPixelTrait))\n        continue;\n      if ((threshold_traits & CopyPixelTrait) != 0)\n        {\n          SetPixelChannel(threshold_image,channel,p[center+i],q);\n          continue;\n        }\n      pixels=p;\n      channel_bias[channel]=0.0;\n      channel_sum[channel]=0.0;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        for (u=0; u < (ssize_t) width; u++)\n        {\n          if (u == (ssize_t) (width-1))\n            channel_bias[channel]+=pixels[i];\n          channel_sum[channel]+=pixels[i];\n          pixels+=GetPixelChannels(image);\n        }\n        pixels+=GetPixelChannels(image)*image->columns;\n      }\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        double\n          mean;\n\n        PixelChannel channel = GetPixelChannelChannel(image,i);\n        PixelTrait traits = GetPixelChannelTraits(image,channel);\n        PixelTrait threshold_traits=GetPixelChannelTraits(threshold_image,\n          channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (threshold_traits == UndefinedPixelTrait))\n          continue;\n        if ((threshold_traits & CopyPixelTrait) != 0)\n          {\n            SetPixelChannel(threshold_image,channel,p[center+i],q);\n            continue;\n          }\n        channel_sum[channel]-=channel_bias[channel];\n        channel_bias[channel]=0.0;\n        pixels=p;\n        for (v=0; v < (ssize_t) height; v++)\n        {\n          channel_bias[channel]+=pixels[i];\n          pixels+=(width-1)*GetPixelChannels(image);\n          channel_sum[channel]+=pixels[i];\n          pixels+=GetPixelChannels(image)*(image->columns+1);\n        }\n        mean=(double) (channel_sum[channel]/number_pixels+bias);\n        SetPixelChannel(threshold_image,channel,(Quantum) ((double)\n          p[center+i] <= mean ? 0 : QuantumRange),q);\n      }\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(threshold_image);\n    }\n    if (SyncCacheViewAuthenticPixels(threshold_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,AdaptiveThresholdImageTag,progress,\n          image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_image->type=image->type;\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "func_src_after": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const double bias,\n  ExceptionInfo *exception)\n{\n#define AdaptiveThresholdImageTag  \"AdaptiveThreshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickSizeType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  /*\n    Initialize threshold image attributes.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (width == 0)\n    return(threshold_image);\n  status=SetImageStorageClass(threshold_image,DirectClass,exception);\n  if (status == MagickFalse)\n    {\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Threshold image.\n  */\n  status=MagickTrue;\n  progress=0;\n  number_pixels=(MagickSizeType) width*height;\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    double\n      channel_bias[MaxPixelChannels],\n      channel_sum[MaxPixelChannels];\n\n    register const Quantum\n      *magick_restrict p,\n      *magick_restrict pixels;\n\n    register Quantum\n      *magick_restrict q;\n\n    register ssize_t\n      i,\n      x;\n\n    ssize_t\n      center,\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      (height/2L),image->columns+width,height,exception);\n    q=QueueCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,\n      1,exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    center=(ssize_t) GetPixelChannels(image)*(image->columns+width)*(height/2L)+\n      GetPixelChannels(image)*(width/2);\n    for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n    {\n      PixelChannel channel = GetPixelChannelChannel(image,i);\n      PixelTrait traits = GetPixelChannelTraits(image,channel);\n      PixelTrait threshold_traits=GetPixelChannelTraits(threshold_image,\n        channel);\n      if ((traits == UndefinedPixelTrait) ||\n          (threshold_traits == UndefinedPixelTrait))\n        continue;\n      if ((threshold_traits & CopyPixelTrait) != 0)\n        {\n          SetPixelChannel(threshold_image,channel,p[center+i],q);\n          continue;\n        }\n      pixels=p;\n      channel_bias[channel]=0.0;\n      channel_sum[channel]=0.0;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        for (u=0; u < (ssize_t) width; u++)\n        {\n          if (u == (ssize_t) (width-1))\n            channel_bias[channel]+=pixels[i];\n          channel_sum[channel]+=pixels[i];\n          pixels+=GetPixelChannels(image);\n        }\n        pixels+=GetPixelChannels(image)*image->columns;\n      }\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        double\n          mean;\n\n        PixelChannel channel = GetPixelChannelChannel(image,i);\n        PixelTrait traits = GetPixelChannelTraits(image,channel);\n        PixelTrait threshold_traits=GetPixelChannelTraits(threshold_image,\n          channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (threshold_traits == UndefinedPixelTrait))\n          continue;\n        if ((threshold_traits & CopyPixelTrait) != 0)\n          {\n            SetPixelChannel(threshold_image,channel,p[center+i],q);\n            continue;\n          }\n        channel_sum[channel]-=channel_bias[channel];\n        channel_bias[channel]=0.0;\n        pixels=p;\n        for (v=0; v < (ssize_t) height; v++)\n        {\n          channel_bias[channel]+=pixels[i];\n          pixels+=(width-1)*GetPixelChannels(image);\n          channel_sum[channel]+=pixels[i];\n          pixels+=GetPixelChannels(image)*(image->columns+1);\n        }\n        mean=(double) (channel_sum[channel]/number_pixels+bias);\n        SetPixelChannel(threshold_image,channel,(Quantum) ((double)\n          p[center+i] <= mean ? 0 : QuantumRange),q);\n      }\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(threshold_image);\n    }\n    if (SyncCacheViewAuthenticPixels(threshold_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,AdaptiveThresholdImageTag,progress,\n          image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_image->type=image->type;\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/a7759f410b773a1dd57b0e1fb28112e1cd8b97bc", "file_name": "MagickCore/threshold.c", "vul_type": "cwe-125", "description": "Write a C function in ImageMagick to perform adaptive thresholding on an image."}
{"func_name": "INST_HANDLER", "func_src_before": "INST_HANDLER (lds) {\t// LDS Rd, k\n\tint d = ((buf[0] >> 4) & 0xf) | ((buf[1] & 0x1) << 4);\n\tint k = (buf[3] << 8) | buf[2];\n\top->ptr = k;\n\n\t// load value from RAMPD:k\n\t__generic_ld_st (op, \"ram\", 0, 1, 0, k, 0);\n\tESIL_A (\"r%d,=,\", d);\n}", "func_src_after": "INST_HANDLER (lds) {\t// LDS Rd, k\n\tif (len < 4) {\n\t\treturn;\n\t}\n\tint d = ((buf[0] >> 4) & 0xf) | ((buf[1] & 0x1) << 4);\n\tint k = (buf[3] << 8) | buf[2];\n\top->ptr = k;\n\n\t// load value from RAMPD:k\n\t__generic_ld_st (op, \"ram\", 0, 1, 0, k, 0);\n\tESIL_A (\"r%d,=,\", d);\n}", "commit_link": "github.com/radare/radare2/commit/041e53cab7ca33481ae45ecd65ad596976d78e68", "file_name": "libr/anal/p/anal_avr.c", "vul_type": "cwe-125", "description": "Write a C function named `INST_HANDLER` for the `lds` instruction that loads a value from a specified memory address into a register, handling potential buffer length issues."}
{"func_name": "jpeg_size", "func_src_before": "static int jpeg_size(unsigned char* data, unsigned int data_size,\n                     int *width, int *height)\n{\n    int i = 0;\n    if (i + 3 < data_size && data[i] == 0xFF && data[i+1] == 0xD8 &&\n            data[i+2] == 0xFF && data[i+3] == 0xE0) {\n        i += 4;\n        if(i + 6 < data_size &&\n                data[i+2] == 'J' && data[i+3] == 'F' && data[i+4] == 'I' &&\n                data[i+5] == 'F' && data[i+6] == 0x00) {\n            unsigned short block_length = data[i] * 256 + data[i+1];\n            while(i<data_size) {\n                i+=block_length;\n                if((i + 1) >= data_size)\n                    return -1;\n                if(data[i] != 0xFF)\n                    return -1;\n                if(data[i+1] == 0xC0) {\n                    *height = data[i+5]*256 + data[i+6];\n                    *width = data[i+7]*256 + data[i+8];\n                    return 0;\n                }\n                i+=2;\n                block_length = data[i] * 256 + data[i+1];\n            }\n        }\n    }\n\n    return -1;\n}", "func_src_after": "static int jpeg_size(unsigned char* data, unsigned int data_size,\n                     int *width, int *height)\n{\n    int i = 0;\n    if (i + 3 < data_size && data[i] == 0xFF && data[i+1] == 0xD8 &&\n            data[i+2] == 0xFF && data[i+3] == 0xE0) {\n        i += 4;\n        if(i + 6 < data_size &&\n                data[i+2] == 'J' && data[i+3] == 'F' && data[i+4] == 'I' &&\n                data[i+5] == 'F' && data[i+6] == 0x00) {\n            unsigned short block_length = data[i] * 256 + data[i+1];\n            while(i<data_size) {\n                i+=block_length;\n                if((i + 1) >= data_size)\n                    return -1;\n                if(data[i] != 0xFF)\n                    return -1;\n                if(data[i+1] == 0xC0) {\n                    *height = data[i+5]*256 + data[i+6];\n                    *width = data[i+7]*256 + data[i+8];\n                    return 0;\n                }\n                i+=2;\n                if (i + 1 < data_size)\n                    block_length = data[i] * 256 + data[i+1];\n            }\n        }\n    }\n\n    return -1;\n}", "commit_link": "github.com/AndreRenaud/PDFGen/commit/ee58aff6918b8bbc3be29b9e3089485ea46ff956", "file_name": "pdfgen.c", "vul_type": "cwe-125", "description": "Write a C function to extract the width and height from a JPEG image's binary data."}
{"func_name": "RLEDECOMPRESS", "func_src_before": "static INLINE BOOL RLEDECOMPRESS(const BYTE* pbSrcBuffer, UINT32 cbSrcBuffer, BYTE* pbDestBuffer,\n                                 UINT32 rowDelta, UINT32 width, UINT32 height)\n{\n\tconst BYTE* pbSrc = pbSrcBuffer;\n\tconst BYTE* pbEnd;\n\tconst BYTE* pbDestEnd;\n\tBYTE* pbDest = pbDestBuffer;\n\tPIXEL temp;\n\tPIXEL fgPel = WHITE_PIXEL;\n\tBOOL fInsertFgPel = FALSE;\n\tBOOL fFirstLine = TRUE;\n\tBYTE bitmask;\n\tPIXEL pixelA, pixelB;\n\tUINT32 runLength;\n\tUINT32 code;\n\tUINT32 advance;\n\tRLEEXTRA\n\n\tif ((rowDelta == 0) || (rowDelta < width))\n\t\treturn FALSE;\n\n\tif (!pbSrcBuffer || !pbDestBuffer)\n\t\treturn FALSE;\n\n\tpbEnd = pbSrcBuffer + cbSrcBuffer;\n\tpbDestEnd = pbDestBuffer + rowDelta * height;\n\n\twhile (pbSrc < pbEnd)\n\t{\n\t\t/* Watch out for the end of the first scanline. */\n\t\tif (fFirstLine)\n\t\t{\n\t\t\tif ((UINT32)(pbDest - pbDestBuffer) >= rowDelta)\n\t\t\t{\n\t\t\t\tfFirstLine = FALSE;\n\t\t\t\tfInsertFgPel = FALSE;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t   Extract the compression order code ID from the compression\n\t\t   order header.\n\t\t*/\n\t\tcode = ExtractCodeId(*pbSrc);\n\n\t\t/* Handle Background Run Orders. */\n\t\tif (code == REGULAR_BG_RUN || code == MEGA_MEGA_BG_RUN)\n\t\t{\n\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\tif (fFirstLine)\n\t\t\t{\n\t\t\t\tif (fInsertFgPel)\n\t\t\t\t{\n\t\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, fgPel);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\trunLength = runLength - 1;\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, BLACK_PIXEL);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (fInsertFgPel)\n\t\t\t\t{\n\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\n\t\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp ^ fgPel);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\trunLength--;\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t}\n\n\t\t\t/* A follow-on background run order will need a foreground pel inserted. */\n\t\t\tfInsertFgPel = TRUE;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* For any of the other run-types a follow-on background run\n\t\t    order does not need a foreground pel inserted. */\n\t\tfInsertFgPel = FALSE;\n\n\t\tswitch (code)\n\t\t{\n\t\t\t/* Handle Foreground Run Orders. */\n\t\t\tcase REGULAR_FG_RUN:\n\t\t\tcase MEGA_MEGA_FG_RUN:\n\t\t\tcase LITE_SET_FG_FG_RUN:\n\t\t\tcase MEGA_MEGA_SET_FG_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\t\tif (code == LITE_SET_FG_FG_RUN || code == MEGA_MEGA_SET_FG_RUN)\n\t\t\t\t{\n\t\t\t\t\tSRCREADPIXEL(fgPel, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\t\tDESTWRITEPIXEL(pbDest, fgPel);\n\t\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\t\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp ^ fgPel);\n\t\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Dithered Run Orders. */\n\t\t\tcase LITE_DITHERED_RUN:\n\t\t\tcase MEGA_MEGA_DITHERED_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tSRCREADPIXEL(pixelA, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\tSRCREADPIXEL(pixelB, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength * 2))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelA);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelB);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Color Run Orders. */\n\t\t\tcase REGULAR_COLOR_RUN:\n\t\t\tcase MEGA_MEGA_COLOR_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tSRCREADPIXEL(pixelA, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelA);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Foreground/Background Image Orders. */\n\t\t\tcase REGULAR_FGBG_IMAGE:\n\t\t\tcase MEGA_MEGA_FGBG_IMAGE:\n\t\t\tcase LITE_SET_FG_FGBG_IMAGE:\n\t\t\tcase MEGA_MEGA_SET_FGBG_IMAGE:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\t\tif (code == LITE_SET_FG_FGBG_IMAGE || code == MEGA_MEGA_SET_FGBG_IMAGE)\n\t\t\t\t{\n\t\t\t\t\tSRCREADPIXEL(fgPel, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t}\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\twhile (runLength > 8)\n\t\t\t\t\t{\n\t\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\t\tpbSrc = pbSrc + 1;\n\t\t\t\t\t\tpbDest = WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, bitmask, fgPel, 8);\n\n\t\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\t\trunLength = runLength - 8;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\twhile (runLength > 8)\n\t\t\t\t\t{\n\t\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\t\tpbSrc = pbSrc + 1;\n\t\t\t\t\t\tpbDest = WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, bitmask, fgPel, 8);\n\n\t\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\t\trunLength = runLength - 8;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (runLength > 0)\n\t\t\t\t{\n\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\t\tif (fFirstLine)\n\t\t\t\t\t{\n\t\t\t\t\t\tpbDest =\n\t\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, bitmask, fgPel, runLength);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tpbDest =\n\t\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, bitmask, fgPel, runLength);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\treturn FALSE;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Color Image Orders. */\n\t\t\tcase REGULAR_COLOR_IMAGE:\n\t\t\tcase MEGA_MEGA_COLOR_IMAGE:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tSRCREADPIXEL(temp, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Special Order 1. */\n\t\t\tcase SPECIAL_FGBG_1:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, g_MaskSpecialFgBg1, fgPel, 8);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, g_MaskSpecialFgBg1, fgPel, 8);\n\t\t\t\t}\n\n\t\t\t\tif (!pbDest)\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Special Order 2. */\n\t\t\tcase SPECIAL_FGBG_2:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, g_MaskSpecialFgBg2, fgPel, 8);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, g_MaskSpecialFgBg2, fgPel, 8);\n\t\t\t\t}\n\n\t\t\t\tif (!pbDest)\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle White Order. */\n\t\t\tcase SPECIAL_WHITE:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tDESTWRITEPIXEL(pbDest, WHITE_PIXEL);\n\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Black Order. */\n\t\t\tcase SPECIAL_BLACK:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tDESTWRITEPIXEL(pbDest, BLACK_PIXEL);\n\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\n\treturn TRUE;\n}", "func_src_after": "static INLINE BOOL RLEDECOMPRESS(const BYTE* pbSrcBuffer, UINT32 cbSrcBuffer, BYTE* pbDestBuffer,\n                                 UINT32 rowDelta, UINT32 width, UINT32 height)\n{\n\tconst BYTE* pbSrc = pbSrcBuffer;\n\tconst BYTE* pbEnd;\n\tconst BYTE* pbDestEnd;\n\tBYTE* pbDest = pbDestBuffer;\n\tPIXEL temp;\n\tPIXEL fgPel = WHITE_PIXEL;\n\tBOOL fInsertFgPel = FALSE;\n\tBOOL fFirstLine = TRUE;\n\tBYTE bitmask;\n\tPIXEL pixelA, pixelB;\n\tUINT32 runLength;\n\tUINT32 code;\n\tUINT32 advance;\n\tRLEEXTRA\n\n\tif ((rowDelta == 0) || (rowDelta < width))\n\t\treturn FALSE;\n\n\tif (!pbSrcBuffer || !pbDestBuffer)\n\t\treturn FALSE;\n\n\tpbEnd = pbSrcBuffer + cbSrcBuffer;\n\tpbDestEnd = pbDestBuffer + rowDelta * height;\n\n\twhile (pbSrc < pbEnd)\n\t{\n\t\t/* Watch out for the end of the first scanline. */\n\t\tif (fFirstLine)\n\t\t{\n\t\t\tif ((UINT32)(pbDest - pbDestBuffer) >= rowDelta)\n\t\t\t{\n\t\t\t\tfFirstLine = FALSE;\n\t\t\t\tfInsertFgPel = FALSE;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t   Extract the compression order code ID from the compression\n\t\t   order header.\n\t\t*/\n\t\tcode = ExtractCodeId(*pbSrc);\n\n\t\t/* Handle Background Run Orders. */\n\t\tif (code == REGULAR_BG_RUN || code == MEGA_MEGA_BG_RUN)\n\t\t{\n\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\tif (fFirstLine)\n\t\t\t{\n\t\t\t\tif (fInsertFgPel)\n\t\t\t\t{\n\t\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, fgPel);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\trunLength = runLength - 1;\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, BLACK_PIXEL);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (fInsertFgPel)\n\t\t\t\t{\n\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\n\t\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp ^ fgPel);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\trunLength--;\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t}\n\n\t\t\t/* A follow-on background run order will need a foreground pel inserted. */\n\t\t\tfInsertFgPel = TRUE;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* For any of the other run-types a follow-on background run\n\t\t    order does not need a foreground pel inserted. */\n\t\tfInsertFgPel = FALSE;\n\n\t\tswitch (code)\n\t\t{\n\t\t\t/* Handle Foreground Run Orders. */\n\t\t\tcase REGULAR_FG_RUN:\n\t\t\tcase MEGA_MEGA_FG_RUN:\n\t\t\tcase LITE_SET_FG_FG_RUN:\n\t\t\tcase MEGA_MEGA_SET_FG_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\t\tif (code == LITE_SET_FG_FG_RUN || code == MEGA_MEGA_SET_FG_RUN)\n\t\t\t\t{\n\t\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\t\treturn FALSE;\n\t\t\t\t\tSRCREADPIXEL(fgPel, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t}\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\t\tDESTWRITEPIXEL(pbDest, fgPel);\n\t\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\t\tDESTREADPIXEL(temp, pbDest - rowDelta);\n\t\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp ^ fgPel);\n\t\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Dithered Run Orders. */\n\t\t\tcase LITE_DITHERED_RUN:\n\t\t\tcase MEGA_MEGA_DITHERED_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\treturn FALSE;\n\t\t\t\tSRCREADPIXEL(pixelA, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\treturn FALSE;\n\t\t\t\tSRCREADPIXEL(pixelB, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength * 2))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelA);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelB);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Color Run Orders. */\n\t\t\tcase REGULAR_COLOR_RUN:\n\t\t\tcase MEGA_MEGA_COLOR_RUN:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\treturn FALSE;\n\t\t\t\tSRCREADPIXEL(pixelA, pbSrc);\n\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, pixelA);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Foreground/Background Image Orders. */\n\t\t\tcase REGULAR_FGBG_IMAGE:\n\t\t\tcase MEGA_MEGA_FGBG_IMAGE:\n\t\t\tcase LITE_SET_FG_FGBG_IMAGE:\n\t\t\tcase MEGA_MEGA_SET_FGBG_IMAGE:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\n\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\treturn FALSE;\n\t\t\t\tif (code == LITE_SET_FG_FGBG_IMAGE || code == MEGA_MEGA_SET_FGBG_IMAGE)\n\t\t\t\t{\n\t\t\t\t\tSRCREADPIXEL(fgPel, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t}\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\twhile (runLength > 8)\n\t\t\t\t\t{\n\t\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\t\tpbSrc = pbSrc + 1;\n\t\t\t\t\t\tpbDest = WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, bitmask, fgPel, 8);\n\n\t\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\t\trunLength = runLength - 8;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\twhile (runLength > 8)\n\t\t\t\t\t{\n\t\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\t\tpbSrc = pbSrc + 1;\n\t\t\t\t\t\tpbDest = WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, bitmask, fgPel, 8);\n\n\t\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\t\treturn FALSE;\n\n\t\t\t\t\t\trunLength = runLength - 8;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (runLength > 0)\n\t\t\t\t{\n\t\t\t\t\tbitmask = *pbSrc;\n\t\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\t\tif (fFirstLine)\n\t\t\t\t\t{\n\t\t\t\t\t\tpbDest =\n\t\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, bitmask, fgPel, runLength);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tpbDest =\n\t\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, bitmask, fgPel, runLength);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!pbDest)\n\t\t\t\t\t\treturn FALSE;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Color Image Orders. */\n\t\t\tcase REGULAR_COLOR_IMAGE:\n\t\t\tcase MEGA_MEGA_COLOR_IMAGE:\n\t\t\t\trunLength = ExtractRunLength(code, pbSrc, &advance);\n\t\t\t\tpbSrc = pbSrc + advance;\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, runLength))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tUNROLL(runLength, {\n\t\t\t\t\tif (pbSrc >= pbEnd)\n\t\t\t\t\t\treturn FALSE;\n\t\t\t\t\tSRCREADPIXEL(temp, pbSrc);\n\t\t\t\t\tSRCNEXTPIXEL(pbSrc);\n\t\t\t\t\tDESTWRITEPIXEL(pbDest, temp);\n\t\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\t});\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Special Order 1. */\n\t\t\tcase SPECIAL_FGBG_1:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, g_MaskSpecialFgBg1, fgPel, 8);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, g_MaskSpecialFgBg1, fgPel, 8);\n\t\t\t\t}\n\n\t\t\t\tif (!pbDest)\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Special Order 2. */\n\t\t\tcase SPECIAL_FGBG_2:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (fFirstLine)\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFIRSTLINEFGBGIMAGE(pbDest, pbDestEnd, g_MaskSpecialFgBg2, fgPel, 8);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpbDest =\n\t\t\t\t\t    WRITEFGBGIMAGE(pbDest, pbDestEnd, rowDelta, g_MaskSpecialFgBg2, fgPel, 8);\n\t\t\t\t}\n\n\t\t\t\tif (!pbDest)\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tbreak;\n\n\t\t\t/* Handle White Order. */\n\t\t\tcase SPECIAL_WHITE:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tDESTWRITEPIXEL(pbDest, WHITE_PIXEL);\n\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\tbreak;\n\n\t\t\t/* Handle Black Order. */\n\t\t\tcase SPECIAL_BLACK:\n\t\t\t\tpbSrc = pbSrc + 1;\n\n\t\t\t\tif (!ENSURE_CAPACITY(pbDest, pbDestEnd, 1))\n\t\t\t\t\treturn FALSE;\n\n\t\t\t\tDESTWRITEPIXEL(pbDest, BLACK_PIXEL);\n\t\t\t\tDESTNEXTPIXEL(pbDest);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/0a98c450c58ec150e44781c89aa6f8e7e0f571f5", "file_name": "libfreerdp/codec/include/bitmap.c", "vul_type": "cwe-125", "description": "Write a C function for run-length decoding of compressed image data."}
{"func_name": "jp2_decode", "func_src_before": "jas_image_t *jp2_decode(jas_stream_t *in, const char *optstr)\n{\n\tjp2_box_t *box;\n\tint found;\n\tjas_image_t *image;\n\tjp2_dec_t *dec;\n\tbool samedtype;\n\tint dtype;\n\tunsigned int i;\n\tjp2_cmap_t *cmapd;\n\tjp2_pclr_t *pclrd;\n\tjp2_cdef_t *cdefd;\n\tunsigned int channo;\n\tint newcmptno;\n\tint_fast32_t *lutents;\n#if 0\n\tjp2_cdefchan_t *cdefent;\n\tint cmptno;\n#endif\n\tjp2_cmapent_t *cmapent;\n\tjas_icchdr_t icchdr;\n\tjas_iccprof_t *iccprof;\n\n\tdec = 0;\n\tbox = 0;\n\timage = 0;\n\n\tJAS_DBGLOG(100, (\"jp2_decode(%p, \\\"%s\\\")\\n\", in, optstr));\n\n\tif (!(dec = jp2_dec_create())) {\n\t\tgoto error;\n\t}\n\n\t/* Get the first box.  This should be a JP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tjas_eprintf(\"error: cannot get box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_JP) {\n\t\tjas_eprintf(\"error: expecting signature box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->data.jp.magic != JP2_JP_MAGIC) {\n\t\tjas_eprintf(\"incorrect magic number\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get the second box.  This should be a FTYP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_FTYP) {\n\t\tjas_eprintf(\"expecting file type box\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get more boxes... */\n\tfound = 0;\n\twhile ((box = jp2_box_get(in))) {\n\t\tif (jas_getdbglevel() >= 1) {\n\t\t\tjas_eprintf(\"got box type %s\\n\", box->info->name);\n\t\t}\n\t\tswitch (box->type) {\n\t\tcase JP2_BOX_JP2C:\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\tcase JP2_BOX_IHDR:\n\t\t\tif (!dec->ihdr) {\n\t\t\t\tdec->ihdr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_BPCC:\n\t\t\tif (!dec->bpcc) {\n\t\t\t\tdec->bpcc = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CDEF:\n\t\t\tif (!dec->cdef) {\n\t\t\t\tdec->cdef = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_PCLR:\n\t\t\tif (!dec->pclr) {\n\t\t\t\tdec->pclr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CMAP:\n\t\t\tif (!dec->cmap) {\n\t\t\t\tdec->cmap = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_COLR:\n\t\t\tif (!dec->colr) {\n\t\t\t\tdec->colr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (box) {\n\t\t\tjp2_box_destroy(box);\n\t\t\tbox = 0;\n\t\t}\n\t\tif (found) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\tjas_eprintf(\"error: no code stream found\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!(dec->image = jpc_decode(in, optstr))) {\n\t\tjas_eprintf(\"error: cannot decode code stream\\n\");\n\t\tgoto error;\n\t}\n\n\t/* An IHDR box must be present. */\n\tif (!dec->ihdr) {\n\t\tjas_eprintf(\"error: missing IHDR box\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Does the number of components indicated in the IHDR box match\n\t  the value specified in the code stream? */\n\tif (dec->ihdr->data.ihdr.numcmpts != JAS_CAST(jas_uint,\n\t  jas_image_numcmpts(dec->image))) {\n\t\tjas_eprintf(\"warning: number of components mismatch\\n\");\n\t}\n\n\t/* At least one component must be present. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Determine if all components have the same data type. */\n\tsamedtype = true;\n\tdtype = jas_image_cmptdtype(dec->image, 0);\n\tfor (i = 1; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tif (jas_image_cmptdtype(dec->image, i) != dtype) {\n\t\t\tsamedtype = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Is the component data type indicated in the IHDR box consistent\n\t  with the data in the code stream? */\n\tif ((samedtype && dec->ihdr->data.ihdr.bpc != JP2_DTYPETOBPC(dtype)) ||\n\t  (!samedtype && dec->ihdr->data.ihdr.bpc != JP2_IHDR_BPCNULL)) {\n\t\tjas_eprintf(\"warning: component data type mismatch (IHDR)\\n\");\n\t}\n\n\t/* Is the compression type supported? */\n\tif (dec->ihdr->data.ihdr.comptype != JP2_IHDR_COMPTYPE) {\n\t\tjas_eprintf(\"error: unsupported compression type\\n\");\n\t\tgoto error;\n\t}\n\n\tif (dec->bpcc) {\n\t\t/* Is the number of components indicated in the BPCC box\n\t\t  consistent with the code stream data? */\n\t\tif (dec->bpcc->data.bpcc.numcmpts != JAS_CAST(jas_uint, jas_image_numcmpts(\n\t\t  dec->image))) {\n\t\t\tjas_eprintf(\"warning: number of components mismatch\\n\");\n\t\t}\n\t\t/* Is the component data type information indicated in the BPCC\n\t\t  box consistent with the code stream data? */\n\t\tif (!samedtype) {\n\t\t\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\t\t\t  ++i) {\n\t\t\t\tif (jas_image_cmptdtype(dec->image, i) !=\n\t\t\t\t  JP2_BPCTODTYPE(dec->bpcc->data.bpcc.bpcs[i])) {\n\t\t\t\t\tjas_eprintf(\"warning: component data type mismatch (BPCC)\\n\");\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tjas_eprintf(\"warning: superfluous BPCC box\\n\");\n\t\t}\n\t}\n\n\t/* A COLR box must be present. */\n\tif (!dec->colr) {\n\t\tjas_eprintf(\"error: no COLR box\\n\");\n\t\tgoto error;\n\t}\n\n\tswitch (dec->colr->data.colr.method) {\n\tcase JP2_COLR_ENUM:\n\t\tjas_image_setclrspc(dec->image, jp2_getcs(&dec->colr->data.colr));\n\t\tbreak;\n\tcase JP2_COLR_ICC:\n\t\ticcprof = jas_iccprof_createfrombuf(dec->colr->data.colr.iccp,\n\t\t  dec->colr->data.colr.iccplen);\n\t\tif (!iccprof) {\n\t\t\tjas_eprintf(\"error: failed to parse ICC profile\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_gethdr(iccprof, &icchdr);\n\t\tjas_eprintf(\"ICC Profile CS %08x\\n\", icchdr.colorspc);\n\t\tjas_image_setclrspc(dec->image, fromiccpcs(icchdr.colorspc));\n\t\tdec->image->cmprof_ = jas_cmprof_createfromiccprof(iccprof);\n\t\tif (!dec->image->cmprof_) {\n\t\t\tjas_iccprof_destroy(iccprof);\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_destroy(iccprof);\n\t\tbreak;\n\t}\n\n\t/* If a CMAP box is present, a PCLR box must also be present. */\n\tif (dec->cmap && !dec->pclr) {\n\t\tjas_eprintf(\"warning: missing PCLR box or superfluous CMAP box\\n\");\n\t\tjp2_box_destroy(dec->cmap);\n\t\tdec->cmap = 0;\n\t}\n\n\t/* If a CMAP box is not present, a PCLR box must not be present. */\n\tif (!dec->cmap && dec->pclr) {\n\t\tjas_eprintf(\"warning: missing CMAP box or superfluous PCLR box\\n\");\n\t\tjp2_box_destroy(dec->pclr);\n\t\tdec->pclr = 0;\n\t}\n\n\t/* Determine the number of channels (which is essentially the number\n\t  of components after any palette mappings have been applied). */\n\tdec->numchans = dec->cmap ? dec->cmap->data.cmap.numchans :\n\t  JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\n\t/* Perform a basic sanity check on the CMAP box if present. */\n\tif (dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\t/* Is the component number reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].cmptno >= JAS_CAST(jas_uint,\n\t\t\t  jas_image_numcmpts(dec->image))) {\n\t\t\t\tjas_eprintf(\"error: invalid component number in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\t/* Is the LUT index reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].pcol >=\n\t\t\t  dec->pclr->data.pclr.numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid CMAP LUT index\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Allocate space for the channel-number to component-number LUT. */\n\tif (!(dec->chantocmptlut = jas_alloc2(dec->numchans,\n\t  sizeof(uint_fast16_t)))) {\n\t\tjas_eprintf(\"error: no memory\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tdec->chantocmptlut[i] = i;\n\t\t}\n\t} else {\n\t\tcmapd = &dec->cmap->data.cmap;\n\t\tpclrd = &dec->pclr->data.pclr;\n\t\tcdefd = &dec->cdef->data.cdef;\n\t\tfor (channo = 0; channo < cmapd->numchans; ++channo) {\n\t\t\tcmapent = &cmapd->ents[channo];\n\t\t\tif (cmapent->map == JP2_CMAP_DIRECT) {\n\t\t\t\tdec->chantocmptlut[channo] = channo;\n\t\t\t} else if (cmapent->map == JP2_CMAP_PALETTE) {\n\t\t\t\tif (!pclrd->numlutents) {\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t\tlutents = jas_alloc2(pclrd->numlutents, sizeof(int_fast32_t));\n\t\t\t\tif (!lutents) {\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t\tfor (i = 0; i < pclrd->numlutents; ++i) {\n\t\t\t\t\tlutents[i] = pclrd->lutdata[cmapent->pcol + i * pclrd->numchans];\n\t\t\t\t}\n\t\t\t\tnewcmptno = jas_image_numcmpts(dec->image);\n\t\t\t\tjas_image_depalettize(dec->image, cmapent->cmptno,\n\t\t\t\t  pclrd->numlutents, lutents,\n\t\t\t\t  JP2_BPCTODTYPE(pclrd->bpc[cmapent->pcol]), newcmptno);\n\t\t\t\tdec->chantocmptlut[channo] = newcmptno;\n\t\t\t\tjas_free(lutents);\n#if 0\n\t\t\t\tif (dec->cdef) {\n\t\t\t\t\tcdefent = jp2_cdef_lookup(cdefd, channo);\n\t\t\t\t\tif (!cdefent) {\n\t\t\t\t\t\tabort();\n\t\t\t\t\t}\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), cdefent->type, cdefent->assoc));\n\t\t\t\t} else {\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), 0, channo + 1));\n\t\t\t\t}\n#else\n\t\t\t\t/* suppress -Wunused-but-set-variable */\n\t\t\t\t(void)cdefd;\n#endif\n\t\t\t} else {\n\t\t\t\tjas_eprintf(\"error: invalid MTYP in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Ensure that the number of channels being used by the decoder\n\t  matches the number of image components. */\n\tif (dec->numchans != jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: mismatch in number of components (%d != %d)\\n\",\n\t\t  dec->numchans, jas_image_numcmpts(dec->image));\n\t\tgoto error;\n\t}\n\n\t/* Mark all components as being of unknown type. */\n\n\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tjas_image_setcmpttype(dec->image, i, JAS_IMAGE_CT_UNKNOWN);\n\t}\n\n\t/* Determine the type of each component. */\n\tif (dec->cdef) {\n\t\tfor (i = 0; i < dec->cdef->data.cdef.numchans; ++i) {\n\t\t\t/* Is the channel number reasonable? */\n\t\t\tif (dec->cdef->data.cdef.ents[i].channo >= dec->numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid channel number in CDEF box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tjas_image_setcmpttype(dec->image,\n\t\t\t  dec->chantocmptlut[dec->cdef->data.cdef.ents[i].channo],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image),\n\t\t\t  dec->cdef->data.cdef.ents[i].type,\n\t\t\t  dec->cdef->data.cdef.ents[i].assoc));\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tjas_image_setcmpttype(dec->image, dec->chantocmptlut[i],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image), 0, i + 1));\n\t\t}\n\t}\n\n\t/* Delete any components that are not of interest. */\n\tfor (i = jas_image_numcmpts(dec->image); i > 0; --i) {\n\t\tif (jas_image_cmpttype(dec->image, i - 1) == JAS_IMAGE_CT_UNKNOWN) {\n\t\t\tjas_image_delcmpt(dec->image, i - 1);\n\t\t}\n\t}\n\n\t/* Ensure that some components survived. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n#if 0\njas_eprintf(\"no of components is %d\\n\", jas_image_numcmpts(dec->image));\n#endif\n\n\t/* Prevent the image from being destroyed later. */\n\timage = dec->image;\n\tdec->image = 0;\n\n\tjp2_dec_destroy(dec);\n\n\treturn image;\n\nerror:\n\tif (box) {\n\t\tjp2_box_destroy(box);\n\t}\n\tif (dec) {\n\t\tjp2_dec_destroy(dec);\n\t}\n\treturn 0;\n}", "func_src_after": "jas_image_t *jp2_decode(jas_stream_t *in, const char *optstr)\n{\n\tjp2_box_t *box;\n\tint found;\n\tjas_image_t *image;\n\tjp2_dec_t *dec;\n\tbool samedtype;\n\tint dtype;\n\tunsigned int i;\n\tjp2_cmap_t *cmapd;\n\tjp2_pclr_t *pclrd;\n\tjp2_cdef_t *cdefd;\n\tunsigned int channo;\n\tint newcmptno;\n\tint_fast32_t *lutents;\n#if 0\n\tjp2_cdefchan_t *cdefent;\n\tint cmptno;\n#endif\n\tjp2_cmapent_t *cmapent;\n\tjas_icchdr_t icchdr;\n\tjas_iccprof_t *iccprof;\n\n\tdec = 0;\n\tbox = 0;\n\timage = 0;\n\n\tJAS_DBGLOG(100, (\"jp2_decode(%p, \\\"%s\\\")\\n\", in, optstr));\n\n\tif (!(dec = jp2_dec_create())) {\n\t\tgoto error;\n\t}\n\n\t/* Get the first box.  This should be a JP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tjas_eprintf(\"error: cannot get box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_JP) {\n\t\tjas_eprintf(\"error: expecting signature box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->data.jp.magic != JP2_JP_MAGIC) {\n\t\tjas_eprintf(\"incorrect magic number\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get the second box.  This should be a FTYP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_FTYP) {\n\t\tjas_eprintf(\"expecting file type box\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get more boxes... */\n\tfound = 0;\n\twhile ((box = jp2_box_get(in))) {\n\t\tif (jas_getdbglevel() >= 1) {\n\t\t\tjas_eprintf(\"got box type %s\\n\", box->info->name);\n\t\t}\n\t\tswitch (box->type) {\n\t\tcase JP2_BOX_JP2C:\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\tcase JP2_BOX_IHDR:\n\t\t\tif (!dec->ihdr) {\n\t\t\t\tdec->ihdr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_BPCC:\n\t\t\tif (!dec->bpcc) {\n\t\t\t\tdec->bpcc = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CDEF:\n\t\t\tif (!dec->cdef) {\n\t\t\t\tdec->cdef = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_PCLR:\n\t\t\tif (!dec->pclr) {\n\t\t\t\tdec->pclr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CMAP:\n\t\t\tif (!dec->cmap) {\n\t\t\t\tdec->cmap = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_COLR:\n\t\t\tif (!dec->colr) {\n\t\t\t\tdec->colr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (box) {\n\t\t\tjp2_box_destroy(box);\n\t\t\tbox = 0;\n\t\t}\n\t\tif (found) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\tjas_eprintf(\"error: no code stream found\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!(dec->image = jpc_decode(in, optstr))) {\n\t\tjas_eprintf(\"error: cannot decode code stream\\n\");\n\t\tgoto error;\n\t}\n\n\t/* An IHDR box must be present. */\n\tif (!dec->ihdr) {\n\t\tjas_eprintf(\"error: missing IHDR box\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Does the number of components indicated in the IHDR box match\n\t  the value specified in the code stream? */\n\tif (dec->ihdr->data.ihdr.numcmpts != JAS_CAST(jas_uint,\n\t  jas_image_numcmpts(dec->image))) {\n\t\tjas_eprintf(\"error: number of components mismatch (IHDR)\\n\");\n\t\tgoto error;\n\t}\n\n\t/* At least one component must be present. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Determine if all components have the same data type. */\n\tsamedtype = true;\n\tdtype = jas_image_cmptdtype(dec->image, 0);\n\tfor (i = 1; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tif (jas_image_cmptdtype(dec->image, i) != dtype) {\n\t\t\tsamedtype = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Is the component data type indicated in the IHDR box consistent\n\t  with the data in the code stream? */\n\tif ((samedtype && dec->ihdr->data.ihdr.bpc != JP2_DTYPETOBPC(dtype)) ||\n\t  (!samedtype && dec->ihdr->data.ihdr.bpc != JP2_IHDR_BPCNULL)) {\n\t\tjas_eprintf(\"error: component data type mismatch (IHDR)\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Is the compression type supported? */\n\tif (dec->ihdr->data.ihdr.comptype != JP2_IHDR_COMPTYPE) {\n\t\tjas_eprintf(\"error: unsupported compression type\\n\");\n\t\tgoto error;\n\t}\n\n\tif (dec->bpcc) {\n\t\t/* Is the number of components indicated in the BPCC box\n\t\t  consistent with the code stream data? */\n\t\tif (dec->bpcc->data.bpcc.numcmpts !=\n\t\t  JAS_CAST(jas_uint, jas_image_numcmpts(dec->image))) {\n\t\t\tjas_eprintf(\"error: number of components mismatch (BPCC)\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\t/* Is the component data type information indicated in the BPCC\n\t\t  box consistent with the code stream data? */\n\t\tif (!samedtype) {\n\t\t\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\t\t\t  ++i) {\n\t\t\t\tif (jas_image_cmptdtype(dec->image, i) !=\n\t\t\t\t  JP2_BPCTODTYPE(dec->bpcc->data.bpcc.bpcs[i])) {\n\t\t\t\t\tjas_eprintf(\"error: component data type mismatch (BPCC)\\n\");\n\t\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tjas_eprintf(\"warning: superfluous BPCC box\\n\");\n\t\t}\n\t}\n\n\t/* A COLR box must be present. */\n\tif (!dec->colr) {\n\t\tjas_eprintf(\"error: no COLR box\\n\");\n\t\tgoto error;\n\t}\n\n\tswitch (dec->colr->data.colr.method) {\n\tcase JP2_COLR_ENUM:\n\t\tjas_image_setclrspc(dec->image, jp2_getcs(&dec->colr->data.colr));\n\t\tbreak;\n\tcase JP2_COLR_ICC:\n\t\ticcprof = jas_iccprof_createfrombuf(dec->colr->data.colr.iccp,\n\t\t  dec->colr->data.colr.iccplen);\n\t\tif (!iccprof) {\n\t\t\tjas_eprintf(\"error: failed to parse ICC profile\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_gethdr(iccprof, &icchdr);\n\t\tjas_eprintf(\"ICC Profile CS %08x\\n\", icchdr.colorspc);\n\t\tjas_image_setclrspc(dec->image, fromiccpcs(icchdr.colorspc));\n\t\tdec->image->cmprof_ = jas_cmprof_createfromiccprof(iccprof);\n\t\tif (!dec->image->cmprof_) {\n\t\t\tjas_iccprof_destroy(iccprof);\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_destroy(iccprof);\n\t\tbreak;\n\t}\n\n\t/* If a CMAP box is present, a PCLR box must also be present. */\n\tif (dec->cmap && !dec->pclr) {\n\t\tjas_eprintf(\"warning: missing PCLR box or superfluous CMAP box\\n\");\n\t\tjp2_box_destroy(dec->cmap);\n\t\tdec->cmap = 0;\n\t}\n\n\t/* If a CMAP box is not present, a PCLR box must not be present. */\n\tif (!dec->cmap && dec->pclr) {\n\t\tjas_eprintf(\"warning: missing CMAP box or superfluous PCLR box\\n\");\n\t\tjp2_box_destroy(dec->pclr);\n\t\tdec->pclr = 0;\n\t}\n\n\t/* Determine the number of channels (which is essentially the number\n\t  of components after any palette mappings have been applied). */\n\tdec->numchans = dec->cmap ? dec->cmap->data.cmap.numchans :\n\t  JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\n\t/* Perform a basic sanity check on the CMAP box if present. */\n\tif (dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\t/* Is the component number reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].cmptno >= JAS_CAST(jas_uint,\n\t\t\t  jas_image_numcmpts(dec->image))) {\n\t\t\t\tjas_eprintf(\"error: invalid component number in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\t/* Is the LUT index reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].pcol >=\n\t\t\t  dec->pclr->data.pclr.numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid CMAP LUT index\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Allocate space for the channel-number to component-number LUT. */\n\tif (!(dec->chantocmptlut = jas_alloc2(dec->numchans,\n\t  sizeof(uint_fast16_t)))) {\n\t\tjas_eprintf(\"error: no memory\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tdec->chantocmptlut[i] = i;\n\t\t}\n\t} else {\n\t\tcmapd = &dec->cmap->data.cmap;\n\t\tpclrd = &dec->pclr->data.pclr;\n\t\tcdefd = &dec->cdef->data.cdef;\n\t\tfor (channo = 0; channo < cmapd->numchans; ++channo) {\n\t\t\tcmapent = &cmapd->ents[channo];\n\t\t\tif (cmapent->map == JP2_CMAP_DIRECT) {\n\t\t\t\tdec->chantocmptlut[channo] = channo;\n\t\t\t} else if (cmapent->map == JP2_CMAP_PALETTE) {\n\t\t\t\tif (!pclrd->numlutents) {\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t\tlutents = jas_alloc2(pclrd->numlutents, sizeof(int_fast32_t));\n\t\t\t\tif (!lutents) {\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t\tfor (i = 0; i < pclrd->numlutents; ++i) {\n\t\t\t\t\tlutents[i] = pclrd->lutdata[cmapent->pcol + i * pclrd->numchans];\n\t\t\t\t}\n\t\t\t\tnewcmptno = jas_image_numcmpts(dec->image);\n\t\t\t\tjas_image_depalettize(dec->image, cmapent->cmptno,\n\t\t\t\t  pclrd->numlutents, lutents,\n\t\t\t\t  JP2_BPCTODTYPE(pclrd->bpc[cmapent->pcol]), newcmptno);\n\t\t\t\tdec->chantocmptlut[channo] = newcmptno;\n\t\t\t\tjas_free(lutents);\n#if 0\n\t\t\t\tif (dec->cdef) {\n\t\t\t\t\tcdefent = jp2_cdef_lookup(cdefd, channo);\n\t\t\t\t\tif (!cdefent) {\n\t\t\t\t\t\tabort();\n\t\t\t\t\t}\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), cdefent->type, cdefent->assoc));\n\t\t\t\t} else {\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), 0, channo + 1));\n\t\t\t\t}\n#else\n\t\t\t\t/* suppress -Wunused-but-set-variable */\n\t\t\t\t(void)cdefd;\n#endif\n\t\t\t} else {\n\t\t\t\tjas_eprintf(\"error: invalid MTYP in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Ensure that the number of channels being used by the decoder\n\t  matches the number of image components. */\n\tif (dec->numchans != jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: mismatch in number of components (%d != %d)\\n\",\n\t\t  dec->numchans, jas_image_numcmpts(dec->image));\n\t\tgoto error;\n\t}\n\n\t/* Mark all components as being of unknown type. */\n\n\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tjas_image_setcmpttype(dec->image, i, JAS_IMAGE_CT_UNKNOWN);\n\t}\n\n\t/* Determine the type of each component. */\n\tif (dec->cdef) {\n\t\tfor (i = 0; i < dec->cdef->data.cdef.numchans; ++i) {\n\t\t\t/* Is the channel number reasonable? */\n\t\t\tif (dec->cdef->data.cdef.ents[i].channo >= dec->numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid channel number in CDEF box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tjas_image_setcmpttype(dec->image,\n\t\t\t  dec->chantocmptlut[dec->cdef->data.cdef.ents[i].channo],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image),\n\t\t\t  dec->cdef->data.cdef.ents[i].type,\n\t\t\t  dec->cdef->data.cdef.ents[i].assoc));\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tjas_image_setcmpttype(dec->image, dec->chantocmptlut[i],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image), 0, i + 1));\n\t\t}\n\t}\n\n\t/* Delete any components that are not of interest. */\n\tfor (i = jas_image_numcmpts(dec->image); i > 0; --i) {\n\t\tif (jas_image_cmpttype(dec->image, i - 1) == JAS_IMAGE_CT_UNKNOWN) {\n\t\t\tjas_image_delcmpt(dec->image, i - 1);\n\t\t}\n\t}\n\n\t/* Ensure that some components survived. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n#if 0\njas_eprintf(\"no of components is %d\\n\", jas_image_numcmpts(dec->image));\n#endif\n\n\t/* Prevent the image from being destroyed later. */\n\timage = dec->image;\n\tdec->image = 0;\n\n\tjp2_dec_destroy(dec);\n\n\treturn image;\n\nerror:\n\tif (box) {\n\t\tjp2_box_destroy(box);\n\t}\n\tif (dec) {\n\t\tjp2_dec_destroy(dec);\n\t}\n\treturn 0;\n}", "commit_link": "github.com/jasper-software/jasper/commit/41f214b121b837fa30d9ca5f2430212110f5cd9b", "file_name": "src/libjasper/jp2/jp2_dec.c", "vul_type": "cwe-125", "description": "Write a C function named `jp2_decode` that decodes a JPEG 2000 image from a given input stream and returns a pointer to the decoded image structure."}
{"func_name": "get_conn_text", "func_src_before": "static inline void get_conn_text(const conn *c, const int af,\n                char* addr, struct sockaddr *sock_addr) {\n    char addr_text[MAXPATHLEN];\n    addr_text[0] = '\\0';\n    const char *protoname = \"?\";\n    unsigned short port = 0;\n\n    switch (af) {\n        case AF_INET:\n            (void) inet_ntop(af,\n                    &((struct sockaddr_in *)sock_addr)->sin_addr,\n                    addr_text,\n                    sizeof(addr_text) - 1);\n            port = ntohs(((struct sockaddr_in *)sock_addr)->sin_port);\n            protoname = IS_UDP(c->transport) ? \"udp\" : \"tcp\";\n            break;\n\n        case AF_INET6:\n            addr_text[0] = '[';\n            addr_text[1] = '\\0';\n            if (inet_ntop(af,\n                    &((struct sockaddr_in6 *)sock_addr)->sin6_addr,\n                    addr_text + 1,\n                    sizeof(addr_text) - 2)) {\n                strcat(addr_text, \"]\");\n            }\n            port = ntohs(((struct sockaddr_in6 *)sock_addr)->sin6_port);\n            protoname = IS_UDP(c->transport) ? \"udp6\" : \"tcp6\";\n            break;\n\n        case AF_UNIX:\n            strncpy(addr_text,\n                    ((struct sockaddr_un *)sock_addr)->sun_path,\n                    sizeof(addr_text) - 1);\n            addr_text[sizeof(addr_text)-1] = '\\0';\n            protoname = \"unix\";\n            break;\n    }\n\n    if (strlen(addr_text) < 2) {\n        /* Most likely this is a connected UNIX-domain client which\n         * has no peer socket address, but there's no portable way\n         * to tell for sure.\n         */\n        sprintf(addr_text, \"<AF %d>\", af);\n    }\n\n    if (port) {\n        sprintf(addr, \"%s:%s:%u\", protoname, addr_text, port);\n    } else {\n        sprintf(addr, \"%s:%s\", protoname, addr_text);\n    }\n}", "func_src_after": "static inline void get_conn_text(const conn *c, const int af,\n                char* addr, struct sockaddr *sock_addr) {\n    char addr_text[MAXPATHLEN];\n    addr_text[0] = '\\0';\n    const char *protoname = \"?\";\n    unsigned short port = 0;\n    size_t pathlen = 0;\n\n    switch (af) {\n        case AF_INET:\n            (void) inet_ntop(af,\n                    &((struct sockaddr_in *)sock_addr)->sin_addr,\n                    addr_text,\n                    sizeof(addr_text) - 1);\n            port = ntohs(((struct sockaddr_in *)sock_addr)->sin_port);\n            protoname = IS_UDP(c->transport) ? \"udp\" : \"tcp\";\n            break;\n\n        case AF_INET6:\n            addr_text[0] = '[';\n            addr_text[1] = '\\0';\n            if (inet_ntop(af,\n                    &((struct sockaddr_in6 *)sock_addr)->sin6_addr,\n                    addr_text + 1,\n                    sizeof(addr_text) - 2)) {\n                strcat(addr_text, \"]\");\n            }\n            port = ntohs(((struct sockaddr_in6 *)sock_addr)->sin6_port);\n            protoname = IS_UDP(c->transport) ? \"udp6\" : \"tcp6\";\n            break;\n\n        case AF_UNIX:\n            // this strncpy call originally could piss off an address\n            // sanitizer; we supplied the size of the dest buf as a limiter,\n            // but optimized versions of strncpy could read past the end of\n            // *src while looking for a null terminator. Since buf and\n            // sun_path here are both on the stack they could even overlap,\n            // which is \"undefined\". In all OSS versions of strncpy I could\n            // find this has no effect; it'll still only copy until the first null\n            // terminator is found. Thus it's possible to get the OS to\n            // examine past the end of sun_path but it's unclear to me if this\n            // can cause any actual problem.\n            //\n            // We need a safe_strncpy util function but I'll punt on figuring\n            // that out for now.\n            pathlen = sizeof(((struct sockaddr_un *)sock_addr)->sun_path);\n            if (MAXPATHLEN <= pathlen) {\n                pathlen = MAXPATHLEN - 1;\n            }\n            strncpy(addr_text,\n                    ((struct sockaddr_un *)sock_addr)->sun_path,\n                    pathlen);\n            addr_text[pathlen] = '\\0';\n            protoname = \"unix\";\n            break;\n    }\n\n    if (strlen(addr_text) < 2) {\n        /* Most likely this is a connected UNIX-domain client which\n         * has no peer socket address, but there's no portable way\n         * to tell for sure.\n         */\n        sprintf(addr_text, \"<AF %d>\", af);\n    }\n\n    if (port) {\n        sprintf(addr, \"%s:%s:%u\", protoname, addr_text, port);\n    } else {\n        sprintf(addr, \"%s:%s\", protoname, addr_text);\n    }\n}", "commit_link": "github.com/memcached/memcached/commit/554b56687a19300a75ec24184746b5512580c819", "file_name": "memcached.c", "vul_type": "cwe-125", "description": "Write a C function named `get_conn_text` that formats a socket address into a human-readable string."}
{"func_name": "parse_sec_attr_44", "func_src_before": "static void parse_sec_attr_44(sc_file_t *file, const u8 *buf, size_t len)\n{\n\t/* OpenSc Operation values for each command operation-type */\n\tconst int df_idx[8] = {\t /* byte 1 = OpenSC type of AC Bit0,  byte 2 = OpenSC type of AC Bit1 ...*/\n\t\tSC_AC_OP_DELETE, SC_AC_OP_CREATE, SC_AC_OP_CREATE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\tSC_AC_OP_LOCK, SC_AC_OP_DELETE, -1};\n\tconst int ef_idx[8] = {\n\t\tSC_AC_OP_READ, SC_AC_OP_UPDATE, SC_AC_OP_WRITE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\t-1, SC_AC_OP_ERASE, -1};\n\tconst int efi_idx[8] = { /* internal EF used for RSA keys */\n\t\tSC_AC_OP_READ, SC_AC_OP_ERASE, SC_AC_OP_UPDATE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\t-1, SC_AC_OP_ERASE, -1};\n\n\tu8\t\tbValue;\n\tint\t\ti;\n\tint\t\tiKeyRef = 0;\n\tint\t\tiMethod;\n\tint\t\tiPinCount;\n\tint\t\tiOffset = 0;\n\tint\t\tiOperation;\n\tconst int*\tp_idx;\n\n\t/* Check all sub-AC definitions within the total AC */\n\twhile (len > 1) {\t\t\t\t/* minimum length = 2 */\n\t\tsize_t iACLen   = buf[iOffset] & 0x0F;\n\t\tif (iACLen > len)\n\t\t\tbreak;\n\n\t\tiMethod = SC_AC_NONE;\t\t/* default no authentication required */\n\n\t\tif (buf[iOffset] & 0X80) { /* AC in adaptive coding */\n\t\t\t/* Evaluates only the command-byte, not the optional P1/P2/Option bytes */\n\t\t\tsize_t\tiParmLen = 1;\t\t\t/* command-byte is always present */\n\t\t\tsize_t\tiKeyLen  = 0;\t\t\t/* Encryption key is optional */\n\n\t\t\tif (buf[iOffset]   & 0x20) iKeyLen++;\n\t\t\tif (buf[iOffset+1] & 0x40) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x20) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x10) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x08) iParmLen++;\n\n\t\t\t/* Get KeyNumber if available */\n\t\t\tif(iKeyLen) {\n\t\t\t\tint iSC;\n\t\t\t\tif (len < 1+(size_t)iACLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiSC = buf[iOffset+iACLen];\n\n\t\t\t\tswitch( (iSC>>5) & 0x03 ){\n\t\t\t\tcase 0:\n\t\t\t\t\tiMethod = SC_AC_TERM;\t\t/* key authentication */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 1:\n\t\t\t\t\tiMethod = SC_AC_AUT;\t\t/* key authentication  */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 2:\n\t\t\t\tcase 3:\n\t\t\t\t\tiMethod = SC_AC_PRO;\t\t/* secure messaging */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tiKeyRef = iSC & 0x1F;\t\t\t/* get key number */\n\t\t\t}\n\n\t\t\t/* Get PinNumber if available */\n\t\t\tif (iACLen > (1+iParmLen+iKeyLen)) {  /* check via total length if pin is present */\n\t\t\t\tif (len < 1+1+1+(size_t)iParmLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiKeyRef = buf[iOffset+1+1+iParmLen];  /* PTL + AM-header + parameter-bytes */\n\t\t\t\tiMethod = SC_AC_CHV;\n\t\t\t}\n\n\t\t\t/* Convert SETCOS command to OpenSC command group */\n\t\t\tif (len < 1+2)\n\t\t\t\tbreak;\n\t\t\tswitch(buf[iOffset+2]){\n\t\t\tcase 0x2A:\t\t\t/* crypto operation */\n\t\t\t\tiOperation = SC_AC_OP_CRYPTO;\n\t\t\t\tbreak;\n\t\t\tcase 0x46:\t\t\t/* key-generation operation */\n\t\t\t\tiOperation = SC_AC_OP_UPDATE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tiOperation = SC_AC_OP_SELECT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsc_file_add_acl_entry(file, iOperation, iMethod, iKeyRef);\n\t\t}\n\t\telse { /* AC in simple coding */\n\t\t\t   /* Initial AC is treated as an operational AC */\n\n\t\t\t/* Get specific Cmd groups for specified file-type */\n\t\t\tswitch (file->type) {\n\t\t\tcase SC_FILE_TYPE_DF:            /* DF */\n\t\t\t\tp_idx = df_idx;\n\t\t\t\tbreak;\n\t\t\tcase SC_FILE_TYPE_INTERNAL_EF:   /* EF for RSA keys */\n\t\t\t\tp_idx = efi_idx;\n\t\t\t\tbreak;\n\t\t\tdefault:                         /* EF */\n\t\t\t\tp_idx = ef_idx;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Encryption key present ? */\n\t\t\tiPinCount = iACLen - 1;\t\t\n\n\t\t\tif (buf[iOffset] & 0x20) {\n\t\t\t\tint iSC;\n\t\t\t\tif (len < 1 + (size_t)iACLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiSC = buf[iOffset + iACLen];\n\n\t\t\t\tswitch( (iSC>>5) & 0x03 ) {\n\t\t\t\tcase 0:\n\t\t\t\t\tiMethod = SC_AC_TERM;\t\t/* key authentication */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 1:\n\t\t\t\t\tiMethod = SC_AC_AUT;\t\t/* key authentication  */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 2:\n\t\t\t\tcase 3:\n\t\t\t\t\tiMethod = SC_AC_PRO;\t\t/* secure messaging */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tiKeyRef = iSC & 0x1F;\t\t\t/* get key number */\n\n\t\t\t\tiPinCount--;\t\t\t\t/* one byte used for keyReference  */\n\t\t\t}\n\n\t\t\t/* Pin present ? */\n\t\t\tif ( iPinCount > 0 ) {\n\t\t\t\tif (len < 1 + 2)\n\t\t\t\t\tbreak;\n\t\t\t\tiKeyRef = buf[iOffset + 2];\t/* pin ref */\n\t\t\t\tiMethod = SC_AC_CHV;\n\t\t\t}\n\n\t\t\t/* Add AC for each command-operationType into OpenSc structure */\n\t\t\tbValue = buf[iOffset + 1];\n\t\t\tfor (i = 0; i < 8; i++) {\n\t\t\t\tif((bValue & 1) && (p_idx[i] >= 0))\n\t\t\t\t\tsc_file_add_acl_entry(file, p_idx[i], iMethod, iKeyRef);\n\t\t\t\tbValue >>= 1;\n\t\t\t}\n\t\t}\n\t\t/* Current field treated, get next AC sub-field */\n\t\tiOffset += iACLen +1;\t\t/* AC + PTL-byte */\n\t\tlen     -= iACLen +1;\n\t}\n}", "func_src_after": "static void parse_sec_attr_44(sc_file_t *file, const u8 *buf, size_t len)\n{\n\t/* OpenSc Operation values for each command operation-type */\n\tconst int df_idx[8] = {\t /* byte 1 = OpenSC type of AC Bit0,  byte 2 = OpenSC type of AC Bit1 ...*/\n\t\tSC_AC_OP_DELETE, SC_AC_OP_CREATE, SC_AC_OP_CREATE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\tSC_AC_OP_LOCK, SC_AC_OP_DELETE, -1};\n\tconst int ef_idx[8] = {\n\t\tSC_AC_OP_READ, SC_AC_OP_UPDATE, SC_AC_OP_WRITE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\t-1, SC_AC_OP_ERASE, -1};\n\tconst int efi_idx[8] = { /* internal EF used for RSA keys */\n\t\tSC_AC_OP_READ, SC_AC_OP_ERASE, SC_AC_OP_UPDATE,\n\t\tSC_AC_OP_INVALIDATE, SC_AC_OP_REHABILITATE,\n\t\t-1, SC_AC_OP_ERASE, -1};\n\n\tu8\t\tbValue;\n\tint\t\ti;\n\tint\t\tiKeyRef = 0;\n\tint\t\tiMethod;\n\tint\t\tiPinCount;\n\tint\t\tiOffset = 0;\n\tint\t\tiOperation;\n\tconst int*\tp_idx;\n\n\t/* Check all sub-AC definitions within the total AC */\n\twhile (len > 1) {\t\t\t\t/* minimum length = 2 */\n\t\tsize_t iACLen   = buf[iOffset] & 0x0F;\n\t\tif (iACLen > len)\n\t\t\tbreak;\n\n\t\tiMethod = SC_AC_NONE;\t\t/* default no authentication required */\n\n\t\tif (buf[iOffset] & 0X80) { /* AC in adaptive coding */\n\t\t\t/* Evaluates only the command-byte, not the optional P1/P2/Option bytes */\n\t\t\tsize_t\tiParmLen = 1;\t\t\t/* command-byte is always present */\n\t\t\tsize_t\tiKeyLen  = 0;\t\t\t/* Encryption key is optional */\n\n\t\t\tif (buf[iOffset]   & 0x20) iKeyLen++;\n\t\t\tif (buf[iOffset+1] & 0x40) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x20) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x10) iParmLen++;\n\t\t\tif (buf[iOffset+1] & 0x08) iParmLen++;\n\n\t\t\t/* Get KeyNumber if available */\n\t\t\tif(iKeyLen) {\n\t\t\t\tint iSC;\n\t\t\t\tif (len < 1+(size_t)iACLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiSC = buf[iOffset+iACLen];\n\n\t\t\t\tswitch( (iSC>>5) & 0x03 ){\n\t\t\t\tcase 0:\n\t\t\t\t\tiMethod = SC_AC_TERM;\t\t/* key authentication */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 1:\n\t\t\t\t\tiMethod = SC_AC_AUT;\t\t/* key authentication  */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 2:\n\t\t\t\tcase 3:\n\t\t\t\t\tiMethod = SC_AC_PRO;\t\t/* secure messaging */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tiKeyRef = iSC & 0x1F;\t\t\t/* get key number */\n\t\t\t}\n\n\t\t\t/* Get PinNumber if available */\n\t\t\tif (iACLen > (1+iParmLen+iKeyLen)) {  /* check via total length if pin is present */\n\t\t\t\tif (len < 1+1+1+(size_t)iParmLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiKeyRef = buf[iOffset+1+1+iParmLen];  /* PTL + AM-header + parameter-bytes */\n\t\t\t\tiMethod = SC_AC_CHV;\n\t\t\t}\n\n\t\t\t/* Convert SETCOS command to OpenSC command group */\n\t\t\tif (len < 1+2)\n\t\t\t\tbreak;\n\t\t\tswitch(buf[iOffset+2]){\n\t\t\tcase 0x2A:\t\t\t/* crypto operation */\n\t\t\t\tiOperation = SC_AC_OP_CRYPTO;\n\t\t\t\tbreak;\n\t\t\tcase 0x46:\t\t\t/* key-generation operation */\n\t\t\t\tiOperation = SC_AC_OP_UPDATE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tiOperation = SC_AC_OP_SELECT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsc_file_add_acl_entry(file, iOperation, iMethod, iKeyRef);\n\t\t}\n\t\telse { /* AC in simple coding */\n\t\t\t   /* Initial AC is treated as an operational AC */\n\n\t\t\t/* Get specific Cmd groups for specified file-type */\n\t\t\tswitch (file->type) {\n\t\t\tcase SC_FILE_TYPE_DF:            /* DF */\n\t\t\t\tp_idx = df_idx;\n\t\t\t\tbreak;\n\t\t\tcase SC_FILE_TYPE_INTERNAL_EF:   /* EF for RSA keys */\n\t\t\t\tp_idx = efi_idx;\n\t\t\t\tbreak;\n\t\t\tdefault:                         /* EF */\n\t\t\t\tp_idx = ef_idx;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Encryption key present ? */\n\t\t\tiPinCount = iACLen > 0 ? iACLen - 1 : 0;\n\n\t\t\tif (buf[iOffset] & 0x20) {\n\t\t\t\tint iSC;\n\t\t\t\tif (len < 1 + (size_t)iACLen)\n\t\t\t\t\tbreak;\n\t\t\t\tiSC = buf[iOffset + iACLen];\n\n\t\t\t\tswitch( (iSC>>5) & 0x03 ) {\n\t\t\t\tcase 0:\n\t\t\t\t\tiMethod = SC_AC_TERM;\t\t/* key authentication */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 1:\n\t\t\t\t\tiMethod = SC_AC_AUT;\t\t/* key authentication  */\n\t\t\t\t\tbreak;\n\t\t\t\tcase 2:\n\t\t\t\tcase 3:\n\t\t\t\t\tiMethod = SC_AC_PRO;\t\t/* secure messaging */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tiKeyRef = iSC & 0x1F;\t\t\t/* get key number */\n\n\t\t\t\tiPinCount--;\t\t\t\t/* one byte used for keyReference  */\n\t\t\t}\n\n\t\t\t/* Pin present ? */\n\t\t\tif ( iPinCount > 0 ) {\n\t\t\t\tif (len < 1 + 2)\n\t\t\t\t\tbreak;\n\t\t\t\tiKeyRef = buf[iOffset + 2];\t/* pin ref */\n\t\t\t\tiMethod = SC_AC_CHV;\n\t\t\t}\n\n\t\t\t/* Add AC for each command-operationType into OpenSc structure */\n\t\t\tbValue = buf[iOffset + 1];\n\t\t\tfor (i = 0; i < 8; i++) {\n\t\t\t\tif((bValue & 1) && (p_idx[i] >= 0))\n\t\t\t\t\tsc_file_add_acl_entry(file, p_idx[i], iMethod, iKeyRef);\n\t\t\t\tbValue >>= 1;\n\t\t\t}\n\t\t}\n\t\t/* Current field treated, get next AC sub-field */\n\t\tiOffset += iACLen +1;\t\t/* AC + PTL-byte */\n\t\tlen     -= iACLen +1;\n\t}\n}", "commit_link": "github.com/OpenSC/OpenSC/commit/c3f23b836e5a1766c36617fe1da30d22f7b63de2", "file_name": "src/libopensc/card-setcos.c", "vul_type": "cwe-125", "description": "Write a C function named `parse_sec_attr_44` that processes security attributes from a buffer and updates an OpenSC file structure with access control entries."}
{"func_name": "do_core_note", "func_src_before": "do_core_note(struct magic_set *ms, unsigned char *nbuf, uint32_t type,\n    int swap, uint32_t namesz, uint32_t descsz,\n    size_t noff, size_t doff, int *flags, size_t size, int clazz)\n{\n#ifdef ELFCORE\n\tint os_style = -1;\n\t/*\n\t * Sigh.  The 2.0.36 kernel in Debian 2.1, at\n\t * least, doesn't correctly implement name\n\t * sections, in core dumps, as specified by\n\t * the \"Program Linking\" section of \"UNIX(R) System\n\t * V Release 4 Programmer's Guide: ANSI C and\n\t * Programming Support Tools\", because my copy\n\t * clearly says \"The first 'namesz' bytes in 'name'\n\t * contain a *null-terminated* [emphasis mine]\n\t * character representation of the entry's owner\n\t * or originator\", but the 2.0.36 kernel code\n\t * doesn't include the terminating null in the\n\t * name....\n\t */\n\tif ((namesz == 4 && strncmp((char *)&nbuf[noff], \"CORE\", 4) == 0) ||\n\t    (namesz == 5 && strcmp((char *)&nbuf[noff], \"CORE\") == 0)) {\n\t\tos_style = OS_STYLE_SVR4;\n\t} \n\n\tif ((namesz == 8 && strcmp((char *)&nbuf[noff], \"FreeBSD\") == 0)) {\n\t\tos_style = OS_STYLE_FREEBSD;\n\t}\n\n\tif ((namesz >= 11 && strncmp((char *)&nbuf[noff], \"NetBSD-CORE\", 11)\n\t    == 0)) {\n\t\tos_style = OS_STYLE_NETBSD;\n\t}\n\n\tif (os_style != -1 && (*flags & FLAGS_DID_CORE_STYLE) == 0) {\n\t\tif (file_printf(ms, \", %s-style\", os_style_names[os_style])\n\t\t    == -1)\n\t\t\treturn 1;\n\t\t*flags |= FLAGS_DID_CORE_STYLE;\n\t\t*flags |= os_style;\n\t}\n\n\tswitch (os_style) {\n\tcase OS_STYLE_NETBSD:\n\t\tif (type == NT_NETBSD_CORE_PROCINFO) {\n\t\t\tchar sbuf[512];\n\t\t\tstruct NetBSD_elfcore_procinfo pi;\n\t\t\tmemset(&pi, 0, sizeof(pi));\n\t\t\tmemcpy(&pi, nbuf + doff, descsz);\n\n\t\t\tif (file_printf(ms, \", from '%.31s', pid=%u, uid=%u, \"\n\t\t\t    \"gid=%u, nlwps=%u, lwp=%u (signal %u/code %u)\",\n\t\t\t    file_printable(sbuf, sizeof(sbuf),\n\t\t\t    CAST(char *, pi.cpi_name)),\n\t\t\t    elf_getu32(swap, (uint32_t)pi.cpi_pid),\n\t\t\t    elf_getu32(swap, pi.cpi_euid),\n\t\t\t    elf_getu32(swap, pi.cpi_egid),\n\t\t\t    elf_getu32(swap, pi.cpi_nlwps),\n\t\t\t    elf_getu32(swap, (uint32_t)pi.cpi_siglwp),\n\t\t\t    elf_getu32(swap, pi.cpi_signo),\n\t\t\t    elf_getu32(swap, pi.cpi_sigcode)) == -1)\n\t\t\t\treturn 1;\n\n\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tif (type == NT_PRPSINFO && *flags & FLAGS_IS_CORE) {\n\t\t\tsize_t i, j;\n\t\t\tunsigned char c;\n\t\t\t/*\n\t\t\t * Extract the program name.  We assume\n\t\t\t * it to be 16 characters (that's what it\n\t\t\t * is in SunOS 5.x and Linux).\n\t\t\t *\n\t\t\t * Unfortunately, it's at a different offset\n\t\t\t * in various OSes, so try multiple offsets.\n\t\t\t * If the characters aren't all printable,\n\t\t\t * reject it.\n\t\t\t */\n\t\t\tfor (i = 0; i < NOFFSETS; i++) {\n\t\t\t\tunsigned char *cname, *cp;\n\t\t\t\tsize_t reloffset = prpsoffsets(i);\n\t\t\t\tsize_t noffset = doff + reloffset;\n\t\t\t\tsize_t k;\n\t\t\t\tfor (j = 0; j < 16; j++, noffset++,\n\t\t\t\t    reloffset++) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the buffer; if\n\t\t\t\t\t * we are, just give up.\n\t\t\t\t\t */\n\t\t\t\t\tif (noffset >= size)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the contents;\n\t\t\t\t\t * if we are, this obviously\n\t\t\t\t\t * isn't the right offset.\n\t\t\t\t\t */\n\t\t\t\t\tif (reloffset >= descsz)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\tc = nbuf[noffset];\n\t\t\t\t\tif (c == '\\0') {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A '\\0' at the\n\t\t\t\t\t\t * beginning is\n\t\t\t\t\t\t * obviously wrong.\n\t\t\t\t\t\t * Any other '\\0'\n\t\t\t\t\t\t * means we're done.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (j == 0)\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A nonprintable\n\t\t\t\t\t\t * character is also\n\t\t\t\t\t\t * wrong.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (!isprint(c) || isquote(c))\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Well, that worked.\n\t\t\t\t */\n\n\t\t\t\t/*\n\t\t\t\t * Try next offsets, in case this match is\n\t\t\t\t * in the middle of a string.\n\t\t\t\t */\n\t\t\t\tfor (k = i + 1 ; k < NOFFSETS; k++) {\n\t\t\t\t\tsize_t no;\n\t\t\t\t\tint adjust = 1;\n\t\t\t\t\tif (prpsoffsets(k) >= prpsoffsets(i))\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tfor (no = doff + prpsoffsets(k);\n\t\t\t\t\t     no < doff + prpsoffsets(i); no++)\n\t\t\t\t\t\tadjust = adjust\n\t\t\t\t\t\t         && isprint(nbuf[no]);\n\t\t\t\t\tif (adjust)\n\t\t\t\t\t\ti = k;\n\t\t\t\t}\n\n\t\t\t\tcname = (unsigned char *)\n\t\t\t\t    &nbuf[doff + prpsoffsets(i)];\n\t\t\t\tfor (cp = cname; *cp && isprint(*cp); cp++)\n\t\t\t\t\tcontinue;\n\t\t\t\t/*\n\t\t\t\t * Linux apparently appends a space at the end\n\t\t\t\t * of the command line: remove it.\n\t\t\t\t */\n\t\t\t\twhile (cp > cname && isspace(cp[-1]))\n\t\t\t\t\tcp--;\n\t\t\t\tif (file_printf(ms, \", from '%.*s'\",\n\t\t\t\t    (int)(cp - cname), cname) == -1)\n\t\t\t\t\treturn 1;\n\t\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\t\treturn 1;\n\n\t\t\ttryanother:\n\t\t\t\t;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n#endif\n\treturn 0;\n}", "func_src_after": "do_core_note(struct magic_set *ms, unsigned char *nbuf, uint32_t type,\n    int swap, uint32_t namesz, uint32_t descsz,\n    size_t noff, size_t doff, int *flags, size_t size, int clazz)\n{\n#ifdef ELFCORE\n\tint os_style = -1;\n\t/*\n\t * Sigh.  The 2.0.36 kernel in Debian 2.1, at\n\t * least, doesn't correctly implement name\n\t * sections, in core dumps, as specified by\n\t * the \"Program Linking\" section of \"UNIX(R) System\n\t * V Release 4 Programmer's Guide: ANSI C and\n\t * Programming Support Tools\", because my copy\n\t * clearly says \"The first 'namesz' bytes in 'name'\n\t * contain a *null-terminated* [emphasis mine]\n\t * character representation of the entry's owner\n\t * or originator\", but the 2.0.36 kernel code\n\t * doesn't include the terminating null in the\n\t * name....\n\t */\n\tif ((namesz == 4 && strncmp((char *)&nbuf[noff], \"CORE\", 4) == 0) ||\n\t    (namesz == 5 && strcmp((char *)&nbuf[noff], \"CORE\") == 0)) {\n\t\tos_style = OS_STYLE_SVR4;\n\t} \n\n\tif ((namesz == 8 && strcmp((char *)&nbuf[noff], \"FreeBSD\") == 0)) {\n\t\tos_style = OS_STYLE_FREEBSD;\n\t}\n\n\tif ((namesz >= 11 && strncmp((char *)&nbuf[noff], \"NetBSD-CORE\", 11)\n\t    == 0)) {\n\t\tos_style = OS_STYLE_NETBSD;\n\t}\n\n\tif (os_style != -1 && (*flags & FLAGS_DID_CORE_STYLE) == 0) {\n\t\tif (file_printf(ms, \", %s-style\", os_style_names[os_style])\n\t\t    == -1)\n\t\t\treturn 1;\n\t\t*flags |= FLAGS_DID_CORE_STYLE;\n\t\t*flags |= os_style;\n\t}\n\n\tswitch (os_style) {\n\tcase OS_STYLE_NETBSD:\n\t\tif (type == NT_NETBSD_CORE_PROCINFO) {\n\t\t\tchar sbuf[512];\n\t\t\tstruct NetBSD_elfcore_procinfo pi;\n\t\t\tmemset(&pi, 0, sizeof(pi));\n\t\t\tmemcpy(&pi, nbuf + doff, descsz);\n\n\t\t\tif (file_printf(ms, \", from '%.31s', pid=%u, uid=%u, \"\n\t\t\t    \"gid=%u, nlwps=%u, lwp=%u (signal %u/code %u)\",\n\t\t\t    file_printable(sbuf, sizeof(sbuf),\n\t\t\t    CAST(char *, pi.cpi_name)),\n\t\t\t    elf_getu32(swap, (uint32_t)pi.cpi_pid),\n\t\t\t    elf_getu32(swap, pi.cpi_euid),\n\t\t\t    elf_getu32(swap, pi.cpi_egid),\n\t\t\t    elf_getu32(swap, pi.cpi_nlwps),\n\t\t\t    elf_getu32(swap, (uint32_t)pi.cpi_siglwp),\n\t\t\t    elf_getu32(swap, pi.cpi_signo),\n\t\t\t    elf_getu32(swap, pi.cpi_sigcode)) == -1)\n\t\t\t\treturn 1;\n\n\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tif (type == NT_PRPSINFO && *flags & FLAGS_IS_CORE) {\n\t\t\tsize_t i, j;\n\t\t\tunsigned char c;\n\t\t\t/*\n\t\t\t * Extract the program name.  We assume\n\t\t\t * it to be 16 characters (that's what it\n\t\t\t * is in SunOS 5.x and Linux).\n\t\t\t *\n\t\t\t * Unfortunately, it's at a different offset\n\t\t\t * in various OSes, so try multiple offsets.\n\t\t\t * If the characters aren't all printable,\n\t\t\t * reject it.\n\t\t\t */\n\t\t\tfor (i = 0; i < NOFFSETS; i++) {\n\t\t\t\tunsigned char *cname, *cp;\n\t\t\t\tsize_t reloffset = prpsoffsets(i);\n\t\t\t\tsize_t noffset = doff + reloffset;\n\t\t\t\tsize_t k;\n\t\t\t\tfor (j = 0; j < 16; j++, noffset++,\n\t\t\t\t    reloffset++) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the buffer; if\n\t\t\t\t\t * we are, just give up.\n\t\t\t\t\t */\n\t\t\t\t\tif (noffset >= size)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the contents;\n\t\t\t\t\t * if we are, this obviously\n\t\t\t\t\t * isn't the right offset.\n\t\t\t\t\t */\n\t\t\t\t\tif (reloffset >= descsz)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\tc = nbuf[noffset];\n\t\t\t\t\tif (c == '\\0') {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A '\\0' at the\n\t\t\t\t\t\t * beginning is\n\t\t\t\t\t\t * obviously wrong.\n\t\t\t\t\t\t * Any other '\\0'\n\t\t\t\t\t\t * means we're done.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (j == 0)\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A nonprintable\n\t\t\t\t\t\t * character is also\n\t\t\t\t\t\t * wrong.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (!isprint(c) || isquote(c))\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Well, that worked.\n\t\t\t\t */\n\n\t\t\t\t/*\n\t\t\t\t * Try next offsets, in case this match is\n\t\t\t\t * in the middle of a string.\n\t\t\t\t */\n\t\t\t\tfor (k = i + 1 ; k < NOFFSETS; k++) {\n\t\t\t\t\tsize_t no;\n\t\t\t\t\tint adjust = 1;\n\t\t\t\t\tif (prpsoffsets(k) >= prpsoffsets(i))\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tfor (no = doff + prpsoffsets(k);\n\t\t\t\t\t     no < doff + prpsoffsets(i); no++)\n\t\t\t\t\t\tadjust = adjust\n\t\t\t\t\t\t         && isprint(nbuf[no]);\n\t\t\t\t\tif (adjust)\n\t\t\t\t\t\ti = k;\n\t\t\t\t}\n\n\t\t\t\tcname = (unsigned char *)\n\t\t\t\t    &nbuf[doff + prpsoffsets(i)];\n\t\t\t\tfor (cp = cname; cp < nbuf + size && *cp\n\t\t\t\t    && isprint(*cp); cp++)\n\t\t\t\t\tcontinue;\n\t\t\t\t/*\n\t\t\t\t * Linux apparently appends a space at the end\n\t\t\t\t * of the command line: remove it.\n\t\t\t\t */\n\t\t\t\twhile (cp > cname && isspace(cp[-1]))\n\t\t\t\t\tcp--;\n\t\t\t\tif (file_printf(ms, \", from '%.*s'\",\n\t\t\t\t    (int)(cp - cname), cname) == -1)\n\t\t\t\t\treturn 1;\n\t\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\t\treturn 1;\n\n\t\t\ttryanother:\n\t\t\t\t;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n#endif\n\treturn 0;\n}", "commit_link": "github.com/file/file/commit/a642587a9c9e2dd7feacdf513c3643ce26ad3c22", "file_name": "src/readelf.c", "vul_type": "cwe-125", "description": "Write a C function named `do_core_note` that processes core dump note segments to determine the originating OS and program details."}
{"func_name": "gst_asf_demux_process_ext_content_desc", "func_src_before": "gst_asf_demux_process_ext_content_desc (GstASFDemux * demux, guint8 * data,\n    guint64 size)\n{\n  /* Other known (and unused) 'text/unicode' metadata available :\n   *\n   *   WM/Lyrics =\n   *   WM/MediaPrimaryClassID = {D1607DBC-E323-4BE2-86A1-48A42A28441E}\n   *   WMFSDKVersion = 9.00.00.2980\n   *   WMFSDKNeeded = 0.0.0.0000\n   *   WM/UniqueFileIdentifier = AMGa_id=R    15334;AMGp_id=P     5149;AMGt_id=T  2324984\n   *   WM/Publisher = 4AD\n   *   WM/Provider = AMG\n   *   WM/ProviderRating = 8\n   *   WM/ProviderStyle = Rock (similar to WM/Genre)\n   *   WM/GenreID (similar to WM/Genre)\n   *   WM/TrackNumber (same as WM/Track but as a string)\n   *\n   * Other known (and unused) 'non-text' metadata available :\n   *\n   *   WM/EncodingTime\n   *   WM/MCDI\n   *   IsVBR\n   *\n   * We might want to read WM/TrackNumber and use atoi() if we don't have\n   * WM/Track\n   */\n\n  GstTagList *taglist;\n  guint16 blockcount, i;\n  gboolean content3D = FALSE;\n\n  struct\n  {\n    const gchar *interleave_name;\n    GstASF3DMode interleaving_type;\n  } stereoscopic_layout_map[] = {\n    {\n    \"SideBySideRF\", GST_ASF_3D_SIDE_BY_SIDE_HALF_RL}, {\n    \"SideBySideLF\", GST_ASF_3D_SIDE_BY_SIDE_HALF_LR}, {\n    \"OverUnderRT\", GST_ASF_3D_TOP_AND_BOTTOM_HALF_RL}, {\n    \"OverUnderLT\", GST_ASF_3D_TOP_AND_BOTTOM_HALF_LR}, {\n    \"DualStream\", GST_ASF_3D_DUAL_STREAM}\n  };\n  GST_INFO_OBJECT (demux, \"object is an extended content description\");\n\n  taglist = gst_tag_list_new_empty ();\n\n  /* Content Descriptor Count */\n  if (size < 2)\n    goto not_enough_data;\n\n  blockcount = gst_asf_demux_get_uint16 (&data, &size);\n\n  for (i = 1; i <= blockcount; ++i) {\n    const gchar *gst_tag_name;\n    guint16 datatype;\n    guint16 value_len;\n    guint16 name_len;\n    GValue tag_value = { 0, };\n    gsize in, out;\n    gchar *name;\n    gchar *name_utf8 = NULL;\n    gchar *value;\n\n    /* Descriptor */\n    if (!gst_asf_demux_get_string (&name, &name_len, &data, &size))\n      goto not_enough_data;\n\n    if (size < 2) {\n      g_free (name);\n      goto not_enough_data;\n    }\n    /* Descriptor Value Data Type */\n    datatype = gst_asf_demux_get_uint16 (&data, &size);\n\n    /* Descriptor Value (not really a string, but same thing reading-wise) */\n    if (!gst_asf_demux_get_string (&value, &value_len, &data, &size)) {\n      g_free (name);\n      goto not_enough_data;\n    }\n\n    name_utf8 =\n        g_convert (name, name_len, \"UTF-8\", \"UTF-16LE\", &in, &out, NULL);\n\n    if (name_utf8 != NULL) {\n      GST_DEBUG (\"Found tag/metadata %s\", name_utf8);\n\n      gst_tag_name = gst_asf_demux_get_gst_tag_from_tag_name (name_utf8);\n      GST_DEBUG (\"gst_tag_name %s\", GST_STR_NULL (gst_tag_name));\n\n      switch (datatype) {\n        case ASF_DEMUX_DATA_TYPE_UTF16LE_STRING:{\n          gchar *value_utf8;\n\n          value_utf8 = g_convert (value, value_len, \"UTF-8\", \"UTF-16LE\",\n              &in, &out, NULL);\n\n          /* get rid of tags with empty value */\n          if (value_utf8 != NULL && *value_utf8 != '\\0') {\n            GST_DEBUG (\"string value %s\", value_utf8);\n\n            value_utf8[out] = '\\0';\n\n            if (gst_tag_name != NULL) {\n              if (strcmp (gst_tag_name, GST_TAG_DATE_TIME) == 0) {\n                guint year = atoi (value_utf8);\n\n                if (year > 0) {\n                  g_value_init (&tag_value, GST_TYPE_DATE_TIME);\n                  g_value_take_boxed (&tag_value, gst_date_time_new_y (year));\n                }\n              } else if (strcmp (gst_tag_name, GST_TAG_GENRE) == 0) {\n                guint id3v1_genre_id;\n                const gchar *genre_str;\n\n                if (sscanf (value_utf8, \"(%u)\", &id3v1_genre_id) == 1 &&\n                    ((genre_str = gst_tag_id3_genre_get (id3v1_genre_id)))) {\n                  GST_DEBUG (\"Genre: %s -> %s\", value_utf8, genre_str);\n                  g_free (value_utf8);\n                  value_utf8 = g_strdup (genre_str);\n                }\n              } else {\n                GType tag_type;\n\n                /* convert tag from string to other type if required */\n                tag_type = gst_tag_get_type (gst_tag_name);\n                g_value_init (&tag_value, tag_type);\n                if (!gst_value_deserialize (&tag_value, value_utf8)) {\n                  GValue from_val = { 0, };\n\n                  g_value_init (&from_val, G_TYPE_STRING);\n                  g_value_set_string (&from_val, value_utf8);\n                  if (!g_value_transform (&from_val, &tag_value)) {\n                    GST_WARNING_OBJECT (demux,\n                        \"Could not transform string tag to \" \"%s tag type %s\",\n                        gst_tag_name, g_type_name (tag_type));\n                    g_value_unset (&tag_value);\n                  }\n                  g_value_unset (&from_val);\n                }\n              }\n            } else {\n              /* metadata ! */\n              GST_DEBUG (\"Setting metadata\");\n              g_value_init (&tag_value, G_TYPE_STRING);\n              g_value_set_string (&tag_value, value_utf8);\n              /* If we found a stereoscopic marker, look for StereoscopicLayout\n               * metadata */\n              if (content3D) {\n                guint i;\n                if (strncmp (\"StereoscopicLayout\", name_utf8,\n                        strlen (name_utf8)) == 0) {\n                  for (i = 0; i < G_N_ELEMENTS (stereoscopic_layout_map); i++) {\n                    if (g_str_equal (stereoscopic_layout_map[i].interleave_name,\n                            value_utf8)) {\n                      demux->asf_3D_mode =\n                          stereoscopic_layout_map[i].interleaving_type;\n                      GST_INFO (\"find interleave type %u\", demux->asf_3D_mode);\n                    }\n                  }\n                }\n                GST_INFO_OBJECT (demux, \"3d type is %u\", demux->asf_3D_mode);\n              } else {\n                demux->asf_3D_mode = GST_ASF_3D_NONE;\n                GST_INFO_OBJECT (demux, \"None 3d type\");\n              }\n            }\n          } else if (value_utf8 == NULL) {\n            GST_WARNING (\"Failed to convert string value to UTF8, skipping\");\n          } else {\n            GST_DEBUG (\"Skipping empty string value for %s\",\n                GST_STR_NULL (gst_tag_name));\n          }\n          g_free (value_utf8);\n          break;\n        }\n        case ASF_DEMUX_DATA_TYPE_BYTE_ARRAY:{\n          if (gst_tag_name) {\n            if (!g_str_equal (gst_tag_name, GST_TAG_IMAGE)) {\n              GST_FIXME (\"Unhandled byte array tag %s\",\n                  GST_STR_NULL (gst_tag_name));\n              break;\n            } else {\n              asf_demux_parse_picture_tag (taglist, (guint8 *) value,\n                  value_len);\n            }\n          }\n          break;\n        }\n        case ASF_DEMUX_DATA_TYPE_DWORD:{\n          guint uint_val = GST_READ_UINT32_LE (value);\n\n          /* this is the track number */\n          g_value_init (&tag_value, G_TYPE_UINT);\n\n          /* WM/Track counts from 0 */\n          if (!strcmp (name_utf8, \"WM/Track\"))\n            ++uint_val;\n\n          g_value_set_uint (&tag_value, uint_val);\n          break;\n        }\n          /* Detect 3D */\n        case ASF_DEMUX_DATA_TYPE_BOOL:{\n          gboolean bool_val = GST_READ_UINT32_LE (value);\n\n          if (strncmp (\"Stereoscopic\", name_utf8, strlen (name_utf8)) == 0) {\n            if (bool_val) {\n              GST_INFO_OBJECT (demux, \"This is 3D contents\");\n              content3D = TRUE;\n            } else {\n              GST_INFO_OBJECT (demux, \"This is not 3D contenst\");\n              content3D = FALSE;\n            }\n          }\n\n          break;\n        }\n        default:{\n          GST_DEBUG (\"Skipping tag %s of type %d\", gst_tag_name, datatype);\n          break;\n        }\n      }\n\n      if (G_IS_VALUE (&tag_value)) {\n        if (gst_tag_name) {\n          GstTagMergeMode merge_mode = GST_TAG_MERGE_APPEND;\n\n          /* WM/TrackNumber is more reliable than WM/Track, since the latter\n           * is supposed to have a 0 base but is often wrongly written to start\n           * from 1 as well, so prefer WM/TrackNumber when we have it: either\n           * replace the value added earlier from WM/Track or put it first in\n           * the list, so that it will get picked up by _get_uint() */\n          if (strcmp (name_utf8, \"WM/TrackNumber\") == 0)\n            merge_mode = GST_TAG_MERGE_REPLACE;\n\n          gst_tag_list_add_values (taglist, merge_mode, gst_tag_name,\n              &tag_value, NULL);\n        } else {\n          GST_DEBUG (\"Setting global metadata %s\", name_utf8);\n          gst_structure_set_value (demux->global_metadata, name_utf8,\n              &tag_value);\n        }\n\n        g_value_unset (&tag_value);\n      }\n    }\n\n    g_free (name);\n    g_free (value);\n    g_free (name_utf8);\n  }\n\n  gst_asf_demux_add_global_tags (demux, taglist);\n\n  return GST_FLOW_OK;\n\n  /* Errors */\nnot_enough_data:\n  {\n    GST_WARNING (\"Unexpected end of data parsing ext content desc object\");\n    gst_tag_list_unref (taglist);\n    return GST_FLOW_OK;         /* not really fatal */\n  }\n}", "func_src_after": "gst_asf_demux_process_ext_content_desc (GstASFDemux * demux, guint8 * data,\n    guint64 size)\n{\n  /* Other known (and unused) 'text/unicode' metadata available :\n   *\n   *   WM/Lyrics =\n   *   WM/MediaPrimaryClassID = {D1607DBC-E323-4BE2-86A1-48A42A28441E}\n   *   WMFSDKVersion = 9.00.00.2980\n   *   WMFSDKNeeded = 0.0.0.0000\n   *   WM/UniqueFileIdentifier = AMGa_id=R    15334;AMGp_id=P     5149;AMGt_id=T  2324984\n   *   WM/Publisher = 4AD\n   *   WM/Provider = AMG\n   *   WM/ProviderRating = 8\n   *   WM/ProviderStyle = Rock (similar to WM/Genre)\n   *   WM/GenreID (similar to WM/Genre)\n   *   WM/TrackNumber (same as WM/Track but as a string)\n   *\n   * Other known (and unused) 'non-text' metadata available :\n   *\n   *   WM/EncodingTime\n   *   WM/MCDI\n   *   IsVBR\n   *\n   * We might want to read WM/TrackNumber and use atoi() if we don't have\n   * WM/Track\n   */\n\n  GstTagList *taglist;\n  guint16 blockcount, i;\n  gboolean content3D = FALSE;\n\n  struct\n  {\n    const gchar *interleave_name;\n    GstASF3DMode interleaving_type;\n  } stereoscopic_layout_map[] = {\n    {\n    \"SideBySideRF\", GST_ASF_3D_SIDE_BY_SIDE_HALF_RL}, {\n    \"SideBySideLF\", GST_ASF_3D_SIDE_BY_SIDE_HALF_LR}, {\n    \"OverUnderRT\", GST_ASF_3D_TOP_AND_BOTTOM_HALF_RL}, {\n    \"OverUnderLT\", GST_ASF_3D_TOP_AND_BOTTOM_HALF_LR}, {\n    \"DualStream\", GST_ASF_3D_DUAL_STREAM}\n  };\n  GST_INFO_OBJECT (demux, \"object is an extended content description\");\n\n  taglist = gst_tag_list_new_empty ();\n\n  /* Content Descriptor Count */\n  if (size < 2)\n    goto not_enough_data;\n\n  blockcount = gst_asf_demux_get_uint16 (&data, &size);\n\n  for (i = 1; i <= blockcount; ++i) {\n    const gchar *gst_tag_name;\n    guint16 datatype;\n    guint16 value_len;\n    guint16 name_len;\n    GValue tag_value = { 0, };\n    gsize in, out;\n    gchar *name;\n    gchar *name_utf8 = NULL;\n    gchar *value;\n\n    /* Descriptor */\n    if (!gst_asf_demux_get_string (&name, &name_len, &data, &size))\n      goto not_enough_data;\n\n    if (size < 2) {\n      g_free (name);\n      goto not_enough_data;\n    }\n    /* Descriptor Value Data Type */\n    datatype = gst_asf_demux_get_uint16 (&data, &size);\n\n    /* Descriptor Value (not really a string, but same thing reading-wise) */\n    if (!gst_asf_demux_get_string (&value, &value_len, &data, &size)) {\n      g_free (name);\n      goto not_enough_data;\n    }\n\n    name_utf8 =\n        g_convert (name, name_len, \"UTF-8\", \"UTF-16LE\", &in, &out, NULL);\n\n    if (name_utf8 != NULL) {\n      GST_DEBUG (\"Found tag/metadata %s\", name_utf8);\n\n      gst_tag_name = gst_asf_demux_get_gst_tag_from_tag_name (name_utf8);\n      GST_DEBUG (\"gst_tag_name %s\", GST_STR_NULL (gst_tag_name));\n\n      switch (datatype) {\n        case ASF_DEMUX_DATA_TYPE_UTF16LE_STRING:{\n          gchar *value_utf8;\n\n          value_utf8 = g_convert (value, value_len, \"UTF-8\", \"UTF-16LE\",\n              &in, &out, NULL);\n\n          /* get rid of tags with empty value */\n          if (value_utf8 != NULL && *value_utf8 != '\\0') {\n            GST_DEBUG (\"string value %s\", value_utf8);\n\n            value_utf8[out] = '\\0';\n\n            if (gst_tag_name != NULL) {\n              if (strcmp (gst_tag_name, GST_TAG_DATE_TIME) == 0) {\n                guint year = atoi (value_utf8);\n\n                if (year > 0) {\n                  g_value_init (&tag_value, GST_TYPE_DATE_TIME);\n                  g_value_take_boxed (&tag_value, gst_date_time_new_y (year));\n                }\n              } else if (strcmp (gst_tag_name, GST_TAG_GENRE) == 0) {\n                guint id3v1_genre_id;\n                const gchar *genre_str;\n\n                if (sscanf (value_utf8, \"(%u)\", &id3v1_genre_id) == 1 &&\n                    ((genre_str = gst_tag_id3_genre_get (id3v1_genre_id)))) {\n                  GST_DEBUG (\"Genre: %s -> %s\", value_utf8, genre_str);\n                  g_free (value_utf8);\n                  value_utf8 = g_strdup (genre_str);\n                }\n              } else {\n                GType tag_type;\n\n                /* convert tag from string to other type if required */\n                tag_type = gst_tag_get_type (gst_tag_name);\n                g_value_init (&tag_value, tag_type);\n                if (!gst_value_deserialize (&tag_value, value_utf8)) {\n                  GValue from_val = { 0, };\n\n                  g_value_init (&from_val, G_TYPE_STRING);\n                  g_value_set_string (&from_val, value_utf8);\n                  if (!g_value_transform (&from_val, &tag_value)) {\n                    GST_WARNING_OBJECT (demux,\n                        \"Could not transform string tag to \" \"%s tag type %s\",\n                        gst_tag_name, g_type_name (tag_type));\n                    g_value_unset (&tag_value);\n                  }\n                  g_value_unset (&from_val);\n                }\n              }\n            } else {\n              /* metadata ! */\n              GST_DEBUG (\"Setting metadata\");\n              g_value_init (&tag_value, G_TYPE_STRING);\n              g_value_set_string (&tag_value, value_utf8);\n              /* If we found a stereoscopic marker, look for StereoscopicLayout\n               * metadata */\n              if (content3D) {\n                guint i;\n                if (strncmp (\"StereoscopicLayout\", name_utf8,\n                        strlen (name_utf8)) == 0) {\n                  for (i = 0; i < G_N_ELEMENTS (stereoscopic_layout_map); i++) {\n                    if (g_str_equal (stereoscopic_layout_map[i].interleave_name,\n                            value_utf8)) {\n                      demux->asf_3D_mode =\n                          stereoscopic_layout_map[i].interleaving_type;\n                      GST_INFO (\"find interleave type %u\", demux->asf_3D_mode);\n                    }\n                  }\n                }\n                GST_INFO_OBJECT (demux, \"3d type is %u\", demux->asf_3D_mode);\n              } else {\n                demux->asf_3D_mode = GST_ASF_3D_NONE;\n                GST_INFO_OBJECT (demux, \"None 3d type\");\n              }\n            }\n          } else if (value_utf8 == NULL) {\n            GST_WARNING (\"Failed to convert string value to UTF8, skipping\");\n          } else {\n            GST_DEBUG (\"Skipping empty string value for %s\",\n                GST_STR_NULL (gst_tag_name));\n          }\n          g_free (value_utf8);\n          break;\n        }\n        case ASF_DEMUX_DATA_TYPE_BYTE_ARRAY:{\n          if (gst_tag_name) {\n            if (!g_str_equal (gst_tag_name, GST_TAG_IMAGE)) {\n              GST_FIXME (\"Unhandled byte array tag %s\",\n                  GST_STR_NULL (gst_tag_name));\n              break;\n            } else {\n              asf_demux_parse_picture_tag (taglist, (guint8 *) value,\n                  value_len);\n            }\n          }\n          break;\n        }\n        case ASF_DEMUX_DATA_TYPE_DWORD:{\n          guint uint_val;\n\n          if (value_len < 4)\n            break;\n\n          uint_val = GST_READ_UINT32_LE (value);\n\n          /* this is the track number */\n          g_value_init (&tag_value, G_TYPE_UINT);\n\n          /* WM/Track counts from 0 */\n          if (!strcmp (name_utf8, \"WM/Track\"))\n            ++uint_val;\n\n          g_value_set_uint (&tag_value, uint_val);\n          break;\n        }\n          /* Detect 3D */\n        case ASF_DEMUX_DATA_TYPE_BOOL:{\n          gboolean bool_val;\n\n          if (value_len < 4)\n            break;\n\n          bool_val = GST_READ_UINT32_LE (value);\n\n          if (strncmp (\"Stereoscopic\", name_utf8, strlen (name_utf8)) == 0) {\n            if (bool_val) {\n              GST_INFO_OBJECT (demux, \"This is 3D contents\");\n              content3D = TRUE;\n            } else {\n              GST_INFO_OBJECT (demux, \"This is not 3D contenst\");\n              content3D = FALSE;\n            }\n          }\n\n          break;\n        }\n        default:{\n          GST_DEBUG (\"Skipping tag %s of type %d\", gst_tag_name, datatype);\n          break;\n        }\n      }\n\n      if (G_IS_VALUE (&tag_value)) {\n        if (gst_tag_name) {\n          GstTagMergeMode merge_mode = GST_TAG_MERGE_APPEND;\n\n          /* WM/TrackNumber is more reliable than WM/Track, since the latter\n           * is supposed to have a 0 base but is often wrongly written to start\n           * from 1 as well, so prefer WM/TrackNumber when we have it: either\n           * replace the value added earlier from WM/Track or put it first in\n           * the list, so that it will get picked up by _get_uint() */\n          if (strcmp (name_utf8, \"WM/TrackNumber\") == 0)\n            merge_mode = GST_TAG_MERGE_REPLACE;\n\n          gst_tag_list_add_values (taglist, merge_mode, gst_tag_name,\n              &tag_value, NULL);\n        } else {\n          GST_DEBUG (\"Setting global metadata %s\", name_utf8);\n          gst_structure_set_value (demux->global_metadata, name_utf8,\n              &tag_value);\n        }\n\n        g_value_unset (&tag_value);\n      }\n    }\n\n    g_free (name);\n    g_free (value);\n    g_free (name_utf8);\n  }\n\n  gst_asf_demux_add_global_tags (demux, taglist);\n\n  return GST_FLOW_OK;\n\n  /* Errors */\nnot_enough_data:\n  {\n    GST_WARNING (\"Unexpected end of data parsing ext content desc object\");\n    gst_tag_list_unref (taglist);\n    return GST_FLOW_OK;         /* not really fatal */\n  }\n}", "commit_link": "github.com/GStreamer/gst-plugins-ugly/commit/d21017b52a585f145e8d62781bcc1c5fefc7ee37", "file_name": "gst/asfdemux/gstasfdemux.c", "vul_type": "cwe-125", "description": "Write a C function in GStreamer for processing extended content descriptors in ASF demuxing."}
{"func_name": "enc_untrusted_recvmsg", "func_src_before": "ssize_t enc_untrusted_recvmsg(int sockfd, struct msghdr *msg, int flags) {\n  size_t total_buffer_size = CalculateTotalMessageSize(msg);\n\n  MessageWriter input;\n  input.Push(sockfd);\n  input.Push<uint64_t>(msg->msg_namelen);\n  input.Push<uint64_t>(total_buffer_size);\n  input.Push<uint64_t>(msg->msg_controllen);\n  input.Push(msg->msg_flags);\n  input.Push(flags);\n\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvMsgHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvmsg\", 2,\n                           /*match_exact_params=*/false);\n\n  ssize_t result = output.next<ssize_t>();\n  int klinux_errno = output.next<int>();\n\n  // recvmsg() returns the number of characters received. On error, -1 is\n  // returned, with errno set to indicate the cause of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  auto msg_name_extent = output.next();\n  // The returned |msg_namelen| should not exceed the buffer size.\n  if (msg_name_extent.size() <= msg->msg_namelen) {\n    msg->msg_namelen = msg_name_extent.size();\n  }\n  memcpy(msg->msg_name, msg_name_extent.As<char>(), msg->msg_namelen);\n\n  // A single buffer is passed from the untrusted side, copy it into the\n  // scattered buffers inside the enclave.\n  auto msg_iov_extent = output.next();\n  size_t total_bytes = msg_iov_extent.size();\n  size_t bytes_copied = 0;\n  for (int i = 0; i < msg->msg_iovlen && bytes_copied < total_bytes; ++i) {\n    size_t bytes_to_copy =\n        std::min(msg->msg_iov[i].iov_len, total_bytes - bytes_copied);\n    memcpy(msg->msg_iov[i].iov_base, msg_iov_extent.As<char>() + bytes_copied,\n           bytes_to_copy);\n    bytes_copied += bytes_to_copy;\n  }\n\n  auto msg_control_extent = output.next();\n  // The returned |msg_controllen| should not exceed the buffer size.\n  if (msg_control_extent.size() <= msg->msg_controllen) {\n    msg->msg_controllen = msg_control_extent.size();\n  }\n  memcpy(msg->msg_control, msg_control_extent.As<char>(), msg->msg_controllen);\n\n  return result;\n}", "func_src_after": "ssize_t enc_untrusted_recvmsg(int sockfd, struct msghdr *msg, int flags) {\n  size_t total_buffer_size = CalculateTotalMessageSize(msg);\n\n  MessageWriter input;\n  input.Push(sockfd);\n  input.Push<uint64_t>(msg->msg_namelen);\n  input.Push<uint64_t>(total_buffer_size);\n  input.Push<uint64_t>(msg->msg_controllen);\n  input.Push(msg->msg_flags);\n  input.Push(flags);\n\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvMsgHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvmsg\", 2,\n                           /*match_exact_params=*/false);\n\n  ssize_t result = output.next<ssize_t>();\n  int klinux_errno = output.next<int>();\n\n  // recvmsg() returns the number of characters received. On error, -1 is\n  // returned, with errno set to indicate the cause of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  if (result > total_buffer_size) {\n    ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n        \"enc_untrusted_recvmsg: result exceeds requested\");\n  }\n\n  auto msg_name_extent = output.next();\n  // The returned |msg_namelen| should not exceed the buffer size.\n  if (msg_name_extent.size() <= msg->msg_namelen) {\n    msg->msg_namelen = msg_name_extent.size();\n  }\n  memcpy(msg->msg_name, msg_name_extent.As<char>(), msg->msg_namelen);\n\n  // A single buffer is passed from the untrusted side, copy it into the\n  // scattered buffers inside the enclave.\n  auto msg_iov_extent = output.next();\n  size_t total_bytes = msg_iov_extent.size();\n  size_t bytes_copied = 0;\n  for (int i = 0; i < msg->msg_iovlen && bytes_copied < total_bytes; ++i) {\n    size_t bytes_to_copy =\n        std::min(msg->msg_iov[i].iov_len, total_bytes - bytes_copied);\n    memcpy(msg->msg_iov[i].iov_base, msg_iov_extent.As<char>() + bytes_copied,\n           bytes_to_copy);\n    bytes_copied += bytes_to_copy;\n  }\n\n  auto msg_control_extent = output.next();\n  // The returned |msg_controllen| should not exceed the buffer size.\n  if (msg_control_extent.size() <= msg->msg_controllen) {\n    msg->msg_controllen = msg_control_extent.size();\n  }\n  memcpy(msg->msg_control, msg_control_extent.As<char>(), msg->msg_controllen);\n\n  return result;\n}", "commit_link": "github.com/google/asylo/commit/fa6485c5d16a7355eab047d4a44345a73bc9131e", "file_name": "asylo/platform/host_call/trusted/host_calls.cc", "vul_type": "cwe-125", "description": "Write a C++ function `enc_untrusted_recvmsg` that wraps a system call to receive a message on a socket within an enclave, handling message structure and error conversion."}
{"func_name": "HPHP::HHVM_METHOD", "func_src_before": "static Array HHVM_METHOD(Memcache, getextendedstats,\n                         const String& /*type*/ /* = null_string */,\n                         int /*slabid*/ /* = 0 */, int /*limit*/ /* = 100 */) {\n  auto data = Native::data<MemcacheData>(this_);\n  memcached_return_t ret;\n  memcached_stat_st *stats;\n\n  stats = memcached_stat(&data->m_memcache, nullptr, &ret);\n  if (ret != MEMCACHED_SUCCESS) {\n    return Array();\n  }\n\n  int server_count = memcached_server_count(&data->m_memcache);\n\n  Array return_val;\n\n  for (int server_id = 0; server_id < server_count; server_id++) {\n    memcached_stat_st *stat;\n    char stats_key[30] = {0};\n    size_t key_len;\n\n    LMCD_SERVER_POSITION_INSTANCE_TYPE instance =\n      memcached_server_instance_by_position(&data->m_memcache, server_id);\n    const char *hostname = LMCD_SERVER_HOSTNAME(instance);\n    in_port_t port = LMCD_SERVER_PORT(instance);\n\n    stat = stats + server_id;\n\n    Array server_stats = memcache_build_stats(&data->m_memcache, stat, &ret);\n    if (ret != MEMCACHED_SUCCESS) {\n      continue;\n    }\n\n    key_len = snprintf(stats_key, sizeof(stats_key), \"%s:%d\", hostname, port);\n\n    return_val.set(String(stats_key, key_len, CopyString), server_stats);\n  }\n\n  free(stats);\n  return return_val;\n}", "func_src_after": "static Array HHVM_METHOD(Memcache, getextendedstats,\n                         const String& /*type*/ /* = null_string */,\n                         int /*slabid*/ /* = 0 */, int /*limit*/ /* = 100 */) {\n  auto data = Native::data<MemcacheData>(this_);\n  memcached_return_t ret;\n  memcached_stat_st *stats;\n\n  stats = memcached_stat(&data->m_memcache, nullptr, &ret);\n  if (ret != MEMCACHED_SUCCESS) {\n    return Array();\n  }\n\n  int server_count = memcached_server_count(&data->m_memcache);\n\n  Array return_val;\n\n  for (int server_id = 0; server_id < server_count; server_id++) {\n    memcached_stat_st *stat;\n    LMCD_SERVER_POSITION_INSTANCE_TYPE instance =\n      memcached_server_instance_by_position(&data->m_memcache, server_id);\n    const char *hostname = LMCD_SERVER_HOSTNAME(instance);\n    in_port_t port = LMCD_SERVER_PORT(instance);\n\n    stat = stats + server_id;\n\n    Array server_stats = memcache_build_stats(&data->m_memcache, stat, &ret);\n    if (ret != MEMCACHED_SUCCESS) {\n      continue;\n    }\n\n    auto const port_str = folly::to<std::string>(port);\n    auto const key_len = strlen(hostname) + 1 + port_str.length();\n    auto key = String(key_len, ReserveString);\n    key += hostname;\n    key += \":\";\n    key += port_str;\n    return_val.set(key, server_stats);\n  }\n\n  free(stats);\n  return return_val;\n}", "commit_link": "github.com/facebook/hhvm/commit/4bff3bfbe90d10451e4638c2118d1ad1117bb3e3", "file_name": "hphp/runtime/ext/memcache/ext_memcache.cpp", "vul_type": "cwe-125", "description": "Write a function in HHVM to retrieve extended statistics from all Memcache servers."}
{"func_name": "_get_3par_host", "func_src_before": "    def _get_3par_host(self, hostname):\n        out = self._cli_run('showhost -verbose %s' % (hostname), None)\n        LOG.debug(\"OUTPUT = \\n%s\" % (pprint.pformat(out)))\n        host = {'id': None, 'name': None,\n                'domain': None,\n                'descriptors': {},\n                'iSCSIPaths': [],\n                'FCPaths': []}\n\n        if out:\n            err = out[0]\n            if err == 'no hosts listed':\n                msg = {'code': 'NON_EXISTENT_HOST',\n                       'desc': \"HOST '%s' was not found\" % hostname}\n                raise hpexceptions.HTTPNotFound(msg)\n\n            # start parsing the lines after the header line\n            for line in out[1:]:\n                if line == '':\n                    break\n                tmp = line.split(',')\n                paths = {}\n\n                LOG.debug(\"line = %s\" % (pprint.pformat(tmp)))\n                host['id'] = tmp[0]\n                host['name'] = tmp[1]\n\n                portPos = tmp[4]\n                LOG.debug(\"portPos = %s\" % (pprint.pformat(portPos)))\n                if portPos == '---':\n                    portPos = None\n                else:\n                    port = portPos.split(':')\n                    portPos = {'node': int(port[0]), 'slot': int(port[1]),\n                               'cardPort': int(port[2])}\n\n                paths['portPos'] = portPos\n\n                # If FC entry\n                if tmp[5] == 'n/a':\n                    paths['wwn'] = tmp[3]\n                    host['FCPaths'].append(paths)\n                # else iSCSI entry\n                else:\n                    paths['name'] = tmp[3]\n                    paths['ipAddr'] = tmp[5]\n                    host['iSCSIPaths'].append(paths)\n\n            # find the offset to the description stuff\n            offset = 0\n            for line in out:\n                if line[:15] == '---------- Host':\n                    break\n                else:\n                    offset += 1\n\n            info = out[offset + 2]\n            tmp = info.split(':')\n            host['domain'] = tmp[1]\n\n            info = out[offset + 4]\n            tmp = info.split(':')\n            host['descriptors']['location'] = tmp[1]\n\n            info = out[offset + 5]\n            tmp = info.split(':')\n            host['descriptors']['ipAddr'] = tmp[1]\n\n            info = out[offset + 6]\n            tmp = info.split(':')\n            host['descriptors']['os'] = tmp[1]\n\n            info = out[offset + 7]\n            tmp = info.split(':')\n            host['descriptors']['model'] = tmp[1]\n\n            info = out[offset + 8]\n            tmp = info.split(':')\n            host['descriptors']['contact'] = tmp[1]\n\n            info = out[offset + 9]\n            tmp = info.split(':')\n            host['descriptors']['comment'] = tmp[1]\n\n        return host", "func_src_after": "    def _get_3par_host(self, hostname):\n        out = self._cli_run(['showhost', '-verbose', hostname])\n        LOG.debug(\"OUTPUT = \\n%s\" % (pprint.pformat(out)))\n        host = {'id': None, 'name': None,\n                'domain': None,\n                'descriptors': {},\n                'iSCSIPaths': [],\n                'FCPaths': []}\n\n        if out:\n            err = out[0]\n            if err == 'no hosts listed':\n                msg = {'code': 'NON_EXISTENT_HOST',\n                       'desc': \"HOST '%s' was not found\" % hostname}\n                raise hpexceptions.HTTPNotFound(msg)\n\n            # start parsing the lines after the header line\n            for line in out[1:]:\n                if line == '':\n                    break\n                tmp = line.split(',')\n                paths = {}\n\n                LOG.debug(\"line = %s\" % (pprint.pformat(tmp)))\n                host['id'] = tmp[0]\n                host['name'] = tmp[1]\n\n                portPos = tmp[4]\n                LOG.debug(\"portPos = %s\" % (pprint.pformat(portPos)))\n                if portPos == '---':\n                    portPos = None\n                else:\n                    port = portPos.split(':')\n                    portPos = {'node': int(port[0]), 'slot': int(port[1]),\n                               'cardPort': int(port[2])}\n\n                paths['portPos'] = portPos\n\n                # If FC entry\n                if tmp[5] == 'n/a':\n                    paths['wwn'] = tmp[3]\n                    host['FCPaths'].append(paths)\n                # else iSCSI entry\n                else:\n                    paths['name'] = tmp[3]\n                    paths['ipAddr'] = tmp[5]\n                    host['iSCSIPaths'].append(paths)\n\n            # find the offset to the description stuff\n            offset = 0\n            for line in out:\n                if line[:15] == '---------- Host':\n                    break\n                else:\n                    offset += 1\n\n            info = out[offset + 2]\n            tmp = info.split(':')\n            host['domain'] = tmp[1]\n\n            info = out[offset + 4]\n            tmp = info.split(':')\n            host['descriptors']['location'] = tmp[1]\n\n            info = out[offset + 5]\n            tmp = info.split(':')\n            host['descriptors']['ipAddr'] = tmp[1]\n\n            info = out[offset + 6]\n            tmp = info.split(':')\n            host['descriptors']['os'] = tmp[1]\n\n            info = out[offset + 7]\n            tmp = info.split(':')\n            host['descriptors']['model'] = tmp[1]\n\n            info = out[offset + 8]\n            tmp = info.split(':')\n            host['descriptors']['contact'] = tmp[1]\n\n            info = out[offset + 9]\n            tmp = info.split(':')\n            host['descriptors']['comment'] = tmp[1]\n\n        return host", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "In Python, write a function to parse detailed host information from CLI output."}
{"func_name": "_get_vdisk_attributes", "func_src_before": "    def _get_vdisk_attributes(self, vdisk_name):\n        \"\"\"Return vdisk attributes, or None if vdisk does not exist\n\n        Exception is raised if the information from system can not be\n        parsed/matched to a single vdisk.\n        \"\"\"\n\n        ssh_cmd = 'svcinfo lsvdisk -bytes -delim ! %s ' % vdisk_name\n        return self._execute_command_and_parse_attributes(ssh_cmd)", "func_src_after": "    def _get_vdisk_attributes(self, vdisk_name):\n        \"\"\"Return vdisk attributes, or None if vdisk does not exist\n\n        Exception is raised if the information from system can not be\n        parsed/matched to a single vdisk.\n        \"\"\"\n\n        ssh_cmd = ['svcinfo', 'lsvdisk', '-bytes', '-delim', '!', vdisk_name]\n        return self._execute_command_and_parse_attributes(ssh_cmd)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch virtual disk attributes using an SSH command, handling non-existence and parsing exceptions."}
{"func_name": "git_hook", "func_src_before": "def git_hook(strict=False, modify=False):\n    \"\"\"\n    Git pre-commit hook to check staged files for isort errors\n\n    :param bool strict - if True, return number of errors on exit,\n        causing the hook to fail. If False, return zero so it will\n        just act as a warning.\n    :param bool modify - if True, fix the sources if they are not\n        sorted properly. If False, only report result without\n        modifying anything.\n\n    :return number of errors if in strict mode, 0 otherwise.\n    \"\"\"\n\n    # Get list of files modified and staged\n    diff_cmd = \"git diff-index --cached --name-only --diff-filter=ACMRTUXB HEAD\"\n    files_modified = get_lines(diff_cmd)\n\n    errors = 0\n    for filename in files_modified:\n        if filename.endswith('.py'):\n            # Get the staged contents of the file\n            staged_cmd = \"git show :%s\" % filename\n            staged_contents = get_output(staged_cmd)\n\n            sort = SortImports(\n                file_path=filename,\n                file_contents=staged_contents.decode(),\n                check=True\n            )\n\n            if sort.incorrectly_sorted:\n                errors += 1\n                if modify:\n                    SortImports(\n                        file_path=filename,\n                        file_contents=staged_contents.decode(),\n                        check=False,\n                    )\n\n    return errors if strict else 0", "func_src_after": "def git_hook(strict=False, modify=False):\n    \"\"\"\n    Git pre-commit hook to check staged files for isort errors\n\n    :param bool strict - if True, return number of errors on exit,\n        causing the hook to fail. If False, return zero so it will\n        just act as a warning.\n    :param bool modify - if True, fix the sources if they are not\n        sorted properly. If False, only report result without\n        modifying anything.\n\n    :return number of errors if in strict mode, 0 otherwise.\n    \"\"\"\n\n    # Get list of files modified and staged\n    diff_cmd = [\"git\", \"diff-index\", \"--cached\", \"--name-only\", \"--diff-filter=ACMRTUXB HEAD\"]\n    files_modified = get_lines(diff_cmd)\n\n    errors = 0\n    for filename in files_modified:\n        if filename.endswith('.py'):\n            # Get the staged contents of the file\n            staged_cmd = [\"git\", \"show\", \":%s\" % filename]\n            staged_contents = get_output(staged_cmd)\n\n            sort = SortImports(\n                file_path=filename,\n                file_contents=staged_contents,\n                check=True\n            )\n\n            if sort.incorrectly_sorted:\n                errors += 1\n                if modify:\n                    SortImports(\n                        file_path=filename,\n                        file_contents=staged_contents,\n                        check=False,\n                    )\n\n    return errors if strict else 0", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "isort/hooks.py", "vul_type": "cwe-078", "description": "Write a Python function named `git_hook` that acts as a pre-commit hook to check if Python files are correctly sorted by `isort`, with options to either strictly enforce sorting or just warn, and to modify files if needed."}
{"func_name": "test_create_modify_host", "func_src_before": "    def test_create_modify_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_NO_HOST_RET), ''])\n\n        create_host_cmd = ('createhost -iscsi -add fakehost '\n                           'iqn.1993-08.org.debian:01:222')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_modify_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_NO_HOST_RET), ''])\n\n        create_host_cmd = ['createhost', '-iscsi', '-add', 'fakehost',\n                           'iqn.1993-08.org.debian:01:222']\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying an iSCSI host."}
{"func_name": "_run_ssh", "func_src_before": "    def _run_ssh(self, command, check_exit_code=True, attempts=1):\n        if not self.sshpool:\n            password = self.configuration.san_password\n            privatekey = self.configuration.san_private_key\n            min_size = self.configuration.ssh_min_pool_conn\n            max_size = self.configuration.ssh_max_pool_conn\n            self.sshpool = utils.SSHPool(self.configuration.san_ip,\n                                         self.configuration.san_ssh_port,\n                                         self.configuration.ssh_conn_timeout,\n                                         self.configuration.san_login,\n                                         password=password,\n                                         privatekey=privatekey,\n                                         min_size=min_size,\n                                         max_size=max_size)\n        last_exception = None\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return utils.ssh_execute(\n                            ssh,\n                            command,\n                            check_exit_code=check_exit_code)\n                    except Exception as e:\n                        LOG.error(e)\n                        last_exception = e\n                        greenthread.sleep(random.randint(20, 500) / 100.0)\n                try:\n                    raise exception.ProcessExecutionError(\n                        exit_code=last_exception.exit_code,\n                        stdout=last_exception.stdout,\n                        stderr=last_exception.stderr,\n                        cmd=last_exception.cmd)\n                except AttributeError:\n                    raise exception.ProcessExecutionError(\n                        exit_code=-1,\n                        stdout=\"\",\n                        stderr=\"Error running SSH command\",\n                        cmd=command)\n\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running SSH command: %s\") % command)", "func_src_after": "    def _run_ssh(self, cmd_list, check_exit_code=True, attempts=1):\n        utils.check_ssh_injection(cmd_list)\n        command = ' '. join(cmd_list)\n\n        if not self.sshpool:\n            password = self.configuration.san_password\n            privatekey = self.configuration.san_private_key\n            min_size = self.configuration.ssh_min_pool_conn\n            max_size = self.configuration.ssh_max_pool_conn\n            self.sshpool = utils.SSHPool(self.configuration.san_ip,\n                                         self.configuration.san_ssh_port,\n                                         self.configuration.ssh_conn_timeout,\n                                         self.configuration.san_login,\n                                         password=password,\n                                         privatekey=privatekey,\n                                         min_size=min_size,\n                                         max_size=max_size)\n        last_exception = None\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return utils.ssh_execute(\n                            ssh,\n                            command,\n                            check_exit_code=check_exit_code)\n                    except Exception as e:\n                        LOG.error(e)\n                        last_exception = e\n                        greenthread.sleep(random.randint(20, 500) / 100.0)\n                try:\n                    raise exception.ProcessExecutionError(\n                        exit_code=last_exception.exit_code,\n                        stdout=last_exception.stdout,\n                        stderr=last_exception.stderr,\n                        cmd=last_exception.cmd)\n                except AttributeError:\n                    raise exception.ProcessExecutionError(\n                        exit_code=-1,\n                        stdout=\"\",\n                        stderr=\"Error running SSH command\",\n                        cmd=command)\n\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running SSH command: %s\") % command)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/san/san.py", "vul_type": "cwe-078", "description": "Write a Python function to execute SSH commands with retry logic and connection pooling."}
{"func_name": "view", "func_src_before": "@app.route('/view/<sid>')\ndef view(sid):\n    if '/' not in sid:\n        path = os.path.join(app.config['UPLOAD_FOLDER'], sid)\n        if os.path.isdir(path):\n            using_firebase = 'true' if app.config['FIREBASE'] else 'false'\n            return render_template('view.html',\n            sid=sid, title=\"Progress for %s\" % sid, using_firebase=using_firebase)\n        else:\n            abort(404)\n    else:\n        abort(403)", "func_src_after": "@app.route('/view/<sid>')\ndef view(sid):\n    if utils.sid_is_valid(sid):\n        path = join(app.config['UPLOAD_FOLDER'], sid)\n        if os.path.isdir(path):\n            using_firebase = 'true' if app.config['FIREBASE'] else 'false'\n            return render_template('view.html', sid=sid,\n                                    title=\"Progress for %s\" % sid,\n                                    using_firebase=using_firebase)\n        else:\n            abort(404)\n    else:\n        abort(403)", "commit_link": "github.com/cheukyin699/genset-demo-site/commit/abb55b1a6786b0a995c2cdf77a7977a1d51cfc0d", "file_name": "app/views.py", "vul_type": "cwe-078", "description": "Create a Python Flask route handler that checks if a provided 'sid' is valid and serves a directory if it exists, or aborts with an error if not."}
{"func_name": "get_title_from_youtube_url", "func_src_before": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output('youtube-dl --get-title %s --no-warnings' % url, stderr=subprocess.STDOUT,\n                                             shell=True)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "func_src_after": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output(['youtube-dl', '--get-title', url, '--no-warnings'],\n                                             stderr=subprocess.STDOUT)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "commit_link": "github.com/w-martin/mindfulness/commit/62e1d5ce9deb57468cf917ce0ce838120ec84c46", "file_name": "src/util.py", "vul_type": "cwe-078", "description": "Write a Python function that extracts the title of a YouTube video from its URL using the `youtube-dl` command-line program, handling any potential errors."}
{"func_name": "test_get_ports", "func_src_before": "    def test_get_ports(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI),\n                                                    ''])\n        self.mox.ReplayAll()\n\n        ports = self.driver.common.get_ports()\n        self.assertEqual(ports['FC'][0], '20210002AC00383D')\n        self.assertEqual(ports['iSCSI']['10.10.120.252']['nsp'], '0:8:2')", "func_src_after": "    def test_get_ports(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI),\n                                                    ''])\n        self.mox.ReplayAll()\n\n        ports = self.driver.common.get_ports()\n        self.assertEqual(ports['FC'][0], '20210002AC00383D')\n        self.assertEqual(ports['iSCSI']['10.10.120.252']['nsp'], '0:8:2')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands to retrieve port information and asserts the results."}
{"func_name": "_create_3par_vlun", "func_src_before": "    def _create_3par_vlun(self, volume, hostname):\n        out = self._cli_run('createvlun %s auto %s' % (volume, hostname), None)\n        if out and len(out) > 1:\n            if \"must be in the same domain\" in out[0]:\n                err = out[0].strip()\n                err = err + \" \" + out[1].strip()\n                raise exception.Invalid3PARDomain(err=err)", "func_src_after": "    def _create_3par_vlun(self, volume, hostname):\n        out = self._cli_run(['createvlun', volume, 'auto', hostname])\n        if out and len(out) > 1:\n            if \"must be in the same domain\" in out[0]:\n                err = out[0].strip()\n                err = err + \" \" + out[1].strip()\n                raise exception.Invalid3PARDomain(err=err)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to create a 3PAR VLUN, handling domain mismatch errors."}
{"func_name": "_set_connections", "func_src_before": "    def _set_connections(self):\n        \"\"\"Set the number of concurrent connections.\n\n        The 3PAR WS API server has a limit of concurrent connections.\n        This is setting the number to the highest allowed, 15 connections.\n        \"\"\"\n        self._cli_run(\"setwsapi -sru high\", None)", "func_src_after": "    def _set_connections(self):\n        \"\"\"Set the number of concurrent connections.\n\n        The 3PAR WS API server has a limit of concurrent connections.\n        This is setting the number to the highest allowed, 15 connections.\n        \"\"\"\n        self._cli_run(['setwsapi', '-sru', 'high'])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to configure the maximum number of concurrent connections for a 3PAR WS API server."}
{"func_name": "_get_chap_secret_for_host", "func_src_before": "    def _get_chap_secret_for_host(self, host_name):\n        \"\"\"Return the CHAP secret for the given host.\"\"\"\n\n        LOG.debug(_('enter: _get_chap_secret_for_host: host name %s')\n                  % host_name)\n\n        ssh_cmd = 'svcinfo lsiscsiauth -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        host_lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(host_lines), '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n\n        header = host_lines.pop(0).split('!')\n        self._assert_ssh_return('name' in header, '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n        self._assert_ssh_return('iscsi_auth_method' in header,\n                                '_get_chap_secret_for_host', ssh_cmd, out, err)\n        self._assert_ssh_return('iscsi_chap_secret' in header,\n                                '_get_chap_secret_for_host', ssh_cmd, out, err)\n        name_index = header.index('name')\n        method_index = header.index('iscsi_auth_method')\n        secret_index = header.index('iscsi_chap_secret')\n\n        chap_secret = None\n        host_found = False\n        for line in host_lines:\n            info = line.split('!')\n            if info[name_index] == host_name:\n                host_found = True\n                if info[method_index] == 'chap':\n                    chap_secret = info[secret_index]\n\n        self._assert_ssh_return(host_found, '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _get_chap_secret_for_host: host name '\n                    '%(host_name)s with secret %(chap_secret)s')\n                  % {'host_name': host_name, 'chap_secret': chap_secret})\n\n        return chap_secret", "func_src_after": "    def _get_chap_secret_for_host(self, host_name):\n        \"\"\"Return the CHAP secret for the given host.\"\"\"\n\n        LOG.debug(_('enter: _get_chap_secret_for_host: host name %s')\n                  % host_name)\n\n        ssh_cmd = ['svcinfo', 'lsiscsiauth', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        host_lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(host_lines), '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n\n        header = host_lines.pop(0).split('!')\n        self._assert_ssh_return('name' in header, '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n        self._assert_ssh_return('iscsi_auth_method' in header,\n                                '_get_chap_secret_for_host', ssh_cmd, out, err)\n        self._assert_ssh_return('iscsi_chap_secret' in header,\n                                '_get_chap_secret_for_host', ssh_cmd, out, err)\n        name_index = header.index('name')\n        method_index = header.index('iscsi_auth_method')\n        secret_index = header.index('iscsi_chap_secret')\n\n        chap_secret = None\n        host_found = False\n        for line in host_lines:\n            info = line.split('!')\n            if info[name_index] == host_name:\n                host_found = True\n                if info[method_index] == 'chap':\n                    chap_secret = info[secret_index]\n\n        self._assert_ssh_return(host_found, '_get_chap_secret_for_host',\n                                ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _get_chap_secret_for_host: host name '\n                    '%(host_name)s with secret %(chap_secret)s')\n                  % {'host_name': host_name, 'chap_secret': chap_secret})\n\n        return chap_secret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve the CHAP secret for a specified host by executing an SSH command and parsing the output."}
{"func_name": "tensorflow::KernelAndDeviceOp::Run", "func_src_before": "Status KernelAndDeviceOp::Run(\n    ScopedStepContainer* step_container, const EagerKernelArgs& inputs,\n    std::vector<EagerKernelRet>* outputs,\n    CancellationManager* cancellation_manager,\n    const absl::optional<EagerRemoteFunctionParams>& remote_func_params) {\n  OpKernelContext::Params params;\n  params.device = device_;\n  params.frame_iter = FrameAndIter(0, 0);\n  params.inputs = inputs.GetTensorValues();\n  params.op_kernel = kernel_.get();\n  params.resource_manager = device_->resource_manager();\n  params.input_alloc_attrs = &input_alloc_attrs_;\n  params.output_attr_array = output_alloc_attrs_.data();\n  params.function_library = flr_;\n  params.slice_reader_cache = &slice_reader_cache_;\n  params.rendezvous = rendezvous_;\n  OpExecutionState* op_execution_state = nullptr;\n\n  CancellationManager default_cancellation_manager;\n  if (cancellation_manager) {\n    params.cancellation_manager = cancellation_manager;\n  } else if (kernel_->is_deferred()) {\n    op_execution_state = new OpExecutionState;\n    params.cancellation_manager = &op_execution_state->cancellation_manager;\n    params.inc_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Ref();\n    };\n    params.dec_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Unref();\n    };\n  } else {\n    params.cancellation_manager = &default_cancellation_manager;\n  }\n\n  params.log_memory = log_memory_;\n\n  params.runner = get_runner();\n\n  params.step_container =\n      step_container == nullptr ? &step_container_ : step_container;\n  auto step_container_cleanup = gtl::MakeCleanup([step_container, this] {\n    if (step_container == nullptr) {\n      this->step_container_.CleanUp();\n    }\n  });\n\n  params.collective_executor =\n      collective_executor_ ? collective_executor_->get() : nullptr;\n\n  OpKernelContext context(&params);\n\n  {\n    port::ScopedFlushDenormal flush;\n    port::ScopedSetRound round(FE_TONEAREST);\n    // 'AnnotatedTraceMe' will trace both scheduling time on host and execution\n    // time on device of the OpKernel.\n    profiler::AnnotatedTraceMe activity(\n        [&] { return kernel_->TraceString(context, /*verbose=*/false); },\n        profiler::TraceMeLevel::kInfo);\n    device_->Compute(kernel_.get(), &context);\n  }\n\n  // Clean up execution op_execution_state if deferred ops aren't running.\n  if (op_execution_state != nullptr) {\n    op_execution_state->Unref();\n  }\n\n  if (!context.status().ok()) return context.status();\n\n  if (outputs != nullptr) {\n    outputs->clear();\n    for (int i = 0; i < context.num_outputs(); ++i) {\n      outputs->push_back(Tensor(*context.mutable_output(i)));\n    }\n  }\n  return Status::OK();\n}", "func_src_after": "Status KernelAndDeviceOp::Run(\n    ScopedStepContainer* step_container, const EagerKernelArgs& inputs,\n    std::vector<EagerKernelRet>* outputs,\n    CancellationManager* cancellation_manager,\n    const absl::optional<EagerRemoteFunctionParams>& remote_func_params) {\n  OpKernelContext::Params params;\n  params.device = device_;\n  params.frame_iter = FrameAndIter(0, 0);\n  params.inputs = inputs.GetTensorValues();\n  params.op_kernel = kernel_.get();\n  params.resource_manager = device_->resource_manager();\n  params.input_alloc_attrs = &input_alloc_attrs_;\n  params.output_attr_array = output_alloc_attrs_.data();\n  params.function_library = flr_;\n  params.slice_reader_cache = &slice_reader_cache_;\n  params.rendezvous = rendezvous_;\n  OpExecutionState* op_execution_state = nullptr;\n\n  CancellationManager default_cancellation_manager;\n  if (cancellation_manager) {\n    params.cancellation_manager = cancellation_manager;\n  } else if (kernel_->is_deferred()) {\n    op_execution_state = new OpExecutionState;\n    params.cancellation_manager = &op_execution_state->cancellation_manager;\n    params.inc_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Ref();\n    };\n    params.dec_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Unref();\n    };\n  } else {\n    params.cancellation_manager = &default_cancellation_manager;\n  }\n\n  params.log_memory = log_memory_;\n\n  params.runner = get_runner();\n\n  params.step_container =\n      step_container == nullptr ? &step_container_ : step_container;\n  auto step_container_cleanup = gtl::MakeCleanup([step_container, this] {\n    if (step_container == nullptr) {\n      this->step_container_.CleanUp();\n    }\n  });\n\n  params.collective_executor =\n      collective_executor_ ? collective_executor_->get() : nullptr;\n\n  OpKernelContext context(&params);\n\n  {\n    port::ScopedFlushDenormal flush;\n    port::ScopedSetRound round(FE_TONEAREST);\n    // 'AnnotatedTraceMe' will trace both scheduling time on host and execution\n    // time on device of the OpKernel.\n    profiler::AnnotatedTraceMe activity(\n        [&] { return kernel_->TraceString(context, /*verbose=*/false); },\n        profiler::TraceMeLevel::kInfo);\n    device_->Compute(kernel_.get(), &context);\n  }\n\n  // Clean up execution op_execution_state if deferred ops aren't running.\n  if (op_execution_state != nullptr) {\n    op_execution_state->Unref();\n  }\n\n  if (!context.status().ok()) return context.status();\n\n  if (outputs != nullptr) {\n    outputs->clear();\n    for (int i = 0; i < context.num_outputs(); ++i) {\n      const auto* output_tensor = context.mutable_output(i);\n      if (output_tensor != nullptr) {\n        outputs->push_back(Tensor(*output_tensor));\n      } else {\n        outputs->push_back(Tensor());\n      }\n    }\n  }\n  return Status::OK();\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/da8558533d925694483d2c136a9220d6d49d843c", "file_name": "tensorflow/core/common_runtime/eager/kernel_and_device.cc", "vul_type": "cwe-476", "description": "Write a C++ function to execute a kernel operation with input arguments, output handling, and cancellation support."}
{"func_name": "check_client_passwd", "func_src_before": "static bool check_client_passwd(PgSocket *client, const char *passwd)\n{\n\tchar md5[MD5_PASSWD_LEN + 1];\n\tconst char *correct;\n\tPgUser *user = client->auth_user;\n\n\t/* disallow empty passwords */\n\tif (!*passwd || !*user->passwd)\n\t\treturn false;\n\n\tswitch (cf_auth_type) {\n\tcase AUTH_PLAIN:\n\t\treturn strcmp(user->passwd, passwd) == 0;\n\tcase AUTH_CRYPT:\n\t\tcorrect = crypt(user->passwd, (char *)client->tmp_login_salt);\n\t\treturn correct && strcmp(correct, passwd) == 0;\n\tcase AUTH_MD5:\n\t\tif (strlen(passwd) != MD5_PASSWD_LEN)\n\t\t\treturn false;\n\t\tif (!isMD5(user->passwd))\n\t\t\tpg_md5_encrypt(user->passwd, user->name, strlen(user->name), user->passwd);\n\t\tpg_md5_encrypt(user->passwd + 3, (char *)client->tmp_login_salt, 4, md5);\n\t\treturn strcmp(md5, passwd) == 0;\n\t}\n\treturn false;\n}", "func_src_after": "static bool check_client_passwd(PgSocket *client, const char *passwd)\n{\n\tchar md5[MD5_PASSWD_LEN + 1];\n\tconst char *correct;\n\tPgUser *user = client->auth_user;\n\n\t/* auth_user may be missing */\n\tif (!user) {\n\t\tslog_error(client, \"Password packet before auth packet?\");\n\t\treturn false;\n\t}\n\n\t/* disallow empty passwords */\n\tif (!*passwd || !*user->passwd)\n\t\treturn false;\n\n\tswitch (cf_auth_type) {\n\tcase AUTH_PLAIN:\n\t\treturn strcmp(user->passwd, passwd) == 0;\n\tcase AUTH_CRYPT:\n\t\tcorrect = crypt(user->passwd, (char *)client->tmp_login_salt);\n\t\treturn correct && strcmp(correct, passwd) == 0;\n\tcase AUTH_MD5:\n\t\tif (strlen(passwd) != MD5_PASSWD_LEN)\n\t\t\treturn false;\n\t\tif (!isMD5(user->passwd))\n\t\t\tpg_md5_encrypt(user->passwd, user->name, strlen(user->name), user->passwd);\n\t\tpg_md5_encrypt(user->passwd + 3, (char *)client->tmp_login_salt, 4, md5);\n\t\treturn strcmp(md5, passwd) == 0;\n\t}\n\treturn false;\n}", "commit_link": "github.com/pgbouncer/pgbouncer/commit/edab5be6665b9e8de66c25ba527509b229468573", "file_name": "src/client.c", "vul_type": "cwe-476", "description": "In C, write a function to validate a client's password using different authentication methods (plain, crypt, MD5)."}
{"func_name": "rds_tcp_kill_sock", "func_src_before": "static void rds_tcp_kill_sock(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tstruct sock *sk;\n\tLIST_HEAD(tmp_list);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_listen_stop(rtn->rds_tcp_listen_sock);\n\trtn->rds_tcp_listen_sock = NULL;\n\tflush_work(&rtn->rds_tcp_accept_w);\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->conn->c_net);\n\n\t\tif (net != c_net)\n\t\t\tcontinue;\n\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node) {\n\t\tsk = tc->t_sock->sk;\n\t\tsk->sk_prot->disconnect(sk, 0);\n\t\ttcp_done(sk);\n\t\tif (tc->conn->c_passive)\n\t\t\trds_conn_destroy(tc->conn->c_passive);\n\t\trds_conn_destroy(tc->conn);\n\t}\n}", "func_src_after": "static void rds_tcp_kill_sock(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tstruct sock *sk;\n\tLIST_HEAD(tmp_list);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_listen_stop(rtn->rds_tcp_listen_sock);\n\trtn->rds_tcp_listen_sock = NULL;\n\tflush_work(&rtn->rds_tcp_accept_w);\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->conn->c_net);\n\n\t\tif (net != c_net)\n\t\t\tcontinue;\n\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node) {\n\t\tif (tc->t_sock) {\n\t\t\tsk = tc->t_sock->sk;\n\t\t\tsk->sk_prot->disconnect(sk, 0);\n\t\t\ttcp_done(sk);\n\t\t}\n\t\tif (tc->conn->c_passive)\n\t\t\trds_conn_destroy(tc->conn->c_passive);\n\t\trds_conn_destroy(tc->conn);\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/91573ae4aed0a49660abdad4d42f2a0db995ee5e", "file_name": "net/rds/tcp.c", "vul_type": "cwe-476", "description": "Write a C function named `rds_tcp_kill_sock` that disconnects and cleans up TCP connections in a given network namespace."}
{"func_name": "ReadXCFImage", "func_src_before": "static Image *ReadXCFImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  char\n    magick[14];\n\n  Image\n    *image;\n\n  int\n    foundPropEnd = 0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  register ssize_t\n    i;\n\n  size_t\n    image_type,\n    length;\n\n  ssize_t\n    count;\n\n  XCFDocInfo\n    doc_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  count=ReadBlob(image,14,(unsigned char *) magick);\n  if ((count != 14) ||\n      (LocaleNCompare((char *) magick,\"gimp xcf\",8) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ResetMagickMemory(&doc_info,0,sizeof(XCFDocInfo));\n  doc_info.exception=exception;\n  doc_info.width=ReadBlobMSBLong(image);\n  doc_info.height=ReadBlobMSBLong(image);\n  if ((doc_info.width > 262144) || (doc_info.height > 262144))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  doc_info.image_type=ReadBlobMSBLong(image);\n  /*\n    Initialize image attributes.\n  */\n  image->columns=doc_info.width;\n  image->rows=doc_info.height;\n  image_type=doc_info.image_type;\n  doc_info.file_size=GetBlobSize(image);\n  image->compression=NoCompression;\n  image->depth=8;\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  if (image_type == GIMP_RGB)\n    ;\n  else\n    if (image_type == GIMP_GRAY)\n      image->colorspace=GRAYColorspace;\n    else\n      if (image_type == GIMP_INDEXED)\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n  (void) SetImageOpacity(image,OpaqueOpacity); \n  (void) SetImageBackgroundColor(image);\n  /*\n    Read properties.\n  */\n  while ((foundPropEnd == MagickFalse) && (EOFBlob(image) == MagickFalse))\n  {\n    PropType prop_type = (PropType) ReadBlobMSBLong(image);\n    size_t prop_size = ReadBlobMSBLong(image);\n\n    switch (prop_type)\n    {\n      case PROP_END:\n        foundPropEnd=1;\n        break;\n      case PROP_COLORMAP:\n      {\n        /* Cannot rely on prop_size here--the value is set incorrectly\n           by some Gimp versions.\n        */\n        size_t num_colours = ReadBlobMSBLong(image);\n        if (DiscardBlobBytes(image,3*num_colours) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n    /*\n      if (info->file_version == 0)\n      {\n        gint i;\n\n        g_message (_(\"XCF warning: version 0 of XCF file format\\n\"\n           \"did not save indexed colormaps correctly.\\n\"\n           \"Substituting grayscale map.\"));\n        info->cp +=\n          xcf_read_int32 (info->fp, (guint32*) &gimage->num_cols, 1);\n        gimage->cmap = g_new (guchar, gimage->num_cols*3);\n        xcf_seek_pos (info, info->cp + gimage->num_cols);\n        for (i = 0; i<gimage->num_cols; i++)\n          {\n            gimage->cmap[i*3+0] = i;\n            gimage->cmap[i*3+1] = i;\n            gimage->cmap[i*3+2] = i;\n          }\n      }\n      else\n      {\n        info->cp +=\n          xcf_read_int32 (info->fp, (guint32*) &gimage->num_cols, 1);\n        gimage->cmap = g_new (guchar, gimage->num_cols*3);\n        info->cp +=\n          xcf_read_int8 (info->fp,\n                   (guint8*) gimage->cmap, gimage->num_cols*3);\n      }\n     */\n        break;\n      }\n      case PROP_COMPRESSION:\n      {\n        doc_info.compression = ReadBlobByte(image);\n        if ((doc_info.compression != COMPRESS_NONE) &&\n            (doc_info.compression != COMPRESS_RLE) &&\n            (doc_info.compression != COMPRESS_ZLIB) &&\n            (doc_info.compression != COMPRESS_FRACTAL))\n          ThrowReaderException(CorruptImageError,\"UnrecognizedImageCompression\");\n      }\n      break;\n\n      case PROP_GUIDES:\n      {\n         /* just skip it - we don't care about guides */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n      }\n      break;\n\n    case PROP_RESOLUTION:\n      {\n        /* float xres = (float) */ (void) ReadBlobMSBLong(image);\n        /* float yres = (float) */ (void) ReadBlobMSBLong(image);\n\n        /*\n        if (xres < GIMP_MIN_RESOLUTION || xres > GIMP_MAX_RESOLUTION ||\n            yres < GIMP_MIN_RESOLUTION || yres > GIMP_MAX_RESOLUTION)\n        {\n        g_message (\"Warning, resolution out of range in XCF file\");\n        xres = gimage->gimp->config->default_xresolution;\n        yres = gimage->gimp->config->default_yresolution;\n        }\n        */\n\n\n        /* BOGUS: we don't write these yet because we aren't\n              reading them properly yet :(\n              image->x_resolution = xres;\n              image->y_resolution = yres;\n        */\n      }\n      break;\n\n    case PROP_TATTOO:\n      {\n        /* we need to read it, even if we ignore it */\n        /*size_t  tattoo_state = */ (void) ReadBlobMSBLong(image);\n      }\n      break;\n\n    case PROP_PARASITES:\n      {\n        /* BOGUS: we may need these for IPTC stuff */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n        /*\n      gssize_t         base = info->cp;\n      GimpParasite *p;\n\n      while (info->cp - base < prop_size)\n        {\n          p = xcf_load_parasite (info);\n          gimp_image_parasite_attach (gimage, p);\n          gimp_parasite_free (p);\n        }\n      if (info->cp - base != prop_size)\n        g_message (\"Error detected while loading an image's parasites\");\n      */\n          }\n      break;\n\n    case PROP_UNIT:\n      {\n        /* BOGUS: ignore for now... */\n      /*size_t unit =  */ (void) ReadBlobMSBLong(image);\n      }\n      break;\n\n    case PROP_PATHS:\n      {\n      /* BOGUS: just skip it for now */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n\n        /*\n      PathList *paths = xcf_load_bzpaths (gimage, info);\n      gimp_image_set_paths (gimage, paths);\n      */\n      }\n      break;\n\n    case PROP_USER_UNIT:\n      {\n        char  unit_string[1000];\n        /*BOGUS: ignored for now */\n        /*float  factor = (float) */ (void) ReadBlobMSBLong(image);\n        /* size_t digits =  */ (void) ReadBlobMSBLong(image);\n        for (i=0; i<5; i++)\n         (void) ReadBlobStringWithLongSize(image, unit_string,\n           sizeof(unit_string));\n      }\n     break;\n\n      default:\n      {\n        int buf[16];\n        ssize_t amount;\n\n      /* read over it... */\n      while ((prop_size > 0) && (EOFBlob(image) == MagickFalse))\n      {\n        amount=(ssize_t) MagickMin(16, prop_size);\n        amount=(ssize_t) ReadBlob(image,(size_t) amount,(unsigned char *) &buf);\n        if (!amount)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n        prop_size -= (size_t) MagickMin(16,(size_t) amount);\n      }\n    }\n    break;\n  }\n  }\n  if (foundPropEnd == MagickFalse)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n    {\n      ; /* do nothing, were just pinging! */\n    }\n  else\n    {\n      int\n        current_layer = 0,\n        foundAllLayers = MagickFalse,\n        number_layers = 0;\n\n      MagickOffsetType\n        oldPos=TellBlob(image);\n\n      XCFLayerInfo\n        *layer_info;\n\n      /*\n        The read pointer.\n      */\n      do\n      {\n        ssize_t offset = ReadBlobMSBSignedLong(image);\n        if (offset == 0)\n          foundAllLayers=MagickTrue;\n        else\n          number_layers++;\n        if (EOFBlob(image) != MagickFalse)\n          {\n            ThrowFileException(exception,CorruptImageError,\n              \"UnexpectedEndOfFile\",image->filename);\n            break;\n          }\n    } while (foundAllLayers == MagickFalse);\n    doc_info.number_layers=number_layers;\n    offset=SeekBlob(image,oldPos,SEEK_SET); /* restore the position! */\n    if (offset < 0)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    /* allocate our array of layer info blocks */\n    length=(size_t) number_layers;\n    layer_info=(XCFLayerInfo *) AcquireQuantumMemory(length,\n      sizeof(*layer_info));\n    if (layer_info == (XCFLayerInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(layer_info,0,number_layers*sizeof(XCFLayerInfo));\n    for ( ; ; )\n    {\n      MagickBooleanType\n        layer_ok;\n\n      MagickOffsetType\n        offset,\n        saved_pos;\n\n      /* read in the offset of the next layer */\n      offset=(MagickOffsetType) ReadBlobMSBLong(image);\n      /* if the offset is 0 then we are at the end\n      *  of the layer list.\n      */\n      if (offset == 0)\n        break;\n      /* save the current position as it is where the\n      *  next layer offset is stored.\n      */\n      saved_pos=TellBlob(image);\n      /* seek to the layer offset */\n      if (SeekBlob(image,offset,SEEK_SET) != offset)\n        ThrowReaderException(ResourceLimitError,\"NotEnoughPixelData\");\n      /* read in the layer */\n      layer_ok=ReadOneLayer(image_info,image,&doc_info,\n        &layer_info[current_layer],current_layer);\n      if (layer_ok == MagickFalse)\n        {\n          int j;\n\n          for (j=0; j < current_layer; j++)\n            layer_info[j].image=DestroyImage(layer_info[j].image);\n          layer_info=(XCFLayerInfo *) RelinquishMagickMemory(layer_info);\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        }\n      /* restore the saved position so we'll be ready to\n      *  read the next offset.\n      */\n      offset=SeekBlob(image, saved_pos, SEEK_SET);\n      current_layer++;\n    }\n#if 0\n        {\n        /* NOTE: XCF layers are REVERSED from composite order! */\n        signed int  j;\n        for (j=number_layers-1; j>=0; j--) {\n          /* BOGUS: need to consider layer blending modes!! */\n\n          if ( layer_info[j].visible ) { /* only visible ones, please! */\n            CompositeImage(image, OverCompositeOp, layer_info[j].image,\n                     layer_info[j].offset_x, layer_info[j].offset_y );\n             layer_info[j].image =DestroyImage( layer_info[j].image );\n\n            /* If we do this, we'll get REAL gray images! */\n            if ( image_type == GIMP_GRAY ) {\n              QuantizeInfo  qi;\n              GetQuantizeInfo(&qi);\n              qi.colorspace = GRAYColorspace;\n              QuantizeImage( &qi, layer_info[j].image );\n            }\n          }\n        }\n      }\n#else\n      {\n        /* NOTE: XCF layers are REVERSED from composite order! */\n        ssize_t  j;\n\n        /* now reverse the order of the layers as they are put\n           into subimages\n        */\n        for (j=(long) number_layers-1; j >= 0; j--)\n          AppendImageToList(&image,layer_info[j].image);\n      }\n#endif\n\n    layer_info=(XCFLayerInfo *) RelinquishMagickMemory(layer_info);\n\n#if 0  /* BOGUS: do we need the channels?? */\n    while (MagickTrue)\n    {\n      /* read in the offset of the next channel */\n      info->cp += xcf_read_int32 (info->fp, &offset, 1);\n\n      /* if the offset is 0 then we are at the end\n      *  of the channel list.\n      */\n      if (offset == 0)\n        break;\n\n      /* save the current position as it is where the\n      *  next channel offset is stored.\n      */\n      saved_pos = info->cp;\n\n      /* seek to the channel offset */\n      xcf_seek_pos (info, offset);\n\n      /* read in the layer */\n      channel = xcf_load_channel (info, gimage);\n      if (channel == 0)\n        goto error;\n\n      num_successful_elements++;\n\n      /* add the channel to the image if its not the selection */\n      if (channel != gimage->selection_mask)\n        gimp_image_add_channel (gimage, channel, -1);\n\n      /* restore the saved position so we'll be ready to\n      *  read the next offset.\n      */\n      xcf_seek_pos (info, saved_pos);\n    }\n#endif\n  }\n\n  (void) CloseBlob(image);\n  DestroyImage(RemoveFirstImageFromList(&image));\n  if (image_type == GIMP_GRAY)\n    image->type=GrayscaleType;\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadXCFImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  char\n    magick[14];\n\n  Image\n    *image;\n\n  int\n    foundPropEnd = 0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  register ssize_t\n    i;\n\n  size_t\n    image_type,\n    length;\n\n  ssize_t\n    count;\n\n  XCFDocInfo\n    doc_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  count=ReadBlob(image,14,(unsigned char *) magick);\n  if ((count != 14) ||\n      (LocaleNCompare((char *) magick,\"gimp xcf\",8) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ResetMagickMemory(&doc_info,0,sizeof(XCFDocInfo));\n  doc_info.exception=exception;\n  doc_info.width=ReadBlobMSBLong(image);\n  doc_info.height=ReadBlobMSBLong(image);\n  if ((doc_info.width > 262144) || (doc_info.height > 262144))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  doc_info.image_type=ReadBlobMSBLong(image);\n  /*\n    Initialize image attributes.\n  */\n  image->columns=doc_info.width;\n  image->rows=doc_info.height;\n  image_type=doc_info.image_type;\n  doc_info.file_size=GetBlobSize(image);\n  image->compression=NoCompression;\n  image->depth=8;\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  if (image_type == GIMP_RGB)\n    ;\n  else\n    if (image_type == GIMP_GRAY)\n      image->colorspace=GRAYColorspace;\n    else\n      if (image_type == GIMP_INDEXED)\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n  (void) SetImageOpacity(image,OpaqueOpacity); \n  (void) SetImageBackgroundColor(image);\n  /*\n    Read properties.\n  */\n  while ((foundPropEnd == MagickFalse) && (EOFBlob(image) == MagickFalse))\n  {\n    PropType prop_type = (PropType) ReadBlobMSBLong(image);\n    size_t prop_size = ReadBlobMSBLong(image);\n\n    switch (prop_type)\n    {\n      case PROP_END:\n        foundPropEnd=1;\n        break;\n      case PROP_COLORMAP:\n      {\n        /* Cannot rely on prop_size here--the value is set incorrectly\n           by some Gimp versions.\n        */\n        size_t num_colours = ReadBlobMSBLong(image);\n        if (DiscardBlobBytes(image,3*num_colours) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n    /*\n      if (info->file_version == 0)\n      {\n        gint i;\n\n        g_message (_(\"XCF warning: version 0 of XCF file format\\n\"\n           \"did not save indexed colormaps correctly.\\n\"\n           \"Substituting grayscale map.\"));\n        info->cp +=\n          xcf_read_int32 (info->fp, (guint32*) &gimage->num_cols, 1);\n        gimage->cmap = g_new (guchar, gimage->num_cols*3);\n        xcf_seek_pos (info, info->cp + gimage->num_cols);\n        for (i = 0; i<gimage->num_cols; i++)\n          {\n            gimage->cmap[i*3+0] = i;\n            gimage->cmap[i*3+1] = i;\n            gimage->cmap[i*3+2] = i;\n          }\n      }\n      else\n      {\n        info->cp +=\n          xcf_read_int32 (info->fp, (guint32*) &gimage->num_cols, 1);\n        gimage->cmap = g_new (guchar, gimage->num_cols*3);\n        info->cp +=\n          xcf_read_int8 (info->fp,\n                   (guint8*) gimage->cmap, gimage->num_cols*3);\n      }\n     */\n        break;\n      }\n      case PROP_COMPRESSION:\n      {\n        doc_info.compression = ReadBlobByte(image);\n        if ((doc_info.compression != COMPRESS_NONE) &&\n            (doc_info.compression != COMPRESS_RLE) &&\n            (doc_info.compression != COMPRESS_ZLIB) &&\n            (doc_info.compression != COMPRESS_FRACTAL))\n          ThrowReaderException(CorruptImageError,\"UnrecognizedImageCompression\");\n      }\n      break;\n\n      case PROP_GUIDES:\n      {\n         /* just skip it - we don't care about guides */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n      }\n      break;\n\n    case PROP_RESOLUTION:\n      {\n        /* float xres = (float) */ (void) ReadBlobMSBLong(image);\n        /* float yres = (float) */ (void) ReadBlobMSBLong(image);\n\n        /*\n        if (xres < GIMP_MIN_RESOLUTION || xres > GIMP_MAX_RESOLUTION ||\n            yres < GIMP_MIN_RESOLUTION || yres > GIMP_MAX_RESOLUTION)\n        {\n        g_message (\"Warning, resolution out of range in XCF file\");\n        xres = gimage->gimp->config->default_xresolution;\n        yres = gimage->gimp->config->default_yresolution;\n        }\n        */\n\n\n        /* BOGUS: we don't write these yet because we aren't\n              reading them properly yet :(\n              image->x_resolution = xres;\n              image->y_resolution = yres;\n        */\n      }\n      break;\n\n    case PROP_TATTOO:\n      {\n        /* we need to read it, even if we ignore it */\n        /*size_t  tattoo_state = */ (void) ReadBlobMSBLong(image);\n      }\n      break;\n\n    case PROP_PARASITES:\n      {\n        /* BOGUS: we may need these for IPTC stuff */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n        /*\n      gssize_t         base = info->cp;\n      GimpParasite *p;\n\n      while (info->cp - base < prop_size)\n        {\n          p = xcf_load_parasite (info);\n          gimp_image_parasite_attach (gimage, p);\n          gimp_parasite_free (p);\n        }\n      if (info->cp - base != prop_size)\n        g_message (\"Error detected while loading an image's parasites\");\n      */\n          }\n      break;\n\n    case PROP_UNIT:\n      {\n        /* BOGUS: ignore for now... */\n      /*size_t unit =  */ (void) ReadBlobMSBLong(image);\n      }\n      break;\n\n    case PROP_PATHS:\n      {\n      /* BOGUS: just skip it for now */\n        if (DiscardBlobBytes(image,prop_size) == MagickFalse)\n          ThrowFileException(&image->exception,CorruptImageError,\n            \"UnexpectedEndOfFile\",image->filename);\n\n        /*\n      PathList *paths = xcf_load_bzpaths (gimage, info);\n      gimp_image_set_paths (gimage, paths);\n      */\n      }\n      break;\n\n    case PROP_USER_UNIT:\n      {\n        char  unit_string[1000];\n        /*BOGUS: ignored for now */\n        /*float  factor = (float) */ (void) ReadBlobMSBLong(image);\n        /* size_t digits =  */ (void) ReadBlobMSBLong(image);\n        for (i=0; i<5; i++)\n         (void) ReadBlobStringWithLongSize(image, unit_string,\n           sizeof(unit_string));\n      }\n     break;\n\n      default:\n      {\n        int buf[16];\n        ssize_t amount;\n\n      /* read over it... */\n      while ((prop_size > 0) && (EOFBlob(image) == MagickFalse))\n      {\n        amount=(ssize_t) MagickMin(16, prop_size);\n        amount=(ssize_t) ReadBlob(image,(size_t) amount,(unsigned char *) &buf);\n        if (!amount)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n        prop_size -= (size_t) MagickMin(16,(size_t) amount);\n      }\n    }\n    break;\n  }\n  }\n  if (foundPropEnd == MagickFalse)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n    {\n      ; /* do nothing, were just pinging! */\n    }\n  else\n    {\n      int\n        current_layer = 0,\n        foundAllLayers = MagickFalse,\n        number_layers = 0;\n\n      MagickOffsetType\n        oldPos=TellBlob(image);\n\n      XCFLayerInfo\n        *layer_info;\n\n      /*\n        The read pointer.\n      */\n      do\n      {\n        ssize_t offset = ReadBlobMSBSignedLong(image);\n        if (offset == 0)\n          foundAllLayers=MagickTrue;\n        else\n          number_layers++;\n        if (EOFBlob(image) != MagickFalse)\n          {\n            ThrowFileException(exception,CorruptImageError,\n              \"UnexpectedEndOfFile\",image->filename);\n            break;\n          }\n    } while (foundAllLayers == MagickFalse);\n    doc_info.number_layers=number_layers;\n    offset=SeekBlob(image,oldPos,SEEK_SET); /* restore the position! */\n    if (offset < 0)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    /* allocate our array of layer info blocks */\n    length=(size_t) number_layers;\n    layer_info=(XCFLayerInfo *) AcquireQuantumMemory(length,\n      sizeof(*layer_info));\n    if (layer_info == (XCFLayerInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(layer_info,0,number_layers*sizeof(XCFLayerInfo));\n    for ( ; ; )\n    {\n      MagickBooleanType\n        layer_ok;\n\n      MagickOffsetType\n        offset,\n        saved_pos;\n\n      /* read in the offset of the next layer */\n      offset=(MagickOffsetType) ReadBlobMSBLong(image);\n      /* if the offset is 0 then we are at the end\n      *  of the layer list.\n      */\n      if (offset == 0)\n        break;\n      /* save the current position as it is where the\n      *  next layer offset is stored.\n      */\n      saved_pos=TellBlob(image);\n      /* seek to the layer offset */\n      if (SeekBlob(image,offset,SEEK_SET) != offset)\n        ThrowReaderException(ResourceLimitError,\"NotEnoughPixelData\");\n      /* read in the layer */\n      layer_ok=ReadOneLayer(image_info,image,&doc_info,\n        &layer_info[current_layer],current_layer);\n      if (layer_ok == MagickFalse)\n        {\n          int j;\n\n          for (j=0; j < current_layer; j++)\n            layer_info[j].image=DestroyImage(layer_info[j].image);\n          layer_info=(XCFLayerInfo *) RelinquishMagickMemory(layer_info);\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        }\n      /* restore the saved position so we'll be ready to\n      *  read the next offset.\n      */\n      offset=SeekBlob(image, saved_pos, SEEK_SET);\n      current_layer++;\n    }\n#if 0\n        {\n        /* NOTE: XCF layers are REVERSED from composite order! */\n        signed int  j;\n        for (j=number_layers-1; j>=0; j--) {\n          /* BOGUS: need to consider layer blending modes!! */\n\n          if ( layer_info[j].visible ) { /* only visible ones, please! */\n            CompositeImage(image, OverCompositeOp, layer_info[j].image,\n                     layer_info[j].offset_x, layer_info[j].offset_y );\n             layer_info[j].image =DestroyImage( layer_info[j].image );\n\n            /* If we do this, we'll get REAL gray images! */\n            if ( image_type == GIMP_GRAY ) {\n              QuantizeInfo  qi;\n              GetQuantizeInfo(&qi);\n              qi.colorspace = GRAYColorspace;\n              QuantizeImage( &qi, layer_info[j].image );\n            }\n          }\n        }\n      }\n#else\n      {\n        /* NOTE: XCF layers are REVERSED from composite order! */\n        ssize_t  j;\n\n        /* now reverse the order of the layers as they are put\n           into subimages\n        */\n        for (j=(long) number_layers-1; j >= 0; j--)\n          AppendImageToList(&image,layer_info[j].image);\n      }\n#endif\n\n    layer_info=(XCFLayerInfo *) RelinquishMagickMemory(layer_info);\n\n#if 0  /* BOGUS: do we need the channels?? */\n    while (MagickTrue)\n    {\n      /* read in the offset of the next channel */\n      info->cp += xcf_read_int32 (info->fp, &offset, 1);\n\n      /* if the offset is 0 then we are at the end\n      *  of the channel list.\n      */\n      if (offset == 0)\n        break;\n\n      /* save the current position as it is where the\n      *  next channel offset is stored.\n      */\n      saved_pos = info->cp;\n\n      /* seek to the channel offset */\n      xcf_seek_pos (info, offset);\n\n      /* read in the layer */\n      channel = xcf_load_channel (info, gimage);\n      if (channel == 0)\n        goto error;\n\n      num_successful_elements++;\n\n      /* add the channel to the image if its not the selection */\n      if (channel != gimage->selection_mask)\n        gimp_image_add_channel (gimage, channel, -1);\n\n      /* restore the saved position so we'll be ready to\n      *  read the next offset.\n      */\n      xcf_seek_pos (info, saved_pos);\n    }\n#endif\n  }\n\n  (void) CloseBlob(image);\n  if (GetNextImageInList(image) != (Image *) NULL)\n    DestroyImage(RemoveFirstImageFromList(&image));\n  if (image_type == GIMP_GRAY)\n    image->type=GrayscaleType;\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/d31fec57e9dfb0516deead2053a856e3c71e9751", "file_name": "coders/xcf.c", "vul_type": "cwe-476", "description": "Write a function in C to read and process XCF image files."}
