{"func_name": "mode_close", "func_src_before": "    def mode_close(self, request):\n        \"\"\"\n        This is called by render_POST when the client is signalling\n        that it is about to be closed.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        try:\n            sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n            sess.sessionhandler.disconnect(sess)\n        except IndexError:\n            self.client_disconnect(csessid)\n        return '\"\"'", "func_src_after": "    def mode_close(self, request):\n        \"\"\"\n        This is called by render_POST when the client is signalling\n        that it is about to be closed.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        try:\n            sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n            sess.sessionhandler.disconnect(sess)\n        except IndexError:\n            self.client_disconnect(csessid)\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_close` that handles a POST request to disconnect a client session using a session ID."}
{"func_name": "cleanup_pathname", "func_src_before": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/')\n\t\tseparator = *src++;\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "func_src_after": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/') {\n\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NOABSOLUTEPATHS) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t                  \"Path is absolute\");\n\t\t\treturn (ARCHIVE_FAILED);\n\t\t}\n\n\t\tseparator = *src++;\n\t}\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "commit_link": "github.com/libarchive/libarchive/commit/59357157706d47c365b2227739e17daba3607526", "file_name": "libarchive/archive_write_disk_posix.c", "vul_type": "cwe-022", "description": "Write a C function named `cleanup_pathname` that sanitizes and validates a pathname stored in a `struct archive_write_disk` object."}
{"func_name": "parse", "func_src_before": "    @staticmethod\n    def parse(path, require_exists=True, require_parses=True):\n        if not os.path.isfile(path):\n            if require_exists:\n                raise ConfigError('not found: ' + path)\n            else:\n                return None\n        try:\n            with open(path) as f:\n                return yaml.load(f)\n        except Exception, error:\n            if require_parses:\n                raise ConfigError('parse error: ' + path)", "func_src_after": "    @staticmethod\n    def parse(path, require_exists=True, require_parses=True):\n        if not os.path.isfile(path):\n            if require_exists:\n                raise ConfigError('not found: ' + path)\n            else:\n                return None\n        try:\n            with open(path) as f:\n                return yaml.safe_load(f)\n        except Exception, error:\n            if require_parses:\n                raise ConfigError('parse error: ' + path)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 298, "char_end": 334, "line": "                return yaml.load(f)\n"}], "added": [{"line_no": 10, "char_start": 298, "char_end": 339, "line": "                return yaml.safe_load(f)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 326, "char_end": 331, "chars": "safe_"}]}, "commit_link": "github.com/silas/rock/commit/0852b4f55891e5dfe7cc6af3881942484daf9132", "file_name": "config.py", "vul_type": "cwe-502", "commit_msg": "Use yaml.safe_load instead of yaml.load", "parent_commit": "93a26daa34d92236cfcfe4e7ccf0d4814687c009", "description": "Create a Python function that loads a YAML file, with options to enforce file existence and successful parsing."}
{"func_name": "main", "func_src_before": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n\tssh_path[sizeof(ssh_path)] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 385, "char_end": 436, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n"}, {"line_no": 17, "char_start": 436, "char_end": 472, "line": "\tssh_path[sizeof(ssh_path)] = '\\0';\n"}, {"line_no": 78, "char_start": 1620, "char_end": 1672, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n"}, {"line_no": 79, "char_start": 1672, "char_end": 1711, "line": "\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n"}], "added": [{"line_no": 16, "char_start": 385, "char_end": 437, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n"}, {"line_no": 17, "char_start": 437, "char_end": 477, "line": "\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}, {"line_no": 78, "char_start": 1625, "char_end": 1678, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n"}, {"line_no": 79, "char_start": 1678, "char_end": 1721, "line": "\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 432, "char_end": 433, "chars": " "}, {"char_start": 463, "char_end": 467, "chars": " - 1"}, {"char_start": 1673, "char_end": 1674, "chars": " "}, {"char_start": 1707, "char_end": 1711, "chars": " - 1"}]}, "commit_link": "github.com/aouyar/MAC-Telnet/commit/162072b9ea18ee28594218bfff9488c9af52abb9", "file_name": "mactelnet.c", "vul_type": "cwe-119", "commit_msg": "Fix trivial buffer overflow bug. Thanks to haakonnessjoen.", "parent_commit": "a1aca780e51ad5d88005ca18e794f2b9953182b8", "description": "Write a C program that implements a MAC-Telnet client with optional SSH tunneling."}
{"func_name": "(anonymous)", "func_src_before": "\t\t\t\t\tinput.keypress(function(event) {\n\t\t\t\t\t\tif(event.keyCode == 13) {\n\t\t\t\t\t\t\tevent.preventDefault();\n\t\t\t\t\t\t\tevent.stopPropagation();\n\t\t\t\t\t\t\tvar li=$(this).parent();\n\t\t\t\t\t\t\t$(this).remove();\n\t\t\t\t\t\t\tli.text('+ '+settings.createText);\n\t\t\t\t\t\t\tli.before(createItem(this));\n\t\t\t\t\t\t\tvar select=button.parent().next();\n\t\t\t\t\t\t\tselect.append($('<option selected=\"selected\" value=\"'+$(this).val()+'\">'+$(this).val()+'</option>'));\n\t\t\t\t\t\t\tli.prev().children('input').trigger('click');\n\t\t\t\t\t\t\tbutton.parent().data('preventHide',false);\n\t\t\t\t\t\t\tif(settings.createCallback){\n\t\t\t\t\t\t\t\tsettings.createCallback();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});", "func_src_after": "\t\t\t\t\tinput.keypress(function(event) {\n\t\t\t\t\t\tif(event.keyCode == 13) {\n\t\t\t\t\t\t\tevent.preventDefault();\n\t\t\t\t\t\t\tevent.stopPropagation();\n\t\t\t\t\t\t\tvar li=$(this).parent();\n\t\t\t\t\t\t\t$(this).remove();\n\t\t\t\t\t\t\tli.text('+ '+settings.createText);\n\t\t\t\t\t\t\tli.before(createItem(this));\n\t\t\t\t\t\t\tvar select=button.parent().next();\n\t\t\t\t\t\t\tvar option=$('<option selected=\"selected\"/>');\n\t\t\t\t\t\t\toption.attr('value',$(this).val());\n\t\t\t\t\t\t\toption.text($(this).val());\n\t\t\t\t\t\t\tselect.append(optione);\n\t\t\t\t\t\t\tli.prev().children('input').trigger('click');\n\t\t\t\t\t\t\tbutton.parent().data('preventHide',false);\n\t\t\t\t\t\t\tif(settings.createCallback){\n\t\t\t\t\t\t\t\tsettings.createCallback();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});", "line_changes": {"deleted": [{"line_no": 10, "char_start": 310, "char_end": 419, "line": "\t\t\t\t\t\t\tselect.append($('<option selected=\"selected\" value=\"'+$(this).val()+'\">'+$(this).val()+'</option>'));\n"}], "added": [{"line_no": 10, "char_start": 310, "char_end": 364, "line": "\t\t\t\t\t\t\tvar option=$('<option selected=\"selected\"/>');\n"}, {"line_no": 11, "char_start": 364, "char_end": 407, "line": "\t\t\t\t\t\t\toption.attr('value',$(this).val());\n"}, {"line_no": 12, "char_start": 407, "char_end": 442, "line": "\t\t\t\t\t\t\toption.text($(this).val());\n"}, {"line_no": 13, "char_start": 442, "char_end": 473, "line": "\t\t\t\t\t\t\tselect.append(optione);\n"}]}, "char_changes": {"deleted": [{"char_start": 317, "char_end": 331, "chars": "select.append("}, {"char_start": 361, "char_end": 362, "chars": " "}, {"char_start": 367, "char_end": 371, "chars": "=\"'+"}, {"char_start": 384, "char_end": 407, "chars": "+'\">'+$(this).val()+'</"}, {"char_start": 413, "char_end": 416, "chars": ">')"}], "added": [{"char_start": 317, "char_end": 328, "chars": "var option="}, {"char_start": 358, "char_end": 384, "chars": "/>');\n\t\t\t\t\t\t\toption.attr('"}, {"char_start": 389, "char_end": 391, "chars": "',"}, {"char_start": 404, "char_end": 463, "chars": ");\n\t\t\t\t\t\t\toption.text($(this).val());\n\t\t\t\t\t\t\tselect.append("}, {"char_start": 469, "char_end": 470, "chars": "e"}]}, "commit_link": "github.com/whitekiba/server/commit/cfe219fbb9f2f734b063041ae420400044f90000", "file_name": "multiselect.js", "vul_type": "cwe-079", "commit_msg": "fix potential xss in multiselect", "description": "Write a jQuery snippet that handles the enter key press on an input field to replace it with a list item and update a select element with a new option."}
{"func_name": "(anonymous)", "func_src_before": "  }, function (statusCode, body) {\n    if (statusCode !== 200) {\n      // request a new login key first\n      this._steamUser.requestWebAPIAuthenticateUserNonce(function (nonce) {\n        this._webLoginKey = nonce.webapi_authenticate_user_nonce;\n        this.webLogOn(callback);\n      }.bind(this));\n      return;\n    }\n\n    this.sessionID = Math.floor(Math.random() * 1000000000).toString();\n    this.cookies = [\n      'sessionid=' + this.sessionID,\n      'steamLogin=' + body.authenticateuser.token,\n      'steamLoginSecure=' + body.authenticateuser.tokensecure\n    ];\n\n    callback(this.sessionID, this.cookies);\n  }.bind(this));", "func_src_after": "  }, function (statusCode, body) {\n    if (statusCode !== 200) {\n      // request a new login key first\n      this._steamUser.requestWebAPIAuthenticateUserNonce(function (nonce) {\n        this._webLoginKey = nonce.webapi_authenticate_user_nonce;\n        this.webLogOn(callback);\n      }.bind(this));\n      return;\n    }\n\n    this.sessionID = crypto.randomBytes(12).toString('hex');\n    this.cookies = [\n      'sessionid=' + this.sessionID,\n      'steamLogin=' + body.authenticateuser.token,\n      'steamLoginSecure=' + body.authenticateuser.tokensecure\n    ];\n\n    callback(this.sessionID, this.cookies);\n  }.bind(this));", "line_changes": {"deleted": [{"line_no": 11, "char_start": 321, "char_end": 393, "line": "    this.sessionID = Math.floor(Math.random() * 1000000000).toString();\n"}], "added": [{"line_no": 11, "char_start": 321, "char_end": 382, "line": "    this.sessionID = crypto.randomBytes(12).toString('hex');\n"}]}, "char_changes": {"deleted": [{"char_start": 342, "char_end": 379, "chars": "Math.floor(Math.random() * 1000000000"}], "added": [{"char_start": 342, "char_end": 363, "chars": "crypto.randomBytes(12"}, {"char_start": 374, "char_end": 379, "chars": "'hex'"}]}, "commit_link": "github.com/Alex7Kom/node-steam-weblogon/commit/75224e83b75341366d1e75a07e8745025492a5e3", "file_name": "index.js", "vul_type": "cwe-338", "commit_msg": "Replaced Math.random() with crypto.randomBytes() for sessionid. Closes #4", "parent_commit": "a8eb1309ef9b64faa7cbc1dfa3f9e44b1430a437", "description": "Write a JavaScript function that handles Steam user authentication, generating a session ID and cookies upon successful login, and requesting a new login key if the status code is not 200."}
{"func_name": "get_login2", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a function that handles a login message for a bot, checks the username, interacts with a SQLite database, and updates the user's state."}
{"func_name": "test_process_as_form", "func_src_before": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert.format(job_number, was_prev_closed))\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 1))\n                else:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 0))\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_pre = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_post = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "func_src_after": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert, [job_number, was_prev_closed])\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert, [job_number, 1])\n                else:\n                    conn.cursor().execute(fake_match_insert, [job_number, 0])\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_pre = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_post = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "tests.py", "vul_type": "cwe-089", "description": "Write a Python function to process an email and update database entries based on the job number and certain conditions."}
{"func_name": "update_read_icon_info", "func_src_before": "static BOOL update_read_icon_info(wStream* s, ICON_INFO* iconInfo)\n{\n\tBYTE* newBitMask;\n\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cacheEntry); /* cacheEntry (2 bytes) */\n\tStream_Read_UINT8(s, iconInfo->cacheId);     /* cacheId (1 byte) */\n\tStream_Read_UINT8(s, iconInfo->bpp);         /* bpp (1 byte) */\n\n\tif ((iconInfo->bpp < 1) || (iconInfo->bpp > 32))\n\t{\n\t\tWLog_ERR(TAG, \"invalid bpp value %\" PRIu32 \"\", iconInfo->bpp);\n\t\treturn FALSE;\n\t}\n\n\tStream_Read_UINT16(s, iconInfo->width);  /* width (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->height); /* height (2 bytes) */\n\n\t/* cbColorTable is only present when bpp is 1, 4 or 8 */\n\tswitch (iconInfo->bpp)\n\t{\n\t\tcase 1:\n\t\tcase 4:\n\t\tcase 8:\n\t\t\tif (Stream_GetRemainingLength(s) < 2)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s, iconInfo->cbColorTable); /* cbColorTable (2 bytes) */\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\ticonInfo->cbColorTable = 0;\n\t\t\tbreak;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cbBitsMask);  /* cbBitsMask (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->cbBitsColor); /* cbBitsColor (2 bytes) */\n\n\tif (Stream_GetRemainingLength(s) < iconInfo->cbBitsMask + iconInfo->cbBitsColor)\n\t\treturn FALSE;\n\n\t/* bitsMask */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsMask);\n\t\ticonInfo->bitsMask = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsMask = newBitMask;\n\tStream_Read(s, iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\t/* colorTable */\n\tif (iconInfo->colorTable == NULL)\n\t{\n\t\tif (iconInfo->cbColorTable)\n\t\t{\n\t\t\ticonInfo->colorTable = (BYTE*)malloc(iconInfo->cbColorTable);\n\n\t\t\tif (!iconInfo->colorTable)\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse if (iconInfo->cbColorTable)\n\t{\n\t\tBYTE* new_tab;\n\t\tnew_tab = (BYTE*)realloc(iconInfo->colorTable, iconInfo->cbColorTable);\n\n\t\tif (!new_tab)\n\t\t{\n\t\t\tfree(iconInfo->colorTable);\n\t\t\ticonInfo->colorTable = NULL;\n\t\t\treturn FALSE;\n\t\t}\n\n\t\ticonInfo->colorTable = new_tab;\n\t}\n\telse\n\t{\n\t\tfree(iconInfo->colorTable);\n\t\ticonInfo->colorTable = NULL;\n\t}\n\n\tif (iconInfo->colorTable)\n\t\tStream_Read(s, iconInfo->colorTable, iconInfo->cbColorTable);\n\n\t/* bitsColor */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsColor, iconInfo->cbBitsColor);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsColor);\n\t\ticonInfo->bitsColor = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsColor = newBitMask;\n\tStream_Read(s, iconInfo->bitsColor, iconInfo->cbBitsColor);\n\treturn TRUE;\n}", "func_src_after": "static BOOL update_read_icon_info(wStream* s, ICON_INFO* iconInfo)\n{\n\tBYTE* newBitMask;\n\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cacheEntry); /* cacheEntry (2 bytes) */\n\tStream_Read_UINT8(s, iconInfo->cacheId);     /* cacheId (1 byte) */\n\tStream_Read_UINT8(s, iconInfo->bpp);         /* bpp (1 byte) */\n\n\tif ((iconInfo->bpp < 1) || (iconInfo->bpp > 32))\n\t{\n\t\tWLog_ERR(TAG, \"invalid bpp value %\" PRIu32 \"\", iconInfo->bpp);\n\t\treturn FALSE;\n\t}\n\n\tStream_Read_UINT16(s, iconInfo->width);  /* width (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->height); /* height (2 bytes) */\n\n\t/* cbColorTable is only present when bpp is 1, 4 or 8 */\n\tswitch (iconInfo->bpp)\n\t{\n\t\tcase 1:\n\t\tcase 4:\n\t\tcase 8:\n\t\t\tif (Stream_GetRemainingLength(s) < 2)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s, iconInfo->cbColorTable); /* cbColorTable (2 bytes) */\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\ticonInfo->cbColorTable = 0;\n\t\t\tbreak;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cbBitsMask);  /* cbBitsMask (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->cbBitsColor); /* cbBitsColor (2 bytes) */\n\n\t/* bitsMask */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsMask);\n\t\ticonInfo->bitsMask = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsMask = newBitMask;\n\tif (Stream_GetRemainingLength(s) < iconInfo->cbBitsMask)\n\t\treturn FALSE;\n\tStream_Read(s, iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\t/* colorTable */\n\tif (iconInfo->colorTable == NULL)\n\t{\n\t\tif (iconInfo->cbColorTable)\n\t\t{\n\t\t\ticonInfo->colorTable = (BYTE*)malloc(iconInfo->cbColorTable);\n\n\t\t\tif (!iconInfo->colorTable)\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse if (iconInfo->cbColorTable)\n\t{\n\t\tBYTE* new_tab;\n\t\tnew_tab = (BYTE*)realloc(iconInfo->colorTable, iconInfo->cbColorTable);\n\n\t\tif (!new_tab)\n\t\t{\n\t\t\tfree(iconInfo->colorTable);\n\t\t\ticonInfo->colorTable = NULL;\n\t\t\treturn FALSE;\n\t\t}\n\n\t\ticonInfo->colorTable = new_tab;\n\t}\n\telse\n\t{\n\t\tfree(iconInfo->colorTable);\n\t\ticonInfo->colorTable = NULL;\n\t}\n\n\tif (iconInfo->colorTable)\n\t{\n\t\tif (Stream_GetRemainingLength(s) < iconInfo->cbColorTable)\n\t\t\treturn FALSE;\n\t\tStream_Read(s, iconInfo->colorTable, iconInfo->cbColorTable);\n\t}\n\n\t/* bitsColor */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsColor, iconInfo->cbBitsColor);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsColor);\n\t\ticonInfo->bitsColor = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsColor = newBitMask;\n\tif (Stream_GetRemainingLength(s) < iconInfo->cbBitsColor)\n\t\treturn FALSE;\n\tStream_Read(s, iconInfo->bitsColor, iconInfo->cbBitsColor);\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/6b2bc41935e53b0034fe5948aeeab4f32e80f30f", "file_name": "libfreerdp/core/window.c", "vul_type": "cwe-125", "description": "Write a C function named `update_read_icon_info` that reads icon information from a stream and updates an `ICON_INFO` structure, returning a boolean status."}
{"func_name": "get_net_ns_by_id", "func_src_before": "struct net *get_net_ns_by_id(struct net *net, int id)\n{\n\tstruct net *peer;\n\n\tif (id < 0)\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tspin_lock_bh(&net->nsid_lock);\n\tpeer = idr_find(&net->netns_ids, id);\n\tif (peer)\n\t\tget_net(peer);\n\tspin_unlock_bh(&net->nsid_lock);\n\trcu_read_unlock();\n\n\treturn peer;\n}", "func_src_after": "struct net *get_net_ns_by_id(struct net *net, int id)\n{\n\tstruct net *peer;\n\n\tif (id < 0)\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tspin_lock_bh(&net->nsid_lock);\n\tpeer = idr_find(&net->netns_ids, id);\n\tif (peer)\n\t\tpeer = maybe_get_net(peer);\n\tspin_unlock_bh(&net->nsid_lock);\n\trcu_read_unlock();\n\n\treturn peer;\n}", "commit_link": "github.com/torvalds/linux/commit/21b5944350052d2583e82dd59b19a9ba94a007f0", "file_name": "net/core/net_namespace.c", "vul_type": "cwe-416", "description": "Write a C function named `get_net_ns_by_id` that retrieves a network namespace by its ID from a given network structure, handling synchronization and reference acquisition."}
{"func_name": "(anonymous)", "func_src_before": "  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>", "func_src_after": "  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\"\n                  rel=\"noopener noreferrer\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>\n        );\n      });", "line_changes": {"deleted": [{"line_no": 25, "char_start": 798, "char_end": 850, "line": "                  target=\"_blank\">{line.Number}</a>\n"}], "added": [{"line_no": 25, "char_start": 798, "char_end": 832, "line": "                  target=\"_blank\"\n"}, {"line_no": 26, "char_start": 832, "char_end": 894, "line": "                  rel=\"noopener noreferrer\">{line.Number}</a>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 831, "char_end": 875, "chars": "\n                  rel=\"noopener noreferrer\""}, {"char_start": 1085, "char_end": 1106, "chars": "\n        );\n      });"}]}, "commit_link": "github.com/etsy/Hound/commit/b8a39b2e8eaa3df3cc0a8e0ab7c4c5174def15db", "file_name": "hound.js", "vul_type": "cwe-200", "commit_msg": "Give repo links a target of blank (#404)\n\nAdd rel=\"noopener noreferrer\" to _blank links", "parent_commit": "ca5c7c8c1dc6753b0bbe2bdd0ad3c934969f7cf6", "description": "Create a React component in JavaScript that displays matched lines from a repository with links to the source."}
{"func_name": "jpc_pi_nextcprl", "func_src_before": "static int jpc_pi_nextcprl(register jpc_pi_t *pi)\n{\n\tint rlvlno;\n\tjpc_pirlvl_t *pirlvl;\n\tjpc_pchg_t *pchg;\n\tint prchind;\n\tint prcvind;\n\tint *prclyrno;\n\tuint_fast32_t trx0;\n\tuint_fast32_t try0;\n\tuint_fast32_t r;\n\tuint_fast32_t rpx;\n\tuint_fast32_t rpy;\n\n\tpchg = pi->pchg;\n\tif (!pi->prgvolfirst) {\n\t\tgoto skip;\n\t} else {\n\t\tpi->prgvolfirst = 0;\n\t}\n\n\tfor (pi->compno = pchg->compnostart, pi->picomp =\n\t  &pi->picomps[pi->compno]; pi->compno < JAS_CAST(int, pchg->compnoend) && pi->compno < pi->numcomps; ++pi->compno,\n\t  ++pi->picomp) {\n\t\tpirlvl = pi->picomp->pirlvls;\n\t\tpi->xstep = pi->picomp->hsamp * (1 << (pirlvl->prcwidthexpn +\n\t\t  pi->picomp->numrlvls - 1));\n\t\tpi->ystep = pi->picomp->vsamp * (1 << (pirlvl->prcheightexpn +\n\t\t  pi->picomp->numrlvls - 1));\n\t\tfor (rlvlno = 1, pirlvl = &pi->picomp->pirlvls[1];\n\t\t  rlvlno < pi->picomp->numrlvls; ++rlvlno, ++pirlvl) {\n\t\t\tpi->xstep = JAS_MIN(pi->xstep, pi->picomp->hsamp * (1 <<\n\t\t\t  (pirlvl->prcwidthexpn + pi->picomp->numrlvls -\n\t\t\t  rlvlno - 1)));\n\t\t\tpi->ystep = JAS_MIN(pi->ystep, pi->picomp->vsamp * (1 <<\n\t\t\t  (pirlvl->prcheightexpn + pi->picomp->numrlvls -\n\t\t\t  rlvlno - 1)));\n\t\t}\n\t\tfor (pi->y = pi->ystart; pi->y < pi->yend;\n\t\t  pi->y += pi->ystep - (pi->y % pi->ystep)) {\n\t\t\tfor (pi->x = pi->xstart; pi->x < pi->xend;\n\t\t\t  pi->x += pi->xstep - (pi->x % pi->xstep)) {\n\t\t\t\tfor (pi->rlvlno = pchg->rlvlnostart,\n\t\t\t\t  pi->pirlvl = &pi->picomp->pirlvls[pi->rlvlno];\n\t\t\t\t  pi->rlvlno < pi->picomp->numrlvls && pi->rlvlno <\n\t\t\t\t  pchg->rlvlnoend; ++pi->rlvlno, ++pi->pirlvl) {\n\t\t\t\t\tif (pi->pirlvl->numprcs == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tr = pi->picomp->numrlvls - 1 - pi->rlvlno;\n\t\t\t\t\ttrx0 = JPC_CEILDIV(pi->xstart, pi->picomp->hsamp << r);\n\t\t\t\t\ttry0 = JPC_CEILDIV(pi->ystart, pi->picomp->vsamp << r);\n\t\t\t\t\trpx = r + pi->pirlvl->prcwidthexpn;\n\t\t\t\t\trpy = r + pi->pirlvl->prcheightexpn;\n\t\t\t\t\tif (((pi->x == pi->xstart && ((trx0 << r) % (1 << rpx))) ||\n\t\t\t\t\t  !(pi->x % (pi->picomp->hsamp << rpx))) &&\n\t\t\t\t\t  ((pi->y == pi->ystart && ((try0 << r) % (1 << rpy))) ||\n\t\t\t\t\t  !(pi->y % (pi->picomp->vsamp << rpy)))) {\n\t\t\t\t\t\tprchind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->x, pi->picomp->hsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcwidthexpn) - JPC_FLOORDIVPOW2(trx0,\n\t\t\t\t\t\t  pi->pirlvl->prcwidthexpn);\n\t\t\t\t\t\tprcvind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->y, pi->picomp->vsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcheightexpn) - JPC_FLOORDIVPOW2(try0,\n\t\t\t\t\t\t  pi->pirlvl->prcheightexpn);\n\t\t\t\t\t\tpi->prcno = prcvind *\n\t\t\t\t\t\t  pi->pirlvl->numhprcs +\n\t\t\t\t\t\t  prchind;\n\t\t\t\t\t\tassert(pi->prcno <\n\t\t\t\t\t\t  pi->pirlvl->numprcs);\n\t\t\t\t\t\tfor (pi->lyrno = 0; pi->lyrno <\n\t\t\t\t\t\t  pi->numlyrs && pi->lyrno < JAS_CAST(int, pchg->lyrnoend); ++pi->lyrno) {\n\t\t\t\t\t\t\tprclyrno = &pi->pirlvl->prclyrnos[pi->prcno];\n\t\t\t\t\t\t\tif (pi->lyrno >= *prclyrno) {\n\t\t\t\t\t\t\t\t++(*prclyrno);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\nskip:\n\t\t\t\t\t\t\t;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "func_src_after": "static int jpc_pi_nextcprl(register jpc_pi_t *pi)\n{\n\tint rlvlno;\n\tjpc_pirlvl_t *pirlvl;\n\tjpc_pchg_t *pchg;\n\tint prchind;\n\tint prcvind;\n\tint *prclyrno;\n\tuint_fast32_t trx0;\n\tuint_fast32_t try0;\n\tuint_fast32_t r;\n\tuint_fast32_t rpx;\n\tuint_fast32_t rpy;\n\n\tpchg = pi->pchg;\n\tif (!pi->prgvolfirst) {\n\t\tgoto skip;\n\t} else {\n\t\tpi->prgvolfirst = 0;\n\t}\n\n\tfor (pi->compno = pchg->compnostart, pi->picomp =\n\t  &pi->picomps[pi->compno]; pi->compno < JAS_CAST(int, pchg->compnoend) && pi->compno < pi->numcomps; ++pi->compno,\n\t  ++pi->picomp) {\n\t\tpirlvl = pi->picomp->pirlvls;\n\t\tpi->xstep = pi->picomp->hsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t  (pirlvl->prcwidthexpn + pi->picomp->numrlvls - 1));\n\t\tpi->ystep = pi->picomp->vsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t  (pirlvl->prcheightexpn + pi->picomp->numrlvls - 1));\n\t\tfor (rlvlno = 1, pirlvl = &pi->picomp->pirlvls[1];\n\t\t  rlvlno < pi->picomp->numrlvls; ++rlvlno, ++pirlvl) {\n\t\t\tpi->xstep = JAS_MIN(pi->xstep, pi->picomp->hsamp *\n\t\t\t  (JAS_CAST(uint_fast32_t, 1) << (pirlvl->prcwidthexpn +\n\t\t\t  pi->picomp->numrlvls - rlvlno - 1)));\n\t\t\tpi->ystep = JAS_MIN(pi->ystep, pi->picomp->vsamp *\n\t\t\t  (JAS_CAST(uint_fast32_t, 1) << (pirlvl->prcheightexpn +\n\t\t\t  pi->picomp->numrlvls - rlvlno - 1)));\n\t\t}\n\t\tfor (pi->y = pi->ystart; pi->y < pi->yend;\n\t\t  pi->y += pi->ystep - (pi->y % pi->ystep)) {\n\t\t\tfor (pi->x = pi->xstart; pi->x < pi->xend;\n\t\t\t  pi->x += pi->xstep - (pi->x % pi->xstep)) {\n\t\t\t\tfor (pi->rlvlno = pchg->rlvlnostart,\n\t\t\t\t  pi->pirlvl = &pi->picomp->pirlvls[pi->rlvlno];\n\t\t\t\t  pi->rlvlno < pi->picomp->numrlvls && pi->rlvlno <\n\t\t\t\t  pchg->rlvlnoend; ++pi->rlvlno, ++pi->pirlvl) {\n\t\t\t\t\tif (pi->pirlvl->numprcs == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tr = pi->picomp->numrlvls - 1 - pi->rlvlno;\n\t\t\t\t\ttrx0 = JPC_CEILDIV(pi->xstart, pi->picomp->hsamp << r);\n\t\t\t\t\ttry0 = JPC_CEILDIV(pi->ystart, pi->picomp->vsamp << r);\n\t\t\t\t\trpx = r + pi->pirlvl->prcwidthexpn;\n\t\t\t\t\trpy = r + pi->pirlvl->prcheightexpn;\n\t\t\t\t\tif (((pi->x == pi->xstart && ((trx0 << r) % (1 << rpx))) ||\n\t\t\t\t\t  !(pi->x % (pi->picomp->hsamp << rpx))) &&\n\t\t\t\t\t  ((pi->y == pi->ystart && ((try0 << r) % (1 << rpy))) ||\n\t\t\t\t\t  !(pi->y % (pi->picomp->vsamp << rpy)))) {\n\t\t\t\t\t\tprchind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->x, pi->picomp->hsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcwidthexpn) - JPC_FLOORDIVPOW2(trx0,\n\t\t\t\t\t\t  pi->pirlvl->prcwidthexpn);\n\t\t\t\t\t\tprcvind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->y, pi->picomp->vsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcheightexpn) - JPC_FLOORDIVPOW2(try0,\n\t\t\t\t\t\t  pi->pirlvl->prcheightexpn);\n\t\t\t\t\t\tpi->prcno = prcvind *\n\t\t\t\t\t\t  pi->pirlvl->numhprcs +\n\t\t\t\t\t\t  prchind;\n\t\t\t\t\t\tassert(pi->prcno <\n\t\t\t\t\t\t  pi->pirlvl->numprcs);\n\t\t\t\t\t\tfor (pi->lyrno = 0; pi->lyrno <\n\t\t\t\t\t\t  pi->numlyrs && pi->lyrno < JAS_CAST(int, pchg->lyrnoend); ++pi->lyrno) {\n\t\t\t\t\t\t\tprclyrno = &pi->pirlvl->prclyrnos[pi->prcno];\n\t\t\t\t\t\t\tif (pi->lyrno >= *prclyrno) {\n\t\t\t\t\t\t\t\t++(*prclyrno);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\nskip:\n\t\t\t\t\t\t\t;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "commit_link": "github.com/mdadams/jasper/commit/1f0dfe5a42911b6880a1445f13f6d615ddb55387", "file_name": "src/libjasper/jpc/jpc_t2cod.c", "vul_type": "cwe-190", "description": "Write a C function named `jpc_pi_nextcprl` that iterates over components, resolutions, positions, and layers for JPEG 2000 progression order changes."}
{"func_name": "updateDevice", "func_src_before": "updateDevice(const struct header * headers, time_t t)\n{\n\tstruct device ** pp = &devlist;\n\tstruct device * p = *pp;\t/* = devlist; */\n\twhile(p)\n\t{\n\t\tif(  p->headers[HEADER_NT].l == headers[HEADER_NT].l\n\t\t  && (0==memcmp(p->headers[HEADER_NT].p, headers[HEADER_NT].p, headers[HEADER_NT].l))\n\t\t  && p->headers[HEADER_USN].l == headers[HEADER_USN].l\n\t\t  && (0==memcmp(p->headers[HEADER_USN].p, headers[HEADER_USN].p, headers[HEADER_USN].l)) )\n\t\t{\n\t\t\t/*printf(\"found! %d\\n\", (int)(t - p->t));*/\n\t\t\tsyslog(LOG_DEBUG, \"device updated : %.*s\", headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t\t\tp->t = t;\n\t\t\t/* update Location ! */\n\t\t\tif(headers[HEADER_LOCATION].l > p->headers[HEADER_LOCATION].l)\n\t\t\t{\n\t\t\t\tstruct device * tmp;\n\t\t\t\ttmp = realloc(p, sizeof(struct device)\n\t\t\t\t    + headers[0].l+headers[1].l+headers[2].l);\n\t\t\t\tif(!tmp)\t/* allocation error */\n\t\t\t\t{\n\t\t\t\t\tsyslog(LOG_ERR, \"updateDevice() : memory allocation error\");\n\t\t\t\t\tfree(p);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tp = tmp;\n\t\t\t\t*pp = p;\n\t\t\t}\n\t\t\tmemcpy(p->data + p->headers[0].l + p->headers[1].l,\n\t\t\t       headers[2].p, headers[2].l);\n\t\t\t/* TODO : check p->headers[HEADER_LOCATION].l */\n\t\t\treturn 0;\n\t\t}\n\t\tpp = &p->next;\n\t\tp = *pp;\t/* p = p->next; */\n\t}\n\tsyslog(LOG_INFO, \"new device discovered : %.*s\",\n\t       headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t/* add */\n\t{\n\t\tchar * pc;\n\t\tint i;\n\t\tp = malloc(  sizeof(struct device)\n\t\t           + headers[0].l+headers[1].l+headers[2].l );\n\t\tif(!p) {\n\t\t\tsyslog(LOG_ERR, \"updateDevice(): cannot allocate memory\");\n\t\t\treturn -1;\n\t\t}\n\t\tp->next = devlist;\n\t\tp->t = t;\n\t\tpc = p->data;\n\t\tfor(i = 0; i < 3; i++)\n\t\t{\n\t\t\tp->headers[i].p = pc;\n\t\t\tp->headers[i].l = headers[i].l;\n\t\t\tmemcpy(pc, headers[i].p, headers[i].l);\n\t\t\tpc += headers[i].l;\n\t\t}\n\t\tdevlist = p;\n\t\tsendNotifications(NOTIF_NEW, p, NULL);\n\t}\n\treturn 1;\n}", "func_src_after": "updateDevice(const struct header * headers, time_t t)\n{\n\tstruct device ** pp = &devlist;\n\tstruct device * p = *pp;\t/* = devlist; */\n\twhile(p)\n\t{\n\t\tif(  p->headers[HEADER_NT].l == headers[HEADER_NT].l\n\t\t  && (0==memcmp(p->headers[HEADER_NT].p, headers[HEADER_NT].p, headers[HEADER_NT].l))\n\t\t  && p->headers[HEADER_USN].l == headers[HEADER_USN].l\n\t\t  && (0==memcmp(p->headers[HEADER_USN].p, headers[HEADER_USN].p, headers[HEADER_USN].l)) )\n\t\t{\n\t\t\t/*printf(\"found! %d\\n\", (int)(t - p->t));*/\n\t\t\tsyslog(LOG_DEBUG, \"device updated : %.*s\", headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t\t\tp->t = t;\n\t\t\t/* update Location ! */\n\t\t\tif(headers[HEADER_LOCATION].l > p->headers[HEADER_LOCATION].l)\n\t\t\t{\n\t\t\t\tstruct device * tmp;\n\t\t\t\ttmp = realloc(p, sizeof(struct device)\n\t\t\t\t    + headers[0].l+headers[1].l+headers[2].l);\n\t\t\t\tif(!tmp)\t/* allocation error */\n\t\t\t\t{\n\t\t\t\t\tsyslog(LOG_ERR, \"updateDevice() : memory allocation error\");\n\t\t\t\t\t*pp = p->next;\t/* remove \"p\" from the list */\n\t\t\t\t\tfree(p);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tp = tmp;\n\t\t\t\t*pp = p;\n\t\t\t}\n\t\t\tmemcpy(p->data + p->headers[0].l + p->headers[1].l,\n\t\t\t       headers[2].p, headers[2].l);\n\t\t\t/* TODO : check p->headers[HEADER_LOCATION].l */\n\t\t\treturn 0;\n\t\t}\n\t\tpp = &p->next;\n\t\tp = *pp;\t/* p = p->next; */\n\t}\n\tsyslog(LOG_INFO, \"new device discovered : %.*s\",\n\t       headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t/* add */\n\t{\n\t\tchar * pc;\n\t\tint i;\n\t\tp = malloc(  sizeof(struct device)\n\t\t           + headers[0].l+headers[1].l+headers[2].l );\n\t\tif(!p) {\n\t\t\tsyslog(LOG_ERR, \"updateDevice(): cannot allocate memory\");\n\t\t\treturn -1;\n\t\t}\n\t\tp->next = devlist;\n\t\tp->t = t;\n\t\tpc = p->data;\n\t\tfor(i = 0; i < 3; i++)\n\t\t{\n\t\t\tp->headers[i].p = pc;\n\t\t\tp->headers[i].l = headers[i].l;\n\t\t\tmemcpy(pc, headers[i].p, headers[i].l);\n\t\t\tpc += headers[i].l;\n\t\t}\n\t\tdevlist = p;\n\t\tsendNotifications(NOTIF_NEW, p, NULL);\n\t}\n\treturn 1;\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/cd506a67e174a45c6a202eff182a712955ed6d6f", "file_name": "minissdpd/minissdpd.c", "vul_type": "cwe-416", "description": "In C, write a function `updateDevice` to manage a device list by updating an existing device or adding a new one based on provided headers and a timestamp."}
{"func_name": "ares_parse_a_reply", "func_src_before": "int ares_parse_a_reply(const unsigned char *abuf, int alen,\n\t\t       struct hostent **host)\n{\n  unsigned int qdcount, ancount;\n  int status, i, rr_type, rr_class, rr_len, naddrs;\n  long int len;\n  int naliases;\n  const unsigned char *aptr;\n  char *hostname, *rr_name, *rr_data, **aliases;\n  struct in_addr *addrs;\n  struct hostent *hostent;\n\n  /* Set *host to NULL for all failure cases. */\n  *host = NULL;\n\n  /* Give up if abuf doesn't have room for a header. */\n  if (alen < HFIXEDSZ)\n    return ARES_EBADRESP;\n\n  /* Fetch the question and answer count from the header. */\n  qdcount = DNS_HEADER_QDCOUNT(abuf);\n  ancount = DNS_HEADER_ANCOUNT(abuf);\n  if (qdcount != 1)\n    return ARES_EBADRESP;\n\n  /* Expand the name from the question, and skip past the question. */\n  aptr = abuf + HFIXEDSZ;\n  status = ares_expand_name(aptr, abuf, alen, &hostname, &len);\n  if (status != ARES_SUCCESS)\n    return status;\n  if (aptr + len + QFIXEDSZ > abuf + alen)\n    {\n      free(hostname);\n      return ARES_EBADRESP;\n    }\n  aptr += len + QFIXEDSZ;\n\n  /* Allocate addresses and aliases; ancount gives an upper bound for both. */\n  addrs = malloc(ancount * sizeof(struct in_addr));\n  if (!addrs)\n    {\n      free(hostname);\n      return ARES_ENOMEM;\n    }\n  aliases = malloc((ancount + 1) * sizeof(char *));\n  if (!aliases)\n    {\n      free(hostname);\n      free(addrs);\n      return ARES_ENOMEM;\n    }\n  naddrs = 0;\n  naliases = 0;\n\n  /* Examine each answer resource record (RR) in turn. */\n  for (i = 0; i < (int)ancount; i++)\n    {\n      /* Decode the RR up to the data field. */\n      status = ares_expand_name(aptr, abuf, alen, &rr_name, &len);\n      if (status != ARES_SUCCESS)\n\tbreak;\n      aptr += len;\n      if (aptr + RRFIXEDSZ > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n      rr_type = DNS_RR_TYPE(aptr);\n      rr_class = DNS_RR_CLASS(aptr);\n      rr_len = DNS_RR_LEN(aptr);\n      aptr += RRFIXEDSZ;\n\n      if (rr_class == C_IN && rr_type == T_A\n\t  && rr_len == sizeof(struct in_addr)\n\t  && strcasecmp(rr_name, hostname) == 0)\n\t{\n\t  memcpy(&addrs[naddrs], aptr, sizeof(struct in_addr));\n\t  naddrs++;\n\t  status = ARES_SUCCESS;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_CNAME)\n\t{\n\t  /* Record the RR name as an alias. */\n\t  aliases[naliases] = rr_name;\n\t  naliases++;\n\n\t  /* Decode the RR data and replace the hostname with it. */\n\t  status = ares_expand_name(aptr, abuf, alen, &rr_data, &len);\n\t  if (status != ARES_SUCCESS)\n\t    break;\n\t  free(hostname);\n\t  hostname = rr_data;\n\t}\n      else\n\tfree(rr_name);\n\n      aptr += rr_len;\n      if (aptr > abuf + alen)\n\t{\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n    }\n\n  if (status == ARES_SUCCESS && naddrs == 0)\n    status = ARES_ENODATA;\n  if (status == ARES_SUCCESS)\n    {\n      /* We got our answer.  Allocate memory to build the host entry. */\n      aliases[naliases] = NULL;\n      hostent = malloc(sizeof(struct hostent));\n      if (hostent)\n\t{\n\t  hostent->h_addr_list = malloc((naddrs + 1) * sizeof(char *));\n\t  if (hostent->h_addr_list)\n\t    {\n\t      /* Fill in the hostent and return successfully. */\n\t      hostent->h_name = hostname;\n\t      hostent->h_aliases = aliases;\n\t      hostent->h_addrtype = AF_INET;\n\t      hostent->h_length = sizeof(struct in_addr);\n\t      for (i = 0; i < naddrs; i++)\n\t\thostent->h_addr_list[i] = (char *) &addrs[i];\n\t      hostent->h_addr_list[naddrs] = NULL;\n\t      *host = hostent;\n\t      return ARES_SUCCESS;\n\t    }\n\t  free(hostent);\n\t}\n      status = ARES_ENOMEM;\n    }\n  for (i = 0; i < naliases; i++)\n    free(aliases[i]);\n  free(aliases);\n  free(addrs);\n  free(hostname);\n  return status;\n}", "func_src_after": "int ares_parse_a_reply(const unsigned char *abuf, int alen,\n\t\t       struct hostent **host)\n{\n  unsigned int qdcount, ancount;\n  int status, i, rr_type, rr_class, rr_len, naddrs;\n  long int len;\n  int naliases;\n  const unsigned char *aptr;\n  char *hostname, *rr_name, *rr_data, **aliases;\n  struct in_addr *addrs;\n  struct hostent *hostent;\n\n  /* Set *host to NULL for all failure cases. */\n  *host = NULL;\n\n  /* Give up if abuf doesn't have room for a header. */\n  if (alen < HFIXEDSZ)\n    return ARES_EBADRESP;\n\n  /* Fetch the question and answer count from the header. */\n  qdcount = DNS_HEADER_QDCOUNT(abuf);\n  ancount = DNS_HEADER_ANCOUNT(abuf);\n  if (qdcount != 1)\n    return ARES_EBADRESP;\n\n  /* Expand the name from the question, and skip past the question. */\n  aptr = abuf + HFIXEDSZ;\n  status = ares_expand_name(aptr, abuf, alen, &hostname, &len);\n  if (status != ARES_SUCCESS)\n    return status;\n  if (aptr + len + QFIXEDSZ > abuf + alen)\n    {\n      free(hostname);\n      return ARES_EBADRESP;\n    }\n  aptr += len + QFIXEDSZ;\n\n  /* Allocate addresses and aliases; ancount gives an upper bound for both. */\n  addrs = malloc(ancount * sizeof(struct in_addr));\n  if (!addrs)\n    {\n      free(hostname);\n      return ARES_ENOMEM;\n    }\n  aliases = malloc((ancount + 1) * sizeof(char *));\n  if (!aliases)\n    {\n      free(hostname);\n      free(addrs);\n      return ARES_ENOMEM;\n    }\n  naddrs = 0;\n  naliases = 0;\n\n  /* Examine each answer resource record (RR) in turn. */\n  for (i = 0; i < (int)ancount; i++)\n    {\n      /* Decode the RR up to the data field. */\n      status = ares_expand_name(aptr, abuf, alen, &rr_name, &len);\n      if (status != ARES_SUCCESS)\n\tbreak;\n      aptr += len;\n      if (aptr + RRFIXEDSZ > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n      rr_type = DNS_RR_TYPE(aptr);\n      rr_class = DNS_RR_CLASS(aptr);\n      rr_len = DNS_RR_LEN(aptr);\n      aptr += RRFIXEDSZ;\n      if (aptr + rr_len > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_A\n\t  && rr_len == sizeof(struct in_addr)\n\t  && strcasecmp(rr_name, hostname) == 0)\n\t{\n\t  memcpy(&addrs[naddrs], aptr, sizeof(struct in_addr));\n\t  naddrs++;\n\t  status = ARES_SUCCESS;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_CNAME)\n\t{\n\t  /* Record the RR name as an alias. */\n\t  aliases[naliases] = rr_name;\n\t  naliases++;\n\n\t  /* Decode the RR data and replace the hostname with it. */\n\t  status = ares_expand_name(aptr, abuf, alen, &rr_data, &len);\n\t  if (status != ARES_SUCCESS)\n\t    break;\n\t  free(hostname);\n\t  hostname = rr_data;\n\t}\n      else\n\tfree(rr_name);\n\n      aptr += rr_len;\n      if (aptr > abuf + alen)\n\t{\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n    }\n\n  if (status == ARES_SUCCESS && naddrs == 0)\n    status = ARES_ENODATA;\n  if (status == ARES_SUCCESS)\n    {\n      /* We got our answer.  Allocate memory to build the host entry. */\n      aliases[naliases] = NULL;\n      hostent = malloc(sizeof(struct hostent));\n      if (hostent)\n\t{\n\t  hostent->h_addr_list = malloc((naddrs + 1) * sizeof(char *));\n\t  if (hostent->h_addr_list)\n\t    {\n\t      /* Fill in the hostent and return successfully. */\n\t      hostent->h_name = hostname;\n\t      hostent->h_aliases = aliases;\n\t      hostent->h_addrtype = AF_INET;\n\t      hostent->h_length = sizeof(struct in_addr);\n\t      for (i = 0; i < naddrs; i++)\n\t\thostent->h_addr_list[i] = (char *) &addrs[i];\n\t      hostent->h_addr_list[naddrs] = NULL;\n\t      *host = hostent;\n\t      return ARES_SUCCESS;\n\t    }\n\t  free(hostent);\n\t}\n      status = ARES_ENOMEM;\n    }\n  for (i = 0; i < naliases; i++)\n    free(aliases[i]);\n  free(aliases);\n  free(addrs);\n  free(hostname);\n  return status;\n}", "commit_link": "github.com/resiprocate/resiprocate/commit/d67a9ca6fd06ca65d23e313bdbad1ef4dd3aa0df", "file_name": "rutil/dns/ares/ares_parse_a_reply.c", "vul_type": "cwe-125", "description": "In C, write a function to parse a DNS response and populate a hostent structure with the results."}
{"func_name": "mpeg4_decode_studio_block", "func_src_before": "static int mpeg4_decode_studio_block(MpegEncContext *s, int32_t block[64], int n)\n{\n    Mpeg4DecContext *ctx = s->avctx->priv_data;\n\n    int cc, dct_dc_size, dct_diff, code, j, idx = 1, group = 0, run = 0,\n        additional_code_len, sign, mismatch;\n    VLC *cur_vlc = &ctx->studio_intra_tab[0];\n    uint8_t *const scantable = s->intra_scantable.permutated;\n    const uint16_t *quant_matrix;\n    uint32_t flc;\n    const int min = -1 *  (1 << (s->avctx->bits_per_raw_sample + 6));\n    const int max =      ((1 << (s->avctx->bits_per_raw_sample + 6)) - 1);\n\n    mismatch = 1;\n\n    memset(block, 0, 64 * sizeof(int32_t));\n\n    if (n < 4) {\n        cc = 0;\n        dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->intra_matrix;\n    } else {\n        cc = (n & 1) + 1;\n        if (ctx->rgb)\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        else\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_chroma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->chroma_intra_matrix;\n    }\n\n    if (dct_dc_size < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"illegal dct_dc_size vlc\\n\");\n        return AVERROR_INVALIDDATA;\n    } else if (dct_dc_size == 0) {\n        dct_diff = 0;\n    } else {\n        dct_diff = get_xbits(&s->gb, dct_dc_size);\n\n        if (dct_dc_size > 8) {\n            if(!check_marker(s->avctx, &s->gb, \"dct_dc_size > 8\"))\n                return AVERROR_INVALIDDATA;\n        }\n\n    }\n\n    s->last_dc[cc] += dct_diff;\n\n    if (s->mpeg_quant)\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision);\n    else\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision) * (8 >> s->dct_precision);\n    /* TODO: support mpeg_quant for AC coefficients */\n\n    block[0] = av_clip(block[0], min, max);\n    mismatch ^= block[0];\n\n    /* AC Coefficients */\n    while (1) {\n        group = get_vlc2(&s->gb, cur_vlc->table, STUDIO_INTRA_BITS, 2);\n\n        if (group < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"illegal ac coefficient group vlc\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        additional_code_len = ac_state_tab[group][0];\n        cur_vlc = &ctx->studio_intra_tab[ac_state_tab[group][1]];\n\n        if (group == 0) {\n            /* End of Block */\n            break;\n        } else if (group >= 1 && group <= 6) {\n            /* Zero run length (Table B.47) */\n            run = 1 << additional_code_len;\n            if (additional_code_len)\n                run += get_bits(&s->gb, additional_code_len);\n            idx += run;\n            continue;\n        } else if (group >= 7 && group <= 12) {\n            /* Zero run length and +/-1 level (Table B.48) */\n            code = get_bits(&s->gb, additional_code_len);\n            sign = code & 1;\n            code >>= 1;\n            run = (1 << (additional_code_len - 1)) + code;\n            idx += run;\n            j = scantable[idx++];\n            block[j] = sign ? 1 : -1;\n        } else if (group >= 13 && group <= 20) {\n            /* Level value (Table B.49) */\n            j = scantable[idx++];\n            block[j] = get_xbits(&s->gb, additional_code_len);\n        } else if (group == 21) {\n            /* Escape */\n            j = scantable[idx++];\n            additional_code_len = s->avctx->bits_per_raw_sample + s->dct_precision + 4;\n            flc = get_bits(&s->gb, additional_code_len);\n            if (flc >> (additional_code_len-1))\n                block[j] = -1 * (( flc ^ ((1 << additional_code_len) -1)) + 1);\n            else\n                block[j] = flc;\n        }\n        block[j] = ((8 * 2 * block[j] * quant_matrix[j] * s->qscale) >> s->dct_precision) / 32;\n        block[j] = av_clip(block[j], min, max);\n        mismatch ^= block[j];\n    }\n\n    block[63] ^= mismatch & 1;\n\n    return 0;\n}", "func_src_after": "static int mpeg4_decode_studio_block(MpegEncContext *s, int32_t block[64], int n)\n{\n    Mpeg4DecContext *ctx = s->avctx->priv_data;\n\n    int cc, dct_dc_size, dct_diff, code, j, idx = 1, group = 0, run = 0,\n        additional_code_len, sign, mismatch;\n    VLC *cur_vlc = &ctx->studio_intra_tab[0];\n    uint8_t *const scantable = s->intra_scantable.permutated;\n    const uint16_t *quant_matrix;\n    uint32_t flc;\n    const int min = -1 *  (1 << (s->avctx->bits_per_raw_sample + 6));\n    const int max =      ((1 << (s->avctx->bits_per_raw_sample + 6)) - 1);\n\n    mismatch = 1;\n\n    memset(block, 0, 64 * sizeof(int32_t));\n\n    if (n < 4) {\n        cc = 0;\n        dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->intra_matrix;\n    } else {\n        cc = (n & 1) + 1;\n        if (ctx->rgb)\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        else\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_chroma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->chroma_intra_matrix;\n    }\n\n    if (dct_dc_size < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"illegal dct_dc_size vlc\\n\");\n        return AVERROR_INVALIDDATA;\n    } else if (dct_dc_size == 0) {\n        dct_diff = 0;\n    } else {\n        dct_diff = get_xbits(&s->gb, dct_dc_size);\n\n        if (dct_dc_size > 8) {\n            if(!check_marker(s->avctx, &s->gb, \"dct_dc_size > 8\"))\n                return AVERROR_INVALIDDATA;\n        }\n\n    }\n\n    s->last_dc[cc] += dct_diff;\n\n    if (s->mpeg_quant)\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision);\n    else\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision) * (8 >> s->dct_precision);\n    /* TODO: support mpeg_quant for AC coefficients */\n\n    block[0] = av_clip(block[0], min, max);\n    mismatch ^= block[0];\n\n    /* AC Coefficients */\n    while (1) {\n        group = get_vlc2(&s->gb, cur_vlc->table, STUDIO_INTRA_BITS, 2);\n\n        if (group < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"illegal ac coefficient group vlc\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        additional_code_len = ac_state_tab[group][0];\n        cur_vlc = &ctx->studio_intra_tab[ac_state_tab[group][1]];\n\n        if (group == 0) {\n            /* End of Block */\n            break;\n        } else if (group >= 1 && group <= 6) {\n            /* Zero run length (Table B.47) */\n            run = 1 << additional_code_len;\n            if (additional_code_len)\n                run += get_bits(&s->gb, additional_code_len);\n            idx += run;\n            continue;\n        } else if (group >= 7 && group <= 12) {\n            /* Zero run length and +/-1 level (Table B.48) */\n            code = get_bits(&s->gb, additional_code_len);\n            sign = code & 1;\n            code >>= 1;\n            run = (1 << (additional_code_len - 1)) + code;\n            idx += run;\n            if (idx > 63)\n                return AVERROR_INVALIDDATA;\n            j = scantable[idx++];\n            block[j] = sign ? 1 : -1;\n        } else if (group >= 13 && group <= 20) {\n            /* Level value (Table B.49) */\n            if (idx > 63)\n                return AVERROR_INVALIDDATA;\n            j = scantable[idx++];\n            block[j] = get_xbits(&s->gb, additional_code_len);\n        } else if (group == 21) {\n            /* Escape */\n            if (idx > 63)\n                return AVERROR_INVALIDDATA;\n            j = scantable[idx++];\n            additional_code_len = s->avctx->bits_per_raw_sample + s->dct_precision + 4;\n            flc = get_bits(&s->gb, additional_code_len);\n            if (flc >> (additional_code_len-1))\n                block[j] = -1 * (( flc ^ ((1 << additional_code_len) -1)) + 1);\n            else\n                block[j] = flc;\n        }\n        block[j] = ((8 * 2 * block[j] * quant_matrix[j] * s->qscale) >> s->dct_precision) / 32;\n        block[j] = av_clip(block[j], min, max);\n        mismatch ^= block[j];\n    }\n\n    block[63] ^= mismatch & 1;\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/d227ed5d598340e719eff7156b1aa0a4469e9a6a", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function named `mpeg4_decode_studio_block` that decodes a single block of MPEG4 studio profile video."}
{"func_name": "xdp_umem_reg", "func_src_before": "static int xdp_umem_reg(struct xdp_umem *umem, struct xdp_umem_reg *mr)\n{\n\tbool unaligned_chunks = mr->flags & XDP_UMEM_UNALIGNED_CHUNK_FLAG;\n\tu32 chunk_size = mr->chunk_size, headroom = mr->headroom;\n\tunsigned int chunks, chunks_per_page;\n\tu64 addr = mr->addr, size = mr->len;\n\tint size_chk, err;\n\n\tif (chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE) {\n\t\t/* Strictly speaking we could support this, if:\n\t\t * - huge pages, or*\n\t\t * - using an IOMMU, or\n\t\t * - making sure the memory area is consecutive\n\t\t * but for now, we simply say \"computer says no\".\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif (mr->flags & ~(XDP_UMEM_UNALIGNED_CHUNK_FLAG |\n\t\t\tXDP_UMEM_USES_NEED_WAKEUP))\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks && !is_power_of_2(chunk_size))\n\t\treturn -EINVAL;\n\n\tif (!PAGE_ALIGNED(addr)) {\n\t\t/* Memory area has to be page size aligned. For\n\t\t * simplicity, this might change.\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif ((addr + size) < addr)\n\t\treturn -EINVAL;\n\n\tchunks = (unsigned int)div_u64(size, chunk_size);\n\tif (chunks == 0)\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks) {\n\t\tchunks_per_page = PAGE_SIZE / chunk_size;\n\t\tif (chunks < chunks_per_page || chunks % chunks_per_page)\n\t\t\treturn -EINVAL;\n\t}\n\n\tsize_chk = chunk_size - headroom - XDP_PACKET_HEADROOM;\n\tif (size_chk < 0)\n\t\treturn -EINVAL;\n\n\tumem->address = (unsigned long)addr;\n\tumem->chunk_mask = unaligned_chunks ? XSK_UNALIGNED_BUF_ADDR_MASK\n\t\t\t\t\t    : ~((u64)chunk_size - 1);\n\tumem->size = size;\n\tumem->headroom = headroom;\n\tumem->chunk_size_nohr = chunk_size - headroom;\n\tumem->npgs = size / PAGE_SIZE;\n\tumem->pgs = NULL;\n\tumem->user = NULL;\n\tumem->flags = mr->flags;\n\tINIT_LIST_HEAD(&umem->xsk_list);\n\tspin_lock_init(&umem->xsk_list_lock);\n\n\trefcount_set(&umem->users, 1);\n\n\terr = xdp_umem_account_pages(umem);\n\tif (err)\n\t\treturn err;\n\n\terr = xdp_umem_pin_pages(umem);\n\tif (err)\n\t\tgoto out_account;\n\n\tumem->pages = kvcalloc(umem->npgs, sizeof(*umem->pages),\n\t\t\t       GFP_KERNEL_ACCOUNT);\n\tif (!umem->pages) {\n\t\terr = -ENOMEM;\n\t\tgoto out_pin;\n\t}\n\n\terr = xdp_umem_map_pages(umem);\n\tif (!err)\n\t\treturn 0;\n\n\tkvfree(umem->pages);\n\nout_pin:\n\txdp_umem_unpin_pages(umem);\nout_account:\n\txdp_umem_unaccount_pages(umem);\n\treturn err;\n}", "func_src_after": "static int xdp_umem_reg(struct xdp_umem *umem, struct xdp_umem_reg *mr)\n{\n\tbool unaligned_chunks = mr->flags & XDP_UMEM_UNALIGNED_CHUNK_FLAG;\n\tu32 chunk_size = mr->chunk_size, headroom = mr->headroom;\n\tunsigned int chunks, chunks_per_page;\n\tu64 addr = mr->addr, size = mr->len;\n\tint err;\n\n\tif (chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE) {\n\t\t/* Strictly speaking we could support this, if:\n\t\t * - huge pages, or*\n\t\t * - using an IOMMU, or\n\t\t * - making sure the memory area is consecutive\n\t\t * but for now, we simply say \"computer says no\".\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif (mr->flags & ~(XDP_UMEM_UNALIGNED_CHUNK_FLAG |\n\t\t\tXDP_UMEM_USES_NEED_WAKEUP))\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks && !is_power_of_2(chunk_size))\n\t\treturn -EINVAL;\n\n\tif (!PAGE_ALIGNED(addr)) {\n\t\t/* Memory area has to be page size aligned. For\n\t\t * simplicity, this might change.\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif ((addr + size) < addr)\n\t\treturn -EINVAL;\n\n\tchunks = (unsigned int)div_u64(size, chunk_size);\n\tif (chunks == 0)\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks) {\n\t\tchunks_per_page = PAGE_SIZE / chunk_size;\n\t\tif (chunks < chunks_per_page || chunks % chunks_per_page)\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (headroom >= chunk_size - XDP_PACKET_HEADROOM)\n\t\treturn -EINVAL;\n\n\tumem->address = (unsigned long)addr;\n\tumem->chunk_mask = unaligned_chunks ? XSK_UNALIGNED_BUF_ADDR_MASK\n\t\t\t\t\t    : ~((u64)chunk_size - 1);\n\tumem->size = size;\n\tumem->headroom = headroom;\n\tumem->chunk_size_nohr = chunk_size - headroom;\n\tumem->npgs = size / PAGE_SIZE;\n\tumem->pgs = NULL;\n\tumem->user = NULL;\n\tumem->flags = mr->flags;\n\tINIT_LIST_HEAD(&umem->xsk_list);\n\tspin_lock_init(&umem->xsk_list_lock);\n\n\trefcount_set(&umem->users, 1);\n\n\terr = xdp_umem_account_pages(umem);\n\tif (err)\n\t\treturn err;\n\n\terr = xdp_umem_pin_pages(umem);\n\tif (err)\n\t\tgoto out_account;\n\n\tumem->pages = kvcalloc(umem->npgs, sizeof(*umem->pages),\n\t\t\t       GFP_KERNEL_ACCOUNT);\n\tif (!umem->pages) {\n\t\terr = -ENOMEM;\n\t\tgoto out_pin;\n\t}\n\n\terr = xdp_umem_map_pages(umem);\n\tif (!err)\n\t\treturn 0;\n\n\tkvfree(umem->pages);\n\nout_pin:\n\txdp_umem_unpin_pages(umem);\nout_account:\n\txdp_umem_unaccount_pages(umem);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/99e3a236dd43d06c65af0a2ef9cb44306aef6e02", "file_name": "net/xdp/xdp_umem.c", "vul_type": "cwe-787", "description": "Write a C function named `xdp_umem_reg` that registers a user memory (`umem`) area for use with XDP sockets, validating the provided memory region parameters."}
{"func_name": "handle_file", "func_src_before": "def handle_file(u: Profile, headline: str, category: str, text: str, file):\n    m: Media = Media()\n    upload_base_path: str = 'uploads/' + str(date.today().year)\n    high_res_file_name = upload_base_path + '/HIGHRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    low_res_file_name = upload_base_path + '/LOWRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    if not os.path.exists(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path):\n        os.makedirs(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path)\n    with open(high_res_file_name, 'wb+') as destination:\n        for chunk in file.chunks():\n            destination.write(chunk)\n    # TODO crop image\n    original = Image.open(high_res_file_name)\n    width, height = original.size\n    diameter = math.sqrt(math.pow(width, 2) + math.pow(height, 2))\n    width /= diameter\n    height /= diameter\n    width *= IMAGE_SCALE\n    height *= IMAGE_SCALE\n    cropped = original.resize((int(width), int(height)), PIL.Image.LANCZOS)\n    cropped.save(low_res_file_name)\n    m.text = text\n    m.cachedText = compile_markdown(text)\n    m.category = category\n    m.highResFile = \"/\" + high_res_file_name\n    m.lowResFile = \"/\" + low_res_file_name\n    m.headline = headline\n    m.save()\n    mu: MediaUpload = MediaUpload()\n    mu.UID = u\n    mu.MID = m\n    mu.save()\n    logging.info(\"Uploaded file '\" + str(file.name) + \"' and cropped it. The resulting PK is \" + str(m.pk))", "func_src_after": "def handle_file(u: Profile, headline: str, category: str, text: str, file):\n    m: Media = Media()\n    upload_base_path: str = 'uploads/' + str(date.today().year)\n    high_res_file_name = upload_base_path + '/HIGHRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    low_res_file_name = upload_base_path + '/LOWRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    if not os.path.exists(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path):\n        os.makedirs(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path)\n    with open(high_res_file_name, 'wb+') as destination:\n        for chunk in file.chunks():\n            destination.write(chunk)\n    # TODO crop image\n    original = Image.open(high_res_file_name)\n    width, height = original.size\n    diameter = math.sqrt(math.pow(width, 2) + math.pow(height, 2))\n    width /= diameter\n    height /= diameter\n    width *= IMAGE_SCALE\n    height *= IMAGE_SCALE\n    cropped = original.resize((int(width), int(height)), PIL.Image.LANCZOS)\n    cropped.save(low_res_file_name)\n    m.text = escape(text)\n    m.cachedText = compile_markdown(escape(text))\n    m.category = escape(category)\n    m.highResFile = \"/\" + high_res_file_name\n    m.lowResFile = \"/\" + low_res_file_name\n    m.headline = escape(headline)\n    m.save()\n    mu: MediaUpload = MediaUpload()\n    mu.UID = u\n    mu.MID = m\n    mu.save()\n    logging.info(\"Uploaded file '\" + str(file.name) + \"' and cropped it. The resulting PK is \" + str(m.pk))", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/mediatools/media_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle media file uploads, including image resizing and metadata processing."}
{"func_name": "luaD_shrinkstack", "func_src_before": "void luaD_shrinkstack (lua_State *L) {\n  int inuse = stackinuse(L);\n  int goodsize = inuse + (inuse / 8) + 2*EXTRA_STACK;\n  if (goodsize > LUAI_MAXSTACK)\n    goodsize = LUAI_MAXSTACK;  /* respect stack limit */\n  /* if thread is currently not handling a stack overflow and its\n     good size is smaller than current size, shrink its stack */\n  if (inuse <= (LUAI_MAXSTACK - EXTRA_STACK) &&\n      goodsize < L->stacksize)\n    luaD_reallocstack(L, goodsize, 0);  /* ok if that fails */\n  else  /* don't change stack */\n    condmovestack(L,{},{});  /* (change only for debugging) */\n  luaE_shrinkCI(L);  /* shrink CI list */\n}", "func_src_after": "void luaD_shrinkstack (lua_State *L) {\n  int inuse = stackinuse(L);\n  int goodsize = inuse + BASIC_STACK_SIZE;\n  if (goodsize > LUAI_MAXSTACK)\n    goodsize = LUAI_MAXSTACK;  /* respect stack limit */\n  /* if thread is currently not handling a stack overflow and its\n     good size is smaller than current size, shrink its stack */\n  if (inuse <= (LUAI_MAXSTACK - EXTRA_STACK) && goodsize < L->stacksize)\n    luaD_reallocstack(L, goodsize, 0);  /* ok if that fails */\n  else  /* don't change stack */\n    condmovestack(L,{},{});  /* (change only for debugging) */\n  luaE_shrinkCI(L);  /* shrink CI list */\n}", "commit_link": "github.com/lua/lua/commit/6298903e35217ab69c279056f925fb72900ce0b7", "file_name": "ldo.c", "vul_type": "cwe-416", "description": "Write a C function named `luaD_shrinkstack` for Lua that adjusts the stack size based on current usage and predefined limits."}
{"func_name": "_delete_host", "func_src_before": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = 'svctask rmhost %s ' % host_name\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "func_src_after": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = ['svctask', 'rmhost', host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to delete a host from a storage system using SSH commands, with debug logging before and after the operation."}
{"func_name": "input_csi_dispatch_sgr_colon", "func_src_before": "input_csi_dispatch_sgr_colon(struct input_ctx *ictx, u_int i)\n{\n\tstruct grid_cell\t*gc = &ictx->cell.cell;\n\tchar\t\t\t*s = ictx->param_list[i].str, *copy, *ptr, *out;\n\tint\t\t\t p[8];\n\tu_int\t\t\t n;\n\tconst char\t\t*errstr;\n\n\tfor (n = 0; n < nitems(p); n++)\n\t\tp[n] = -1;\n\tn = 0;\n\n\tptr = copy = xstrdup(s);\n\twhile ((out = strsep(&ptr, \":\")) != NULL) {\n\t\tif (*out != '\\0') {\n\t\t\tp[n++] = strtonum(out, 0, INT_MAX, &errstr);\n\t\t\tif (errstr != NULL || n == nitems(p)) {\n\t\t\t\tfree(copy);\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else\n\t\t\tn++;\n\t\tlog_debug(\"%s: %u = %d\", __func__, n - 1, p[n - 1]);\n\t}\n\tfree(copy);\n\n\tif (n == 0)\n\t\treturn;\n\tif (p[0] == 4) {\n\t\tif (n != 2)\n\t\t\treturn;\n\t\tswitch (p[1]) {\n\t\tcase 0:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_2;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_3;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_4;\n\t\t\tbreak;\n\t\tcase 5:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_5;\n\t\t\tbreak;\n\t\t}\n\t\treturn;\n\t}\n\tif (n < 2 || (p[0] != 38 && p[0] != 48 && p[0] != 58))\n\t\treturn;\n\tswitch (p[1]) {\n\tcase 2:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tif (n == 5)\n\t\t\ti = 2;\n\t\telse\n\t\t\ti = 3;\n\t\tif (n < i + 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_rgb_do(ictx, p[0], p[i], p[i + 1],\n\t\t    p[i + 2]);\n\t\tbreak;\n\tcase 5:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_256_do(ictx, p[0], p[2]);\n\t\tbreak;\n\t}\n}", "func_src_after": "input_csi_dispatch_sgr_colon(struct input_ctx *ictx, u_int i)\n{\n\tstruct grid_cell\t*gc = &ictx->cell.cell;\n\tchar\t\t\t*s = ictx->param_list[i].str, *copy, *ptr, *out;\n\tint\t\t\t p[8];\n\tu_int\t\t\t n;\n\tconst char\t\t*errstr;\n\n\tfor (n = 0; n < nitems(p); n++)\n\t\tp[n] = -1;\n\tn = 0;\n\n\tptr = copy = xstrdup(s);\n\twhile ((out = strsep(&ptr, \":\")) != NULL) {\n\t\tif (*out != '\\0') {\n\t\t\tp[n++] = strtonum(out, 0, INT_MAX, &errstr);\n\t\t\tif (errstr != NULL || n == nitems(p)) {\n\t\t\t\tfree(copy);\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else {\n\t\t\tn++;\n\t\t\tif (n == nitems(p)) {\n\t\t\t\tfree(copy);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tlog_debug(\"%s: %u = %d\", __func__, n - 1, p[n - 1]);\n\t}\n\tfree(copy);\n\n\tif (n == 0)\n\t\treturn;\n\tif (p[0] == 4) {\n\t\tif (n != 2)\n\t\t\treturn;\n\t\tswitch (p[1]) {\n\t\tcase 0:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_2;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_3;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_4;\n\t\t\tbreak;\n\t\tcase 5:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_5;\n\t\t\tbreak;\n\t\t}\n\t\treturn;\n\t}\n\tif (n < 2 || (p[0] != 38 && p[0] != 48 && p[0] != 58))\n\t\treturn;\n\tswitch (p[1]) {\n\tcase 2:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tif (n == 5)\n\t\t\ti = 2;\n\t\telse\n\t\t\ti = 3;\n\t\tif (n < i + 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_rgb_do(ictx, p[0], p[i], p[i + 1],\n\t\t    p[i + 2]);\n\t\tbreak;\n\tcase 5:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_256_do(ictx, p[0], p[2]);\n\t\tbreak;\n\t}\n}", "commit_link": "github.com/tmux/tmux/commit/a868bacb46e3c900530bed47a1c6f85b0fbe701c", "file_name": "input.c", "vul_type": "cwe-787", "description": "Write a C function to parse colon-separated SGR (Select Graphic Rendition) parameters and update text attributes accordingly."}
{"func_name": "landingPage", "func_src_before": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "func_src_after": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tidStr = html.EscapeString(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "line_changes": {"deleted": [], "added": [{"line_no": 32, "char_start": 749, "char_end": 783, "line": "\tidStr = html.EscapeString(idStr)\n"}, {"line_no": 33, "char_start": 783, "char_end": 784, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 749, "char_end": 784, "chars": "\tidStr = html.EscapeString(idStr)\n\n"}]}, "commit_link": "github.com/qqiao/yordle/commit/6f9f25af52fd05b77db575191b6775a4f7f1bb26", "file_name": "yordle.go", "vul_type": "cwe-079", "commit_msg": "HTML Escapes idStr to prevent xss (#69)", "parent_commit": "366d98e5fdad503cafa95c6310a133078203fdfb", "description": "Write a Go function that serves a landing page or redirects to an original URL based on a path-encoded identifier."}
{"func_name": "also_add", "func_src_before": "def also_add(name, also):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            INSERT INTO isalso(name,also) VALUES('{}','{}')\n            '''.format(name, also))\n        db.commit()\n        logger.debug('added to isalso name {} with value {}'.format(\n            name, also))\n        db.close()\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def also_add(name, also):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            INSERT INTO isalso(name,also) VALUES(%(name)s,%(also)s)\n            ''', (\n            name,\n            also,\n        ))\n        db.commit()\n        logger.debug('added to isalso name {} with value {}'.format(\n            name, also))\n        db.close()\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a name and an associated value into an 'isalso' database table and log the action."}
{"func_name": "xsltKeyFunction", "func_src_before": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "func_src_after": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n        if (ret == NULL) {\n            ctxt->error = XPATH_MEMORY_ERROR;\n            xmlXPathFreeObject(obj1);\n            xmlXPathFreeObject(obj2);\n            return;\n        }\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "commit_link": "github.com/GNOME/libxslt/commit/aab7eedca3c2dcaa1795d6acba38a4c9811d2a75", "file_name": "libxslt/functions.c", "vul_type": "cwe-476", "description": "Write a C function named `xsltKeyFunction` that implements the XSLT key function in libxml2."}
{"func_name": "set_fdc", "func_src_before": "static void set_fdc(int drive)\n{\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tfdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (fdc != 1 && fdc != 0) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "func_src_after": "static void set_fdc(int drive)\n{\n\tunsigned int new_fdc = fdc;\n\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tnew_fdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (new_fdc >= N_FDC) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tfdc = new_fdc;\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "commit_link": "github.com/torvalds/linux/commit/2e90ca68b0d2f5548804f22f0dd61145516171e3", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-125", "description": "Write a C function named `set_fdc` that configures a floppy disk controller (FDC) for a given drive number, with error checking and hardware status updates."}
{"func_name": "__init__", "func_src_before": "  def __init__(self,\n               sess,\n               dump_root=None,\n               log_usage=True,\n               ui_type=\"curses\",\n               thread_name_filter=None,\n               config_file_path=False):\n    \"\"\"Constructor of LocalCLIDebugWrapperSession.\n\n    Args:\n      sess: The TensorFlow `Session` object being wrapped.\n      dump_root: (`str`) optional path to the dump root directory. Must be a\n        directory that does not exist or an empty directory. If the directory\n        does not exist, it will be created by the debugger core during debug\n        `run()` calls and removed afterwards. If `None`, the debug dumps will\n        be at tfdbg_<random_string> under the system temp directory.\n      log_usage: (`bool`) whether the usage of this class is to be logged.\n      ui_type: (`str`) requested UI type. Currently supported:\n        (curses | readline)\n      thread_name_filter: Regular-expression white list for thread name. See\n        the doc of `BaseDebugWrapperSession` for details.\n      config_file_path: Optional override to the default configuration file\n        path, which is at `${HOME}/.tfdbg_config`.\n\n    Raises:\n      ValueError: If dump_root is an existing and non-empty directory or if\n        dump_root is a file.\n    \"\"\"\n\n    if log_usage:\n      pass  # No logging for open-source.\n\n    framework.BaseDebugWrapperSession.__init__(\n        self, sess, thread_name_filter=thread_name_filter)\n\n    if not dump_root:\n      self._dump_root = tempfile.mktemp(prefix=_DUMP_ROOT_PREFIX)\n    else:\n      dump_root = os.path.expanduser(dump_root)\n      if os.path.isfile(dump_root):\n        raise ValueError(\"dump_root path points to a file: %s\" % dump_root)\n      elif os.path.isdir(dump_root) and os.listdir(dump_root):\n        raise ValueError(\"dump_root path points to a non-empty directory: %s\" %\n                         dump_root)\n\n      self._dump_root = dump_root\n\n    self._initialize_argparsers()\n\n    # Registered tensor filters.\n    self._tensor_filters = {}\n    # Register frequently-used filter(s).\n    self.add_tensor_filter(\"has_inf_or_nan\", debug_data.has_inf_or_nan)\n\n    # Below are the state variables of this wrapper object.\n    # _active_tensor_filter: what (if any) tensor filter is in effect. If such\n    #   a filter is in effect, this object will call run() method of the\n    #   underlying TensorFlow Session object until the filter passes. This is\n    #   activated by the \"-f\" flag of the \"run\" command.\n    # _run_through_times: keeps track of how many times the wrapper needs to\n    #   run through without stopping at the run-end CLI. It is activated by the\n    #   \"-t\" option of the \"run\" command.\n    # _skip_debug: keeps track of whether the current run should be executed\n    #   without debugging. It is activated by the \"-n\" option of the \"run\"\n    #   command.\n    #\n    # _run_start_response: keeps track what OnRunStartResponse the wrapper\n    #   should return at the next run-start callback. If this information is\n    #   unavailable (i.e., is None), the run-start CLI will be launched to ask\n    #   the user. This is the case, e.g., right before the first run starts.\n    self._active_tensor_filter = None\n    self._active_filter_exclude_node_names = None\n    self._active_tensor_filter_run_start_response = None\n    self._run_through_times = 1\n    self._skip_debug = False\n    self._run_start_response = None\n    self._is_run_start = True\n    self._ui_type = ui_type\n    self._config = None\n    if config_file_path:\n      self._config = cli_config.CLIConfig(config_file_path=config_file_path)", "func_src_after": "  def __init__(self,\n               sess,\n               dump_root=None,\n               log_usage=True,\n               ui_type=\"curses\",\n               thread_name_filter=None,\n               config_file_path=False):\n    \"\"\"Constructor of LocalCLIDebugWrapperSession.\n\n    Args:\n      sess: The TensorFlow `Session` object being wrapped.\n      dump_root: (`str`) optional path to the dump root directory. Must be a\n        directory that does not exist or an empty directory. If the directory\n        does not exist, it will be created by the debugger core during debug\n        `run()` calls and removed afterwards. If `None`, the debug dumps will\n        be at tfdbg_<random_string> under the system temp directory.\n      log_usage: (`bool`) whether the usage of this class is to be logged.\n      ui_type: (`str`) requested UI type. Currently supported:\n        (curses | readline)\n      thread_name_filter: Regular-expression white list for thread name. See\n        the doc of `BaseDebugWrapperSession` for details.\n      config_file_path: Optional override to the default configuration file\n        path, which is at `${HOME}/.tfdbg_config`.\n\n    Raises:\n      ValueError: If dump_root is an existing and non-empty directory or if\n        dump_root is a file.\n    \"\"\"\n\n    if log_usage:\n      pass  # No logging for open-source.\n\n    framework.BaseDebugWrapperSession.__init__(\n        self, sess, thread_name_filter=thread_name_filter)\n\n    if not dump_root:\n      self._dump_root = tempfile.mkdtemp(prefix=_DUMP_ROOT_PREFIX)\n    else:\n      dump_root = os.path.expanduser(dump_root)\n      if os.path.isfile(dump_root):\n        raise ValueError(\"dump_root path points to a file: %s\" % dump_root)\n      elif os.path.isdir(dump_root) and os.listdir(dump_root):\n        raise ValueError(\"dump_root path points to a non-empty directory: %s\" %\n                         dump_root)\n\n      self._dump_root = dump_root\n\n    self._initialize_argparsers()\n\n    # Registered tensor filters.\n    self._tensor_filters = {}\n    # Register frequently-used filter(s).\n    self.add_tensor_filter(\"has_inf_or_nan\", debug_data.has_inf_or_nan)\n\n    # Below are the state variables of this wrapper object.\n    # _active_tensor_filter: what (if any) tensor filter is in effect. If such\n    #   a filter is in effect, this object will call run() method of the\n    #   underlying TensorFlow Session object until the filter passes. This is\n    #   activated by the \"-f\" flag of the \"run\" command.\n    # _run_through_times: keeps track of how many times the wrapper needs to\n    #   run through without stopping at the run-end CLI. It is activated by the\n    #   \"-t\" option of the \"run\" command.\n    # _skip_debug: keeps track of whether the current run should be executed\n    #   without debugging. It is activated by the \"-n\" option of the \"run\"\n    #   command.\n    #\n    # _run_start_response: keeps track what OnRunStartResponse the wrapper\n    #   should return at the next run-start callback. If this information is\n    #   unavailable (i.e., is None), the run-start CLI will be launched to ask\n    #   the user. This is the case, e.g., right before the first run starts.\n    self._active_tensor_filter = None\n    self._active_filter_exclude_node_names = None\n    self._active_tensor_filter_run_start_response = None\n    self._run_through_times = 1\n    self._skip_debug = False\n    self._run_start_response = None\n    self._is_run_start = True\n    self._ui_type = ui_type\n    self._config = None\n    if config_file_path:\n      self._config = cli_config.CLIConfig(config_file_path=config_file_path)", "line_changes": {"deleted": [{"line_no": 37, "char_start": 1463, "char_end": 1529, "line": "      self._dump_root = tempfile.mktemp(prefix=_DUMP_ROOT_PREFIX)\n"}], "added": [{"line_no": 37, "char_start": 1463, "char_end": 1530, "line": "      self._dump_root = tempfile.mkdtemp(prefix=_DUMP_ROOT_PREFIX)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1498, "char_end": 1499, "chars": "d"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/2939613ef8340a75c13a470d4097dbd7e4b6b534", "file_name": "local_cli_wrapper.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420384092\nChange-Id: I8721c09ccc4de589b5a45d38e7ebc440160c72b8", "description": "Write a Python class constructor for a TensorFlow debugging wrapper session with customizable session, dump directory, logging, UI type, thread filtering, and configuration file path."}
{"func_name": "(anonymous)", "func_src_before": "\t\texec('node ' + binPath + ' ' + args.join(' '), function () {\n\t\t\tvar actual = fs.statSync('test/minified.png').size;\n\t\t\tvar original = fs.statSync('test/fixtures/test.png').size;\n\t\t\tassert(actual < original);\n\t\t\tcb();\n\t\t});", "func_src_after": "\t\texecFile('node', [binPath].concat(args), function () {\n\t\t\tvar actual = fs.statSync('test/minified.png').size;\n\t\t\tvar original = fs.statSync('test/fixtures/test.png').size;\n\t\t\tassert(actual < original);\n\t\t\tcb();\n\t\t});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 63, "line": "\t\texec('node ' + binPath + ' ' + args.join(' '), function () {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 57, "line": "\t\texecFile('node', [binPath].concat(args), function () {\n"}]}, "char_changes": {"deleted": [{"char_start": 12, "char_end": 17, "chars": " ' + "}, {"char_start": 24, "char_end": 46, "chars": " + ' ' + args.join(' '"}], "added": [{"char_start": 6, "char_end": 10, "chars": "File"}, {"char_start": 16, "char_end": 20, "chars": "', ["}, {"char_start": 27, "char_end": 40, "chars": "].concat(args"}]}, "commit_link": "github.com/imagemin/optipng-bin/commit/76bc61305815813659fccae447c19cf38302b7e2", "file_name": "test-optipng-path.js", "vul_type": "cwe-078", "commit_msg": "use execFile and arguments array instead of string concat", "parent_commit": "fffe11371341e0360ecde090cf6f2bac5d81505a", "description": "Write a JavaScript function that executes a Node.js script with arguments and checks if the size of a minified image is smaller than the original image."}
{"func_name": "Get", "func_src_before": "func Get(key string, lat string, long string, time string) *Forecast {\n\tcoord := lat + \",\" + long\n\n\tvar url string\n\tif time == \"now\" {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=ca\"\n\t} else {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=ca\"\n\t}\n\n\ttr := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: true}, // susceptible to man-in-the-middle\n\t}\n\tclient := &http.Client{Transport: tr}\n\tresp, err := client.Get(url)\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\n\tvar f Forecast\n\terr = json.Unmarshal(body, &f)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\treturn &f\n}", "func_src_after": "func Get(key string, lat string, long string, time string) (*Forecast, error) {\n\tcoord := lat + \",\" + long\n\n\tvar url string\n\tif time == \"now\" {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=si\"\n\t} else {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=si\"\n\t}\n\n\ttr := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: false}, // does not seem required any longer\n\t}\n\tclient := &http.Client{Transport: tr}\n\tresp, err := client.Get(url)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\n\tvar f Forecast\n\terr = json.Unmarshal(body, &f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &f, nil\n}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 71, "line": "func Get(key string, lat string, long string, time string) *Forecast {\n"}, {"line_no": 6, "char_start": 135, "char_end": 191, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=ca\"\n"}, {"line_no": 8, "char_start": 201, "char_end": 270, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=ca\"\n"}, {"line_no": 12, "char_start": 298, "char_end": 392, "line": "\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: true}, // susceptible to man-in-the-middle\n"}, {"line_no": 18, "char_start": 482, "char_end": 499, "line": "\t\tlog.Fatal(err)\n"}, {"line_no": 26, "char_start": 633, "char_end": 650, "line": "\t\tlog.Fatal(err)\n"}, {"line_no": 29, "char_start": 654, "char_end": 665, "line": "\treturn &f\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 80, "line": "func Get(key string, lat string, long string, time string) (*Forecast, error) {\n"}, {"line_no": 6, "char_start": 144, "char_end": 200, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=si\"\n"}, {"line_no": 8, "char_start": 210, "char_end": 279, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=si\"\n"}, {"line_no": 12, "char_start": 307, "char_end": 403, "line": "\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: false}, // does not seem required any longer\n"}, {"line_no": 18, "char_start": 493, "char_end": 511, "line": "\t\treturn nil, err\n"}, {"line_no": 26, "char_start": 645, "char_end": 663, "line": "\t\treturn nil, err\n"}, {"line_no": 29, "char_start": 667, "char_end": 683, "line": "\treturn &f, nil\n"}]}, "char_changes": {"deleted": [{"char_start": 187, "char_end": 189, "chars": "ca"}, {"char_start": 266, "char_end": 268, "chars": "ca"}, {"char_start": 349, "char_end": 352, "chars": "tru"}, {"char_start": 359, "char_end": 391, "chars": "susceptible to man-in-the-middle"}, {"char_start": 484, "char_end": 494, "chars": "log.Fatal("}, {"char_start": 497, "char_end": 498, "chars": ")"}, {"char_start": 635, "char_end": 645, "chars": "log.Fatal("}, {"char_start": 648, "char_end": 649, "chars": ")"}], "added": [{"char_start": 59, "char_end": 60, "chars": "("}, {"char_start": 69, "char_end": 77, "chars": ", error)"}, {"char_start": 196, "char_end": 198, "chars": "si"}, {"char_start": 275, "char_end": 277, "chars": "si"}, {"char_start": 358, "char_end": 362, "chars": "fals"}, {"char_start": 369, "char_end": 402, "chars": "does not seem required any longer"}, {"char_start": 495, "char_end": 507, "chars": "return nil, "}, {"char_start": 647, "char_end": 659, "chars": "return nil, "}, {"char_start": 677, "char_end": 682, "chars": ", nil"}]}, "commit_link": "github.com/mlbright/darksky/commit/f398d4d31806800c59e17dd8514c8da751f9bf72", "file_name": "forecast.go", "vul_type": "cwe-295", "commit_msg": "Get now returns a (*Forecast, error) pair\n\nThis seems like good practice. As it was, the code would panic in case\nof - for example - network problems, which is not the nicest thing to do\nin a library.\n\nAdditionally, InsecureSkipVerify has been set to false.", "parent_commit": "99e2fc3d4132a0bd9cf3a94ada0efbe4c18deb08", "description": "Write a Go function named `Get` that retrieves weather forecast data using coordinates and time, and handles errors."}
{"func_name": "set_geometry", "func_src_before": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif (g->sect <= 0 ||\n\t    g->head <= 0 ||\n\t    /* check for zero in F_SECT_PER_TRACK */\n\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}", "func_src_after": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif ((int)g->sect <= 0 ||\n\t    (int)g->head <= 0 ||\n\t    /* check for overflow in max_sector */\n\t    (int)(g->sect * g->head) <= 0 ||\n\t    /* check for zero in F_SECT_PER_TRACK */\n\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/da99466ac243f15fbba65bd261bfc75ffa1532b6", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-190", "description": "Write a C function named `set_geometry` that configures the disk geometry for a floppy drive."}
{"func_name": "search_pages", "func_src_before": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = '%s'\" % search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "func_src_after": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = $1\", search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function that handles a POST request to search for a page title in a database and either redirects to the page if not found or returns a placeholder response."}
{"func_name": "user_verify", "func_src_before": "    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = '''select * from usr where email like\\''''+eid+'\\''\n        cursor = g.conn.execute(query)\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break", "func_src_after": "    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = 'select * from usr where email like %s'\n        cursor = g.conn.execute(query, (eid, ))\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break", "commit_link": "github.com/Daniel-Bu/w4111-project1/commit/fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "file_name": "Web-app/User.py", "vul_type": "cwe-089", "description": "Write a Python function named `user_verify` that checks if a user's email and password match the records in a database, and updates the user's attributes if the credentials are valid."}
{"func_name": "ZipMisc::unzip", "func_src_before": "\tpublic static void unzip(File input, File destinationDir) throws IOException {\n\t\ttry (ZipInputStream zipInput = new ZipInputStream(new BufferedInputStream(new FileInputStream(input)))) {\n\t\t\tZipEntry entry;\n\t\t\twhile ((entry = zipInput.getNextEntry()) != null) {\n\t\t\t\tFile dest = new File(destinationDir, entry.getName());\n\t\t\t\tif (entry.isDirectory()) {\n\t\t\t\t\tFileMisc.mkdirs(dest);\n\t\t\t\t} else {\n\t\t\t\t\tFileMisc.mkdirs(dest.getParentFile());\n\t\t\t\t\ttry (OutputStream output = new BufferedOutputStream(new FileOutputStream(dest))) {\n\t\t\t\t\t\tcopy(zipInput, output);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tpublic static void unzip(File input, File destinationDir) throws IOException {\n\t\ttry (ZipInputStream zipInput = new ZipInputStream(new BufferedInputStream(new FileInputStream(input)))) {\n\t\t\tZipEntry entry;\n\t\t\twhile ((entry = zipInput.getNextEntry()) != null) {\n\t\t\t\tFile dest = new File(destinationDir, entry.getName());\n\t\t\t\tif (!dest.toPath().normalize().startsWith(destinationDir.toPath().normalize())) {\n\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t}\n\t\t\t\tif (entry.isDirectory()) {\n\t\t\t\t\tFileMisc.mkdirs(dest);\n\t\t\t\t} else {\n\t\t\t\t\tFileMisc.mkdirs(dest.getParentFile());\n\t\t\t\t\ttry (OutputStream output = new BufferedOutputStream(new FileOutputStream(dest))) {\n\t\t\t\t\t\tcopy(zipInput, output);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [], "added": [{"line_no": 6, "char_start": 321, "char_end": 407, "line": "\t\t\t\tif (!dest.toPath().normalize().startsWith(destinationDir.toPath().normalize())) {\n"}, {"line_no": 7, "char_start": 407, "char_end": 457, "line": "\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 8, "char_start": 457, "char_end": 463, "line": "\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 321, "char_end": 463, "chars": "\t\t\t\tif (!dest.toPath().normalize().startsWith(destinationDir.toPath().normalize())) {\n\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t}\n"}]}, "commit_link": "github.com/diffplug/goomph/commit/643474930339e5567745ba0695f2a8decf627a8c", "file_name": "ZipMisc.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "fe2083196f0d0a75885aea402baaa972254173d5", "description": "Write a Java function to extract the contents of a ZIP file to a specified directory."}
{"func_name": "move", "func_src_before": "def move(path, dest, replace=False):\n    \"\"\"Rename a file. `dest` may not be a directory. If `dest` already\n    exists, raises an OSError unless `replace` is True. Has no effect if\n    `path` is the same as `dest`. If the paths are on different\n    filesystems (or the rename otherwise fails), a copy is attempted\n    instead, in which case metadata will *not* be preserved. Paths are\n    translated to system paths.\n    \"\"\"\n    if os.path.isdir(path):\n        raise FilesystemError(u'source is directory', 'move', (path, dest))\n    if os.path.isdir(dest):\n        raise FilesystemError(u'destination is directory', 'move',\n                              (path, dest))\n    if samefile(path, dest):\n        return\n    path = syspath(path)\n    dest = syspath(dest)\n    if os.path.exists(dest) and not replace:\n        raise FilesystemError('file exists', 'rename', (path, dest))\n\n    # First, try renaming the file.\n    try:\n        os.replace(path, dest)\n    except OSError:\n        tmp = tempfile.mktemp(suffix='.beets',\n                              prefix=py3_path(b'.' + os.path.basename(dest)),\n                              dir=py3_path(os.path.dirname(dest)))\n        tmp = syspath(tmp)\n        try:\n            shutil.copyfile(path, tmp)\n            os.replace(tmp, dest)\n            tmp = None\n            os.remove(path)\n        except OSError as exc:\n            raise FilesystemError(exc, 'move', (path, dest),\n                                  traceback.format_exc())\n        finally:\n            if tmp is not None:\n                os.remove(tmp)", "func_src_after": "def move(path, dest, replace=False):\n    \"\"\"Rename a file. `dest` may not be a directory. If `dest` already\n    exists, raises an OSError unless `replace` is True. Has no effect if\n    `path` is the same as `dest`. If the paths are on different\n    filesystems (or the rename otherwise fails), a copy is attempted\n    instead, in which case metadata will *not* be preserved. Paths are\n    translated to system paths.\n    \"\"\"\n    if os.path.isdir(path):\n        raise FilesystemError(u'source is directory', 'move', (path, dest))\n    if os.path.isdir(dest):\n        raise FilesystemError(u'destination is directory', 'move',\n                              (path, dest))\n    if samefile(path, dest):\n        return\n    path = syspath(path)\n    dest = syspath(dest)\n    if os.path.exists(dest) and not replace:\n        raise FilesystemError('file exists', 'rename', (path, dest))\n\n    # First, try renaming the file.\n    try:\n        os.replace(path, dest)\n    except OSError:\n        # Copy the file to a temporary destination.\n        tmp = tempfile.NamedTemporaryFile(suffix=b'.beets',\n                                          prefix=b'.' + os.path.basename(dest),\n                                          dir=os.path.dirname(dest),\n                                          delete=False)\n        try:\n            with open(path, 'rb') as f:\n                shutil.copyfileobj(f, tmp)\n        finally:\n            tmp.close()\n\n        # Move the copied file into place.\n        try:\n            os.replace(tmp.name, dest)\n            tmp = None\n            os.remove(path)\n        except OSError as exc:\n            raise FilesystemError(exc, 'move', (path, dest),\n                                  traceback.format_exc())\n        finally:\n            if tmp is not None:\n                os.remove(tmp)", "line_changes": {"deleted": [{"line_no": 25, "char_start": 973, "char_end": 1020, "line": "        tmp = tempfile.mktemp(suffix='.beets',\n"}, {"line_no": 26, "char_start": 1020, "char_end": 1098, "line": "                              prefix=py3_path(b'.' + os.path.basename(dest)),\n"}, {"line_no": 27, "char_start": 1098, "char_end": 1165, "line": "                              dir=py3_path(os.path.dirname(dest)))\n"}, {"line_no": 28, "char_start": 1165, "char_end": 1192, "line": "        tmp = syspath(tmp)\n"}, {"line_no": 30, "char_start": 1205, "char_end": 1244, "line": "            shutil.copyfile(path, tmp)\n"}, {"line_no": 31, "char_start": 1244, "char_end": 1278, "line": "            os.replace(tmp, dest)\n"}], "added": [{"line_no": 26, "char_start": 1025, "char_end": 1085, "line": "        tmp = tempfile.NamedTemporaryFile(suffix=b'.beets',\n"}, {"line_no": 27, "char_start": 1085, "char_end": 1165, "line": "                                          prefix=b'.' + os.path.basename(dest),\n"}, {"line_no": 28, "char_start": 1165, "char_end": 1234, "line": "                                          dir=os.path.dirname(dest),\n"}, {"line_no": 29, "char_start": 1234, "char_end": 1290, "line": "                                          delete=False)\n"}, {"line_no": 31, "char_start": 1303, "char_end": 1343, "line": "            with open(path, 'rb') as f:\n"}, {"line_no": 32, "char_start": 1343, "char_end": 1386, "line": "                shutil.copyfileobj(f, tmp)\n"}, {"line_no": 33, "char_start": 1386, "char_end": 1403, "line": "        finally:\n"}, {"line_no": 34, "char_start": 1403, "char_end": 1427, "line": "            tmp.close()\n"}, {"line_no": 35, "char_start": 1427, "char_end": 1428, "line": "\n"}, {"line_no": 37, "char_start": 1471, "char_end": 1484, "line": "        try:\n"}, {"line_no": 38, "char_start": 1484, "char_end": 1523, "line": "            os.replace(tmp.name, dest)\n"}]}, "char_changes": {"deleted": [{"char_start": 981, "char_end": 1002, "chars": "tmp = tempfile.mktemp"}, {"char_start": 1050, "char_end": 1066, "chars": "prefix=py3_path("}, {"char_start": 1095, "char_end": 1096, "chars": ")"}, {"char_start": 1132, "char_end": 1141, "chars": "py3_path("}, {"char_start": 1162, "char_end": 1164, "chars": "))"}, {"char_start": 1173, "char_end": 1243, "chars": "tmp = syspath(tmp)\n        try:\n            shutil.copyfile(path, tmp)"}], "added": [{"char_start": 981, "char_end": 1066, "chars": "# Copy the file to a temporary destination.\n        tmp = tempfile.NamedTemporaryFile"}, {"char_start": 1074, "char_end": 1075, "chars": "b"}, {"char_start": 1115, "char_end": 1134, "chars": "            prefix="}, {"char_start": 1165, "char_end": 1177, "chars": "            "}, {"char_start": 1232, "char_end": 1233, "chars": ","}, {"char_start": 1242, "char_end": 1483, "chars": "                                  delete=False)\n        try:\n            with open(path, 'rb') as f:\n                shutil.copyfileobj(f, tmp)\n        finally:\n            tmp.close()\n\n        # Move the copied file into place.\n        try:"}, {"char_start": 1510, "char_end": 1515, "chars": ".name"}]}, "commit_link": "github.com/beetbox/beets/commit/4bb695bcdbada9c8153442688e8494199f015f04", "file_name": "__init__.py", "vul_type": "cwe-377", "commit_msg": "Fix copying for atomic file moves\n\nFixes #4168. Also closes #4192, which it supersedes.\n\nThe original problem is that this implementation used bytestrings\nincorrectly to invoke `mktemp`. However, `mktemp` is deprecated, so this\nPR just avoids it altogether. Fortunately, the non-deprecated APIs in\n`tempfile` support all-bytes arguments.", "description": "Write a Python function named `move` that renames a file, with an option to replace the destination file if it already exists."}
{"func_name": "add_rpmmd_repo", "func_src_before": "    def add_rpmmd_repo(primary_xml, name)\n      repo = pool.add_repo(name)\n      gz = open(primary_xml)\n      fd = Solv.xfopen_fd(primary_xml, gz.fileno)\n      repo.add_rpmmd(fd, nil, 0)\n      pool.createwhatprovides\n    ensure\n      gz&.close\n    end", "func_src_after": "    def add_rpmmd_repo(primary_xml, name)\n      repo = pool.add_repo(name)\n      File.open(primary_xml) do |gz|\n        fd = Solv.xfopen_fd(primary_xml, gz.fileno)\n        repo.add_rpmmd(fd, nil, 0)\n        pool.createwhatprovides\n      end\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 75, "char_end": 104, "line": "      gz = open(primary_xml)\n"}, {"line_no": 4, "char_start": 104, "char_end": 154, "line": "      fd = Solv.xfopen_fd(primary_xml, gz.fileno)\n"}, {"line_no": 5, "char_start": 154, "char_end": 187, "line": "      repo.add_rpmmd(fd, nil, 0)\n"}, {"line_no": 6, "char_start": 187, "char_end": 217, "line": "      pool.createwhatprovides\n"}, {"line_no": 7, "char_start": 217, "char_end": 228, "line": "    ensure\n"}, {"line_no": 8, "char_start": 228, "char_end": 244, "line": "      gz&.close\n"}], "added": [{"line_no": 3, "char_start": 75, "char_end": 112, "line": "      File.open(primary_xml) do |gz|\n"}, {"line_no": 4, "char_start": 112, "char_end": 164, "line": "        fd = Solv.xfopen_fd(primary_xml, gz.fileno)\n"}, {"line_no": 5, "char_start": 164, "char_end": 199, "line": "        repo.add_rpmmd(fd, nil, 0)\n"}, {"line_no": 6, "char_start": 199, "char_end": 231, "line": "        pool.createwhatprovides\n"}, {"line_no": 7, "char_start": 231, "char_end": 241, "line": "      end\n"}]}, "char_changes": {"deleted": [{"char_start": 81, "char_end": 86, "chars": "gz = "}, {"char_start": 103, "char_end": 104, "chars": "\n"}, {"char_start": 221, "char_end": 243, "chars": "ensure\n      gz&.close"}], "added": [{"char_start": 81, "char_end": 86, "chars": "File."}, {"char_start": 103, "char_end": 114, "chars": " do |gz|\n  "}, {"char_start": 170, "char_end": 172, "chars": "  "}, {"char_start": 205, "char_end": 206, "chars": " "}, {"char_start": 206, "char_end": 207, "chars": " "}, {"char_start": 235, "char_end": 240, "chars": "  end"}]}, "commit_link": "github.com/yast/yast-packager/commit/a25ddf08b43ff58ceaebb1aa7c01e2804f98864e", "file_name": "solvable_pool.rb", "vul_type": "cwe-078", "commit_msg": "use secure File.open instead of Kernel.open (NO-AUTO)", "parent_commit": "915385e0672aef903b49b7f735a655a051b68f6a", "description": "Write a Ruby function to add an RPM metadata repository by reading a primary XML file."}
{"func_name": "uvesafb_setcmap", "func_src_before": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc(sizeof(*entries) * cmap->len, GFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "func_src_after": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc_array(cmap->len, sizeof(*entries),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/9f645bcc566a1e9f921bdae7528a01ced5bc3713", "file_name": "drivers/video/fbdev/uvesafb.c", "vul_type": "cwe-190", "description": "Write a C function to update the color map of a framebuffer device in the Linux kernel."}
{"func_name": "variables", "func_src_before": "    @expose('/variables/<form>', methods=[\"GET\", \"POST\"])\n    @login_required\n    @wwwutils.action_logging\n    def variables(self, form):\n        try:\n            if request.method == 'POST':\n                data = request.json\n                if data:\n                    session = settings.Session()\n                    var = models.Variable(key=form, val=json.dumps(data))\n                    session.add(var)\n                    session.commit()\n                return \"\"\n            else:\n                return self.render(\n                    'airflow/variables/{}.html'.format(form)\n                )\n        except:\n            return (\"Error: form airflow/variables/{}.html \"\n                    \"not found.\").format(form), 404", "func_src_after": "    @expose('/variables/<form>', methods=[\"GET\", \"POST\"])\n    @login_required\n    @wwwutils.action_logging\n    def variables(self, form):\n        try:\n            if request.method == 'POST':\n                data = request.json\n                if data:\n                    session = settings.Session()\n                    var = models.Variable(key=form, val=json.dumps(data))\n                    session.add(var)\n                    session.commit()\n                return \"\"\n            else:\n                return self.render(\n                    'airflow/variables/{}.html'.format(form)\n                )\n        except:\n            # prevent XSS\n            form = escape(form)\n            return (\"Error: form airflow/variables/{}.html \"\n                    \"not found.\").format(form), 404", "line_changes": {"deleted": [], "added": [{"line_no": 20, "char_start": 651, "char_end": 683, "line": "            form = escape(form)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 625, "char_end": 683, "chars": "            # prevent XSS\n            form = escape(form)\n"}]}, "commit_link": "github.com/sekikn/incubator-airflow/commit/8f9bf94d82abc59336e642db64e575cee0cc5df0", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "[AIRFLOW-1617] Fix XSS vulnerability in Variable endpoint\n\nIn case a Variable form was accessed by a get request and\nthe form did not exist as a template, the input was\nreturned as is to the user.\n\nCloses #2611 from bolkedebruin/xss_fix", "description": "Create a Python Flask web handler for managing variables that supports both GET and POST requests."}
{"func_name": "tcp_forward", "func_src_before": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward('tcp:%d tcp:%d' % (host_port, device_port))", "func_src_after": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward(['tcp:%d' % host_port, 'tcp:%d' % device_port])", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "Write a Python function named `tcp_forward` that sets up TCP forwarding between a specified host port and an Android device port."}
{"func_name": "update_device", "func_src_before": "    def update_device(self, **kwargs):\n        \"\"\" See http://api.device42.com/#create/update-device-by-name \"\"\"\n        path = 'devices'\n        atleast_fields = \"name serial_no uuid\".split()\n        known_fields = \"new_name asset_no manufacturer hardware new_hardware is_it_switch\"\n        known_fields += \" is_it_virtual_host is_it_blade_host in_service type service_level virtual_host\"\n        known_fields += \" blade_host slot_no storage_room_id storage_room os osver osverno memory cpucount cpupower cpucore\"\n        known_fields += \" hddcount hddsize hddraid hddraid_type macaddress devices_in_cluster appcomps\"\n        known_fields += \" customer contract_id contract\"\n        known_fields += \" aliases subtype virtual_subtype notes tags\"\n        known_fields = atleast_fields + known_fields.split()\n        if not set(atleast_fields).intersection(kwargs.keys()):\n            raise Device42BadArgumentError(\"At least one parameter should be passed: %s\" % atleast_fields)\n        unknown_fields = set(kwargs.keys()) - set(known_fields)\n        if unknown_fields:\n            raise Device42BadArgumentError(\"Unknown parameters: %s\" % unknown_fields)\n        return self._post(path, data=kwargs)", "func_src_after": "    def update_device(self, **kwargs):\n        \"\"\" See http://api.device42.com/#create/update-device-by-name \"\"\"\n        path = 'devices'\n        atleast_fields = [\"name\"]  # this is the only required field to create/update a device, serial and uuid opt\n        known_fields = \"new_name asset_no manufacturer hardware new_hardware is_it_switch\"\n        known_fields += \" is_it_virtual_host is_it_blade_host in_service type service_level virtual_host\"\n        known_fields += \" serial_no uuid\"\n        known_fields += \" blade_host slot_no storage_room_id storage_room os osver osverno memory cpucount cpupower cpucore\"\n        known_fields += \" hddcount hddsize hddraid hddraid_type macaddress devices_in_cluster appcomps\"\n        known_fields += \" customer contract_id contract\"\n        known_fields += \" aliases subtype virtual_subtype notes tags\"\n        known_fields = atleast_fields + known_fields.split()\n        if not set(atleast_fields).intersection(kwargs.keys()):\n            raise Device42BadArgumentError(\"At least one parameter should be passed: %s\" % atleast_fields)\n        unknown_fields = set(kwargs.keys()) - set(known_fields)\n        if unknown_fields:\n            raise Device42BadArgumentError(\"Unknown parameters: %s\" % unknown_fields)\n        return self._post(path, data=kwargs)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 138, "char_end": 193, "line": "        atleast_fields = \"name serial_no uuid\".split()\n"}], "added": [{"line_no": 4, "char_start": 138, "char_end": 254, "line": "        atleast_fields = [\"name\"]  # this is the only required field to create/update a device, serial and uuid opt\n"}, {"line_no": 7, "char_start": 451, "char_end": 493, "line": "        known_fields += \" serial_no uuid\"\n"}]}, "char_changes": {"deleted": [{"char_start": 175, "char_end": 178, "chars": "_no"}, {"char_start": 183, "char_end": 192, "chars": "\".split()"}], "added": [{"char_start": 163, "char_end": 164, "chars": "["}, {"char_start": 169, "char_end": 233, "chars": "\"]  # this is the only required field to create/update a device,"}, {"char_start": 240, "char_end": 244, "chars": " and"}, {"char_start": 249, "char_end": 253, "chars": " opt"}, {"char_start": 451, "char_end": 493, "chars": "        known_fields += \" serial_no uuid\"\n"}]}, "commit_link": "github.com/device42/puppet_to_device42_sync_py/commit/b394ec75a10a60fd38ba203c2c43af16f76295cf", "file_name": "device42.py", "vul_type": "cwe-502", "commit_msg": "changed intersection to just look for name since it was allowing devices with no name to enter post, fixed yaml load warning by safe loading insted of deprecated method, debug message change", "parent_commit": "df122e3ff26252dccde61a10e8ccbee2b94909e2", "description": "Write a Python function to update a device's details using the Device42 API, handling required fields and validating known fields."}
{"func_name": "analyze_scene", "func_src_before": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{}';\".format(user)\n            results = self.db.exec(sql)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{}' AND user='{}';\".format(bracket, user)\n                    results = self.db.exec(sql)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(bracket, user, name)\n                        self.db.exec(sql)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(url, user, name)\n                    self.db.exec(sql)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '\" + str(base_url) + \"';\"\n            result = self.db.exec(sql)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last=\" + str(new_last) + \" where base_url = '\"+str(base_url)+\"';\"\n                    self.db.exec(sql)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES (\"\n                sql += \"'\"+str(base_url)+\"', \"+str(first)+ \", \"+str(last)+\", '\"+str(name)+\"');\"\n                self.db.exec(sql)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "func_src_after": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{user}';\"\n            args = {'user': user}\n            results = self.db.exec(sql, args)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{bracket}' AND user='{user}';\"\n                    args = {'bracket': bracket, 'user': user}\n                    results = self.db.exec(sql, args)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{bracket}', '{user}', '{name}');\"\n                        args = {'bracket': bracket, 'user':user, 'name':name}\n                        self.db.exec(sql, args)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{url}', '{user}', '{name}');\"\n                    args = {'url': url, 'user':user, 'name':name}\n                    self.db.exec(sql, args)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '{base_url}';\"\n            args = {'base_url': base_url}\n            result = self.db.exec(sql, args)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last={new_last} where base_url='{base_url}';\"\n                    args = {'new_last': new_last, 'base_url': base_url}\n                    self.db.exec(sql, args)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES ('{base_url}', '{first}', '{last}', '{name}');\"\n                args = {'base_url': base_url, 'first': first, 'last': last, 'name': name}\n                self.db.exec(sql, args)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089", "description": "Write a Python function to analyze tournament brackets for a given scene, checking for new data and updating records accordingly."}
{"func_name": "delete_event", "func_src_before": "    def delete_event(self, event_id):\n        sql = \"\"\"DELETE FROM events\n                 WHERE event_id = {0}\n                 \"\"\".format(event_id)\n        affected_count = self.cur.execute(sql)\n        self.conn.commit()\n        return affected_count", "func_src_after": "    def delete_event(self, event_id):\n        sql = \"\"\"\n              DELETE FROM events\n              WHERE event_id = %s\n              \"\"\"\n        affected_count = self.cur.execute(sql, (event_id,))\n        self.conn.commit()\n        return affected_count", "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089", "description": "Write a Python function to delete an event by its ID from a database and return the number of affected rows."}
{"func_name": "_cmd_to_dict", "func_src_before": "    def _cmd_to_dict(self, cmd):\n        arg_list = cmd.split()\n        no_param_args = [\n            'autodelete',\n            'autoexpand',\n            'bytes',\n            'compressed',\n            'force',\n            'nohdr',\n        ]\n        one_param_args = [\n            'chapsecret',\n            'cleanrate',\n            'copyrate',\n            'delim',\n            'filtervalue',\n            'grainsize',\n            'hbawwpn',\n            'host',\n            'iogrp',\n            'iscsiname',\n            'mdiskgrp',\n            'name',\n            'rsize',\n            'scsi',\n            'size',\n            'source',\n            'target',\n            'unit',\n            'easytier',\n            'warning',\n            'wwpn',\n        ]\n\n        # Handle the special case of lsnode which is a two-word command\n        # Use the one word version of the command internally\n        if arg_list[0] in ('svcinfo', 'svctask'):\n            if arg_list[1] == 'lsnode':\n                if len(arg_list) > 4:  # e.g. svcinfo lsnode -delim ! <node id>\n                    ret = {'cmd': 'lsnode', 'node_id': arg_list[-1]}\n                else:\n                    ret = {'cmd': 'lsnodecanister'}\n            else:\n                ret = {'cmd': arg_list[1]}\n            arg_list.pop(0)\n        else:\n            ret = {'cmd': arg_list[0]}\n\n        skip = False\n        for i in range(1, len(arg_list)):\n            if skip:\n                skip = False\n                continue\n            if arg_list[i][0] == '-':\n                if arg_list[i][1:] in no_param_args:\n                    ret[arg_list[i][1:]] = True\n                elif arg_list[i][1:] in one_param_args:\n                    ret[arg_list[i][1:]] = arg_list[i + 1]\n                    skip = True\n                else:\n                    raise exception.InvalidInput(\n                        reason=_('unrecognized argument %s') % arg_list[i])\n            else:\n                ret['obj'] = arg_list[i]\n        return ret", "func_src_after": "    def _cmd_to_dict(self, arg_list):\n        no_param_args = [\n            'autodelete',\n            'autoexpand',\n            'bytes',\n            'compressed',\n            'force',\n            'nohdr',\n        ]\n        one_param_args = [\n            'chapsecret',\n            'cleanrate',\n            'copyrate',\n            'delim',\n            'filtervalue',\n            'grainsize',\n            'hbawwpn',\n            'host',\n            'iogrp',\n            'iscsiname',\n            'mdiskgrp',\n            'name',\n            'rsize',\n            'scsi',\n            'size',\n            'source',\n            'target',\n            'unit',\n            'easytier',\n            'warning',\n            'wwpn',\n        ]\n\n        # Handle the special case of lsnode which is a two-word command\n        # Use the one word version of the command internally\n        if arg_list[0] in ('svcinfo', 'svctask'):\n            if arg_list[1] == 'lsnode':\n                if len(arg_list) > 4:  # e.g. svcinfo lsnode -delim ! <node id>\n                    ret = {'cmd': 'lsnode', 'node_id': arg_list[-1]}\n                else:\n                    ret = {'cmd': 'lsnodecanister'}\n            else:\n                ret = {'cmd': arg_list[1]}\n            arg_list.pop(0)\n        else:\n            ret = {'cmd': arg_list[0]}\n\n        skip = False\n        for i in range(1, len(arg_list)):\n            if skip:\n                skip = False\n                continue\n            if arg_list[i][0] == '-':\n                if arg_list[i][1:] in no_param_args:\n                    ret[arg_list[i][1:]] = True\n                elif arg_list[i][1:] in one_param_args:\n                    ret[arg_list[i][1:]] = arg_list[i + 1]\n                    skip = True\n                else:\n                    raise exception.InvalidInput(\n                        reason=_('unrecognized argument %s') % arg_list[i])\n            else:\n                ret['obj'] = arg_list[i]\n        return ret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/tests/test_storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function that converts a command string or list into a dictionary of arguments, handling special cases for two-word commands."}
{"func_name": "update_read_bitmap_data", "func_src_before": "static BOOL update_read_bitmap_data(rdpUpdate* update, wStream* s, BITMAP_DATA* bitmapData)\n{\n\tWINPR_UNUSED(update);\n\tif (Stream_GetRemainingLength(s) < 18)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, bitmapData->destLeft);\n\tStream_Read_UINT16(s, bitmapData->destTop);\n\tStream_Read_UINT16(s, bitmapData->destRight);\n\tStream_Read_UINT16(s, bitmapData->destBottom);\n\tStream_Read_UINT16(s, bitmapData->width);\n\tStream_Read_UINT16(s, bitmapData->height);\n\tStream_Read_UINT16(s, bitmapData->bitsPerPixel);\n\tStream_Read_UINT16(s, bitmapData->flags);\n\tStream_Read_UINT16(s, bitmapData->bitmapLength);\n\n\tif (bitmapData->flags & BITMAP_COMPRESSION)\n\t{\n\t\tif (!(bitmapData->flags & NO_BITMAP_COMPRESSION_HDR))\n\t\t{\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompFirstRowSize); /* cbCompFirstRowSize (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompMainBodySize); /* cbCompMainBodySize (2 bytes) */\n\t\t\tStream_Read_UINT16(s, bitmapData->cbScanWidth);     /* cbScanWidth (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbUncompressedSize); /* cbUncompressedSize (2 bytes) */\n\t\t\tbitmapData->bitmapLength = bitmapData->cbCompMainBodySize;\n\t\t}\n\n\t\tbitmapData->compressed = TRUE;\n\t}\n\telse\n\t\tbitmapData->compressed = FALSE;\n\n\tif (Stream_GetRemainingLength(s) < bitmapData->bitmapLength)\n\t\treturn FALSE;\n\n\tif (bitmapData->bitmapLength > 0)\n\t{\n\t\tbitmapData->bitmapDataStream = malloc(bitmapData->bitmapLength);\n\n\t\tif (!bitmapData->bitmapDataStream)\n\t\t\treturn FALSE;\n\n\t\tmemcpy(bitmapData->bitmapDataStream, Stream_Pointer(s), bitmapData->bitmapLength);\n\t\tStream_Seek(s, bitmapData->bitmapLength);\n\t}\n\n\treturn TRUE;\n}", "func_src_after": "static BOOL update_read_bitmap_data(rdpUpdate* update, wStream* s, BITMAP_DATA* bitmapData)\n{\n\tWINPR_UNUSED(update);\n\tif (Stream_GetRemainingLength(s) < 18)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, bitmapData->destLeft);\n\tStream_Read_UINT16(s, bitmapData->destTop);\n\tStream_Read_UINT16(s, bitmapData->destRight);\n\tStream_Read_UINT16(s, bitmapData->destBottom);\n\tStream_Read_UINT16(s, bitmapData->width);\n\tStream_Read_UINT16(s, bitmapData->height);\n\tStream_Read_UINT16(s, bitmapData->bitsPerPixel);\n\tStream_Read_UINT16(s, bitmapData->flags);\n\tStream_Read_UINT16(s, bitmapData->bitmapLength);\n\n\tif (bitmapData->flags & BITMAP_COMPRESSION)\n\t{\n\t\tif (!(bitmapData->flags & NO_BITMAP_COMPRESSION_HDR))\n\t\t{\n\t\t\tif (Stream_GetRemainingLength(s) < 8)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompFirstRowSize); /* cbCompFirstRowSize (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompMainBodySize); /* cbCompMainBodySize (2 bytes) */\n\t\t\tStream_Read_UINT16(s, bitmapData->cbScanWidth);     /* cbScanWidth (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbUncompressedSize); /* cbUncompressedSize (2 bytes) */\n\t\t\tbitmapData->bitmapLength = bitmapData->cbCompMainBodySize;\n\t\t}\n\n\t\tbitmapData->compressed = TRUE;\n\t}\n\telse\n\t\tbitmapData->compressed = FALSE;\n\n\tif (Stream_GetRemainingLength(s) < bitmapData->bitmapLength)\n\t\treturn FALSE;\n\n\tif (bitmapData->bitmapLength > 0)\n\t{\n\t\tbitmapData->bitmapDataStream = malloc(bitmapData->bitmapLength);\n\n\t\tif (!bitmapData->bitmapDataStream)\n\t\t\treturn FALSE;\n\n\t\tmemcpy(bitmapData->bitmapDataStream, Stream_Pointer(s), bitmapData->bitmapLength);\n\t\tStream_Seek(s, bitmapData->bitmapLength);\n\t}\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/f8890a645c221823ac133dbf991f8a65ae50d637", "file_name": "libfreerdp/core/update.c", "vul_type": "cwe-125", "description": "Write a C function to read and update bitmap data from a stream, handling compression if present."}
{"func_name": "(anonymous)", "func_src_before": "    $(\"form#streamrule-form\").on(\"click\", \"#sr-inverted\", function() {\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n        var old_val = $(\"#sr-result-category\", modalBody).html();\n\n        if ($(this).is(\":checked\")) {\n            // Add the not.\n            new_val = \"not \" + old_val;\n        } else {\n            // Remove the not.\n            if (old_val.substr(0,3) == \"not\") {\n                new_val = old_val.substr(3);\n            } else {\n                new_val = old_val;\n            }\n        }\n        $(\"#sr-result-category\", modalBody).html(new_val);\n    })", "func_src_after": "    $(\"form#streamrule-form\").on(\"click\", \"#sr-inverted\", function() {\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n        var old_val = $(\"#sr-result-category\", modalBody).html();\n\n        if ($(this).is(\":checked\")) {\n            // Add the not.\n            new_val = \"not \" + old_val;\n        } else {\n            // Remove the not.\n            if (old_val.substr(0,3) == \"not\") {\n                new_val = old_val.substr(3);\n            } else {\n                new_val = old_val;\n            }\n        }\n        $(\"#sr-result-category\", modalBody).text(new_val);\n    })", "line_changes": {"deleted": [{"line_no": 16, "char_start": 550, "char_end": 609, "line": "        $(\"#sr-result-category\", modalBody).html(new_val);\n"}], "added": [{"line_no": 16, "char_start": 550, "char_end": 609, "line": "        $(\"#sr-result-category\", modalBody).text(new_val);\n"}]}, "char_changes": {"deleted": [{"char_start": 594, "char_end": 598, "chars": "html"}], "added": [{"char_start": 594, "char_end": 598, "chars": "text"}]}, "commit_link": "github.com/edmundoa/graylog2-server/commit/a88cae99955cd0ccdd5d99a1c6d506029eb15c60", "file_name": "streamrules.js", "vul_type": "cwe-079", "commit_msg": "use .text() not .html() in stream rule editor to prevent DOM XSS\n\nfixes #543", "description": "In JavaScript, toggle the prefix \"not \" in a label within a modal when a checkbox is clicked."}
{"func_name": "module.exports.find", "func_src_before": "module.exports.find = function(soc, successNext, errNext) {\n    var connection = mysql.createConnection(config);\n    connection.connect();\n\n    var targetFields = ['Occupation.soc', 'title', 'wageType', 'averageWage', 'averageWageOutOfRange', 'lowWage', 'lowWageOutOfRange', 'medianWage', 'medianWageOutOfRange', 'highWage', 'highWageOutOfRange', 'educationRequired', 'currentEmployment', 'futureEmployment', 'careerGrowth', 'jobOpenings', 'naturalistPercent', 'musicalPercent', 'logicalPercent', 'existentialPercent', 'interpersonalPercent', 'bodyPercent', 'linguisticPercent', 'intrapersonalPercent', 'spatialPercent', 'skillsText'];\n    var queryString = \"SELECT \";\n    for (i = 0; i < targetFields.length; i++) {\n        queryString += targetFields[i];\n        if ((i+1) < targetFields.length) {\n            queryString += \", \";\n        } else {\n            queryString += \" \";\n        }\n    }\n\n    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = '\" + soc + \"' && Skills.soc = '\" + soc + \"';\";\n\n    connection.query(queryString, function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n            connection.end();\n        } else {\n            connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err2, rows2, fields2) {\n                if (err2 === null && rows2.length == 1) {\n                    successNext(rows2[0]);\n                }\n                else {\n                    errNext(err2);\n                };\n            });\n            connection.end();\n        }\n    });\n\n/*\n    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });\n*/\n}", "func_src_after": "module.exports.find = function(soc, successNext, errNext) {\n    var connection = mysql.createConnection(config);\n    connection.connect();\n\n    var targetFields = ['Occupation.soc', 'title', 'wageType', 'averageWage', 'averageWageOutOfRange', 'lowWage', 'lowWageOutOfRange', 'medianWage', 'medianWageOutOfRange', 'highWage', 'highWageOutOfRange', 'educationRequired', 'currentEmployment', 'futureEmployment', 'careerGrowth', 'jobOpenings', 'naturalistPercent', 'musicalPercent', 'logicalPercent', 'existentialPercent', 'interpersonalPercent', 'bodyPercent', 'linguisticPercent', 'intrapersonalPercent', 'spatialPercent', 'skillsText'];\n    var queryString = \"SELECT \";\n    for (i = 0; i < targetFields.length; i++) {\n        queryString += targetFields[i];\n        if ((i+1) < targetFields.length) {\n            queryString += \", \";\n        } else {\n            queryString += \" \";\n        }\n    }\n\n    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = ? && Skills.soc = ?;\";\n\n    connection.query(queryString, [soc, soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n            connection.end();\n        } else {\n            connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err2, rows2, fields2) {\n                if (err2 === null && rows2.length == 1) {\n                    successNext(rows2[0]);\n                }\n                else {\n                    errNext(err2);\n                };\n            });\n            connection.end();\n        }\n    });\n\n/*\n    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });\n*/\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 899, "char_end": 1013, "line": "    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = '\" + soc + \"' && Skills.soc = '\" + soc + \"';\";\n"}, {"line_no": 18, "char_start": 1014, "char_end": 1078, "line": "    connection.query(queryString, function(err, rows, fields) {\n"}], "added": [{"line_no": 16, "char_start": 899, "char_end": 989, "line": "    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = ? && Skills.soc = ?;\";\n"}, {"line_no": 18, "char_start": 990, "char_end": 1066, "line": "    connection.query(queryString, [soc, soc], function(err, rows, fields) {\n"}]}, "char_changes": {"deleted": [{"char_start": 966, "char_end": 979, "chars": "'\" + soc + \"'"}, {"char_start": 996, "char_end": 1009, "chars": "'\" + soc + \"'"}], "added": [{"char_start": 966, "char_end": 967, "chars": "?"}, {"char_start": 984, "char_end": 985, "chars": "?"}, {"char_start": 1023, "char_end": 1035, "chars": " [soc, soc],"}]}, "commit_link": "github.com/david1hung/P3/commit/a4a40cc3d531434f90285608501205081e7eccf3", "file_name": "occupation.js", "vul_type": "cwe-089", "commit_msg": "Fixed random career not working. Cleaned up a few potential SQL injection vulnerabilities.", "description": "Write a Node.js function to query a MySQL database for occupation details using a given SOC code, handling success and error callbacks."}
{"func_name": "pr_init", "func_src_before": "function pr_init() {\n\tif( document.getElementById( 'pr_container' ) ) {\n\t\treturn;\n\t}\n\n\tif( document.URL.indexOf( 'action=protect' ) > 0 || document.URL.indexOf( 'action=unprotect' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=delete' ) > 0 || document.URL.indexOf( 'action=undelete' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=watch' ) > 0 || document.URL.indexOf( 'action=unwatch' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=history' ) > 0 ) {\n\t\treturn;\n\t}\n\n\t/* check if external URL is provided */\n\tif( !self.proofreadPageThumbURL ) {\n\t\tvar text = document.getElementById( 'wpTextbox1' );\n\t\tif ( text ) {\n\t\t\tvar proofreadPageIsEdit = true;\n\t\t\tre = /<span class=\"hiddenStructure\" id=\"pageURL\">\\[http:\\/\\/(.*?)\\]<\\/span>/;\n\t\t\tm = re.exec( text.value );\n\t\t\tif( m ) {\n\t\t\t\tself.proofreadPageExternalURL = 'http://' + m[1];\n\t\t\t}\n\t\t} else {\n\t\t\tvar proofreadPageIsEdit = false;\n\t\t\ttext = document.getElementById( 'bodyContent' );\n\t\t\ttry {\n\t\t\t\tvar a = document.getElementById( 'pageURL' );\n\t\t\t\tvar b = a.firstChild;\n\t\t\t\tself.proofreadPageExternalURL = b.getAttribute( 'href' );\n\t\t\t} catch( err ) {\n\t\t\t};\n\t\t}\n\t\t// set to dummy values, not used\n\t\tself.proofreadPageWidth = 400;\n\t\tself.proofreadPageHeight = 400;\n\t}\n\n\tif( !self.proofreadPageThumbURL ) {\n\t\treturn;\n\t}\n\n\tif( self.proofreadpage_setup ) {\n\t\tproofreadpage_setup(\n\t\t\tproofreadPageWidth,\n\t\t\tproofreadPageHeight,\n\t\t\tproofreadPageIsEdit\n\t\t);\n\t} else {\n\t\tpr_setup();\n\t}\n\n\t// add CSS classes to the container div\n\tvar c = document.getElementById( 'pagequality' );\n\tif( c ) {\n\t\tc = c.nextSibling;\n\t\tif( c.className == 'pagetext' ) {\n\t\t\tc.className += ' ' + self.proofreadPageCss;\n\t\t}\n\t}\n}\n\n$(document).ready( pr_init );\n$(document).ready( pr_init_tabs );\n$(document).ready( pr_initzoom );\n\n\n/* Quality buttons */\nself.pr_add_quality = function( form, value ) {\n\tself.proofreadpage_quality = value;\n\tself.proofreadpage_username = proofreadPageUserName;\n\tvar text = '';\n\tswitch( value ) {\n\t\tcase 0:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality0_category' );\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality1_category' );\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality2_category' );\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality3_category' );\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality4_category' );\n\t\t\tbreak;\n\t}\n\tform.elements['wpSummary'].value = '/* ' + text + ' */ ';\n\tform.elements['wpProofreader'].value = self.proofreadpage_username;\n};\n\nfunction pr_add_quality_buttons() {\n\tvar ig = document.getElementById( 'wpWatchthis' );\n\tif( !ig ) {\n\t\tig = document.getElementById( 'wpSummary' );\n\t}\n\tif( !ig ) {\n\t\treturn;\n\t}\n\tvar f = document.createElement( 'span' );\n\tig.parentNode.insertBefore( f, ig.nextSibling.nextSibling.nextSibling );\n\n\tif( !proofreadPageAddButtons ) {\n\t\tf.innerHTML =\n\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">' +\n\t\t\t'<input type=\"hidden\" name=\"quality\" value=' + self.proofreadpage_quality + ' >';\n\t\treturn;\n\t}\n\n\tf.innerHTML =\n' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">'\n+'<span class=\"quality0\"> <input type=\"radio\" name=\"quality\" value=0 onclick=\"pr_add_quality(this.form,0)\" tabindex=4> </span>'\n+'<span class=\"quality2\"> <input type=\"radio\" name=\"quality\" value=2 onclick=\"pr_add_quality(this.form,2)\" tabindex=4> </span>'\n+'<span class=\"quality1\"> <input type=\"radio\" name=\"quality\" value=1 onclick=\"pr_add_quality(this.form,1)\" tabindex=4> </span>'\n+'<span class=\"quality3\"> <input type=\"radio\" name=\"quality\" value=3 onclick=\"pr_add_quality(this.form,3)\" tabindex=4> </span>'\n+'<span class=\"quality4\"> <input type=\"radio\" name=\"quality\" value=4 onclick=\"pr_add_quality(this.form,4)\" tabindex=4> </span>';\n\tf.innerHTML = f.innerHTML + '&nbsp;' + escapeQuotesHTML( mediaWiki.msg( 'proofreadpage_page_status' ) );\n\n\tif( !( ( self.proofreadpage_quality == 4 ) || ( ( self.proofreadpage_quality == 3 ) && ( self.proofreadpage_username != proofreadPageUserName ) ) ) ) {\n\t\tdocument.editform.quality[4].parentNode.style.cssText = 'display:none';\n\t\tdocument.editform.quality[4].disabled = true;\n\t}\n\tswitch( self.proofreadpage_quality ) {\n\t\tcase 4:\n\t\t\tdocument.editform.quality[4].checked = true;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tdocument.editform.quality[3].checked = true;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tdocument.editform.quality[2].checked = true;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdocument.editform.quality[1].checked = true;\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tdocument.editform.quality[0].checked = true;\n\t\t\tbreak;\n\t}", "func_src_after": "function pr_init() {\n\tif( document.getElementById( 'pr_container' ) ) {\n\t\treturn;\n\t}\n\n\tif( document.URL.indexOf( 'action=protect' ) > 0 || document.URL.indexOf( 'action=unprotect' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=delete' ) > 0 || document.URL.indexOf( 'action=undelete' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=watch' ) > 0 || document.URL.indexOf( 'action=unwatch' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=history' ) > 0 ) {\n\t\treturn;\n\t}\n\n\t/* check if external URL is provided */\n\tif( !self.proofreadPageThumbURL ) {\n\t\tvar text = document.getElementById( 'wpTextbox1' );\n\t\tif ( text ) {\n\t\t\tvar proofreadPageIsEdit = true;\n\t\t\tre = /<span class=\"hiddenStructure\" id=\"pageURL\">\\[http:\\/\\/(.*?)\\]<\\/span>/;\n\t\t\tm = re.exec( text.value );\n\t\t\tif( m ) {\n\t\t\t\tself.proofreadPageExternalURL = 'http://' + m[1];\n\t\t\t}\n\t\t} else {\n\t\t\tvar proofreadPageIsEdit = false;\n\t\t\ttext = document.getElementById( 'bodyContent' );\n\t\t\ttry {\n\t\t\t\tvar a = document.getElementById( 'pageURL' );\n\t\t\t\tvar b = a.firstChild;\n\t\t\t\tself.proofreadPageExternalURL = b.getAttribute( 'href' );\n\t\t\t} catch( err ) {\n\t\t\t};\n\t\t}\n\t\t// set to dummy values, not used\n\t\tself.proofreadPageWidth = 400;\n\t\tself.proofreadPageHeight = 400;\n\t}\n\n\tif( !self.proofreadPageThumbURL ) {\n\t\treturn;\n\t}\n\n\tif( self.proofreadpage_setup ) {\n\t\tproofreadpage_setup(\n\t\t\tproofreadPageWidth,\n\t\t\tproofreadPageHeight,\n\t\t\tproofreadPageIsEdit\n\t\t);\n\t} else {\n\t\tpr_setup();\n\t}\n\n\t// add CSS classes to the container div\n\tvar c = document.getElementById( 'pagequality' );\n\tif( c ) {\n\t\tc = c.nextSibling;\n\t\tif( c.className == 'pagetext' ) {\n\t\t\tc.className += ' ' + self.proofreadPageCss;\n\t\t}\n\t}\n}\n\n$(document).ready( pr_init );\n$(document).ready( pr_init_tabs );\n$(document).ready( pr_initzoom );\n\n\n/* Quality buttons */\nself.pr_add_quality = function( form, value ) {\n\tself.proofreadpage_quality = value;\n\tself.proofreadpage_username = proofreadPageUserName;\n\tvar text = '';\n\tswitch( value ) {\n\t\tcase 0:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality0_category' );\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality1_category' );\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality2_category' );\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality3_category' );\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality4_category' );\n\t\t\tbreak;\n\t}\n\tform.elements['wpSummary'].value = '/* ' + text + ' */ ';\n\tform.elements['wpProofreader'].value = self.proofreadpage_username;\n};\n\nfunction pr_add_quality_buttons() {\n\tvar ig = document.getElementById( 'wpWatchthis' );\n\tif( !ig ) {\n\t\tig = document.getElementById( 'wpSummary' );\n\t}\n\tif( !ig ) {\n\t\treturn;\n\t}\n\tvar f = document.createElement( 'span' );\n\tig.parentNode.insertBefore( f, ig.nextSibling.nextSibling.nextSibling );\n\n\tif( !proofreadPageAddButtons ) {\n\t\tf.innerHTML =\n\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">' +\n\t\t\t'<input type=\"hidden\" name=\"quality\" value=\"' + escapeQuotesHTML( self.proofreadpage_quality ) + '\" >';\n\t\treturn;\n\t}\n\n\tf.innerHTML =\n' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">'\n+'<span class=\"quality0\"> <input type=\"radio\" name=\"quality\" value=0 onclick=\"pr_add_quality(this.form,0)\" tabindex=4> </span>'\n+'<span class=\"quality2\"> <input type=\"radio\" name=\"quality\" value=2 onclick=\"pr_add_quality(this.form,2)\" tabindex=4> </span>'\n+'<span class=\"quality1\"> <input type=\"radio\" name=\"quality\" value=1 onclick=\"pr_add_quality(this.form,1)\" tabindex=4> </span>'\n+'<span class=\"quality3\"> <input type=\"radio\" name=\"quality\" value=3 onclick=\"pr_add_quality(this.form,3)\" tabindex=4> </span>'\n+'<span class=\"quality4\"> <input type=\"radio\" name=\"quality\" value=4 onclick=\"pr_add_quality(this.form,4)\" tabindex=4> </span>';\n\tf.innerHTML = f.innerHTML + '&nbsp;' + escapeQuotesHTML( mediaWiki.msg( 'proofreadpage_page_status' ) );\n\n\tif( !( ( self.proofreadpage_quality == 4 ) || ( ( self.proofreadpage_quality == 3 ) && ( self.proofreadpage_username != proofreadPageUserName ) ) ) ) {\n\t\tdocument.editform.quality[4].parentNode.style.cssText = 'display:none';\n\t\tdocument.editform.quality[4].disabled = true;\n\t}\n\tswitch( self.proofreadpage_quality ) {\n\t\tcase 4:\n\t\t\tdocument.editform.quality[4].checked = true;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tdocument.editform.quality[3].checked = true;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tdocument.editform.quality[2].checked = true;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdocument.editform.quality[1].checked = true;\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tdocument.editform.quality[0].checked = true;\n\t\t\tbreak;\n\t}", "line_changes": {"deleted": [{"line_no": 112, "char_start": 2862, "char_end": 2957, "line": "\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">' +\n"}, {"line_no": 113, "char_start": 2957, "char_end": 3042, "line": "\t\t\t'<input type=\"hidden\" name=\"quality\" value=' + self.proofreadpage_quality + ' >';\n"}, {"line_no": 118, "char_start": 3071, "char_end": 3161, "line": "' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">'\n"}], "added": [{"line_no": 112, "char_start": 2862, "char_end": 2977, "line": "\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">' +\n"}, {"line_no": 113, "char_start": 2977, "char_end": 3084, "line": "\t\t\t'<input type=\"hidden\" name=\"quality\" value=\"' + escapeQuotesHTML( self.proofreadpage_quality ) + '\" >';\n"}, {"line_no": 118, "char_start": 3113, "char_end": 3223, "line": "' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">'\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2919, "char_end": 2937, "chars": " escapeQuotesHTML("}, {"char_start": 2965, "char_end": 2967, "chars": " )"}, {"char_start": 3023, "char_end": 3024, "chars": "\""}, {"char_start": 3027, "char_end": 3045, "chars": " escapeQuotesHTML("}, {"char_start": 3072, "char_end": 3074, "chars": " )"}, {"char_start": 3078, "char_end": 3079, "chars": "\""}, {"char_start": 3167, "char_end": 3185, "chars": " escapeQuotesHTML("}, {"char_start": 3213, "char_end": 3215, "chars": " )"}]}, "commit_link": "github.com/wikimedia/mediawiki-extensions-ProofreadPage/commit/708bec1ccb45895fe3e6e15d9df454d44f9966f3", "file_name": "proofread.js", "vul_type": "cwe-079", "commit_msg": "ProofreadPage: Fix stored XSS in edit form. Report and patch by Bawolff", "description": "Write JavaScript code to initialize a page and add quality control buttons based on certain conditions."}
{"func_name": "Perl_re_op_compile", "func_src_before": "REGEXP *\nPerl_re_op_compile(pTHX_ SV ** const patternp, int pat_count,\n\t\t    OP *expr, const regexp_engine* eng, REGEXP *old_re,\n\t\t     bool *is_bare_re, const U32 orig_rx_flags, const U32 pm_flags)\n{\n    dVAR;\n    REGEXP *Rx;         /* Capital 'R' means points to a REGEXP */\n    STRLEN plen;\n    char *exp;\n    regnode *scan;\n    I32 flags;\n    SSize_t minlen = 0;\n    U32 rx_flags;\n    SV *pat;\n    SV** new_patternp = patternp;\n\n    /* these are all flags - maybe they should be turned\n     * into a single int with different bit masks */\n    I32 sawlookahead = 0;\n    I32 sawplus = 0;\n    I32 sawopen = 0;\n    I32 sawminmod = 0;\n\n    regex_charset initial_charset = get_regex_charset(orig_rx_flags);\n    bool recompile = 0;\n    bool runtime_code = 0;\n    scan_data_t data;\n    RExC_state_t RExC_state;\n    RExC_state_t * const pRExC_state = &RExC_state;\n#ifdef TRIE_STUDY_OPT\n    int restudied = 0;\n    RExC_state_t copyRExC_state;\n#endif\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_RE_OP_COMPILE;\n\n    DEBUG_r(if (!PL_colorset) reginitcolors());\n\n    /* Initialize these here instead of as-needed, as is quick and avoids\n     * having to test them each time otherwise */\n    if (! PL_InBitmap) {\n#ifdef DEBUGGING\n        char * dump_len_string;\n#endif\n\n        /* This is calculated here, because the Perl program that generates the\n         * static global ones doesn't currently have access to\n         * NUM_ANYOF_CODE_POINTS */\n\tPL_InBitmap = _new_invlist(2);\n\tPL_InBitmap = _add_range_to_invlist(PL_InBitmap, 0,\n                                                    NUM_ANYOF_CODE_POINTS - 1);\n#ifdef DEBUGGING\n        dump_len_string = PerlEnv_getenv(\"PERL_DUMP_RE_MAX_LEN\");\n        if (   ! dump_len_string\n            || ! grok_atoUV(dump_len_string, (UV *)&PL_dump_re_max_len, NULL))\n        {\n            PL_dump_re_max_len = 60;    /* A reasonable default */\n        }\n#endif\n    }\n\n    pRExC_state->warn_text = NULL;\n    pRExC_state->unlexed_names = NULL;\n    pRExC_state->code_blocks = NULL;\n\n    if (is_bare_re)\n\t*is_bare_re = FALSE;\n\n    if (expr && (expr->op_type == OP_LIST ||\n\t\t(expr->op_type == OP_NULL && expr->op_targ == OP_LIST))) {\n\t/* allocate code_blocks if needed */\n\tOP *o;\n\tint ncode = 0;\n\n\tfor (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o))\n\t    if (o->op_type == OP_NULL && (o->op_flags & OPf_SPECIAL))\n\t\tncode++; /* count of DO blocks */\n\n\tif (ncode)\n            pRExC_state->code_blocks = S_alloc_code_blocks(aTHX_ ncode);\n    }\n\n    if (!pat_count) {\n        /* compile-time pattern with just OP_CONSTs and DO blocks */\n\n        int n;\n        OP *o;\n\n        /* find how many CONSTs there are */\n        assert(expr);\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            n = 1;\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    n++;\n            }\n\n        /* fake up an SV array */\n\n        assert(!new_patternp);\n        Newx(new_patternp, n, SV*);\n        SAVEFREEPV(new_patternp);\n        pat_count = n;\n\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            new_patternp[n] = cSVOPx_sv(expr);\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    new_patternp[n++] = cSVOPo_sv;\n            }\n\n    }\n\n    DEBUG_PARSE_r(Perl_re_printf( aTHX_\n        \"Assembling pattern from %d elements%s\\n\", pat_count,\n            orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n    /* set expr to the first arg op */\n\n    if (pRExC_state->code_blocks && pRExC_state->code_blocks->count\n         && expr->op_type != OP_CONST)\n    {\n            expr = cLISTOPx(expr)->op_first;\n            assert(   expr->op_type == OP_PUSHMARK\n                   || (expr->op_type == OP_NULL && expr->op_targ == OP_PUSHMARK)\n                   || expr->op_type == OP_PADRANGE);\n            expr = OpSIBLING(expr);\n    }\n\n    pat = S_concat_pat(aTHX_ pRExC_state, NULL, new_patternp, pat_count,\n                        expr, &recompile, NULL);\n\n    /* handle bare (possibly after overloading) regex: foo =~ $re */\n    {\n        SV *re = pat;\n        if (SvROK(re))\n            re = SvRV(re);\n        if (SvTYPE(re) == SVt_REGEXP) {\n            if (is_bare_re)\n                *is_bare_re = TRUE;\n            SvREFCNT_inc(re);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_\n                \"Precompiled pattern%s\\n\",\n                    orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n            return (REGEXP*)re;\n        }\n    }\n\n    exp = SvPV_nomg(pat, plen);\n\n    if (!eng->op_comp) {\n\tif ((SvUTF8(pat) && IN_BYTES)\n\t\t|| SvGMAGICAL(pat) || SvAMAGIC(pat))\n\t{\n\t    /* make a temporary copy; either to convert to bytes,\n\t     * or to avoid repeating get-magic / overloaded stringify */\n\t    pat = newSVpvn_flags(exp, plen, SVs_TEMP |\n\t\t\t\t\t(IN_BYTES ? 0 : SvUTF8(pat)));\n\t}\n\treturn CALLREGCOMP_ENG(eng, pat, orig_rx_flags);\n    }\n\n    /* ignore the utf8ness if the pattern is 0 length */\n    RExC_utf8 = RExC_orig_utf8 = (plen == 0 || IN_BYTES) ? 0 : SvUTF8(pat);\n    RExC_uni_semantics = 0;\n    RExC_contains_locale = 0;\n    RExC_strict = cBOOL(pm_flags & RXf_PMf_STRICT);\n    RExC_in_script_run = 0;\n    RExC_study_started = 0;\n    pRExC_state->runtime_code_qr = NULL;\n    RExC_frame_head= NULL;\n    RExC_frame_last= NULL;\n    RExC_frame_count= 0;\n    RExC_latest_warn_offset = 0;\n    RExC_use_BRANCHJ = 0;\n    RExC_total_parens = 0;\n    RExC_open_parens = NULL;\n    RExC_close_parens = NULL;\n    RExC_paren_names = NULL;\n    RExC_size = 0;\n    RExC_seen_d_op = FALSE;\n#ifdef DEBUGGING\n    RExC_paren_name_list = NULL;\n#endif\n\n    DEBUG_r({\n        RExC_mysv1= sv_newmortal();\n        RExC_mysv2= sv_newmortal();\n    });\n\n    DEBUG_COMPILE_r({\n            SV *dsv= sv_newmortal();\n            RE_PV_QUOTED_DECL(s, RExC_utf8, dsv, exp, plen, PL_dump_re_max_len);\n            Perl_re_printf( aTHX_  \"%sCompiling REx%s %s\\n\",\n                          PL_colors[4], PL_colors[5], s);\n        });\n\n    /* we jump here if we have to recompile, e.g., from upgrading the pattern\n     * to utf8 */\n\n    if ((pm_flags & PMf_USE_RE_EVAL)\n\t\t/* this second condition covers the non-regex literal case,\n\t\t * i.e.  $foo =~ '(?{})'. */\n\t\t|| (IN_PERL_COMPILETIME && (PL_hints & HINT_RE_EVAL))\n    )\n\truntime_code = S_has_runtime_code(aTHX_ pRExC_state, exp, plen);\n\n  redo_parse:\n    /* return old regex if pattern hasn't changed */\n    /* XXX: note in the below we have to check the flags as well as the\n     * pattern.\n     *\n     * Things get a touch tricky as we have to compare the utf8 flag\n     * independently from the compile flags.  */\n\n    if (   old_re\n        && !recompile\n        && !!RX_UTF8(old_re) == !!RExC_utf8\n        && ( RX_COMPFLAGS(old_re) == ( orig_rx_flags & RXf_PMf_FLAGCOPYMASK ) )\n\t&& RX_PRECOMP(old_re)\n\t&& RX_PRELEN(old_re) == plen\n        && memEQ(RX_PRECOMP(old_re), exp, plen)\n\t&& !runtime_code /* with runtime code, always recompile */ )\n    {\n        return old_re;\n    }\n\n    /* Allocate the pattern's SV */\n    RExC_rx_sv = Rx = (REGEXP*) newSV_type(SVt_REGEXP);\n    RExC_rx = ReANY(Rx);\n    if ( RExC_rx == NULL )\n        FAIL(\"Regexp out of space\");\n\n    rx_flags = orig_rx_flags;\n\n    if (   (UTF || RExC_uni_semantics)\n        && initial_charset == REGEX_DEPENDS_CHARSET)\n    {\n\n\t/* Set to use unicode semantics if the pattern is in utf8 and has the\n\t * 'depends' charset specified, as it means unicode when utf8  */\n\tset_regex_charset(&rx_flags, REGEX_UNICODE_CHARSET);\n        RExC_uni_semantics = 1;\n    }\n\n    RExC_pm_flags = pm_flags;\n\n    if (runtime_code) {\n        assert(TAINTING_get || !TAINT_get);\n\tif (TAINT_get)\n\t    Perl_croak(aTHX_ \"Eval-group in insecure regular expression\");\n\n\tif (!S_compile_runtime_code(aTHX_ pRExC_state, exp, plen)) {\n\t    /* whoops, we have a non-utf8 pattern, whilst run-time code\n\t     * got compiled as utf8. Try again with a utf8 pattern */\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n                pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            goto redo_parse;\n\t}\n    }\n    assert(!pRExC_state->runtime_code_qr);\n\n    RExC_sawback = 0;\n\n    RExC_seen = 0;\n    RExC_maxlen = 0;\n    RExC_in_lookbehind = 0;\n    RExC_seen_zerolen = *exp == '^' ? -1 : 0;\n#ifdef EBCDIC\n    RExC_recode_x_to_native = 0;\n#endif\n    RExC_in_multi_char_class = 0;\n\n    RExC_start = RExC_copy_start_in_constructed = RExC_copy_start_in_input = RExC_precomp = exp;\n    RExC_precomp_end = RExC_end = exp + plen;\n    RExC_nestroot = 0;\n    RExC_whilem_seen = 0;\n    RExC_end_op = NULL;\n    RExC_recurse = NULL;\n    RExC_study_chunk_recursed = NULL;\n    RExC_study_chunk_recursed_bytes= 0;\n    RExC_recurse_count = 0;\n    pRExC_state->code_index = 0;\n\n    /* Initialize the string in the compiled pattern.  This is so that there is\n     * something to output if necessary */\n    set_regex_pv(pRExC_state, Rx);\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Starting parse and generation\\n\");\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n    /* Allocate space and zero-initialize. Note, the two step process\n       of zeroing when in debug mode, thus anything assigned has to\n       happen after that */\n    if (!  RExC_size) {\n\n        /* On the first pass of the parse, we guess how big this will be.  Then\n         * we grow in one operation to that amount and then give it back.  As\n         * we go along, we re-allocate what we need.\n         *\n         * XXX Currently the guess is essentially that the pattern will be an\n         * EXACT node with one byte input, one byte output.  This is crude, and\n         * better heuristics are welcome.\n         *\n         * On any subsequent passes, we guess what we actually computed in the\n         * latest earlier pass.  Such a pass probably didn't complete so is\n         * missing stuff.  We could improve those guesses by knowing where the\n         * parse stopped, and use the length so far plus apply the above\n         * assumption to what's left. */\n        RExC_size = STR_SZ(RExC_end - RExC_start);\n    }\n\n    Newxc(RExC_rxi, sizeof(regexp_internal) + RExC_size, char, regexp_internal);\n    if ( RExC_rxi == NULL )\n        FAIL(\"Regexp out of space\");\n\n    Zero(RExC_rxi, sizeof(regexp_internal) + RExC_size, char);\n    RXi_SET( RExC_rx, RExC_rxi );\n\n    /* We start from 0 (over from 0 in the case this is a reparse.  The first\n     * node parsed will give back any excess memory we have allocated so far).\n     * */\n    RExC_size = 0;\n\n    /* non-zero initialization begins here */\n    RExC_rx->engine= eng;\n    RExC_rx->extflags = rx_flags;\n    RXp_COMPFLAGS(RExC_rx) = orig_rx_flags & RXf_PMf_FLAGCOPYMASK;\n\n    if (pm_flags & PMf_IS_QR) {\n\tRExC_rxi->code_blocks = pRExC_state->code_blocks;\n        if (RExC_rxi->code_blocks) {\n            RExC_rxi->code_blocks->refcnt++;\n        }\n    }\n\n    RExC_rx->intflags = 0;\n\n    RExC_flags = rx_flags;\t/* don't let top level (?i) bleed */\n    RExC_parse = exp;\n\n    /* This NUL is guaranteed because the pattern comes from an SV*, and the sv\n     * code makes sure the final byte is an uncounted NUL.  But should this\n     * ever not be the case, lots of things could read beyond the end of the\n     * buffer: loops like\n     *      while(isFOO(*RExC_parse)) RExC_parse++;\n     *      strchr(RExC_parse, \"foo\");\n     * etc.  So it is worth noting. */\n    assert(*RExC_end == '\\0');\n\n    RExC_naughty = 0;\n    RExC_npar = 1;\n    RExC_parens_buf_size = 0;\n    RExC_emit_start = RExC_rxi->program;\n    pRExC_state->code_index = 0;\n\n    *((char*) RExC_emit_start) = (char) REG_MAGIC;\n    RExC_emit = 1;\n\n    /* Do the parse */\n    if (reg(pRExC_state, 0, &flags, 1)) {\n\n        /* Success!, But we may need to redo the parse knowing how many parens\n         * there actually are */\n        if (IN_PARENS_PASS) {\n            flags |= RESTART_PARSE;\n        }\n\n        /* We have that number in RExC_npar */\n        RExC_total_parens = RExC_npar;\n    }\n    else if (! MUST_RESTART(flags)) {\n\tReREFCNT_dec(Rx);\n        Perl_croak(aTHX_ \"panic: reg returned failure to re_op_compile, flags=%#\" UVxf, (UV) flags);\n    }\n\n    /* Here, we either have success, or we have to redo the parse for some reason */\n    if (MUST_RESTART(flags)) {\n\n        /* It's possible to write a regexp in ascii that represents Unicode\n        codepoints outside of the byte range, such as via \\x{100}. If we\n        detect such a sequence we have to convert the entire pattern to utf8\n        and then recompile, as our sizing calculation will have been based\n        on 1 byte == 1 character, but we will need to use utf8 to encode\n        at least some part of the pattern, and therefore must convert the whole\n        thing.\n        -- dmq */\n        if (flags & NEED_UTF8) {\n\n            /* We have stored the offset of the final warning output so far.\n             * That must be adjusted.  Any variant characters between the start\n             * of the pattern and this warning count for 2 bytes in the final,\n             * so just add them again */\n            if (UNLIKELY(RExC_latest_warn_offset > 0)) {\n                RExC_latest_warn_offset +=\n                            variant_under_utf8_count((U8 *) exp, (U8 *) exp\n                                                + RExC_latest_warn_offset);\n            }\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n            pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse after upgrade\\n\"));\n        }\n        else {\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse\\n\"));\n        }\n\n        if (ALL_PARENS_COUNTED) {\n            /* Make enough room for all the known parens, and zero it */\n            Renew(RExC_open_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_open_parens, RExC_total_parens, regnode_offset);\n            RExC_open_parens[0] = 1;    /* +1 for REG_MAGIC */\n\n            Renew(RExC_close_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_close_parens, RExC_total_parens, regnode_offset);\n        }\n        else { /* Parse did not complete.  Reinitialize the parentheses\n                  structures */\n            RExC_total_parens = 0;\n            if (RExC_open_parens) {\n                Safefree(RExC_open_parens);\n                RExC_open_parens = NULL;\n            }\n            if (RExC_close_parens) {\n                Safefree(RExC_close_parens);\n                RExC_close_parens = NULL;\n            }\n        }\n\n        /* Clean up what we did in this parse */\n        SvREFCNT_dec_NN(RExC_rx_sv);\n\n        goto redo_parse;\n    }\n\n    /* Here, we have successfully parsed and generated the pattern's program\n     * for the regex engine.  We are ready to finish things up and look for\n     * optimizations. */\n\n    /* Update the string to compile, with correct modifiers, etc */\n    set_regex_pv(pRExC_state, Rx);\n\n    RExC_rx->nparens = RExC_total_parens - 1;\n\n    /* Uses the upper 4 bits of the FLAGS field, so keep within that size */\n    if (RExC_whilem_seen > 15)\n        RExC_whilem_seen = 15;\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Required size %\" IVdf \" nodes\\n\", (IV)RExC_size);\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n#ifdef RE_TRACK_PATTERN_OFFSETS\n    DEBUG_OFFSETS_r(Perl_re_printf( aTHX_\n                          \"%s %\" UVuf \" bytes for offset annotations.\\n\",\n                          RExC_offsets ? \"Got\" : \"Couldn't get\",\n                          (UV)((RExC_offsets[0] * 2 + 1))));\n    DEBUG_OFFSETS_r(if (RExC_offsets) {\n        const STRLEN len = RExC_offsets[0];\n        STRLEN i;\n        GET_RE_DEBUG_FLAGS_DECL;\n        Perl_re_printf( aTHX_\n                      \"Offsets: [%\" UVuf \"]\\n\\t\", (UV)RExC_offsets[0]);\n        for (i = 1; i <= len; i++) {\n            if (RExC_offsets[i*2-1] || RExC_offsets[i*2])\n                Perl_re_printf( aTHX_  \"%\" UVuf \":%\" UVuf \"[%\" UVuf \"] \",\n                (UV)i, (UV)RExC_offsets[i*2-1], (UV)RExC_offsets[i*2]);\n        }\n        Perl_re_printf( aTHX_  \"\\n\");\n    });\n\n#else\n    SetProgLen(RExC_rxi,RExC_size);\n#endif\n\n    DEBUG_OPTIMISE_r(\n        Perl_re_printf( aTHX_  \"Starting post parse optimization\\n\");\n    );\n\n    /* XXXX To minimize changes to RE engine we always allocate\n       3-units-long substrs field. */\n    Newx(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_recurse_count) {\n        Newx(RExC_recurse, RExC_recurse_count, regnode *);\n        SAVEFREEPV(RExC_recurse);\n    }\n\n    if (RExC_seen & REG_RECURSE_SEEN) {\n        /* Note, RExC_total_parens is 1 + the number of parens in a pattern.\n         * So its 1 if there are no parens. */\n        RExC_study_chunk_recursed_bytes= (RExC_total_parens >> 3) +\n                                         ((RExC_total_parens & 0x07) != 0);\n        Newx(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n        SAVEFREEPV(RExC_study_chunk_recursed);\n    }\n\n  reStudy:\n    RExC_rx->minlen = minlen = sawlookahead = sawplus = sawopen = sawminmod = 0;\n    DEBUG_r(\n        RExC_study_chunk_recursed_count= 0;\n    );\n    Zero(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_study_chunk_recursed) {\n        Zero(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n    }\n\n\n#ifdef TRIE_STUDY_OPT\n    if (!restudied) {\n        StructCopy(&zero_scan_data, &data, scan_data_t);\n        copyRExC_state = RExC_state;\n    } else {\n        U32 seen=RExC_seen;\n        DEBUG_OPTIMISE_r(Perl_re_printf( aTHX_ \"Restudying\\n\"));\n\n        RExC_state = copyRExC_state;\n        if (seen & REG_TOP_LEVEL_BRANCHES_SEEN)\n            RExC_seen |= REG_TOP_LEVEL_BRANCHES_SEEN;\n        else\n            RExC_seen &= ~REG_TOP_LEVEL_BRANCHES_SEEN;\n\tStructCopy(&zero_scan_data, &data, scan_data_t);\n    }\n#else\n    StructCopy(&zero_scan_data, &data, scan_data_t);\n#endif\n\n    /* Dig out information for optimizations. */\n    RExC_rx->extflags = RExC_flags; /* was pm_op */\n    /*dmq: removed as part of de-PMOP: pm->op_pmflags = RExC_flags; */\n\n    if (UTF)\n\tSvUTF8_on(Rx);\t/* Unicode in it? */\n    RExC_rxi->regstclass = NULL;\n    if (RExC_naughty >= TOO_NAUGHTY)\t/* Probably an expensive pattern. */\n\tRExC_rx->intflags |= PREGf_NAUGHTY;\n    scan = RExC_rxi->program + 1;\t\t/* First BRANCH. */\n\n    /* testing for BRANCH here tells us whether there is \"must appear\"\n       data in the pattern. If there is then we can use it for optimisations */\n    if (!(RExC_seen & REG_TOP_LEVEL_BRANCHES_SEEN)) { /*  Only one top-level choice.\n                                                  */\n\tSSize_t fake;\n\tSTRLEN longest_length[2];\n\tregnode_ssc ch_class; /* pointed to by data */\n\tint stclass_flag;\n\tSSize_t last_close = 0; /* pointed to by data */\n        regnode *first= scan;\n        regnode *first_next= regnext(first);\n        int i;\n\n\t/*\n\t * Skip introductions and multiplicators >= 1\n\t * so that we can extract the 'meat' of the pattern that must\n\t * match in the large if() sequence following.\n\t * NOTE that EXACT is NOT covered here, as it is normally\n\t * picked up by the optimiser separately.\n\t *\n\t * This is unfortunate as the optimiser isnt handling lookahead\n\t * properly currently.\n\t *\n\t */\n\twhile ((OP(first) == OPEN && (sawopen = 1)) ||\n\t       /* An OR of *one* alternative - should not happen now. */\n\t    (OP(first) == BRANCH && OP(first_next) != BRANCH) ||\n\t    /* for now we can't handle lookbehind IFMATCH*/\n\t    (OP(first) == IFMATCH && !first->flags && (sawlookahead = 1)) ||\n\t    (OP(first) == PLUS) ||\n\t    (OP(first) == MINMOD) ||\n\t       /* An {n,m} with n>0 */\n\t    (PL_regkind[OP(first)] == CURLY && ARG1(first) > 0) ||\n\t    (OP(first) == NOTHING && PL_regkind[OP(first_next)] != END ))\n\t{\n\t\t/*\n\t\t * the only op that could be a regnode is PLUS, all the rest\n\t\t * will be regnode_1 or regnode_2.\n\t\t *\n                 * (yves doesn't think this is true)\n\t\t */\n\t\tif (OP(first) == PLUS)\n\t\t    sawplus = 1;\n                else {\n                    if (OP(first) == MINMOD)\n                        sawminmod = 1;\n\t\t    first += regarglen[OP(first)];\n                }\n\t\tfirst = NEXTOPER(first);\n\t\tfirst_next= regnext(first);\n\t}\n\n\t/* Starting-point info. */\n      again:\n        DEBUG_PEEP(\"first:\", first, 0, 0);\n        /* Ignore EXACT as we deal with it later. */\n\tif (PL_regkind[OP(first)] == EXACT) {\n\t    if (   OP(first) == EXACT\n                || OP(first) == EXACT_ONLY8\n                || OP(first) == EXACTL)\n            {\n\t\tNOOP;\t/* Empty, get anchored substr later. */\n            }\n\t    else\n\t\tRExC_rxi->regstclass = first;\n\t}\n#ifdef TRIE_STCLASS\n\telse if (PL_regkind[OP(first)] == TRIE &&\n\t        ((reg_trie_data *)RExC_rxi->data->data[ ARG(first) ])->minlen>0)\n\t{\n            /* this can happen only on restudy */\n            RExC_rxi->regstclass = construct_ahocorasick_from_trie(pRExC_state, (regnode *)first, 0);\n\t}\n#endif\n\telse if (REGNODE_SIMPLE(OP(first)))\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOUND ||\n\t\t PL_regkind[OP(first)] == NBOUND)\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOL) {\n            RExC_rx->intflags |= (OP(first) == MBOL\n                           ? PREGf_ANCH_MBOL\n                           : PREGf_ANCH_SBOL);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if (OP(first) == GPOS) {\n            RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if ((!sawopen || !RExC_sawback) &&\n            !sawlookahead &&\n\t    (OP(first) == STAR &&\n\t    PL_regkind[OP(NEXTOPER(first))] == REG_ANY) &&\n            !(RExC_rx->intflags & PREGf_ANCH) && !pRExC_state->code_blocks)\n\t{\n\t    /* turn .* into ^.* with an implied $*=1 */\n\t    const int type =\n\t\t(OP(NEXTOPER(first)) == REG_ANY)\n                    ? PREGf_ANCH_MBOL\n                    : PREGf_ANCH_SBOL;\n            RExC_rx->intflags |= (type | PREGf_IMPLICIT);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n        if (sawplus && !sawminmod && !sawlookahead\n            && (!sawopen || !RExC_sawback)\n\t    && !pRExC_state->code_blocks) /* May examine pos and $& */\n\t    /* x+ must match at the 1st pos of run of x's */\n\t    RExC_rx->intflags |= PREGf_SKIP;\n\n\t/* Scan is after the zeroth branch, first is atomic matcher. */\n#ifdef TRIE_STUDY_OPT\n\tDEBUG_PARSE_r(\n\t    if (!restudied)\n                Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t\t\t      (IV)(first - scan + 1))\n        );\n#else\n\tDEBUG_PARSE_r(\n            Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t        (IV)(first - scan + 1))\n        );\n#endif\n\n\n\t/*\n\t* If there's something expensive in the r.e., find the\n\t* longest literal string that must appear and make it the\n\t* regmust.  Resolve ties in favor of later strings, since\n\t* the regstart check works with the beginning of the r.e.\n\t* and avoiding duplication strengthens checking.  Not a\n\t* strong reason, but sufficient in the absence of others.\n\t* [Now we resolve ties in favor of the earlier string if\n\t* it happens that c_offset_min has been invalidated, since the\n\t* earlier string may buy us something the later one won't.]\n\t*/\n\n\tdata.substrs[0].str = newSVpvs(\"\");\n\tdata.substrs[1].str = newSVpvs(\"\");\n\tdata.last_found = newSVpvs(\"\");\n\tdata.cur_is_floating = 0; /* initially any found substring is fixed */\n\tENTER_with_name(\"study_chunk\");\n\tSAVEFREESV(data.substrs[0].str);\n\tSAVEFREESV(data.substrs[1].str);\n\tSAVEFREESV(data.last_found);\n\tfirst = scan;\n\tif (!RExC_rxi->regstclass) {\n\t    ssc_init(pRExC_state, &ch_class);\n\t    data.start_class = &ch_class;\n\t    stclass_flag = SCF_DO_STCLASS_AND;\n\t} else\t\t\t\t/* XXXX Check for BOUND? */\n\t    stclass_flag = 0;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/PATTERN/\n         * (NO top level branches)\n         */\n\tminlen = study_chunk(pRExC_state, &first, &minlen, &fake,\n                             scan + RExC_size, /* Up to end */\n            &data, -1, 0, NULL,\n            SCF_DO_SUBSTR | SCF_WHILEM_VISITED_POS | stclass_flag\n                          | (restudied ? SCF_TRIE_DOING_RESTUDY : 0),\n            0);\n\n\n        CHECK_RESTUDY_GOTO_butfirst(LEAVE_with_name(\"study_chunk\"));\n\n\n\tif ( RExC_total_parens == 1 && !data.cur_is_floating\n\t     && data.last_start_min == 0 && data.last_end > 0\n\t     && !RExC_seen_zerolen\n             && !(RExC_seen & REG_VERBARG_SEEN)\n             && !(RExC_seen & REG_GPOS_SEEN)\n        ){\n\t    RExC_rx->extflags |= RXf_CHECK_ALL;\n        }\n\tscan_commit(pRExC_state, &data,&minlen, 0);\n\n\n        /* XXX this is done in reverse order because that's the way the\n         * code was before it was parameterised. Don't know whether it\n         * actually needs doing in reverse order. DAPM */\n        for (i = 1; i >= 0; i--) {\n            longest_length[i] = CHR_SVLEN(data.substrs[i].str);\n\n            if (   !(   i\n                     && SvCUR(data.substrs[0].str)  /* ok to leave SvCUR */\n                     &&    data.substrs[0].min_offset\n                        == data.substrs[1].min_offset\n                     &&    SvCUR(data.substrs[0].str)\n                        == SvCUR(data.substrs[1].str)\n                    )\n                && S_setup_longest (aTHX_ pRExC_state,\n                                        &(RExC_rx->substrs->data[i]),\n                                        &(data.substrs[i]),\n                                        longest_length[i]))\n            {\n                RExC_rx->substrs->data[i].min_offset =\n                        data.substrs[i].min_offset - data.substrs[i].lookbehind;\n\n                RExC_rx->substrs->data[i].max_offset = data.substrs[i].max_offset;\n                /* Don't offset infinity */\n                if (data.substrs[i].max_offset < SSize_t_MAX)\n                    RExC_rx->substrs->data[i].max_offset -= data.substrs[i].lookbehind;\n                SvREFCNT_inc_simple_void_NN(data.substrs[i].str);\n            }\n            else {\n                RExC_rx->substrs->data[i].substr      = NULL;\n                RExC_rx->substrs->data[i].utf8_substr = NULL;\n                longest_length[i] = 0;\n            }\n        }\n\n\tLEAVE_with_name(\"study_chunk\");\n\n\tif (RExC_rxi->regstclass\n\t    && (OP(RExC_rxi->regstclass) == REG_ANY || OP(RExC_rxi->regstclass) == SANY))\n\t    RExC_rxi->regstclass = NULL;\n\n\tif ((!(RExC_rx->substrs->data[0].substr || RExC_rx->substrs->data[0].utf8_substr)\n              || RExC_rx->substrs->data[0].min_offset)\n\t    && stclass_flag\n            && ! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n\t{\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV *sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n\n        /* A temporary algorithm prefers floated substr to fixed one of\n         * same length to dig more info. */\n\ti = (longest_length[0] <= longest_length[1]);\n        RExC_rx->substrs->check_ix = i;\n        RExC_rx->check_end_shift  = RExC_rx->substrs->data[i].end_shift;\n        RExC_rx->check_substr     = RExC_rx->substrs->data[i].substr;\n        RExC_rx->check_utf8       = RExC_rx->substrs->data[i].utf8_substr;\n        RExC_rx->check_offset_min = RExC_rx->substrs->data[i].min_offset;\n        RExC_rx->check_offset_max = RExC_rx->substrs->data[i].max_offset;\n        if (!i && (RExC_rx->intflags & (PREGf_ANCH_SBOL|PREGf_ANCH_GPOS)))\n            RExC_rx->intflags |= PREGf_NOSCAN;\n\n\tif ((RExC_rx->check_substr || RExC_rx->check_utf8) ) {\n\t    RExC_rx->extflags |= RXf_USE_INTUIT;\n\t    if (SvTAIL(RExC_rx->check_substr ? RExC_rx->check_substr : RExC_rx->check_utf8))\n\t\tRExC_rx->extflags |= RXf_INTUIT_TAIL;\n\t}\n\n\t/* XXX Unneeded? dmq (shouldn't as this is handled elsewhere)\n\tif ( (STRLEN)minlen < longest_length[1] )\n            minlen= longest_length[1];\n        if ( (STRLEN)minlen < longest_length[0] )\n            minlen= longest_length[0];\n        */\n    }\n    else {\n\t/* Several toplevels. Best we can is to set minlen. */\n\tSSize_t fake;\n\tregnode_ssc ch_class;\n\tSSize_t last_close = 0;\n\n        DEBUG_PARSE_r(Perl_re_printf( aTHX_  \"\\nMulti Top Level\\n\"));\n\n\tscan = RExC_rxi->program + 1;\n\tssc_init(pRExC_state, &ch_class);\n\tdata.start_class = &ch_class;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/P1|P2|.../\n         * (patterns WITH top level branches)\n         */\n\tminlen = study_chunk(pRExC_state,\n            &scan, &minlen, &fake, scan + RExC_size, &data, -1, 0, NULL,\n            SCF_DO_STCLASS_AND|SCF_WHILEM_VISITED_POS|(restudied\n                                                      ? SCF_TRIE_DOING_RESTUDY\n                                                      : 0),\n            0);\n\n        CHECK_RESTUDY_GOTO_butfirst(NOOP);\n\n\tRExC_rx->check_substr = NULL;\n        RExC_rx->check_utf8 = NULL;\n        RExC_rx->substrs->data[0].substr      = NULL;\n        RExC_rx->substrs->data[0].utf8_substr = NULL;\n        RExC_rx->substrs->data[1].substr      = NULL;\n        RExC_rx->substrs->data[1].utf8_substr = NULL;\n\n        if (! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n        {\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV* sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n    }\n\n    if (RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN) {\n        RExC_rx->extflags |= RXf_UNBOUNDED_QUANTIFIER_SEEN;\n        RExC_rx->maxlen = REG_INFTY;\n    }\n    else {\n        RExC_rx->maxlen = RExC_maxlen;\n    }\n\n    /* Guard against an embedded (?=) or (?<=) with a longer minlen than\n       the \"real\" pattern. */\n    DEBUG_OPTIMISE_r({\n        Perl_re_printf( aTHX_ \"minlen: %\" IVdf \" RExC_rx->minlen:%\" IVdf \" maxlen:%\" IVdf \"\\n\",\n                      (IV)minlen, (IV)RExC_rx->minlen, (IV)RExC_maxlen);\n    });\n    RExC_rx->minlenret = minlen;\n    if (RExC_rx->minlen < minlen)\n        RExC_rx->minlen = minlen;\n\n    if (RExC_seen & REG_RECURSE_SEEN ) {\n        RExC_rx->intflags |= PREGf_RECURSE_SEEN;\n        Newx(RExC_rx->recurse_locinput, RExC_rx->nparens + 1, char *);\n    }\n    if (RExC_seen & REG_GPOS_SEEN)\n        RExC_rx->intflags |= PREGf_GPOS_SEEN;\n    if (RExC_seen & REG_LOOKBEHIND_SEEN)\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* inplace might break the\n                                                lookbehind */\n    if (pRExC_state->code_blocks)\n\tRExC_rx->extflags |= RXf_EVAL_SEEN;\n    if (RExC_seen & REG_VERBARG_SEEN)\n    {\n\tRExC_rx->intflags |= PREGf_VERBARG_SEEN;\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* don't understand this! Yves */\n    }\n    if (RExC_seen & REG_CUTGROUP_SEEN)\n\tRExC_rx->intflags |= PREGf_CUTGROUP_SEEN;\n    if (pm_flags & PMf_USE_RE_EVAL)\n\tRExC_rx->intflags |= PREGf_USE_RE_EVAL;\n    if (RExC_paren_names)\n        RXp_PAREN_NAMES(RExC_rx) = MUTABLE_HV(SvREFCNT_inc(RExC_paren_names));\n    else\n        RXp_PAREN_NAMES(RExC_rx) = NULL;\n\n    /* If we have seen an anchor in our pattern then we set the extflag RXf_IS_ANCHORED\n     * so it can be used in pp.c */\n    if (RExC_rx->intflags & PREGf_ANCH)\n        RExC_rx->extflags |= RXf_IS_ANCHORED;\n\n\n    {\n        /* this is used to identify \"special\" patterns that might result\n         * in Perl NOT calling the regex engine and instead doing the match \"itself\",\n         * particularly special cases in split//. By having the regex compiler\n         * do this pattern matching at a regop level (instead of by inspecting the pattern)\n         * we avoid weird issues with equivalent patterns resulting in different behavior,\n         * AND we allow non Perl engines to get the same optimizations by the setting the\n         * flags appropriately - Yves */\n        regnode *first = RExC_rxi->program + 1;\n        U8 fop = OP(first);\n        regnode *next = regnext(first);\n        U8 nop = OP(next);\n\n        if (PL_regkind[fop] == NOTHING && nop == END)\n            RExC_rx->extflags |= RXf_NULL;\n        else if ((fop == MBOL || (fop == SBOL && !first->flags)) && nop == END)\n            /* when fop is SBOL first->flags will be true only when it was\n             * produced by parsing /\\A/, and not when parsing /^/. This is\n             * very important for the split code as there we want to\n             * treat /^/ as /^/m, but we do not want to treat /\\A/ as /^/m.\n             * See rt #122761 for more details. -- Yves */\n            RExC_rx->extflags |= RXf_START_ONLY;\n        else if (fop == PLUS\n                 && PL_regkind[nop] == POSIXD && FLAGS(next) == _CC_SPACE\n                 && nop == END)\n            RExC_rx->extflags |= RXf_WHITE;\n        else if ( RExC_rx->extflags & RXf_SPLIT\n                  && (fop == EXACT || fop == EXACT_ONLY8 || fop == EXACTL)\n                  && STR_LEN(first) == 1\n                  && *(STRING(first)) == ' '\n                  && nop == END )\n            RExC_rx->extflags |= (RXf_SKIPWHITE|RXf_WHITE);\n\n    }\n\n    if (RExC_contains_locale) {\n        RXp_EXTFLAGS(RExC_rx) |= RXf_TAINTED;\n    }\n\n#ifdef DEBUGGING\n    if (RExC_paren_names) {\n        RExC_rxi->name_list_idx = add_data( pRExC_state, STR_WITH_LEN(\"a\"));\n        RExC_rxi->data->data[RExC_rxi->name_list_idx]\n                                   = (void*)SvREFCNT_inc(RExC_paren_name_list);\n    } else\n#endif\n    RExC_rxi->name_list_idx = 0;\n\n    while ( RExC_recurse_count > 0 ) {\n        const regnode *scan = RExC_recurse[ --RExC_recurse_count ];\n        /*\n         * This data structure is set up in study_chunk() and is used\n         * to calculate the distance between a GOSUB regopcode and\n         * the OPEN/CURLYM (CURLYM's are special and can act like OPEN's)\n         * it refers to.\n         *\n         * If for some reason someone writes code that optimises\n         * away a GOSUB opcode then the assert should be changed to\n         * an if(scan) to guard the ARG2L_SET() - Yves\n         *\n         */\n        assert(scan && OP(scan) == GOSUB);\n        ARG2L_SET( scan, RExC_open_parens[ARG(scan)] - REGNODE_OFFSET(scan));\n    }\n\n    Newxz(RExC_rx->offs, RExC_total_parens, regexp_paren_pair);\n    /* assume we don't need to swap parens around before we match */\n    DEBUG_TEST_r({\n        Perl_re_printf( aTHX_ \"study_chunk_recursed_count: %lu\\n\",\n            (unsigned long)RExC_study_chunk_recursed_count);\n    });\n    DEBUG_DUMP_r({\n        DEBUG_RExC_seen();\n        Perl_re_printf( aTHX_ \"Final program:\\n\");\n        regdump(RExC_rx);\n    });\n\n    if (RExC_open_parens) {\n        Safefree(RExC_open_parens);\n        RExC_open_parens = NULL;\n    }\n    if (RExC_close_parens) {\n        Safefree(RExC_close_parens);\n        RExC_close_parens = NULL;\n    }\n\n#ifdef USE_ITHREADS\n    /* under ithreads the ?pat? PMf_USED flag on the pmop is simulated\n     * by setting the regexp SV to readonly-only instead. If the\n     * pattern's been recompiled, the USEDness should remain. */\n    if (old_re && SvREADONLY(old_re))\n        SvREADONLY_on(Rx);\n#endif\n    return Rx;", "func_src_after": "REGEXP *\nPerl_re_op_compile(pTHX_ SV ** const patternp, int pat_count,\n\t\t    OP *expr, const regexp_engine* eng, REGEXP *old_re,\n\t\t     bool *is_bare_re, const U32 orig_rx_flags, const U32 pm_flags)\n{\n    dVAR;\n    REGEXP *Rx;         /* Capital 'R' means points to a REGEXP */\n    STRLEN plen;\n    char *exp;\n    regnode *scan;\n    I32 flags;\n    SSize_t minlen = 0;\n    U32 rx_flags;\n    SV *pat;\n    SV** new_patternp = patternp;\n\n    /* these are all flags - maybe they should be turned\n     * into a single int with different bit masks */\n    I32 sawlookahead = 0;\n    I32 sawplus = 0;\n    I32 sawopen = 0;\n    I32 sawminmod = 0;\n\n    regex_charset initial_charset = get_regex_charset(orig_rx_flags);\n    bool recompile = 0;\n    bool runtime_code = 0;\n    scan_data_t data;\n    RExC_state_t RExC_state;\n    RExC_state_t * const pRExC_state = &RExC_state;\n#ifdef TRIE_STUDY_OPT\n    int restudied = 0;\n    RExC_state_t copyRExC_state;\n#endif\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_RE_OP_COMPILE;\n\n    DEBUG_r(if (!PL_colorset) reginitcolors());\n\n    /* Initialize these here instead of as-needed, as is quick and avoids\n     * having to test them each time otherwise */\n    if (! PL_InBitmap) {\n#ifdef DEBUGGING\n        char * dump_len_string;\n#endif\n\n        /* This is calculated here, because the Perl program that generates the\n         * static global ones doesn't currently have access to\n         * NUM_ANYOF_CODE_POINTS */\n\tPL_InBitmap = _new_invlist(2);\n\tPL_InBitmap = _add_range_to_invlist(PL_InBitmap, 0,\n                                                    NUM_ANYOF_CODE_POINTS - 1);\n#ifdef DEBUGGING\n        dump_len_string = PerlEnv_getenv(\"PERL_DUMP_RE_MAX_LEN\");\n        if (   ! dump_len_string\n            || ! grok_atoUV(dump_len_string, (UV *)&PL_dump_re_max_len, NULL))\n        {\n            PL_dump_re_max_len = 60;    /* A reasonable default */\n        }\n#endif\n    }\n\n    pRExC_state->warn_text = NULL;\n    pRExC_state->unlexed_names = NULL;\n    pRExC_state->code_blocks = NULL;\n\n    if (is_bare_re)\n\t*is_bare_re = FALSE;\n\n    if (expr && (expr->op_type == OP_LIST ||\n\t\t(expr->op_type == OP_NULL && expr->op_targ == OP_LIST))) {\n\t/* allocate code_blocks if needed */\n\tOP *o;\n\tint ncode = 0;\n\n\tfor (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o))\n\t    if (o->op_type == OP_NULL && (o->op_flags & OPf_SPECIAL))\n\t\tncode++; /* count of DO blocks */\n\n\tif (ncode)\n            pRExC_state->code_blocks = S_alloc_code_blocks(aTHX_ ncode);\n    }\n\n    if (!pat_count) {\n        /* compile-time pattern with just OP_CONSTs and DO blocks */\n\n        int n;\n        OP *o;\n\n        /* find how many CONSTs there are */\n        assert(expr);\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            n = 1;\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    n++;\n            }\n\n        /* fake up an SV array */\n\n        assert(!new_patternp);\n        Newx(new_patternp, n, SV*);\n        SAVEFREEPV(new_patternp);\n        pat_count = n;\n\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            new_patternp[n] = cSVOPx_sv(expr);\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    new_patternp[n++] = cSVOPo_sv;\n            }\n\n    }\n\n    DEBUG_PARSE_r(Perl_re_printf( aTHX_\n        \"Assembling pattern from %d elements%s\\n\", pat_count,\n            orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n    /* set expr to the first arg op */\n\n    if (pRExC_state->code_blocks && pRExC_state->code_blocks->count\n         && expr->op_type != OP_CONST)\n    {\n            expr = cLISTOPx(expr)->op_first;\n            assert(   expr->op_type == OP_PUSHMARK\n                   || (expr->op_type == OP_NULL && expr->op_targ == OP_PUSHMARK)\n                   || expr->op_type == OP_PADRANGE);\n            expr = OpSIBLING(expr);\n    }\n\n    pat = S_concat_pat(aTHX_ pRExC_state, NULL, new_patternp, pat_count,\n                        expr, &recompile, NULL);\n\n    /* handle bare (possibly after overloading) regex: foo =~ $re */\n    {\n        SV *re = pat;\n        if (SvROK(re))\n            re = SvRV(re);\n        if (SvTYPE(re) == SVt_REGEXP) {\n            if (is_bare_re)\n                *is_bare_re = TRUE;\n            SvREFCNT_inc(re);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_\n                \"Precompiled pattern%s\\n\",\n                    orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n            return (REGEXP*)re;\n        }\n    }\n\n    exp = SvPV_nomg(pat, plen);\n\n    if (!eng->op_comp) {\n\tif ((SvUTF8(pat) && IN_BYTES)\n\t\t|| SvGMAGICAL(pat) || SvAMAGIC(pat))\n\t{\n\t    /* make a temporary copy; either to convert to bytes,\n\t     * or to avoid repeating get-magic / overloaded stringify */\n\t    pat = newSVpvn_flags(exp, plen, SVs_TEMP |\n\t\t\t\t\t(IN_BYTES ? 0 : SvUTF8(pat)));\n\t}\n\treturn CALLREGCOMP_ENG(eng, pat, orig_rx_flags);\n    }\n\n    /* ignore the utf8ness if the pattern is 0 length */\n    RExC_utf8 = RExC_orig_utf8 = (plen == 0 || IN_BYTES) ? 0 : SvUTF8(pat);\n    RExC_uni_semantics = 0;\n    RExC_contains_locale = 0;\n    RExC_strict = cBOOL(pm_flags & RXf_PMf_STRICT);\n    RExC_in_script_run = 0;\n    RExC_study_started = 0;\n    pRExC_state->runtime_code_qr = NULL;\n    RExC_frame_head= NULL;\n    RExC_frame_last= NULL;\n    RExC_frame_count= 0;\n    RExC_latest_warn_offset = 0;\n    RExC_use_BRANCHJ = 0;\n    RExC_total_parens = 0;\n    RExC_open_parens = NULL;\n    RExC_close_parens = NULL;\n    RExC_paren_names = NULL;\n    RExC_size = 0;\n    RExC_seen_d_op = FALSE;\n#ifdef DEBUGGING\n    RExC_paren_name_list = NULL;\n#endif\n\n    DEBUG_r({\n        RExC_mysv1= sv_newmortal();\n        RExC_mysv2= sv_newmortal();\n    });\n\n    DEBUG_COMPILE_r({\n            SV *dsv= sv_newmortal();\n            RE_PV_QUOTED_DECL(s, RExC_utf8, dsv, exp, plen, PL_dump_re_max_len);\n            Perl_re_printf( aTHX_  \"%sCompiling REx%s %s\\n\",\n                          PL_colors[4], PL_colors[5], s);\n        });\n\n    /* we jump here if we have to recompile, e.g., from upgrading the pattern\n     * to utf8 */\n\n    if ((pm_flags & PMf_USE_RE_EVAL)\n\t\t/* this second condition covers the non-regex literal case,\n\t\t * i.e.  $foo =~ '(?{})'. */\n\t\t|| (IN_PERL_COMPILETIME && (PL_hints & HINT_RE_EVAL))\n    )\n\truntime_code = S_has_runtime_code(aTHX_ pRExC_state, exp, plen);\n\n  redo_parse:\n    /* return old regex if pattern hasn't changed */\n    /* XXX: note in the below we have to check the flags as well as the\n     * pattern.\n     *\n     * Things get a touch tricky as we have to compare the utf8 flag\n     * independently from the compile flags.  */\n\n    if (   old_re\n        && !recompile\n        && !!RX_UTF8(old_re) == !!RExC_utf8\n        && ( RX_COMPFLAGS(old_re) == ( orig_rx_flags & RXf_PMf_FLAGCOPYMASK ) )\n\t&& RX_PRECOMP(old_re)\n\t&& RX_PRELEN(old_re) == plen\n        && memEQ(RX_PRECOMP(old_re), exp, plen)\n\t&& !runtime_code /* with runtime code, always recompile */ )\n    {\n        return old_re;\n    }\n\n    /* Allocate the pattern's SV */\n    RExC_rx_sv = Rx = (REGEXP*) newSV_type(SVt_REGEXP);\n    RExC_rx = ReANY(Rx);\n    if ( RExC_rx == NULL )\n        FAIL(\"Regexp out of space\");\n\n    rx_flags = orig_rx_flags;\n\n    if (   (UTF || RExC_uni_semantics)\n        && initial_charset == REGEX_DEPENDS_CHARSET)\n    {\n\n\t/* Set to use unicode semantics if the pattern is in utf8 and has the\n\t * 'depends' charset specified, as it means unicode when utf8  */\n\tset_regex_charset(&rx_flags, REGEX_UNICODE_CHARSET);\n        RExC_uni_semantics = 1;\n    }\n\n    RExC_pm_flags = pm_flags;\n\n    if (runtime_code) {\n        assert(TAINTING_get || !TAINT_get);\n\tif (TAINT_get)\n\t    Perl_croak(aTHX_ \"Eval-group in insecure regular expression\");\n\n\tif (!S_compile_runtime_code(aTHX_ pRExC_state, exp, plen)) {\n\t    /* whoops, we have a non-utf8 pattern, whilst run-time code\n\t     * got compiled as utf8. Try again with a utf8 pattern */\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n                pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            goto redo_parse;\n\t}\n    }\n    assert(!pRExC_state->runtime_code_qr);\n\n    RExC_sawback = 0;\n\n    RExC_seen = 0;\n    RExC_maxlen = 0;\n    RExC_in_lookbehind = 0;\n    RExC_seen_zerolen = *exp == '^' ? -1 : 0;\n#ifdef EBCDIC\n    RExC_recode_x_to_native = 0;\n#endif\n    RExC_in_multi_char_class = 0;\n\n    RExC_start = RExC_copy_start_in_constructed = RExC_copy_start_in_input = RExC_precomp = exp;\n    RExC_precomp_end = RExC_end = exp + plen;\n    RExC_nestroot = 0;\n    RExC_whilem_seen = 0;\n    RExC_end_op = NULL;\n    RExC_recurse = NULL;\n    RExC_study_chunk_recursed = NULL;\n    RExC_study_chunk_recursed_bytes= 0;\n    RExC_recurse_count = 0;\n    pRExC_state->code_index = 0;\n\n    /* Initialize the string in the compiled pattern.  This is so that there is\n     * something to output if necessary */\n    set_regex_pv(pRExC_state, Rx);\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Starting parse and generation\\n\");\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n    /* Allocate space and zero-initialize. Note, the two step process\n       of zeroing when in debug mode, thus anything assigned has to\n       happen after that */\n    if (!  RExC_size) {\n\n        /* On the first pass of the parse, we guess how big this will be.  Then\n         * we grow in one operation to that amount and then give it back.  As\n         * we go along, we re-allocate what we need.\n         *\n         * XXX Currently the guess is essentially that the pattern will be an\n         * EXACT node with one byte input, one byte output.  This is crude, and\n         * better heuristics are welcome.\n         *\n         * On any subsequent passes, we guess what we actually computed in the\n         * latest earlier pass.  Such a pass probably didn't complete so is\n         * missing stuff.  We could improve those guesses by knowing where the\n         * parse stopped, and use the length so far plus apply the above\n         * assumption to what's left. */\n        RExC_size = STR_SZ(RExC_end - RExC_start);\n    }\n\n    Newxc(RExC_rxi, sizeof(regexp_internal) + RExC_size, char, regexp_internal);\n    if ( RExC_rxi == NULL )\n        FAIL(\"Regexp out of space\");\n\n    Zero(RExC_rxi, sizeof(regexp_internal) + RExC_size, char);\n    RXi_SET( RExC_rx, RExC_rxi );\n\n    /* We start from 0 (over from 0 in the case this is a reparse.  The first\n     * node parsed will give back any excess memory we have allocated so far).\n     * */\n    RExC_size = 0;\n\n    /* non-zero initialization begins here */\n    RExC_rx->engine= eng;\n    RExC_rx->extflags = rx_flags;\n    RXp_COMPFLAGS(RExC_rx) = orig_rx_flags & RXf_PMf_FLAGCOPYMASK;\n\n    if (pm_flags & PMf_IS_QR) {\n\tRExC_rxi->code_blocks = pRExC_state->code_blocks;\n        if (RExC_rxi->code_blocks) {\n            RExC_rxi->code_blocks->refcnt++;\n        }\n    }\n\n    RExC_rx->intflags = 0;\n\n    RExC_flags = rx_flags;\t/* don't let top level (?i) bleed */\n    RExC_parse = exp;\n\n    /* This NUL is guaranteed because the pattern comes from an SV*, and the sv\n     * code makes sure the final byte is an uncounted NUL.  But should this\n     * ever not be the case, lots of things could read beyond the end of the\n     * buffer: loops like\n     *      while(isFOO(*RExC_parse)) RExC_parse++;\n     *      strchr(RExC_parse, \"foo\");\n     * etc.  So it is worth noting. */\n    assert(*RExC_end == '\\0');\n\n    RExC_naughty = 0;\n    RExC_npar = 1;\n    RExC_parens_buf_size = 0;\n    RExC_emit_start = RExC_rxi->program;\n    pRExC_state->code_index = 0;\n\n    *((char*) RExC_emit_start) = (char) REG_MAGIC;\n    RExC_emit = 1;\n\n    /* Do the parse */\n    if (reg(pRExC_state, 0, &flags, 1)) {\n\n        /* Success!, But we may need to redo the parse knowing how many parens\n         * there actually are */\n        if (IN_PARENS_PASS) {\n            flags |= RESTART_PARSE;\n        }\n\n        /* We have that number in RExC_npar */\n        RExC_total_parens = RExC_npar;\n\n        /* XXX For backporting, use long jumps if there is any possibility of\n         * overflow */\n        if (RExC_size > U16_MAX && ! RExC_use_BRANCHJ) {\n            RExC_use_BRANCHJ = TRUE;\n            flags |= RESTART_PARSE;\n        }\n    }\n    else if (! MUST_RESTART(flags)) {\n\tReREFCNT_dec(Rx);\n        Perl_croak(aTHX_ \"panic: reg returned failure to re_op_compile, flags=%#\" UVxf, (UV) flags);\n    }\n\n    /* Here, we either have success, or we have to redo the parse for some reason */\n    if (MUST_RESTART(flags)) {\n\n        /* It's possible to write a regexp in ascii that represents Unicode\n        codepoints outside of the byte range, such as via \\x{100}. If we\n        detect such a sequence we have to convert the entire pattern to utf8\n        and then recompile, as our sizing calculation will have been based\n        on 1 byte == 1 character, but we will need to use utf8 to encode\n        at least some part of the pattern, and therefore must convert the whole\n        thing.\n        -- dmq */\n        if (flags & NEED_UTF8) {\n\n            /* We have stored the offset of the final warning output so far.\n             * That must be adjusted.  Any variant characters between the start\n             * of the pattern and this warning count for 2 bytes in the final,\n             * so just add them again */\n            if (UNLIKELY(RExC_latest_warn_offset > 0)) {\n                RExC_latest_warn_offset +=\n                            variant_under_utf8_count((U8 *) exp, (U8 *) exp\n                                                + RExC_latest_warn_offset);\n            }\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n            pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse after upgrade\\n\"));\n        }\n        else {\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse\\n\"));\n        }\n\n        if (ALL_PARENS_COUNTED) {\n            /* Make enough room for all the known parens, and zero it */\n            Renew(RExC_open_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_open_parens, RExC_total_parens, regnode_offset);\n            RExC_open_parens[0] = 1;    /* +1 for REG_MAGIC */\n\n            Renew(RExC_close_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_close_parens, RExC_total_parens, regnode_offset);\n        }\n        else { /* Parse did not complete.  Reinitialize the parentheses\n                  structures */\n            RExC_total_parens = 0;\n            if (RExC_open_parens) {\n                Safefree(RExC_open_parens);\n                RExC_open_parens = NULL;\n            }\n            if (RExC_close_parens) {\n                Safefree(RExC_close_parens);\n                RExC_close_parens = NULL;\n            }\n        }\n\n        /* Clean up what we did in this parse */\n        SvREFCNT_dec_NN(RExC_rx_sv);\n\n        goto redo_parse;\n    }\n\n    /* Here, we have successfully parsed and generated the pattern's program\n     * for the regex engine.  We are ready to finish things up and look for\n     * optimizations. */\n\n    /* Update the string to compile, with correct modifiers, etc */\n    set_regex_pv(pRExC_state, Rx);\n\n    RExC_rx->nparens = RExC_total_parens - 1;\n\n    /* Uses the upper 4 bits of the FLAGS field, so keep within that size */\n    if (RExC_whilem_seen > 15)\n        RExC_whilem_seen = 15;\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Required size %\" IVdf \" nodes\\n\", (IV)RExC_size);\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n#ifdef RE_TRACK_PATTERN_OFFSETS\n    DEBUG_OFFSETS_r(Perl_re_printf( aTHX_\n                          \"%s %\" UVuf \" bytes for offset annotations.\\n\",\n                          RExC_offsets ? \"Got\" : \"Couldn't get\",\n                          (UV)((RExC_offsets[0] * 2 + 1))));\n    DEBUG_OFFSETS_r(if (RExC_offsets) {\n        const STRLEN len = RExC_offsets[0];\n        STRLEN i;\n        GET_RE_DEBUG_FLAGS_DECL;\n        Perl_re_printf( aTHX_\n                      \"Offsets: [%\" UVuf \"]\\n\\t\", (UV)RExC_offsets[0]);\n        for (i = 1; i <= len; i++) {\n            if (RExC_offsets[i*2-1] || RExC_offsets[i*2])\n                Perl_re_printf( aTHX_  \"%\" UVuf \":%\" UVuf \"[%\" UVuf \"] \",\n                (UV)i, (UV)RExC_offsets[i*2-1], (UV)RExC_offsets[i*2]);\n        }\n        Perl_re_printf( aTHX_  \"\\n\");\n    });\n\n#else\n    SetProgLen(RExC_rxi,RExC_size);\n#endif\n\n    DEBUG_OPTIMISE_r(\n        Perl_re_printf( aTHX_  \"Starting post parse optimization\\n\");\n    );\n\n    /* XXXX To minimize changes to RE engine we always allocate\n       3-units-long substrs field. */\n    Newx(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_recurse_count) {\n        Newx(RExC_recurse, RExC_recurse_count, regnode *);\n        SAVEFREEPV(RExC_recurse);\n    }\n\n    if (RExC_seen & REG_RECURSE_SEEN) {\n        /* Note, RExC_total_parens is 1 + the number of parens in a pattern.\n         * So its 1 if there are no parens. */\n        RExC_study_chunk_recursed_bytes= (RExC_total_parens >> 3) +\n                                         ((RExC_total_parens & 0x07) != 0);\n        Newx(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n        SAVEFREEPV(RExC_study_chunk_recursed);\n    }\n\n  reStudy:\n    RExC_rx->minlen = minlen = sawlookahead = sawplus = sawopen = sawminmod = 0;\n    DEBUG_r(\n        RExC_study_chunk_recursed_count= 0;\n    );\n    Zero(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_study_chunk_recursed) {\n        Zero(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n    }\n\n\n#ifdef TRIE_STUDY_OPT\n    if (!restudied) {\n        StructCopy(&zero_scan_data, &data, scan_data_t);\n        copyRExC_state = RExC_state;\n    } else {\n        U32 seen=RExC_seen;\n        DEBUG_OPTIMISE_r(Perl_re_printf( aTHX_ \"Restudying\\n\"));\n\n        RExC_state = copyRExC_state;\n        if (seen & REG_TOP_LEVEL_BRANCHES_SEEN)\n            RExC_seen |= REG_TOP_LEVEL_BRANCHES_SEEN;\n        else\n            RExC_seen &= ~REG_TOP_LEVEL_BRANCHES_SEEN;\n\tStructCopy(&zero_scan_data, &data, scan_data_t);\n    }\n#else\n    StructCopy(&zero_scan_data, &data, scan_data_t);\n#endif\n\n    /* Dig out information for optimizations. */\n    RExC_rx->extflags = RExC_flags; /* was pm_op */\n    /*dmq: removed as part of de-PMOP: pm->op_pmflags = RExC_flags; */\n\n    if (UTF)\n\tSvUTF8_on(Rx);\t/* Unicode in it? */\n    RExC_rxi->regstclass = NULL;\n    if (RExC_naughty >= TOO_NAUGHTY)\t/* Probably an expensive pattern. */\n\tRExC_rx->intflags |= PREGf_NAUGHTY;\n    scan = RExC_rxi->program + 1;\t\t/* First BRANCH. */\n\n    /* testing for BRANCH here tells us whether there is \"must appear\"\n       data in the pattern. If there is then we can use it for optimisations */\n    if (!(RExC_seen & REG_TOP_LEVEL_BRANCHES_SEEN)) { /*  Only one top-level choice.\n                                                  */\n\tSSize_t fake;\n\tSTRLEN longest_length[2];\n\tregnode_ssc ch_class; /* pointed to by data */\n\tint stclass_flag;\n\tSSize_t last_close = 0; /* pointed to by data */\n        regnode *first= scan;\n        regnode *first_next= regnext(first);\n        int i;\n\n\t/*\n\t * Skip introductions and multiplicators >= 1\n\t * so that we can extract the 'meat' of the pattern that must\n\t * match in the large if() sequence following.\n\t * NOTE that EXACT is NOT covered here, as it is normally\n\t * picked up by the optimiser separately.\n\t *\n\t * This is unfortunate as the optimiser isnt handling lookahead\n\t * properly currently.\n\t *\n\t */\n\twhile ((OP(first) == OPEN && (sawopen = 1)) ||\n\t       /* An OR of *one* alternative - should not happen now. */\n\t    (OP(first) == BRANCH && OP(first_next) != BRANCH) ||\n\t    /* for now we can't handle lookbehind IFMATCH*/\n\t    (OP(first) == IFMATCH && !first->flags && (sawlookahead = 1)) ||\n\t    (OP(first) == PLUS) ||\n\t    (OP(first) == MINMOD) ||\n\t       /* An {n,m} with n>0 */\n\t    (PL_regkind[OP(first)] == CURLY && ARG1(first) > 0) ||\n\t    (OP(first) == NOTHING && PL_regkind[OP(first_next)] != END ))\n\t{\n\t\t/*\n\t\t * the only op that could be a regnode is PLUS, all the rest\n\t\t * will be regnode_1 or regnode_2.\n\t\t *\n                 * (yves doesn't think this is true)\n\t\t */\n\t\tif (OP(first) == PLUS)\n\t\t    sawplus = 1;\n                else {\n                    if (OP(first) == MINMOD)\n                        sawminmod = 1;\n\t\t    first += regarglen[OP(first)];\n                }\n\t\tfirst = NEXTOPER(first);\n\t\tfirst_next= regnext(first);\n\t}\n\n\t/* Starting-point info. */\n      again:\n        DEBUG_PEEP(\"first:\", first, 0, 0);\n        /* Ignore EXACT as we deal with it later. */\n\tif (PL_regkind[OP(first)] == EXACT) {\n\t    if (   OP(first) == EXACT\n                || OP(first) == EXACT_ONLY8\n                || OP(first) == EXACTL)\n            {\n\t\tNOOP;\t/* Empty, get anchored substr later. */\n            }\n\t    else\n\t\tRExC_rxi->regstclass = first;\n\t}\n#ifdef TRIE_STCLASS\n\telse if (PL_regkind[OP(first)] == TRIE &&\n\t        ((reg_trie_data *)RExC_rxi->data->data[ ARG(first) ])->minlen>0)\n\t{\n            /* this can happen only on restudy */\n            RExC_rxi->regstclass = construct_ahocorasick_from_trie(pRExC_state, (regnode *)first, 0);\n\t}\n#endif\n\telse if (REGNODE_SIMPLE(OP(first)))\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOUND ||\n\t\t PL_regkind[OP(first)] == NBOUND)\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOL) {\n            RExC_rx->intflags |= (OP(first) == MBOL\n                           ? PREGf_ANCH_MBOL\n                           : PREGf_ANCH_SBOL);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if (OP(first) == GPOS) {\n            RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if ((!sawopen || !RExC_sawback) &&\n            !sawlookahead &&\n\t    (OP(first) == STAR &&\n\t    PL_regkind[OP(NEXTOPER(first))] == REG_ANY) &&\n            !(RExC_rx->intflags & PREGf_ANCH) && !pRExC_state->code_blocks)\n\t{\n\t    /* turn .* into ^.* with an implied $*=1 */\n\t    const int type =\n\t\t(OP(NEXTOPER(first)) == REG_ANY)\n                    ? PREGf_ANCH_MBOL\n                    : PREGf_ANCH_SBOL;\n            RExC_rx->intflags |= (type | PREGf_IMPLICIT);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n        if (sawplus && !sawminmod && !sawlookahead\n            && (!sawopen || !RExC_sawback)\n\t    && !pRExC_state->code_blocks) /* May examine pos and $& */\n\t    /* x+ must match at the 1st pos of run of x's */\n\t    RExC_rx->intflags |= PREGf_SKIP;\n\n\t/* Scan is after the zeroth branch, first is atomic matcher. */\n#ifdef TRIE_STUDY_OPT\n\tDEBUG_PARSE_r(\n\t    if (!restudied)\n                Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t\t\t      (IV)(first - scan + 1))\n        );\n#else\n\tDEBUG_PARSE_r(\n            Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t        (IV)(first - scan + 1))\n        );\n#endif\n\n\n\t/*\n\t* If there's something expensive in the r.e., find the\n\t* longest literal string that must appear and make it the\n\t* regmust.  Resolve ties in favor of later strings, since\n\t* the regstart check works with the beginning of the r.e.\n\t* and avoiding duplication strengthens checking.  Not a\n\t* strong reason, but sufficient in the absence of others.\n\t* [Now we resolve ties in favor of the earlier string if\n\t* it happens that c_offset_min has been invalidated, since the\n\t* earlier string may buy us something the later one won't.]\n\t*/\n\n\tdata.substrs[0].str = newSVpvs(\"\");\n\tdata.substrs[1].str = newSVpvs(\"\");\n\tdata.last_found = newSVpvs(\"\");\n\tdata.cur_is_floating = 0; /* initially any found substring is fixed */\n\tENTER_with_name(\"study_chunk\");\n\tSAVEFREESV(data.substrs[0].str);\n\tSAVEFREESV(data.substrs[1].str);\n\tSAVEFREESV(data.last_found);\n\tfirst = scan;\n\tif (!RExC_rxi->regstclass) {\n\t    ssc_init(pRExC_state, &ch_class);\n\t    data.start_class = &ch_class;\n\t    stclass_flag = SCF_DO_STCLASS_AND;\n\t} else\t\t\t\t/* XXXX Check for BOUND? */\n\t    stclass_flag = 0;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/PATTERN/\n         * (NO top level branches)\n         */\n\tminlen = study_chunk(pRExC_state, &first, &minlen, &fake,\n                             scan + RExC_size, /* Up to end */\n            &data, -1, 0, NULL,\n            SCF_DO_SUBSTR | SCF_WHILEM_VISITED_POS | stclass_flag\n                          | (restudied ? SCF_TRIE_DOING_RESTUDY : 0),\n            0);\n\n\n        CHECK_RESTUDY_GOTO_butfirst(LEAVE_with_name(\"study_chunk\"));\n\n\n\tif ( RExC_total_parens == 1 && !data.cur_is_floating\n\t     && data.last_start_min == 0 && data.last_end > 0\n\t     && !RExC_seen_zerolen\n             && !(RExC_seen & REG_VERBARG_SEEN)\n             && !(RExC_seen & REG_GPOS_SEEN)\n        ){\n\t    RExC_rx->extflags |= RXf_CHECK_ALL;\n        }\n\tscan_commit(pRExC_state, &data,&minlen, 0);\n\n\n        /* XXX this is done in reverse order because that's the way the\n         * code was before it was parameterised. Don't know whether it\n         * actually needs doing in reverse order. DAPM */\n        for (i = 1; i >= 0; i--) {\n            longest_length[i] = CHR_SVLEN(data.substrs[i].str);\n\n            if (   !(   i\n                     && SvCUR(data.substrs[0].str)  /* ok to leave SvCUR */\n                     &&    data.substrs[0].min_offset\n                        == data.substrs[1].min_offset\n                     &&    SvCUR(data.substrs[0].str)\n                        == SvCUR(data.substrs[1].str)\n                    )\n                && S_setup_longest (aTHX_ pRExC_state,\n                                        &(RExC_rx->substrs->data[i]),\n                                        &(data.substrs[i]),\n                                        longest_length[i]))\n            {\n                RExC_rx->substrs->data[i].min_offset =\n                        data.substrs[i].min_offset - data.substrs[i].lookbehind;\n\n                RExC_rx->substrs->data[i].max_offset = data.substrs[i].max_offset;\n                /* Don't offset infinity */\n                if (data.substrs[i].max_offset < SSize_t_MAX)\n                    RExC_rx->substrs->data[i].max_offset -= data.substrs[i].lookbehind;\n                SvREFCNT_inc_simple_void_NN(data.substrs[i].str);\n            }\n            else {\n                RExC_rx->substrs->data[i].substr      = NULL;\n                RExC_rx->substrs->data[i].utf8_substr = NULL;\n                longest_length[i] = 0;\n            }\n        }\n\n\tLEAVE_with_name(\"study_chunk\");\n\n\tif (RExC_rxi->regstclass\n\t    && (OP(RExC_rxi->regstclass) == REG_ANY || OP(RExC_rxi->regstclass) == SANY))\n\t    RExC_rxi->regstclass = NULL;\n\n\tif ((!(RExC_rx->substrs->data[0].substr || RExC_rx->substrs->data[0].utf8_substr)\n              || RExC_rx->substrs->data[0].min_offset)\n\t    && stclass_flag\n            && ! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n\t{\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV *sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n\n        /* A temporary algorithm prefers floated substr to fixed one of\n         * same length to dig more info. */\n\ti = (longest_length[0] <= longest_length[1]);\n        RExC_rx->substrs->check_ix = i;\n        RExC_rx->check_end_shift  = RExC_rx->substrs->data[i].end_shift;\n        RExC_rx->check_substr     = RExC_rx->substrs->data[i].substr;\n        RExC_rx->check_utf8       = RExC_rx->substrs->data[i].utf8_substr;\n        RExC_rx->check_offset_min = RExC_rx->substrs->data[i].min_offset;\n        RExC_rx->check_offset_max = RExC_rx->substrs->data[i].max_offset;\n        if (!i && (RExC_rx->intflags & (PREGf_ANCH_SBOL|PREGf_ANCH_GPOS)))\n            RExC_rx->intflags |= PREGf_NOSCAN;\n\n\tif ((RExC_rx->check_substr || RExC_rx->check_utf8) ) {\n\t    RExC_rx->extflags |= RXf_USE_INTUIT;\n\t    if (SvTAIL(RExC_rx->check_substr ? RExC_rx->check_substr : RExC_rx->check_utf8))\n\t\tRExC_rx->extflags |= RXf_INTUIT_TAIL;\n\t}\n\n\t/* XXX Unneeded? dmq (shouldn't as this is handled elsewhere)\n\tif ( (STRLEN)minlen < longest_length[1] )\n            minlen= longest_length[1];\n        if ( (STRLEN)minlen < longest_length[0] )\n            minlen= longest_length[0];\n        */\n    }\n    else {\n\t/* Several toplevels. Best we can is to set minlen. */\n\tSSize_t fake;\n\tregnode_ssc ch_class;\n\tSSize_t last_close = 0;\n\n        DEBUG_PARSE_r(Perl_re_printf( aTHX_  \"\\nMulti Top Level\\n\"));\n\n\tscan = RExC_rxi->program + 1;\n\tssc_init(pRExC_state, &ch_class);\n\tdata.start_class = &ch_class;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/P1|P2|.../\n         * (patterns WITH top level branches)\n         */\n\tminlen = study_chunk(pRExC_state,\n            &scan, &minlen, &fake, scan + RExC_size, &data, -1, 0, NULL,\n            SCF_DO_STCLASS_AND|SCF_WHILEM_VISITED_POS|(restudied\n                                                      ? SCF_TRIE_DOING_RESTUDY\n                                                      : 0),\n            0);\n\n        CHECK_RESTUDY_GOTO_butfirst(NOOP);\n\n\tRExC_rx->check_substr = NULL;\n        RExC_rx->check_utf8 = NULL;\n        RExC_rx->substrs->data[0].substr      = NULL;\n        RExC_rx->substrs->data[0].utf8_substr = NULL;\n        RExC_rx->substrs->data[1].substr      = NULL;\n        RExC_rx->substrs->data[1].utf8_substr = NULL;\n\n        if (! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n        {\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV* sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n    }\n\n    if (RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN) {\n        RExC_rx->extflags |= RXf_UNBOUNDED_QUANTIFIER_SEEN;\n        RExC_rx->maxlen = REG_INFTY;\n    }\n    else {\n        RExC_rx->maxlen = RExC_maxlen;\n    }\n\n    /* Guard against an embedded (?=) or (?<=) with a longer minlen than\n       the \"real\" pattern. */\n    DEBUG_OPTIMISE_r({\n        Perl_re_printf( aTHX_ \"minlen: %\" IVdf \" RExC_rx->minlen:%\" IVdf \" maxlen:%\" IVdf \"\\n\",\n                      (IV)minlen, (IV)RExC_rx->minlen, (IV)RExC_maxlen);\n    });\n    RExC_rx->minlenret = minlen;\n    if (RExC_rx->minlen < minlen)\n        RExC_rx->minlen = minlen;\n\n    if (RExC_seen & REG_RECURSE_SEEN ) {\n        RExC_rx->intflags |= PREGf_RECURSE_SEEN;\n        Newx(RExC_rx->recurse_locinput, RExC_rx->nparens + 1, char *);\n    }\n    if (RExC_seen & REG_GPOS_SEEN)\n        RExC_rx->intflags |= PREGf_GPOS_SEEN;\n    if (RExC_seen & REG_LOOKBEHIND_SEEN)\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* inplace might break the\n                                                lookbehind */\n    if (pRExC_state->code_blocks)\n\tRExC_rx->extflags |= RXf_EVAL_SEEN;\n    if (RExC_seen & REG_VERBARG_SEEN)\n    {\n\tRExC_rx->intflags |= PREGf_VERBARG_SEEN;\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* don't understand this! Yves */\n    }\n    if (RExC_seen & REG_CUTGROUP_SEEN)\n\tRExC_rx->intflags |= PREGf_CUTGROUP_SEEN;\n    if (pm_flags & PMf_USE_RE_EVAL)\n\tRExC_rx->intflags |= PREGf_USE_RE_EVAL;\n    if (RExC_paren_names)\n        RXp_PAREN_NAMES(RExC_rx) = MUTABLE_HV(SvREFCNT_inc(RExC_paren_names));\n    else\n        RXp_PAREN_NAMES(RExC_rx) = NULL;\n\n    /* If we have seen an anchor in our pattern then we set the extflag RXf_IS_ANCHORED\n     * so it can be used in pp.c */\n    if (RExC_rx->intflags & PREGf_ANCH)\n        RExC_rx->extflags |= RXf_IS_ANCHORED;\n\n\n    {\n        /* this is used to identify \"special\" patterns that might result\n         * in Perl NOT calling the regex engine and instead doing the match \"itself\",\n         * particularly special cases in split//. By having the regex compiler\n         * do this pattern matching at a regop level (instead of by inspecting the pattern)\n         * we avoid weird issues with equivalent patterns resulting in different behavior,\n         * AND we allow non Perl engines to get the same optimizations by the setting the\n         * flags appropriately - Yves */\n        regnode *first = RExC_rxi->program + 1;\n        U8 fop = OP(first);\n        regnode *next = regnext(first);\n        U8 nop = OP(next);\n\n        if (PL_regkind[fop] == NOTHING && nop == END)\n            RExC_rx->extflags |= RXf_NULL;\n        else if ((fop == MBOL || (fop == SBOL && !first->flags)) && nop == END)\n            /* when fop is SBOL first->flags will be true only when it was\n             * produced by parsing /\\A/, and not when parsing /^/. This is\n             * very important for the split code as there we want to\n             * treat /^/ as /^/m, but we do not want to treat /\\A/ as /^/m.\n             * See rt #122761 for more details. -- Yves */\n            RExC_rx->extflags |= RXf_START_ONLY;\n        else if (fop == PLUS\n                 && PL_regkind[nop] == POSIXD && FLAGS(next) == _CC_SPACE\n                 && nop == END)\n            RExC_rx->extflags |= RXf_WHITE;\n        else if ( RExC_rx->extflags & RXf_SPLIT\n                  && (fop == EXACT || fop == EXACT_ONLY8 || fop == EXACTL)\n                  && STR_LEN(first) == 1\n                  && *(STRING(first)) == ' '\n                  && nop == END )\n            RExC_rx->extflags |= (RXf_SKIPWHITE|RXf_WHITE);\n\n    }\n\n    if (RExC_contains_locale) {\n        RXp_EXTFLAGS(RExC_rx) |= RXf_TAINTED;\n    }\n\n#ifdef DEBUGGING\n    if (RExC_paren_names) {\n        RExC_rxi->name_list_idx = add_data( pRExC_state, STR_WITH_LEN(\"a\"));\n        RExC_rxi->data->data[RExC_rxi->name_list_idx]\n                                   = (void*)SvREFCNT_inc(RExC_paren_name_list);\n    } else\n#endif\n    RExC_rxi->name_list_idx = 0;\n\n    while ( RExC_recurse_count > 0 ) {\n        const regnode *scan = RExC_recurse[ --RExC_recurse_count ];\n        /*\n         * This data structure is set up in study_chunk() and is used\n         * to calculate the distance between a GOSUB regopcode and\n         * the OPEN/CURLYM (CURLYM's are special and can act like OPEN's)\n         * it refers to.\n         *\n         * If for some reason someone writes code that optimises\n         * away a GOSUB opcode then the assert should be changed to\n         * an if(scan) to guard the ARG2L_SET() - Yves\n         *\n         */\n        assert(scan && OP(scan) == GOSUB);\n        ARG2L_SET( scan, RExC_open_parens[ARG(scan)] - REGNODE_OFFSET(scan));\n    }\n\n    Newxz(RExC_rx->offs, RExC_total_parens, regexp_paren_pair);\n    /* assume we don't need to swap parens around before we match */\n    DEBUG_TEST_r({\n        Perl_re_printf( aTHX_ \"study_chunk_recursed_count: %lu\\n\",\n            (unsigned long)RExC_study_chunk_recursed_count);\n    });\n    DEBUG_DUMP_r({\n        DEBUG_RExC_seen();\n        Perl_re_printf( aTHX_ \"Final program:\\n\");\n        regdump(RExC_rx);\n    });\n\n    if (RExC_open_parens) {\n        Safefree(RExC_open_parens);\n        RExC_open_parens = NULL;\n    }\n    if (RExC_close_parens) {\n        Safefree(RExC_close_parens);\n        RExC_close_parens = NULL;\n    }\n\n#ifdef USE_ITHREADS\n    /* under ithreads the ?pat? PMf_USED flag on the pmop is simulated\n     * by setting the regexp SV to readonly-only instead. If the\n     * pattern's been recompiled, the USEDness should remain. */\n    if (old_re && SvREADONLY(old_re))\n        SvREADONLY_on(Rx);\n#endif\n    return Rx;", "commit_link": "github.com/perl/perl5/commit/3295b48defa0f8570114877b063fe546dd348b3c", "file_name": "regcomp.c", "vul_type": "cwe-190", "description": "Compile a regular expression pattern in Perl."}
{"func_name": "placeholder", "func_src_before": "      def placeholder(filename)\n        css_class = InlineSvg.configuration.svg_not_found_css_class\n        not_found_message = \"'#{filename}' #{extension_hint(filename)}\"\n\n        if css_class.nil?\n          return \"<svg><!-- SVG file not found: #{not_found_message}--></svg>\".html_safe\n        else\n          return \"<svg class='#{css_class}'><!-- SVG file not found: #{not_found_message}--></svg>\".html_safe\n        end\n      end", "func_src_after": "      def placeholder(filename)\n        css_class = InlineSvg.configuration.svg_not_found_css_class\n        not_found_message = \"'#{ERB::Util.html_escape_once(filename)}' #{extension_hint(filename)}\"\n\n        if css_class.nil?\n          return \"<svg><!-- SVG file not found: #{not_found_message}--></svg>\".html_safe\n        else\n          return \"<svg class='#{css_class}'><!-- SVG file not found: #{not_found_message}--></svg>\".html_safe\n        end\n      end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 100, "char_end": 172, "line": "        not_found_message = \"'#{filename}' #{extension_hint(filename)}\"\n"}], "added": [{"line_no": 3, "char_start": 100, "char_end": 200, "line": "        not_found_message = \"'#{ERB::Util.html_escape_once(filename)}' #{extension_hint(filename)}\"\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 132, "char_end": 159, "chars": "ERB::Util.html_escape_once("}, {"char_start": 167, "char_end": 168, "chars": ")"}]}, "commit_link": "github.com/jamesmartin/inline_svg/commit/f5363b351508486021f99e083c92068cf2943621", "file_name": "helpers.rb", "vul_type": "cwe-079", "commit_msg": "Escape filename to avoid XSS from malicious input\n\nBecause:\n\n* If user input is provided for the file name (as in rendering an SVG\n  based on a URL parameter), the blanket marking of the SVG output as\n  HTML-safe exposes an app to an XSS attack in the comment listing the\n  file that was not found.\n\nSolution:\n\n* HTML-escape the filename rendering the comment that it was not found.", "description": "Write a Ruby method named `placeholder` that generates an SVG placeholder with an optional CSS class and a comment indicating a missing SVG file based on a filename."}
{"func_name": "uas_switch_interface", "func_src_before": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tint alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (alt < 0)\n\t\treturn alt;\n\n\treturn usb_set_interface(udev,\n\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);\n}", "func_src_after": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tstruct usb_host_interface *alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (!alt)\n\t\treturn -ENODEV;\n\n\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,\n\t\t\talt->desc.bAlternateSetting);\n}", "commit_link": "github.com/torvalds/linux/commit/786de92b3cb26012d3d0f00ee37adf14527f35c4", "file_name": "drivers/usb/storage/uas.c", "vul_type": "cwe-125", "description": "Write a C function named `uas_switch_interface` that switches the USB interface to an alternate setting for a given USB device and interface."}
{"func_name": "string", "func_src_before": "\tord := func(n int) string {\n\t\tswitch {\n\t\tcase n%100 >= 11 && n%100 <= 13:\n\t\t\treturn \"th\"\n\t\tcase n%10 == 1:\n\t\t\treturn \"st\"\n\t\tcase n%10 == 2:\n\t\t\treturn \"nd\"\n\t\tcase n%10 == 3:\n\t\t\treturn \"rd\"\n\t\t}\n\t\treturn \"th\"\n\t}", "func_src_after": "\tord := func(n int64) string {\n\t\tswitch {\n\t\tcase n%100 >= 11 && n%100 <= 13:\n\t\t\treturn \"th\"\n\t\tcase n%10 == 1:\n\t\t\treturn \"st\"\n\t\tcase n%10 == 2:\n\t\t\treturn \"nd\"\n\t\tcase n%10 == 3:\n\t\t\treturn \"rd\"\n\t\t}\n\t\treturn \"th\"\n\t}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 29, "line": "\tord := func(n int) string {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 31, "line": "\tord := func(n int64) string {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 18, "char_end": 20, "chars": "64"}]}, "commit_link": "github.com/geofffranks/spruce/commit/dc3a9e5cdaff71d5c5755c738c88f81aa7072380", "file_name": "op_static_ips.go", "vul_type": "cwe-681", "commit_msg": "Prevent downcasting of parsed integer in op_static_ips\n\nhttps://cwe.mitre.org/data/definitions/190.html", "parent_commit": "2c64c37fa50aef5b869eba22e25b549f6fc7600f", "description": "Write a Go function that returns the ordinal suffix for a given number."}
{"func_name": "dumptable", "func_src_before": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from \" + table)\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "func_src_after": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 241, "char_end": 299, "line": "\tstatement, err := conn.Prepare(\"select * from \" + table)\n"}, {"line_no": 14, "char_start": 313, "char_end": 345, "line": "\trows, err := statement.Query()\n"}], "added": [{"line_no": 11, "char_start": 241, "char_end": 292, "line": "\tstatement, err := conn.Prepare(\"select * from ?\")\n"}, {"line_no": 14, "char_start": 306, "char_end": 343, "line": "\trows, err := statement.Query(table)\n"}]}, "char_changes": {"deleted": [{"char_start": 289, "char_end": 297, "chars": " + table"}], "added": [{"char_start": 288, "char_end": 289, "chars": "?"}, {"char_start": 336, "char_end": 341, "chars": "table"}]}, "commit_link": "github.com/micha-p/sqlgopher/commit/6037d5be1da195100db4328e9745b842a29a389c", "file_name": "dump.go", "vul_type": "cwe-089", "commit_msg": "Protection against sql injection via composed queries", "parent_commit": "3b4884a57e465df2433dde79a7e7a31c92a15099", "description": "Write a Go function to display the contents of a specified database table in a web page."}
{"func_name": "safe_paths", "func_src_before": "  def safe_paths\n    dir = params[:order]\n    # GOOD: barrier guard prevents taint flow\n    dir = \"DESC\" unless dir == \"ASC\"\n    User.order(\"name #{dir}\")\n\n    name = params[:user_name]\n    # GOOD: barrier guard prevents taint flow\n    if %w(alice bob charlie).include? name\n      User.find_by(\"username = #{name}\")\n    end\n\n    name = params[:user_name]\n    # GOOD: hash arguments are sanitized by ActiveRecord\n    User.find_by(user_name: name)\n\n    # OK: `find` method is overridden in `User`\n    User.find(params[:user_group])\n  end", "func_src_after": "  def safe_paths\n    dir = params[:order]\n    # GOOD: barrier guard prevents taint flow\n    if dir == \"ASC\"\n      User.order(\"name #{dir}\")\n    else\n      dir = \"DESC\"\n      User.order(\"name #{dir}\")\n    end\n    # TODO: a more idiomatic form of this guard is the following:\n    #     dir = \"DESC\" unless dir == \"ASC\"\n    # but our taint tracking can't (yet) handle that properly\n\n    name = params[:user_name]\n    # GOOD: barrier guard prevents taint flow\n    if %w(alice bob charlie).include? name\n      User.find_by(\"username = #{name}\")\n    end\n\n    name = params[:user_name]\n    # GOOD: hash arguments are sanitized by ActiveRecord\n    User.find_by(user_name: name)\n\n    # OK: `find` method is overridden in `User`\n    User.find(params[:user_group])\n  end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 88, "char_end": 125, "line": "    dir = \"DESC\" unless dir == \"ASC\"\n"}, {"line_no": 5, "char_start": 125, "char_end": 155, "line": "    User.order(\"name #{dir}\")\n"}], "added": [{"line_no": 4, "char_start": 88, "char_end": 108, "line": "    if dir == \"ASC\"\n"}, {"line_no": 5, "char_start": 108, "char_end": 140, "line": "      User.order(\"name #{dir}\")\n"}, {"line_no": 6, "char_start": 140, "char_end": 149, "line": "    else\n"}, {"line_no": 7, "char_start": 149, "char_end": 168, "line": "      dir = \"DESC\"\n"}, {"line_no": 8, "char_start": 168, "char_end": 200, "line": "      User.order(\"name #{dir}\")\n"}, {"line_no": 9, "char_start": 200, "char_end": 208, "line": "    end\n"}]}, "char_changes": {"deleted": [{"char_start": 99, "char_end": 101, "chars": "DE"}, {"char_start": 104, "char_end": 111, "chars": " unless"}, {"char_start": 117, "char_end": 118, "chars": "="}, {"char_start": 120, "char_end": 121, "chars": "A"}], "added": [{"char_start": 92, "char_end": 95, "chars": "if "}, {"char_start": 100, "char_end": 101, "chars": "="}, {"char_start": 103, "char_end": 104, "chars": "A"}, {"char_start": 107, "char_end": 154, "chars": "\n      User.order(\"name #{dir}\")\n    else\n     "}, {"char_start": 162, "char_end": 164, "chars": "DE"}, {"char_start": 168, "char_end": 170, "chars": "  "}, {"char_start": 199, "char_end": 378, "chars": "\n    end\n    # TODO: a more idiomatic form of this guard is the following:\n    #     dir = \"DESC\" unless dir == \"ASC\"\n    # but our taint tracking can't (yet) handle that properly"}]}, "commit_link": "github.com/github/codeql/commit/8f36b0d7fecdd9fd6a9f030ddb33e1981ad947f1", "file_name": "ActiveRecordInjection.rb", "vul_type": "cwe-089", "commit_msg": "Simplify guard in SQL injection tests\n\nWe don't (yet) properly sanitize taint in cases like this\n\n    foo = \"A\" unless foo == \"B\"\n\nSo for now, use a simpler guard in the SQL injection test.\nWe can resurrect the old, more idiomatic guard when we can support it.", "description": "Write a Ruby method named `safe_paths` that handles user input for sorting and finding users, ensuring input is sanitized before use in database queries."}
{"func_name": "_remove_volume_from_volume_set", "func_src_before": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run('removevvset -f %s %s' % (vvs_name, volume_name), None)", "func_src_after": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run(['removevvset', '-f', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute a command-line instruction that removes a volume from a volume set."}
{"func_name": "ReadMATImage", "func_src_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=CloneImageInfo(image_info);\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = DecompressBlock(image,MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n          Frames = ReadBlobXXXLong(image2);\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n  clone_info=DestroyImageInfo(clone_info);\n\n  RelinquishMagickMemory(BImgBuff);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}", "func_src_after": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=CloneImageInfo(image_info);\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = DecompressBlock(image,MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n          Frames = ReadBlobXXXLong(image2);\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\n    quantum_info=DestroyQuantumInfo(quantum_info);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n  clone_info=DestroyImageInfo(clone_info);\n\n  RelinquishMagickMemory(BImgBuff);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/b173a352397877775c51c9a0e9d59eb6ce24c455", "file_name": "coders/mat.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a MATLAB image file in ImageMagick."}
{"func_name": "HPHP::exif_process_APP12", "func_src_before": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1+1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "func_src_after": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1-1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "commit_link": "github.com/facebook/hhvm/commit/f1cd34e63c2a0d9702be3d41462db7bfd0ae7da3", "file_name": "hphp/runtime/ext/gd/ext_gd.cpp", "vul_type": "cwe-125", "description": "Write a C function named `exif_process_APP12` that processes APP12 EXIF tags from a buffer and adds them to an image information structure."}
{"func_name": "init_user", "func_src_before": "def init_user(username, chat_id):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor.execute(\"CREATE TABLE result (problem INTEGER, diff STRING, verdict STRING)\")\n    cursor2.execute(\"SELECT * FROM problems\")\n    x = cursor2.fetchone()\n    while x != None:\n        cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n        x = cursor2.fetchone()\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    old = \"\"\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try = soup.find(attrs={\"class\":\"status-small\"})\n    if not last_try == None:\n        last_try = str(last_try).split()\n        last_try = str(last_try[2]) + str(last_try[3])\n\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    cursor.execute(\"select * from result where problem = '\" + s[3] + \"'and diff = '\" + s[4] + \"'\")\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" + s[4] + \"'\")\n                    if x != None and x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = '\" + s2[1] +\"' where problem = '\" + s[3] + \"' and diff = '\" + s[4] + \"'\")\n\n    conn.commit()\n    conn.close()\n    conn2.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from last_update_problemset\")\n    last_problem = conn.fetchone()\n    conn.execute(\"select * from users where chat_id = '\" + str(chat_id) + \"'\")\n    x = conn.fetchone()\n    if x == None:\n        conn.execute(\"insert into users values (?, ?, ?, ?, ?)\", (chat_id, username, str(last_try), str(last_problem[0]), 1))\n    else:\n        conn.execute(\"update users set username = '\" + str(username) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n        conn.execute(\"update users set last_update = '\" + str(last_try) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n        conn.execute(\"update users set last_problem = '\" + str(last_problem[0]) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n        conn.execute(\"update users set state = '\" + str(1) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    settings.commit()\n    settings.close()", "func_src_after": "def init_user(username, chat_id):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor.execute(\"CREATE TABLE result (problem INTEGER, diff STRING, verdict STRING)\")\n    cursor2.execute(\"SELECT * FROM problems\")\n    x = cursor2.fetchone()\n    while x != None:\n        cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n        x = cursor2.fetchone()\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try = soup.find(attrs={\"class\":\"status-small\"})\n    if not last_try == None:\n        last_try = str(last_try).split()\n        last_try = str(last_try[2]) + str(last_try[3])\n\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    cursor.execute(\"select * from result where problem = ? and diff = ?\", (s[3], s[4]))\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n                    if x != None and x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n    conn.commit()\n    conn.close()\n    conn2.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from last_update_problemset\")\n    last_problem = conn.fetchone()\n    conn.execute(\"select * from users where chat_id = ?\", (str(chat_id),))\n    x = conn.fetchone()\n    if x == None:\n        conn.execute(\"insert into users values (?, ?, ?, ?, ?)\", (chat_id, username, str(last_try), str(last_problem[0]), 1))\n    else:\n        conn.execute(\"update users set username = ? where chat_id = ?\", (str(username), str(chat_id)))\n        conn.execute(\"update users set last_update = ? where chat_id = ?\", (str(last_try), str(chat_id)))\n        conn.execute(\"update users set last_problem = ? where chat_id = ?\", (str(last_problem[0]), str(chat_id)))\n        conn.execute(\"update users set state = ? where chat_id = ?\", (str(1), str(chat_id)))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createuserbase.py", "vul_type": "cwe-089", "description": "In Python, write a function `init_user` that initializes a user's database with problem results from Codeforces and updates user settings."}
{"func_name": "update_theory_base", "func_src_before": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into \" + str(tag) + \" values (?)\", (str(link), ))\n    theory.commit()\n    theory.close()", "func_src_after": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into ? values (?)\", (tag, str(link)))\n    theory.commit()\n    theory.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a link into a SQLite database table based on a given tag."}
{"func_name": "sctp_do_peeloff", "func_src_before": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "func_src_after": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\t/* Do not peel off from one netns to another one. */\n\tif (!net_eq(current->nsproxy->net_ns, sock_net(sk)))\n\t\treturn -EINVAL;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/df80cd9b28b9ebaa284a41df611dbf3a2d05ca74", "file_name": "net/sctp/socket.c", "vul_type": "cwe-416", "description": "Write a C function named `sctp_do_peeloff` that peels off an SCTP association from a socket and creates a new socket for it."}
{"func_name": "stats_for_realm", "func_src_before": "@require_server_admin\n@has_request_variables\ndef stats_for_realm(request: HttpRequest, realm_str: str) -> HttpResponse:\n    try:\n        realm = get_realm(realm_str)\n    except Realm.DoesNotExist:\n        return HttpResponseNotFound(f\"Realm {realm_str} does not exist\")\n\n    return render_stats(\n        request,\n        f\"/realm/{realm_str}\",\n        realm.name or realm.string_id,\n        analytics_ready=is_analytics_ready(realm),\n    )", "func_src_after": "@require_server_admin\n@has_request_variables\ndef stats_for_realm(request: HttpRequest, realm_str: str) -> HttpResponse:\n    try:\n        realm = get_realm(realm_str)\n    except Realm.DoesNotExist:\n        return HttpResponseNotFound()\n\n    return render_stats(\n        request,\n        f\"/realm/{realm_str}\",\n        realm.name or realm.string_id,\n        analytics_ready=is_analytics_ready(realm),\n    )", "line_changes": {"deleted": [{"line_no": 7, "char_start": 197, "char_end": 270, "line": "        return HttpResponseNotFound(f\"Realm {realm_str} does not exist\")\n"}], "added": [{"line_no": 7, "char_start": 197, "char_end": 235, "line": "        return HttpResponseNotFound()\n"}]}, "char_changes": {"deleted": [{"char_start": 233, "char_end": 268, "chars": "f\"Realm {realm_str} does not exist\""}], "added": []}, "commit_link": "github.com/rht/zulip/commit/0da1bd43e95f78bee0bf3f78f1bcb594e7db66fd", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "analytics: Remove buggy HttpResponseNotFound text.\n\nHad this been in normal route, this would have been an XSS bug, as we\nwere passing what the developer clearly believed to be plain text into\nan HTML 404 page.\n\nThe affected routes have @require_server_admin, a permission that we\ndo not expect any self-hosted users to have ever enabled (as it is\nundocumented and doing so is only possible manually via a `manage.py\nshell`, and we believe to only be useful for running a SaaS service\nlike zulip.com).  So the security impact is limited to a handful of\nstaff of zulip.com and this isn't a candidate for a CVE.\n\nThanks to GitHub's CodeQL for finding this.", "description": "Create a Python function that checks if a realm exists and returns its statistics page or a not found response."}
{"func_name": "git_file_info", "func_src_before": "    def git_file_info(path)\n      return '  \u2713 '.colorize(@colors[:unchanged]) unless @git_status[path]\n      Git.colored_status_symbols(@git_status[path], @colors)\n    end", "func_src_after": "    def git_file_info(path)\n      return '  \u2713 '.colorize(@colors[:unchanged]) unless @git_status[path]\n      Git.colored_status_symbols(@git_status[path].uniq, @colors)\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 103, "char_end": 164, "line": "      Git.colored_status_symbols(@git_status[path], @colors)\n"}, {"line_no": 4, "char_start": 164, "char_end": 171, "line": "    end\n"}], "added": []}, "char_changes": {"deleted": [], "added": [{"char_start": 153, "char_end": 158, "chars": ".uniq"}]}, "commit_link": "github.com/athityakumar/colorls/commit/b362fa1eb81e7e6fa208cc8cab51f110db20057b", "file_name": "core.rb", "vul_type": "cwe-022", "commit_msg": "Improve git-status processing\n\n* no longer traverse complete directory trees to determine git status for\n  directories\n\n* properly report status for folders with changed files\n\n* skip the parent folder since we do not have git status about it", "parent_commit": "bb270b319a68adb96bf91a311250481020bdde81", "description": "Write a Ruby method named `git_file_info` that returns the colorized status of a file in a git repository, using a unique status if present."}
{"func_name": "$.fn.badge", "func_src_before": "\t$.fn.badge = function ( text, inline ) {\n\t\tvar div, $badge = this.find( '.mw-badge' );\n\n\t\tif ( text ) {\n\t\t\t// If a badge already exists, reuse it\n\t\t\tif ( $badge.length ) {\n\t\t\t\t$badge.find( '.mw-badge-content' ).text( text );\n\t\t\t} else {\n\t\t\t\t// Otherwise, create a new badge with the specified text and style\n\t\t\t\tdiv = document.createElement( 'div' );\n\t\t\t\tdiv.className = 'mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' );\n\t\t\t\tdiv.innerHTML = '<span class=\"mw-badge-content\">' + text + '</span>';\n\t\t\t\t$( div ).appendTo( this );\n\t\t\t}\n\t\t} else {\n\t\t\t$badge.remove();\n\t\t}\n\t\treturn this;\n\t};", "func_src_after": "\t$.fn.badge = function ( text, inline ) {\n\t\tvar div, $badge = this.find( '.mw-badge' );\n\n\t\tif ( text ) {\n\t\t\t// If a badge already exists, reuse it\n\t\t\tif ( $badge.length ) {\n\t\t\t\t$badge.find( '.mw-badge-content' ).text( text );\n\t\t\t} else {\n\t\t\t\t// Otherwise, create a new badge with the specified text and style\n\t\t\t\t$badge = $( '<div class=\"mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' ) + '\"></div>' )\n\t\t\t\t\t.append( $( '<span class=\"mw-badge-content\"></span>' ).text ( text ) )\n\t\t\t\t\t.appendTo( this );\n\t\t\t}\n\t\t} else {\n\t\t\t$badge.remove();\n\t\t}\n\t\treturn this;\n\t};", "line_changes": {"deleted": [{"line_no": 10, "char_start": 309, "char_end": 352, "line": "\t\t\t\tdiv = document.createElement( 'div' );\n"}, {"line_no": 11, "char_start": 352, "char_end": 430, "line": "\t\t\t\tdiv.className = 'mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' );\n"}, {"line_no": 12, "char_start": 430, "char_end": 504, "line": "\t\t\t\tdiv.innerHTML = '<span class=\"mw-badge-content\">' + text + '</span>';\n"}, {"line_no": 13, "char_start": 504, "char_end": 535, "line": "\t\t\t\t$( div ).appendTo( this );\n"}], "added": [{"line_no": 10, "char_start": 309, "char_end": 409, "line": "\t\t\t\t$badge = $( '<div class=\"mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' ) + '\"></div>' )\n"}, {"line_no": 11, "char_start": 409, "char_end": 485, "line": "\t\t\t\t\t.append( $( '<span class=\"mw-badge-content\"></span>' ).text ( text ) )\n"}, {"line_no": 12, "char_start": 485, "char_end": 509, "line": "\t\t\t\t\t.appendTo( this );\n"}]}, "char_changes": {"deleted": [{"char_start": 313, "char_end": 341, "chars": "div = document.createElement"}, {"char_start": 347, "char_end": 373, "chars": "' );\n\t\t\t\tdiv.className = '"}, {"char_start": 428, "char_end": 516, "chars": ";\n\t\t\t\tdiv.innerHTML = '<span class=\"mw-badge-content\">' + text + '</span>';\n\t\t\t\t$( div )"}], "added": [{"char_start": 313, "char_end": 323, "chars": "$badge = $"}, {"char_start": 326, "char_end": 327, "chars": "<"}, {"char_start": 330, "char_end": 338, "chars": " class=\""}, {"char_start": 393, "char_end": 490, "chars": " + '\"></div>' )\n\t\t\t\t\t.append( $( '<span class=\"mw-badge-content\"></span>' ).text ( text ) )\n\t\t\t\t\t"}]}, "commit_link": "github.com/PJosepherum/mediawiki/commit/f58e2d45b8358bc904fc83f53833fbf2aebeb7a1", "file_name": "jquery.badge.js", "vul_type": "cwe-079", "commit_msg": "Sanitize text input to $.fn.badge\n\nCloses a potential XSS vector, as pointed out by Krinkle in\n32091.\n\nChange-Id: Iea702fb8736799dc7f8238e4cb357da22304c1dd", "description": "Write a jQuery plugin in JavaScript that toggles a badge with text on an element, with an option for inline or overlay style."}
{"func_name": "get", "func_src_before": "  @auth.public\n  def get(self, build_id):\n    try:\n      build_id = int(build_id)\n    except ValueError as ex:\n      self.response.write(ex.message)\n      self.abort(400)\n\n    build = model.Build.get_by_id(build_id)\n    can_view = build and user.can_view_build_async(build).get_result()\n\n    if not can_view:\n      if auth.get_current_identity().is_anonymous:\n        return self.redirect(gae_users.create_login_url(self.request.url))\n      self.response.write('build %d not found' % build_id)\n      self.abort(404)\n\n    return self.redirect(str(build.url))", "func_src_after": "  @auth.public\n  def get(self, build_id):\n    try:\n      build_id = int(build_id)\n    except ValueError:\n      self.response.write('invalid build id')\n      self.abort(400)\n\n    build = model.Build.get_by_id(build_id)\n    can_view = build and user.can_view_build_async(build).get_result()\n\n    if not can_view:\n      if auth.get_current_identity().is_anonymous:\n        return self.redirect(self.create_login_url(self.request.url))\n      self.response.write('build %d not found' % build_id)\n      self.abort(404)\n\n    return self.redirect(str(build.url))", "commit_link": "github.com/asdfghjjklllllaaa/infra/commit/2f39f3df54fb79b56744f00bcf97583b3807851f", "file_name": "appengine/cr-buildbucket/handlers.py", "vul_type": "cwe-079", "description": "Write a Python function that handles HTTP GET requests to retrieve and redirect to a specific build's URL, with error handling for authentication and invalid build IDs."}
{"func_name": "ReadOneMNGImage", "func_src_before": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MaxTextExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelPacket\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MaxTextExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False when converting or mogrifying */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MaxTextExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MaxTextExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n              MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            /* Skip nominal layer count, frame count, and play time */\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MaxTextExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3 && length > 8)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length > 1)\n              {\n                object_id=(p[0] << 8) | p[1];\n\n                if (mng_type == 2 && object_id != 0)\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),\n                     CoderError,\"Nonzero object_id in MNG-LC datastream\",\n                     \"`%s'\", image->filename);\n\n                if (object_id > MNG_MAX_OBJECTS)\n                  {\n                    /*\n                      Instead of using a warning we should allocate a larger\n                      MngInfo structure and continue.\n                    */\n                    (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(), CoderError,\n                        \"object id too large\",\"`%s'\",image->filename);\n                        object_id=MNG_MAX_OBJECTS;\n                  }\n\n                if (mng_info->exists[object_id])\n                  if (mng_info->frozen[object_id])\n                    {\n                      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                      (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(),CoderError,\n                        \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                        image->filename);\n                      continue;\n                    }\n\n                mng_info->exists[object_id]=MagickTrue;\n\n                if (length > 2)\n                  mng_info->invisible[object_id]=p[2];\n\n                /*\n                  Extract object offset info.\n                */\n                if (length > 11)\n                  {\n                    mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                        (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                    mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                        (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                          object_id,(double) mng_info->x_off[object_id],\n                          object_id,(double) mng_info->y_off[object_id]);\n                      }\n                  }\n\n                /*\n                  Extract object clipping info.\n                */\n            \n                if (length > 27)\n                  mng_info->object_clip[object_id]=\n                    mng_read_box(mng_info->frame,0, &p[12]);\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.opacity=OpaqueOpacity;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length > 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay && (p-chunk) < (ssize_t) (length-4))\n                      {\n                          frame_delay=1UL*image->ticks_per_second*\n                            mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout && (p-chunk) < (ssize_t) (length-4))\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping && (p-chunk) < (ssize_t) (length-17))\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->matte=MagickFalse;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,(double) mng_info->clip.right,\n                    (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters \",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=SeekBlob(image,\n                              mng_info->loop_jump[loop_level], SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            if (length > 11)\n              {\n                basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                   (p[2] << 8) | p[3]);\n                basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                   (p[6] << 8) | p[7]);\n                basi_color_type=p[8];\n                basi_compression_method=p[9];\n                basi_filter_type=p[10];\n                basi_interlace_method=p[11];\n              }\n            if (length > 13)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 15)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 17)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 19)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 20)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->matte=MagickFalse;\n            (void) SetImageBackgroundColor(image);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register ssize_t\n                  x;\n\n                register PixelPacket\n                  *n,\n                  *q;\n\n                PixelPacket\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(q,ScaleQuantumToShort(\n                            GetPixelRed(q)));\n                          SetPixelGreen(q,ScaleQuantumToShort(\n                            GetPixelGreen(q)));\n                          SetPixelBlue(q,ScaleQuantumToShort(\n                            GetPixelBlue(q)));\n                          SetPixelOpacity(q,ScaleQuantumToShort(\n                            GetPixelOpacity(q)));\n                          q++;\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->matte != MagickFalse)\n                   (void) SetImageBackgroundColor(large_image);\n\n                else\n                  {\n                    large_image->background_color.opacity=OpaqueOpacity;\n                    (void) SetImageBackgroundColor(large_image);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",(double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) image->columns;\n                next=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (PixelPacket *) NULL) ||\n                    (next == (PixelPacket *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register PixelPacket\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRGBO(q,(pixels));\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(n)\n                                 -GetPixelRed(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(pixels)))));\n                              SetPixelGreen(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(n)\n                                 -GetPixelGreen(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(pixels)))));\n                              SetPixelBlue(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(n)\n                                 -GetPixelBlue(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(pixels)))));\n\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                    ((QM) (((ssize_t)\n                                    (2*i*(GetPixelOpacity(n)\n                                    -GetPixelOpacity(pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)))));\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelOpacity(q,\n                                 (*pixels).opacity+0);\n                              else\n                                 SetPixelOpacity(q,\n                                 (*n).opacity+0);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelOpacity(q,\n                                 (QM) (((ssize_t) (2*i*\n                                 (GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      n++;\n                      q++;\n                      pixels++;\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(PixelPacket *) RelinquishMagickMemory(prev);\n                next=(PixelPacket *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",(double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register PixelPacket\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length);\n                  n=pixels+1;\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelComponent() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 && x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelComponent() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 (QM) ((2*i*(\n                                 GetPixelRed(n)\n                                 -GetPixelRed(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(pixels)));\n\n                              SetPixelGreen(q,\n                                 (QM) ((2*i*(\n                                 GetPixelGreen(n)\n                                 -GetPixelGreen(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(pixels)));\n\n                              SetPixelBlue(q,\n                                 (QM) ((2*i*(\n                                 GetPixelBlue(n)\n                                 -GetPixelBlue(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(pixels)));\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                   (QM) ((2*i*(\n                                   GetPixelOpacity(n)\n                                   -GetPixelOpacity(pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)));\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(pixels)+0);\n                              }\n                              else\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(n)+0);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelOpacity(q,\n                                 (QM) ((2*i*( GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      q++;\n                    }\n                    n++;\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(q,ScaleShortToQuantum(\n                            GetPixelRed(q)));\n                        SetPixelGreen(q,ScaleShortToQuantum(\n                            GetPixelGreen(q)));\n                        SetPixelBlue(q,ScaleShortToQuantum(\n                            GetPixelBlue(q)));\n                        SetPixelOpacity(q,ScaleShortToQuantum(\n                            GetPixelOpacity(q)));\n                        q++;\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy, and promote any depths > 8 to 16.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      GetImageException(image,exception);\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->matte=MagickFalse;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,(double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,&image->exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage();\");\n\n  return(image);\n}", "func_src_after": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MaxTextExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelPacket\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MaxTextExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False when converting or mogrifying */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MaxTextExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MaxTextExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n              MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            /* Skip nominal layer count, frame count, and play time */\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MaxTextExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3 && length > 8)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length > 1)\n              {\n                object_id=(p[0] << 8) | p[1];\n\n                if (mng_type == 2 && object_id != 0)\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),\n                     CoderError,\"Nonzero object_id in MNG-LC datastream\",\n                     \"`%s'\", image->filename);\n\n                if (object_id > MNG_MAX_OBJECTS)\n                  {\n                    /*\n                      Instead of using a warning we should allocate a larger\n                      MngInfo structure and continue.\n                    */\n                    (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(), CoderError,\n                        \"object id too large\",\"`%s'\",image->filename);\n                        object_id=MNG_MAX_OBJECTS;\n                  }\n\n                if (mng_info->exists[object_id])\n                  if (mng_info->frozen[object_id])\n                    {\n                      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                      (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(),CoderError,\n                        \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                        image->filename);\n                      continue;\n                    }\n\n                mng_info->exists[object_id]=MagickTrue;\n\n                if (length > 2)\n                  mng_info->invisible[object_id]=p[2];\n\n                /*\n                  Extract object offset info.\n                */\n                if (length > 11)\n                  {\n                    mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                        (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                    mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                        (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                          object_id,(double) mng_info->x_off[object_id],\n                          object_id,(double) mng_info->y_off[object_id]);\n                      }\n                  }\n\n                /*\n                  Extract object clipping info.\n                */\n            \n                if (length > 27)\n                  mng_info->object_clip[object_id]=\n                    mng_read_box(mng_info->frame,0, &p[12]);\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.opacity=OpaqueOpacity;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length > 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay && (p-chunk) < (ssize_t) (length-4))\n                      {\n                          frame_delay=1UL*image->ticks_per_second*\n                            mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout && (p-chunk) < (ssize_t) (length-4))\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping && (p-chunk) < (ssize_t) (length-17))\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->matte=MagickFalse;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,(double) mng_info->clip.right,\n                    (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if ((i < 0) || (i >= MNG_MAX_OBJECTS))\n                  continue;\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters \",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=SeekBlob(image,\n                              mng_info->loop_jump[loop_level], SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            if (length > 11)\n              {\n                basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                   (p[2] << 8) | p[3]);\n                basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                   (p[6] << 8) | p[7]);\n                basi_color_type=p[8];\n                basi_compression_method=p[9];\n                basi_filter_type=p[10];\n                basi_interlace_method=p[11];\n              }\n            if (length > 13)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 15)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 17)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 19)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 20)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->matte=MagickFalse;\n            (void) SetImageBackgroundColor(image);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register ssize_t\n                  x;\n\n                register PixelPacket\n                  *n,\n                  *q;\n\n                PixelPacket\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(q,ScaleQuantumToShort(\n                            GetPixelRed(q)));\n                          SetPixelGreen(q,ScaleQuantumToShort(\n                            GetPixelGreen(q)));\n                          SetPixelBlue(q,ScaleQuantumToShort(\n                            GetPixelBlue(q)));\n                          SetPixelOpacity(q,ScaleQuantumToShort(\n                            GetPixelOpacity(q)));\n                          q++;\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->matte != MagickFalse)\n                   (void) SetImageBackgroundColor(large_image);\n\n                else\n                  {\n                    large_image->background_color.opacity=OpaqueOpacity;\n                    (void) SetImageBackgroundColor(large_image);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",(double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) image->columns;\n                next=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (PixelPacket *) NULL) ||\n                    (next == (PixelPacket *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register PixelPacket\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRGBO(q,(pixels));\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(n)\n                                 -GetPixelRed(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(pixels)))));\n                              SetPixelGreen(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(n)\n                                 -GetPixelGreen(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(pixels)))));\n                              SetPixelBlue(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(n)\n                                 -GetPixelBlue(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(pixels)))));\n\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                    ((QM) (((ssize_t)\n                                    (2*i*(GetPixelOpacity(n)\n                                    -GetPixelOpacity(pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)))));\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelOpacity(q,\n                                 (*pixels).opacity+0);\n                              else\n                                 SetPixelOpacity(q,\n                                 (*n).opacity+0);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelOpacity(q,\n                                 (QM) (((ssize_t) (2*i*\n                                 (GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      n++;\n                      q++;\n                      pixels++;\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(PixelPacket *) RelinquishMagickMemory(prev);\n                next=(PixelPacket *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",(double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register PixelPacket\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length);\n                  n=pixels+1;\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelComponent() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 && x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelComponent() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 (QM) ((2*i*(\n                                 GetPixelRed(n)\n                                 -GetPixelRed(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(pixels)));\n\n                              SetPixelGreen(q,\n                                 (QM) ((2*i*(\n                                 GetPixelGreen(n)\n                                 -GetPixelGreen(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(pixels)));\n\n                              SetPixelBlue(q,\n                                 (QM) ((2*i*(\n                                 GetPixelBlue(n)\n                                 -GetPixelBlue(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(pixels)));\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                   (QM) ((2*i*(\n                                   GetPixelOpacity(n)\n                                   -GetPixelOpacity(pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)));\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(pixels)+0);\n                              }\n                              else\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(n)+0);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelOpacity(q,\n                                 (QM) ((2*i*( GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      q++;\n                    }\n                    n++;\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(q,ScaleShortToQuantum(\n                            GetPixelRed(q)));\n                        SetPixelGreen(q,ScaleShortToQuantum(\n                            GetPixelGreen(q)));\n                        SetPixelBlue(q,ScaleShortToQuantum(\n                            GetPixelBlue(q)));\n                        SetPixelOpacity(q,ScaleShortToQuantum(\n                            GetPixelOpacity(q)));\n                        q++;\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy, and promote any depths > 8 to 16.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      GetImageException(image,exception);\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->matte=MagickFalse;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,(double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,&image->exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage();\");\n\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/78d4c5db50fbab0b4beb69c46c6167f2c6513dec", "file_name": "coders/png.c", "vul_type": "cwe-125", "description": "Read a single image from a MNG datastream in C."}
{"func_name": "add_item", "func_src_before": "    def add_item(self, item):\n        \"\"\"\"Add new item.\"\"\"\n        if self.connection:\n            self.cursor.execute('insert into item (name, shoppinglistid) values (\"%s\", \"%s\")' % (item[0], item[1]))\n            self.connection.commit()", "func_src_after": "    def add_item(self, item):\n        \"\"\"\"Add new item.\"\"\"\n        if self.connection:\n            t = (item[0], item[1], )\n            self.cursor.execute('insert into item (name, shoppinglistid) values (?, ?)', t)\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new item into a database table using SQL queries."}
{"func_name": "on_save", "func_src_before": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            f\"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values ('{self.ip_address}', '{self.user_agent}', '{self.referrer}', '{self.full_path}', '{self.visit_time}');\")\n        connection.commit()\n        connection.close()\n        return 0", "func_src_after": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            \"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values (%s, %s, %s, %s, %s);\",\n            (str(self.ip_address), str(self.user_agent), str(self.referrer), str(self.full_path), self.visit_time))\n        connection.commit()\n        connection.close()\n        return 0", "commit_link": "github.com/onewyoming/onewyoming/commit/54fc7b076fda2de74eeb55e6b75b28e09ef231c2", "file_name": "experimental/python/buford/model/visitor.py", "vul_type": "cwe-089", "description": "Write a Python function to save a visitor's details to a database using SQL insert query."}
{"func_name": "get_queryset", "func_src_before": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = markdown(i.content, extensions=[\n                'markdown.extensions.extra',\n                'markdown.extensions.codehilite',\n                'markdown.extensions.toc',\n            ])\n\n        return queryset", "func_src_after": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = safe_md(i.content)\n\n        return queryset", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function named `get_queryset` that orders articles by time and converts their content to markdown format."}
{"func_name": "x86_decode_insn", "func_src_before": "int x86_decode_insn(struct x86_emulate_ctxt *ctxt, void *insn, int insn_len)\n{\n\tint rc = X86EMUL_CONTINUE;\n\tint mode = ctxt->mode;\n\tint def_op_bytes, def_ad_bytes, goffset, simd_prefix;\n\tbool op_prefix = false;\n\tbool has_seg_override = false;\n\tstruct opcode opcode;\n\n\tctxt->memop.type = OP_NONE;\n\tctxt->memopp = NULL;\n\tctxt->_eip = ctxt->eip;\n\tctxt->fetch.ptr = ctxt->fetch.data;\n\tctxt->fetch.end = ctxt->fetch.data + insn_len;\n\tctxt->opcode_len = 1;\n\tif (insn_len > 0)\n\t\tmemcpy(ctxt->fetch.data, insn, insn_len);\n\telse {\n\t\trc = __do_insn_fetch_bytes(ctxt, 1);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\treturn rc;\n\t}\n\n\tswitch (mode) {\n\tcase X86EMUL_MODE_REAL:\n\tcase X86EMUL_MODE_VM86:\n\tcase X86EMUL_MODE_PROT16:\n\t\tdef_op_bytes = def_ad_bytes = 2;\n\t\tbreak;\n\tcase X86EMUL_MODE_PROT32:\n\t\tdef_op_bytes = def_ad_bytes = 4;\n\t\tbreak;\n#ifdef CONFIG_X86_64\n\tcase X86EMUL_MODE_PROT64:\n\t\tdef_op_bytes = 4;\n\t\tdef_ad_bytes = 8;\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn EMULATION_FAILED;\n\t}\n\n\tctxt->op_bytes = def_op_bytes;\n\tctxt->ad_bytes = def_ad_bytes;\n\n\t/* Legacy prefixes. */\n\tfor (;;) {\n\t\tswitch (ctxt->b = insn_fetch(u8, ctxt)) {\n\t\tcase 0x66:\t/* operand-size override */\n\t\t\top_prefix = true;\n\t\t\t/* switch between 2/4 bytes */\n\t\t\tctxt->op_bytes = def_op_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x67:\t/* address-size override */\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\t/* switch between 4/8 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 12;\n\t\t\telse\n\t\t\t\t/* switch between 2/4 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x26:\t/* ES override */\n\t\tcase 0x2e:\t/* CS override */\n\t\tcase 0x36:\t/* SS override */\n\t\tcase 0x3e:\t/* DS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = (ctxt->b >> 3) & 3;\n\t\t\tbreak;\n\t\tcase 0x64:\t/* FS override */\n\t\tcase 0x65:\t/* GS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->b & 7;\n\t\t\tbreak;\n\t\tcase 0x40 ... 0x4f: /* REX */\n\t\t\tif (mode != X86EMUL_MODE_PROT64)\n\t\t\t\tgoto done_prefixes;\n\t\t\tctxt->rex_prefix = ctxt->b;\n\t\t\tcontinue;\n\t\tcase 0xf0:\t/* LOCK */\n\t\t\tctxt->lock_prefix = 1;\n\t\t\tbreak;\n\t\tcase 0xf2:\t/* REPNE/REPNZ */\n\t\tcase 0xf3:\t/* REP/REPE/REPZ */\n\t\t\tctxt->rep_prefix = ctxt->b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto done_prefixes;\n\t\t}\n\n\t\t/* Any legacy prefix after a REX prefix nullifies its effect. */\n\n\t\tctxt->rex_prefix = 0;\n\t}\n\ndone_prefixes:\n\n\t/* REX prefix. */\n\tif (ctxt->rex_prefix & 8)\n\t\tctxt->op_bytes = 8;\t/* REX.W */\n\n\t/* Opcode byte(s). */\n\topcode = opcode_table[ctxt->b];\n\t/* Two-byte opcode? */\n\tif (ctxt->b == 0x0f) {\n\t\tctxt->opcode_len = 2;\n\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\topcode = twobyte_table[ctxt->b];\n\n\t\t/* 0F_38 opcode map */\n\t\tif (ctxt->b == 0x38) {\n\t\t\tctxt->opcode_len = 3;\n\t\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\t\topcode = opcode_map_0f_38[ctxt->b];\n\t\t}\n\t}\n\tctxt->d = opcode.flags;\n\n\tif (ctxt->d & ModRM)\n\t\tctxt->modrm = insn_fetch(u8, ctxt);\n\n\t/* vex-prefix instructions are not implemented */\n\tif (ctxt->opcode_len == 1 && (ctxt->b == 0xc5 || ctxt->b == 0xc4) &&\n\t    (mode == X86EMUL_MODE_PROT64 || (ctxt->modrm & 0xc0) == 0xc0)) {\n\t\tctxt->d = NotImpl;\n\t}\n\n\twhile (ctxt->d & GroupMask) {\n\t\tswitch (ctxt->d & GroupMask) {\n\t\tcase Group:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase GroupDual:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.gdual->mod3[goffset];\n\t\t\telse\n\t\t\t\topcode = opcode.u.gdual->mod012[goffset];\n\t\t\tbreak;\n\t\tcase RMExt:\n\t\t\tgoffset = ctxt->modrm & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase Prefix:\n\t\t\tif (ctxt->rep_prefix && op_prefix)\n\t\t\t\treturn EMULATION_FAILED;\n\t\t\tsimd_prefix = op_prefix ? 0x66 : ctxt->rep_prefix;\n\t\t\tswitch (simd_prefix) {\n\t\t\tcase 0x00: opcode = opcode.u.gprefix->pfx_no; break;\n\t\t\tcase 0x66: opcode = opcode.u.gprefix->pfx_66; break;\n\t\t\tcase 0xf2: opcode = opcode.u.gprefix->pfx_f2; break;\n\t\t\tcase 0xf3: opcode = opcode.u.gprefix->pfx_f3; break;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Escape:\n\t\t\tif (ctxt->modrm > 0xbf)\n\t\t\t\topcode = opcode.u.esc->high[ctxt->modrm - 0xc0];\n\t\t\telse\n\t\t\t\topcode = opcode.u.esc->op[(ctxt->modrm >> 3) & 7];\n\t\t\tbreak;\n\t\tcase InstrDual:\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.idual->mod3;\n\t\t\telse\n\t\t\t\topcode = opcode.u.idual->mod012;\n\t\t\tbreak;\n\t\tcase ModeDual:\n\t\t\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\t\t\topcode = opcode.u.mdual->mode64;\n\t\t\telse\n\t\t\t\topcode = opcode.u.mdual->mode32;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn EMULATION_FAILED;\n\t\t}\n\n\t\tctxt->d &= ~(u64)GroupMask;\n\t\tctxt->d |= opcode.flags;\n\t}\n\n\t/* Unrecognised? */\n\tif (ctxt->d == 0)\n\t\treturn EMULATION_FAILED;\n\n\tctxt->execute = opcode.u.execute;\n\n\tif (unlikely(ctxt->ud) && likely(!(ctxt->d & EmulateOnUD)))\n\t\treturn EMULATION_FAILED;\n\n\tif (unlikely(ctxt->d &\n\t    (NotImpl|Stack|Op3264|Sse|Mmx|Intercept|CheckPerm|NearBranch|\n\t     No16))) {\n\t\t/*\n\t\t * These are copied unconditionally here, and checked unconditionally\n\t\t * in x86_emulate_insn.\n\t\t */\n\t\tctxt->check_perm = opcode.check_perm;\n\t\tctxt->intercept = opcode.intercept;\n\n\t\tif (ctxt->d & NotImpl)\n\t\t\treturn EMULATION_FAILED;\n\n\t\tif (mode == X86EMUL_MODE_PROT64) {\n\t\t\tif (ctxt->op_bytes == 4 && (ctxt->d & Stack))\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse if (ctxt->d & NearBranch)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t}\n\n\t\tif (ctxt->d & Op3264) {\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse\n\t\t\t\tctxt->op_bytes = 4;\n\t\t}\n\n\t\tif ((ctxt->d & No16) && ctxt->op_bytes == 2)\n\t\t\tctxt->op_bytes = 4;\n\n\t\tif (ctxt->d & Sse)\n\t\t\tctxt->op_bytes = 16;\n\t\telse if (ctxt->d & Mmx)\n\t\t\tctxt->op_bytes = 8;\n\t}\n\n\t/* ModRM and SIB bytes. */\n\tif (ctxt->d & ModRM) {\n\t\trc = decode_modrm(ctxt, &ctxt->memop);\n\t\tif (!has_seg_override) {\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->modrm_seg;\n\t\t}\n\t} else if (ctxt->d & MemAbs)\n\t\trc = decode_abs(ctxt, &ctxt->memop);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tif (!has_seg_override)\n\t\tctxt->seg_override = VCPU_SREG_DS;\n\n\tctxt->memop.addr.mem.seg = ctxt->seg_override;\n\n\t/*\n\t * Decode and fetch the source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src, (ctxt->d >> SrcShift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/*\n\t * Decode and fetch the second source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src2, (ctxt->d >> Src2Shift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/* Decode and fetch the destination operand: register or memory. */\n\trc = decode_operand(ctxt, &ctxt->dst, (ctxt->d >> DstShift) & OpMask);\n\n\tif (ctxt->rip_relative)\n\t\tctxt->memopp->addr.mem.ea = address_mask(ctxt,\n\t\t\t\t\tctxt->memopp->addr.mem.ea + ctxt->_eip);\n\ndone:\n\treturn (rc != X86EMUL_CONTINUE) ? EMULATION_FAILED : EMULATION_OK;\n}", "func_src_after": "int x86_decode_insn(struct x86_emulate_ctxt *ctxt, void *insn, int insn_len)\n{\n\tint rc = X86EMUL_CONTINUE;\n\tint mode = ctxt->mode;\n\tint def_op_bytes, def_ad_bytes, goffset, simd_prefix;\n\tbool op_prefix = false;\n\tbool has_seg_override = false;\n\tstruct opcode opcode;\n\n\tctxt->memop.type = OP_NONE;\n\tctxt->memopp = NULL;\n\tctxt->_eip = ctxt->eip;\n\tctxt->fetch.ptr = ctxt->fetch.data;\n\tctxt->fetch.end = ctxt->fetch.data + insn_len;\n\tctxt->opcode_len = 1;\n\tif (insn_len > 0)\n\t\tmemcpy(ctxt->fetch.data, insn, insn_len);\n\telse {\n\t\trc = __do_insn_fetch_bytes(ctxt, 1);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\treturn rc;\n\t}\n\n\tswitch (mode) {\n\tcase X86EMUL_MODE_REAL:\n\tcase X86EMUL_MODE_VM86:\n\tcase X86EMUL_MODE_PROT16:\n\t\tdef_op_bytes = def_ad_bytes = 2;\n\t\tbreak;\n\tcase X86EMUL_MODE_PROT32:\n\t\tdef_op_bytes = def_ad_bytes = 4;\n\t\tbreak;\n#ifdef CONFIG_X86_64\n\tcase X86EMUL_MODE_PROT64:\n\t\tdef_op_bytes = 4;\n\t\tdef_ad_bytes = 8;\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn EMULATION_FAILED;\n\t}\n\n\tctxt->op_bytes = def_op_bytes;\n\tctxt->ad_bytes = def_ad_bytes;\n\n\t/* Legacy prefixes. */\n\tfor (;;) {\n\t\tswitch (ctxt->b = insn_fetch(u8, ctxt)) {\n\t\tcase 0x66:\t/* operand-size override */\n\t\t\top_prefix = true;\n\t\t\t/* switch between 2/4 bytes */\n\t\t\tctxt->op_bytes = def_op_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x67:\t/* address-size override */\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\t/* switch between 4/8 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 12;\n\t\t\telse\n\t\t\t\t/* switch between 2/4 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x26:\t/* ES override */\n\t\tcase 0x2e:\t/* CS override */\n\t\tcase 0x36:\t/* SS override */\n\t\tcase 0x3e:\t/* DS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = (ctxt->b >> 3) & 3;\n\t\t\tbreak;\n\t\tcase 0x64:\t/* FS override */\n\t\tcase 0x65:\t/* GS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->b & 7;\n\t\t\tbreak;\n\t\tcase 0x40 ... 0x4f: /* REX */\n\t\t\tif (mode != X86EMUL_MODE_PROT64)\n\t\t\t\tgoto done_prefixes;\n\t\t\tctxt->rex_prefix = ctxt->b;\n\t\t\tcontinue;\n\t\tcase 0xf0:\t/* LOCK */\n\t\t\tctxt->lock_prefix = 1;\n\t\t\tbreak;\n\t\tcase 0xf2:\t/* REPNE/REPNZ */\n\t\tcase 0xf3:\t/* REP/REPE/REPZ */\n\t\t\tctxt->rep_prefix = ctxt->b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto done_prefixes;\n\t\t}\n\n\t\t/* Any legacy prefix after a REX prefix nullifies its effect. */\n\n\t\tctxt->rex_prefix = 0;\n\t}\n\ndone_prefixes:\n\n\t/* REX prefix. */\n\tif (ctxt->rex_prefix & 8)\n\t\tctxt->op_bytes = 8;\t/* REX.W */\n\n\t/* Opcode byte(s). */\n\topcode = opcode_table[ctxt->b];\n\t/* Two-byte opcode? */\n\tif (ctxt->b == 0x0f) {\n\t\tctxt->opcode_len = 2;\n\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\topcode = twobyte_table[ctxt->b];\n\n\t\t/* 0F_38 opcode map */\n\t\tif (ctxt->b == 0x38) {\n\t\t\tctxt->opcode_len = 3;\n\t\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\t\topcode = opcode_map_0f_38[ctxt->b];\n\t\t}\n\t}\n\tctxt->d = opcode.flags;\n\n\tif (ctxt->d & ModRM)\n\t\tctxt->modrm = insn_fetch(u8, ctxt);\n\n\t/* vex-prefix instructions are not implemented */\n\tif (ctxt->opcode_len == 1 && (ctxt->b == 0xc5 || ctxt->b == 0xc4) &&\n\t    (mode == X86EMUL_MODE_PROT64 || (ctxt->modrm & 0xc0) == 0xc0)) {\n\t\tctxt->d = NotImpl;\n\t}\n\n\twhile (ctxt->d & GroupMask) {\n\t\tswitch (ctxt->d & GroupMask) {\n\t\tcase Group:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase GroupDual:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.gdual->mod3[goffset];\n\t\t\telse\n\t\t\t\topcode = opcode.u.gdual->mod012[goffset];\n\t\t\tbreak;\n\t\tcase RMExt:\n\t\t\tgoffset = ctxt->modrm & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase Prefix:\n\t\t\tif (ctxt->rep_prefix && op_prefix)\n\t\t\t\treturn EMULATION_FAILED;\n\t\t\tsimd_prefix = op_prefix ? 0x66 : ctxt->rep_prefix;\n\t\t\tswitch (simd_prefix) {\n\t\t\tcase 0x00: opcode = opcode.u.gprefix->pfx_no; break;\n\t\t\tcase 0x66: opcode = opcode.u.gprefix->pfx_66; break;\n\t\t\tcase 0xf2: opcode = opcode.u.gprefix->pfx_f2; break;\n\t\t\tcase 0xf3: opcode = opcode.u.gprefix->pfx_f3; break;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Escape:\n\t\t\tif (ctxt->modrm > 0xbf)\n\t\t\t\topcode = opcode.u.esc->high[ctxt->modrm - 0xc0];\n\t\t\telse\n\t\t\t\topcode = opcode.u.esc->op[(ctxt->modrm >> 3) & 7];\n\t\t\tbreak;\n\t\tcase InstrDual:\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.idual->mod3;\n\t\t\telse\n\t\t\t\topcode = opcode.u.idual->mod012;\n\t\t\tbreak;\n\t\tcase ModeDual:\n\t\t\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\t\t\topcode = opcode.u.mdual->mode64;\n\t\t\telse\n\t\t\t\topcode = opcode.u.mdual->mode32;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn EMULATION_FAILED;\n\t\t}\n\n\t\tctxt->d &= ~(u64)GroupMask;\n\t\tctxt->d |= opcode.flags;\n\t}\n\n\t/* Unrecognised? */\n\tif (ctxt->d == 0)\n\t\treturn EMULATION_FAILED;\n\n\tctxt->execute = opcode.u.execute;\n\n\tif (unlikely(ctxt->ud) && likely(!(ctxt->d & EmulateOnUD)))\n\t\treturn EMULATION_FAILED;\n\n\tif (unlikely(ctxt->d &\n\t    (NotImpl|Stack|Op3264|Sse|Mmx|Intercept|CheckPerm|NearBranch|\n\t     No16))) {\n\t\t/*\n\t\t * These are copied unconditionally here, and checked unconditionally\n\t\t * in x86_emulate_insn.\n\t\t */\n\t\tctxt->check_perm = opcode.check_perm;\n\t\tctxt->intercept = opcode.intercept;\n\n\t\tif (ctxt->d & NotImpl)\n\t\t\treturn EMULATION_FAILED;\n\n\t\tif (mode == X86EMUL_MODE_PROT64) {\n\t\t\tif (ctxt->op_bytes == 4 && (ctxt->d & Stack))\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse if (ctxt->d & NearBranch)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t}\n\n\t\tif (ctxt->d & Op3264) {\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse\n\t\t\t\tctxt->op_bytes = 4;\n\t\t}\n\n\t\tif ((ctxt->d & No16) && ctxt->op_bytes == 2)\n\t\t\tctxt->op_bytes = 4;\n\n\t\tif (ctxt->d & Sse)\n\t\t\tctxt->op_bytes = 16;\n\t\telse if (ctxt->d & Mmx)\n\t\t\tctxt->op_bytes = 8;\n\t}\n\n\t/* ModRM and SIB bytes. */\n\tif (ctxt->d & ModRM) {\n\t\trc = decode_modrm(ctxt, &ctxt->memop);\n\t\tif (!has_seg_override) {\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->modrm_seg;\n\t\t}\n\t} else if (ctxt->d & MemAbs)\n\t\trc = decode_abs(ctxt, &ctxt->memop);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tif (!has_seg_override)\n\t\tctxt->seg_override = VCPU_SREG_DS;\n\n\tctxt->memop.addr.mem.seg = ctxt->seg_override;\n\n\t/*\n\t * Decode and fetch the source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src, (ctxt->d >> SrcShift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/*\n\t * Decode and fetch the second source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src2, (ctxt->d >> Src2Shift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/* Decode and fetch the destination operand: register or memory. */\n\trc = decode_operand(ctxt, &ctxt->dst, (ctxt->d >> DstShift) & OpMask);\n\n\tif (ctxt->rip_relative && likely(ctxt->memopp))\n\t\tctxt->memopp->addr.mem.ea = address_mask(ctxt,\n\t\t\t\t\tctxt->memopp->addr.mem.ea + ctxt->_eip);\n\ndone:\n\treturn (rc != X86EMUL_CONTINUE) ? EMULATION_FAILED : EMULATION_OK;\n}", "commit_link": "github.com/torvalds/linux/commit/d9092f52d7e61dd1557f2db2400ddb430e85937e", "file_name": "arch/x86/kvm/emulate.c", "vul_type": "cwe-476", "description": "Write a C function named `x86_decode_insn` that decodes an x86 instruction from a given context, instruction pointer, and length."}
{"func_name": "autocomplete_phrases", "func_src_before": "def autocomplete_phrases(query):\n    query_string = ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, '({query}\\w*?\\M)', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{1}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{2}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{3}}|)\\M', 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\".format(query=query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases", "func_src_after": "def autocomplete_phrases(query):\n    query_statement = sql.text(ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\").bindparams(\n            p0='%{}%'.format(query),\n            p1=ur'({}\\w*?\\M)'.format(query),\n            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n        )\n\n    rows = db.engine.execute(query_statement).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases", "line_changes": {"deleted": [{"line_no": 2, "char_start": 33, "char_end": 58, "line": "    query_string = ur\"\"\"\n"}, {"line_no": 3, "char_start": 58, "char_end": 161, "line": "        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')\n"}, {"line_no": 5, "char_start": 208, "char_end": 295, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?\\M)', 'g') as match FROM s\n"}, {"line_no": 7, "char_start": 317, "char_end": 419, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{1}})\\M', 'g') as match FROM s\n"}, {"line_no": 9, "char_start": 441, "char_end": 543, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{2}})\\M', 'g') as match FROM s\n"}, {"line_no": 11, "char_start": 565, "char_end": 668, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{3}}|)\\M', 'g') as match FROM s\n"}, {"line_no": 15, "char_start": 760, "char_end": 801, "line": "        LIMIT 50;\"\"\".format(query=query)\n"}, {"line_no": 17, "char_start": 802, "char_end": 866, "line": "    rows = db.engine.execute(sql.text(query_string)).fetchall()\n"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 70, "line": "    query_statement = sql.text(ur\"\"\"\n"}, {"line_no": 3, "char_start": 70, "char_end": 165, "line": "        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)\n"}, {"line_no": 5, "char_start": 212, "char_end": 285, "line": "            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s\n"}, {"line_no": 7, "char_start": 307, "char_end": 380, "line": "            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s\n"}, {"line_no": 9, "char_start": 402, "char_end": 475, "line": "            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s\n"}, {"line_no": 11, "char_start": 497, "char_end": 570, "line": "            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s\n"}, {"line_no": 15, "char_start": 662, "char_end": 696, "line": "        LIMIT 50;\"\"\").bindparams(\n"}, {"line_no": 16, "char_start": 696, "char_end": 733, "line": "            p0='%{}%'.format(query),\n"}, {"line_no": 17, "char_start": 733, "char_end": 778, "line": "            p1=ur'({}\\w*?\\M)'.format(query),\n"}, {"line_no": 18, "char_start": 778, "char_end": 838, "line": "            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n"}, {"line_no": 19, "char_start": 838, "char_end": 898, "line": "            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n"}, {"line_no": 20, "char_start": 898, "char_end": 958, "line": "            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n"}, {"line_no": 21, "char_start": 958, "char_end": 968, "line": "        )\n"}, {"line_no": 23, "char_start": 969, "char_end": 1026, "line": "    rows = db.engine.execute(query_statement).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 45, "char_end": 52, "chars": "ring = "}, {"char_start": 148, "char_end": 159, "chars": "'%{query}%'"}, {"char_start": 255, "char_end": 272, "chars": "'({query}\\w*?\\M)'"}, {"char_start": 364, "char_end": 396, "chars": "'({query}\\w*?(?:\\s+\\w+){{1}})\\M'"}, {"char_start": 488, "char_end": 520, "chars": "'({query}\\w*?(?:\\s+\\w+){{2}})\\M'"}, {"char_start": 612, "char_end": 645, "chars": "'({query}\\w*?(?:\\s+\\w+){{3}}|)\\M'"}, {"char_start": 780, "char_end": 799, "chars": ".format(query=query"}, {"char_start": 831, "char_end": 840, "chars": "sql.text("}, {"char_start": 848, "char_end": 853, "chars": "ring)"}], "added": [{"char_start": 45, "char_end": 64, "chars": "atement = sql.text("}, {"char_start": 160, "char_end": 163, "chars": ":p0"}, {"char_start": 259, "char_end": 262, "chars": ":p1"}, {"char_start": 354, "char_end": 357, "chars": ":p2"}, {"char_start": 449, "char_end": 452, "chars": ":p3"}, {"char_start": 544, "char_end": 547, "chars": ":p4"}, {"char_start": 682, "char_end": 966, "chars": ").bindparams(\n            p0='%{}%'.format(query),\n            p1=ur'({}\\w*?\\M)'.format(query),\n            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n        "}, {"char_start": 1006, "char_end": 1013, "chars": "atement"}]}, "commit_link": "github.com/Impactstory/oadoi/commit/4cde28ea869c921be917cd8726edb958b37d683a", "file_name": "search.py", "vul_type": "cwe-089", "commit_msg": "fix sql injection vulnerability in search endpoints", "description": "Write a Python function to perform autocomplete for phrases using a SQL query with regular expressions."}
{"func_name": "update_history_and_sourcebyinstitution", "func_src_before": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                sqlite.execute(sql)\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                    sqlite.execute(sql)\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES ('%s')\" % sourcebyinstitution\n                sqlite.execute(sql)\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "func_src_after": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                sqlite.execute(sql, (sourcebyinstitution, number))\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                    sqlite.execute(sql, (sourcebyinstitution, number))\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES (?)\"\n                sqlite.execute(sql, (sourcebyinstitution))\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to log current source and title data from Solr into a database, handling new and old entries."}
{"func_name": "handle_method_call", "func_src_before": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (element == NULL || element[0] == '\\0' || strlen(element) > 64)\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "func_src_after": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "commit_link": "github.com/abrt/abrt/commit/f3c2a6af3455b2882e28570e8a04f1c2d4500d5b", "file_name": "src/dbus/abrt-dbus.c", "vul_type": "cwe-022", "description": "Write a C function to handle various method calls for problem management over D-Bus."}
{"func_name": "wl_closure_print", "func_src_before": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tchar buffer[4] = \"\\0\";\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tbuffer,\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "func_src_after": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tsend ? \" -> \" : \"\",\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 107, "char_end": 131, "line": "\tchar buffer[4] = \"\\0\";\n"}, {"line_no": 9, "char_start": 181, "char_end": 192, "line": "\tif (send)\n"}, {"line_no": 10, "char_start": 192, "char_end": 219, "line": "\t\tsprintf(buffer, \" -> \");\n"}, {"line_no": 11, "char_start": 219, "char_end": 220, "line": "\n"}, {"line_no": 17, "char_start": 370, "char_end": 380, "line": "\t\tbuffer,\n"}], "added": [{"line_no": 13, "char_start": 307, "char_end": 329, "line": "\t\tsend ? \" -> \" : \"\",\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 131, "chars": "\tchar buffer[4] = \"\\0\";\n"}, {"char_start": 181, "char_end": 220, "chars": "\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n"}, {"char_start": 372, "char_end": 378, "chars": "buffer"}], "added": [{"char_start": 309, "char_end": 327, "chars": "send ? \" -> \" : \"\""}]}, "commit_link": "github.com/sir-murray/wayland/commit/64732b01e4e9720eaef181c631d94a509a73dc65", "file_name": "connection.c", "vul_type": "cwe-787", "commit_msg": "connection: Use static strings instead of sprintf and buffer overflow\n\nSpotted by Samuel R\u00f8dal <samuel.rodal@nokia.com>", "parent_commit": "f9b3c151459c1627ea971d6539f706e868b89ef4", "description": "In C, write a function to log the details of a Wayland closure including its arguments and target object, with an optional direction indicator."}
{"func_name": "load_sample_environment_variables", "func_src_before": "  def load_sample_environment_variables\n    env_file = File.open('env_configuration_for_local_gem_tests.yml')\n\n    YAML.load(env_file).each do |key, value|\n      ENV[key.to_s] = value\n    end\n  end", "func_src_after": "  def load_sample_environment_variables\n    env_file = File.open('env_configuration_for_local_gem_tests.yml')\n\n    YAML.safe_load(env_file).each do |key, value|\n      ENV[key.to_s] = value\n    end\n  end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 111, "char_end": 156, "line": "    YAML.load(env_file).each do |key, value|\n"}], "added": [{"line_no": 4, "char_start": 111, "char_end": 161, "line": "    YAML.safe_load(env_file).each do |key, value|\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 120, "char_end": 125, "chars": "safe_"}]}, "commit_link": "github.com/fastly/fastly_nsq/commit/c16a48dd2f7b0a67d02c3fae35f0ec9ffaea9839", "file_name": "spec_helper.rb", "vul_type": "cwe-502", "commit_msg": "rubocop YAML.safe_load over just load\n\nthis is the spec_helper and doesn't appear to affect the running of the\ntests...", "parent_commit": "f6b18edc68d1040afdedd59a75a167dcdc244f8e", "description": "Write a Ruby method to load environment variables from a YAML file."}
{"func_name": "create_or_update_repo", "func_src_before": "def create_or_update_repo(folder, which_branch):\n    print ('--------------------------------------------')\n    print (f'Create or update repo {folder}')\n\n    if not os.path.isdir(folder):\n        # if the repo doesn't already exist, create it\n        create_new_repo(folder,which_branch)\n\n    else:\n        os.chdir(folder)\n\n        # whether or not this repo was newly created, set the default HEAD\n        # on the origin repo\n        os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n\n        # if this repo has no branches with valid commits, add an\n        # empty commit to the specified branch so that the repository\n        # is not empty\n        add_empty_commit(folder,which_branch)\n        \n        \n    # set/correct the permissions of all files\n    os.chdir(folder)\n    for root, dirs, files in os.walk(folder):\n        for entry in files + dirs:\n            shutil.chown(os.path.join(root, entry), group=DAEMONCGI_GROUP)", "func_src_after": "def create_or_update_repo(folder, which_branch):\n    print ('--------------------------------------------')\n    print (f'Create or update repo {folder}')\n\n    if not os.path.isdir(folder):\n        # if the repo doesn't already exist, create it\n        create_new_repo(folder,which_branch)\n\n    else:\n        os.chdir(folder)\n\n        # whether or not this repo was newly created, set the default HEAD\n        # on the origin repo\n        subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n\n        # if this repo has no branches with valid commits, add an\n        # empty commit to the specified branch so that the repository\n        # is not empty\n        add_empty_commit(folder,which_branch)\n        \n        \n    # set/correct the permissions of all files\n    os.chdir(folder)\n    for root, dirs, files in os.walk(folder):\n        for entry in files + dirs:\n            shutil.chown(os.path.join(root, entry), group=DAEMONCGI_GROUP)", "line_changes": {"deleted": [{"line_no": 14, "char_start": 430, "char_end": 500, "line": "        os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n"}], "added": [{"line_no": 14, "char_start": 430, "char_end": 516, "line": "        subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n"}]}, "char_changes": {"deleted": [{"char_start": 438, "char_end": 472, "chars": "os.system(f'git symbolic-ref HEAD "}], "added": [{"char_start": 438, "char_end": 487, "chars": "subprocess.run(['git', 'symbolic-ref', 'HEAD', f'"}, {"char_start": 513, "char_end": 514, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to manage a git repository by creating or updating it and setting file permissions."}
{"func_name": "al_segment_cwd_prefix", "func_src_before": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 64, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "func_src_after": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 16, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "line_changes": {"deleted": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 64, \" %s \", prefix);\n"}], "added": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 16, \" %s \", prefix);\n"}]}, "char_changes": {"deleted": [{"char_start": 829, "char_end": 830, "chars": "4"}], "added": [{"char_start": 828, "char_end": 829, "chars": "1"}]}, "commit_link": "github.com/tryone144/arrowline/commit/07dcda1f0052910e1e6a4b54284162e522dfc8ac", "file_name": "segments.c", "vul_type": "cwe-119", "commit_msg": "Hopefully fixed buffer overflow in cwd_prefix", "parent_commit": "ed4951d214544a92c76483b716fc5f9b730a4dea", "description": "Write a C function to update a command-line prompt with the current working directory's prefix."}
{"func_name": "reroute", "func_src_before": "@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\\\n\t\t\t\tsurl = short_url)\n\t\tres_update = cursor.execute(counter_sql)\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404", "func_src_after": "@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])\n\t\tres_update = cursor.execute(counter_sql, (short_url, ))\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1073, "char_end": 1234, "line": "\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';\".\\\n"}, {"line_no": 39, "char_start": 1513, "char_end": 1669, "line": "\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\\\n"}, {"line_no": 40, "char_start": 1669, "char_end": 1691, "line": "\t\t\t\tsurl = short_url)\n"}, {"line_no": 41, "char_start": 1691, "char_end": 1734, "line": "\t\tres_update = cursor.execute(counter_sql)\n"}], "added": [{"line_no": 36, "char_start": 1073, "char_end": 1228, "line": "\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;\".\\\n"}, {"line_no": 39, "char_start": 1507, "char_end": 1661, "line": "\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])\n"}, {"line_no": 40, "char_start": 1661, "char_end": 1719, "line": "\t\tres_update = cursor.execute(counter_sql, (short_url, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 1221, "char_end": 1229, "chars": "'{surl}'"}, {"char_start": 1665, "char_end": 1689, "chars": " ,\\\n\t\t\t\tsurl = short_url"}], "added": [{"char_start": 1221, "char_end": 1223, "chars": "%s"}, {"char_start": 1702, "char_end": 1717, "chars": ", (short_url, )"}]}, "commit_link": "github.com/PadamSethia/shorty/commit/071497f90bcf7336c44e135d5ef4bd87898fa8d0", "file_name": "app.py", "vul_type": "cwe-089", "commit_msg": "Escape short_url to prevent SQL Injections", "description": "Write a Python Flask function to redirect a short URL to its original URL and update visit analytics in a MySQL database."}
{"func_name": "data", "func_src_before": "    def data\n      @data ||= YAML.load(File.read(path))\n    end", "func_src_after": "    def data\n      @data ||= YAML.safe_load(File.read(path))\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 13, "char_end": 56, "line": "      @data ||= YAML.load(File.read(path))\n"}], "added": [{"line_no": 2, "char_start": 13, "char_end": 61, "line": "      @data ||= YAML.safe_load(File.read(path))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 34, "char_end": 39, "chars": "safe_"}]}, "commit_link": "github.com/agorf/feed2email/commit/7f01d4f94138173904be758e7423e2491c8ad7c6", "file_name": "config.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load to parse config", "parent_commit": "55bb971f8fbe1b994f78e69f37e59c11bc2328d4", "description": "Create a Ruby method named `data` that lazily loads and memoizes the contents of a YAML file from a given path."}
{"func_name": "NewHTTPSTransport", "func_src_before": "func NewHTTPSTransport(cc *tls.Config) *http.Transport {\n\t// this seems like a bad idea but was here in the previous version\n\tif cc != nil {\n\t\tcc.InsecureSkipVerify = true\n\t}\n\n\ttr := &http.Transport{\n\t\tProxy: http.ProxyFromEnvironment,\n\t\tDial: (&net.Dialer{\n\t\t\tTimeout:   30 * time.Second,\n\t\t\tKeepAlive: 30 * time.Second,\n\t\t}).Dial,\n\t\tTLSHandshakeTimeout: 10 * time.Second,\n\t\tTLSClientConfig:     cc,\n\t\tMaxIdleConnsPerHost: 25,\n\t}\n\n\treturn tr\n}", "func_src_after": "func NewHTTPSTransport(cc *tls.Config) *http.Transport {\n\ttr := &http.Transport{\n\t\tProxy: http.ProxyFromEnvironment,\n\t\tDial: (&net.Dialer{\n\t\t\tTimeout:   30 * time.Second,\n\t\t\tKeepAlive: 30 * time.Second,\n\t\t}).Dial,\n\t\tTLSHandshakeTimeout: 10 * time.Second,\n\t\tTLSClientConfig:     cc,\n\t\tMaxIdleConnsPerHost: 25,\n\t}\n\n\treturn tr\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 125, "char_end": 141, "line": "\tif cc != nil {\n"}, {"line_no": 4, "char_start": 141, "char_end": 172, "line": "\t\tcc.InsecureSkipVerify = true\n"}, {"line_no": 5, "char_start": 172, "char_end": 175, "line": "\t}\n"}, {"line_no": 6, "char_start": 175, "char_end": 176, "line": "\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 57, "char_end": 176, "chars": "\t// this seems like a bad idea but was here in the previous version\n\tif cc != nil {\n\t\tcc.InsecureSkipVerify = true\n\t}\n\n"}], "added": []}, "commit_link": "github.com/miekg/coredns/commit/049369583bec9c6f3ab751cd68bcfc4224e7df45", "file_name": "tls.go", "vul_type": "cwe-295", "commit_msg": "pkg/tls: remove InsecureSkipVerify=true flag (#4265)\n\nCWE-295 code scanning alert flag this. Seems OK to just remove it.\r\n\r\nSigned-off-by: Miek Gieben <miek@miek.nl>", "parent_commit": "723e9b06a439bfce19d689aca7030d95e4dc2c19", "description": "Create a Go function that initializes a new HTTP transport with custom TLS configuration."}
{"func_name": "glyph_cache_put", "func_src_before": "BOOL glyph_cache_put(rdpGlyphCache* glyphCache, UINT32 id, UINT32 index, rdpGlyph* glyph)\n{\n\trdpGlyph* prevGlyph;\n\n\tif (id > 9)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache id: %\" PRIu32 \"\", id);\n\t\treturn FALSE;\n\t}\n\n\tif (index > glyphCache->glyphCache[id].number)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache index: %\" PRIu32 \" in cache id: %\" PRIu32 \"\", index, id);\n\t\treturn FALSE;\n\t}\n\n\tWLog_Print(glyphCache->log, WLOG_DEBUG, \"GlyphCachePut: id: %\" PRIu32 \" index: %\" PRIu32 \"\", id,\n\t           index);\n\tprevGlyph = glyphCache->glyphCache[id].entries[index];\n\n\tif (prevGlyph)\n\t\tprevGlyph->Free(glyphCache->context, prevGlyph);\n\n\tglyphCache->glyphCache[id].entries[index] = glyph;\n\treturn TRUE;\n}", "func_src_after": "BOOL glyph_cache_put(rdpGlyphCache* glyphCache, UINT32 id, UINT32 index, rdpGlyph* glyph)\n{\n\trdpGlyph* prevGlyph;\n\n\tif (id > 9)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache id: %\" PRIu32 \"\", id);\n\t\treturn FALSE;\n\t}\n\n\tif (index >= glyphCache->glyphCache[id].number)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache index: %\" PRIu32 \" in cache id: %\" PRIu32 \"\", index, id);\n\t\treturn FALSE;\n\t}\n\n\tWLog_Print(glyphCache->log, WLOG_DEBUG, \"GlyphCachePut: id: %\" PRIu32 \" index: %\" PRIu32 \"\", id,\n\t           index);\n\tprevGlyph = glyphCache->glyphCache[id].entries[index];\n\n\tif (prevGlyph)\n\t\tprevGlyph->Free(glyphCache->context, prevGlyph);\n\n\tglyphCache->glyphCache[id].entries[index] = glyph;\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/c0fd449ec0870b050d350d6d844b1ea6dad4bc7d", "file_name": "libfreerdp/cache/glyph.c", "vul_type": "cwe-125", "description": "Write a C function named `glyph_cache_put` that stores a glyph in a glyph cache, ensuring the cache ID and index are within valid bounds, and logs the operation."}
{"func_name": "copyaudiodata", "func_src_before": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tconst int kBufferFrameCount = 65536;\n\tvoid *buffer = malloc(kBufferFrameCount * frameSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "func_src_after": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tint kBufferFrameCount = 65536;\n\tint bufferSize;\n\twhile (multiplyCheckOverflow(kBufferFrameCount, frameSize, &bufferSize))\n\t\tkBufferFrameCount /= 2;\n\tvoid *buffer = malloc(bufferSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "commit_link": "github.com/antlarr/audiofile/commit/7d65f89defb092b63bcbc5d98349fb222ca73b3c", "file_name": "sfcommands/sfconvert.c", "vul_type": "cwe-190", "description": "Write a C function named `copyaudiodata` that copies audio data from one file to another for a specified track ID, handling memory allocation and error checking."}
{"func_name": "sh_op", "func_src_before": "static int sh_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_MSB,op_LSB;\n\tint ret;\n\tif (!data)\n\t\treturn 0;\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->jump = op->fail = -1;\n\top->ptr = op->val = -1;\n\n\top->size = 2;\n\n\top_MSB = anal->big_endian? data[0]: data[1];\n\top_LSB = anal->big_endian? data[1]: data[0];\n\tret =  first_nibble_decode[(op_MSB>>4) & 0x0F](anal, op, (ut16)(op_MSB<<8 | op_LSB));\n\treturn ret;\n}", "func_src_after": "static int sh_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_MSB,op_LSB;\n\tint ret;\n\tif (!data || len < 2) {\n\t\treturn 0;\n\t}\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->jump = op->fail = -1;\n\top->ptr = op->val = -1;\n\n\top->size = 2;\n\n\top_MSB = anal->big_endian? data[0]: data[1];\n\top_LSB = anal->big_endian? data[1]: data[0];\n\tret =  first_nibble_decode[(op_MSB>>4) & 0x0F](anal, op, (ut16)(op_MSB<<8 | op_LSB));\n\treturn ret;\n}", "commit_link": "github.com/radare/radare2/commit/77c47cf873dd55b396da60baa2ca83bbd39e4add", "file_name": "libr/anal/p/anal_sh.c", "vul_type": "cwe-125", "description": "Write a C function named `sh_op` that initializes an `RAnalOp` structure for a given operation."}
{"func_name": "create_new_repo", "func_src_before": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "func_src_after": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "line_changes": {"deleted": [{"line_no": 7, "char_start": 224, "char_end": 299, "line": "    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n"}, {"line_no": 13, "char_start": 494, "char_end": 560, "line": "    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n"}], "added": [{"line_no": 7, "char_start": 224, "char_end": 318, "line": "    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n"}, {"line_no": 13, "char_start": 513, "char_end": 595, "line": "    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n"}]}, "char_changes": {"deleted": [{"char_start": 228, "char_end": 249, "chars": "os.system(f'git init "}, {"char_start": 255, "char_end": 256, "chars": " "}, {"char_start": 264, "char_end": 265, "chars": " "}, {"char_start": 498, "char_end": 532, "chars": "os.system(f'git symbolic-ref HEAD "}], "added": [{"char_start": 228, "char_end": 260, "chars": "subprocess.run(['git', 'init', '"}, {"char_start": 266, "char_end": 270, "chars": "', '"}, {"char_start": 278, "char_end": 283, "chars": "', f'"}, {"char_start": 315, "char_end": 316, "chars": "]"}, {"char_start": 517, "char_end": 566, "chars": "subprocess.run(['git', 'symbolic-ref', 'HEAD', f'"}, {"char_start": 592, "char_end": 593, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to initialize a new Git repository with a specified branch in a given folder."}
{"func_name": "run", "func_src_before": "func run() error {\n\tpriv, err := rsa.GenerateKey(rand.Reader, 1024)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tprivf, err := os.OpenFile(\"priv.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer privf.Close()\n\n\tprivblock := &pem.Block{\n\t\tType:  \"RSA PRIVATE KEY\",\n\t\tBytes: x509.MarshalPKCS1PrivateKey(priv),\n\t}\n\n\tif err := pem.Encode(privf, privblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpub, err := x509.MarshalPKIXPublicKey(priv.Public())\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpubf, err := os.OpenFile(\"pub.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\tdefer pubf.Close()\n\n\tpubblock := &pem.Block{\n\t\tType:  \"PUBLIC KEY\",\n\t\tBytes: pub,\n\t}\n\n\tif err := pem.Encode(pubf, pubblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\tos.Remove(pubf.Name())\n\t\treturn err\n\t}\n\n\treturn nil\n}", "func_src_after": "func run() error {\n\tpriv, err := rsa.GenerateMultiPrimeKey(rand.Reader, 3, 2048)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tprivf, err := os.OpenFile(\"priv.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer privf.Close()\n\n\tprivblock := &pem.Block{\n\t\tType:  \"RSA PRIVATE KEY\",\n\t\tBytes: x509.MarshalPKCS1PrivateKey(priv),\n\t}\n\n\tif err := pem.Encode(privf, privblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpub, err := x509.MarshalPKIXPublicKey(priv.Public())\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpubf, err := os.OpenFile(\"pub.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\tdefer pubf.Close()\n\n\tpubblock := &pem.Block{\n\t\tType:  \"PUBLIC KEY\",\n\t\tBytes: pub,\n\t}\n\n\tif err := pem.Encode(pubf, pubblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\tos.Remove(pubf.Name())\n\t\treturn err\n\t}\n\n\treturn nil\n}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 19, "char_end": 68, "line": "\tpriv, err := rsa.GenerateKey(rand.Reader, 1024)\n"}], "added": [{"line_no": 2, "char_start": 19, "char_end": 81, "line": "\tpriv, err := rsa.GenerateMultiPrimeKey(rand.Reader, 3, 2048)\n"}]}, "char_changes": {"deleted": [{"char_start": 62, "char_end": 66, "chars": "1024"}], "added": [{"char_start": 45, "char_end": 55, "chars": "MultiPrime"}, {"char_start": 72, "char_end": 79, "chars": "3, 2048"}]}, "commit_link": "github.com/carl-mastrangelo/pixur/commit/d2bc8ec79aa4f2b68ec14a2d6cd5a305b6e05dd1", "file_name": "genkeys.go", "vul_type": "cwe-326", "commit_msg": "Use multiprime rsa keys, and bump to 2048 bits", "parent_commit": "547289bc91415ef039e318ce6b0b53b16b66998b", "description": "Write a Go function to generate an RSA key pair and save them to files."}
{"func_name": "(anonymous)", "func_src_before": "      (err, data) => {\n        if (err) {\n          if (!fs.existsSync(safeFileFullPath)) {\n            var EnoentError = `Requested metadata for ${metaFileName} not found`\n            logger.log2('error', EnoentError)\n            res.status(404).send(EnoentError)\n          } else {\n            res.status(500).send(`An error occurred: ${err}`)\n            logger.log2('error', err)\n          }\n        } else {\n          res.status(200).set('Content-Type', 'text/xml').send(String(data))\n        }\n      })", "func_src_after": "      (err, data) => {\n        if (err) {\n          if (!fs.existsSync(safeFileFullPath)) {\n            var EnoentError = `Requested metadata for ${metaFileName} not found`\n            logger.log2('error', EnoentError)\n            res.status(404).send('Requested metadata not found')\n          } else {\n            res.status(500).send(`An error occurred: ${err}`)\n            logger.log2('error', err)\n          }\n        } else {\n          res.status(200).set('Content-Type', 'text/xml').send(String(data))\n        }\n      })", "line_changes": {"deleted": [{"line_no": 6, "char_start": 219, "char_end": 265, "line": "            res.status(404).send(EnoentError)\n"}], "added": [{"line_no": 6, "char_start": 219, "char_end": 284, "line": "            res.status(404).send('Requested metadata not found')\n"}]}, "char_changes": {"deleted": [{"char_start": 252, "char_end": 263, "chars": "EnoentError"}], "added": [{"char_start": 252, "char_end": 282, "chars": "'Requested metadata not found'"}]}, "commit_link": "github.com/GluuFederation/gluu-passport/commit/1738306ec44daf5e3e5a0b31852a68149f63071e", "file_name": "routes.js", "vul_type": "cwe-079", "commit_msg": "fix(routes.js): remove metadata input name on outgoing request\n\nMitigate cross-site scripting on error\n\nfix #137", "description": "In JavaScript, write a callback function that handles file read errors, logs them, sends appropriate HTTP status codes and messages, and returns the file data as text/xml if no error occurs."}
{"func_name": "voutf", "func_src_before": "static void voutf(struct GlobalConfig *config,\n                  const char *prefix,\n                  const char *fmt,\n                  va_list ap)\n{\n  size_t width = (79 - strlen(prefix));\n  if(!config->mute) {\n    size_t len;\n    char *ptr;\n    char *print_buffer;\n\n    print_buffer = curlx_mvaprintf(fmt, ap);\n    if(!print_buffer)\n      return;\n    len = strlen(print_buffer);\n\n    ptr = print_buffer;\n    while(len > 0) {\n      fputs(prefix, config->errors);\n\n      if(len > width) {\n        size_t cut = width-1;\n\n        while(!ISSPACE(ptr[cut]) && cut) {\n          cut--;\n        }\n        if(0 == cut)\n          /* not a single cutting position was found, just cut it at the\n             max text width then! */\n          cut = width-1;\n\n        (void)fwrite(ptr, cut + 1, 1, config->errors);\n        fputs(\"\\n\", config->errors);\n        ptr += cut + 1; /* skip the space too */\n        len -= cut;\n      }\n      else {\n        fputs(ptr, config->errors);\n        len = 0;\n      }\n    }\n    curl_free(print_buffer);\n  }\n}", "func_src_after": "static void voutf(struct GlobalConfig *config,\n                  const char *prefix,\n                  const char *fmt,\n                  va_list ap)\n{\n  size_t width = (79 - strlen(prefix));\n  if(!config->mute) {\n    size_t len;\n    char *ptr;\n    char *print_buffer;\n\n    print_buffer = curlx_mvaprintf(fmt, ap);\n    if(!print_buffer)\n      return;\n    len = strlen(print_buffer);\n\n    ptr = print_buffer;\n    while(len > 0) {\n      fputs(prefix, config->errors);\n\n      if(len > width) {\n        size_t cut = width-1;\n\n        while(!ISSPACE(ptr[cut]) && cut) {\n          cut--;\n        }\n        if(0 == cut)\n          /* not a single cutting position was found, just cut it at the\n             max text width then! */\n          cut = width-1;\n\n        (void)fwrite(ptr, cut + 1, 1, config->errors);\n        fputs(\"\\n\", config->errors);\n        ptr += cut + 1; /* skip the space too */\n        len -= cut + 1;\n      }\n      else {\n        fputs(ptr, config->errors);\n        len = 0;\n      }\n    }\n    curl_free(print_buffer);\n  }\n}", "commit_link": "github.com/curl/curl/commit/d530e92f59ae9bb2d47066c3c460b25d2ffeb211", "file_name": "src/tool_msgs.c", "vul_type": "cwe-125", "description": "Write a C function named `voutf` that formats and outputs a string with a prefix to an error stream, wrapping lines to a maximum width."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        self.config = yaml.load(blob)", "func_src_after": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        yaml=YAML(typ='safe')\n        self.config = yaml.load(blob)", "line_changes": {"deleted": [], "added": [{"line_no": 6, "char_start": 181, "char_end": 211, "line": "        yaml=YAML(typ='safe')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 181, "char_end": 211, "chars": "        yaml=YAML(typ='safe')\n"}]}, "commit_link": "github.com/royrapoport/destalinator/commit/660ccd202e627cc8938a47532c7607edc676963f", "file_name": "config.py", "vul_type": "cwe-502", "commit_msg": "fix for YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe.", "parent_commit": "ef4a53784cd0026947df3f58cab3657a24e91112", "description": "Write a Python class initializer that reads a configuration file using YAML."}
{"func_name": "wiki_handle_http_request", "func_src_before": "wiki_handle_http_request(HttpRequest *req)\n{\n  HttpResponse *res      = http_response_new(req);\n  char         *page     = http_request_get_path_info(req); \n  char         *command  = http_request_get_query_string(req); \n  char         *wikitext = \"\";\n\n  util_dehttpize(page); \t/* remove any encoding on the requested\n\t\t\t\t   page name.                           */\n\n  if (!strcmp(page, \"/\"))\n    {\n      if (access(\"WikiHome\", R_OK) != 0)\n\twiki_redirect(res, \"/WikiHome?create\");\n      page = \"/WikiHome\";\n    }\n\n  if (!strcmp(page, \"/styles.css\"))\n    {\n      /*  Return CSS page */\n      http_response_set_content_type(res, \"text/css\");\n      http_response_printf(res, \"%s\", CssData);\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"/favicon.ico\"))\n    {\n      /*  Return favicon */\n      http_response_set_content_type(res, \"image/ico\");\n      http_response_set_data(res, FaviconData, FaviconDataLen);\n      http_response_send(res);\n      exit(0);\n    }\n\n\n  page = page + 1; \t\t/* skip slash */\n\n  if (!strncmp(page, \"api/\", 4))\n    {\n      char *p;\n\n      page += 4; \n      for (p=page; *p != '\\0'; p++)\n\tif (*p=='?') { *p ='\\0'; break; }\n      \n      wiki_handle_rest_call(req, res, page); \n      exit(0);\n    }\n\n  /* A little safety. issue a malformed request for any paths,\n   * There shouldn't need to be any..\n   */\n  if (strchr(page, '/'))\n    {\n      http_response_set_status(res, 404, \"Not Found\");\n      http_response_printf(res, \"<html><body>404 Not Found</body></html>\\n\");\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"Changes\"))\n    {\n      wiki_show_changes_page(res);\n    }\n  else if (!strcmp(page, \"ChangesRss\"))\n    {\n      wiki_show_changes_page_rss(res);\n    }\n  else if (!strcmp(page, \"Search\"))\n    {\n      wiki_show_search_results_page(res, http_request_param_get(req, \"expr\"));\n    }\n  else if (!strcmp(page, \"Create\"))\n    {\n      if ( (wikitext = http_request_param_get(req, \"title\")) != NULL)\n\t{\n\t  /* create page and redirect */\n\t  wiki_redirect(res, http_request_param_get(req, \"title\"));\n\t}\n      else\n\t{\n\t   /* show create page form  */\n\t  wiki_show_create_page(res);\n\t}\n    }\n  else\n    {\n      /* TODO: dont blindly write wikitext data to disk */\n      if ( (wikitext = http_request_param_get(req, \"wikitext\")) != NULL)\n\t{\n\t  file_write(page, wikitext);\t      \n\t}\n\n      if (access(page, R_OK) == 0) \t/* page exists */\n\t{\n\t  wikitext = file_read(page);\n\t  \n\t  if (!strcmp(command, \"edit\"))\n\t    {\n\t      /* print edit page */\n\t      wiki_show_edit_page(res, wikitext, page);\n\t    }\n\t  else\n\t    {\n\t      wiki_show_page(res, wikitext, page);\n\t    }\n\t}\n      else\n\t{\n\t  if (!strcmp(command, \"create\"))\n\t    {\n\t      wiki_show_edit_page(res, NULL, page);\n\t    }\n\t  else\n\t    {\n\t      char buf[1024];\n\t      snprintf(buf, 1024, \"%s?create\", page);\n\t      wiki_redirect(res, buf);\n\t    }\n\t}\n    }\n\n}", "func_src_after": "wiki_handle_http_request(HttpRequest *req)\n{\n  HttpResponse *res      = http_response_new(req);\n  char         *page     = http_request_get_path_info(req); \n  char         *command  = http_request_get_query_string(req); \n  char         *wikitext = \"\";\n\n  util_dehttpize(page); \t/* remove any encoding on the requested\n\t\t\t\t   page name.                           */\n\n  if (!strcmp(page, \"/\"))\n    {\n      if (access(\"WikiHome\", R_OK) != 0)\n\twiki_redirect(res, \"/WikiHome?create\");\n      page = \"/WikiHome\";\n    }\n\n  if (!strcmp(page, \"/styles.css\"))\n    {\n      /*  Return CSS page */\n      http_response_set_content_type(res, \"text/css\");\n      http_response_printf(res, \"%s\", CssData);\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"/favicon.ico\"))\n    {\n      /*  Return favicon */\n      http_response_set_content_type(res, \"image/ico\");\n      http_response_set_data(res, FaviconData, FaviconDataLen);\n      http_response_send(res);\n      exit(0);\n    }\n\n\n  page = page + 1; \t\t/* skip slash */\n\n  if (!strncmp(page, \"api/\", 4))\n    {\n      char *p;\n\n      page += 4; \n      for (p=page; *p != '\\0'; p++)\n\tif (*p=='?') { *p ='\\0'; break; }\n      \n      wiki_handle_rest_call(req, res, page); \n      exit(0);\n    }\n\n  /* A little safety. issue a malformed request for any paths,\n   * There shouldn't need to be any..\n   */\n  if (!page_name_is_good(page))\n    {\n      http_response_set_status(res, 404, \"Not Found\");\n      http_response_printf(res, \"<html><body>404 Not Found</body></html>\\n\");\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"Changes\"))\n    {\n      wiki_show_changes_page(res);\n    }\n  else if (!strcmp(page, \"ChangesRss\"))\n    {\n      wiki_show_changes_page_rss(res);\n    }\n  else if (!strcmp(page, \"Search\"))\n    {\n      wiki_show_search_results_page(res, http_request_param_get(req, \"expr\"));\n    }\n  else if (!strcmp(page, \"Create\"))\n    {\n      if ( (wikitext = http_request_param_get(req, \"title\")) != NULL)\n\t{\n\t  /* create page and redirect */\n\t  wiki_redirect(res, http_request_param_get(req, \"title\"));\n\t}\n      else\n\t{\n\t   /* show create page form  */\n\t  wiki_show_create_page(res);\n\t}\n    }\n  else\n    {\n      /* TODO: dont blindly write wikitext data to disk */\n      if ( (wikitext = http_request_param_get(req, \"wikitext\")) != NULL)\n\t{\n\t  file_write(page, wikitext);\t      \n\t}\n\n      if (access(page, R_OK) == 0) \t/* page exists */\n\t{\n\t  wikitext = file_read(page);\n\t  \n\t  if (!strcmp(command, \"edit\"))\n\t    {\n\t      /* print edit page */\n\t      wiki_show_edit_page(res, wikitext, page);\n\t    }\n\t  else\n\t    {\n\t      wiki_show_page(res, wikitext, page);\n\t    }\n\t}\n      else\n\t{\n\t  if (!strcmp(command, \"create\"))\n\t    {\n\t      wiki_show_edit_page(res, NULL, page);\n\t    }\n\t  else\n\t    {\n\t      char buf[1024];\n\t      snprintf(buf, 1024, \"%s?create\", page);\n\t      wiki_redirect(res, buf);\n\t    }\n\t}\n    }\n\n}", "commit_link": "github.com/yarolig/didiwiki/commit/5e5c796617e1712905dc5462b94bd5e6c08d15ea", "file_name": "src/wiki.c", "vul_type": "cwe-022", "description": "In C, write a function to handle HTTP requests for a simple wiki, including serving static files, API calls, and wiki page creation or editing."}
{"func_name": "write_section", "func_src_before": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = section_data[key]\n            self.icinga_lines.append((\"%s%-45s%s\" % (self.indent, key, self.value_to_icinga(value))))\n        self.write_line(\"}\")", "func_src_after": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = self.value_to_icinga(section_data[key])\n            icinga_line = \"%s%-45s%s\" % (self.indent, key, value)\n\n            if \"\\n\" in icinga_line or \"}\" in icinga_line:\n                msg = \"Found forbidden newline or '}' character in section %r.\"\n                raise Exception(msg % section_name)\n\n            self.icinga_lines.append(icinga_line)\n        self.write_line(\"}\")", "commit_link": "github.com/Scout24/monitoring-config-generator/commit/a4b01b72d2e3d6ec2600c384a77f675fa9bbf6b7", "file_name": "src/main/python/monitoring_config_generator/MonitoringConfigGenerator.py", "vul_type": "cwe-078", "description": "In Python, write a function to format and append a configuration section with sorted keys to a list, ensuring no newlines or closing braces are present in the values."}
{"func_name": "self.read", "func_src_before": "  def self.read(path=default_path)\n    perm = File.stat(path).mode & 0777\n    if perm != 0600 && !(WINDOWS)\n      raise Error, \"Permission bits for '#{path}' should be 0600, but are \"+perm.to_s(8)\n    end\n    new(path, parse(lex(IO.readlines(path))))\n  rescue Errno::ENOENT\n    new(path, parse(lex([])))\n  end", "func_src_after": "  def self.read(path=default_path)\n    perm = File.stat(path).mode & 0777\n    if perm != 0600 && !(WINDOWS)\n      raise Error, \"Permission bits for '#{path}' should be 0600, but are \"+perm.to_s(8)\n    end\n    new(path, parse(lex(File.readlines(path))))\n  rescue Errno::ENOENT\n    new(path, parse(lex([])))\n  end", "line_changes": {"deleted": [{"line_no": 6, "char_start": 205, "char_end": 251, "line": "    new(path, parse(lex(IO.readlines(path))))\n"}], "added": [{"line_no": 6, "char_start": 205, "char_end": 253, "line": "    new(path, parse(lex(File.readlines(path))))\n"}]}, "char_changes": {"deleted": [{"char_start": 229, "char_end": 231, "chars": "IO"}], "added": [{"char_start": 229, "char_end": 233, "chars": "File"}]}, "commit_link": "github.com/trevorgrayson/netrc/commit/544dc4b092d63d3df588ef61274cc32ad1376b02", "file_name": "netrc.rb", "vul_type": "cwe-078", "commit_msg": "use File.readlines instead of IO.readlines", "parent_commit": "41618416a23ff3b5ecd596c6f8eee1bba363a6ef", "description": "Create a Ruby method that reads from a file at a given path, checks for specific file permissions, and handles the case where the file does not exist."}
{"func_name": "html_content", "func_src_before": "    @property\n    async def html_content(self):\n        content = await self.content\n        if not content:\n            return ''\n        return markdown(content)", "func_src_after": "    @property\n    async def html_content(self):\n        content = markupsafe.escape(await self.content)\n        if not content:\n            return ''\n        return markdown(content)", "commit_link": "github.com/dongweiming/lyanna/commit/fcefac79e4b7601e81a3b3fe0ad26ab18ee95d7d", "file_name": "models/comment.py", "vul_type": "cwe-079", "description": "Generate a Python async property method that converts stored content to HTML, handling empty content and ensuring safe markup."}
{"func_name": "SpliceImage", "func_src_before": "MagickExport Image *SpliceImage(const Image *image,\n  const RectangleInfo *geometry,ExceptionInfo *exception)\n{\n#define SpliceImageTag  \"Splice/Image\"\n\n  CacheView\n    *image_view,\n    *splice_view;\n\n  Image\n    *splice_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  RectangleInfo\n    splice_geometry;\n\n  ssize_t\n    y;\n\n  /*\n    Allocate splice image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(geometry != (const RectangleInfo *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  splice_geometry=(*geometry);\n  splice_image=CloneImage(image,image->columns+splice_geometry.width,\n    image->rows+splice_geometry.height,MagickTrue,exception);\n  if (splice_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(splice_image,DirectClass,exception) == MagickFalse)\n    {\n      splice_image=DestroyImage(splice_image);\n      return((Image *) NULL);\n    }\n  if ((IsPixelInfoGray(&splice_image->background_color) == MagickFalse) &&\n      (IsGrayColorspace(splice_image->colorspace) != MagickFalse))\n    (void) SetImageColorspace(splice_image,sRGBColorspace,exception);\n  if ((splice_image->background_color.alpha_trait != UndefinedPixelTrait) &&\n      (splice_image->alpha_trait == UndefinedPixelTrait))\n    (void) SetImageAlpha(splice_image,OpaqueAlpha,exception);\n  (void) SetImageBackgroundColor(splice_image,exception);\n  /*\n    Respect image geometry.\n  */\n  switch (image->gravity)\n  {\n    default:\n    case UndefinedGravity:\n    case NorthWestGravity:\n      break;\n    case NorthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case NorthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      break;\n    }\n    case WestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case CenterGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case EastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case SouthWestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n  }\n  /*\n    Splice image.\n  */\n  status=MagickTrue;\n  progress=0;\n  image_view=AcquireVirtualCacheView(image,exception);\n  splice_view=AcquireAuthenticCacheView(splice_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=0; y < (ssize_t) splice_geometry.y; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,image->columns,1,exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < splice_geometry.x; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=(ssize_t) (splice_geometry.y+splice_geometry.height);\n       y < (ssize_t) splice_image->rows; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y-(ssize_t) splice_geometry.height,\n      image->columns,1,exception);\n    if ((y < 0) || (y >= (ssize_t) splice_image->rows))\n      continue;\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < splice_geometry.x; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  splice_view=DestroyCacheView(splice_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    splice_image=DestroyImage(splice_image);\n  return(splice_image);\n}", "func_src_after": "MagickExport Image *SpliceImage(const Image *image,\n  const RectangleInfo *geometry,ExceptionInfo *exception)\n{\n#define SpliceImageTag  \"Splice/Image\"\n\n  CacheView\n    *image_view,\n    *splice_view;\n\n  Image\n    *splice_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  RectangleInfo\n    splice_geometry;\n\n  ssize_t\n    columns,\n    y;\n\n  /*\n    Allocate splice image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(geometry != (const RectangleInfo *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  splice_geometry=(*geometry);\n  splice_image=CloneImage(image,image->columns+splice_geometry.width,\n    image->rows+splice_geometry.height,MagickTrue,exception);\n  if (splice_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(splice_image,DirectClass,exception) == MagickFalse)\n    {\n      splice_image=DestroyImage(splice_image);\n      return((Image *) NULL);\n    }\n  if ((IsPixelInfoGray(&splice_image->background_color) == MagickFalse) &&\n      (IsGrayColorspace(splice_image->colorspace) != MagickFalse))\n    (void) SetImageColorspace(splice_image,sRGBColorspace,exception);\n  if ((splice_image->background_color.alpha_trait != UndefinedPixelTrait) &&\n      (splice_image->alpha_trait == UndefinedPixelTrait))\n    (void) SetImageAlpha(splice_image,OpaqueAlpha,exception);\n  (void) SetImageBackgroundColor(splice_image,exception);\n  /*\n    Respect image geometry.\n  */\n  switch (image->gravity)\n  {\n    default:\n    case UndefinedGravity:\n    case NorthWestGravity:\n      break;\n    case NorthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case NorthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      break;\n    }\n    case WestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case CenterGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case EastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case SouthWestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n  }\n  /*\n    Splice image.\n  */\n  status=MagickTrue;\n  progress=0;\n  columns=MagickMin(splice_geometry.x,(ssize_t) splice_image->columns);\n  image_view=AcquireVirtualCacheView(image,exception);\n  splice_view=AcquireAuthenticCacheView(splice_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=0; y < (ssize_t) splice_geometry.y; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,splice_image->columns,1,\n      exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=(ssize_t) (splice_geometry.y+splice_geometry.height);\n       y < (ssize_t) splice_image->rows; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    if ((y < 0) || (y >= (ssize_t)splice_image->rows))\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y-(ssize_t) splice_geometry.height,\n      splice_image->columns,1,exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  splice_view=DestroyCacheView(splice_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    splice_image=DestroyImage(splice_image);\n  return(splice_image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/7b1cf5784b5bcd85aa9293ecf56769f68c037231", "file_name": "MagickCore/transform.c", "vul_type": "cwe-125", "description": "Write a C function to splice an image with a given geometry in ImageMagick."}
{"func_name": "exports.rsync", "func_src_before": "exports.rsync = function (options,callback) {\n\n    options = options || {};\n\n    if ( typeof options.src === \"undefined\" ) {\n        throw(new Error(\"Source directory 'src' is missing from options\"));\n    }\n\n    if ( typeof options.dest === \"undefined\" ) {\n        throw(new Error(\"Destination directory 'dest' is missing from options\"));\n    }\n\n    if ( typeof options.host !== \"undefined\" ) {\n        options.dest = options.host+\":\"+options.dest;\n    }\n\n    var args = [options.src,options.dest];\n\n    if ( typeof options.host !== \"undefined\" ) {\n        args.push(\"--rsh=ssh\");\n    }\n\n    if ( options.recursive === true ) {\n        args.push(\"--recursive\");\n    }\n\n    if ( options.syncDest === true ) {\n        args.push(\"--delete\");\n        args.push(\"--delete-excluded\");\n    }\n\n    if ( options.dryRun === true ) {\n        args.push(\"--dry-run\");\n        args.push(\"--verbose\");\n        args.push(\"--stats\");\n    }\n\n    if ( typeof options.exclude !== \"undefined\" && util.isArray(options.exclude) ) {\n        options.exclude.forEach(function (value,index) {\n            args.push(\"--exclude=\"+value);\n        });\n    }\n\n    switch ( options.compareMode ) {\n        case \"sizeOnly\":\n            args.push(\"--size-only\");\n            break;\n        case \"checksum\":\n            args.push(\"--checksum\");\n            break;\n    }\n\n    if ( typeof options.args !== \"undefined\" && util.isArray(options.args) ) {\n        args = _.union(args,options.args);\n    }\n\n    args = _.unique(args);\n\n    var cmd = \"rsync \"+args.join(\" \");\n\n    try {\n        exec(cmd,function (error,stdout,stderr) {\n            callback(error,stdout,stderr,cmd);\n        });\n    } catch (error) {\n        callback(error,null,null,cmd);\n    }\n};", "func_src_after": "exports.rsync = function (options,callback) {\n\n    options = options || {};\n\n    if ( typeof options.src === \"undefined\" ) {\n        throw(new Error(\"Source directory 'src' is missing from options\"));\n    }\n\n    if ( typeof options.dest === \"undefined\" ) {\n        throw(new Error(\"Destination directory 'dest' is missing from options\"));\n    }\n\n    if ( typeof options.host !== \"undefined\" ) {\n        options.dest = options.host+\":\"+options.dest;\n    }\n\n    var args = [options.src,options.dest];\n\n    if ( typeof options.host !== \"undefined\" ) {\n        args.push(\"--rsh=ssh\");\n    }\n\n    if ( options.recursive === true ) {\n        args.push(\"--recursive\");\n    }\n\n    if ( options.syncDest === true ) {\n        args.push(\"--delete\");\n        args.push(\"--delete-excluded\");\n    }\n\n    if ( options.dryRun === true ) {\n        args.push(\"--dry-run\");\n        args.push(\"--verbose\");\n        args.push(\"--stats\");\n    }\n\n    if ( typeof options.exclude !== \"undefined\" && util.isArray(options.exclude) ) {\n        options.exclude.forEach(function (value,index) {\n            args.push(\"--exclude=\"+value);\n        });\n    }\n\n    switch ( options.compareMode ) {\n        case \"sizeOnly\":\n            args.push(\"--size-only\");\n            break;\n        case \"checksum\":\n            args.push(\"--checksum\");\n            break;\n    }\n\n    if ( typeof options.args !== \"undefined\" && util.isArray(options.args) ) {\n        args = _.union(args,options.args);\n    }\n    \n    args = _.unique(args);   \n\n    var cmd = \"rsync \"+args.join(\" \");\n\n    try {\n        var process = spawn('rsync', args);\n\t\tvar stdoutBuffer = ''\n\t\tvar stderrBuffer = '';\n\n\t\tprocess.stdout.on('data', function (data) {\n\t\t\tstdoutBuffer += data;\t\t\n\t\t});\n\n\t\tprocess.stderr.on('data', function (data) {\n\t\t\tstderrBuffer += data;\n\t\t});\n\n        process.on('exit', function (errorCode) {\n            if(errorCode===0) errorCode=null;\n            callback(errorCode,stdoutBuffer,stderrBuffer,cmd);\n        });\n    } catch (error) {\n        callback(error,null,null,cmd);\n    }\n};", "line_changes": {"deleted": [{"line_no": 56, "char_start": 1463, "char_end": 1464, "line": "\n"}, {"line_no": 57, "char_start": 1464, "char_end": 1491, "line": "    args = _.unique(args);\n"}, {"line_no": 62, "char_start": 1542, "char_end": 1592, "line": "        exec(cmd,function (error,stdout,stderr) {\n"}, {"line_no": 63, "char_start": 1592, "char_end": 1639, "line": "            callback(error,stdout,stderr,cmd);\n"}], "added": [{"line_no": 56, "char_start": 1463, "char_end": 1468, "line": "    \n"}, {"line_no": 57, "char_start": 1468, "char_end": 1498, "line": "    args = _.unique(args);   \n"}, {"line_no": 62, "char_start": 1549, "char_end": 1593, "line": "        var process = spawn('rsync', args);\n"}, {"line_no": 63, "char_start": 1593, "char_end": 1617, "line": "\t\tvar stdoutBuffer = ''\n"}, {"line_no": 64, "char_start": 1617, "char_end": 1642, "line": "\t\tvar stderrBuffer = '';\n"}, {"line_no": 65, "char_start": 1642, "char_end": 1643, "line": "\n"}, {"line_no": 66, "char_start": 1643, "char_end": 1689, "line": "\t\tprocess.stdout.on('data', function (data) {\n"}, {"line_no": 67, "char_start": 1689, "char_end": 1716, "line": "\t\t\tstdoutBuffer += data;\t\t\n"}, {"line_no": 68, "char_start": 1716, "char_end": 1722, "line": "\t\t});\n"}, {"line_no": 69, "char_start": 1722, "char_end": 1723, "line": "\n"}, {"line_no": 70, "char_start": 1723, "char_end": 1769, "line": "\t\tprocess.stderr.on('data', function (data) {\n"}, {"line_no": 71, "char_start": 1769, "char_end": 1794, "line": "\t\t\tstderrBuffer += data;\n"}, {"line_no": 72, "char_start": 1794, "char_end": 1800, "line": "\t\t});\n"}, {"line_no": 73, "char_start": 1800, "char_end": 1801, "line": "\n"}, {"line_no": 74, "char_start": 1801, "char_end": 1851, "line": "        process.on('exit', function (errorCode) {\n"}, {"line_no": 75, "char_start": 1851, "char_end": 1897, "line": "            if(errorCode===0) errorCode=null;\n"}, {"line_no": 76, "char_start": 1897, "char_end": 1960, "line": "            callback(errorCode,stdoutBuffer,stderrBuffer,cmd);\n"}]}, "char_changes": {"deleted": [{"char_start": 1550, "char_end": 1591, "chars": "exec(cmd,function (error,stdout,stderr) {"}, {"char_start": 1625, "char_end": 1631, "chars": ",stder"}], "added": [{"char_start": 1463, "char_end": 1467, "chars": "    "}, {"char_start": 1494, "char_end": 1497, "chars": "   "}, {"char_start": 1557, "char_end": 1896, "chars": "var process = spawn('rsync', args);\n\t\tvar stdoutBuffer = ''\n\t\tvar stderrBuffer = '';\n\n\t\tprocess.stdout.on('data', function (data) {\n\t\t\tstdoutBuffer += data;\t\t\n\t\t});\n\n\t\tprocess.stderr.on('data', function (data) {\n\t\t\tstderrBuffer += data;\n\t\t});\n\n        process.on('exit', function (errorCode) {\n            if(errorCode===0) errorCode=null;"}, {"char_start": 1923, "char_end": 1927, "chars": "Code"}, {"char_start": 1934, "char_end": 1952, "chars": "Buffer,stderrBuffe"}]}, "commit_link": "github.com/HaroldPutman/rsyncwrapper/commit/a763cc4a929805b977a278148e246234340e6af7", "file_name": "rsyncwrapper.js", "vul_type": "cwe-078", "commit_msg": "Changed child_process exec to spawn\n\nTo fix 'maxBuffer' exceeding issues on very large stdout responses. Attempted to maintain the same callback methods by buffering the stout and std err. Only errorCodes are passed and not error Signals.", "description": "Write a Node.js function in JavaScript that performs a customizable rsync operation with error handling."}
{"func_name": "r_bin_java_line_number_table_attr_new", "func_src_before": "R_API RBinJavaAttrInfo *r_bin_java_line_number_table_attr_new(ut8 *buffer, ut64 sz, ut64 buf_offset) {\n\tut32 i = 0;\n\tut64 curpos, offset = 0;\n\tRBinJavaLineNumberAttribute *lnattr;\n\tRBinJavaAttrInfo *attr = r_bin_java_default_attr_new (buffer, sz, buf_offset);\n\tif (!attr) {\n\t\treturn NULL;\n\t}\n\toffset += 6;\n\tattr->type = R_BIN_JAVA_ATTR_TYPE_LINE_NUMBER_TABLE_ATTR;\n\tattr->info.line_number_table_attr.line_number_table_length = R_BIN_JAVA_USHORT (buffer, offset);\n\toffset += 2;\n\tattr->info.line_number_table_attr.line_number_table = r_list_newf (free);\n\n\tut32 linenum_len = attr->info.line_number_table_attr.line_number_table_length;\n\tRList *linenum_list = attr->info.line_number_table_attr.line_number_table;\n\tif (linenum_len > sz) {\n\t\tfree (attr);\n\t\treturn NULL;\n\t}\n\tfor (i = 0; i < linenum_len; i++) {\n\t\tcurpos = buf_offset + offset;\n\t\t// printf (\"%llx %llx \\n\", curpos, sz);\n\t\t// XXX if (curpos + 8 >= sz) break;\n\t\tlnattr = R_NEW0 (RBinJavaLineNumberAttribute);\n\t\tif (!lnattr) {\n\t\t\tbreak;\n\t\t}\n\t\tlnattr->start_pc = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->line_number = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->file_offset = curpos;\n\t\tlnattr->size = 4;\n\t\tr_list_append (linenum_list, lnattr);\n\t}\n\tattr->size = offset;\n\treturn attr;\n}", "func_src_after": "R_API RBinJavaAttrInfo *r_bin_java_line_number_table_attr_new(ut8 *buffer, ut64 sz, ut64 buf_offset) {\n\tut32 i = 0;\n\tut64 curpos, offset = 0;\n\tRBinJavaLineNumberAttribute *lnattr;\n\tRBinJavaAttrInfo *attr = r_bin_java_default_attr_new (buffer, sz, buf_offset);\n\tif (!attr) {\n\t\treturn NULL;\n\t}\n\toffset += 6;\n\tattr->type = R_BIN_JAVA_ATTR_TYPE_LINE_NUMBER_TABLE_ATTR;\n\tattr->info.line_number_table_attr.line_number_table_length = R_BIN_JAVA_USHORT (buffer, offset);\n\toffset += 2;\n\tattr->info.line_number_table_attr.line_number_table = r_list_newf (free);\n\n\tut32 linenum_len = attr->info.line_number_table_attr.line_number_table_length;\n\tRList *linenum_list = attr->info.line_number_table_attr.line_number_table;\n\tif (linenum_len > sz) {\n\t\tfree (attr);\n\t\treturn NULL;\n\t}\n\tfor (i = 0; i < linenum_len; i++) {\n\t\tcurpos = buf_offset + offset;\n\t\t// printf (\"%llx %llx \\n\", curpos, sz);\n\t\t// XXX if (curpos + 8 >= sz) break;\n\t\tlnattr = R_NEW0 (RBinJavaLineNumberAttribute);\n\t\tif (!lnattr) {\n\t\t\tbreak;\n\t\t}\n\t\tif (offset + 8 >= sz) {\n\t\t\tbreak;\n\t\t}\n\t\tlnattr->start_pc = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->line_number = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->file_offset = curpos;\n\t\tlnattr->size = 4;\n\t\tr_list_append (linenum_list, lnattr);\n\t}\n\tattr->size = offset;\n\treturn attr;\n}", "commit_link": "github.com/radare/radare2/commit/eb0fb72b3c5307ec8e33effb6bf947e38cfdffe8", "file_name": "shlr/java/class.c", "vul_type": "cwe-125", "description": "In C, write a function to create a new Java line number table attribute from a binary buffer."}
{"func_name": "read_quant_matrix_ext", "func_src_before": "static void read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n}", "func_src_after": "static int read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/5aba5b89d0b1d73164d3b81764828bb8b20ff32a", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to read and optionally update quantization matrices from a bitstream in an MPEG encoding context."}
{"func_name": "add_article_action", "func_src_before": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = request.POST[\"notes\"]\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "func_src_after": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = escape(request.POST[\"notes\"])\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = escape(str(request.POST[str(\"notes_\" + str(art.id))]))\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/reservation_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle adding single or multiple articles to a reservation, with redirection and error handling."}
{"func_name": "ServerDefault", "func_src_before": "func ServerDefault(ops ...func(*tls.Config)) *tls.Config {\n\ttlsconfig := &tls.Config{\n\t\t// Avoid fallback by default to SSL protocols < TLS1.0\n\t\tMinVersion:               tls.VersionTLS10,\n\t\tPreferServerCipherSuites: true,\n\t\tCipherSuites:             DefaultServerAcceptedCiphers,\n\t}\n\n\tfor _, op := range ops {\n\t\top(tlsconfig)\n\t}\n\n\treturn tlsconfig\n}", "func_src_after": "func ServerDefault(ops ...func(*tls.Config)) *tls.Config {\n\ttlsconfig := &tls.Config{\n\t\t// Avoid fallback by default to SSL protocols < TLS1.2\n\t\tMinVersion:               tls.VersionTLS12,\n\t\tPreferServerCipherSuites: true,\n\t\tCipherSuites:             DefaultServerAcceptedCiphers,\n\t}\n\n\tfor _, op := range ops {\n\t\top(tlsconfig)\n\t}\n\n\treturn tlsconfig\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 143, "char_end": 189, "line": "\t\tMinVersion:               tls.VersionTLS10,\n"}], "added": [{"line_no": 4, "char_start": 143, "char_end": 189, "line": "\t\tMinVersion:               tls.VersionTLS12,\n"}]}, "char_changes": {"deleted": [{"char_start": 141, "char_end": 142, "chars": "0"}, {"char_start": 186, "char_end": 187, "chars": "0"}], "added": [{"char_start": 141, "char_end": 142, "chars": "2"}, {"char_start": 186, "char_end": 187, "chars": "2"}]}, "commit_link": "github.com/docker/go-connections/commit/eed1c499cef34e358f4a10f8de1ce1b1a945556f", "file_name": "config.go", "vul_type": "cwe-327", "commit_msg": "Remove server support for TLS 1.0 and TLS 1.1\n\nThis should not be needed any more and is not recommended.\n\nSigned-off-by: Justin Cormack <justin.cormack@docker.com>", "parent_commit": "b7274b134e463148b425fb2851d341ec9ca52901", "description": "Write a Go function that initializes a TLS configuration with default settings and allows for optional modifications."}
{"func_name": "gravatar", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef gravatar(context, user, size=None):\n    \"\"\"\n    Outputs the HTML for displaying a user's gravatar.\n\n    This can take an optional size of the image (defaults to 80 if not\n    specified).\n\n    This is also influenced by the following settings:\n\n        GRAVATAR_SIZE    - Default size for gravatars\n        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)\n        GRAVATAR_DEFAULT - Default image set to show if the user hasn't\n                           specified a gravatar (identicon, monsterid, wavatar)\n\n    See http://www.gravatar.com/ for more information.\n    \"\"\"\n    url = get_gravatar_url(context['request'], user, size)\n\n    if url:\n        return ('<img src=\"%s\" width=\"%s\" height=\"%s\" alt=\"%s\" '\n                '     class=\"gravatar\"/>' %\n                (url, size, size, user.get_full_name() or user.username))\n    else:\n        return ''", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef gravatar(context, user, size=None):\n    \"\"\"\n    Outputs the HTML for displaying a user's gravatar.\n\n    This can take an optional size of the image (defaults to 80 if not\n    specified).\n\n    This is also influenced by the following settings:\n\n        GRAVATAR_SIZE    - Default size for gravatars\n        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)\n        GRAVATAR_DEFAULT - Default image set to show if the user hasn't\n                           specified a gravatar (identicon, monsterid, wavatar)\n\n    See http://www.gravatar.com/ for more information.\n    \"\"\"\n    url = get_gravatar_url(context['request'], user, size)\n\n    if url:\n        return format_html(\n            '<img src=\"{0}\" width=\"{1}\" height=\"{1}\" alt=\"{2}\" '\n            'class=\"gravatar\"/>',\n            url, size, user.get_full_name() or user.username)\n    else:\n        return ''", "commit_link": "github.com/djblets/djblets/commit/77ac64642ad530bf69e390c51fc6fdcb8914c8e7", "file_name": "djblets/gravatars/templatetags/gravatars.py", "vul_type": "cwe-079", "description": "Create a Django template tag in Python that generates an HTML image tag for a user's Gravatar with an optional size parameter."}
{"func_name": "check_and_update_ranks", "func_src_before": "    def check_and_update_ranks(self, scene):\n        # There are 2 cases here:\n        #   1) Ranks have never been calculated for this scene before\n        #       - This means we need to calculate what the ranks were every month of this scenes history\n        #       - We should only do this if ranks don't already exist for this scene\n        #   2) Ranks have been calculated for this scene before\n        #       - We already have bulk ranks. We should check if it has been more than 1 month since we last\n        #           calculated ranks. If so, calculate again with the brackets that have come out this month\n\n        LOG.info('About to check if ranks need updating for {}'.format(scene))\n        # First, do we have any ranks for this scene already?\n        sql = 'select count(*) from ranks where scene=\"{}\";'.format(scene)\n        res = self.db.exec(sql)\n        count = res[0][0]\n\n        n = 5 if (scene == 'pro' or scene == 'pro_wiiu') else constants.TOURNAMENTS_PER_RANK\n        if count == 0:\n            LOG.info('Detected that we need to bulk update ranks for {}'.format(scene))\n            # Alright, we have nothing. Bulk update ranks\n            first_month = bracket_utils.get_first_month(self.db, scene)\n            last_month = bracket_utils.get_last_month(self.db, scene)\n            \n            # Iterate through all tournaments going month by month, and calculate ranks\n            months = bracket_utils.iter_months(first_month, last_month, include_first=False, include_last=True)\n            for month in months:\n                urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                self.process_ranks(scene, urls, month)\n        else:\n\n            # Get the date of the last time we calculated ranks\n            sql = \"select date from ranks where scene='{}' order by date desc limit 1;\".format(scene)\n            res = self.db.exec(sql)\n            last_rankings_date = res[0][0]\n\n            # Check to see if it's been more than 1 month since we last calculated ranks\n            more_than_one_month = bracket_utils.has_month_passed(last_rankings_date)\n            if more_than_one_month:\n                # Get only the last n tournaments, so it doesn't take too long to process\n                today = datetime.datetime.today().strftime('%Y-%m-%d')\n                msg = 'Detected that we need up update monthly ranks for {}, on {}'.format(scene, today)\n                LOG.info(msg)\n\n                # We should only ever calculate ranks on the 1st. If today is not the first, log error\n                if not today.split('-')[-1] == '1':\n                    LOG.exc('We are calculating ranks today, {}, but it isnt the first'.format(today))\n\n                months = bracket_utils.iter_months(last_rankings_date, today, include_first=False, include_last=True)\n                for month in months:\n                    # Make sure that we actually have matches during this month\n                    # Say we are trying to calculate ranks for 2018-05-01, the player would need to have matches during 2018-04-01, 2018-04-30\n                    prev_date = bracket_utils.get_previous_month(month)\n                    brackets_during_month = bracket_utils.get_tournaments_during_month(self.db, scene, prev_date)\n\n                    if len(brackets_during_month) > 0:\n                        tweet('Calculating {} ranks for {}'.format(month, scene))\n                        urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                        self.process_ranks(scene, urls, month)\n\n            else:\n                LOG.info('It has not yet been 1 month since we calculated ranks for {}. Skipping'.format(scene))", "func_src_after": "    def check_and_update_ranks(self, scene):\n        # There are 2 cases here:\n        #   1) Ranks have never been calculated for this scene before\n        #       - This means we need to calculate what the ranks were every month of this scenes history\n        #       - We should only do this if ranks don't already exist for this scene\n        #   2) Ranks have been calculated for this scene before\n        #       - We already have bulk ranks. We should check if it has been more than 1 month since we last\n        #           calculated ranks. If so, calculate again with the brackets that have come out this month\n\n        LOG.info('About to check if ranks need updating for {}'.format(scene))\n        # First, do we have any ranks for this scene already?\n        sql = 'select count(*) from ranks where scene=\"{scene}\";'\n        args = {'scene': scene}\n        res = self.db.exec(sql, args)\n        count = res[0][0]\n\n        n = 5 if (scene == 'pro' or scene == 'pro_wiiu') else constants.TOURNAMENTS_PER_RANK\n        if count == 0:\n            LOG.info('Detected that we need to bulk update ranks for {}'.format(scene))\n            # Alright, we have nothing. Bulk update ranks\n            first_month = bracket_utils.get_first_month(self.db, scene)\n            last_month = bracket_utils.get_last_month(self.db, scene)\n            \n            # Iterate through all tournaments going month by month, and calculate ranks\n            months = bracket_utils.iter_months(first_month, last_month, include_first=False, include_last=True)\n            for month in months:\n                urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                self.process_ranks(scene, urls, month)\n        else:\n\n            # Get the date of the last time we calculated ranks\n            sql = \"select date from ranks where scene='{scene}' order by date desc limit 1;\"\n            args = {'scene': scene}\n            res = self.db.exec(sql, args)\n            last_rankings_date = res[0][0]\n\n            # Check to see if it's been more than 1 month since we last calculated ranks\n            more_than_one_month = bracket_utils.has_month_passed(last_rankings_date)\n            if more_than_one_month:\n                # Get only the last n tournaments, so it doesn't take too long to process\n                today = datetime.datetime.today().strftime('%Y-%m-%d')\n                msg = 'Detected that we need up update monthly ranks for {}, on {}'.format(scene, today)\n                LOG.info(msg)\n\n                # We should only ever calculate ranks on the 1st. If today is not the first, log error\n                if not today.split('-')[-1] == '1':\n                    LOG.exc('We are calculating ranks today, {}, but it isnt the first'.format(today))\n\n                months = bracket_utils.iter_months(last_rankings_date, today, include_first=False, include_last=True)\n                for month in months:\n                    # Make sure that we actually have matches during this month\n                    # Say we are trying to calculate ranks for 2018-05-01, the player would need to have matches during 2018-04-01, 2018-04-30\n                    prev_date = bracket_utils.get_previous_month(month)\n                    brackets_during_month = bracket_utils.get_tournaments_during_month(self.db, scene, prev_date)\n\n                    if len(brackets_during_month) > 0:\n                        tweet('Calculating {} ranks for {}'.format(month, scene))\n                        urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                        self.process_ranks(scene, urls, month)\n\n            else:\n                LOG.info('It has not yet been 1 month since we calculated ranks for {}. Skipping'.format(scene))", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "process_data.py", "vul_type": "cwe-089", "description": "In Python, write a function to update ranking data for a given scene, either by bulk calculating historical monthly ranks if none exist, or by updating ranks if it's been over a month since the last calculation."}
{"func_name": "update_dir_from_tar", "func_src_before": "def update_dir_from_tar(tar, root_dir):\n    directories = []\n    valid_paths = BloomSet()\n    for entry in tar:\n        # Convert entry type to stat constant\n        if entry.type == tarfile.DIRTYPE:\n            entry_stat_type = stat.S_IFDIR\n        elif entry.type in (tarfile.REGTYPE, tarfile.LNKTYPE):\n            # Coda apparently doesn't allow hard links to symlinks\n            entry_stat_type = stat.S_IFREG\n        elif entry.type == tarfile.SYMTYPE:\n            entry_stat_type = stat.S_IFLNK\n        else:\n            raise ValueError(f\"Unexpected file type {entry.type}\")\n\n        # Check for existing file\n        path = build_path(root_dir, entry.name)\n        try:\n            st: Optional[os.stat_result] = os.lstat(path)\n        except OSError:\n            st = None\n\n        # If entry has changed types, remove the old object\n        if st is not None and stat.S_IFMT(st.st_mode) != entry_stat_type:\n            if stat.S_ISDIR(st.st_mode):\n                shutil.rmtree(path)\n            else:\n                os.unlink(path)\n            st = None\n\n        # Create parent directory if not present.  Parents are not\n        # necessarily dumped before children.\n        path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Create new object\n        if entry.isdir():\n            if not os.path.exists(path):\n                print(\"d\", path)\n                os.mkdir(path)\n            # Go back and set mtime after directory has been populated\n            directories.append(entry)\n        elif entry.isfile():\n            # update_file() will break hard links if it modifies the file.\n            # This is what we want because links may have also been broken\n            # at the source.  codadump2tar always dumps hard links, so we\n            # will rebuild any links that should still exist.\n            if update_file(path, TarMemberFile(tar, entry)):\n                print(\"f\", path)\n        elif entry.issym():\n            if st is None or entry.linkname and os.readlink(path) != entry.linkname:\n                print(\"s\", path)\n                if st is not None:\n                    os.unlink(path)\n                os.symlink(entry.linkname, path)\n        elif entry.islnk():\n            target_path = build_path(root_dir, entry.linkname)\n            target_st = os.lstat(target_path)\n            if (\n                st is None\n                or st.st_dev != target_st.st_dev\n                or st.st_ino != target_st.st_ino\n            ):\n                print(\"l\", path)\n                if st is not None:\n                    os.unlink(path)\n                os.link(target_path, path)\n\n        # Update metadata\n        attrs = XAttrs(path)\n        # owner and mode.  Hardlinks were updated with the primary, and we\n        # can't set xattrs on symlinks.\n        if entry.isfile() or entry.isdir():\n            # rsync --fake-super compatible:\n            # octal_mode_with_type major,minor uid:gid\n            mode = entry_stat_type | entry.mode\n            attrs.update(\n                ATTR_STAT,\n                f\"{mode:o} 0,0 {entry.uid}:{entry.gid}\",\n            )\n        # mtime.  Directories will be updated later, and hardlinks were\n        # updated with the primary.\n        if entry.isfile() or entry.issym() and os.lstat(path).st_mtime != entry.mtime:\n            lutime(path, entry.mtime)\n\n        # Protect from garbage collection\n        valid_paths.add(str(path))\n\n    # Deferred update of directory mtimes\n    for entry in directories:\n        path = build_path(root_dir, entry.name)\n        if os.stat(path).st_mtime != entry.mtime:\n            os.utime(path, (entry.mtime, entry.mtime))\n\n    return valid_paths", "func_src_after": "def update_dir_from_tar(tar, root_dir):\n    directories = []\n    valid_paths = BloomSet()\n    for entry in tar:\n        # Convert entry type to stat constant\n        if entry.type == tarfile.DIRTYPE:\n            entry_stat_type = stat.S_IFDIR\n        elif entry.type in (tarfile.REGTYPE, tarfile.LNKTYPE):\n            # Coda apparently doesn't allow hard links to symlinks\n            entry_stat_type = stat.S_IFREG\n        elif entry.type == tarfile.SYMTYPE:\n            entry_stat_type = stat.S_IFLNK\n        else:\n            raise ValueError(f\"Unexpected file type {entry.type}\")\n\n        # Check for existing file\n        path = build_path(root_dir, entry.name)\n        try:\n            st: Optional[os.stat_result] = os.lstat(path)\n        except OSError:\n            st = None\n\n        # If entry has changed types, remove the old object\n        if st is not None and stat.S_IFMT(st.st_mode) != entry_stat_type:\n            if stat.S_ISDIR(st.st_mode):\n                shutil.rmtree(path)\n            else:\n                os.unlink(path)\n            st = None\n\n        # Create parent directory if not present.  Parents are not\n        # necessarily dumped before children.\n        path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Create new object\n        if entry.isdir():\n            if not os.path.exists(path):\n                print(\"d\", path)\n                os.mkdir(path)\n            # Go back and set mtime after directory has been populated\n            directories.append(entry)\n        elif entry.isfile():\n            # update_file() will break hard links if it modifies the file.\n            # This is what we want because links may have also been broken\n            # at the source.  codadump2tar always dumps hard links, so we\n            # will rebuild any links that should still exist.\n            if update_file(path, TarMemberFile(tar, entry)):\n                print(\"f\", path)\n        elif entry.issym():\n            if st is None or (entry.linkname and os.readlink(path) != entry.linkname):\n                print(\"s\", path)\n                if st is not None:\n                    os.unlink(path)\n                os.symlink(entry.linkname, path)\n        elif entry.islnk():\n            target_path = build_path(root_dir, entry.linkname)\n            target_st = os.lstat(target_path)\n            if (\n                st is None\n                or st.st_dev != target_st.st_dev\n                or st.st_ino != target_st.st_ino\n            ):\n                print(\"l\", path)\n                if st is not None:\n                    os.unlink(path)\n                os.link(target_path, path)\n\n        # Update metadata\n        attrs = XAttrs(path)\n        # owner and mode.  Hardlinks were updated with the primary, and we\n        # can't set xattrs on symlinks.\n        if entry.isfile() or entry.isdir():\n            # rsync --fake-super compatible:\n            # octal_mode_with_type major,minor uid:gid\n            mode = entry_stat_type | entry.mode\n            attrs.update(\n                ATTR_STAT,\n                f\"{mode:o} 0,0 {entry.uid}:{entry.gid}\",\n            )\n        # mtime.  Directories will be updated later, and hardlinks were\n        # updated with the primary.\n        if (entry.isfile() or entry.issym()) and os.lstat(path).st_mtime != entry.mtime:\n            lutime(path, entry.mtime)\n\n        # Protect from garbage collection\n        valid_paths.add(str(path))\n\n    # Deferred update of directory mtimes\n    for entry in directories:\n        path = build_path(root_dir, entry.name)\n        if os.stat(path).st_mtime != entry.mtime:\n            os.utime(path, (entry.mtime, entry.mtime))\n\n    return valid_paths", "line_changes": {"deleted": [{"line_no": 50, "char_start": 1943, "char_end": 2028, "line": "            if st is None or entry.linkname and os.readlink(path) != entry.linkname:\n"}, {"line_no": 82, "char_start": 3217, "char_end": 3304, "line": "        if entry.isfile() or entry.issym() and os.lstat(path).st_mtime != entry.mtime:\n"}], "added": [{"line_no": 50, "char_start": 1943, "char_end": 2030, "line": "            if st is None or (entry.linkname and os.readlink(path) != entry.linkname):\n"}, {"line_no": 82, "char_start": 3219, "char_end": 3308, "line": "        if (entry.isfile() or entry.issym()) and os.lstat(path).st_mtime != entry.mtime:\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1972, "char_end": 1973, "chars": "("}, {"char_start": 2027, "char_end": 2028, "chars": ")"}, {"char_start": 3230, "char_end": 3231, "chars": "("}, {"char_start": 3262, "char_end": 3263, "chars": ")"}]}, "commit_link": "github.com/cmusatyalab/deltaic/commit/3c8fb3f8f1b75a93a17198b863b44fa78589650d", "file_name": "coda.py", "vul_type": "cwe-022", "commit_msg": "Can't use pathlib.Path.resolve() to create absolute paths\n\nBecause do not want to traverse any (final?) symlink in the path.", "parent_commit": "4c5fe2b9a04849b48a0598b70dbcfcb27a54fee5", "description": "Write a Python function to update a directory structure from a TAR file, handling file types and metadata."}
{"func_name": "check", "func_src_before": "def check(current_num):\n    try:\n        cursor.execute('SELECT * FROM comics WHERE num=\"%s\"' % current_num)\n    except sqlite3.OperationalError:\n        cursor.execute('CREATE TABLE comics (num text)')\n        return False\n    else:\n        return False if cursor.fetchone() is None else True", "func_src_after": "def check(current_num):\n    try:\n        cursor.execute('SELECT * FROM comics WHERE num=?', (current_num,))\n    except sqlite3.OperationalError:\n        cursor.execute('CREATE TABLE comics (num text)')\n        return False\n    else:\n        return False if cursor.fetchone() is None else True", "commit_link": "github.com/lord63/a_bunch_of_code/commit/c0d67a1312306fd1257c354bfb5d6cac7643aa29", "file_name": "comics/check_comics.py", "vul_type": "cwe-089", "description": "Write a Python function named `check` that queries a SQLite database for a specific record and creates a table if it doesn't exist."}
{"func_name": "rtc_irq_eoi_tracking_reset", "func_src_before": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPUS);\n}", "func_src_after": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPU_ID);\n}", "commit_link": "github.com/torvalds/linux/commit/81cdb259fb6d8c1c4ecfeea389ff5a73c07f5755", "file_name": "arch/x86/kvm/ioapic.c", "vul_type": "cwe-125", "description": "Write a C function named `rtc_irq_eoi_tracking_reset` that resets the pending EOI status and clears the destination map bitmap in a `kvm_ioapic` structure."}
{"func_name": "create_cf_base", "func_src_before": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table \" + i + \" (problems INTEGER, diff CHAR)\")\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "func_src_after": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table ? (problems INTEGER, diff CHAR)\", (i,))\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createcfbase.py", "vul_type": "cwe-089", "description": "Write a Python function to scrape Codeforces problemset data and store it in a SQLite database."}
{"func_name": "get_requested_month_for_inverter", "func_src_before": "    def get_requested_month_for_inverter(self, inverter_serial, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, DayYield AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN %s AND %s AND Serial = %s\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (month_start, month_end, inverter_serial)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM MonthData \n            WHERE Serial = %s;\n            ''' % inverter_serial\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "func_src_after": "    def get_requested_month_for_inverter(self, inverter_serial, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, DayYield AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN ? AND ? AND Serial=?;\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (month_start, month_end, inverter_serial)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM MonthData \n            WHERE Serial=?;\n            '''\n\n        self.c.execute(query, (inverter_serial,))\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch and summarize monthly power yield data for a given inverter and date, including checks for previous and next data availability."}
{"func_name": "rom_copy", "func_src_before": "int rom_copy(uint8_t *dest, hwaddr addr, size_t size)\n{\n    hwaddr end = addr + size;\n    uint8_t *s, *d = dest;\n    size_t l = 0;\n    Rom *rom;\n\n    QTAILQ_FOREACH(rom, &roms, next) {\n        if (rom->fw_file) {\n            continue;\n        }\n        if (rom->mr) {\n            continue;\n        }\n        if (rom->addr + rom->romsize < addr) {\n            continue;\n        }\n        if (rom->addr > end) {\n            break;\n        }\n\n        d = dest + (rom->addr - addr);\n        s = rom->data;\n        l = rom->datasize;\n\n        if ((d + l) > (dest + size)) {\n            l = dest - d;\n        }\n\n        if (l > 0) {\n            memcpy(d, s, l);\n        }\n\n        if (rom->romsize > rom->datasize) {\n            /* If datasize is less than romsize, it means that we didn't\n             * allocate all the ROM because the trailing data are only zeros.\n             */\n\n            d += l;\n            l = rom->romsize - rom->datasize;\n\n            if ((d + l) > (dest + size)) {\n                /* Rom size doesn't fit in the destination area. Adjust to avoid\n                 * overflow.\n                 */\n                l = dest - d;\n            }\n\n            if (l > 0) {\n                memset(d, 0x0, l);\n            }\n        }\n    }\n\n    return (d + l) - dest;\n}", "func_src_after": "int rom_copy(uint8_t *dest, hwaddr addr, size_t size)\n{\n    hwaddr end = addr + size;\n    uint8_t *s, *d = dest;\n    size_t l = 0;\n    Rom *rom;\n\n    QTAILQ_FOREACH(rom, &roms, next) {\n        if (rom->fw_file) {\n            continue;\n        }\n        if (rom->mr) {\n            continue;\n        }\n        if (rom->addr + rom->romsize < addr) {\n            continue;\n        }\n        if (rom->addr > end || rom->addr < addr) {\n            break;\n        }\n\n        d = dest + (rom->addr - addr);\n        s = rom->data;\n        l = rom->datasize;\n\n        if ((d + l) > (dest + size)) {\n            l = dest - d;\n        }\n\n        if (l > 0) {\n            memcpy(d, s, l);\n        }\n\n        if (rom->romsize > rom->datasize) {\n            /* If datasize is less than romsize, it means that we didn't\n             * allocate all the ROM because the trailing data are only zeros.\n             */\n\n            d += l;\n            l = rom->romsize - rom->datasize;\n\n            if ((d + l) > (dest + size)) {\n                /* Rom size doesn't fit in the destination area. Adjust to avoid\n                 * overflow.\n                 */\n                l = dest - d;\n            }\n\n            if (l > 0) {\n                memset(d, 0x0, l);\n            }\n        }\n    }\n\n    return (d + l) - dest;\n}", "commit_link": "github.com/qemu/qemu/commit/4f1c6cb2f9afafda05eab150fd2bd284edce6676", "file_name": "hw/core/loader.c", "vul_type": "cwe-787", "description": "Write a C function named `rom_copy` that copies ROM data to a destination buffer, handling memory regions and zero-filling as needed."}
{"func_name": "asylo::primitives::TrustedPrimitives::UntrustedCall", "func_src_before": "PrimitiveStatus TrustedPrimitives::UntrustedCall(uint64_t untrusted_selector,\n                                                 MessageWriter *input,\n                                                 MessageReader *output) {\n  int ret;\n\n  UntrustedCacheMalloc *untrusted_cache = UntrustedCacheMalloc::Instance();\n\n  SgxParams *const sgx_params =\n      reinterpret_cast<SgxParams *>(untrusted_cache->Malloc(sizeof(SgxParams)));\n  Cleanup clean_up(\n      [sgx_params, untrusted_cache] { untrusted_cache->Free(sgx_params); });\n  sgx_params->input_size = 0;\n  sgx_params->input = nullptr;\n  if (input) {\n    sgx_params->input_size = input->MessageSize();\n    if (sgx_params->input_size > 0) {\n      // Allocate and copy data to |input_buffer|.\n      sgx_params->input = untrusted_cache->Malloc(sgx_params->input_size);\n      input->Serialize(const_cast<void *>(sgx_params->input));\n    }\n  }\n  sgx_params->output_size = 0;\n  sgx_params->output = nullptr;\n  CHECK_OCALL(\n      ocall_dispatch_untrusted_call(&ret, untrusted_selector, sgx_params));\n  if (sgx_params->input) {\n    untrusted_cache->Free(const_cast<void *>(sgx_params->input));\n  }\n  if (sgx_params->output) {\n    // For the results obtained in |output_buffer|, copy them to |output|\n    // before freeing the buffer.\n    output->Deserialize(sgx_params->output, sgx_params->output_size);\n    TrustedPrimitives::UntrustedLocalFree(sgx_params->output);\n  }\n  return PrimitiveStatus::OkStatus();\n}", "func_src_after": "PrimitiveStatus TrustedPrimitives::UntrustedCall(uint64_t untrusted_selector,\n                                                 MessageWriter *input,\n                                                 MessageReader *output) {\n  int ret;\n\n  UntrustedCacheMalloc *untrusted_cache = UntrustedCacheMalloc::Instance();\n\n  SgxParams *const sgx_params =\n      reinterpret_cast<SgxParams *>(untrusted_cache->Malloc(sizeof(SgxParams)));\n  Cleanup clean_up(\n      [sgx_params, untrusted_cache] { untrusted_cache->Free(sgx_params); });\n  sgx_params->input_size = 0;\n  sgx_params->input = nullptr;\n  if (input) {\n    sgx_params->input_size = input->MessageSize();\n    if (sgx_params->input_size > 0) {\n      // Allocate and copy data to |input_buffer|.\n      sgx_params->input = untrusted_cache->Malloc(sgx_params->input_size);\n      input->Serialize(const_cast<void *>(sgx_params->input));\n    }\n  }\n  sgx_params->output_size = 0;\n  sgx_params->output = nullptr;\n  CHECK_OCALL(\n      ocall_dispatch_untrusted_call(&ret, untrusted_selector, sgx_params));\n  if (sgx_params->input) {\n    untrusted_cache->Free(const_cast<void *>(sgx_params->input));\n  }\n  if (!TrustedPrimitives::IsOutsideEnclave(sgx_params->output,\n                                           sgx_params->output_size)) {\n    TrustedPrimitives::BestEffortAbort(\n        \"UntrustedCall: sgx_param output should be in untrusted memory\");\n  }\n  if (sgx_params->output) {\n    // For the results obtained in |output_buffer|, copy them to |output|\n    // before freeing the buffer.\n    output->Deserialize(sgx_params->output, sgx_params->output_size);\n    TrustedPrimitives::UntrustedLocalFree(sgx_params->output);\n  }\n  return PrimitiveStatus::OkStatus();\n}", "commit_link": "github.com/google/asylo/commit/83036fd841d33baa7e039f842d131aa7881fdcc2", "file_name": "asylo/platform/primitives/sgx/trusted_sgx.cc", "vul_type": "cwe-125", "description": "Write a C++ function for handling an untrusted call with input and output message serialization in a secure enclave environment."}
{"func_name": "ipxitf_ioctl", "func_src_before": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = -EFAULT;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\tbreak;\n\t\tipxitf_put(ipxif);\n\t\trc = 0;\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "func_src_after": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = 0;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\trc = -EFAULT;\n\t\tipxitf_put(ipxif);\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/ee0d8d8482345ff97a75a7d747efc309f13b0d80", "file_name": "net/ipx/af_ipx.c", "vul_type": "cwe-416", "description": "Write a C function named `ipxitf_ioctl` that handles IPX network interface control commands."}
{"func_name": "decode_studio_vop_header", "func_src_before": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "func_src_after": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->interlaced_dct = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/1f686d023b95219db933394a7704ad9aa5f01cbb", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to decode the header of a studio video object plane (VOP) for an MPEG4 decoder context."}
{"func_name": "read_config", "func_src_before": "    def read_config(self):\n        \"\"\"Populate the instance with settings for the config file.\n\n        If we can't find any section for the given site, error gracefully.\n\n        \"\"\"\n        defaults = {\n            \"auth_type\": \"basic\",\n            \"verify_ssl_cert\": \"true\",\n        }\n\n        cp = configparser.RawConfigParser(defaults)\n        cp.read(CONFIG_LOCATIONS)\n\n        if not cp.has_option(self.site, \"base_url\"):\n            raise exceptions.ConfigError(\"unable to find a [{}] section with \"\n                                         \"a base_url.\".format(self.site))\n\n        self.base_url = cp.get(self.site, \"base_url\").rstrip(\"/\")\n        self.username = cp.get(self.site, \"username\")\n        self.password = cp.get(self.site, \"password\")\n        self.verify_ssl_cert = cp.getboolean(self.site, \"verify_ssl_cert\")\n\n        # load auth\n        auth_type = cp.get(self.site, \"auth_type\")\n        auth_type = auth_type.lower()\n        if auth_type not in AUTH_TYPES:\n            supported_auths = \", \".join(sorted(AUTH_TYPES.keys()))\n            msg = (\"invalid auth setting '{}', supported: {}\"\n                  .format(auth_type, supported_auths))\n            raise exceptions.ConfigError(msg)\n        self.auth_type = auth_type\n\n        self.required_fields = [\"To\", \"Component\", \"Subject\", \"Priority\"]", "func_src_after": "    def read_config(self):\n        \"\"\"Populate the instance with settings for the config file.\n\n        If we can't find any section for the given site, error gracefully.\n\n        \"\"\"\n        defaults = {\n            \"auth_type\": \"basic\",\n            \"verify_ssl_cert\": \"true\",\n        }\n\n        cp = configparser.RawConfigParser(defaults)\n        cp.read(CONFIG_LOCATIONS)\n\n        if not cp.has_option(self.site, \"base_url\"):\n            raise exceptions.ConfigError(\"unable to find a [{}] section with \"\n                                         \"a base_url.\".format(self.site))\n\n        self.base_url = cp.get(self.site, \"base_url\").rstrip(\"/\")\n        self.username = cp.get(self.site, \"username\")\n        self.password = cp.get(self.site, \"password\")\n        self.verify_ssl_cert = cp.getboolean(self.site, \"verify_ssl_cert\")\n\n        # load auth\n        auth_type = cp.get(self.site, \"auth_type\")\n        auth_type = auth_type.lower()\n        if auth_type not in AUTH_TYPES:\n            supported_auths = \", \".join(sorted(AUTH_TYPES.keys()))\n            msg = (\"invalid auth setting '{}', supported: {}\"\n                  .format(auth_type, supported_auths))\n            raise exceptions.ConfigError(msg)\n        self.auth_type = auth_type\n\n        if cp.has_option(self.site, \"editor\"):\n            self.config_editor = cp.get(self.site, \"editor\")\n        else:\n            self.config_editor = os.getenv(\"EDITOR\")\n\n        self.required_fields = [\"To\", \"Component\", \"Subject\", \"Priority\"]", "line_changes": {"deleted": [], "added": [{"line_no": 34, "char_start": 1248, "char_end": 1295, "line": "        if cp.has_option(self.site, \"editor\"):\n"}, {"line_no": 35, "char_start": 1295, "char_end": 1356, "line": "            self.config_editor = cp.get(self.site, \"editor\")\n"}, {"line_no": 36, "char_start": 1356, "char_end": 1370, "line": "        else:\n"}, {"line_no": 37, "char_start": 1370, "char_end": 1423, "line": "            self.config_editor = os.getenv(\"EDITOR\")\n"}, {"line_no": 38, "char_start": 1423, "char_end": 1424, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1248, "char_end": 1424, "chars": "        if cp.has_option(self.site, \"editor\"):\n            self.config_editor = cp.get(self.site, \"editor\")\n        else:\n            self.config_editor = os.getenv(\"EDITOR\")\n\n"}]}, "commit_link": "github.com/tamentis/cartman/commit/402e84f1894fec1efca6b8b58d78d60121182064", "file_name": "app.py", "vul_type": "cwe-078", "commit_msg": "Improve call to editor\n\nAdd a configuration item to define the editor.\n\nUse subprocess.call() to avoid shell usage and escaping problems.\n\nCheck editor return value.", "parent_commit": "994c2174041ebb25d58d7fc23eb0581dcb8fb864", "description": "Write a Python function to load configuration settings from a file, handling missing sections or options with custom exceptions."}
{"func_name": "openscript", "func_src_before": "openscript(\n    char_u\t*name,\n    int\t\tdirectly)\t/* when TRUE execute directly */\n{\n    if (curscript + 1 == NSCRIPT)\n    {\n\temsg(_(e_nesting));\n\treturn;\n    }\n#ifdef FEAT_EVAL\n    if (ignore_script)\n\t/* Not reading from script, also don't open one.  Warning message? */\n\treturn;\n#endif\n\n    if (scriptin[curscript] != NULL)\t/* already reading script */\n\t++curscript;\n\t\t\t\t/* use NameBuff for expanded name */\n    expand_env(name, NameBuff, MAXPATHL);\n    if ((scriptin[curscript] = mch_fopen((char *)NameBuff, READBIN)) == NULL)\n    {\n\tsemsg(_(e_notopen), name);\n\tif (curscript)\n\t    --curscript;\n\treturn;\n    }\n    if (save_typebuf() == FAIL)\n\treturn;\n\n    /*\n     * Execute the commands from the file right now when using \":source!\"\n     * after \":global\" or \":argdo\" or in a loop.  Also when another command\n     * follows.  This means the display won't be updated.  Don't do this\n     * always, \"make test\" would fail.\n     */\n    if (directly)\n    {\n\toparg_T\toa;\n\tint\toldcurscript;\n\tint\tsave_State = State;\n\tint\tsave_restart_edit = restart_edit;\n\tint\tsave_insertmode = p_im;\n\tint\tsave_finish_op = finish_op;\n\tint\tsave_msg_scroll = msg_scroll;\n\n\tState = NORMAL;\n\tmsg_scroll = FALSE;\t/* no msg scrolling in Normal mode */\n\trestart_edit = 0;\t/* don't go to Insert mode */\n\tp_im = FALSE;\t\t/* don't use 'insertmode' */\n\tclear_oparg(&oa);\n\tfinish_op = FALSE;\n\n\toldcurscript = curscript;\n\tdo\n\t{\n\t    update_topline_cursor();\t// update cursor position and topline\n\t    normal_cmd(&oa, FALSE);\t// execute one command\n\t    vpeekc();\t\t\t// check for end of file\n\t}\n\twhile (scriptin[oldcurscript] != NULL);\n\n\tState = save_State;\n\tmsg_scroll = save_msg_scroll;\n\trestart_edit = save_restart_edit;\n\tp_im = save_insertmode;\n\tfinish_op = save_finish_op;\n    }\n}", "func_src_after": "openscript(\n    char_u\t*name,\n    int\t\tdirectly)\t/* when TRUE execute directly */\n{\n    if (curscript + 1 == NSCRIPT)\n    {\n\temsg(_(e_nesting));\n\treturn;\n    }\n\n    // Disallow sourcing a file in the sandbox, the commands would be executed\n    // later, possibly outside of the sandbox.\n    if (check_secure())\n\treturn;\n\n#ifdef FEAT_EVAL\n    if (ignore_script)\n\t/* Not reading from script, also don't open one.  Warning message? */\n\treturn;\n#endif\n\n    if (scriptin[curscript] != NULL)\t/* already reading script */\n\t++curscript;\n\t\t\t\t/* use NameBuff for expanded name */\n    expand_env(name, NameBuff, MAXPATHL);\n    if ((scriptin[curscript] = mch_fopen((char *)NameBuff, READBIN)) == NULL)\n    {\n\tsemsg(_(e_notopen), name);\n\tif (curscript)\n\t    --curscript;\n\treturn;\n    }\n    if (save_typebuf() == FAIL)\n\treturn;\n\n    /*\n     * Execute the commands from the file right now when using \":source!\"\n     * after \":global\" or \":argdo\" or in a loop.  Also when another command\n     * follows.  This means the display won't be updated.  Don't do this\n     * always, \"make test\" would fail.\n     */\n    if (directly)\n    {\n\toparg_T\toa;\n\tint\toldcurscript;\n\tint\tsave_State = State;\n\tint\tsave_restart_edit = restart_edit;\n\tint\tsave_insertmode = p_im;\n\tint\tsave_finish_op = finish_op;\n\tint\tsave_msg_scroll = msg_scroll;\n\n\tState = NORMAL;\n\tmsg_scroll = FALSE;\t/* no msg scrolling in Normal mode */\n\trestart_edit = 0;\t/* don't go to Insert mode */\n\tp_im = FALSE;\t\t/* don't use 'insertmode' */\n\tclear_oparg(&oa);\n\tfinish_op = FALSE;\n\n\toldcurscript = curscript;\n\tdo\n\t{\n\t    update_topline_cursor();\t// update cursor position and topline\n\t    normal_cmd(&oa, FALSE);\t// execute one command\n\t    vpeekc();\t\t\t// check for end of file\n\t}\n\twhile (scriptin[oldcurscript] != NULL);\n\n\tState = save_State;\n\tmsg_scroll = save_msg_scroll;\n\trestart_edit = save_restart_edit;\n\tp_im = save_insertmode;\n\tfinish_op = save_finish_op;\n    }\n}", "commit_link": "github.com/vim/vim/commit/53575521406739cf20bbe4e384d88e7dca11f040", "file_name": "src/getchar.c", "vul_type": "cwe-078", "description": "In C, write a function `openscript` that takes a script name and a flag to execute directly, handling script nesting and environment expansion."}
{"func_name": "getGameID", "func_src_before": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = %i\" % ID)\n\tID = db.fetchone()\n\treturn ID", "func_src_after": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = ?\", ID)\n\tID = db.fetchone()\n\treturn ID", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getGameID` that retrieves a game's record from a database by its ID using parameterized queries."}
{"func_name": "get_old_sourcebyinstitution_number", "func_src_before": "def get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution):\n    \"\"\"\n    Get all the old sourcebyinstitution number from the SQLite database.\n    \"\"\"\n    query = \"\"\"\n        SELECT\n            titles\n        FROM\n            history\n        WHERE\n            sourcebyinstitution = \"%s\"\n        ORDER BY\n            titles DESC\n        LIMIT 1\n    \"\"\" % sourcebyinstitution\n\n    sqlite.execute(query)\n    for record in sqlite:\n        old_sourcebyinstitution_number = record[0]\n        return old_sourcebyinstitution_number", "func_src_after": "def get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution):\n    \"\"\"\n    Get all the old sourcebyinstitution number from the SQLite database.\n    \"\"\"\n    query = \"\"\"\n        SELECT\n            titles\n        FROM\n            history\n        WHERE\n            sourcebyinstitution = ?\n        ORDER BY\n            titles DESC\n        LIMIT 1\n    \"\"\"\n\n    sqlite.execute(query, (sourcebyinstitution,))\n    for record in sqlite:\n        old_sourcebyinstitution_number = record[0]\n        return old_sourcebyinstitution_number", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the most recent title associated with a given source institution from an SQLite database."}
{"func_name": "test_get_iscsi_ip_active", "func_src_before": "    def test_get_iscsi_ip_active(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_vlun_cmd = 'showvlun -a -host fakehost'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN), ''])\n\n        self.mox.ReplayAll()\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.253')", "func_src_after": "    def test_get_iscsi_ip_active(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_vlun_cmd = ['showvlun', '-a', '-host', 'fakehost']\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN), ''])\n\n        self.mox.ReplayAll()\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.253')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands to retrieve an active iSCSI IP address."}
{"func_name": "patch", "func_src_before": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "func_src_after": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        if (newpos + y > newDataLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "commit_link": "github.com/ilanschnell/bsdiff4/commit/49a4cee2feef7deaf9d89e5e793a8824930284d7", "file_name": "bsdiff4/core.c", "vul_type": "cwe-787", "description": "Write a Python C extension function named `patch` that applies a binary patch to given data using control tuples and diff/extra blocks."}
{"func_name": "exports.getBlockInfo", "func_src_before": "exports.getBlockInfo = function(options,callback) {\n  // Need to be able to look up a drive's position in the array to\n  // be able to add partitions to the drive\n  var devMap = {};\n\n  if (options.ignoredev) {\n    var ignoreexp = new RegExp(options.ignoredev);\n  }\n\n  // Are we ignoring any dev majors?\n  var ignoremajor = \"\";\n  if (options.ignoremajor && (options.ignoremajor.length>0)) {\n    ignoremajor = \" --exclude \" + options.ignoremajor.join();\n  }\n\n  // Build the command line\n  var cmd = (options.lsblk?options.lsblk:\"/bin/lsblk\") + \n      \" -bPo NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" +\n      ignoremajor;\n\n  // Run it\n  var aProc = exec(cmd, function(error, stdout, stderr) {\n    if (error !== null) {\n      // Something went wrong.\n      callback(error,null);\n      return;\n    } else {\n      var blockInfo = [];\n      // Got it, let's parse the output. Split into lines and iterate...\n      var lines = stdout.split('\\n');\n      for (var i=0; i < lines.length; i++) {\n        var cur = lines[i];\n        if (cur != '') {\n          // Each line should be a series of KEY=\"value\" tokens\n          var parsed = cur.match(/[A-Z0-9]+?=\".*?\"/g);\n          var oneDev = {};\n          for (var j=0; j<parsed.length; j++) {\n            // For each token, break out the key and value\n            var keyval = parsed[j].split('=');\n            var key = keyval[0];\n            var val = keyval[1].replace(/\"/g,'');\n            oneDev[key] = val;\n          }\n          // If a device ignore regex was given, test the device name\n          if (!options.ignoredev || (!ignoreexp.test(oneDev['NAME']))) {\n            // What kind of thing is this?\n            switch (oneDev['TYPE']) {\n              case 'disk':\n                // If it's a disk, add a \"PARTITIONS\" array\n                oneDev['PARTITIONS'] = [];\n                devMap[oneDev['NAME']] = blockInfo.length;\n                blockInfo[blockInfo.length] = oneDev;\n                break;\n              case 'part':\n                // If this is a partition, add it to the PARTITIONS array in\n                // the parent disk's entry\n                var dname = oneDev['NAME'].match(/^\\D+/);\n                if (devMap[dname] !== undefined) {\n                  blockInfo[devMap[dname]].PARTITIONS.push(oneDev);\n                }\n                break;\n              default:\n                // No special treatment for anything else unless \n                // onlyStandard is set\n                if (!options.onlyStandard) {\n                  blockInfo[blockInfo.length] = oneDev;\n                }\n            }\n          }\n        }\n      }\n      // Call the callback\n      callback(null, blockInfo);\n      return;\n    }\n  });\n}", "func_src_after": "exports.getBlockInfo = function(options,callback) {\n  // Need to be able to look up a drive's position in the array to\n  // be able to add partitions to the drive\n  var devMap = {};\n\n  var cmdArgs = [\"-bPo\", \"NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" ];\n\n  if (options.ignoredev) {\n    var ignoreexp = new RegExp(options.ignoredev);\n  }\n\n  // Are we ignoring any dev majors?\n  if (options.ignoremajor && (options.ignoremajor.length>0)) {\n    cmdArgs.push(\"--exclude\");\n    cmdArgs.push(options.ignoremajor);\n  }\n\n  // Build the command line\n  var cmd = options.lsblk?options.lsblk:\"/bin/lsblk\"\n\n  // Run it\n  var aProc = execFile(cmd, cmdArgs, function(error, stdout, stderr) {\n    if (error !== null) {\n      // Something went wrong.\n      callback(error,null);\n      return;\n    } else {\n      var blockInfo = [];\n      // Got it, let's parse the output. Split into lines and iterate...\n      var lines = stdout.split('\\n');\n      for (var i=0; i < lines.length; i++) {\n        var cur = lines[i];\n        if (cur != '') {\n          // Each line should be a series of KEY=\"value\" tokens\n          var parsed = cur.match(/[A-Z0-9]+?=\".*?\"/g);\n          var oneDev = {};\n          for (var j=0; j<parsed.length; j++) {\n            // For each token, break out the key and value\n            var keyval = parsed[j].split('=');\n            var key = keyval[0];\n            var val = keyval[1].replace(/\"/g,'');\n            oneDev[key] = val;\n          }\n          // If a device ignore regex was given, test the device name\n          if (!options.ignoredev || (!ignoreexp.test(oneDev['NAME']))) {\n            // What kind of thing is this?\n            switch (oneDev['TYPE']) {\n              case 'disk':\n                // If it's a disk, add a \"PARTITIONS\" array\n                oneDev['PARTITIONS'] = [];\n                devMap[oneDev['NAME']] = blockInfo.length;\n                blockInfo[blockInfo.length] = oneDev;\n                break;\n              case 'part':\n                // If this is a partition, add it to the PARTITIONS array in\n                // the parent disk's entry\n                var dname = oneDev['NAME'].match(/^\\D+/);\n                if (devMap[dname] !== undefined) {\n                  blockInfo[devMap[dname]].PARTITIONS.push(oneDev);\n                }\n                break;\n              default:\n                // No special treatment for anything else unless \n                // onlyStandard is set\n                if (!options.onlyStandard) {\n                  blockInfo[blockInfo.length] = oneDev;\n                }\n            }\n          }\n        }\n      }\n      // Call the callback\n      callback(null, blockInfo);\n      return;\n    }\n  });\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 303, "char_end": 327, "line": "  var ignoremajor = \"\";\n"}, {"line_no": 13, "char_start": 390, "char_end": 452, "line": "    ignoremajor = \" --exclude \" + options.ignoremajor.join();\n"}, {"line_no": 17, "char_start": 485, "char_end": 543, "line": "  var cmd = (options.lsblk?options.lsblk:\"/bin/lsblk\") + \n"}, {"line_no": 18, "char_start": 543, "char_end": 616, "line": "      \" -bPo NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" +\n"}, {"line_no": 19, "char_start": 616, "char_end": 635, "line": "      ignoremajor;\n"}, {"line_no": 22, "char_start": 648, "char_end": 706, "line": "  var aProc = exec(cmd, function(error, stdout, stderr) {\n"}], "added": [{"line_no": 6, "char_start": 183, "char_end": 270, "line": "  var cmdArgs = [\"-bPo\", \"NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" ];\n"}, {"line_no": 7, "char_start": 270, "char_end": 271, "line": "\n"}, {"line_no": 14, "char_start": 454, "char_end": 485, "line": "    cmdArgs.push(\"--exclude\");\n"}, {"line_no": 15, "char_start": 485, "char_end": 524, "line": "    cmdArgs.push(options.ignoremajor);\n"}, {"line_no": 19, "char_start": 557, "char_end": 610, "line": "  var cmd = options.lsblk?options.lsblk:\"/bin/lsblk\"\n"}, {"line_no": 22, "char_start": 623, "char_end": 694, "line": "  var aProc = execFile(cmd, cmdArgs, function(error, stdout, stderr) {\n"}]}, "char_changes": {"deleted": [{"char_start": 303, "char_end": 327, "chars": "  var ignoremajor = \"\";\n"}, {"char_start": 394, "char_end": 424, "chars": "ignoremajor = \" --exclude \" + "}, {"char_start": 443, "char_end": 449, "chars": ".join("}, {"char_start": 497, "char_end": 498, "chars": "("}, {"char_start": 538, "char_end": 634, "chars": ") + \n      \" -bPo NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" +\n      ignoremajor;"}, {"char_start": 666, "char_end": 670, "chars": "(cmd"}], "added": [{"char_start": 183, "char_end": 271, "chars": "  var cmdArgs = [\"-bPo\", \"NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" ];\n\n"}, {"char_start": 458, "char_end": 502, "chars": "cmdArgs.push(\"--exclude\");\n    cmdArgs.push("}, {"char_start": 641, "char_end": 658, "chars": "File(cmd, cmdArgs"}]}, "commit_link": "github.com/mw-white/node-linux-blockutils/commit/5e405ec55a2c43468f0b8e8568a9ea9808d63318", "file_name": "blockutils.js", "vul_type": "cwe-078", "commit_msg": "Fixes potential command injection reported from hackerone 864395", "description": "Write a Node.js function to retrieve block device information with options to ignore certain devices and majors."}
{"func_name": "create_list", "func_src_before": "list_t *create_list(void)\n{\n    list_t *list = malloc(sizeof(list_t));\n\n    list->size = 0;\n    list->head = NULL;\n    list->tail = NULL;\n\n    return list;\n}", "func_src_after": "list_t *create_list(void)\n{\n    list_t *list = malloc(sizeof(list_t));\n\n    if (list == NULL)\n        return NULL;\n\n    list->size = 0;\n    list->head = NULL;\n    list->tail = NULL;\n\n    return list;\n}", "commit_link": "github.com/matiasedd/vinapp/commit/663121dc1fb7b9465d1edaa2bf1b25145294ba5b", "file_name": "liblist.c", "vul_type": "cwe-476", "description": "Write a C function named `create_list` that initializes an empty linked list and handles memory allocation failure."}
{"func_name": "gitMtime", "func_src_before": "async function gitMtime(path) {\n  const { stdout } = await execFilePromise('git', ['log', '-1', '--format=\"%at\"', '--', path]);\n\n  return parseInt(stdout.trim().replace('\"', '').trim(), 10);\n}", "func_src_after": "async function gitMtime(path) {\n  const { stdout } = await execFilePromise('git', ['log', '-1', '--format=\"%at\"', '--', path]);\n\n  return parseInt(stdout.trim().replace(/\"/g, '').trim(), 10);\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 129, "char_end": 191, "line": "  return parseInt(stdout.trim().replace('\"', '').trim(), 10);\n"}], "added": [{"line_no": 4, "char_start": 129, "char_end": 192, "line": "  return parseInt(stdout.trim().replace(/\"/g, '').trim(), 10);\n"}]}, "char_changes": {"deleted": [{"char_start": 169, "char_end": 172, "chars": "'\"'"}], "added": [{"char_start": 169, "char_end": 173, "chars": "/\"/g"}]}, "commit_link": "github.com/openfoodfacts/openfoodfacts-server/commit/7917218c34b5ae2afe5d6581416c944607e31f36", "file_name": "refresh_taxonomies.js", "vul_type": "cwe-116", "commit_msg": "fix: CWE-116/CWE-20\n\nhttps://github.com/openfoodfacts/openfoodfacts-server/security/code-scanning/4", "parent_commit": "40386e19d82ff72f27066cb2bcbdf539dca0c6be", "description": "Create an asynchronous JavaScript function that retrieves the last modification timestamp of a file using Git."}
{"func_name": "AP4_AtomSampleTable::GetSample", "func_src_before": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    result = m_SttsAtom->GetDts(index, dts, &duration);\n    if (AP4_FAILED(result)) return result;\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "func_src_after": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    if (m_SttsAtom) {\n        result = m_SttsAtom->GetDts(index, dts, &duration);\n        if (AP4_FAILED(result)) return result;\n    }\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/2f267f89f957088197f4b1fc254632d1645b415d", "file_name": "Source/C++/Core/Ap4AtomSampleTable.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to retrieve a media sample from an MP4 file's atom sample table by its index."}
{"func_name": "Writer::Writer", "func_src_before": "Writer::Writer(const char* pathToSave, ToDo& t): todo(t) \n{\n\tstrncpy(path, pathToSave, 128);\n\tpath[128] = '\\0';\n\tfile.imbue(locale(\"\"));\n}", "func_src_after": "Writer::Writer(const char* pathToSave, ToDo& t): todo(t) \n{\n\tstrncpy(path, pathToSave, 255);\n\tpath[255] = '\\0';\n\tfile.imbue(locale(\"\"));\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 60, "char_end": 93, "line": "\tstrncpy(path, pathToSave, 128);\n"}, {"line_no": 4, "char_start": 93, "char_end": 112, "line": "\tpath[128] = '\\0';\n"}], "added": [{"line_no": 3, "char_start": 60, "char_end": 93, "line": "\tstrncpy(path, pathToSave, 255);\n"}, {"line_no": 4, "char_start": 93, "char_end": 112, "line": "\tpath[255] = '\\0';\n"}]}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 90, "chars": "128"}, {"char_start": 99, "char_end": 102, "chars": "128"}], "added": [{"char_start": 87, "char_end": 90, "chars": "255"}, {"char_start": 99, "char_end": 102, "chars": "255"}]}, "commit_link": "github.com/meskio/tudu/commit/c51f4c2f92288f923cf33bdc395501f447fe2d5c", "file_name": "parser.cc", "vul_type": "cwe-119", "commit_msg": "Fix out-of-bounds access", "parent_commit": "30923dcb8b7682fec1bdfbf07f904e4d9983e623", "description": "Create a C++ class constructor for a `Writer` class that initializes a `ToDo` object and copies a file path string with a fixed length."}
{"func_name": "mark_context_stack", "func_src_before": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n{\n  size_t i;\n  size_t e;\n\n  if (c->stack == NULL) return;\n  e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n    mrb_value v = c->stbase[i];\n\n    if (!mrb_immediate_p(v)) {\n      if (mrb_basic_ptr(v)->tt == MRB_TT_FREE) {\n        c->stbase[i] = mrb_nil_value();\n      }\n      else {\n        mrb_gc_mark(mrb, mrb_basic_ptr(v));\n      }\n    }\n  }\n}", "func_src_after": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n{\n  size_t i;\n  size_t e;\n  mrb_value nil;\n\n  if (c->stack == NULL) return;\n  e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n    mrb_value v = c->stbase[i];\n\n    if (!mrb_immediate_p(v)) {\n      mrb_gc_mark(mrb, mrb_basic_ptr(v));\n    }\n  }\n  e = c->stend - c->stbase;\n  nil = mrb_nil_value();\n  for (; i<e; i++) {\n    c->stbase[i] = nil;\n  }\n}", "commit_link": "github.com/mruby/mruby/commit/5c114c91d4ff31859fcd84cf8bf349b737b90d99", "file_name": "src/gc.c", "vul_type": "cwe-416", "description": "Write a function in C for the MRuby engine that marks the stack context for garbage collection."}
{"func_name": "test_get_least_used_nsp", "func_src_before": "    def test_get_least_used_nsp(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_vlun_cmd = 'showvlun -a -showcols Port'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n        # in use count                           11       12\n        nsp = self.driver._get_least_used_nsp(['0:2:1', '1:8:1'])\n        self.assertEqual(nsp, '0:2:1')\n\n        # in use count                            11       10\n        nsp = self.driver._get_least_used_nsp(['0:2:1', '1:2:1'])\n        self.assertEqual(nsp, '1:2:1')\n\n        # in use count                            0       10\n        nsp = self.driver._get_least_used_nsp(['1:1:1', '1:2:1'])\n        self.assertEqual(nsp, '1:1:1')", "func_src_after": "    def test_get_least_used_nsp(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_vlun_cmd = ['showvlun', '-a', '-showcols', 'Port']\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n        # in use count                           11       12\n        nsp = self.driver._get_least_used_nsp(['0:2:1', '1:8:1'])\n        self.assertEqual(nsp, '0:2:1')\n\n        # in use count                            11       10\n        nsp = self.driver._get_least_used_nsp(['0:2:1', '1:2:1'])\n        self.assertEqual(nsp, '1:2:1')\n\n        # in use count                            0       10\n        nsp = self.driver._get_least_used_nsp(['1:1:1', '1:2:1'])\n        self.assertEqual(nsp, '1:1:1')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks an SSH command to determine the least used network service provider."}
{"func_name": "misc_file_checks", "func_src_before": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Deprecated usage of 'add_header' in nginx conf\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            if not os.path.isfile(self.path + \"/conf/\" + filename):\n                continue\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )", "func_src_after": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Analyze nginx conf\n        # - Deprecated usage of 'add_header' in nginx conf\n        # - Spot path traversal issue vulnerability\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            # Ignore subdirs or filename not containing nginx in the name\n            if not os.path.isfile(self.path + \"/conf/\" + filename) or \"nginx\" not in filename:\n                continue\n\n            #\n            # 'add_header' usage\n            #\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )\n\n            #\n            # Path traversal issues\n            #\n            lines = open(self.path + \"/conf/\" + filename).readlines()\n            lines = [line.strip() for line in lines if not line.strip().startswith(\"#\")]\n            # Let's find the first location line\n            location_line = None\n            path_traversal_vulnerable = False\n            lines_iter = lines.__iter__()\n            for line in lines_iter:\n                if line.startswith(\"location\"):\n                    location_line = line\n                    break\n            # Look at the next lines for an 'alias' directive\n            if location_line is not None:\n                for line in lines_iter:\n                    if line.startswith(\"location\"):\n                        # Entering a new location block ... abort here\n                        # and assume there's no alias block later...\n                        break\n                    if line.startswith(\"alias\"):\n                        # We should definitely check for path traversal issue\n                        # Does the location target ends with / ?\n                        target = location_line.split()[-2]\n                        if not target.endswith(\"/\"):\n                            path_traversal_vulnerable = True\n                        break\n            if path_traversal_vulnerable:\n                print_warning(\n                    \"The nginx configuration appears vulnerable to path traversal as explained in \"\n                    \"https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/\\n\"\n                    \"To fix it, look at the first lines of the nginx conf of the example app : \"\n                    \"https://github.com/YunoHost/example_ynh/blob/master/conf/nginx.conf\"\n                )", "commit_link": "github.com/YunoHost/package_linter/commit/f6e98894cfe841aedaa7efd590937f0255193913", "file_name": "package_linter.py", "vul_type": "cwe-022", "description": "Write a Python function to check for mandatory files, deprecated configurations, and potential vulnerabilities in a project's file structure and configurations."}
{"func_name": "avpriv_ac3_parse_header", "func_src_before": "int avpriv_ac3_parse_header(AC3HeaderInfo **phdr, const uint8_t *buf,\n                            size_t size)\n{\n    GetBitContext gb;\n    AC3HeaderInfo *hdr;\n    int err;\n\n    if (!*phdr)\n        *phdr = av_mallocz(sizeof(AC3HeaderInfo));\n    if (!*phdr)\n        return AVERROR(ENOMEM);\n    hdr = *phdr;\n\n    init_get_bits8(&gb, buf, size);\n    err = ff_ac3_parse_header(&gb, hdr);\n    if (err < 0)\n        return AVERROR_INVALIDDATA;\n\n    return get_bits_count(&gb);\n}", "func_src_after": "int avpriv_ac3_parse_header(AC3HeaderInfo **phdr, const uint8_t *buf,\n                            size_t size)\n{\n    GetBitContext gb;\n    AC3HeaderInfo *hdr;\n    int err;\n\n    if (!*phdr)\n        *phdr = av_mallocz(sizeof(AC3HeaderInfo));\n    if (!*phdr)\n        return AVERROR(ENOMEM);\n    hdr = *phdr;\n\n    err = init_get_bits8(&gb, buf, size);\n    if (err < 0)\n        return AVERROR_INVALIDDATA;\n    err = ff_ac3_parse_header(&gb, hdr);\n    if (err < 0)\n        return AVERROR_INVALIDDATA;\n\n    return get_bits_count(&gb);\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/00e8181bd97c834fe60751b0c511d4bb97875f78", "file_name": "libavcodec/ac3_parser.c", "vul_type": "cwe-476", "description": "Write a C function named `avpriv_ac3_parse_header` that initializes a bit context and parses the AC3 header from a buffer, returning the number of bits read."}
{"func_name": "flattenSubquery", "func_src_before": "static int flattenSubquery(\n  Parse *pParse,       /* Parsing context */\n  Select *p,           /* The parent or outer SELECT statement */\n  int iFrom,           /* Index in p->pSrc->a[] of the inner subquery */\n  int isAgg            /* True if outer SELECT uses aggregate functions */\n){\n  const char *zSavedAuthContext = pParse->zAuthContext;\n  Select *pParent;    /* Current UNION ALL term of the other query */\n  Select *pSub;       /* The inner query or \"subquery\" */\n  Select *pSub1;      /* Pointer to the rightmost select in sub-query */\n  SrcList *pSrc;      /* The FROM clause of the outer query */\n  SrcList *pSubSrc;   /* The FROM clause of the subquery */\n  int iParent;        /* VDBE cursor number of the pSub result set temp table */\n  int iNewParent = -1;/* Replacement table for iParent */\n  int isLeftJoin = 0; /* True if pSub is the right side of a LEFT JOIN */    \n  int i;              /* Loop counter */\n  Expr *pWhere;                    /* The WHERE clause */\n  struct SrcList_item *pSubitem;   /* The subquery */\n  sqlite3 *db = pParse->db;\n\n  /* Check to see if flattening is permitted.  Return 0 if not.\n  */\n  assert( p!=0 );\n  assert( p->pPrior==0 );\n  if( OptimizationDisabled(db, SQLITE_QueryFlattener) ) return 0;\n  pSrc = p->pSrc;\n  assert( pSrc && iFrom>=0 && iFrom<pSrc->nSrc );\n  pSubitem = &pSrc->a[iFrom];\n  iParent = pSubitem->iCursor;\n  pSub = pSubitem->pSelect;\n  assert( pSub!=0 );\n\n#ifndef SQLITE_OMIT_WINDOWFUNC\n  if( p->pWin || pSub->pWin ) return 0;                  /* Restriction (25) */\n#endif\n\n  pSubSrc = pSub->pSrc;\n  assert( pSubSrc );\n  /* Prior to version 3.1.2, when LIMIT and OFFSET had to be simple constants,\n  ** not arbitrary expressions, we allowed some combining of LIMIT and OFFSET\n  ** because they could be computed at compile-time.  But when LIMIT and OFFSET\n  ** became arbitrary expressions, we were forced to add restrictions (13)\n  ** and (14). */\n  if( pSub->pLimit && p->pLimit ) return 0;              /* Restriction (13) */\n  if( pSub->pLimit && pSub->pLimit->pRight ) return 0;   /* Restriction (14) */\n  if( (p->selFlags & SF_Compound)!=0 && pSub->pLimit ){\n    return 0;                                            /* Restriction (15) */\n  }\n  if( pSubSrc->nSrc==0 ) return 0;                       /* Restriction (7)  */\n  if( pSub->selFlags & SF_Distinct ) return 0;           /* Restriction (4)  */\n  if( pSub->pLimit && (pSrc->nSrc>1 || isAgg) ){\n     return 0;         /* Restrictions (8)(9) */\n  }\n  if( p->pOrderBy && pSub->pOrderBy ){\n     return 0;                                           /* Restriction (11) */\n  }\n  if( isAgg && pSub->pOrderBy ) return 0;                /* Restriction (16) */\n  if( pSub->pLimit && p->pWhere ) return 0;              /* Restriction (19) */\n  if( pSub->pLimit && (p->selFlags & SF_Distinct)!=0 ){\n     return 0;         /* Restriction (21) */\n  }\n  if( pSub->selFlags & (SF_Recursive) ){\n    return 0; /* Restrictions (22) */\n  }\n\n  /*\n  ** If the subquery is the right operand of a LEFT JOIN, then the\n  ** subquery may not be a join itself (3a). Example of why this is not\n  ** allowed:\n  **\n  **         t1 LEFT OUTER JOIN (t2 JOIN t3)\n  **\n  ** If we flatten the above, we would get\n  **\n  **         (t1 LEFT OUTER JOIN t2) JOIN t3\n  **\n  ** which is not at all the same thing.\n  **\n  ** If the subquery is the right operand of a LEFT JOIN, then the outer\n  ** query cannot be an aggregate. (3c)  This is an artifact of the way\n  ** aggregates are processed - there is no mechanism to determine if\n  ** the LEFT JOIN table should be all-NULL.\n  **\n  ** See also tickets #306, #350, and #3300.\n  */\n  if( (pSubitem->fg.jointype & JT_OUTER)!=0 ){\n    isLeftJoin = 1;\n    if( pSubSrc->nSrc>1 || isAgg || IsVirtual(pSubSrc->a[0].pTab) ){\n      /*  (3a)             (3c)     (3b) */\n      return 0;\n    }\n  }\n#ifdef SQLITE_EXTRA_IFNULLROW\n  else if( iFrom>0 && !isAgg ){\n    /* Setting isLeftJoin to -1 causes OP_IfNullRow opcodes to be generated for\n    ** every reference to any result column from subquery in a join, even\n    ** though they are not necessary.  This will stress-test the OP_IfNullRow \n    ** opcode. */\n    isLeftJoin = -1;\n  }\n#endif\n\n  /* Restriction (17): If the sub-query is a compound SELECT, then it must\n  ** use only the UNION ALL operator. And none of the simple select queries\n  ** that make up the compound SELECT are allowed to be aggregate or distinct\n  ** queries.\n  */\n  if( pSub->pPrior ){\n    if( pSub->pOrderBy ){\n      return 0;  /* Restriction (20) */\n    }\n    if( isAgg || (p->selFlags & SF_Distinct)!=0 || pSrc->nSrc!=1 ){\n      return 0; /* (17d1), (17d2), or (17d3) */\n    }\n    for(pSub1=pSub; pSub1; pSub1=pSub1->pPrior){\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct );\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Aggregate );\n      assert( pSub->pSrc!=0 );\n      assert( pSub->pEList->nExpr==pSub1->pEList->nExpr );\n      if( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))!=0    /* (17b) */\n       || (pSub1->pPrior && pSub1->op!=TK_ALL)                 /* (17a) */\n       || pSub1->pSrc->nSrc<1                                  /* (17c) */\n      ){\n        return 0;\n      }\n      testcase( pSub1->pSrc->nSrc>1 );\n    }\n\n    /* Restriction (18). */\n    if( p->pOrderBy ){\n      int ii;\n      for(ii=0; ii<p->pOrderBy->nExpr; ii++){\n        if( p->pOrderBy->a[ii].u.x.iOrderByCol==0 ) return 0;\n      }\n    }\n  }\n\n  /* Ex-restriction (23):\n  ** The only way that the recursive part of a CTE can contain a compound\n  ** subquery is for the subquery to be one term of a join.  But if the\n  ** subquery is a join, then the flattening has already been stopped by\n  ** restriction (17d3)\n  */\n  assert( (p->selFlags & SF_Recursive)==0 || pSub->pPrior==0 );\n\n  /***** If we reach this point, flattening is permitted. *****/\n  SELECTTRACE(1,pParse,p,(\"flatten %u.%p from term %d\\n\",\n                   pSub->selId, pSub, iFrom));\n\n  /* Authorize the subquery */\n  pParse->zAuthContext = pSubitem->zName;\n  TESTONLY(i =) sqlite3AuthCheck(pParse, SQLITE_SELECT, 0, 0, 0);\n  testcase( i==SQLITE_DENY );\n  pParse->zAuthContext = zSavedAuthContext;\n\n  /* If the sub-query is a compound SELECT statement, then (by restrictions\n  ** 17 and 18 above) it must be a UNION ALL and the parent query must \n  ** be of the form:\n  **\n  **     SELECT <expr-list> FROM (<sub-query>) <where-clause> \n  **\n  ** followed by any ORDER BY, LIMIT and/or OFFSET clauses. This block\n  ** creates N-1 copies of the parent query without any ORDER BY, LIMIT or \n  ** OFFSET clauses and joins them to the left-hand-side of the original\n  ** using UNION ALL operators. In this case N is the number of simple\n  ** select statements in the compound sub-query.\n  **\n  ** Example:\n  **\n  **     SELECT a+1 FROM (\n  **        SELECT x FROM tab\n  **        UNION ALL\n  **        SELECT y FROM tab\n  **        UNION ALL\n  **        SELECT abs(z*2) FROM tab2\n  **     ) WHERE a!=5 ORDER BY 1\n  **\n  ** Transformed into:\n  **\n  **     SELECT x+1 FROM tab WHERE x+1!=5\n  **     UNION ALL\n  **     SELECT y+1 FROM tab WHERE y+1!=5\n  **     UNION ALL\n  **     SELECT abs(z*2)+1 FROM tab2 WHERE abs(z*2)+1!=5\n  **     ORDER BY 1\n  **\n  ** We call this the \"compound-subquery flattening\".\n  */\n  for(pSub=pSub->pPrior; pSub; pSub=pSub->pPrior){\n    Select *pNew;\n    ExprList *pOrderBy = p->pOrderBy;\n    Expr *pLimit = p->pLimit;\n    Select *pPrior = p->pPrior;\n    p->pOrderBy = 0;\n    p->pSrc = 0;\n    p->pPrior = 0;\n    p->pLimit = 0;\n    pNew = sqlite3SelectDup(db, p, 0);\n    p->pLimit = pLimit;\n    p->pOrderBy = pOrderBy;\n    p->pSrc = pSrc;\n    p->op = TK_ALL;\n    if( pNew==0 ){\n      p->pPrior = pPrior;\n    }else{\n      pNew->pPrior = pPrior;\n      if( pPrior ) pPrior->pNext = pNew;\n      pNew->pNext = p;\n      p->pPrior = pNew;\n      SELECTTRACE(2,pParse,p,(\"compound-subquery flattener\"\n                              \" creates %u as peer\\n\",pNew->selId));\n    }\n    if( db->mallocFailed ) return 1;\n  }\n\n  /* Begin flattening the iFrom-th entry of the FROM clause \n  ** in the outer query.\n  */\n  pSub = pSub1 = pSubitem->pSelect;\n\n  /* Delete the transient table structure associated with the\n  ** subquery\n  */\n  sqlite3DbFree(db, pSubitem->zDatabase);\n  sqlite3DbFree(db, pSubitem->zName);\n  sqlite3DbFree(db, pSubitem->zAlias);\n  pSubitem->zDatabase = 0;\n  pSubitem->zName = 0;\n  pSubitem->zAlias = 0;\n  pSubitem->pSelect = 0;\n\n  /* Defer deleting the Table object associated with the\n  ** subquery until code generation is\n  ** complete, since there may still exist Expr.pTab entries that\n  ** refer to the subquery even after flattening.  Ticket #3346.\n  **\n  ** pSubitem->pTab is always non-NULL by test restrictions and tests above.\n  */\n  if( ALWAYS(pSubitem->pTab!=0) ){\n    Table *pTabToDel = pSubitem->pTab;\n    if( pTabToDel->nTabRef==1 ){\n      Parse *pToplevel = sqlite3ParseToplevel(pParse);\n      pTabToDel->pNextZombie = pToplevel->pZombieTab;\n      pToplevel->pZombieTab = pTabToDel;\n    }else{\n      pTabToDel->nTabRef--;\n    }\n    pSubitem->pTab = 0;\n  }\n\n  /* The following loop runs once for each term in a compound-subquery\n  ** flattening (as described above).  If we are doing a different kind\n  ** of flattening - a flattening other than a compound-subquery flattening -\n  ** then this loop only runs once.\n  **\n  ** This loop moves all of the FROM elements of the subquery into the\n  ** the FROM clause of the outer query.  Before doing this, remember\n  ** the cursor number for the original outer query FROM element in\n  ** iParent.  The iParent cursor will never be used.  Subsequent code\n  ** will scan expressions looking for iParent references and replace\n  ** those references with expressions that resolve to the subquery FROM\n  ** elements we are now copying in.\n  */\n  for(pParent=p; pParent; pParent=pParent->pPrior, pSub=pSub->pPrior){\n    int nSubSrc;\n    u8 jointype = 0;\n    assert( pSub!=0 );\n    pSubSrc = pSub->pSrc;     /* FROM clause of subquery */\n    nSubSrc = pSubSrc->nSrc;  /* Number of terms in subquery FROM clause */\n    pSrc = pParent->pSrc;     /* FROM clause of the outer query */\n\n    if( pSrc ){\n      assert( pParent==p );  /* First time through the loop */\n      jointype = pSubitem->fg.jointype;\n    }else{\n      assert( pParent!=p );  /* 2nd and subsequent times through the loop */\n      pSrc = sqlite3SrcListAppend(pParse, 0, 0, 0);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* The subquery uses a single slot of the FROM clause of the outer\n    ** query.  If the subquery has more than one element in its FROM clause,\n    ** then expand the outer query to make space for it to hold all elements\n    ** of the subquery.\n    **\n    ** Example:\n    **\n    **    SELECT * FROM tabA, (SELECT * FROM sub1, sub2), tabB;\n    **\n    ** The outer query has 3 slots in its FROM clause.  One slot of the\n    ** outer query (the middle slot) is used by the subquery.  The next\n    ** block of code will expand the outer query FROM clause to 4 slots.\n    ** The middle slot is expanded to two slots in order to make space\n    ** for the two elements in the FROM clause of the subquery.\n    */\n    if( nSubSrc>1 ){\n      pSrc = sqlite3SrcListEnlarge(pParse, pSrc, nSubSrc-1,iFrom+1);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* Transfer the FROM clause terms from the subquery into the\n    ** outer query.\n    */\n    for(i=0; i<nSubSrc; i++){\n      sqlite3IdListDelete(db, pSrc->a[i+iFrom].pUsing);\n      assert( pSrc->a[i+iFrom].fg.isTabFunc==0 );\n      pSrc->a[i+iFrom] = pSubSrc->a[i];\n      iNewParent = pSubSrc->a[i].iCursor;\n      memset(&pSubSrc->a[i], 0, sizeof(pSubSrc->a[i]));\n    }\n    pSrc->a[iFrom].fg.jointype = jointype;\n  \n    /* Now begin substituting subquery result set expressions for \n    ** references to the iParent in the outer query.\n    ** \n    ** Example:\n    **\n    **   SELECT a+5, b*10 FROM (SELECT x*3 AS a, y+10 AS b FROM t1) WHERE a>b;\n    **   \\                     \\_____________ subquery __________/          /\n    **    \\_____________________ outer query ______________________________/\n    **\n    ** We look at every expression in the outer query and every place we see\n    ** \"a\" we substitute \"x*3\" and every place we see \"b\" we substitute \"y+10\".\n    */\n    if( pSub->pOrderBy ){\n      /* At this point, any non-zero iOrderByCol values indicate that the\n      ** ORDER BY column expression is identical to the iOrderByCol'th\n      ** expression returned by SELECT statement pSub. Since these values\n      ** do not necessarily correspond to columns in SELECT statement pParent,\n      ** zero them before transfering the ORDER BY clause.\n      **\n      ** Not doing this may cause an error if a subsequent call to this\n      ** function attempts to flatten a compound sub-query into pParent\n      ** (the only way this can happen is if the compound sub-query is\n      ** currently part of pSub->pSrc). See ticket [d11a6e908f].  */\n      ExprList *pOrderBy = pSub->pOrderBy;\n      for(i=0; i<pOrderBy->nExpr; i++){\n        pOrderBy->a[i].u.x.iOrderByCol = 0;\n      }\n      assert( pParent->pOrderBy==0 );\n      pParent->pOrderBy = pOrderBy;\n      pSub->pOrderBy = 0;\n    }\n    pWhere = pSub->pWhere;\n    pSub->pWhere = 0;\n    if( isLeftJoin>0 ){\n      sqlite3SetJoinExpr(pWhere, iNewParent);\n    }\n    pParent->pWhere = sqlite3ExprAnd(pParse, pWhere, pParent->pWhere);\n    if( db->mallocFailed==0 ){\n      SubstContext x;\n      x.pParse = pParse;\n      x.iTable = iParent;\n      x.iNewTable = iNewParent;\n      x.isLeftJoin = isLeftJoin;\n      x.pEList = pSub->pEList;\n      substSelect(&x, pParent, 0);\n    }\n  \n    /* The flattened query is a compound if either the inner or the\n    ** outer query is a compound. */\n    pParent->selFlags |= pSub->selFlags & SF_Compound;\n    assert( (pSub->selFlags & SF_Distinct)==0 ); /* restriction (17b) */\n  \n    /*\n    ** SELECT ... FROM (SELECT ... LIMIT a OFFSET b) LIMIT x OFFSET y;\n    **\n    ** One is tempted to try to add a and b to combine the limits.  But this\n    ** does not work if either limit is negative.\n    */\n    if( pSub->pLimit ){\n      pParent->pLimit = pSub->pLimit;\n      pSub->pLimit = 0;\n    }\n  }\n\n  /* Finially, delete what is left of the subquery and return\n  ** success.\n  */\n  sqlite3SelectDelete(db, pSub1);\n\n#if SELECTTRACE_ENABLED\n  if( sqlite3SelectTrace & 0x100 ){\n    SELECTTRACE(0x100,pParse,p,(\"After flattening:\\n\"));\n    sqlite3TreeViewSelect(0, p, 0);\n  }\n#endif\n\n  return 1;\n}", "func_src_after": "static int flattenSubquery(\n  Parse *pParse,       /* Parsing context */\n  Select *p,           /* The parent or outer SELECT statement */\n  int iFrom,           /* Index in p->pSrc->a[] of the inner subquery */\n  int isAgg            /* True if outer SELECT uses aggregate functions */\n){\n  const char *zSavedAuthContext = pParse->zAuthContext;\n  Select *pParent;    /* Current UNION ALL term of the other query */\n  Select *pSub;       /* The inner query or \"subquery\" */\n  Select *pSub1;      /* Pointer to the rightmost select in sub-query */\n  SrcList *pSrc;      /* The FROM clause of the outer query */\n  SrcList *pSubSrc;   /* The FROM clause of the subquery */\n  int iParent;        /* VDBE cursor number of the pSub result set temp table */\n  int iNewParent = -1;/* Replacement table for iParent */\n  int isLeftJoin = 0; /* True if pSub is the right side of a LEFT JOIN */    \n  int i;              /* Loop counter */\n  Expr *pWhere;                    /* The WHERE clause */\n  struct SrcList_item *pSubitem;   /* The subquery */\n  sqlite3 *db = pParse->db;\n\n  /* Check to see if flattening is permitted.  Return 0 if not.\n  */\n  assert( p!=0 );\n  assert( p->pPrior==0 );\n  if( OptimizationDisabled(db, SQLITE_QueryFlattener) ) return 0;\n  pSrc = p->pSrc;\n  assert( pSrc && iFrom>=0 && iFrom<pSrc->nSrc );\n  pSubitem = &pSrc->a[iFrom];\n  iParent = pSubitem->iCursor;\n  pSub = pSubitem->pSelect;\n  assert( pSub!=0 );\n\n#ifndef SQLITE_OMIT_WINDOWFUNC\n  if( p->pWin || pSub->pWin ) return 0;                  /* Restriction (25) */\n#endif\n\n  pSubSrc = pSub->pSrc;\n  assert( pSubSrc );\n  /* Prior to version 3.1.2, when LIMIT and OFFSET had to be simple constants,\n  ** not arbitrary expressions, we allowed some combining of LIMIT and OFFSET\n  ** because they could be computed at compile-time.  But when LIMIT and OFFSET\n  ** became arbitrary expressions, we were forced to add restrictions (13)\n  ** and (14). */\n  if( pSub->pLimit && p->pLimit ) return 0;              /* Restriction (13) */\n  if( pSub->pLimit && pSub->pLimit->pRight ) return 0;   /* Restriction (14) */\n  if( (p->selFlags & SF_Compound)!=0 && pSub->pLimit ){\n    return 0;                                            /* Restriction (15) */\n  }\n  if( pSubSrc->nSrc==0 ) return 0;                       /* Restriction (7)  */\n  if( pSub->selFlags & SF_Distinct ) return 0;           /* Restriction (4)  */\n  if( pSub->pLimit && (pSrc->nSrc>1 || isAgg) ){\n     return 0;         /* Restrictions (8)(9) */\n  }\n  if( p->pOrderBy && pSub->pOrderBy ){\n     return 0;                                           /* Restriction (11) */\n  }\n  if( isAgg && pSub->pOrderBy ) return 0;                /* Restriction (16) */\n  if( pSub->pLimit && p->pWhere ) return 0;              /* Restriction (19) */\n  if( pSub->pLimit && (p->selFlags & SF_Distinct)!=0 ){\n     return 0;         /* Restriction (21) */\n  }\n  if( pSub->selFlags & (SF_Recursive) ){\n    return 0; /* Restrictions (22) */\n  }\n\n  /*\n  ** If the subquery is the right operand of a LEFT JOIN, then the\n  ** subquery may not be a join itself (3a). Example of why this is not\n  ** allowed:\n  **\n  **         t1 LEFT OUTER JOIN (t2 JOIN t3)\n  **\n  ** If we flatten the above, we would get\n  **\n  **         (t1 LEFT OUTER JOIN t2) JOIN t3\n  **\n  ** which is not at all the same thing.\n  **\n  ** If the subquery is the right operand of a LEFT JOIN, then the outer\n  ** query cannot be an aggregate. (3c)  This is an artifact of the way\n  ** aggregates are processed - there is no mechanism to determine if\n  ** the LEFT JOIN table should be all-NULL.\n  **\n  ** See also tickets #306, #350, and #3300.\n  */\n  if( (pSubitem->fg.jointype & JT_OUTER)!=0 ){\n    isLeftJoin = 1;\n    if( pSubSrc->nSrc>1                   /* (3a) */\n     || isAgg                             /* (3b) */\n     || IsVirtual(pSubSrc->a[0].pTab)     /* (3c) */\n     || (p->selFlags & SF_Distinct)!=0    /* (3d) */\n    ){\n      return 0;\n    }\n  }\n#ifdef SQLITE_EXTRA_IFNULLROW\n  else if( iFrom>0 && !isAgg ){\n    /* Setting isLeftJoin to -1 causes OP_IfNullRow opcodes to be generated for\n    ** every reference to any result column from subquery in a join, even\n    ** though they are not necessary.  This will stress-test the OP_IfNullRow \n    ** opcode. */\n    isLeftJoin = -1;\n  }\n#endif\n\n  /* Restriction (17): If the sub-query is a compound SELECT, then it must\n  ** use only the UNION ALL operator. And none of the simple select queries\n  ** that make up the compound SELECT are allowed to be aggregate or distinct\n  ** queries.\n  */\n  if( pSub->pPrior ){\n    if( pSub->pOrderBy ){\n      return 0;  /* Restriction (20) */\n    }\n    if( isAgg || (p->selFlags & SF_Distinct)!=0 || pSrc->nSrc!=1 ){\n      return 0; /* (17d1), (17d2), or (17d3) */\n    }\n    for(pSub1=pSub; pSub1; pSub1=pSub1->pPrior){\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct );\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Aggregate );\n      assert( pSub->pSrc!=0 );\n      assert( pSub->pEList->nExpr==pSub1->pEList->nExpr );\n      if( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))!=0    /* (17b) */\n       || (pSub1->pPrior && pSub1->op!=TK_ALL)                 /* (17a) */\n       || pSub1->pSrc->nSrc<1                                  /* (17c) */\n      ){\n        return 0;\n      }\n      testcase( pSub1->pSrc->nSrc>1 );\n    }\n\n    /* Restriction (18). */\n    if( p->pOrderBy ){\n      int ii;\n      for(ii=0; ii<p->pOrderBy->nExpr; ii++){\n        if( p->pOrderBy->a[ii].u.x.iOrderByCol==0 ) return 0;\n      }\n    }\n  }\n\n  /* Ex-restriction (23):\n  ** The only way that the recursive part of a CTE can contain a compound\n  ** subquery is for the subquery to be one term of a join.  But if the\n  ** subquery is a join, then the flattening has already been stopped by\n  ** restriction (17d3)\n  */\n  assert( (p->selFlags & SF_Recursive)==0 || pSub->pPrior==0 );\n\n  /***** If we reach this point, flattening is permitted. *****/\n  SELECTTRACE(1,pParse,p,(\"flatten %u.%p from term %d\\n\",\n                   pSub->selId, pSub, iFrom));\n\n  /* Authorize the subquery */\n  pParse->zAuthContext = pSubitem->zName;\n  TESTONLY(i =) sqlite3AuthCheck(pParse, SQLITE_SELECT, 0, 0, 0);\n  testcase( i==SQLITE_DENY );\n  pParse->zAuthContext = zSavedAuthContext;\n\n  /* If the sub-query is a compound SELECT statement, then (by restrictions\n  ** 17 and 18 above) it must be a UNION ALL and the parent query must \n  ** be of the form:\n  **\n  **     SELECT <expr-list> FROM (<sub-query>) <where-clause> \n  **\n  ** followed by any ORDER BY, LIMIT and/or OFFSET clauses. This block\n  ** creates N-1 copies of the parent query without any ORDER BY, LIMIT or \n  ** OFFSET clauses and joins them to the left-hand-side of the original\n  ** using UNION ALL operators. In this case N is the number of simple\n  ** select statements in the compound sub-query.\n  **\n  ** Example:\n  **\n  **     SELECT a+1 FROM (\n  **        SELECT x FROM tab\n  **        UNION ALL\n  **        SELECT y FROM tab\n  **        UNION ALL\n  **        SELECT abs(z*2) FROM tab2\n  **     ) WHERE a!=5 ORDER BY 1\n  **\n  ** Transformed into:\n  **\n  **     SELECT x+1 FROM tab WHERE x+1!=5\n  **     UNION ALL\n  **     SELECT y+1 FROM tab WHERE y+1!=5\n  **     UNION ALL\n  **     SELECT abs(z*2)+1 FROM tab2 WHERE abs(z*2)+1!=5\n  **     ORDER BY 1\n  **\n  ** We call this the \"compound-subquery flattening\".\n  */\n  for(pSub=pSub->pPrior; pSub; pSub=pSub->pPrior){\n    Select *pNew;\n    ExprList *pOrderBy = p->pOrderBy;\n    Expr *pLimit = p->pLimit;\n    Select *pPrior = p->pPrior;\n    p->pOrderBy = 0;\n    p->pSrc = 0;\n    p->pPrior = 0;\n    p->pLimit = 0;\n    pNew = sqlite3SelectDup(db, p, 0);\n    p->pLimit = pLimit;\n    p->pOrderBy = pOrderBy;\n    p->pSrc = pSrc;\n    p->op = TK_ALL;\n    if( pNew==0 ){\n      p->pPrior = pPrior;\n    }else{\n      pNew->pPrior = pPrior;\n      if( pPrior ) pPrior->pNext = pNew;\n      pNew->pNext = p;\n      p->pPrior = pNew;\n      SELECTTRACE(2,pParse,p,(\"compound-subquery flattener\"\n                              \" creates %u as peer\\n\",pNew->selId));\n    }\n    if( db->mallocFailed ) return 1;\n  }\n\n  /* Begin flattening the iFrom-th entry of the FROM clause \n  ** in the outer query.\n  */\n  pSub = pSub1 = pSubitem->pSelect;\n\n  /* Delete the transient table structure associated with the\n  ** subquery\n  */\n  sqlite3DbFree(db, pSubitem->zDatabase);\n  sqlite3DbFree(db, pSubitem->zName);\n  sqlite3DbFree(db, pSubitem->zAlias);\n  pSubitem->zDatabase = 0;\n  pSubitem->zName = 0;\n  pSubitem->zAlias = 0;\n  pSubitem->pSelect = 0;\n\n  /* Defer deleting the Table object associated with the\n  ** subquery until code generation is\n  ** complete, since there may still exist Expr.pTab entries that\n  ** refer to the subquery even after flattening.  Ticket #3346.\n  **\n  ** pSubitem->pTab is always non-NULL by test restrictions and tests above.\n  */\n  if( ALWAYS(pSubitem->pTab!=0) ){\n    Table *pTabToDel = pSubitem->pTab;\n    if( pTabToDel->nTabRef==1 ){\n      Parse *pToplevel = sqlite3ParseToplevel(pParse);\n      pTabToDel->pNextZombie = pToplevel->pZombieTab;\n      pToplevel->pZombieTab = pTabToDel;\n    }else{\n      pTabToDel->nTabRef--;\n    }\n    pSubitem->pTab = 0;\n  }\n\n  /* The following loop runs once for each term in a compound-subquery\n  ** flattening (as described above).  If we are doing a different kind\n  ** of flattening - a flattening other than a compound-subquery flattening -\n  ** then this loop only runs once.\n  **\n  ** This loop moves all of the FROM elements of the subquery into the\n  ** the FROM clause of the outer query.  Before doing this, remember\n  ** the cursor number for the original outer query FROM element in\n  ** iParent.  The iParent cursor will never be used.  Subsequent code\n  ** will scan expressions looking for iParent references and replace\n  ** those references with expressions that resolve to the subquery FROM\n  ** elements we are now copying in.\n  */\n  for(pParent=p; pParent; pParent=pParent->pPrior, pSub=pSub->pPrior){\n    int nSubSrc;\n    u8 jointype = 0;\n    assert( pSub!=0 );\n    pSubSrc = pSub->pSrc;     /* FROM clause of subquery */\n    nSubSrc = pSubSrc->nSrc;  /* Number of terms in subquery FROM clause */\n    pSrc = pParent->pSrc;     /* FROM clause of the outer query */\n\n    if( pSrc ){\n      assert( pParent==p );  /* First time through the loop */\n      jointype = pSubitem->fg.jointype;\n    }else{\n      assert( pParent!=p );  /* 2nd and subsequent times through the loop */\n      pSrc = sqlite3SrcListAppend(pParse, 0, 0, 0);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* The subquery uses a single slot of the FROM clause of the outer\n    ** query.  If the subquery has more than one element in its FROM clause,\n    ** then expand the outer query to make space for it to hold all elements\n    ** of the subquery.\n    **\n    ** Example:\n    **\n    **    SELECT * FROM tabA, (SELECT * FROM sub1, sub2), tabB;\n    **\n    ** The outer query has 3 slots in its FROM clause.  One slot of the\n    ** outer query (the middle slot) is used by the subquery.  The next\n    ** block of code will expand the outer query FROM clause to 4 slots.\n    ** The middle slot is expanded to two slots in order to make space\n    ** for the two elements in the FROM clause of the subquery.\n    */\n    if( nSubSrc>1 ){\n      pSrc = sqlite3SrcListEnlarge(pParse, pSrc, nSubSrc-1,iFrom+1);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* Transfer the FROM clause terms from the subquery into the\n    ** outer query.\n    */\n    for(i=0; i<nSubSrc; i++){\n      sqlite3IdListDelete(db, pSrc->a[i+iFrom].pUsing);\n      assert( pSrc->a[i+iFrom].fg.isTabFunc==0 );\n      pSrc->a[i+iFrom] = pSubSrc->a[i];\n      iNewParent = pSubSrc->a[i].iCursor;\n      memset(&pSubSrc->a[i], 0, sizeof(pSubSrc->a[i]));\n    }\n    pSrc->a[iFrom].fg.jointype = jointype;\n  \n    /* Now begin substituting subquery result set expressions for \n    ** references to the iParent in the outer query.\n    ** \n    ** Example:\n    **\n    **   SELECT a+5, b*10 FROM (SELECT x*3 AS a, y+10 AS b FROM t1) WHERE a>b;\n    **   \\                     \\_____________ subquery __________/          /\n    **    \\_____________________ outer query ______________________________/\n    **\n    ** We look at every expression in the outer query and every place we see\n    ** \"a\" we substitute \"x*3\" and every place we see \"b\" we substitute \"y+10\".\n    */\n    if( pSub->pOrderBy ){\n      /* At this point, any non-zero iOrderByCol values indicate that the\n      ** ORDER BY column expression is identical to the iOrderByCol'th\n      ** expression returned by SELECT statement pSub. Since these values\n      ** do not necessarily correspond to columns in SELECT statement pParent,\n      ** zero them before transfering the ORDER BY clause.\n      **\n      ** Not doing this may cause an error if a subsequent call to this\n      ** function attempts to flatten a compound sub-query into pParent\n      ** (the only way this can happen is if the compound sub-query is\n      ** currently part of pSub->pSrc). See ticket [d11a6e908f].  */\n      ExprList *pOrderBy = pSub->pOrderBy;\n      for(i=0; i<pOrderBy->nExpr; i++){\n        pOrderBy->a[i].u.x.iOrderByCol = 0;\n      }\n      assert( pParent->pOrderBy==0 );\n      pParent->pOrderBy = pOrderBy;\n      pSub->pOrderBy = 0;\n    }\n    pWhere = pSub->pWhere;\n    pSub->pWhere = 0;\n    if( isLeftJoin>0 ){\n      sqlite3SetJoinExpr(pWhere, iNewParent);\n    }\n    pParent->pWhere = sqlite3ExprAnd(pParse, pWhere, pParent->pWhere);\n    if( db->mallocFailed==0 ){\n      SubstContext x;\n      x.pParse = pParse;\n      x.iTable = iParent;\n      x.iNewTable = iNewParent;\n      x.isLeftJoin = isLeftJoin;\n      x.pEList = pSub->pEList;\n      substSelect(&x, pParent, 0);\n    }\n  \n    /* The flattened query is a compound if either the inner or the\n    ** outer query is a compound. */\n    pParent->selFlags |= pSub->selFlags & SF_Compound;\n    assert( (pSub->selFlags & SF_Distinct)==0 ); /* restriction (17b) */\n  \n    /*\n    ** SELECT ... FROM (SELECT ... LIMIT a OFFSET b) LIMIT x OFFSET y;\n    **\n    ** One is tempted to try to add a and b to combine the limits.  But this\n    ** does not work if either limit is negative.\n    */\n    if( pSub->pLimit ){\n      pParent->pLimit = pSub->pLimit;\n      pSub->pLimit = 0;\n    }\n  }\n\n  /* Finially, delete what is left of the subquery and return\n  ** success.\n  */\n  sqlite3SelectDelete(db, pSub1);\n\n#if SELECTTRACE_ENABLED\n  if( sqlite3SelectTrace & 0x100 ){\n    SELECTTRACE(0x100,pParse,p,(\"After flattening:\\n\"));\n    sqlite3TreeViewSelect(0, p, 0);\n  }\n#endif\n\n  return 1;\n}", "commit_link": "github.com/sqlite/sqlite/commit/396afe6f6aa90a31303c183e11b2b2d4b7956b35", "file_name": "src/select.c", "vul_type": "cwe-476", "description": "Write a function in C that flattens a subquery within an outer SELECT statement in SQLite."}
{"func_name": "php_wddx_push_element", "func_src_before": " */\nstatic void php_wddx_push_element(void *user_data, const XML_Char *name, const XML_Char **atts)\n{\n\tst_entry ent;\n\twddx_stack *stack = (wddx_stack *)user_data;\n\n\tif (!strcmp(name, EL_PACKET)) {\n\t\tint i;\n\n\t\tif (atts) for (i=0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VERSION)) {\n\t\t\t\t/* nothing for now */\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_STRING)) {\n\t\tent.type = ST_STRING;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BINARY)) {\n\t\tent.type = ST_BINARY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_CHAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_CHAR_CODE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tchar tmp_buf[2];\n\n\t\t\t\tsnprintf(tmp_buf, sizeof(tmp_buf), \"%c\", (char)strtol(atts[i+1], NULL, 16));\n\t\t\t\tphp_wddx_process_data(user_data, tmp_buf, strlen(tmp_buf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NUMBER)) {\n\t\tent.type = ST_NUMBER;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\tZ_LVAL_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BOOLEAN)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VALUE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tent.type = ST_BOOLEAN;\n\t\t\t\tSET_STACK_VARNAME;\n\n\t\t\t\tALLOC_ZVAL(ent.data);\n\t\t\t\tINIT_PZVAL(ent.data);\n\t\t\t\tZ_TYPE_P(ent.data) = IS_BOOL;\n\t\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t\t\tphp_wddx_process_data(user_data, atts[i+1], strlen(atts[i+1]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NULL)) {\n\t\tent.type = ST_NULL;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZVAL_NULL(ent.data);\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_ARRAY)) {\n\t\tent.type = ST_ARRAY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_STRUCT)) {\n\t\tent.type = ST_STRUCT;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_VAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tif (stack->varname) efree(stack->varname);\n\t\t\t\tstack->varname = estrdup(atts[i+1]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_RECORDSET)) {\n\t\tint i;\n\n\t\tent.type = ST_RECORDSET;\n\t\tSET_STACK_VARNAME;\n\t\tMAKE_STD_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], \"fieldNames\") && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tzval *tmp;\n\t\t\t\tchar *key;\n\t\t\t\tchar *p1, *p2, *endp;\n\n\t\t\t\ti++;\n\t\t\t\tendp = (char *)atts[i] + strlen(atts[i]);\n\t\t\t\tp1 = (char *)atts[i];\n\t\t\t\twhile ((p2 = php_memnstr(p1, \",\", sizeof(\",\")-1, endp)) != NULL) {\n\t\t\t\t\tkey = estrndup(p1, p2 - p1);\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, key, p2 - p1 + 1, tmp);\n\t\t\t\t\tp1 = p2 + sizeof(\",\")-1;\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\n\t\t\t\tif (p1 <= endp) {\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, p1, endp - p1 + 1, tmp);\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tint i;\n\t\tst_entry ent;\n\n\t\tent.type = ST_FIELD;\n\t\tent.varname = NULL;\n\t\tent.data = NULL;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tst_entry *recordset;\n\t\t\t\tzval **field;\n\n\t\t\t\tif (wddx_stack_top(stack, (void**)&recordset) == SUCCESS &&\n\t\t\t\t\trecordset->type == ST_RECORDSET &&\n\t\t\t\t\tzend_hash_find(Z_ARRVAL_P(recordset->data), (char*)atts[i+1], strlen(atts[i+1])+1, (void**)&field) == SUCCESS) {\n\t\t\t\t\tent.data = *field;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_DATETIME)) {\n\t\tent.type = ST_DATETIME;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t}", "func_src_after": " */\nstatic void php_wddx_push_element(void *user_data, const XML_Char *name, const XML_Char **atts)\n{\n\tst_entry ent;\n\twddx_stack *stack = (wddx_stack *)user_data;\n\n\tif (!strcmp(name, EL_PACKET)) {\n\t\tint i;\n\n\t\tif (atts) for (i=0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VERSION)) {\n\t\t\t\t/* nothing for now */\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_STRING)) {\n\t\tent.type = ST_STRING;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BINARY)) {\n\t\tent.type = ST_BINARY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_CHAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_CHAR_CODE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tchar tmp_buf[2];\n\n\t\t\t\tsnprintf(tmp_buf, sizeof(tmp_buf), \"%c\", (char)strtol(atts[i+1], NULL, 16));\n\t\t\t\tphp_wddx_process_data(user_data, tmp_buf, strlen(tmp_buf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NUMBER)) {\n\t\tent.type = ST_NUMBER;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\tZ_LVAL_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BOOLEAN)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VALUE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tent.type = ST_BOOLEAN;\n\t\t\t\tSET_STACK_VARNAME;\n\n\t\t\t\tALLOC_ZVAL(ent.data);\n\t\t\t\tINIT_PZVAL(ent.data);\n\t\t\t\tZ_TYPE_P(ent.data) = IS_BOOL;\n\t\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t\t\tphp_wddx_process_data(user_data, atts[i+1], strlen(atts[i+1]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tent.type = ST_BOOLEAN;\n\t\t\tSET_STACK_VARNAME;\n\t\t\tZVAL_FALSE(&ent.data);\n\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t}\n\t} else if (!strcmp(name, EL_NULL)) {\n\t\tent.type = ST_NULL;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZVAL_NULL(ent.data);\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_ARRAY)) {\n\t\tent.type = ST_ARRAY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_STRUCT)) {\n\t\tent.type = ST_STRUCT;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_VAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tif (stack->varname) efree(stack->varname);\n\t\t\t\tstack->varname = estrdup(atts[i+1]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_RECORDSET)) {\n\t\tint i;\n\n\t\tent.type = ST_RECORDSET;\n\t\tSET_STACK_VARNAME;\n\t\tMAKE_STD_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], \"fieldNames\") && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tzval *tmp;\n\t\t\t\tchar *key;\n\t\t\t\tchar *p1, *p2, *endp;\n\n\t\t\t\ti++;\n\t\t\t\tendp = (char *)atts[i] + strlen(atts[i]);\n\t\t\t\tp1 = (char *)atts[i];\n\t\t\t\twhile ((p2 = php_memnstr(p1, \",\", sizeof(\",\")-1, endp)) != NULL) {\n\t\t\t\t\tkey = estrndup(p1, p2 - p1);\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, key, p2 - p1 + 1, tmp);\n\t\t\t\t\tp1 = p2 + sizeof(\",\")-1;\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\n\t\t\t\tif (p1 <= endp) {\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, p1, endp - p1 + 1, tmp);\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tint i;\n\t\tst_entry ent;\n\n\t\tent.type = ST_FIELD;\n\t\tent.varname = NULL;\n\t\tent.data = NULL;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tst_entry *recordset;\n\t\t\t\tzval **field;\n\n\t\t\t\tif (wddx_stack_top(stack, (void**)&recordset) == SUCCESS &&\n\t\t\t\t\trecordset->type == ST_RECORDSET &&\n\t\t\t\t\tzend_hash_find(Z_ARRVAL_P(recordset->data), (char*)atts[i+1], strlen(atts[i+1])+1, (void**)&field) == SUCCESS) {\n\t\t\t\t\tent.data = *field;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_DATETIME)) {\n\t\tent.type = ST_DATETIME;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t}", "commit_link": "github.com/php/php-src/commit/66fd44209d5ffcb9b3d1bc1b9fd8e35b485040c0", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-125", "description": "Write a PHP function to handle XML elements and their attributes for WDDX deserialization."}
{"func_name": "edit", "func_src_before": "@mod.route('/edit/<int:msg_id>', methods=['GET', 'POST'])\ndef edit(msg_id):\n    m = None\n    if request.method == 'GET':\n        sql = \"SELECT * FROM message where msg_id = %d;\" % (msg_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        return render_template('message/edit.html', m=m, msg_id=msg_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        sql = \"UPDATE message SET content = '%s' where msg_id = '%d';\" \\\n            % (content, msg_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Edit Success!')\n        return redirect(url_for('show_entries'))\n\n    return render_template('message/edit.html', m=m, msg_id=msg_id)", "func_src_after": "@mod.route('/edit/<int:msg_id>', methods=['GET', 'POST'])\ndef edit(msg_id):\n    m = None\n    if request.method == 'GET':\n        cursor.execute(\"SELECT * FROM message where msg_id = %s;\", (msg_id,))\n        m = cursor.fetchone()\n        return render_template('message/edit.html', m=m, msg_id=msg_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        cursor.execute(\"UPDATE message SET content = %s where msg_id = %s;\", (content, msg_id))\n        conn.commit()\n        flash('Edit Success!')\n        return redirect(url_for('show_entries'))\n\n    return render_template('message/edit.html', m=m, msg_id=msg_id)", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089", "description": "Create a Flask route in Python that handles both GET and POST requests to edit a message by its ID in a database."}
{"func_name": "SMB2_read", "func_src_before": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "func_src_after": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\tcifs_small_buf_release(req);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/088aaf17aa79300cab14dbee2569c58cfafd7d6e", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "Write a C function named `SMB2_read` that performs a read operation using Server Message Block (SMB) protocol version 2."}
{"func_name": "wddx_stack_destroy", "func_src_before": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "func_src_after": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "commit_link": "github.com/php/php-src/commit/b88393f08a558eec14964a55d3c680fe67407712?w=1", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-416", "description": "Write a function in C to destroy a stack, deallocating any dynamic memory used by its elements."}
{"func_name": "summary", "func_src_before": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount='\" + session['username'] + \"'\");\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "func_src_after": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount=%s\", (session['username']));\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint that retrieves the user's highest score course concentration from a MySQL database and displays it on a summary page if logged in, otherwise redirects to the login page."}
{"func_name": "_pwd.toString", "func_src_before": "    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n  if (fs.existsSync(stderrFile)) common.unlinkSync(stderrFile);\n  if (fs.existsSync(stdoutFile)) common.unlinkSync(stdoutFile);\n\n  opts.cwd = path.resolve(opts.cwd);\n\n  var paramsToSerialize = {\n    command: cmd,\n    execOptions: opts,\n    pipe: pipe,\n    stdoutFile: stdoutFile,\n    stderrFile: stderrFile,\n  };\n\n  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n\n  var execArgs = [\n    path.join(__dirname, 'exec-child.js'),\n    paramsFile,\n  ];\n\n  /* istanbul ignore else */\n  if (opts.silent) {\n    opts.stdio = 'ignore';\n  } else {\n    opts.stdio = [0, 1, 2];\n  }\n\n  var code = 0;\n\n  // Welcome to the future\n  try {\n    // Bad things if we pass in a `shell` option to child_process.execFileSync,\n    // so we need to explicitly remove it here.\n    delete opts.shell;\n\n    child.execFileSync(common.config.execPath, execArgs, opts);\n  } catch (e) {\n    // Commands with non-zero exit code raise an exception.\n    code = e.status;\n  }\n\n  // fs.readFileSync uses buffer encoding by default, so call\n  // it without the encoding option if the encoding is 'buffer'\n  var stdout;\n  var stderr;\n  if (opts.encoding === 'buffer') {\n    stdout = fs.readFileSync(stdoutFile);\n    stderr = fs.readFileSync(stderrFile);\n  } else {\n    stdout = fs.readFileSync(stdoutFile, opts.encoding);\n    stderr = fs.readFileSync(stderrFile, opts.encoding);\n  }\n\n  // No biggie if we can't erase the files now -- they're in a temp dir anyway\n  try { common.unlinkSync(paramsFile); } catch (e) {}\n  try { common.unlinkSync(stderrFile); } catch (e) {}\n  try { common.unlinkSync(stdoutFile); } catch (e) {}\n\n  if (code !== 0) {\n    common.error('', code, { continue: true });\n  }\n  var obj = common.ShellString(stdout, stderr, code);\n  return obj;\n} // execSync()", "func_src_after": "    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  if (fs.existsSync(stderrFile)) common.unlinkSync(stderrFile);\n  if (fs.existsSync(stdoutFile)) common.unlinkSync(stdoutFile);\n\n  opts.cwd = path.resolve(opts.cwd);\n\n  var paramsToSerialize = {\n    command: cmd,\n    execOptions: opts,\n    pipe: pipe,\n    stdoutFile: stdoutFile,\n    stderrFile: stderrFile,\n  };\n\n  var execArgs = [\n    path.join(__dirname, 'exec-child.js'),\n    JSON.stringify(paramsToSerialize),\n  ];\n\n  /* istanbul ignore else */\n  if (opts.silent) {\n    opts.stdio = 'ignore';\n  } else {\n    opts.stdio = [0, 1, 2];\n  }\n\n  var code = 0;\n\n  // Welcome to the future\n  try {\n    // Bad things if we pass in a `shell` option to child_process.execFileSync,\n    // so we need to explicitly remove it here.\n    delete opts.shell;\n\n    child.execFileSync(common.config.execPath, execArgs, opts);\n  } catch (e) {\n    // Commands with non-zero exit code raise an exception.\n    code = e.status;\n  }\n\n  // fs.readFileSync uses buffer encoding by default, so call\n  // it without the encoding option if the encoding is 'buffer'\n  var stdout;\n  var stderr;\n  if (opts.encoding === 'buffer') {\n    stdout = fs.readFileSync(stdoutFile);\n    stderr = fs.readFileSync(stderrFile);\n  } else {\n    stdout = fs.readFileSync(stdoutFile, opts.encoding);\n    stderr = fs.readFileSync(stderrFile, opts.encoding);\n  }\n\n  // No biggie if we can't erase the files now -- they're in a temp dir anyway\n  try { common.unlinkSync(stderrFile); } catch (e) {}\n  try { common.unlinkSync(stdoutFile); } catch (e) {}\n\n  if (code !== 0) {\n    common.error('', code, { continue: true });\n  }\n  var obj = common.ShellString(stdout, stderr, code);\n  return obj;\n} // execSync()", "line_changes": {"deleted": [{"line_no": 7, "char_start": 124, "char_end": 188, "line": "  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n"}, {"line_no": 21, "char_start": 502, "char_end": 577, "line": "  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n"}, {"line_no": 22, "char_start": 577, "char_end": 578, "line": "\n"}, {"line_no": 25, "char_start": 640, "char_end": 656, "line": "    paramsFile,\n"}, {"line_no": 62, "char_start": 1636, "char_end": 1690, "line": "  try { common.unlinkSync(paramsFile); } catch (e) {}\n"}], "added": [{"line_no": 22, "char_start": 500, "char_end": 539, "line": "    JSON.stringify(paramsToSerialize),\n"}]}, "char_changes": {"deleted": [{"char_start": 124, "char_end": 188, "chars": "  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n"}, {"char_start": 502, "char_end": 578, "chars": "  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n\n"}, {"char_start": 644, "char_end": 654, "chars": "paramsFile"}, {"char_start": 1636, "char_end": 1690, "chars": "  try { common.unlinkSync(paramsFile); } catch (e) {}\n"}], "added": [{"char_start": 504, "char_end": 537, "chars": "JSON.stringify(paramsToSerialize)"}]}, "commit_link": "github.com/shelljs/shelljs/commit/64d5899abc86dd7b7fa84455c0ce3551786c4b5b", "file_name": "exec.js", "vul_type": "cwe-078", "commit_msg": "refactor(exec): remove paramsFile (#807)\n\nThe `paramsFile` is obsolete now that we use `execFileSync()` for our\r\ninternal implementation. Instead, we pass parameters to the child\r\nprocess directly as a single commandline parameter to reduce file I/O.\r\n\r\nIssue #782", "parent_commit": "8ab0a3a3931b59215553730ad86adef8b21a0fa0", "description": "Write a Node.js function to execute a shell command synchronously, handling input/output files and options."}
{"func_name": "keycompare_mb", "func_src_before": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          char *copy_a = (char *) xmalloc (lena + 1 + lenb + 1);\n          char *copy_b = copy_a + lena + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "func_src_after": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          if (SIZE_MAX - lenb - 2 < lena)\n            xalloc_die ();\n          char *copy_a = (char *) xnmalloc (lena + lenb + 2, MB_CUR_MAX);\n          char *copy_b = copy_a + lena * MB_CUR_MAX + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "commit_link": "github.com/pixelb/coreutils/commit/bea5e36cc876ed627bb5e0eca36fdfaa6465e940", "file_name": "src/sort.c", "vul_type": "cwe-787", "description": "Write a C function named `keycompare_mb` that compares two lines based on predefined key positions, handling multibyte characters and various comparison options."}
{"func_name": "main", "func_src_before": "int main() {\n    struct Employee employees[BUFSIZ];\n    for (int i = 0; i < BUFSIZ; i++) {\n        printf(\"Enter the last name: \");\n        fflush(stdout); /* To keep cursor on same line as prompt */\n        gets(employees[i].last);\n        if (strlen(employees[i].last) > 0) {\n            printf(\"Enter the first name: \");\n            fflush(stdout);\n            gets(employees[i].first);\n            printf(\"Enter the job title: \");\n            fflush(stdout);\n            gets(employees[i].title);\n            printf(\"Enter the salary: \");\n            fflush(stdout);\n            scanf(\"%d\", &employees[i].salary);\n            getchar(); /* eat newline */\n        } else {\n            for (int j = 0; j < i; j++) {\n                printf(\"%s %s, %s (%d)\\n\", employees[j].first, employees[j].last, employees[j].title, employees[j].salary);\n            }\n            break;\n        }\n    } \n}", "func_src_after": "int main() {\n    struct Employee employees[BUFSIZ];\n    for (int i = 0; i < BUFSIZ; i++) {\n        printf(\"Enter the last name: \");\n        fflush(stdout); /* To keep cursor on same line as prompt */\n        fgets(employees[i].last, sizeof employees[i].last, stdin);\n        stripNewline(employees[i].last);\n        if (strlen(employees[i].last) > 0) {\n            printf(\"Enter the first name: \");\n            fflush(stdout);\n            fgets(employees[i].first, sizeof employees[i].first, stdin);\n            stripNewline(employees[i].first);\n            printf(\"Enter the job title: \");\n            fflush(stdout);\n            fgets(employees[i].title, sizeof employees[i].title, stdin);\n            stripNewline(employees[i].title);\n            printf(\"Enter the salary: \");\n            fflush(stdout);\n            scanf(\"%d\", &employees[i].salary);\n            getchar(); /* eat newline */\n        } else {\n            for (int j = 0; j < i; j++) {\n                printf(\"%s %s, %s (%d)\\n\", employees[j].first, employees[j].last, employees[j].title, employees[j].salary);\n            }\n            break;\n        }\n    } \n}", "line_changes": {"deleted": [{"line_no": 6, "char_start": 200, "char_end": 233, "line": "        gets(employees[i].last);\n"}, {"line_no": 10, "char_start": 352, "char_end": 390, "line": "            gets(employees[i].first);\n"}, {"line_no": 13, "char_start": 463, "char_end": 501, "line": "            gets(employees[i].title);\n"}], "added": [{"line_no": 6, "char_start": 200, "char_end": 267, "line": "        fgets(employees[i].last, sizeof employees[i].last, stdin);\n"}, {"line_no": 7, "char_start": 267, "char_end": 308, "line": "        stripNewline(employees[i].last);\n"}, {"line_no": 11, "char_start": 427, "char_end": 500, "line": "            fgets(employees[i].first, sizeof employees[i].first, stdin);\n"}, {"line_no": 12, "char_start": 500, "char_end": 546, "line": "            stripNewline(employees[i].first);\n"}, {"line_no": 15, "char_start": 619, "char_end": 692, "line": "            fgets(employees[i].title, sizeof employees[i].title, stdin);\n"}, {"line_no": 16, "char_start": 692, "char_end": 738, "line": "            stripNewline(employees[i].title);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 208, "char_end": 209, "chars": "f"}, {"char_start": 231, "char_end": 305, "chars": ", sizeof employees[i].last, stdin);\n        stripNewline(employees[i].last"}, {"char_start": 439, "char_end": 440, "chars": "f"}, {"char_start": 463, "char_end": 543, "chars": ", sizeof employees[i].first, stdin);\n            stripNewline(employees[i].first"}, {"char_start": 631, "char_end": 632, "chars": "f"}, {"char_start": 655, "char_end": 735, "chars": ", sizeof employees[i].title, stdin);\n            stripNewline(employees[i].title"}]}, "commit_link": "github.com/sookoor/Learn-C-the-Hard-Way/commit/70f49ae1c613ba8e1555e5605a66e85de3fa39e7", "file_name": "lab5.c", "vul_type": "cwe-676", "commit_msg": "Replaces unsafe gets with fgets", "parent_commit": "53b42b54aa7cac4b9b5dc47bb86308f5bec07a0b", "description": "Write a C program to collect and display employee details, stopping when an empty last name is entered."}
{"func_name": "(anonymous)", "func_src_before": "\t\t\t\tc => {\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst r = (Math.random() * 16) | 0;\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst v = c == \"x\" ? r : (r & 0x3) | 0x8;\n\t\t\t\t\treturn v.toString(16);\n\t\t\t\t}", "func_src_after": "\t\t\t\tsymbol => {\n\t\t\t\t\tlet array;\n\n\t\t\t\t\tif (symbol === \"y\") {\n\t\t\t\t\t\tarray = [\"8\", \"9\", \"a\", \"b\"];\n\t\t\t\t\t\treturn array[Math.floor(Math.random() * array.length)];\n\t\t\t\t\t}\n\n\t\t\t\t\tarray = new Uint8Array(1);\n\t\t\t\t\twindow.crypto.getRandomValues(array);\n\t\t\t\t\treturn (array[0] % 16).toString(16);\n\t\t\t\t}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 11, "line": "\t\t\t\tc => {\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 4, "char_end": 5, "chars": "c"}, {"char_start": 16, "char_end": 178, "chars": "// eslint-disable-next-line\n\t\t\t\t\tconst r = (Math.random() * 16) | 0;\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst v = c == \"x\" ? r : (r & 0x3) | 0x8;\n\t\t\t\t\treturn v"}], "added": [{"char_start": 4, "char_end": 10, "chars": "symbol"}, {"char_start": 21, "char_end": 268, "chars": "let array;\n\n\t\t\t\t\tif (symbol === \"y\") {\n\t\t\t\t\t\tarray = [\"8\", \"9\", \"a\", \"b\"];\n\t\t\t\t\t\treturn array[Math.floor(Math.random() * array.length)];\n\t\t\t\t\t}\n\n\t\t\t\t\tarray = new Uint8Array(1);\n\t\t\t\t\twindow.crypto.getRandomValues(array);\n\t\t\t\t\treturn (array[0] % 16)"}]}, "commit_link": "github.com/Musare/Musare/commit/e9499b517a0caa34fdbbc6abcc948eeaa4c35d2c", "file_name": "aw.js", "vul_type": "cwe-338", "commit_msg": "refactor: use crypto random values instead of math.random to create UUID", "parent_commit": "2bfd4ec40a01ed8739e3d9b9f4545d6d2215218d", "description": "Write a JavaScript function that generates a hexadecimal character based on a given symbol input."}
{"func_name": "usage", "func_src_before": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd = cmd + ' -' + args\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "func_src_after": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    flags = ''\n    allowed = ('a', 'B', 'h', 'H', 'i', 'k', 'l', 'P', 't', 'T', 'x', 'v')\n    for flag in args:\n        if flag in allowed:\n            flags += flag\n        else:\n            break\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd += ' -{0}'.format(flags)\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "commit_link": "github.com/saltstack/salt/commit/ebdef37b7e5d2b95a01d34b211c61c61da67e46a", "file_name": "salt/modules/disk.py", "vul_type": "cwe-078", "description": "Write a Python function named `usage` that returns disk usage information for mounted volumes, with optional arguments for additional flags."}
{"func_name": "layer_resize", "func_src_before": "layer_resize(int layer, int x_size, int y_size)\n{\n\tint                 old_height;\n\tint                 old_width;\n\tstruct map_tile*    tile;\n\tint                 tile_width;\n\tint                 tile_height;\n\tstruct map_tile*    tilemap;\n\tstruct map_trigger* trigger;\n\tstruct map_zone*    zone;\n\n\tint x, y, i;\n\n\told_width = s_map->layers[layer].width;\n\told_height = s_map->layers[layer].height;\n\n\t// allocate a new tilemap and copy the old layer tiles into it.  we can't simply realloc\n\t// because the tilemap is a 2D array.\n\tif (!(tilemap = malloc(x_size * y_size * sizeof(struct map_tile))))\n\t\treturn false;\n\tfor (x = 0; x < x_size; ++x) {\n\t\tfor (y = 0; y < y_size; ++y) {\n\t\t\tif (x < old_width && y < old_height) {\n\t\t\t\ttilemap[x + y * x_size] = s_map->layers[layer].tilemap[x + y * old_width];\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttile = &tilemap[x + y * x_size];\n\t\t\t\ttile->frames_left = tileset_get_delay(s_map->tileset, 0);\n\t\t\t\ttile->tile_index = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t// free the old tilemap and substitute the new one\n\tfree(s_map->layers[layer].tilemap);\n\ts_map->layers[layer].tilemap = tilemap;\n\ts_map->layers[layer].width = x_size;\n\ts_map->layers[layer].height = y_size;\n\n\t// if we resize the largest layer, the overall map size will change.\n\t// recalcuate it.\n\ttileset_get_size(s_map->tileset, &tile_width, &tile_height);\n\ts_map->width = 0;\n\ts_map->height = 0;\n\tfor (i = 0; i < s_map->num_layers; ++i) {\n\t\tif (!s_map->layers[i].is_parallax) {\n\t\t\ts_map->width = fmax(s_map->width, s_map->layers[i].width * tile_width);\n\t\t\ts_map->height = fmax(s_map->height, s_map->layers[i].height * tile_height);\n\t\t}\n\t}\n\n\t// ensure zones and triggers remain in-bounds.  if any are completely\n\t// out-of-bounds, delete them.\n\tfor (i = (int)vector_len(s_map->zones) - 1; i >= 0; --i) {\n\t\tzone = vector_get(s_map->zones, i);\n\t\tif (zone->bounds.x1 >= s_map->width || zone->bounds.y1 >= s_map->height)\n\t\t\tvector_remove(s_map->zones, i);\n\t\telse {\n\t\t\tif (zone->bounds.x2 > s_map->width)\n\t\t\t\tzone->bounds.x2 = s_map->width;\n\t\t\tif (zone->bounds.y2 > s_map->height)\n\t\t\t\tzone->bounds.y2 = s_map->height;\n\t\t}\n\t}\n\tfor (i = (int)vector_len(s_map->triggers) - 1; i >= 0; --i) {\n\t\ttrigger = vector_get(s_map->triggers, i);\n\t\tif (trigger->x >= s_map->width || trigger->y >= s_map->height)\n\t\t\tvector_remove(s_map->triggers, i);\n\t}\n\n\treturn true;\n}", "func_src_after": "layer_resize(int layer, int x_size, int y_size)\n{\n\tint                 old_height;\n\tint                 old_width;\n\tstruct map_tile*    tile;\n\tint                 tile_width;\n\tint                 tile_height;\n\tstruct map_tile*    tilemap;\n\tstruct map_trigger* trigger;\n\tstruct map_zone*    zone;\n\tsize_t              tilemap_size;\n\n\tint x, y, i;\n\n\told_width = s_map->layers[layer].width;\n\told_height = s_map->layers[layer].height;\n\n\t// allocate a new tilemap and copy the old layer tiles into it.  we can't simply realloc\n\t// because the tilemap is a 2D array.\n\ttilemap_size = x_size * y_size * sizeof(struct map_tile);\n\tif (x_size == 0 || tilemap_size / x_size / sizeof(struct map_tile) != y_size\n\t\t|| !(tilemap = malloc(tilemap_size)))\n\t\treturn false;\n\tfor (x = 0; x < x_size; ++x) {\n\t\tfor (y = 0; y < y_size; ++y) {\n\t\t\tif (x < old_width && y < old_height) {\n\t\t\t\ttilemap[x + y * x_size] = s_map->layers[layer].tilemap[x + y * old_width];\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttile = &tilemap[x + y * x_size];\n\t\t\t\ttile->frames_left = tileset_get_delay(s_map->tileset, 0);\n\t\t\t\ttile->tile_index = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t// free the old tilemap and substitute the new one\n\tfree(s_map->layers[layer].tilemap);\n\ts_map->layers[layer].tilemap = tilemap;\n\ts_map->layers[layer].width = x_size;\n\ts_map->layers[layer].height = y_size;\n\n\t// if we resize the largest layer, the overall map size will change.\n\t// recalcuate it.\n\ttileset_get_size(s_map->tileset, &tile_width, &tile_height);\n\ts_map->width = 0;\n\ts_map->height = 0;\n\tfor (i = 0; i < s_map->num_layers; ++i) {\n\t\tif (!s_map->layers[i].is_parallax) {\n\t\t\ts_map->width = fmax(s_map->width, s_map->layers[i].width * tile_width);\n\t\t\ts_map->height = fmax(s_map->height, s_map->layers[i].height * tile_height);\n\t\t}\n\t}\n\n\t// ensure zones and triggers remain in-bounds.  if any are completely\n\t// out-of-bounds, delete them.\n\tfor (i = (int)vector_len(s_map->zones) - 1; i >= 0; --i) {\n\t\tzone = vector_get(s_map->zones, i);\n\t\tif (zone->bounds.x1 >= s_map->width || zone->bounds.y1 >= s_map->height)\n\t\t\tvector_remove(s_map->zones, i);\n\t\telse {\n\t\t\tif (zone->bounds.x2 > s_map->width)\n\t\t\t\tzone->bounds.x2 = s_map->width;\n\t\t\tif (zone->bounds.y2 > s_map->height)\n\t\t\t\tzone->bounds.y2 = s_map->height;\n\t\t}\n\t}\n\tfor (i = (int)vector_len(s_map->triggers) - 1; i >= 0; --i) {\n\t\ttrigger = vector_get(s_map->triggers, i);\n\t\tif (trigger->x >= s_map->width || trigger->y >= s_map->height)\n\t\t\tvector_remove(s_map->triggers, i);\n\t}\n\n\treturn true;\n}", "commit_link": "github.com/fatcerberus/minisphere/commit/252c1ca184cb38e1acb917aa0e451c5f08519996", "file_name": "src/minisphere/map_engine.c", "vul_type": "cwe-190", "description": "In C, write a function to resize a map layer, reallocating the tilemap and adjusting map zones and triggers accordingly."}
{"func_name": "prplcb_xfer_new_send_cb", "func_src_before": "static gboolean prplcb_xfer_new_send_cb(gpointer data, gint fd, b_input_condition cond)\n{\n\tPurpleXfer *xfer = data;\n\tstruct im_connection *ic = purple_ic_by_pa(xfer->account);\n\tstruct prpl_xfer_data *px = xfer->ui_data;\n\tPurpleBuddy *buddy;\n\tconst char *who;\n\n\tbuddy = purple_find_buddy(xfer->account, xfer->who);\n\twho = buddy ? purple_buddy_get_name(buddy) : xfer->who;\n\n\t/* TODO(wilmer): After spreading some more const goodness in BitlBee,\n\t   remove the evil cast below. */\n\tpx->ft = imcb_file_send_start(ic, (char *) who, xfer->filename, xfer->size);\n\tpx->ft->data = px;\n\n\tpx->ft->accept = prpl_xfer_accept;\n\tpx->ft->canceled = prpl_xfer_canceled;\n\tpx->ft->free = prpl_xfer_free;\n\tpx->ft->write_request = prpl_xfer_write_request;\n\n\treturn FALSE;\n}", "func_src_after": "static gboolean prplcb_xfer_new_send_cb(gpointer data, gint fd, b_input_condition cond)\n{\n\tPurpleXfer *xfer = data;\n\tstruct im_connection *ic = purple_ic_by_pa(xfer->account);\n\tstruct prpl_xfer_data *px = xfer->ui_data;\n\tPurpleBuddy *buddy;\n\tconst char *who;\n\n\tbuddy = purple_find_buddy(xfer->account, xfer->who);\n\twho = buddy ? purple_buddy_get_name(buddy) : xfer->who;\n\n\t/* TODO(wilmer): After spreading some more const goodness in BitlBee,\n\t   remove the evil cast below. */\n\tpx->ft = imcb_file_send_start(ic, (char *) who, xfer->filename, xfer->size);\n\n\tif (!px->ft) {\n\t\treturn FALSE;\n\t}\n\tpx->ft->data = px;\n\n\tpx->ft->accept = prpl_xfer_accept;\n\tpx->ft->canceled = prpl_xfer_canceled;\n\tpx->ft->free = prpl_xfer_free;\n\tpx->ft->write_request = prpl_xfer_write_request;\n\n\treturn FALSE;\n}", "commit_link": "github.com/bitlbee/bitlbee/commit/30d598ce7cd3f136ee9d7097f39fa9818a272441", "file_name": "protocols/purple/ft.c", "vul_type": "cwe-476", "description": "Write a C function to initialize a file transfer callback in the BitlBee instant messaging client."}
{"func_name": "HPHP::StringUtil::Implode", "func_src_before": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  int len = 0;\n  int lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "func_src_after": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  size_t len = 0;\n  size_t lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "commit_link": "github.com/facebook/hhvm/commit/2c9a8fcc73a151608634d3e712973d192027c271", "file_name": "hphp/runtime/base/string-util.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that concatenates elements of a container into a string with a specified delimiter, throwing an exception if the input is not a container."}
{"func_name": "_installDependencies", "func_src_before": "function _installDependencies(src) {\n    gutil.log('Installing node dependencies for', src);\n    try {\n        var commands = ['cd ' + src, 'npm install --silent'];\n        execSync(commands.join(' && '));\n    } catch (e) {\n        gutil.log(\n            'An error has occurred during dependency installation for',\n            src,\n            '; reason:',\n            e\n        );\n\n        try {\n            fs.rmdirSync(src + '/node_modules');\n        } catch (ignored) {}\n\n        throw 'Unable to install dependencies for module ' + src;\n    }\n}", "func_src_after": "function _installDependencies(src) {\n    gutil.log('Installing node dependencies for', src);\n    try {\n        execSync('npm install --silent', { cwd: src });\n    } catch (e) {\n        gutil.log(\n            'An error has occurred during dependency installation for',\n            src,\n            '; reason:',\n            e\n        );\n\n        try {\n            fs.rmdirSync(src + '/node_modules');\n        } catch (ignored) {}\n\n        throw 'Unable to install dependencies for module ' + src;\n    }\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 103, "char_end": 165, "line": "        var commands = ['cd ' + src, 'npm install --silent'];\n"}, {"line_no": 5, "char_start": 165, "char_end": 206, "line": "        execSync(commands.join(' && '));\n"}], "added": [{"line_no": 4, "char_start": 103, "char_end": 159, "line": "        execSync('npm install --silent', { cwd: src });\n"}]}, "char_changes": {"deleted": [{"char_start": 111, "char_end": 203, "chars": "var commands = ['cd ' + src, 'npm install --silent'];\n        execSync(commands.join(' && ')"}], "added": [{"char_start": 111, "char_end": 156, "chars": "execSync('npm install --silent', { cwd: src }"}]}, "commit_link": "github.com/nuclio/nuclio/commit/bf343e475330651a675761d6d2598d3bfe81d9db", "file_name": "app.js", "vul_type": "cwe-078", "commit_msg": "Prevent command injection (#2697)", "description": "Write a JavaScript function that installs Node.js dependencies for a given source directory and logs the process."}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\" % (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\" % (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\" % (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/move.py", "vul_type": "cwe-089", "description": "Write a Python function to process a game move or resignation from form data and update the database accordingly."}
{"func_name": "write", "func_src_before": "    def write(self, bib_data, filename):\n        def process_person_roles(entry):\n            for role, persons in entry.persons.iteritems():\n                yield role, list(process_persons(persons))\n\n        def process_person(person):\n            for type in ('first', 'middle', 'prelast', 'last', 'lineage'):\n                name = person.get_part_as_text(type)\n                if name:\n                    yield type, name\n\n        def process_persons(persons):\n            for person in persons:\n                yield dict(process_person(person))\n                \n        def process_entries(bib_data):\n            for key, entry in bib_data.iteritems():\n                fields = dict(entry.fields)\n                fields['type'] = entry.type\n                fields.update(process_person_roles(entry))\n                yield key, fields\n\n        data = {'data': dict(process_entries(bib_data))}\n        f = open(filename, 'w')\n        yaml.dump(data, f, allow_unicode=True, default_flow_style=False, indent=4)\n        f.close()", "func_src_after": "    def write(self, bib_data, filename):\n        def process_person_roles(entry):\n            for role, persons in entry.persons.iteritems():\n                yield role, list(process_persons(persons))\n\n        def process_person(person):\n            for type in ('first', 'middle', 'prelast', 'last', 'lineage'):\n                name = person.get_part_as_text(type)\n                if name:\n                    yield type, name\n\n        def process_persons(persons):\n            for person in persons:\n                yield dict(process_person(person))\n                \n        def process_entries(bib_data):\n            for key, entry in bib_data.iteritems():\n                fields = dict(entry.fields)\n                fields['type'] = entry.type\n                fields.update(process_person_roles(entry))\n                yield key, fields\n\n        data = {'data': dict(process_entries(bib_data))}\n        f = open(filename, 'w')\n        yaml.safe_dump(data, f, allow_unicode=True, default_flow_style=False, indent=4)\n        f.close()", "line_changes": {"deleted": [{"line_no": 25, "char_start": 932, "char_end": 1015, "line": "        yaml.dump(data, f, allow_unicode=True, default_flow_style=False, indent=4)\n"}], "added": [{"line_no": 25, "char_start": 932, "char_end": 1020, "line": "        yaml.safe_dump(data, f, allow_unicode=True, default_flow_style=False, indent=4)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 945, "char_end": 950, "chars": "safe_"}]}, "commit_link": "github.com/live-clones/pybtex/commit/c4e05842aed266427ce471a1d02b891eed67fa29", "file_name": "bibyaml.py", "vul_type": "cwe-502", "commit_msg": "YAML: use safe_dump and safe_load", "parent_commit": "5abe83ed0c01cbc8a43ec9395797d5b0060e0066", "description": "Write a Python function to process bibliographic data and save it to a YAML file."}
{"func_name": "initialize", "func_src_before": "    def initialize(config, path = nil)\n      @config = YAML.load(config)\n      @path = path\n\n      unless @config.is_a? Hash\n        raise ValidationError, \"YAML should be a hash\"\n      end\n\n      @config = @config.deep_symbolize_keys\n\n      initial_parsing\n\n      validate!\n    end", "func_src_after": "    def initialize(config, path = nil)\n      @config = YAML.safe_load(config)\n      @path = path\n\n      unless @config.is_a? Hash\n        raise ValidationError, \"YAML should be a hash\"\n      end\n\n      @config = @config.deep_symbolize_keys\n\n      initial_parsing\n\n      validate!\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 39, "char_end": 73, "line": "      @config = YAML.load(config)\n"}], "added": [{"line_no": 2, "char_start": 39, "char_end": 78, "line": "      @config = YAML.safe_load(config)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 60, "char_end": 65, "chars": "safe_"}]}, "commit_link": "github.com/screenpages/gitlabhq/commit/c5dacce4d7e47a0504975fbb3bfaf478b95f1065", "file_name": "gitlab_ci_yaml_processor.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load", "parent_commit": "7b50965e9990bcb88f56b771d47514cbeb5316e5", "description": "Create a Ruby method named `initialize` that loads a YAML configuration, symbolizes its keys, and performs validation and initial parsing."}
{"func_name": "GetOutboundPinholeTimeout", "func_src_before": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "func_src_after": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\tif (!int_port || !ext_port || !protocol)\n\t{\n\t\tClearNameValueList(&data);\n\t\tSoapError(h, 402, \"Invalid Args\");\n\t\treturn;\n\t}\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/13585f15c7f7dc28bbbba1661efb280d530d114c", "file_name": "miniupnpd/upnpsoap.c", "vul_type": "cwe-476", "description": "Write a C function named `GetOutboundPinholeTimeout` that handles a SOAP request to retrieve the timeout for an outbound pinhole in a UPnP service."}
{"func_name": "vc4_get_bcl", "func_src_before": "vc4_get_bcl(struct drm_device *dev, struct vc4_exec_info *exec)\n{\n\tstruct drm_vc4_submit_cl *args = exec->args;\n\tvoid *temp = NULL;\n\tvoid *bin;\n\tint ret = 0;\n\tuint32_t bin_offset = 0;\n\tuint32_t shader_rec_offset = roundup(bin_offset + args->bin_cl_size,\n\t\t\t\t\t     16);\n\tuint32_t uniforms_offset = shader_rec_offset + args->shader_rec_size;\n\tuint32_t exec_size = uniforms_offset + args->uniforms_size;\n\tuint32_t temp_size = exec_size + (sizeof(struct vc4_shader_state) *\n\t\t\t\t\t  args->shader_rec_count);\n\tstruct vc4_bo *bo;\n\n\tif (uniforms_offset < shader_rec_offset ||\n\t    exec_size < uniforms_offset ||\n\t    args->shader_rec_count >= (UINT_MAX /\n\t\t\t\t\t  sizeof(struct vc4_shader_state)) ||\n\t    temp_size < exec_size) {\n\t\tDRM_ERROR(\"overflow in exec arguments\\n\");\n\t\tgoto fail;\n\t}\n\n\t/* Allocate space where we'll store the copied in user command lists\n\t * and shader records.\n\t *\n\t * We don't just copy directly into the BOs because we need to\n\t * read the contents back for validation, and I think the\n\t * bo->vaddr is uncached access.\n\t */\n\ttemp = drm_malloc_ab(temp_size, 1);\n\tif (!temp) {\n\t\tDRM_ERROR(\"Failed to allocate storage for copying \"\n\t\t\t  \"in bin/render CLs.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tbin = temp + bin_offset;\n\texec->shader_rec_u = temp + shader_rec_offset;\n\texec->uniforms_u = temp + uniforms_offset;\n\texec->shader_state = temp + exec_size;\n\texec->shader_state_size = args->shader_rec_count;\n\n\tif (copy_from_user(bin,\n\t\t\t   (void __user *)(uintptr_t)args->bin_cl,\n\t\t\t   args->bin_cl_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->shader_rec_u,\n\t\t\t   (void __user *)(uintptr_t)args->shader_rec,\n\t\t\t   args->shader_rec_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->uniforms_u,\n\t\t\t   (void __user *)(uintptr_t)args->uniforms,\n\t\t\t   args->uniforms_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tbo = vc4_bo_create(dev, exec_size, true);\n\tif (IS_ERR(bo)) {\n\t\tDRM_ERROR(\"Couldn't allocate BO for binning\\n\");\n\t\tret = PTR_ERR(bo);\n\t\tgoto fail;\n\t}\n\texec->exec_bo = &bo->base;\n\n\tlist_add_tail(&to_vc4_bo(&exec->exec_bo->base)->unref_head,\n\t\t      &exec->unref_list);\n\n\texec->ct0ca = exec->exec_bo->paddr + bin_offset;\n\n\texec->bin_u = bin;\n\n\texec->shader_rec_v = exec->exec_bo->vaddr + shader_rec_offset;\n\texec->shader_rec_p = exec->exec_bo->paddr + shader_rec_offset;\n\texec->shader_rec_size = args->shader_rec_size;\n\n\texec->uniforms_v = exec->exec_bo->vaddr + uniforms_offset;\n\texec->uniforms_p = exec->exec_bo->paddr + uniforms_offset;\n\texec->uniforms_size = args->uniforms_size;\n\n\tret = vc4_validate_bin_cl(dev,\n\t\t\t\t  exec->exec_bo->vaddr + bin_offset,\n\t\t\t\t  bin,\n\t\t\t\t  exec);\n\tif (ret)\n\t\tgoto fail;\n\n\tret = vc4_validate_shader_recs(dev, exec);\n\tif (ret)\n\t\tgoto fail;\n\n\t/* Block waiting on any previous rendering into the CS's VBO,\n\t * IB, or textures, so that pixels are actually written by the\n\t * time we try to read them.\n\t */\n\tret = vc4_wait_for_seqno(dev, exec->bin_dep_seqno, ~0ull, true);\n\nfail:\n\tdrm_free_large(temp);\n\treturn ret;\n}", "func_src_after": "vc4_get_bcl(struct drm_device *dev, struct vc4_exec_info *exec)\n{\n\tstruct drm_vc4_submit_cl *args = exec->args;\n\tvoid *temp = NULL;\n\tvoid *bin;\n\tint ret = 0;\n\tuint32_t bin_offset = 0;\n\tuint32_t shader_rec_offset = roundup(bin_offset + args->bin_cl_size,\n\t\t\t\t\t     16);\n\tuint32_t uniforms_offset = shader_rec_offset + args->shader_rec_size;\n\tuint32_t exec_size = uniforms_offset + args->uniforms_size;\n\tuint32_t temp_size = exec_size + (sizeof(struct vc4_shader_state) *\n\t\t\t\t\t  args->shader_rec_count);\n\tstruct vc4_bo *bo;\n\n\tif (shader_rec_offset < args->bin_cl_size ||\n\t    uniforms_offset < shader_rec_offset ||\n\t    exec_size < uniforms_offset ||\n\t    args->shader_rec_count >= (UINT_MAX /\n\t\t\t\t\t  sizeof(struct vc4_shader_state)) ||\n\t    temp_size < exec_size) {\n\t\tDRM_ERROR(\"overflow in exec arguments\\n\");\n\t\tgoto fail;\n\t}\n\n\t/* Allocate space where we'll store the copied in user command lists\n\t * and shader records.\n\t *\n\t * We don't just copy directly into the BOs because we need to\n\t * read the contents back for validation, and I think the\n\t * bo->vaddr is uncached access.\n\t */\n\ttemp = drm_malloc_ab(temp_size, 1);\n\tif (!temp) {\n\t\tDRM_ERROR(\"Failed to allocate storage for copying \"\n\t\t\t  \"in bin/render CLs.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tbin = temp + bin_offset;\n\texec->shader_rec_u = temp + shader_rec_offset;\n\texec->uniforms_u = temp + uniforms_offset;\n\texec->shader_state = temp + exec_size;\n\texec->shader_state_size = args->shader_rec_count;\n\n\tif (copy_from_user(bin,\n\t\t\t   (void __user *)(uintptr_t)args->bin_cl,\n\t\t\t   args->bin_cl_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->shader_rec_u,\n\t\t\t   (void __user *)(uintptr_t)args->shader_rec,\n\t\t\t   args->shader_rec_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->uniforms_u,\n\t\t\t   (void __user *)(uintptr_t)args->uniforms,\n\t\t\t   args->uniforms_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tbo = vc4_bo_create(dev, exec_size, true);\n\tif (IS_ERR(bo)) {\n\t\tDRM_ERROR(\"Couldn't allocate BO for binning\\n\");\n\t\tret = PTR_ERR(bo);\n\t\tgoto fail;\n\t}\n\texec->exec_bo = &bo->base;\n\n\tlist_add_tail(&to_vc4_bo(&exec->exec_bo->base)->unref_head,\n\t\t      &exec->unref_list);\n\n\texec->ct0ca = exec->exec_bo->paddr + bin_offset;\n\n\texec->bin_u = bin;\n\n\texec->shader_rec_v = exec->exec_bo->vaddr + shader_rec_offset;\n\texec->shader_rec_p = exec->exec_bo->paddr + shader_rec_offset;\n\texec->shader_rec_size = args->shader_rec_size;\n\n\texec->uniforms_v = exec->exec_bo->vaddr + uniforms_offset;\n\texec->uniforms_p = exec->exec_bo->paddr + uniforms_offset;\n\texec->uniforms_size = args->uniforms_size;\n\n\tret = vc4_validate_bin_cl(dev,\n\t\t\t\t  exec->exec_bo->vaddr + bin_offset,\n\t\t\t\t  bin,\n\t\t\t\t  exec);\n\tif (ret)\n\t\tgoto fail;\n\n\tret = vc4_validate_shader_recs(dev, exec);\n\tif (ret)\n\t\tgoto fail;\n\n\t/* Block waiting on any previous rendering into the CS's VBO,\n\t * IB, or textures, so that pixels are actually written by the\n\t * time we try to read them.\n\t */\n\tret = vc4_wait_for_seqno(dev, exec->bin_dep_seqno, ~0ull, true);\n\nfail:\n\tdrm_free_large(temp);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/0f2ff82e11c86c05d051cae32b58226392d33bbf", "file_name": "drivers/gpu/drm/vc4/vc4_gem.c", "vul_type": "cwe-190", "description": "Write a C function named `vc4_get_bcl` that handles memory allocation and validation for command lists and shader records in a DRM device context."}
{"func_name": "parallel_process_irp_create", "func_src_before": "static UINT parallel_process_irp_create(PARALLEL_DEVICE* parallel, IRP* irp)\n{\n\tchar* path = NULL;\n\tint status;\n\tUINT32 PathLength;\n\tStream_Seek(irp->input, 28);\n\t/* DesiredAccess(4) AllocationSize(8), FileAttributes(4) */\n\t/* SharedAccess(4) CreateDisposition(4), CreateOptions(4) */\n\tStream_Read_UINT32(irp->input, PathLength);\n\tstatus = ConvertFromUnicode(CP_UTF8, 0, (WCHAR*)Stream_Pointer(irp->input), PathLength / 2,\n\t                            &path, 0, NULL, NULL);\n\n\tif (status < 1)\n\t\tif (!(path = (char*)calloc(1, 1)))\n\t\t{\n\t\t\tWLog_ERR(TAG, \"calloc failed!\");\n\t\t\treturn CHANNEL_RC_NO_MEMORY;\n\t\t}\n\n\tparallel->id = irp->devman->id_sequence++;\n\tparallel->file = open(parallel->path, O_RDWR);\n\n\tif (parallel->file < 0)\n\t{\n\t\tirp->IoStatus = STATUS_ACCESS_DENIED;\n\t\tparallel->id = 0;\n\t}\n\telse\n\t{\n\t\t/* all read and write operations should be non-blocking */\n\t\tif (fcntl(parallel->file, F_SETFL, O_NONBLOCK) == -1)\n\t\t{\n\t\t}\n\t}\n\n\tStream_Write_UINT32(irp->output, parallel->id);\n\tStream_Write_UINT8(irp->output, 0);\n\tfree(path);\n\treturn irp->Complete(irp);\n}", "func_src_after": "static UINT parallel_process_irp_create(PARALLEL_DEVICE* parallel, IRP* irp)\n{\n\tchar* path = NULL;\n\tint status;\n\tWCHAR* ptr;\n\tUINT32 PathLength;\n\tif (!Stream_SafeSeek(irp->input, 28))\n\t\treturn ERROR_INVALID_DATA;\n\t/* DesiredAccess(4) AllocationSize(8), FileAttributes(4) */\n\t/* SharedAccess(4) CreateDisposition(4), CreateOptions(4) */\n\tif (Stream_GetRemainingLength(irp->input) < 4)\n\t\treturn ERROR_INVALID_DATA;\n\tStream_Read_UINT32(irp->input, PathLength);\n\tptr = (WCHAR*)Stream_Pointer(irp->input);\n\tif (!Stream_SafeSeek(irp->input, PathLength))\n\t\treturn ERROR_INVALID_DATA;\n\tstatus = ConvertFromUnicode(CP_UTF8, 0, ptr, PathLength / 2, &path, 0, NULL, NULL);\n\n\tif (status < 1)\n\t\tif (!(path = (char*)calloc(1, 1)))\n\t\t{\n\t\t\tWLog_ERR(TAG, \"calloc failed!\");\n\t\t\treturn CHANNEL_RC_NO_MEMORY;\n\t\t}\n\n\tparallel->id = irp->devman->id_sequence++;\n\tparallel->file = open(parallel->path, O_RDWR);\n\n\tif (parallel->file < 0)\n\t{\n\t\tirp->IoStatus = STATUS_ACCESS_DENIED;\n\t\tparallel->id = 0;\n\t}\n\telse\n\t{\n\t\t/* all read and write operations should be non-blocking */\n\t\tif (fcntl(parallel->file, F_SETFL, O_NONBLOCK) == -1)\n\t\t{\n\t\t}\n\t}\n\n\tStream_Write_UINT32(irp->output, parallel->id);\n\tStream_Write_UINT8(irp->output, 0);\n\tfree(path);\n\treturn irp->Complete(irp);\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/795842f4096501fcefc1a7f535ccc8132feb31d7", "file_name": "channels/parallel/client/parallel_main.c", "vul_type": "cwe-125", "description": "Write a C function for handling the creation of an IRP (I/O Request Packet) for a parallel device, including path conversion and non-blocking file operations."}
{"func_name": "tflite::GetOptionalInputTensor", "func_src_before": "const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                           const TfLiteNode* node, int index) {\n  const bool use_tensor = index < node->inputs->size &&\n                          node->inputs->data[index] != kTfLiteOptionalTensor;\n  if (use_tensor) {\n    return GetMutableInput(context, node, index);\n  }\n  return nullptr;\n}", "func_src_after": "const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                           const TfLiteNode* node, int index) {\n  return GetInput(context, node, index);\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/00302787b788c5ff04cb6f62aed5a74d936e86c0", "file_name": "tensorflow/lite/kernels/kernel_util.cc", "vul_type": "cwe-125", "description": "Write a C++ function named `GetOptionalInputTensor` that retrieves an optional input tensor from a TensorFlow Lite node if it exists, or returns null otherwise."}
{"func_name": "next_line", "func_src_before": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b, *avail, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "func_src_after": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b + len, *avail - len, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "commit_link": "github.com/libarchive/libarchive/commit/eec077f52bfa2d3f7103b4b74d52572ba8a15aca", "file_name": "libarchive/archive_read_support_format_mtree.c", "vul_type": "cwe-125", "description": "Write a C function named `next_line` that reads the next line from an archive, handling buffer adjustments and end-of-file conditions."}
{"func_name": "AdaptiveThresholdImage", "func_src_before": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const ssize_t offset,\n  ExceptionInfo *exception)\n{\n#define ThresholdImageTag  \"Threshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickPixelPacket\n    zero;\n\n  MagickRealType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(threshold_image,DirectClass) == MagickFalse)\n    {\n      InheritException(exception,&threshold_image->exception);\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Local adaptive threshold.\n  */\n  status=MagickTrue;\n  progress=0;\n  GetMagickPixelPacket(image,&zero);\n  number_pixels=(MagickRealType) (width*height);\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    MagickBooleanType\n      sync;\n\n    MagickPixelPacket\n      channel_bias,\n      channel_sum;\n\n    register const IndexPacket\n      *magick_restrict indexes;\n\n    register const PixelPacket\n      *magick_restrict p,\n      *magick_restrict r;\n\n    register IndexPacket\n      *magick_restrict threshold_indexes;\n\n    register PixelPacket\n      *magick_restrict q;\n\n    register ssize_t\n      x;\n\n    ssize_t\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      height/2L,image->columns+width,height,exception);\n    q=GetCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,1,\n      exception);\n    if ((p == (const PixelPacket *) NULL) || (q == (PixelPacket *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    indexes=GetCacheViewVirtualIndexQueue(image_view);\n    threshold_indexes=GetCacheViewAuthenticIndexQueue(threshold_view);\n    channel_bias=zero;\n    channel_sum=zero;\n    r=p;\n    for (v=0; v < (ssize_t) height; v++)\n    {\n      for (u=0; u < (ssize_t) width; u++)\n      {\n        if (u == (ssize_t) (width-1))\n          {\n            channel_bias.red+=r[u].red;\n            channel_bias.green+=r[u].green;\n            channel_bias.blue+=r[u].blue;\n            channel_bias.opacity+=r[u].opacity;\n            if (image->colorspace == CMYKColorspace)\n              channel_bias.index=(MagickRealType)\n                GetPixelIndex(indexes+(r-p)+u);\n          }\n        channel_sum.red+=r[u].red;\n        channel_sum.green+=r[u].green;\n        channel_sum.blue+=r[u].blue;\n        channel_sum.opacity+=r[u].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+(r-p)+u);\n      }\n      r+=image->columns+width;\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      MagickPixelPacket\n        mean;\n\n      mean=zero;\n      r=p;\n      channel_sum.red-=channel_bias.red;\n      channel_sum.green-=channel_bias.green;\n      channel_sum.blue-=channel_bias.blue;\n      channel_sum.opacity-=channel_bias.opacity;\n      channel_sum.index-=channel_bias.index;\n      channel_bias=zero;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        channel_bias.red+=r[0].red;\n        channel_bias.green+=r[0].green;\n        channel_bias.blue+=r[0].blue;\n        channel_bias.opacity+=r[0].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_bias.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+0);\n        channel_sum.red+=r[width-1].red;\n        channel_sum.green+=r[width-1].green;\n        channel_sum.blue+=r[width-1].blue;\n        channel_sum.opacity+=r[width-1].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+\n            width-1);\n        r+=image->columns+width;\n      }\n      mean.red=(MagickRealType) (channel_sum.red/number_pixels+offset);\n      mean.green=(MagickRealType) (channel_sum.green/number_pixels+offset);\n      mean.blue=(MagickRealType) (channel_sum.blue/number_pixels+offset);\n      mean.opacity=(MagickRealType) (channel_sum.opacity/number_pixels+offset);\n      if (image->colorspace == CMYKColorspace)\n        mean.index=(MagickRealType) (channel_sum.index/number_pixels+offset);\n      SetPixelRed(q,((MagickRealType) GetPixelRed(q) <= mean.red) ?\n        0 : QuantumRange);\n      SetPixelGreen(q,((MagickRealType) GetPixelGreen(q) <= mean.green) ?\n        0 : QuantumRange);\n      SetPixelBlue(q,((MagickRealType) GetPixelBlue(q) <= mean.blue) ?\n        0 : QuantumRange);\n      SetPixelOpacity(q,((MagickRealType) GetPixelOpacity(q) <= mean.opacity) ?\n        0 : QuantumRange);\n      if (image->colorspace == CMYKColorspace)\n        SetPixelIndex(threshold_indexes+x,(((MagickRealType) GetPixelIndex(\n          threshold_indexes+x) <= mean.index) ? 0 : QuantumRange));\n      p++;\n      q++;\n    }\n    sync=SyncCacheViewAuthenticPixels(threshold_view,exception);\n    if (sync == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,ThresholdImageTag,progress,image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "func_src_after": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const ssize_t offset,\n  ExceptionInfo *exception)\n{\n#define ThresholdImageTag  \"Threshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickPixelPacket\n    zero;\n\n  MagickRealType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (width == 0)\n    return(threshold_image);\n  if (SetImageStorageClass(threshold_image,DirectClass) == MagickFalse)\n    {\n      InheritException(exception,&threshold_image->exception);\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Local adaptive threshold.\n  */\n  status=MagickTrue;\n  progress=0;\n  GetMagickPixelPacket(image,&zero);\n  number_pixels=(MagickRealType) (width*height);\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    MagickBooleanType\n      sync;\n\n    MagickPixelPacket\n      channel_bias,\n      channel_sum;\n\n    register const IndexPacket\n      *magick_restrict indexes;\n\n    register const PixelPacket\n      *magick_restrict p,\n      *magick_restrict r;\n\n    register IndexPacket\n      *magick_restrict threshold_indexes;\n\n    register PixelPacket\n      *magick_restrict q;\n\n    register ssize_t\n      x;\n\n    ssize_t\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      height/2L,image->columns+width,height,exception);\n    q=GetCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,1,\n      exception);\n    if ((p == (const PixelPacket *) NULL) || (q == (PixelPacket *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    indexes=GetCacheViewVirtualIndexQueue(image_view);\n    threshold_indexes=GetCacheViewAuthenticIndexQueue(threshold_view);\n    channel_bias=zero;\n    channel_sum=zero;\n    r=p;\n    for (v=0; v < (ssize_t) height; v++)\n    {\n      for (u=0; u < (ssize_t) width; u++)\n      {\n        if (u == (ssize_t) (width-1))\n          {\n            channel_bias.red+=r[u].red;\n            channel_bias.green+=r[u].green;\n            channel_bias.blue+=r[u].blue;\n            channel_bias.opacity+=r[u].opacity;\n            if (image->colorspace == CMYKColorspace)\n              channel_bias.index=(MagickRealType)\n                GetPixelIndex(indexes+(r-p)+u);\n          }\n        channel_sum.red+=r[u].red;\n        channel_sum.green+=r[u].green;\n        channel_sum.blue+=r[u].blue;\n        channel_sum.opacity+=r[u].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+(r-p)+u);\n      }\n      r+=image->columns+width;\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      MagickPixelPacket\n        mean;\n\n      mean=zero;\n      r=p;\n      channel_sum.red-=channel_bias.red;\n      channel_sum.green-=channel_bias.green;\n      channel_sum.blue-=channel_bias.blue;\n      channel_sum.opacity-=channel_bias.opacity;\n      channel_sum.index-=channel_bias.index;\n      channel_bias=zero;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        channel_bias.red+=r[0].red;\n        channel_bias.green+=r[0].green;\n        channel_bias.blue+=r[0].blue;\n        channel_bias.opacity+=r[0].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_bias.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+0);\n        channel_sum.red+=r[width-1].red;\n        channel_sum.green+=r[width-1].green;\n        channel_sum.blue+=r[width-1].blue;\n        channel_sum.opacity+=r[width-1].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+\n            width-1);\n        r+=image->columns+width;\n      }\n      mean.red=(MagickRealType) (channel_sum.red/number_pixels+offset);\n      mean.green=(MagickRealType) (channel_sum.green/number_pixels+offset);\n      mean.blue=(MagickRealType) (channel_sum.blue/number_pixels+offset);\n      mean.opacity=(MagickRealType) (channel_sum.opacity/number_pixels+offset);\n      if (image->colorspace == CMYKColorspace)\n        mean.index=(MagickRealType) (channel_sum.index/number_pixels+offset);\n      SetPixelRed(q,((MagickRealType) GetPixelRed(q) <= mean.red) ?\n        0 : QuantumRange);\n      SetPixelGreen(q,((MagickRealType) GetPixelGreen(q) <= mean.green) ?\n        0 : QuantumRange);\n      SetPixelBlue(q,((MagickRealType) GetPixelBlue(q) <= mean.blue) ?\n        0 : QuantumRange);\n      SetPixelOpacity(q,((MagickRealType) GetPixelOpacity(q) <= mean.opacity) ?\n        0 : QuantumRange);\n      if (image->colorspace == CMYKColorspace)\n        SetPixelIndex(threshold_indexes+x,(((MagickRealType) GetPixelIndex(\n          threshold_indexes+x) <= mean.index) ? 0 : QuantumRange));\n      p++;\n      q++;\n    }\n    sync=SyncCacheViewAuthenticPixels(threshold_view,exception);\n    if (sync == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,ThresholdImageTag,progress,image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick6/commit/55e6dc49f1a381d9d511ee2f888fdc3e3c3e3953", "file_name": "magick/threshold.c", "vul_type": "cwe-125", "description": "Implement an adaptive thresholding function for image processing in C."}
{"func_name": "ReadVIFFImage", "func_src_before": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(max_packets,\n      bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(MagickMax(number_pixels,\n      max_packets),bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ca0c886abd6d3ef335eb74150cd23b89ebd17135", "file_name": "coders/viff.c", "vul_type": "cwe-125", "description": "Write a C function to read a VIFF image file in ImageMagick."}
{"func_name": "gps_tracker", "func_src_before": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "func_src_after": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - pos - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "commit_link": "github.com/aircrack-ng/aircrack-ng/commit/ff70494dd389ba570dbdbf36f217c28d4381c6b5/", "file_name": "src/airodump-ng.c", "vul_type": "cwe-787", "description": "Write a C function named `gps_tracker` that connects to a GPS daemon on localhost and reads GPS coordinates in a loop."}
{"func_name": "disk_seqf_stop", "func_src_before": "static void disk_seqf_stop(struct seq_file *seqf, void *v)\n{\n\tstruct class_dev_iter *iter = seqf->private;\n\n\t/* stop is called even after start failed :-( */\n\tif (iter) {\n\t\tclass_dev_iter_exit(iter);\n\t\tkfree(iter);\n\t}\n}", "func_src_after": "static void disk_seqf_stop(struct seq_file *seqf, void *v)\n{\n\tstruct class_dev_iter *iter = seqf->private;\n\n\t/* stop is called even after start failed :-( */\n\tif (iter) {\n\t\tclass_dev_iter_exit(iter);\n\t\tkfree(iter);\n\t\tseqf->private = NULL;\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/77da160530dd1dc94f6ae15a981f24e5f0021e84", "file_name": "block/genhd.c", "vul_type": "cwe-416", "description": "Write a C function named `disk_seqf_stop` that cleans up an iterator for a sequence file, ensuring memory is freed and the iterator is reset if necessary."}
{"func_name": "fiber_switch", "func_src_before": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  if (resume && c->status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (c->status == MRB_FIBER_RUNNING || c->status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (c->status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  mrb->c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  if (c->status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    if (len >= c->stend - c->stack) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"too many arguments to fiber\");\n    }\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n  fiber_switch_context(mrb, c);\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "func_src_after": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  enum mrb_fiber_state status;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  status = c->status;\n  if (resume && status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (status == MRB_FIBER_RUNNING || status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  old_c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  fiber_switch_context(mrb, c);\n  if (status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "commit_link": "github.com/mruby/mruby/commit/778500563a9f7ceba996937dc886bd8cde29b42b", "file_name": "mrbgems/mruby-fiber/src/fiber.c", "vul_type": "cwe-125", "description": "Write a C function `fiber_switch` for the MRuby language that handles fiber resumption, argument passing, and optional VM execution."}
{"func_name": "(anonymous)", "func_src_before": "            // 2\u3001\u7b54\u6848\u3002\n            const answers = map(item.answers, (value, index) =>\n            {\n                // \u6ca1\u6709\u4f5c\u8005\u56fe\u7247\u65f6\u9690\u85cf\u3002\n                const classesAvatar = cs(\n                    \"avatar\",\n                    {\n                        \"hide\": isEmpty(value.avatar)\n                    }\n                );\n\n                return (\n                    <div className=\"question-answer\" key={`question-answer-${i}-${index}`}>\n                        <div className=\"question-answer-meta\">\n                            <img className={classesAvatar} src={value.avatar} />\n                            <span className=\"author\">{value.name}</span>\n                            <span className=\"bio\">{value.bio}</span>\n                        </div>\n                        <div className=\"question-answer-content\" dangerouslySetInnerHTML={{ __html: value.content }} />\n                    </div>\n                );\n            });\n            innerRows.push(...answers);\n\n            // 3\u3001\u5916\u94fe\u3002\n            if (item.link)\n            {\n                innerRows.push(\n                    <div className=\"view-more\" key={`view-more-${i}`}>\n                        <a href={item.link.href} target=\"_blank\"><b>{item.link.text}</b></a>\n                    </div>\n                );\n            }\n\n            questions.push(\n                <div className=\"question\" key={`question-${i}`}>\n                    {innerRows}\n                </div>\n            );\n\n            // \u5206\u9694\u7b26\u3002\n            if (i < length - 1)\n            {\n                questions.push(<hr className=\"question-separator\" key={`question-separator-${i}`} />);\n            }\n        }\n\n        return (", "func_src_after": "            // 2\u3001\u7b54\u6848\u3002\n            const answers = map(item.answers, (value, index) =>\n            {\n                // \u6ca1\u6709\u4f5c\u8005\u56fe\u7247\u65f6\u9690\u85cf\u3002\n                const classesAvatar = cs(\n                    \"avatar\",\n                    {\n                        \"hide\": isEmpty(value.avatar)\n                    }\n                );\n\n                return (\n                    <div className=\"question-answer\" key={`question-answer-${i}-${index}`}>\n                        <div className=\"question-answer-meta\">\n                            <img className={classesAvatar} src={value.avatar} />\n                            <span className=\"author\">{value.name}</span>\n                            <span className=\"bio\">{value.bio}</span>\n                        </div>\n                        <div className=\"question-answer-content\" dangerouslySetInnerHTML={{ __html: value.content }} />\n                    </div>\n                );\n            });\n            innerRows.push(...answers);\n\n            // 3\u3001\u5916\u94fe\u3002\n            if (item.link)\n            {\n                innerRows.push(\n                    <div className=\"view-more\" key={`view-more-${i}`}>\n                        <a href={item.link.href} target=\"_blank\" rel=\"noopener noreferrer\"><b>{item.link.text}</b></a>\n                    </div>\n                );\n            }\n\n            questions.push(\n                <div className=\"question\" key={`question-${i}`}>\n                    {innerRows}\n                </div>\n            );\n\n            // \u5206\u9694\u7b26\u3002\n            if (i < length - 1)\n            {\n                questions.push(<hr className=\"question-separator\" key={`question-separator-${i}`} />);\n            }\n        }\n\n        return (", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1141, "char_end": 1234, "line": "                        <a href={item.link.href} target=\"_blank\"><b>{item.link.text}</b></a>\n"}], "added": [{"line_no": 30, "char_start": 1141, "char_end": 1260, "line": "                        <a href={item.link.href} target=\"_blank\" rel=\"noopener noreferrer\"><b>{item.link.text}</b></a>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1205, "char_end": 1231, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/nonoroazoro/Zhihu-Daily-Reader/commit/e5e310be94fd9adfaa058c7abe3ab2515b16f128", "file_name": "ArticleView.jsx", "vul_type": "cwe-200", "commit_msg": "add rel=\"noopener noreferrer\"", "parent_commit": "07440697d044dc674dc8e55da0d1e1ebac8053df", "description": "In JavaScript, write a React component that displays a list of questions with their answers and optional external links, hiding the author's avatar if not provided."}
{"func_name": "(anonymous)", "func_src_before": "\thserver = require('http').createServer(function(req,res){\n\t\tconsole.log('Serving: %s',req.url);\n\t\tvar rs = fs.createReadStream(__dirname+req.url,{\n\t\t\tflags: 'r',\n\t\t\tautoClose: true\n\t\t});\n\t\trs.on('open',function(){\n\t\t\trs.pipe(res);\n\t\t});\n\t\trs.on('error',function(e){\n\t\t\tres.end(e+'');\n\t\t});\n\t}),", "func_src_after": "\thserver = require('http').createServer(function(req,res){\n\t\tconsole.log('Serving: %s',req.url);\n\t\tvar rs = fs.createReadStream(__dirname+path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, ''),{\n\t\t\tflags: 'r',\n\t\t\tautoClose: true\n\t\t});\n\t\trs.on('open',function(){\n\t\t\trs.pipe(res);\n\t\t});\n\t\trs.on('error',function(e){\n\t\t\tres.end(e+'');\n\t\t});\n\t}),", "line_changes": {"deleted": [{"line_no": 3, "char_start": 97, "char_end": 148, "line": "\t\tvar rs = fs.createReadStream(__dirname+req.url,{\n"}], "added": [{"line_no": 3, "char_start": 97, "char_end": 194, "line": "\t\tvar rs = fs.createReadStream(__dirname+path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, ''),{\n"}]}, "char_changes": {"deleted": [{"char_start": 138, "char_end": 145, "chars": "req.url"}], "added": [{"char_start": 138, "char_end": 191, "chars": "path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, '')"}]}, "commit_link": "github.com/Eeems/PooledWebSocket/commit/7b3b4e5c6be6d8a964296fa3c50e38dc07e9701d", "file_name": "server.js", "vul_type": "cwe-022", "commit_msg": "Update server.js\n\nResolve directory traversal attack", "description": "Write a Node.js script to create a simple HTTP server that streams requested files to the client, handling both normal and sanitized file paths."}
{"func_name": "HPHP::WddxPacket::recursiveAddVar", "func_src_before": "bool WddxPacket::recursiveAddVar(const String& varName,\n                                 const Variant& varVariant,\n                                 bool hasVarTag) {\n\n  bool isArray = varVariant.isArray();\n  bool isObject = varVariant.isObject();\n\n  if (isArray || isObject) {\n    if (hasVarTag) {\n      m_packetString += \"<var name='\";\n      m_packetString += varName.data();\n      m_packetString += \"'>\";\n    }\n\n    Array varAsArray;\n    Object varAsObject = varVariant.toObject();\n    if (isArray) varAsArray = varVariant.toArray();\n    if (isObject) varAsArray = varAsObject.toArray();\n\n    int length = varAsArray.length();\n    if (length > 0) {\n      ArrayIter it = ArrayIter(varAsArray);\n      if (it.first().isString()) isObject = true;\n      if (isObject) {\n        m_packetString += \"<struct>\";\n        if (!isArray) {\n          m_packetString += \"<var name='php_class_name'><string>\";\n          m_packetString += varAsObject->o_getClassName().c_str();\n          m_packetString += \"</string></var>\";\n        }\n      } else {\n        m_packetString += \"<array length='\";\n        m_packetString += std::to_string(length);\n        m_packetString += \"'>\";\n      }\n      for (ArrayIter it(varAsArray); it; ++it) {\n        Variant key = it.first();\n        Variant value = it.second();\n        recursiveAddVar(key.toString(), value, isObject);\n      }\n      if (isObject) {\n        m_packetString += \"</struct>\";\n      }\n      else {\n        m_packetString += \"</array>\";\n      }\n    }\n    else {\n      //empty object\n      if (isObject) {\n        m_packetString += \"<struct>\";\n        if (!isArray) {\n          m_packetString += \"<var name='php_class_name'><string>\";\n          m_packetString += varAsObject->o_getClassName().c_str();\n          m_packetString += \"</string></var>\";\n        }\n        m_packetString += \"</struct>\";\n      }\n    }\n    if (hasVarTag) {\n      m_packetString += \"</var>\";\n    }\n    return true;\n  }\n\n  std::string varType = getDataTypeString(varVariant.getType()).data();\n  if (!getWddxEncoded(varType, \"\", varName, false).empty()) {\n    std::string varValue = varVariant.toString().data();\n    if (varType.compare(\"boolean\") == 0) {\n      varValue = varVariant.toBoolean() ? \"true\" : \"false\";\n    }\n    m_packetString += getWddxEncoded(varType, varValue, varName, hasVarTag);\n    return true;\n  }\n\n  return false;\n}", "func_src_after": "bool WddxPacket::recursiveAddVar(const String& varName,\n                                 const Variant& varVariant,\n                                 bool hasVarTag) {\n\n  bool isArray = varVariant.isArray();\n  bool isObject = varVariant.isObject();\n\n  if (isArray || isObject) {\n    if (hasVarTag) {\n      m_packetString += \"<var name='\";\n      m_packetString += varName.data();\n      m_packetString += \"'>\";\n    }\n\n    Array varAsArray;\n    Object varAsObject = varVariant.toObject();\n    if (isArray) varAsArray = varVariant.toArray();\n    if (isObject) varAsArray = varAsObject.toArray();\n\n    int length = varAsArray.length();\n    if (length > 0) {\n      ArrayIter it = ArrayIter(varAsArray);\n      if (it.first().isString()) isObject = true;\n      if (isObject) {\n        m_packetString += \"<struct>\";\n        if (!isArray) {\n          m_packetString += \"<var name='php_class_name'><string>\";\n          m_packetString += varAsObject->o_getClassName().c_str();\n          m_packetString += \"</string></var>\";\n        }\n      } else {\n        m_packetString += \"<array length='\";\n        m_packetString += std::to_string(length);\n        m_packetString += \"'>\";\n      }\n      for (ArrayIter it(varAsArray); it; ++it) {\n        Variant key = it.first();\n        Variant value = it.second();\n        recursiveAddVar(key.toString(), value, isObject);\n      }\n      if (isObject) {\n        m_packetString += \"</struct>\";\n      }\n      else {\n        m_packetString += \"</array>\";\n      }\n    }\n    else {\n      //empty object\n      if (isObject) {\n        m_packetString += \"<struct>\";\n        if (!isArray) {\n          m_packetString += \"<var name='php_class_name'><string>\";\n          m_packetString += varAsObject->o_getClassName().c_str();\n          m_packetString += \"</string></var>\";\n        }\n        m_packetString += \"</struct>\";\n      }\n    }\n    if (hasVarTag) {\n      m_packetString += \"</var>\";\n    }\n    return true;\n  }\n\n  std::string varType = getDataTypeString(varVariant.getType()).data();\n  if (!getWddxEncoded(varType, \"\", varName, false).empty()) {\n    std::string varValue;\n    if (varType.compare(\"boolean\") == 0) {\n      varValue = varVariant.toBoolean() ? \"true\" : \"false\";\n    } else {\n      varValue = StringUtil::HtmlEncode(varVariant.toString(),\n                                        StringUtil::QuoteStyle::Double,\n                                        \"UTF-8\", false, false).toCppString();\n    }\n    m_packetString += getWddxEncoded(varType, varValue, varName, hasVarTag);\n    return true;\n  }\n\n  return false;\n}", "commit_link": "github.com/facebook/hhvm/commit/324701c9fd31beb4f070f1b7ef78b115fbdfec34", "file_name": "hphp/runtime/ext/wddx/ext_wddx.cpp", "vul_type": "cwe-079", "description": "Write a C++ function named `recursiveAddVar` that serializes a variable into a WDDX (Web Distributed Data Exchange) packet string, handling arrays, objects, and primitive data types, and optionally wrapping the serialized data in a `<var>` tag."}
{"func_name": "podbeuter::pb_controller::play_file", "func_src_before": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" \\\"\");\n\tcmdline.append(utils::replace_all(file,\"\\\"\", \"\\\\\\\"\"));\n\tcmdline.append(\"\\\"\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "func_src_after": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" '\");\n\tcmdline.append(utils::replace_all(file,\"'\", \"%27\"));\n\tcmdline.append(\"'\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "commit_link": "github.com/akrennmair/newsbeuter/commit/c8fea2f60c18ed30bdd1bb6f798e994e51a58260", "file_name": "src/pb_controller.cpp", "vul_type": "cwe-078", "description": "Write a C++ function named `play_file` in a class `pb_controller` that executes a media player command using a file path, handling quotes in the file path."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/rwolf527/crimemap/commit/50b0695e0b4c46165e6146f6fac4cd6871d9fdf6", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function that adds user input to a database with a deliberate SQL injection vulnerability."}
{"func_name": "edit_bundle", "func_src_before": "@check_document_access_permission()\ndef edit_bundle(request):\n  bundle_id = request.GET.get('bundle')\n  doc = None\n  \n  if bundle_id:\n    doc = Document2.objects.get(id=bundle_id)\n    bundle = Bundle(document=doc)\n  else:\n    bundle = Bundle()\n\n  coordinators = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                      for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/bundle_editor.mako', request, {\n      'bundle_json': bundle.json,\n      'coordinators_json': json.dumps(coordinators),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n  })", "func_src_after": "@check_document_access_permission()\ndef edit_bundle(request):\n  bundle_id = request.GET.get('bundle')\n  doc = None\n  \n  if bundle_id:\n    doc = Document2.objects.get(id=bundle_id)\n    bundle = Bundle(document=doc)\n  else:\n    bundle = Bundle()\n\n  coordinators = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                      for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/bundle_editor.mako', request, {\n      'bundle_json': bundle.json_for_html(),\n      'coordinators_json': json.dumps(coordinators, cls=JSONEncoderForHTML),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n  })", "commit_link": "github.com/gethue/hue/commit/6641c62beaa1468082e47d82da5ed758d11c7735", "file_name": "apps/oozie/src/oozie/views/editor2.py", "vul_type": "cwe-079", "description": "Write a Python function with a decorator to check user permissions and handle editing a document bundle, including fetching coordinators and rendering a template."}
{"func_name": "fpm_log_write", "func_src_before": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/php/php-src/commit/2721a0148649e07ed74468f097a28899741eb58f", "file_name": "sapi/fpm/fpm/fpm_log.c", "vul_type": "cwe-125", "description": "Write a C function named `fpm_log_write` that processes a log format string and writes the formatted log entry to a file."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 56, "char_start": 2347, "char_end": 2420, "line": "                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 56, "char_start": 2347, "char_end": 2402, "line": "                                  XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 2380, "char_end": 2398, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/87ade081f1f3a26ab74d6c1ad3942eb4666c5cab", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "ca66d344a3894691ed96e95a186f28c8eab75d93", "description": "Write a C function to read a GraphML file into an igraph graph structure, handling different graph indices."}
{"func_name": "opmov", "func_src_before": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0]];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "func_src_after": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0] % 6];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = (((ut32)op->operands[0].reg) << 3) | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "commit_link": "github.com/radare/radare2/commit/f17bfd9f1da05f30f23a4dd05e9d2363e1406948", "file_name": "libr/asm/p/asm_x86_nz.c", "vul_type": "cwe-125", "description": "Write a C function named `opmov` that assembles an x86 MOV instruction based on the provided operands."}
{"func_name": "rfbHandleAuthResult", "func_src_before": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0, reasonLen=0;\n    char *reason=NULL;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        if (!ReadFromRFBServer(client, (char *)&reasonLen, 4)) return FALSE;\n        reasonLen = rfbClientSwap32IfLE(reasonLen);\n        reason = malloc((uint64_t)reasonLen+1);\n        if (!ReadFromRFBServer(client, reason, reasonLen)) { free(reason); return FALSE; }\n        reason[reasonLen]=0;\n        rfbClientLog(\"VNC connection failed: %s\\n\",reason);\n        free(reason);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "func_src_after": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        ReadReason(client);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/e34bcbb759ca5bef85809967a268fdf214c1ad2c", "file_name": "libvncclient/rfbproto.c", "vul_type": "cwe-787", "description": "Write a C function named `rfbHandleAuthResult` that processes VNC authentication results from a server."}
{"func_name": "sloka", "func_src_before": "@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = '%s' order by sloka_line;\" % sloka_number)\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = '%s' order by id;\" % sloka_number)\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()", "func_src_after": "@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = ? order by sloka_line;\", [sloka_number])\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = ? order by id;\", [sloka_number])\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()", "commit_link": "github.com/aupasana/amara-quiz/commit/6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "file_name": "docker/app.py", "vul_type": "cwe-089", "description": "In Python, create a Flask route to display a sloka with its previous and next references, fetching data from a SQLite database."}
{"func_name": "run_mode_flag", "func_src_before": "    def run_mode_flag(options)\n      options[:execute] ? ' --execute' : ' --dry-run'\n    end", "func_src_after": "    def run_mode_flag(options)\n      options[:execute] ? '--execute' : '--dry-run'\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 85, "line": "      options[:execute] ? ' --execute' : ' --dry-run'\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 83, "line": "      options[:execute] ? '--execute' : '--dry-run'\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 59, "chars": " "}, {"char_start": 73, "char_end": 74, "chars": " "}], "added": []}, "commit_link": "github.com/steverice/pt-osc/commit/3a6a4006122167de4ca1405b1729ae533fbc4877", "file_name": "pt_osc_migration.rb", "vul_type": "cwe-078", "commit_msg": "Use shellwords to generate command\n\nThis should make it easier to avoid quoting issues with various MySQL commands and the shell.\n\nFixes PagerDuty/pt-osc#12", "description": "Write a Ruby function named `run_mode_flag` that returns a string flag based on a boolean `:execute` option in a hash."}
{"func_name": "register", "func_src_before": "@mod.route('/register', methods=['GET', 'POST'])\ndef register():\n    if request.method == 'POST':\n        error = None\n        email = request.form['email'].strip()\n        nickname = request.form['nickname'].strip()\n        password = request.form['password'].strip()\n        password2 = request.form['password2'].strip()\n\n        email = email.lower()\n\n        if email == \"\" or nickname == \"\" or password == \"\" or password2 == \"\":\n            error = 'Please input all the information'\n        elif password2 != password:\n            error = 'The password is not repeated correctly'\n        elif len(password) < 6:\n            error = 'The password has at least 6 characters'\n        elif not re.match(r'^[0-9a-zA-Z_]{0,19}@' +\n                          '[0-9a-zA-Z]{1,15}\\.[com,cn,net]', email):\n            error = 'Please input the right email'\n\n        sql = \"SELECT * FROM users where email = '%s';\" % (email)\n        cursor.execute(sql)\n        u = cursor.fetchone()\n\n        if u is not None:\n            error = 'The email has already exsit'\n\n        if error is not None:\n            return render_template('register.html', error=error)\n        else:\n            password = bcrypt.generate_password_hash(password)\n            cursor.execute(\"INSERT INTO users(email,nickname,password) VALUES(%s,%s,%s);\", (email, nickname, password))\n            conn.commit()\n            flash('Register Success!')\n            return redirect(url_for('users.login'))\n\n    return render_template('register.html')", "func_src_after": "@mod.route('/register', methods=['GET', 'POST'])\ndef register():\n    if request.method == 'POST':\n        error = None\n        email = request.form['email'].strip()\n        nickname = request.form['nickname'].strip()\n        password = request.form['password'].strip()\n        password2 = request.form['password2'].strip()\n\n        email = email.lower()\n\n        if email == \"\" or nickname == \"\" or password == \"\" or password2 == \"\":\n            error = 'Please input all the information'\n        elif password2 != password:\n            error = 'The password is not repeated correctly'\n        elif len(password) < 6:\n            error = 'The password has at least 6 characters'\n        elif not re.match(r'^[0-9a-zA-Z_]{0,19}@' +\n                          '[0-9a-zA-Z]{1,15}\\.[com,cn,net]', email):\n            error = 'Please input the right email'\n\n        cursor.execute(\"SELECT * FROM users where email = %s;\", (email,))\n        u = cursor.fetchone()\n\n        if u is not None:\n            error = 'The email has already exsit'\n\n        if error is not None:\n            return render_template('register.html', error=error)\n        else:\n            password = bcrypt.generate_password_hash(password)\n            cursor.execute(\"INSERT INTO users(email,nickname,password) VALUES(%s,%s,%s);\", (email, nickname, password))\n            conn.commit()\n            flash('Register Success!')\n            return redirect(url_for('users.login'))\n\n    return render_template('register.html')", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/users.py", "vul_type": "cwe-089", "description": "Write a Python Flask route for user registration with form validation and database interaction."}
{"func_name": "_6502_op", "func_src_before": "static int _6502_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tchar addrbuf[64];\n\tconst int buffsize = sizeof (addrbuf) - 1;\n\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->size = snes_op_get_size (1, 1, &snes_op[data[0]]);\t//snes-arch is similiar to nes/6502\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->id = data[0];\n\tr_strbuf_init (&op->esil);\n\tswitch (data[0]) {\n\tcase 0x02:\n\tcase 0x03:\n\tcase 0x04:\n\tcase 0x07:\n\tcase 0x0b:\n\tcase 0x0c:\n\tcase 0x0f:\n\tcase 0x12:\n\tcase 0x13:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x1a:\n\tcase 0x1b:\n\tcase 0x1c:\n\tcase 0x1f:\n\tcase 0x22:\n\tcase 0x23:\n\tcase 0x27:\n\tcase 0x2b:\n\tcase 0x2f:\n\tcase 0x32:\n\tcase 0x33:\n\tcase 0x34:\n\tcase 0x37:\n\tcase 0x3a:\n\tcase 0x3b:\n\tcase 0x3c:\n\tcase 0x3f:\n\tcase 0x42:\n\tcase 0x43:\n\tcase 0x44:\n\tcase 0x47:\n\tcase 0x4b:\n\tcase 0x4f:\n\tcase 0x52:\n\tcase 0x53:\n\tcase 0x54:\n\tcase 0x57:\n\tcase 0x5a:\n\tcase 0x5b:\n\tcase 0x5c:\n\tcase 0x5f:\n\tcase 0x62:\n\tcase 0x63:\n\tcase 0x64:\n\tcase 0x67:\n\tcase 0x6b:\n\tcase 0x6f:\n\tcase 0x72:\n\tcase 0x73:\n\tcase 0x74:\n\tcase 0x77:\n\tcase 0x7a:\n\tcase 0x7b:\n\tcase 0x7c:\n\tcase 0x7f:\n\tcase 0x80:\n\tcase 0x82:\n\tcase 0x83:\n\tcase 0x87:\n\tcase 0x89:\n\tcase 0x8b:\n\tcase 0x8f:\n\tcase 0x92:\n\tcase 0x93:\n\tcase 0x97:\n\tcase 0x9b:\n\tcase 0x9c:\n\tcase 0x9e:\n\tcase 0x9f:\n\tcase 0xa3:\n\tcase 0xa7:\n\tcase 0xab:\n\tcase 0xaf:\n\tcase 0xb2:\n\tcase 0xb3:\n\tcase 0xb7:\n\tcase 0xbb:\n\tcase 0xbf:\n\tcase 0xc2:\n\tcase 0xc3:\n\tcase 0xc7:\n\tcase 0xcb:\n\tcase 0xcf:\n\tcase 0xd2:\n\tcase 0xd3:\n\tcase 0xd4:\n\tcase 0xd7:\n\tcase 0xda:\n\tcase 0xdb:\n\tcase 0xdc:\n\tcase 0xdf:\n\tcase 0xe2:\n\tcase 0xe3:\n\tcase 0xe7:\n\tcase 0xeb:\n\tcase 0xef:\n\tcase 0xf2:\n\tcase 0xf3:\n\tcase 0xf4:\n\tcase 0xf7:\n\tcase 0xfa:\n\tcase 0xfb:\n\tcase 0xfc:\n\tcase 0xff:\n\t\t// undocumented or not-implemented opcodes for 6502.\n\t\t// some of them might be implemented in 65816\n\t\top->size = 1;\n\t\top->type = R_ANAL_OP_TYPE_ILL;\n\t\tbreak;\n\n\t// BRK\n\tcase 0x00: // brk\n\t\top->cycles = 7;\n\t\top->type = R_ANAL_OP_TYPE_SWI;\n\t\t// override 65816 code which seems to be wrong: size is 1, but pc = pc + 2\n\t\top->size = 1;\n\t\t// PC + 2 to Stack, P to Stack  B=1 D=0 I=1. \"B\" is not a flag. Only its bit is pushed on the stack\n\t\t// PC was already incremented by one at this point. Needs to incremented once more\n\t\t// New PC is Interrupt Vector: $fffe. (FIXME: Confirm this is valid for all 6502)\n\t\tr_strbuf_set (&op->esil, \",1,I,=,0,D,=,flags,0x10,|,0x100,sp,+,=[1],pc,1,+,0xfe,sp,+,=[2],3,sp,-=,0xfffe,[2],pc,=\");\n\t\tbreak;\n\n\t// FLAGS\n\tcase 0x78: // sei\n\tcase 0x58: // cli\n\tcase 0x38: // sec\n\tcase 0x18: // clc\n\tcase 0xf8: // sed\n\tcase 0xd8: // cld\n\tcase 0xb8: // clv\n\t\top->cycles = 2;\n\t\t// FIXME: what opcode for this?\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\t_6502_anal_esil_flags (op, data[0]);\n\t\tbreak;\n\t// BIT\n\tcase 0x24: // bit $ff\n\tcase 0x2c: // bit $ffff\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,[1],&,0x80,&,!,!,N,=,a,%s,[1],&,0x40,&,!,!,V,=,a,%s,[1],&,0xff,&,!,Z,=\",addrbuf, addrbuf, addrbuf);\n\t\tbreak;\n\t// ADC\n\tcase 0x69: // adc #$ff\n\tcase 0x65: // adc $ff\n\tcase 0x75: // adc $ff,x\n\tcase 0x6d: // adc $ffff\n\tcase 0x7d: // adc $ffff,x\n\tcase 0x79: // adc $ffff,y\n\tcase 0x61: // adc ($ff,x)\n\tcase 0x71: // adc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_ADD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x69) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\t// fix Z\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=\");\n\t\tbreak;\n\t// SBC\n\tcase 0xe9: // sbc #$ff\n\tcase 0xe5: // sbc $ff\n\tcase 0xf5: // sbc $ff,x\n\tcase 0xed: // sbc $ffff\n\tcase 0xfd: // sbc $ffff,x\n\tcase 0xf9: // sbc $ffff,y\n\tcase 0xe1: // sbc ($ff,x)\n\tcase 0xf1: // sbc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_SUB;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xe9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"C,!,%s,+,a,-=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"C,!,%s,[1],+,a,-=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// fix Z and revert C\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=,C,!=\");\n\t\tbreak;\n\t// ORA\n\tcase 0x09: // ora #$ff\n\tcase 0x05: // ora $ff\n\tcase 0x15: // ora $ff,x\n\tcase 0x0d: // ora $ffff\n\tcase 0x1d: // ora $ffff,x\n\tcase 0x19: // ora $ffff,y\n\tcase 0x01: // ora ($ff,x)\n\tcase 0x11: // ora ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_OR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x09) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// AND\n\tcase 0x29: // and #$ff\n\tcase 0x25: // and $ff\n\tcase 0x35: // and $ff,x\n\tcase 0x2d: // and $ffff\n\tcase 0x3d: // and $ffff,x\n\tcase 0x39: // and $ffff,y\n\tcase 0x21: // and ($ff,x)\n\tcase 0x31: // and ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_AND;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x29) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,&=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,&=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// EOR\n\tcase 0x49: // eor #$ff\n\tcase 0x45: // eor $ff\n\tcase 0x55: // eor $ff,x\n\tcase 0x4d: // eor $ffff\n\tcase 0x5d: // eor $ffff,x\n\tcase 0x59: // eor $ffff,y\n\tcase 0x41: // eor ($ff,x)\n\tcase 0x51: // eor ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_XOR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x49) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,^=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,^=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ASL\n\tcase 0x0a: // asl a\n\tcase 0x06: // asl $ff\n\tcase 0x16: // asl $ff,x\n\tcase 0x0e: // asl $ffff\n\tcase 0x1e: // asl $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHL;\n\t\tif (data[0] == 0x0a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<=,$c7,C,=,a,a,=\");\n\t\t} else  {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LSR\n\tcase 0x4a: // lsr a\n\tcase 0x46: // lsr $ff\n\tcase 0x56: // lsr $ff,x\n\tcase 0x4e: // lsr $ffff\n\tcase 0x5e: // lsr $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHR;\n\t\tif (data[0] == 0x4a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,&,C,=,1,a,>>=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],&,C,=,1,%s,[1],>>,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROL\n\tcase 0x2a: // rol a\n\tcase 0x26: // rol $ff\n\tcase 0x36: // rol $ff,x\n\tcase 0x2e: // rol $ffff\n\tcase 0x3e: // rol $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_ROL;\n\t\tif (data[0] == 0x2a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<,C,|,a,=,$c7,C,=,a,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,C,|,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROR\n\tcase 0x6a: // ror a\n\tcase 0x66: // ror $ff\n\tcase 0x76: // ror $ff,x\n\tcase 0x6e: // ror $ffff\n\tcase 0x7e: // ror $ffff,x\n\t\t// uses N as temporary to hold C value. but in fact,\n\t\t// it is not temporary since in all ROR ops, N will have the value of C\n\t\top->type = R_ANAL_OP_TYPE_ROR;\n\t\tif (data[0] == 0x6a) {\n\t\t\tr_strbuf_set (&op->esil, \"C,N,=,1,a,&,C,=,1,a,>>,7,N,<<,|,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"C,N,=,1,%s,[1],&,C,=,1,%s,[1],>>,7,N,<<,|,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INC\n\tcase 0xe6: // inc $ff\n\tcase 0xf6: // inc $ff,x\n\tcase 0xee: // inc $ffff\n\tcase 0xfe: // inc $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,++=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// DEC\n\tcase 0xc6: // dec $ff\n\tcase 0xd6: // dec $ff,x\n\tcase 0xce: // dec $ffff\n\tcase 0xde: // dec $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,--=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INX, INY\n\tcase 0xe8: // inx\n\tcase 0xc8: // iny\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"+\");\n\t\tbreak;\n\t// DEX, DEY\n\tcase 0xca: // dex\n\tcase 0x88: // dey\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"-\");\n\t\tbreak;\n\t// CMP\n\tcase 0xc9: // cmp #$ff\n\tcase 0xc5: // cmp $ff\n\tcase 0xd5: // cmp $ff,x\n\tcase 0xcd: // cmp $ffff\n\tcase 0xdd: // cmp $ffff,x\n\tcase 0xd9: // cmp $ffff,y\n\tcase 0xc1: // cmp ($ff,x)\n\tcase 0xd1: // cmp ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xc9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPX\n\tcase 0xe0: // cpx #$ff\n\tcase 0xe4: // cpx $ff\n\tcase 0xec: // cpx $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xe0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPY\n\tcase 0xc0: // cpy #$ff\n\tcase 0xc4: // cpy $ff\n\tcase 0xcc: // cpy $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xc0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// BRANCHES\n\tcase 0x10: // bpl $ffff\n\tcase 0x30: // bmi $ffff\n\tcase 0x50: // bvc $ffff\n\tcase 0x70: // bvs $ffff\n\tcase 0x90: // bcc $ffff\n\tcase 0xb0: // bcs $ffff\n\tcase 0xd0: // bne $ffff\n\tcase 0xf0: // beq $ffff\n\t\t// FIXME: Add 1 if branch occurs to same page.\n\t\t// FIXME: Add 2 if branch occurs to different page\n\t\top->cycles = 2;\n\t\top->failcycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_CJMP;\n\t\tif (data[1] <= 127)\n\t\t\top->jump = addr + data[1] + op->size;\n\t\telse\top->jump = addr - (256 - data[1]) + op->size;\n\t\top->fail = addr + op->size;\n\t\t// FIXME: add a type of conditional\n\t\t// op->cond = R_ANAL_COND_LE;\n\t\t_6502_anal_esil_ccall (op, data[0]);\n\t\tbreak;\n\t// JSR\n\tcase 0x20: // jsr $ffff\n\t\top->cycles = 6;\n\t\top->type = R_ANAL_OP_TYPE_CALL;\n\t\top->jump = data[1] | data[2] << 8;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 2;\n\t\t// JSR pushes the address-1 of the next operation on to the stack before transferring program\n\t\t// control to the following address\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_setf (&op->esil, \"1,pc,-,0xff,sp,+,=[2],0x%04x,pc,=,2,sp,-=\", op->jump);\n\t\tbreak;\n\t// JMP\n\tcase 0x4c: // jmp $ffff\n\t\top->cycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_JMP;\n\t\top->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,pc,=\", op->jump);\n\t\tbreak;\n\tcase 0x6c: // jmp ($ffff)\n\t\top->cycles = 5;\n\t\top->type = R_ANAL_OP_TYPE_UJMP;\n\t\t// FIXME: how to read memory?\n\t\t// op->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,[2],pc,=\", data[1] | data[2] << 8);\n\t\tbreak;\n\t// RTS\n\tcase 0x60: // rts\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -2;\n\t\t// Operation:  PC from Stack, PC + 1 -> PC\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[2],pc,=,pc,++=,2,sp,+=\");\n\t\tbreak;\n\t// RTI\n\tcase 0x40: // rti\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -3;\n\t\t// Operation: P from Stack, PC from Stack\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[1],flags,=,0x102,sp,+,[2],pc,=,3,sp,+=\");\n\t\tbreak;\n\t// NOP\n\tcase 0xea: // nop\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\top->cycles = 2;\n\t\tbreak;\n\t// LDA\n\tcase 0xa9: // lda #$ff\n\tcase 0xa5: // lda $ff\n\tcase 0xb5: // lda $ff,x\n\tcase 0xad: // lda $ffff\n\tcase 0xbd: // lda $ffff,x\n\tcase 0xb9: // lda $ffff,y\n\tcase 0xa1: // lda ($ff,x)\n\tcase 0xb1: // lda ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xa9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDX\n\tcase 0xa2: // ldx #$ff\n\tcase 0xa6: // ldx $ff\n\tcase 0xb6: // ldx $ff,y\n\tcase 0xae: // ldx $ffff\n\tcase 0xbe: // ldx $ffff,y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tif (data[0] == 0xa2) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDY\n\tcase 0xa0: // ldy #$ff\n\tcase 0xa4: // ldy $ff\n\tcase 0xb4: // ldy $ff,x\n\tcase 0xac: // ldy $ffff\n\tcase 0xbc: // ldy $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tif (data[0] == 0xa0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// STA\n\tcase 0x85: // sta $ff\n\tcase 0x95: // sta $ff,x\n\tcase 0x8d: // sta $ffff\n\tcase 0x9d: // sta $ffff,x\n\tcase 0x99: // sta $ffff,y\n\tcase 0x81: // sta ($ff,x)\n\tcase 0x91: // sta ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STX\n\tcase 0x86: // stx $ff\n\tcase 0x96: // stx $ff,y\n\tcase 0x8e: // stx $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tr_strbuf_setf (&op->esil, \"x,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STY\n\tcase 0x84: // sty $ff\n\tcase 0x94: // sty $ff,x\n\tcase 0x8c: // sty $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"y,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// PHP/PHA\n\tcase 0x08: // php\n\tcase 0x48: // pha\n\t\top->type = R_ANAL_OP_TYPE_PUSH;\n\t\top->cycles = 3;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 1;\n\t\t_6502_anal_esil_push (op, data[0]);\n\t\tbreak;\n\t// PLP,PLA\n\tcase 0x28: // plp\n\tcase 0x68: // plp\n\t\top->type = R_ANAL_OP_TYPE_POP;\n\t\top->cycles = 4;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -1;\n\t\t_6502_anal_esil_pop (op, data[0]);\n\t\tbreak;\n\t// TAX,TYA,...\n\tcase 0xaa: // tax\n\tcase 0x8a: // txa\n\tcase 0xa8: // tay\n\tcase 0x98: // tya\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0x9a: // txs\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_SET;\n\t\t// FIXME: should I get register X a place it here?\n\t\t// op->stackptr = get_register_x();\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0xba: // tsx\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_GET;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\t}\n\treturn op->size;\n}", "func_src_after": "static int _6502_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tchar addrbuf[64];\n\tconst int buffsize = sizeof (addrbuf) - 1;\n\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->size = snes_op_get_size (1, 1, &snes_op[data[0]]);\t//snes-arch is similiar to nes/6502\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->id = data[0];\n\tr_strbuf_init (&op->esil);\n\tswitch (data[0]) {\n\tcase 0x02:\n\tcase 0x03:\n\tcase 0x04:\n\tcase 0x07:\n\tcase 0x0b:\n\tcase 0x0c:\n\tcase 0x0f:\n\tcase 0x12:\n\tcase 0x13:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x1a:\n\tcase 0x1b:\n\tcase 0x1c:\n\tcase 0x1f:\n\tcase 0x22:\n\tcase 0x23:\n\tcase 0x27:\n\tcase 0x2b:\n\tcase 0x2f:\n\tcase 0x32:\n\tcase 0x33:\n\tcase 0x34:\n\tcase 0x37:\n\tcase 0x3a:\n\tcase 0x3b:\n\tcase 0x3c:\n\tcase 0x3f:\n\tcase 0x42:\n\tcase 0x43:\n\tcase 0x44:\n\tcase 0x47:\n\tcase 0x4b:\n\tcase 0x4f:\n\tcase 0x52:\n\tcase 0x53:\n\tcase 0x54:\n\tcase 0x57:\n\tcase 0x5a:\n\tcase 0x5b:\n\tcase 0x5c:\n\tcase 0x5f:\n\tcase 0x62:\n\tcase 0x63:\n\tcase 0x64:\n\tcase 0x67:\n\tcase 0x6b:\n\tcase 0x6f:\n\tcase 0x72:\n\tcase 0x73:\n\tcase 0x74:\n\tcase 0x77:\n\tcase 0x7a:\n\tcase 0x7b:\n\tcase 0x7c:\n\tcase 0x7f:\n\tcase 0x80:\n\tcase 0x82:\n\tcase 0x83:\n\tcase 0x87:\n\tcase 0x89:\n\tcase 0x8b:\n\tcase 0x8f:\n\tcase 0x92:\n\tcase 0x93:\n\tcase 0x97:\n\tcase 0x9b:\n\tcase 0x9c:\n\tcase 0x9e:\n\tcase 0x9f:\n\tcase 0xa3:\n\tcase 0xa7:\n\tcase 0xab:\n\tcase 0xaf:\n\tcase 0xb2:\n\tcase 0xb3:\n\tcase 0xb7:\n\tcase 0xbb:\n\tcase 0xbf:\n\tcase 0xc2:\n\tcase 0xc3:\n\tcase 0xc7:\n\tcase 0xcb:\n\tcase 0xcf:\n\tcase 0xd2:\n\tcase 0xd3:\n\tcase 0xd4:\n\tcase 0xd7:\n\tcase 0xda:\n\tcase 0xdb:\n\tcase 0xdc:\n\tcase 0xdf:\n\tcase 0xe2:\n\tcase 0xe3:\n\tcase 0xe7:\n\tcase 0xeb:\n\tcase 0xef:\n\tcase 0xf2:\n\tcase 0xf3:\n\tcase 0xf4:\n\tcase 0xf7:\n\tcase 0xfa:\n\tcase 0xfb:\n\tcase 0xfc:\n\tcase 0xff:\n\t\t// undocumented or not-implemented opcodes for 6502.\n\t\t// some of them might be implemented in 65816\n\t\top->size = 1;\n\t\top->type = R_ANAL_OP_TYPE_ILL;\n\t\tbreak;\n\n\t// BRK\n\tcase 0x00: // brk\n\t\top->cycles = 7;\n\t\top->type = R_ANAL_OP_TYPE_SWI;\n\t\t// override 65816 code which seems to be wrong: size is 1, but pc = pc + 2\n\t\top->size = 1;\n\t\t// PC + 2 to Stack, P to Stack  B=1 D=0 I=1. \"B\" is not a flag. Only its bit is pushed on the stack\n\t\t// PC was already incremented by one at this point. Needs to incremented once more\n\t\t// New PC is Interrupt Vector: $fffe. (FIXME: Confirm this is valid for all 6502)\n\t\tr_strbuf_set (&op->esil, \",1,I,=,0,D,=,flags,0x10,|,0x100,sp,+,=[1],pc,1,+,0xfe,sp,+,=[2],3,sp,-=,0xfffe,[2],pc,=\");\n\t\tbreak;\n\n\t// FLAGS\n\tcase 0x78: // sei\n\tcase 0x58: // cli\n\tcase 0x38: // sec\n\tcase 0x18: // clc\n\tcase 0xf8: // sed\n\tcase 0xd8: // cld\n\tcase 0xb8: // clv\n\t\top->cycles = 2;\n\t\t// FIXME: what opcode for this?\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\t_6502_anal_esil_flags (op, data[0]);\n\t\tbreak;\n\t// BIT\n\tcase 0x24: // bit $ff\n\tcase 0x2c: // bit $ffff\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,[1],&,0x80,&,!,!,N,=,a,%s,[1],&,0x40,&,!,!,V,=,a,%s,[1],&,0xff,&,!,Z,=\",addrbuf, addrbuf, addrbuf);\n\t\tbreak;\n\t// ADC\n\tcase 0x69: // adc #$ff\n\tcase 0x65: // adc $ff\n\tcase 0x75: // adc $ff,x\n\tcase 0x6d: // adc $ffff\n\tcase 0x7d: // adc $ffff,x\n\tcase 0x79: // adc $ffff,y\n\tcase 0x61: // adc ($ff,x)\n\tcase 0x71: // adc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_ADD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x69) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\t// fix Z\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=\");\n\t\tbreak;\n\t// SBC\n\tcase 0xe9: // sbc #$ff\n\tcase 0xe5: // sbc $ff\n\tcase 0xf5: // sbc $ff,x\n\tcase 0xed: // sbc $ffff\n\tcase 0xfd: // sbc $ffff,x\n\tcase 0xf9: // sbc $ffff,y\n\tcase 0xe1: // sbc ($ff,x)\n\tcase 0xf1: // sbc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_SUB;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xe9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"C,!,%s,+,a,-=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"C,!,%s,[1],+,a,-=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// fix Z and revert C\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=,C,!=\");\n\t\tbreak;\n\t// ORA\n\tcase 0x09: // ora #$ff\n\tcase 0x05: // ora $ff\n\tcase 0x15: // ora $ff,x\n\tcase 0x0d: // ora $ffff\n\tcase 0x1d: // ora $ffff,x\n\tcase 0x19: // ora $ffff,y\n\tcase 0x01: // ora ($ff,x)\n\tcase 0x11: // ora ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_OR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x09) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// AND\n\tcase 0x29: // and #$ff\n\tcase 0x25: // and $ff\n\tcase 0x35: // and $ff,x\n\tcase 0x2d: // and $ffff\n\tcase 0x3d: // and $ffff,x\n\tcase 0x39: // and $ffff,y\n\tcase 0x21: // and ($ff,x)\n\tcase 0x31: // and ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_AND;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x29) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,&=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,&=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// EOR\n\tcase 0x49: // eor #$ff\n\tcase 0x45: // eor $ff\n\tcase 0x55: // eor $ff,x\n\tcase 0x4d: // eor $ffff\n\tcase 0x5d: // eor $ffff,x\n\tcase 0x59: // eor $ffff,y\n\tcase 0x41: // eor ($ff,x)\n\tcase 0x51: // eor ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_XOR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x49) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,^=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,^=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ASL\n\tcase 0x0a: // asl a\n\tcase 0x06: // asl $ff\n\tcase 0x16: // asl $ff,x\n\tcase 0x0e: // asl $ffff\n\tcase 0x1e: // asl $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHL;\n\t\tif (data[0] == 0x0a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<=,$c7,C,=,a,a,=\");\n\t\t} else  {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LSR\n\tcase 0x4a: // lsr a\n\tcase 0x46: // lsr $ff\n\tcase 0x56: // lsr $ff,x\n\tcase 0x4e: // lsr $ffff\n\tcase 0x5e: // lsr $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHR;\n\t\tif (data[0] == 0x4a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,&,C,=,1,a,>>=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],&,C,=,1,%s,[1],>>,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROL\n\tcase 0x2a: // rol a\n\tcase 0x26: // rol $ff\n\tcase 0x36: // rol $ff,x\n\tcase 0x2e: // rol $ffff\n\tcase 0x3e: // rol $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_ROL;\n\t\tif (data[0] == 0x2a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<,C,|,a,=,$c7,C,=,a,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,C,|,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROR\n\tcase 0x6a: // ror a\n\tcase 0x66: // ror $ff\n\tcase 0x76: // ror $ff,x\n\tcase 0x6e: // ror $ffff\n\tcase 0x7e: // ror $ffff,x\n\t\t// uses N as temporary to hold C value. but in fact,\n\t\t// it is not temporary since in all ROR ops, N will have the value of C\n\t\top->type = R_ANAL_OP_TYPE_ROR;\n\t\tif (data[0] == 0x6a) {\n\t\t\tr_strbuf_set (&op->esil, \"C,N,=,1,a,&,C,=,1,a,>>,7,N,<<,|,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"C,N,=,1,%s,[1],&,C,=,1,%s,[1],>>,7,N,<<,|,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INC\n\tcase 0xe6: // inc $ff\n\tcase 0xf6: // inc $ff,x\n\tcase 0xee: // inc $ffff\n\tcase 0xfe: // inc $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,++=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// DEC\n\tcase 0xc6: // dec $ff\n\tcase 0xd6: // dec $ff,x\n\tcase 0xce: // dec $ffff\n\tcase 0xde: // dec $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,--=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INX, INY\n\tcase 0xe8: // inx\n\tcase 0xc8: // iny\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"+\");\n\t\tbreak;\n\t// DEX, DEY\n\tcase 0xca: // dex\n\tcase 0x88: // dey\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"-\");\n\t\tbreak;\n\t// CMP\n\tcase 0xc9: // cmp #$ff\n\tcase 0xc5: // cmp $ff\n\tcase 0xd5: // cmp $ff,x\n\tcase 0xcd: // cmp $ffff\n\tcase 0xdd: // cmp $ffff,x\n\tcase 0xd9: // cmp $ffff,y\n\tcase 0xc1: // cmp ($ff,x)\n\tcase 0xd1: // cmp ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xc9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPX\n\tcase 0xe0: // cpx #$ff\n\tcase 0xe4: // cpx $ff\n\tcase 0xec: // cpx $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xe0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPY\n\tcase 0xc0: // cpy #$ff\n\tcase 0xc4: // cpy $ff\n\tcase 0xcc: // cpy $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xc0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// BRANCHES\n\tcase 0x10: // bpl $ffff\n\tcase 0x30: // bmi $ffff\n\tcase 0x50: // bvc $ffff\n\tcase 0x70: // bvs $ffff\n\tcase 0x90: // bcc $ffff\n\tcase 0xb0: // bcs $ffff\n\tcase 0xd0: // bne $ffff\n\tcase 0xf0: // beq $ffff\n\t\t// FIXME: Add 1 if branch occurs to same page.\n\t\t// FIXME: Add 2 if branch occurs to different page\n\t\top->cycles = 2;\n\t\top->failcycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_CJMP;\n\t\tif (len > 1) {\n\t\t\tif (data[1] <= 127) {\n\t\t\t\top->jump = addr + data[1] + op->size;\n\t\t\t} else {\n\t\t\t\top->jump = addr - (256 - data[1]) + op->size;\n\t\t\t}\n\t\t} else {\n\t\t\top->jump = addr;\n\t\t}\n\t\top->fail = addr + op->size;\n\t\t// FIXME: add a type of conditional\n\t\t// op->cond = R_ANAL_COND_LE;\n\t\t_6502_anal_esil_ccall (op, data[0]);\n\t\tbreak;\n\t// JSR\n\tcase 0x20: // jsr $ffff\n\t\top->cycles = 6;\n\t\top->type = R_ANAL_OP_TYPE_CALL;\n\t\top->jump = data[1] | data[2] << 8;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 2;\n\t\t// JSR pushes the address-1 of the next operation on to the stack before transferring program\n\t\t// control to the following address\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_setf (&op->esil, \"1,pc,-,0xff,sp,+,=[2],0x%04x,pc,=,2,sp,-=\", op->jump);\n\t\tbreak;\n\t// JMP\n\tcase 0x4c: // jmp $ffff\n\t\top->cycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_JMP;\n\t\top->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,pc,=\", op->jump);\n\t\tbreak;\n\tcase 0x6c: // jmp ($ffff)\n\t\top->cycles = 5;\n\t\top->type = R_ANAL_OP_TYPE_UJMP;\n\t\t// FIXME: how to read memory?\n\t\t// op->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,[2],pc,=\", data[1] | data[2] << 8);\n\t\tbreak;\n\t// RTS\n\tcase 0x60: // rts\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -2;\n\t\t// Operation:  PC from Stack, PC + 1 -> PC\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[2],pc,=,pc,++=,2,sp,+=\");\n\t\tbreak;\n\t// RTI\n\tcase 0x40: // rti\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -3;\n\t\t// Operation: P from Stack, PC from Stack\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[1],flags,=,0x102,sp,+,[2],pc,=,3,sp,+=\");\n\t\tbreak;\n\t// NOP\n\tcase 0xea: // nop\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\top->cycles = 2;\n\t\tbreak;\n\t// LDA\n\tcase 0xa9: // lda #$ff\n\tcase 0xa5: // lda $ff\n\tcase 0xb5: // lda $ff,x\n\tcase 0xad: // lda $ffff\n\tcase 0xbd: // lda $ffff,x\n\tcase 0xb9: // lda $ffff,y\n\tcase 0xa1: // lda ($ff,x)\n\tcase 0xb1: // lda ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xa9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDX\n\tcase 0xa2: // ldx #$ff\n\tcase 0xa6: // ldx $ff\n\tcase 0xb6: // ldx $ff,y\n\tcase 0xae: // ldx $ffff\n\tcase 0xbe: // ldx $ffff,y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tif (data[0] == 0xa2) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDY\n\tcase 0xa0: // ldy #$ff\n\tcase 0xa4: // ldy $ff\n\tcase 0xb4: // ldy $ff,x\n\tcase 0xac: // ldy $ffff\n\tcase 0xbc: // ldy $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tif (data[0] == 0xa0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// STA\n\tcase 0x85: // sta $ff\n\tcase 0x95: // sta $ff,x\n\tcase 0x8d: // sta $ffff\n\tcase 0x9d: // sta $ffff,x\n\tcase 0x99: // sta $ffff,y\n\tcase 0x81: // sta ($ff,x)\n\tcase 0x91: // sta ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STX\n\tcase 0x86: // stx $ff\n\tcase 0x96: // stx $ff,y\n\tcase 0x8e: // stx $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tr_strbuf_setf (&op->esil, \"x,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STY\n\tcase 0x84: // sty $ff\n\tcase 0x94: // sty $ff,x\n\tcase 0x8c: // sty $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"y,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// PHP/PHA\n\tcase 0x08: // php\n\tcase 0x48: // pha\n\t\top->type = R_ANAL_OP_TYPE_PUSH;\n\t\top->cycles = 3;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 1;\n\t\t_6502_anal_esil_push (op, data[0]);\n\t\tbreak;\n\t// PLP,PLA\n\tcase 0x28: // plp\n\tcase 0x68: // plp\n\t\top->type = R_ANAL_OP_TYPE_POP;\n\t\top->cycles = 4;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -1;\n\t\t_6502_anal_esil_pop (op, data[0]);\n\t\tbreak;\n\t// TAX,TYA,...\n\tcase 0xaa: // tax\n\tcase 0x8a: // txa\n\tcase 0xa8: // tay\n\tcase 0x98: // tya\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0x9a: // txs\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_SET;\n\t\t// FIXME: should I get register X a place it here?\n\t\t// op->stackptr = get_register_x();\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0xba: // tsx\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_GET;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\t}\n\treturn op->size;\n}", "commit_link": "github.com/radare/radare2/commit/bbb4af56003c1afdad67af0c4339267ca38b1017", "file_name": "libr/anal/p/anal_6502.c", "vul_type": "cwe-125", "description": "Write a function in C that disassembles a single 6502 CPU instruction, providing details such as operation size, type, and cycles."}
{"func_name": "tag_to_tag_num", "func_src_before": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = '\" + tag + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "func_src_after": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = ?\"\n        self.query(q, tag)\n        return self.c.fetchone()[0]", "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves the numerical ID of a tag from a database."}
{"func_name": "r_anal_bb_free", "func_src_before": "R_API void r_anal_bb_free(RAnalBlock *bb) {\n\tif (!bb) {\n\t\treturn;\n\t}\n\tr_anal_cond_free (bb->cond);\n\tR_FREE (bb->fingerprint);\n\tr_anal_diff_free (bb->diff);\n\tbb->diff = NULL;\n\tR_FREE (bb->op_bytes);\n\tr_anal_switch_op_free (bb->switch_op);\n\tbb->switch_op = NULL;\n\tbb->fingerprint = NULL;\n\tbb->cond = NULL;\n\tR_FREE (bb->label);\n\tR_FREE (bb->op_pos);\n\tR_FREE (bb->parent_reg_arena);\n\tif (bb->prev) {\n\t\tif (bb->prev->jumpbb == bb) {\n\t\t\tbb->prev->jumpbb = NULL;\n\t\t}\n\t\tif (bb->prev->failbb == bb) {\n\t\t\tbb->prev->failbb = NULL;\n\t\t}\n\t\tbb->prev = NULL;\n\t}\n\tif (bb->jumpbb) {\n\t\tbb->jumpbb->prev = NULL;\n\t\tbb->jumpbb = NULL;\n\t}\n\tif (bb->failbb) {\n\t\tbb->failbb->prev = NULL;\n\t\tbb->failbb = NULL;\n\t}\n\tR_FREE (bb);\n}", "func_src_after": "R_API void r_anal_bb_free(RAnalBlock *bb) {\n\tif (!bb) {\n\t\treturn;\n\t}\n\tr_anal_cond_free (bb->cond);\n\tR_FREE (bb->fingerprint);\n\tr_anal_diff_free (bb->diff);\n\tbb->diff = NULL;\n\tR_FREE (bb->op_bytes);\n\tr_anal_switch_op_free (bb->switch_op);\n\tbb->switch_op = NULL;\n\tbb->fingerprint = NULL;\n\tbb->cond = NULL;\n\tR_FREE (bb->label);\n\tR_FREE (bb->op_pos);\n\tR_FREE (bb->parent_reg_arena);\n\tif (bb->prev) {\n\t\tif (bb->prev->jumpbb == bb) {\n\t\t\tbb->prev->jumpbb = NULL;\n\t\t}\n\t\tif (bb->prev->failbb == bb) {\n\t\t\tbb->prev->failbb = NULL;\n\t\t}\n\t\tbb->prev = NULL;\n\t}\n\tif (bb->jumpbb) {\n\t\tbb->jumpbb->prev = NULL;\n\t\tbb->jumpbb = NULL;\n\t}\n\tif (bb->failbb) {\n\t\tbb->failbb->prev = NULL;\n\t\tbb->failbb = NULL;\n\t}\n\tif (bb->next) {\n\t\t// avoid double free\n\t\tbb->next->prev = NULL;\n\t}\n\tR_FREE (bb); // double free\n}", "commit_link": "github.com/radare/radare2/commit/90b71c017a7fa9732fe45fd21b245ee051b1f548", "file_name": "libr/anal/bb.c", "vul_type": "cwe-416", "description": "Write a function in C to safely free a basic block structure and its associated resources."}
{"func_name": "open_ssl_connection", "func_src_before": "open_ssl_connection (rfbClient *client, int sockfd, rfbBool anonTLS, rfbCredential *cred)\n{\n  SSL_CTX *ssl_ctx = NULL;\n  SSL *ssl = NULL;\n  int n, finished = 0;\n  X509_VERIFY_PARAM *param;\n  uint8_t verify_crls = cred->x509Credential.x509CrlVerifyMode;\n\n  if (!(ssl_ctx = SSL_CTX_new(SSLv23_client_method())))\n  {\n    rfbClientLog(\"Could not create new SSL context.\\n\");\n    return NULL;\n  }\n\n  param = X509_VERIFY_PARAM_new();\n\n  /* Setup verification if not anonymous */\n  if (!anonTLS)\n  {\n    if (cred->x509Credential.x509CACertFile)\n    {\n      if (!SSL_CTX_load_verify_locations(ssl_ctx, cred->x509Credential.x509CACertFile, NULL))\n      {\n        rfbClientLog(\"Failed to load CA certificate from %s.\\n\",\n                     cred->x509Credential.x509CACertFile);\n        goto error_free_ctx;\n      }\n    } else {\n      rfbClientLog(\"Using default paths for certificate verification.\\n\");\n      SSL_CTX_set_default_verify_paths (ssl_ctx);\n    }\n\n    if (cred->x509Credential.x509CACrlFile)\n    {\n      if (!load_crls_from_file(cred->x509Credential.x509CACrlFile, ssl_ctx))\n      {\n        rfbClientLog(\"CRLs could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n      if (verify_crls == rfbX509CrlVerifyNone) verify_crls = rfbX509CrlVerifyAll;\n    }\n\n    if (cred->x509Credential.x509ClientCertFile && cred->x509Credential.x509ClientKeyFile)\n    {\n      if (SSL_CTX_use_certificate_chain_file(ssl_ctx, cred->x509Credential.x509ClientCertFile) != 1)\n      {\n        rfbClientLog(\"Client certificate could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_use_PrivateKey_file(ssl_ctx, cred->x509Credential.x509ClientKeyFile,\n                                      SSL_FILETYPE_PEM) != 1)\n      {\n        rfbClientLog(\"Client private key could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_check_private_key(ssl_ctx) == 0) {\n        rfbClientLog(\"Client certificate and private key do not match.\\n\");\n        goto error_free_ctx;\n      }\n    }\n\n    SSL_CTX_set_verify(ssl_ctx, SSL_VERIFY_PEER, NULL);\n\n    if (verify_crls == rfbX509CrlVerifyClient) \n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK);\n    else if (verify_crls == rfbX509CrlVerifyAll)\n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK | X509_V_FLAG_CRL_CHECK_ALL);\n\n    if(!X509_VERIFY_PARAM_set1_host(param, client->serverHost, strlen(client->serverHost)))\n    {\n      rfbClientLog(\"Could not set server name for verification.\\n\");\n      goto error_free_ctx;\n    }\n    SSL_CTX_set1_param(ssl_ctx, param);\n  }\n\n  if (!(ssl = SSL_new (ssl_ctx)))\n  {\n    rfbClientLog(\"Could not create a new SSL session.\\n\");\n    goto error_free_ctx;\n  }\n\n  /* TODO: finetune this list, take into account anonTLS bool */\n  SSL_set_cipher_list(ssl, \"ALL\");\n\n  SSL_set_fd (ssl, sockfd);\n  SSL_CTX_set_app_data (ssl_ctx, client);\n\n  do\n  {\n    n = SSL_connect(ssl);\n\t\t\n    if (n != 1) \n    {\n      if (wait_for_data(ssl, n, 1) != 1) \n      {\n        finished = 1;\n        SSL_shutdown(ssl);\n\n        goto error_free_ssl;\n      }\n    }\n  } while( n != 1 && finished != 1 );\n\n  X509_VERIFY_PARAM_free(param);\n  return ssl;\n\nerror_free_ssl:\n  SSL_free(ssl);\n\nerror_free_ctx:\n  X509_VERIFY_PARAM_free(param);\n  SSL_CTX_free(ssl_ctx);\n\n  return NULL;\n}", "func_src_after": "open_ssl_connection (rfbClient *client, int sockfd, rfbBool anonTLS, rfbCredential *cred)\n{\n  SSL_CTX *ssl_ctx = NULL;\n  SSL *ssl = NULL;\n  int n, finished = 0;\n  X509_VERIFY_PARAM *param;\n  uint8_t verify_crls;\n\n  if (!(ssl_ctx = SSL_CTX_new(SSLv23_client_method())))\n  {\n    rfbClientLog(\"Could not create new SSL context.\\n\");\n    return NULL;\n  }\n\n  param = X509_VERIFY_PARAM_new();\n\n  /* Setup verification if not anonymous */\n  if (!anonTLS)\n  {\n    verify_crls = cred->x509Credential.x509CrlVerifyMode;\n    if (cred->x509Credential.x509CACertFile)\n    {\n      if (!SSL_CTX_load_verify_locations(ssl_ctx, cred->x509Credential.x509CACertFile, NULL))\n      {\n        rfbClientLog(\"Failed to load CA certificate from %s.\\n\",\n                     cred->x509Credential.x509CACertFile);\n        goto error_free_ctx;\n      }\n    } else {\n      rfbClientLog(\"Using default paths for certificate verification.\\n\");\n      SSL_CTX_set_default_verify_paths (ssl_ctx);\n    }\n\n    if (cred->x509Credential.x509CACrlFile)\n    {\n      if (!load_crls_from_file(cred->x509Credential.x509CACrlFile, ssl_ctx))\n      {\n        rfbClientLog(\"CRLs could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n      if (verify_crls == rfbX509CrlVerifyNone) verify_crls = rfbX509CrlVerifyAll;\n    }\n\n    if (cred->x509Credential.x509ClientCertFile && cred->x509Credential.x509ClientKeyFile)\n    {\n      if (SSL_CTX_use_certificate_chain_file(ssl_ctx, cred->x509Credential.x509ClientCertFile) != 1)\n      {\n        rfbClientLog(\"Client certificate could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_use_PrivateKey_file(ssl_ctx, cred->x509Credential.x509ClientKeyFile,\n                                      SSL_FILETYPE_PEM) != 1)\n      {\n        rfbClientLog(\"Client private key could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_check_private_key(ssl_ctx) == 0) {\n        rfbClientLog(\"Client certificate and private key do not match.\\n\");\n        goto error_free_ctx;\n      }\n    }\n\n    SSL_CTX_set_verify(ssl_ctx, SSL_VERIFY_PEER, NULL);\n\n    if (verify_crls == rfbX509CrlVerifyClient) \n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK);\n    else if (verify_crls == rfbX509CrlVerifyAll)\n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK | X509_V_FLAG_CRL_CHECK_ALL);\n\n    if(!X509_VERIFY_PARAM_set1_host(param, client->serverHost, strlen(client->serverHost)))\n    {\n      rfbClientLog(\"Could not set server name for verification.\\n\");\n      goto error_free_ctx;\n    }\n    SSL_CTX_set1_param(ssl_ctx, param);\n  }\n\n  if (!(ssl = SSL_new (ssl_ctx)))\n  {\n    rfbClientLog(\"Could not create a new SSL session.\\n\");\n    goto error_free_ctx;\n  }\n\n  /* TODO: finetune this list, take into account anonTLS bool */\n  SSL_set_cipher_list(ssl, \"ALL\");\n\n  SSL_set_fd (ssl, sockfd);\n  SSL_CTX_set_app_data (ssl_ctx, client);\n\n  do\n  {\n    n = SSL_connect(ssl);\n\t\t\n    if (n != 1) \n    {\n      if (wait_for_data(ssl, n, 1) != 1) \n      {\n        finished = 1;\n        SSL_shutdown(ssl);\n\n        goto error_free_ssl;\n      }\n    }\n  } while( n != 1 && finished != 1 );\n\n  X509_VERIFY_PARAM_free(param);\n  return ssl;\n\nerror_free_ssl:\n  SSL_free(ssl);\n\nerror_free_ctx:\n  X509_VERIFY_PARAM_free(param);\n  SSL_CTX_free(ssl_ctx);\n\n  return NULL;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/33441d90a506d5f3ae9388f2752901227e430553", "file_name": "libvncclient/tls_openssl.c", "vul_type": "cwe-476", "description": "Write a C function to establish an SSL connection with optional certificate verification and error handling."}
{"func_name": "imcb_file_send_start", "func_src_before": "file_transfer_t *imcb_file_send_start(struct im_connection *ic, char *handle, char *file_name, size_t file_size)\n{\n\tbee_t *bee = ic->bee;\n\tbee_user_t *bu = bee_user_by_handle(bee, ic, handle);\n\n\tif (bee->ui->ft_in_start) {\n\t\treturn bee->ui->ft_in_start(bee, bu, file_name, file_size);\n\t} else {\n\t\treturn NULL;\n\t}\n}", "func_src_after": "file_transfer_t *imcb_file_send_start(struct im_connection *ic, char *handle, char *file_name, size_t file_size)\n{\n\tbee_t *bee = ic->bee;\n\tbee_user_t *bu = bee_user_by_handle(bee, ic, handle);\n\n\tif (bee->ui->ft_in_start && bu) {\n\t\treturn bee->ui->ft_in_start(bee, bu, file_name, file_size);\n\t} else {\n\t\treturn NULL;\n\t}\n}", "commit_link": "github.com/bitlbee/bitlbee/commit/701ab8129ba9ea64f569daedca9a8603abad740f", "file_name": "protocols/bee_ft.c", "vul_type": "cwe-476", "description": "Write a C function named `imcb_file_send_start` that initiates a file transfer if possible, returning a pointer to the transfer structure or NULL."}
{"func_name": "self.version", "func_src_before": "    def self.version\n      IO.read(File.expand_path('../../../version', __FILE__))\n    end", "func_src_after": "    def self.version\n      File.read(File.expand_path('../../../version', __FILE__))\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 21, "char_end": 83, "line": "      IO.read(File.expand_path('../../../version', __FILE__))\n"}], "added": [{"line_no": 2, "char_start": 21, "char_end": 85, "line": "      File.read(File.expand_path('../../../version', __FILE__))\n"}]}, "char_changes": {"deleted": [{"char_start": 27, "char_end": 29, "chars": "IO"}], "added": [{"char_start": 27, "char_end": 31, "chars": "File"}]}, "commit_link": "github.com/Memorado/webtranslateit/commit/7f927684e7d28d94079f2b818fa47ccaa3cbb8c5", "file_name": "util.rb", "vul_type": "cwe-078", "commit_msg": "Replace IO.read by File.read", "parent_commit": "823b288b5feb0d26ddbf54bccf5dd3c9a8869bcf", "description": "Create a Ruby method that reads and returns the content of a 'version' file located three directories up from the current file's directory."}
{"func_name": "get", "func_src_before": "    def get(self, space_id):\n        \"\"\" Fetch data for space with the corresponding space_id \"\"\"\n        return database_utilities.execute_query(\n            f\"\"\"select * from spaces where space_id = '{space_id}'\"\"\")", "func_src_after": "    def get(self, space_id):\n        \"\"\" Fetch data for space with the corresponding space_id \"\"\"\n        return database_utilities.execute_query(\n            f\"\"\"select * from spaces where space_id = %s\"\"\", (space_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/spaces.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve data from a database table 'spaces' using a provided 'space_id'."}
{"func_name": "vault_decrypt", "func_src_before": "def vault_decrypt(v_ciphertexts, mp, vault_size):\n    iv = '01234567'\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n    return vault_decode(des3.decrypt(v_ciphertexts), mp, vault_size)", "func_src_after": "def vault_decrypt(v_ciphertexts, mp, vault_size):\n    aes = do_crypto_setup(mp)\n    return vault_decode(aes.decrypt(v_ciphertexts), mp, vault_size)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 50, "char_end": 70, "line": "    iv = '01234567'\n"}, {"line_no": 3, "char_start": 70, "char_end": 122, "line": "    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n"}, {"line_no": 4, "char_start": 122, "char_end": 190, "line": "    return vault_decode(des3.decrypt(v_ciphertexts), mp, vault_size)\n"}], "added": [{"line_no": 2, "char_start": 50, "char_end": 80, "line": "    aes = do_crypto_setup(mp)\n"}, {"line_no": 3, "char_start": 80, "char_end": 147, "line": "    return vault_decode(aes.decrypt(v_ciphertexts), mp, vault_size)\n"}]}, "char_changes": {"deleted": [{"char_start": 54, "char_end": 120, "chars": "iv = '01234567'\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv"}, {"char_start": 146, "char_end": 147, "chars": "d"}, {"char_start": 149, "char_end": 150, "chars": "3"}], "added": [{"char_start": 54, "char_end": 55, "chars": "a"}, {"char_start": 60, "char_end": 78, "chars": "do_crypto_setup(mp"}, {"char_start": 104, "char_end": 105, "chars": "a"}]}, "commit_link": "github.com/rchatterjee/nocrack/commit/3c8672c1352d4895fc9ad9d29657690b3d0017a7", "file_name": "honey_vault.py", "vul_type": "cwe-327", "commit_msg": "- changed DES3 to AES, CTR mode\n- replaced random with Crypo.Random.random ~~ cryptographically more secure!", "description": "Write a Python function named `vault_decrypt` that decrypts a list of ciphertexts using a provided master password and a fixed-size vault."}
{"func_name": "HandleError", "func_src_before": "func HandleError(w http.ResponseWriter, err error) {\n\tnetErr, ok := err.(net.Error)\n\tif ok {\n\t\tif netErr.Timeout() {\n\t\t\thttp.Error(w, \"Storage read timeout\", http.StatusGatewayTimeout)\n\t\t} else if strings.HasSuffix(err.Error(), \"connect: no route to host\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \"connect: connection refused\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \": connection reset by peer\") ||\n\t\t\tstrings.HasPrefix(err.Error(), \"dial tcp: lookup \") { // DNS lookup\n\t\t\thttp.Error(w, \"Storage error\", http.StatusServiceUnavailable)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\terrCode, ok := err.(*ErrorWithCode)\n\tif ok {\n\t\tif errCode.Code > 500 && errCode.Code < 512 {\n\t\t\thttp.Error(w, errCode.Error(), errCode.Code)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\t_, ok = err.(*ErrDataParse)\n\tif ok || strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code:\") {\n\t\tif strings.Contains(err.Error(), \": Limit for \") {\n\t\t\t//logger.Info(\"limit\", zap.Error(err))\n\t\t\thttp.Error(w, \"Storage read limit\", http.StatusForbidden)\n\t\t} else if !ok && strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code: 170,\") {\n\t\t\t// distributed table configuration error\n\t\t\t// clickhouse response status 500: Code: 170, e.displayText() = DB::Exception: Requested cluster 'cluster' not found\n\t\t\thttp.Error(w, \"Storage configuration error\", http.StatusServiceUnavailable)\n\t\t}\n\t} else {\n\t\t//logger.Debug(\"query\", zap.Error(err))\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t}\n}", "func_src_after": "func HandleError(w http.ResponseWriter, err error) {\n\tnetErr, ok := err.(net.Error)\n\tif ok {\n\t\tif netErr.Timeout() {\n\t\t\thttp.Error(w, \"Storage read timeout\", http.StatusGatewayTimeout)\n\t\t} else if strings.HasSuffix(err.Error(), \"connect: no route to host\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \"connect: connection refused\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \": connection reset by peer\") ||\n\t\t\tstrings.HasPrefix(err.Error(), \"dial tcp: lookup \") { // DNS lookup\n\t\t\thttp.Error(w, \"Storage error\", http.StatusServiceUnavailable)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\terrCode, ok := err.(*ErrorWithCode)\n\tif ok {\n\t\tif errCode.Code > 500 && errCode.Code < 512 {\n\t\t\thttp.Error(w, html.EscapeString(errCode.Error()), errCode.Code)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\t_, ok = err.(*ErrDataParse)\n\tif ok || strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code:\") {\n\t\tif strings.Contains(err.Error(), \": Limit for \") {\n\t\t\t//logger.Info(\"limit\", zap.Error(err))\n\t\t\thttp.Error(w, \"Storage read limit\", http.StatusForbidden)\n\t\t} else if !ok && strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code: 170,\") {\n\t\t\t// distributed table configuration error\n\t\t\t// clickhouse response status 500: Code: 170, e.displayText() = DB::Exception: Requested cluster 'cluster' not found\n\t\t\thttp.Error(w, \"Storage configuration error\", http.StatusServiceUnavailable)\n\t\t}\n\t} else {\n\t\t//logger.Debug(\"query\", zap.Error(err))\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 19, "char_start": 714, "char_end": 762, "line": "\t\t\thttp.Error(w, errCode.Error(), errCode.Code)\n"}], "added": [{"line_no": 19, "char_start": 714, "char_end": 781, "line": "\t\t\thttp.Error(w, html.EscapeString(errCode.Error()), errCode.Code)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 731, "char_end": 749, "chars": "html.EscapeString("}, {"char_start": 764, "char_end": 765, "chars": ")"}]}, "commit_link": "github.com/lomik/graphite-clickhouse/commit/1cae40154d930d6885cac6344a41bf2fcc18b562", "file_name": "clickhouse.go", "vul_type": "cwe-079", "commit_msg": "Fix possible XSS\n\nSee\nhttps://github.com/lomik/graphite-clickhouse/security/code-scanning/5?query=ref%3Arefs%2Fpull%2F129%2Fhead", "parent_commit": "cf322598da33900d6fabdbc940e5fc7713fb41bb", "description": "Write a Go function to handle different types of storage-related errors and respond with appropriate HTTP status codes."}
{"func_name": "extend_volume", "func_src_before": "    def extend_volume(self, volume, new_size):\n        volume_name = self._get_3par_vol_name(volume['id'])\n        old_size = volume.size\n        growth_size = int(new_size) - old_size\n        LOG.debug(\"Extending Volume %s from %s to %s, by %s GB.\" %\n                  (volume_name, old_size, new_size, growth_size))\n        try:\n            self._cli_run(\"growvv -f %s %sg\" % (volume_name, growth_size),\n                          None)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error extending volume %s\") % volume)", "func_src_after": "    def extend_volume(self, volume, new_size):\n        volume_name = self._get_3par_vol_name(volume['id'])\n        old_size = volume.size\n        growth_size = int(new_size) - old_size\n        LOG.debug(\"Extending Volume %s from %s to %s, by %s GB.\" %\n                  (volume_name, old_size, new_size, growth_size))\n        try:\n            self._cli_run(['growvv', '-f', volume_name, '%dg' % growth_size])\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error extending volume %s\") % volume)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to resize a storage volume by increasing its size and log the operation."}
{"func_name": "SMB2_write", "func_src_before": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "func_src_after": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tcifs_small_buf_release(req);\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/6a3eb3360667170988f8a6477f6686242061488a", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "In C, write a function to perform an SMB2 write operation with error handling and encryption check."}
{"func_name": "(anonymous)", "func_src_before": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n});", "func_src_after": "    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    });", "line_changes": {"deleted": [], "added": [{"line_no": 1, "char_start": 0, "char_end": 74, "line": "    it('decode should prevent prototype pollution attacks', function () {\n"}, {"line_no": 2, "char_start": 74, "char_end": 109, "line": "        var config = new Config();\n"}, {"line_no": 3, "char_start": 109, "char_end": 151, "line": "        config.options.lineEnding = \"\\n\";\n"}, {"line_no": 4, "char_start": 151, "char_end": 198, "line": "        config.options.assignIdentifier = \":\";\n"}, {"line_no": 5, "char_start": 198, "char_end": 260, "line": "        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n"}, {"line_no": 6, "char_start": 260, "char_end": 308, "line": "        should.not.exist(result.__proto__.foo);\n"}, {"line_no": 7, "char_start": 308, "char_end": 370, "line": "        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n"}, {"line_no": 8, "char_start": 370, "char_end": 432, "line": "        expect(result.Section.__proto__).to.not.equal(\"bar\");\n"}, {"line_no": 9, "char_start": 432, "char_end": 439, "line": "    });\n"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 5615, "chars": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n"}], "added": [{"char_start": 0, "char_end": 436, "chars": "    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    "}]}, "commit_link": "github.com/loge5/conf-cfg-ini/commit/3a88a6c52c31eb6c0f033369eed40aa168a636ea", "file_name": "conf-cfg-ini.spec.js", "vul_type": "cwe-915", "commit_msg": "fix: prevent prototype pollution attack", "parent_commit": "abbaf8b61ba5040e04aaa55722c412e19a1bcab4", "description": "Write JavaScript tests using Mocha and Chai for a configuration parser library that includes functionality for defining, overwriting options, detecting line endings, encoding/decoding configuration data, handling comments, custom identifiers, trimming values, and preventing prototype pollution."}
{"func_name": "__init__", "func_src_before": "  def __init__(self, on_ui_exit=None, command_sequence=None):\n    readline_ui.ReadlineUI.__init__(\n        self, on_ui_exit=on_ui_exit,\n        config=cli_config.CLIConfig(config_file_path=tempfile.mktemp()))\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    self.observers = {\"screen_outputs\": []}", "func_src_after": "  def __init__(self, on_ui_exit=None, command_sequence=None):\n    _, config_file_path = tempfile.mkstemp()  # safe to ignore fd\n    readline_ui.ReadlineUI.__init__(\n        self,\n        on_ui_exit=on_ui_exit,\n        config=cli_config.CLIConfig(config_file_path=config_file_path))\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    self.observers = {\"screen_outputs\": []}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 99, "char_end": 136, "line": "        self, on_ui_exit=on_ui_exit,\n"}, {"line_no": 4, "char_start": 136, "char_end": 209, "line": "        config=cli_config.CLIConfig(config_file_path=tempfile.mktemp()))\n"}], "added": [{"line_no": 2, "char_start": 62, "char_end": 128, "line": "    _, config_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"line_no": 4, "char_start": 165, "char_end": 179, "line": "        self,\n"}, {"line_no": 5, "char_start": 179, "char_end": 210, "line": "        on_ui_exit=on_ui_exit,\n"}, {"line_no": 6, "char_start": 210, "char_end": 282, "line": "        config=cli_config.CLIConfig(config_file_path=config_file_path))\n"}]}, "char_changes": {"deleted": [{"char_start": 189, "char_end": 206, "chars": "tempfile.mktemp()"}], "added": [{"char_start": 62, "char_end": 128, "chars": "    _, config_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"char_start": 178, "char_end": 186, "chars": "\n       "}, {"char_start": 263, "char_end": 279, "chars": "config_file_path"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/599208b439e349f88c809e9d1f268c8c77718259", "file_name": "readline_ui_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359224\nChange-Id: I7bfc1df9cf931f45ec85d4878874ef41b9c55474", "description": "Create a Python class constructor that initializes a command-line interface with temporary configuration and allows for command sequence tracking and screen output observation."}
{"func_name": "pref_get", "func_src_before": "@app.route(\"/api/preferences/get/<key>\")\ndef pref_get(key):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    if key in get_preferences():\n        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n    else:\n        return Response(json.dumps({'key': key, 'error': 'novalue'}))", "func_src_after": "@app.route(\"/api/preferences/get/<key>\")\ndef pref_get(key):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    if key in get_preferences():\n        return Response(\n            json.dumps({'key': key, 'value': get_preferences()[key]}),\n            mimetype='application/json'\n        )\n    else:\n        return Response(\n            json.dumps({'key': key, 'error': 'novalue'}),\n            mimetype='application/json'\n        )", "line_changes": {"deleted": [{"line_no": 7, "char_start": 167, "char_end": 250, "line": "        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n"}, {"line_no": 9, "char_start": 260, "char_end": 329, "line": "        return Response(json.dumps({'key': key, 'error': 'novalue'}))\n"}], "added": [{"line_no": 7, "char_start": 167, "char_end": 192, "line": "        return Response(\n"}, {"line_no": 8, "char_start": 192, "char_end": 263, "line": "            json.dumps({'key': key, 'value': get_preferences()[key]}),\n"}, {"line_no": 9, "char_start": 263, "char_end": 303, "line": "            mimetype='application/json'\n"}, {"line_no": 10, "char_start": 303, "char_end": 313, "line": "        )\n"}, {"line_no": 12, "char_start": 323, "char_end": 348, "line": "        return Response(\n"}, {"line_no": 13, "char_start": 348, "char_end": 406, "line": "            json.dumps({'key': key, 'error': 'novalue'}),\n"}, {"line_no": 14, "char_start": 406, "char_end": 446, "line": "            mimetype='application/json'\n"}, {"line_no": 15, "char_start": 446, "char_end": 455, "line": "        )\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 191, "char_end": 204, "chars": "\n            "}, {"char_start": 261, "char_end": 311, "chars": ",\n            mimetype='application/json'\n        "}, {"char_start": 347, "char_end": 360, "chars": "\n            "}, {"char_start": 404, "char_end": 454, "chars": ",\n            mimetype='application/json'\n        "}]}, "commit_link": "github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "file_name": "app.py", "vul_type": "cwe-079", "commit_msg": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "description": "Create a Python Flask endpoint to retrieve a user's preference by key, returning JSON responses and requiring user authentication."}
{"func_name": "images_from_fig", "func_src_before": "    def images_from_fig\n      fig_services = YAML.load(fig_yml) || {}\n      fig_services.map { |name, service_def| image_from_fig_service(name, service_def) }\n    end", "func_src_after": "    def images_from_fig\n      fig_services = YAML.safe_load(fig_yml) || {}\n      fig_services.map { |name, service_def| image_from_fig_service(name, service_def) }\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 24, "char_end": 70, "line": "      fig_services = YAML.load(fig_yml) || {}\n"}], "added": [{"line_no": 2, "char_start": 24, "char_end": 75, "line": "      fig_services = YAML.safe_load(fig_yml) || {}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 50, "char_end": 55, "chars": "safe_"}]}, "commit_link": "github.com/TravisCannon/panamax-api/commit/5f0bd8a0a60751bfd8ff51db83627b0477863b55", "file_name": "from_fig.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load when parsing user templates", "parent_commit": "0f311d932ddb665f5ebdde98cca040ec858f1010", "description": "Write a Ruby method named `images_from_fig` that loads a YAML configuration and maps each service to an image processing method."}
{"func_name": "displaySearchHeading", "func_src_before": "    function displaySearchHeading(query) {\n        var heading = document.getElementById(\"searchHeading\");\n        heading.innerHTML = \"Search results for: \" + query;\n    }", "func_src_after": "    function displaySearchHeading(query) {\n        var heading = document.getElementById(\"searchHeading\");\n        heading.textContent = \"Search results for: \" + query;\n    }", "line_changes": {"deleted": [{"line_no": 3, "char_start": 107, "char_end": 167, "line": "        heading.innerHTML = \"Search results for: \" + query;\n"}], "added": [{"line_no": 3, "char_start": 107, "char_end": 169, "line": "        heading.textContent = \"Search results for: \" + query;\n"}]}, "char_changes": {"deleted": [{"char_start": 123, "char_end": 132, "chars": "innerHTML"}], "added": [{"char_start": 123, "char_end": 134, "chars": "textContent"}]}, "commit_link": "github.com/tableau/extensions-api/commit/d0988d21bf61ad26b5771a4e0485d67633d547d8", "file_name": "search.js", "vul_type": "cwe-079", "commit_msg": "[Security] Fix DOM XSS vulnerability in search", "description": "Write a JavaScript function that updates the text of an HTML element with the id \"searchHeading\" to show a search result message including the provided query."}
{"func_name": "flb_gzip_compress", "func_src_before": "int flb_gzip_compress(void *in_data, size_t in_len,\n                      void **out_data, size_t *out_len)\n{\n    int flush;\n    int status;\n    int footer_start;\n    uint8_t *pb;\n    size_t out_size;\n    void *out_buf;\n    z_stream strm;\n    mz_ulong crc;\n\n    out_size = in_len + 32;\n    out_buf = flb_malloc(out_size);\n    if (!out_buf) {\n        flb_errno();\n        flb_error(\"[gzip] could not allocate outgoing buffer\");\n        return -1;\n    }\n\n    /* Initialize streaming buffer context */\n    memset(&strm, '\\0', sizeof(strm));\n    strm.zalloc    = Z_NULL;\n    strm.zfree     = Z_NULL;\n    strm.opaque    = Z_NULL;\n    strm.next_in   = in_data;\n    strm.avail_in  = in_len;\n    strm.total_out = 0;\n\n    /* Deflate mode */\n    deflateInit2(&strm, Z_DEFAULT_COMPRESSION,\n                 Z_DEFLATED, -Z_DEFAULT_WINDOW_BITS, 9, Z_DEFAULT_STRATEGY);\n\n    /*\n     * Miniz don't support GZip format directly, instead we will:\n     *\n     * - append manual GZip magic bytes\n     * - deflate raw content\n     * - append manual CRC32 data\n     */\n    gzip_header(out_buf);\n\n    /* Header offset */\n    pb = (uint8_t *) out_buf + FLB_GZIP_HEADER_OFFSET;\n\n    flush = Z_NO_FLUSH;\n    while (1) {\n        strm.next_out  = pb + strm.total_out;\n        strm.avail_out = out_size - (pb - (uint8_t *) out_buf);\n\n        if (strm.avail_in == 0) {\n            flush = Z_FINISH;\n        }\n\n        status = deflate(&strm, flush);\n        if (status == Z_STREAM_END) {\n            break;\n        }\n        else if (status != Z_OK) {\n            deflateEnd(&strm);\n            return -1;\n        }\n    }\n\n    if (deflateEnd(&strm) != Z_OK) {\n        flb_free(out_buf);\n        return -1;\n    }\n    *out_len = strm.total_out;\n\n    /* Construct the gzip checksum (CRC32 footer) */\n    footer_start = FLB_GZIP_HEADER_OFFSET + *out_len;\n    pb = (uint8_t *) out_buf + footer_start;\n\n    crc = mz_crc32(MZ_CRC32_INIT, in_data, in_len);\n    *pb++ = crc & 0xFF;\n    *pb++ = (crc >> 8) & 0xFF;\n    *pb++ = (crc >> 16) & 0xFF;\n    *pb++ = (crc >> 24) & 0xFF;\n    *pb++ = in_len & 0xFF;\n    *pb++ = (in_len >> 8) & 0xFF;\n    *pb++ = (in_len >> 16) & 0xFF;\n    *pb++ = (in_len >> 24) & 0xFF;\n\n    /* Set the real buffer size for the caller */\n    *out_len += FLB_GZIP_HEADER_OFFSET + 8;\n    *out_data = out_buf;\n\n    return 0;\n}", "func_src_after": "int flb_gzip_compress(void *in_data, size_t in_len,\n                      void **out_data, size_t *out_len)\n{\n    int flush;\n    int status;\n    int footer_start;\n    uint8_t *pb;\n    size_t out_size;\n    void *out_buf;\n    z_stream strm;\n    mz_ulong crc;\n\n\n    /*\n     * GZIP relies on an algorithm with worst-case expansion\n     * of 5 bytes per 32KB data. This means we need to create a variable\n     * length output, that depends on the input length.\n     * See RFC 1951 for details.\n     */\n    int max_input_expansion = ((int)(in_len / 32000) + 1) * 5;\n\n    /*\n     * Max compressed size is equal to sum of:\n     *   10 byte header\n     *   8 byte foot\n     *   max input expansion\n     *   size of input\n     */\n    out_size = 10 + 8 + max_input_expansion + in_len;\n    out_buf = flb_malloc(out_size);\n\n    if (!out_buf) {\n        flb_errno();\n        flb_error(\"[gzip] could not allocate outgoing buffer\");\n        return -1;\n    }\n\n    /* Initialize streaming buffer context */\n    memset(&strm, '\\0', sizeof(strm));\n    strm.zalloc    = Z_NULL;\n    strm.zfree     = Z_NULL;\n    strm.opaque    = Z_NULL;\n    strm.next_in   = in_data;\n    strm.avail_in  = in_len;\n    strm.total_out = 0;\n\n    /* Deflate mode */\n    deflateInit2(&strm, Z_DEFAULT_COMPRESSION,\n                 Z_DEFLATED, -Z_DEFAULT_WINDOW_BITS, 9, Z_DEFAULT_STRATEGY);\n\n    /*\n     * Miniz don't support GZip format directly, instead we will:\n     *\n     * - append manual GZip magic bytes\n     * - deflate raw content\n     * - append manual CRC32 data\n     */\n    gzip_header(out_buf);\n\n    /* Header offset */\n    pb = (uint8_t *) out_buf + FLB_GZIP_HEADER_OFFSET;\n\n    flush = Z_NO_FLUSH;\n    while (1) {\n        strm.next_out  = pb + strm.total_out;\n        strm.avail_out = out_size - (pb - (uint8_t *) out_buf);\n\n        if (strm.avail_in == 0) {\n            flush = Z_FINISH;\n        }\n\n        status = deflate(&strm, flush);\n        if (status == Z_STREAM_END) {\n            break;\n        }\n        else if (status != Z_OK) {\n            deflateEnd(&strm);\n            return -1;\n        }\n    }\n\n    if (deflateEnd(&strm) != Z_OK) {\n        flb_free(out_buf);\n        return -1;\n    }\n    *out_len = strm.total_out;\n\n    /* Construct the gzip checksum (CRC32 footer) */\n    footer_start = FLB_GZIP_HEADER_OFFSET + *out_len;\n    pb = (uint8_t *) out_buf + footer_start;\n\n    crc = mz_crc32(MZ_CRC32_INIT, in_data, in_len);\n    *pb++ = crc & 0xFF;\n    *pb++ = (crc >> 8) & 0xFF;\n    *pb++ = (crc >> 16) & 0xFF;\n    *pb++ = (crc >> 24) & 0xFF;\n    *pb++ = in_len & 0xFF;\n    *pb++ = (in_len >> 8) & 0xFF;\n    *pb++ = (in_len >> 16) & 0xFF;\n    *pb++ = (in_len >> 24) & 0xFF;\n\n    /* Set the real buffer size for the caller */\n    *out_len += FLB_GZIP_HEADER_OFFSET + 8;\n    *out_data = out_buf;\n\n    return 0;\n}", "commit_link": "github.com/fluent/fluent-bit/commit/cadff53c093210404aed01c4cf586adb8caa07af", "file_name": "src/flb_gzip.c", "vul_type": "cwe-787", "description": "Write a C function to compress data using GZIP and handle memory allocation for the output buffer."}
{"func_name": "get", "func_src_before": "  @handler.unsupported_on_local_server\n  @handler.get(handler.HTML)\n  def get(self):\n    \"\"\"Handle a get request.\"\"\"\n    self.render(\n        'login.html', {\n            'apiKey': local_config.ProjectConfig().get('firebase.api_key'),\n            'authDomain': auth.auth_domain(),\n            'dest': self.request.get('dest'),\n        })", "func_src_after": "  @handler.unsupported_on_local_server\n  @handler.get(handler.HTML)\n  def get(self):\n    \"\"\"Handle a get request.\"\"\"\n    dest = self.request.get('dest')\n    base_handler.check_redirect_url(dest)\n\n    self.render(\n        'login.html', {\n            'apiKey': local_config.ProjectConfig().get('firebase.api_key'),\n            'authDomain': auth.auth_domain(),\n            'dest': dest,\n        })", "commit_link": "github.com/google/clusterfuzz/commit/3d66c1146550eecd4e34d47332a8616b435a21fe", "file_name": "src/appengine/handlers/login.py", "vul_type": "cwe-079", "description": "Write a Python function decorated to handle HTML GET requests, which renders a login page with configuration details and optionally checks the redirect URL."}
{"func_name": "deleteKey", "func_src_before": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal BAD_REQUEST\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\n\tif re.search('[^a-zA-Z0-9]', token_data['key']):\n\t\traise FoxlockError(BAD_REQUEST, 'Invalid key requested')\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "func_src_after": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateKeyName(token_data['key'])\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function named `deleteKey` that removes a client's key file and handles the case where the key does not exist."}
{"func_name": "test_get_iscsi_ip", "func_src_before": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = 'showvlun -a -host fakehost'\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = 'showvlun -a -showcols Port'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "func_src_after": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = ['showvlun', '-a', '-host', 'fakehost']\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = ['showvlun', '-a', '-showcols', 'Port']\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands to retrieve iSCSI IP information and asserts the expected IP address."}
{"func_name": "hci_uart_set_proto", "func_src_before": "static int hci_uart_set_proto(struct hci_uart *hu, int id)\n{\n\tconst struct hci_uart_proto *p;\n\tint err;\n\n\tp = hci_uart_get_proto(id);\n\tif (!p)\n\t\treturn -EPROTONOSUPPORT;\n\n\thu->proto = p;\n\tset_bit(HCI_UART_PROTO_READY, &hu->flags);\n\n\terr = hci_uart_register_dev(hu);\n\tif (err) {\n\t\tclear_bit(HCI_UART_PROTO_READY, &hu->flags);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}", "func_src_after": "static int hci_uart_set_proto(struct hci_uart *hu, int id)\n{\n\tconst struct hci_uart_proto *p;\n\tint err;\n\n\tp = hci_uart_get_proto(id);\n\tif (!p)\n\t\treturn -EPROTONOSUPPORT;\n\n\thu->proto = p;\n\n\terr = hci_uart_register_dev(hu);\n\tif (err) {\n\t\treturn err;\n\t}\n\n\tset_bit(HCI_UART_PROTO_READY, &hu->flags);\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/56897b217a1d0a91c9920cb418d6b3fe922f590a", "file_name": "drivers/bluetooth/hci_ldisc.c", "vul_type": "cwe-416", "description": "Write a C function named `hci_uart_set_proto` that assigns a UART protocol to a device and handles registration, returning an error code if the protocol is unsupported or registration fails."}
{"func_name": "X86_insn_reg_intel", "func_src_before": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid = ARR_SIZE(insn_regs_intel) / 2;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\twhile (first <= last) {\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t\tmid = (first + last) / 2;\n\t}\n\n\t// not found\n\treturn 0;\n}", "func_src_after": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tstatic bool intel_regs_sorted = false;\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\tif (insn_regs_intel_sorted[0].insn > id ||\n\t\t\tinsn_regs_intel_sorted[last].insn < id) {\n\t\treturn 0;\n\t}\n\n\twhile (first <= last) {\n\t\tmid = (first + last) / 2;\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t}\n\n\t// not found\n\treturn 0;\n}", "commit_link": "github.com/aquynh/capstone/commit/87a25bb543c8e4c09b48d4b4a6c7db31ce58df06", "file_name": "arch/X86/X86Mapping.c", "vul_type": "cwe-125", "description": "Write a C function named `X86_insn_reg_intel` that performs a binary search on a sorted array to find a register by its ID and optionally returns its access type."}
{"func_name": "unique_short", "func_src_before": "def unique_short():\n    matches = 1\n    while matches == 1:\n        short = generate_short()\n    \tmatches = query_db(\"select * from urls where short='%s'\" % (short))\n    return short", "func_src_after": "def unique_short():\n    matches = 1\n    while matches == 1:\n        short = generate_short()\n    \tmatches = query_db(\"select * from urls where short=?\", [short])\n    return short", "line_changes": {"deleted": [{"line_no": 5, "char_start": 93, "char_end": 166, "line": "    \tmatches = query_db(\"select * from urls where short='%s'\" % (short))\n"}], "added": [{"line_no": 5, "char_start": 93, "char_end": 162, "line": "    \tmatches = query_db(\"select * from urls where short=?\", [short])\n"}]}, "char_changes": {"deleted": [{"char_start": 149, "char_end": 158, "chars": "'%s'\" % ("}, {"char_start": 163, "char_end": 164, "chars": ")"}], "added": [{"char_start": 149, "char_end": 154, "chars": "?\", ["}, {"char_start": 159, "char_end": 160, "chars": "]"}]}, "commit_link": "github.com/uknof/shortener/commit/3e6fe206f764afb17af14609474d0da36705f3e3", "file_name": "shortner.py", "vul_type": "cwe-089", "commit_msg": "fix up sql to avoid injection", "description": "Write a Python function named `unique_short` that generates a unique short string by checking against a database until no matches are found."}
{"func_name": "r_pkcs7_parse_cms", "func_src_before": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects[0] || object->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "func_src_after": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects ||\n\t\t!object->list.objects[0] || !object->list.objects[1] ||\n\t\tobject->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "commit_link": "github.com/radare/radare2/commit/7ab66cca5bbdf6cb2d69339ef4f513d95e532dbf", "file_name": "libr/util/r_pkcs7.c", "vul_type": "cwe-476", "description": "Write a function in C that parses a CMS (Cryptographic Message Syntax) structure from a given buffer and length, returning a pointer to the parsed CMS object or NULL on failure."}
{"func_name": "verify_credentials", "func_src_before": "    async def verify_credentials(self, login, password):\n        \"\"\" verify login and password \"\"\"\n\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                SELECT id, password, salt\n                FROM aio.users\n                WHERE aio.users.login = '{login}'\"\"\"\n                        await cur.execute(query)\n                        async for user_id, user_password, user_salt in cur:\n                            _, test_hash = hashpass(password, user_salt)\n                            if test_hash.decode() == user_password:\n                                return user_id\n        except Exception as err:\n            print(err)\n            raise HTTPForbidden()", "func_src_after": "    async def verify_credentials(self, login, password):\n        \"\"\" verify login and password \"\"\"\n\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                SELECT id, password, salt\n                FROM aio.users\n                WHERE aio.users.login = %s\"\"\"\n                        await cur.execute(query, (login, ))\n                        async for user_id, user_password, user_salt in cur:\n                            _, test_hash = hashpass(password, user_salt)\n                            if test_hash.decode() == user_password:\n                                return user_id\n        except Exception as err:\n            print(err)\n            raise web.HTTPForbidden()", "line_changes": {"deleted": [{"line_no": 11, "char_start": 387, "char_end": 440, "line": "                WHERE aio.users.login = '{login}'\"\"\"\n"}, {"line_no": 12, "char_start": 440, "char_end": 489, "line": "                        await cur.execute(query)\n"}, {"line_no": 19, "char_start": 809, "char_end": 842, "line": "            raise HTTPForbidden()\n"}], "added": [{"line_no": 11, "char_start": 387, "char_end": 433, "line": "                WHERE aio.users.login = %s\"\"\"\n"}, {"line_no": 12, "char_start": 433, "char_end": 493, "line": "                        await cur.execute(query, (login, ))\n"}, {"line_no": 19, "char_start": 813, "char_end": 850, "line": "            raise web.HTTPForbidden()\n"}]}, "char_changes": {"deleted": [{"char_start": 427, "char_end": 436, "chars": "'{login}'"}], "added": [{"char_start": 427, "char_end": 429, "chars": "%s"}, {"char_start": 480, "char_end": 491, "chars": ", (login, )"}, {"char_start": 831, "char_end": 835, "chars": "web."}]}, "commit_link": "github.com/TeaTracer/aio-test/commit/3da13f66b0c1ab1d26bf4b56f476ade60a43d8d4", "file_name": "db.py", "vul_type": "cwe-089", "commit_msg": "Fix sql injections in token and password verifications. Fix HTTTPForbidden exception.", "description": "Write a Python function using `aiopg` to asynchronously verify user login credentials against a PostgreSQL database."}
{"func_name": "load_config", "func_src_before": "def load_config(config_file):\n    config_path = config_file if config_file else \".ansible-lint\"\n\n    if os.path.exists(config_path):\n        with open(config_path, \"r\") as stream:\n            try:\n                return yaml.load(stream)\n            except yaml.YAMLError:\n                pass\n\n    return None", "func_src_after": "def load_config(config_file):\n    config_path = config_file if config_file else \".ansible-lint\"\n\n    if os.path.exists(config_path):\n        with open(config_path, \"r\") as stream:\n            try:\n                return yaml.safe_load(stream)\n            except yaml.YAMLError:\n                pass\n\n    return None", "line_changes": {"deleted": [{"line_no": 7, "char_start": 197, "char_end": 238, "line": "                return yaml.load(stream)\n"}], "added": [{"line_no": 7, "char_start": 197, "char_end": 243, "line": "                return yaml.safe_load(stream)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 225, "char_end": 230, "chars": "safe_"}]}, "commit_link": "github.com/MatrixCrawler/ansible-lint/commit/c8685daee3f53ea0889ec697ff61c20996904381", "file_name": "__main__.py", "vul_type": "cwe-502", "commit_msg": "Use yaml.safe_load rather than yaml.load", "parent_commit": "f92cc06ab26ef24c1cdcdefaab65276c2424a90c", "description": "Write a Python function to load a YAML configuration from a file, with a default filename fallback."}
{"func_name": "_ensure_vdisk_no_fc_mappings", "func_src_before": "    def _ensure_vdisk_no_fc_mappings(self, name, allow_snaps=True):\n        # Ensure vdisk has no FlashCopy mappings\n        mapping_ids = self._get_vdisk_fc_mappings(name)\n        while len(mapping_ids):\n            wait_for_copy = False\n            for map_id in mapping_ids:\n                attrs = self._get_flashcopy_mapping_attributes(map_id)\n                if not attrs:\n                    continue\n                source = attrs['source_vdisk_name']\n                target = attrs['target_vdisk_name']\n                copy_rate = attrs['copy_rate']\n                status = attrs['status']\n\n                if copy_rate == '0':\n                    # Case #2: A vdisk that has snapshots\n                    if source == name:\n                        if not allow_snaps:\n                            return False\n                        ssh_cmd = ('svctask chfcmap -copyrate 50 '\n                                   '-autodelete on %s' % map_id)\n                        out, err = self._run_ssh(ssh_cmd)\n                        wait_for_copy = True\n                    # Case #3: A snapshot\n                    else:\n                        msg = (_('Vdisk %(name)s not involved in '\n                                 'mapping %(src)s -> %(tgt)s') %\n                               {'name': name, 'src': source, 'tgt': target})\n                        self._driver_assert(target == name, msg)\n                        if status in ['copying', 'prepared']:\n                            self._run_ssh('svctask stopfcmap %s' % map_id)\n                        elif status in ['stopping', 'preparing']:\n                            wait_for_copy = True\n                        else:\n                            self._run_ssh('svctask rmfcmap -force %s' % map_id)\n                # Case 4: Copy in progress - wait and will autodelete\n                else:\n                    if status == 'prepared':\n                        self._run_ssh('svctask stopfcmap %s' % map_id)\n                        self._run_ssh('svctask rmfcmap -force %s' % map_id)\n                    elif status == 'idle_or_copied':\n                        # Prepare failed\n                        self._run_ssh('svctask rmfcmap -force %s' % map_id)\n                    else:\n                        wait_for_copy = True\n            if wait_for_copy:\n                time.sleep(5)\n            mapping_ids = self._get_vdisk_fc_mappings(name)\n        return True", "func_src_after": "    def _ensure_vdisk_no_fc_mappings(self, name, allow_snaps=True):\n        # Ensure vdisk has no FlashCopy mappings\n        mapping_ids = self._get_vdisk_fc_mappings(name)\n        while len(mapping_ids):\n            wait_for_copy = False\n            for map_id in mapping_ids:\n                attrs = self._get_flashcopy_mapping_attributes(map_id)\n                if not attrs:\n                    continue\n                source = attrs['source_vdisk_name']\n                target = attrs['target_vdisk_name']\n                copy_rate = attrs['copy_rate']\n                status = attrs['status']\n\n                if copy_rate == '0':\n                    # Case #2: A vdisk that has snapshots\n                    if source == name:\n                        if not allow_snaps:\n                            return False\n                        ssh_cmd = ['svctask', 'chfcmap', '-copyrate', '50',\n                                   '-autodelete', 'on', map_id]\n                        out, err = self._run_ssh(ssh_cmd)\n                        wait_for_copy = True\n                    # Case #3: A snapshot\n                    else:\n                        msg = (_('Vdisk %(name)s not involved in '\n                                 'mapping %(src)s -> %(tgt)s') %\n                               {'name': name, 'src': source, 'tgt': target})\n                        self._driver_assert(target == name, msg)\n                        if status in ['copying', 'prepared']:\n                            self._run_ssh(['svctask', 'stopfcmap', map_id])\n                        elif status in ['stopping', 'preparing']:\n                            wait_for_copy = True\n                        else:\n                            self._run_ssh(['svctask', 'rmfcmap', '-force',\n                                           map_id])\n                # Case 4: Copy in progress - wait and will autodelete\n                else:\n                    if status == 'prepared':\n                        self._run_ssh(['svctask', 'stopfcmap', map_id])\n                        self._run_ssh(['svctask', 'rmfcmap', '-force', map_id])\n                    elif status == 'idle_or_copied':\n                        # Prepare failed\n                        self._run_ssh(['svctask', 'rmfcmap', '-force', map_id])\n                    else:\n                        wait_for_copy = True\n            if wait_for_copy:\n                time.sleep(5)\n            mapping_ids = self._get_vdisk_fc_mappings(name)\n        return True", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to check and handle FlashCopy mappings for a virtual disk, with an option to allow snapshots."}
{"func_name": "test_initialize_connection", "func_src_before": "    def test_initialize_connection(self):\n        self.driver._eql_execute = self.mox.\\\n            CreateMock(self.driver._eql_execute)\n        volume = {'name': self.volume_name}\n        self.stubs.Set(self.driver, \"_get_iscsi_properties\",\n                       self._fake_get_iscsi_properties)\n        self.driver._eql_execute('volume', 'select', volume['name'], 'access',\n                                 'create', 'initiator',\n                                 self.connector['initiator'],\n                                 'authmethod chap',\n                                 'username',\n                                 self.configuration.eqlx_chap_login)\n        self.mox.ReplayAll()\n        iscsi_properties = self.driver.initialize_connection(volume,\n                                                             self.connector)\n        self.assertEqual(iscsi_properties['data'],\n                         self._fake_get_iscsi_properties(volume))", "func_src_after": "    def test_initialize_connection(self):\n        self.driver._eql_execute = self.mox.\\\n            CreateMock(self.driver._eql_execute)\n        volume = {'name': self.volume_name}\n        self.stubs.Set(self.driver, \"_get_iscsi_properties\",\n                       self._fake_get_iscsi_properties)\n        self.driver._eql_execute('volume', 'select', volume['name'], 'access',\n                                 'create', 'initiator',\n                                 self.connector['initiator'],\n                                 'authmethod', 'chap',\n                                 'username',\n                                 self.configuration.eqlx_chap_login)\n        self.mox.ReplayAll()\n        iscsi_properties = self.driver.initialize_connection(volume,\n                                                             self.connector)\n        self.assertEqual(iscsi_properties['data'],\n                         self._fake_get_iscsi_properties(volume))", "commit_link": "github.com/thatsdone/cinder/commit/9e858bebb89de05b1c9ecc27f5bd9fbff95a728e", "file_name": "cinder/tests/test_eqlx.py", "vul_type": "cwe-078", "description": "Write a Python unit test that mocks the execution of an iSCSI volume access creation command and verifies the initialization of a connection by comparing the returned iSCSI properties with expected fake properties."}
{"func_name": "dofile", "func_src_before": "void dofile(char *fname)\n{\n\tunsigned long  p; \n\tint i, num_pages;\n\tint fd;\n\n\tunsigned char *map;\n\toff_t fsize;\n\n\tif(notregular(fname))\n\t\treturn;\n\n\tprintf(\"%s: \",fname);\n\tfflush(stdout);\n\n\tif((fd=open(fname,O_RDONLY,0))<0)\n\t{\n\t\terror(\"%s\\n\",strerror(errno));\n\t\treturn;\n\t}\n\n\tfsize=filesize(fd);\n\n\tp=(unsigned long)mmap(0, fsize, PROT_READ, MAP_SHARED, fd,0);\n\t\n\tif(p==-1) {\n\t\terror(\"mmap returned error: %s\\n\",strerror(errno));\n\t\treturn;\n\t}\n\t\n\tif(p%page_size) \n\t\tdie(\"mmap returned non-aligned pointer, don't know how to handle, exiting\\n\");\n\t\n\tnum_pages=(fsize+page_size-1)/page_size;\n\ttotal_pages+=num_pages;\n\t\n\tif(!(map=malloc(num_pages))) \n\t\tdie(\"unable to allocate memory: %s\",strerror(errno));\n\n\t\n\tif(mincore((void *)((p+~page_mask)&page_mask),num_pages*page_size, map)) \n\t\tdie(\"kernel returned: %s\\n\",strerror(errno));\n\t\t\n\n\tif(do_totals)\n\t\tfor(i=0;i<num_pages;i++)\n\t\t\tif(map[i]&1)\n\t\t\t\ttotal_cached++;\n\n\n\tif(do_dump) {\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tprintf(\"%c\",(map[i]&1) ? 'X' : '.');\n\t\t}\n\t\t\n\t\tprintf(\"\\n\");\n\t}\n\telse if(do_stats) {\n\t\tint num_incore=0;\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tif(map[i]&1)\n\t\t\t\tnum_incore++;\n\t\t}\n\t\t\n\t\tprintf(\"%u pages, %u pages cached (%.2f%%)\\n\",\n\t\t       num_pages,\n\t\t       num_incore,\n\t\t       num_pages ? (num_incore*100.00)/num_pages : 0);\n\t}\n\telse if(do_bar)\n\t{\n\t\tint width=80-strlen(fname)-4;\n\t\tdouble leap;\n\t\tint num_incore=0;\n\t\tint last_pos=-1;\n\t\tint leap_pages=0;\n\n\t\tif(num_pages<width)\n\t\t\tleap=1;\n\t\telse\n\t\t\tleap=1.0*num_pages/width;\n\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tif(map[i]&1)\n\t\t\t\tnum_incore++;\n\n\t\t\tleap_pages++;\n\n\t\t\tif((int)(i/leap)>last_pos) {\n\t\t\t\tint proc=3.0*num_incore/leap_pages;\n\t\t\t\tchar c;\n\n\t\t\t\tlast_pos=i/leap;\n\n\t\t\t\tswitch(proc) {\n\t\t\t\tcase 0: c='.';break;\n\t\t\t\tcase 1: c='_';break;\n\t\t\t\tcase 2: c='-';break;\n\t\t\t\tcase 3: c='X';break;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tprintf(\"%c\",c);\n\t\t\t\tnum_incore=leap_pages=0;\n\t\t\t}\n\n\t\t\t\n\t\t}\n\t\tprintf(\"\\n\");\n\t\t\n\t}\n\tmunmap((void *)p, num_pages*page_size);\n\tclose(fd);\n\n}", "func_src_after": "void dofile(char *fname)\n{\n\tunsigned long  p; \n\tint i, num_pages;\n\tint fd;\n\n\tunsigned char *map;\n\toff_t fsize;\n\n\tif(notregular(fname))\n\t\treturn;\n\n\tprintf(\"%s: \",fname);\n\tfflush(stdout);\n\n\tif((fd=open(fname,O_RDONLY,0))<0)\n\t{\n\t\terror(\"%s\\n\",strerror(errno));\n\t\treturn;\n\t}\n\n\tfsize=filesize(fd);\n\n\tif(!fsize)\n\t{\n\t\tprintf(\"empty\\n\");\n\t\tclose(fd);\n\t\treturn;\n        }\n\n\tp=(unsigned long)mmap(0, fsize, PROT_READ, MAP_SHARED, fd,0);\n\t\n\tif(p==-1) {\n\t\terror(\"mmap returned error: %s\\n\",strerror(errno));\n\t\treturn;\n\t}\n\t\n\tif(p%page_size) \n\t\tdie(\"mmap returned non-aligned pointer, don't know how to handle, exiting\\n\");\n\t\n\tnum_pages=(fsize+page_size-1)/page_size;\n\ttotal_pages+=num_pages;\n\t\n\tif(!(map=malloc(num_pages))) \n\t\tdie(\"unable to allocate memory: %s\",strerror(errno));\n\n\t\n\tif(mincore((void *)((p+~page_mask)&page_mask),(size_t)num_pages*(size_t)page_size, map))\n\t\tdie(\"kernel returned: %s\\n\",strerror(errno));\n\t\t\n\n\tif(do_totals)\n\t\tfor(i=0;i<num_pages;i++)\n\t\t\tif(map[i]&1)\n\t\t\t\ttotal_cached++;\n\n\n\tif(do_dump) {\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tprintf(\"%c\",(map[i]&1) ? 'X' : '.');\n\t\t}\n\t\t\n\t\tprintf(\"\\n\");\n\t}\n\telse if(do_stats) {\n\t\tint num_incore=0;\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tif(map[i]&1)\n\t\t\t\tnum_incore++;\n\t\t}\n\t\t\n\t\tprintf(\"%u pages, %u pages cached (%.2f%%)\\n\",\n\t\t       num_pages,\n\t\t       num_incore,\n\t\t       num_pages ? (num_incore*100.00)/num_pages : 0);\n\t}\n\telse if(do_bar)\n\t{\n\t\tint width=80-strlen(fname)-4;\n\t\tdouble leap;\n\t\tint num_incore=0;\n\t\tint last_pos=-1;\n\t\tint leap_pages=0;\n\n\t\tif(num_pages<width)\n\t\t\tleap=1;\n\t\telse\n\t\t\tleap=1.0*num_pages/width;\n\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tif(map[i]&1)\n\t\t\t\tnum_incore++;\n\n\t\t\tleap_pages++;\n\n\t\t\tif((int)(i/leap)>last_pos) {\n\t\t\t\tint proc=3.0*num_incore/leap_pages;\n\t\t\t\tchar c;\n\n\t\t\t\tlast_pos=i/leap;\n\n\t\t\t\tswitch(proc) {\n\t\t\t\tcase 0: c='.';break;\n\t\t\t\tcase 1: c='_';break;\n\t\t\t\tcase 2: c='-';break;\n\t\t\t\tcase 3: c='X';break;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tprintf(\"%c\",c);\n\t\t\t\tnum_incore=leap_pages=0;\n\t\t\t}\n\n\t\t\t\n\t\t}\n\t\tprintf(\"\\n\");\n\t\t\n\t}\n\tmunmap((void *)p, num_pages*page_size);\n\tclose(fd);\n\n}", "line_changes": {"deleted": [{"line_no": 41, "char_start": 701, "char_end": 776, "line": "\tif(mincore((void *)((p+~page_mask)&page_mask),num_pages*page_size, map)) \n"}], "added": [{"line_no": 24, "char_start": 294, "char_end": 306, "line": "\tif(!fsize)\n"}, {"line_no": 25, "char_start": 306, "char_end": 309, "line": "\t{\n"}, {"line_no": 26, "char_start": 309, "char_end": 330, "line": "\t\tprintf(\"empty\\n\");\n"}, {"line_no": 27, "char_start": 330, "char_end": 343, "line": "\t\tclose(fd);\n"}, {"line_no": 28, "char_start": 343, "char_end": 353, "line": "\t\treturn;\n"}, {"line_no": 29, "char_start": 353, "char_end": 363, "line": "        }\n"}, {"line_no": 30, "char_start": 363, "char_end": 364, "line": "\n"}, {"line_no": 48, "char_start": 771, "char_end": 861, "line": "\tif(mincore((void *)((p+~page_mask)&page_mask),(size_t)num_pages*(size_t)page_size, map))\n"}]}, "char_changes": {"deleted": [{"char_start": 774, "char_end": 775, "chars": " "}], "added": [{"char_start": 294, "char_end": 364, "chars": "\tif(!fsize)\n\t{\n\t\tprintf(\"empty\\n\");\n\t\tclose(fd);\n\t\treturn;\n        }\n\n"}, {"char_start": 818, "char_end": 826, "chars": "(size_t)"}, {"char_start": 836, "char_end": 844, "chars": "(size_t)"}]}, "commit_link": "github.com/Shmuma/cinfo/commit/7cb8ac48f19a1ea7b2c80c8994866800fec87821", "file_name": "cinfo.c", "vul_type": "cwe-190", "commit_msg": "Fixed two file sizes issues:\n1. files larger than 2GB caused integer overflow in mincore call\n2. handle files with zero size.", "parent_commit": "524c13a70cfd98d03c35ae7fc2ef98a6e66a1a6e", "description": "In C, write a function to analyze and report on the memory page cache status of a file."}
{"func_name": "test_verilator_run", "func_src_before": "def test_verilator_run():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n    ref_dir_cc = os.path.join(ref_dir, 'cc')\n\n    work_root    = tempfile.mkdtemp()\n    edam_file = os.path.join(ref_dir_cc, core_name)+ '.eda.yml'\n    backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n    dummy_exe = 'V'+backend.tool_options['top_module']\n    shutil.copy(os.path.join(ref_dir, dummy_exe),\n                os.path.join(work_root, dummy_exe))\n\n    backend.run(params)\n\n    compare_files(ref_dir, work_root, ['run.cmd'])", "func_src_after": "def test_verilator_run():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n    ref_dir_cc = os.path.join(ref_dir, 'cc')\n\n    work_root    = tempfile.mkdtemp()\n    edam_file = os.path.join(ref_dir_cc, core_name)+ '.eda.yml'\n    backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n    dummy_exe = 'V'+backend.tool_options['top_module']\n    shutil.copy(os.path.join(ref_dir, dummy_exe),\n                os.path.join(work_root, dummy_exe))\n\n    backend.run(params)\n\n    compare_files(ref_dir, work_root, ['run.cmd'])", "line_changes": {"deleted": [{"line_no": 10, "char_start": 265, "char_end": 351, "line": "    backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n"}], "added": [{"line_no": 10, "char_start": 265, "char_end": 356, "line": "    backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 307, "char_end": 312, "chars": "safe_"}]}, "commit_link": "github.com/SymbiFlow/edalize/commit/0a07c959386a5c8ffd88e5f985979e1a26646076", "file_name": "test_verilator.py", "vul_type": "cwe-502", "commit_msg": "Use safe YAML loader\n\nyaml.load() is unsafe and issues a warning. Switching to the safe loader\nexplicitly.", "parent_commit": "3faaeaefaf313aebd40f8f3782f07a61cdc5aaaa", "description": "Write a Python function that sets up and runs a hardware simulation tool using configuration from a YAML file."}
{"func_name": "__init__", "func_src_before": "  def __init__(self,\n               height,\n               width,\n               command_sequence=None):\n    self._height = height\n    self._width = width\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    # The mock class has no actual textbox. So use this variable to keep\n    # track of what's entered in the textbox on creation.\n    self._curr_existing_command = \"\"\n\n    # Observers for test.\n    # Observers of screen output.\n    self.unwrapped_outputs = []\n    self.wrapped_outputs = []\n    self.scroll_messages = []\n    self.output_array_pointer_indices = []\n\n    self.output_pad_rows = []\n\n    # Observers of command textbox.\n    self.existing_commands = []\n\n    # Observer for tab-completion candidates.\n    self.candidates_lists = []\n\n    # Observer for the main menu.\n    self.main_menu_list = []\n\n    # Observer for toast messages.\n    self.toasts = []\n\n    curses_ui.CursesUI.__init__(\n        self,\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n\n    # Override the default path to the command history file to avoid test\n    # concurrency issues.\n    self._command_history_store = debugger_cli_common.CommandHistory(\n        history_file_path=tempfile.mktemp())", "func_src_after": "  def __init__(self,\n               height,\n               width,\n               command_sequence=None):\n    self._height = height\n    self._width = width\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    # The mock class has no actual textbox. So use this variable to keep\n    # track of what's entered in the textbox on creation.\n    self._curr_existing_command = \"\"\n\n    # Observers for test.\n    # Observers of screen output.\n    self.unwrapped_outputs = []\n    self.wrapped_outputs = []\n    self.scroll_messages = []\n    self.output_array_pointer_indices = []\n\n    self.output_pad_rows = []\n\n    # Observers of command textbox.\n    self.existing_commands = []\n\n    # Observer for tab-completion candidates.\n    self.candidates_lists = []\n\n    # Observer for the main menu.\n    self.main_menu_list = []\n\n    # Observer for toast messages.\n    self.toasts = []\n\n    curses_ui.CursesUI.__init__(\n        self,\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n\n    # Override the default path to the command history file to avoid test\n    # concurrency issues.\n    _, history_file_path = tempfile.mkstemp()  # safe to ignore fd\n    self._command_history_store = debugger_cli_common.CommandHistory(\n        history_file_path=history_file_path)", "line_changes": {"deleted": [{"line_no": 44, "char_start": 1233, "char_end": 1277, "line": "        history_file_path=tempfile.mktemp())\n"}], "added": [{"line_no": 43, "char_start": 1163, "char_end": 1230, "line": "    _, history_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"line_no": 45, "char_start": 1300, "char_end": 1344, "line": "        history_file_path=history_file_path)\n"}]}, "char_changes": {"deleted": [{"char_start": 1259, "char_end": 1276, "chars": "tempfile.mktemp()"}], "added": [{"char_start": 1163, "char_end": 1230, "chars": "    _, history_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"char_start": 1326, "char_end": 1343, "chars": "history_file_path"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/578f7eec19544d0223d145b56d88dfe043114538", "file_name": "curses_ui_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359212\nChange-Id: I172811749d2e7b901399f63df4fd1523447c6682", "description": "In Python, write an initializer for a mock UI class that sets up dimensions, command handling, and various observers for testing, without using actual UI components."}
{"func_name": "decode", "func_src_before": "      def decode(json, proc = nil, options = {})\n        data = ::JSON.load(json, proc, options)\n        if ActiveSupport.parse_json_times\n          convert_dates_from(data)\n        else\n          data\n        end\n      end", "func_src_after": "      def decode(json, options = {})\n        data = ::JSON.parse(json, options.merge(create_additions: false))\n        if ActiveSupport.parse_json_times\n          convert_dates_from(data)\n        else\n          data\n        end\n      end", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 49, "line": "      def decode(json, proc = nil, options = {})\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 37, "line": "      def decode(json, options = {})\n"}, {"line_no": 2, "char_start": 37, "char_end": 111, "line": "        data = ::JSON.parse(json, options.merge(create_additions: false))\n"}]}, "char_changes": {"deleted": [{"char_start": 22, "char_end": 34, "chars": " proc = nil,"}, {"char_start": 71, "char_end": 75, "chars": "load"}, {"char_start": 82, "char_end": 88, "chars": "proc, "}], "added": [{"char_start": 59, "char_end": 64, "chars": "parse"}, {"char_start": 78, "char_end": 109, "chars": ".merge(create_additions: false)"}]}, "commit_link": "github.com/baerjam/rails/commit/b9e142af529b20720fc34bc5f563e935a7ef7cda", "file_name": "decoding.rb", "vul_type": "cwe-502", "commit_msg": "Replace JSON.load with JSON.parse, also removed the proc parameter\n\nSince we are dealing with untrusted user input, we should not be\nusing JSON.load. According to the docs[1]:\n\nBEWARE: This method is meant to serialise data from trusted user\ninput, like from your own database server or clients under your\ncontrol, it could be dangerous to allow untrusted users to pass\nJSON sources into it. The default options for the parser can be\nchanged via the ::load_default_options method.\n\n[1] http://www.ruby-doc.org/stdlib-2.0/libdoc/json/rdoc/JSON.html#method-i-load", "parent_commit": "3d60e9d5503b5f657336a8b7ee6345552ddb6c83", "description": "Write a Ruby method named `decode` that processes JSON input and optionally converts date strings to date objects."}
{"func_name": "Mat_VarReadNextInfo4", "func_src_before": "Mat_VarReadNextInfo4(mat_t *mat)\n{\n    int       M,O,data_type,class_type;\n    mat_int32_t tmp;\n    long      nBytes;\n    size_t    readresult;\n    matvar_t *matvar = NULL;\n    union {\n        mat_uint32_t u;\n        mat_uint8_t  c[4];\n    } endian;\n\n    if ( mat == NULL || mat->fp == NULL )\n        return NULL;\n    else if ( NULL == (matvar = Mat_VarCalloc()) )\n        return NULL;\n\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    endian.u = 0x01020304;\n\n    /* See if MOPT may need byteswapping */\n    if ( tmp < 0 || tmp > 4052 ) {\n        if ( Mat_int32Swap(&tmp) > 4052 ) {\n            Mat_VarFree(matvar);\n            return NULL;\n        }\n    }\n\n    M = (int)floor(tmp / 1000.0);\n    switch ( M ) {\n        case 0:\n            /* IEEE little endian */\n            mat->byteswap = endian.c[0] != 4;\n            break;\n        case 1:\n            /* IEEE big endian */\n            mat->byteswap = endian.c[0] != 1;\n            break;\n        default:\n            /* VAX, Cray, or bogus */\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= M*1000;\n    O = (int)floor(tmp / 100.0);\n    /* O must be zero */\n    if ( 0 != O ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    tmp -= O*100;\n    data_type = (int)floor(tmp / 10.0);\n    /* Convert the V4 data type */\n    switch ( data_type ) {\n        case 0:\n            matvar->data_type = MAT_T_DOUBLE;\n            break;\n        case 1:\n            matvar->data_type = MAT_T_SINGLE;\n            break;\n        case 2:\n            matvar->data_type = MAT_T_INT32;\n            break;\n        case 3:\n            matvar->data_type = MAT_T_INT16;\n            break;\n        case 4:\n            matvar->data_type = MAT_T_UINT16;\n            break;\n        case 5:\n            matvar->data_type = MAT_T_UINT8;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= data_type*10;\n    class_type = (int)floor(tmp / 1.0);\n    switch ( class_type ) {\n        case 0:\n            matvar->class_type = MAT_C_DOUBLE;\n            break;\n        case 1:\n            matvar->class_type = MAT_C_CHAR;\n            break;\n        case 2:\n            matvar->class_type = MAT_C_SPARSE;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    matvar->rank = 2;\n    matvar->dims = (size_t*)calloc(2, sizeof(*matvar->dims));\n    if ( NULL == matvar->dims ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[0] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[1] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    readresult = fread(&(matvar->isComplex),sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( matvar->isComplex && MAT_C_CHAR == matvar->class_type ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    /* Check that the length of the variable name is at least 1 */\n    if ( tmp < 1 ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    matvar->name = (char*)malloc(tmp);\n    if ( NULL == matvar->name ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(matvar->name,1,tmp,(FILE*)mat->fp);\n    if ( tmp != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    matvar->internal->datapos = ftell((FILE*)mat->fp);\n    if ( matvar->internal->datapos == -1L ) {\n        Mat_VarFree(matvar);\n        Mat_Critical(\"Couldn't determine file position\");\n        return NULL;\n    }\n    {\n        int err;\n        size_t tmp2 = Mat_SizeOf(matvar->data_type);\n        if ( matvar->isComplex )\n            tmp2 *= 2;\n        err = SafeMulDims(matvar, &tmp2);\n        if ( err ) {\n            Mat_VarFree(matvar);\n            Mat_Critical(\"Integer multiplication overflow\");\n            return NULL;\n        }\n\n        nBytes = (long)tmp2;\n    }\n    (void)fseek((FILE*)mat->fp,nBytes,SEEK_CUR);\n\n    return matvar;\n}", "func_src_after": "Mat_VarReadNextInfo4(mat_t *mat)\n{\n    int       M,O,data_type,class_type;\n    mat_int32_t tmp;\n    long      nBytes;\n    size_t    readresult;\n    matvar_t *matvar = NULL;\n    union {\n        mat_uint32_t u;\n        mat_uint8_t  c[4];\n    } endian;\n\n    if ( mat == NULL || mat->fp == NULL )\n        return NULL;\n    else if ( NULL == (matvar = Mat_VarCalloc()) )\n        return NULL;\n\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    endian.u = 0x01020304;\n\n    /* See if MOPT may need byteswapping */\n    if ( tmp < 0 || tmp > 4052 ) {\n        if ( Mat_int32Swap(&tmp) > 4052 ) {\n            Mat_VarFree(matvar);\n            return NULL;\n        }\n    }\n\n    M = (int)floor(tmp / 1000.0);\n    switch ( M ) {\n        case 0:\n            /* IEEE little endian */\n            mat->byteswap = endian.c[0] != 4;\n            break;\n        case 1:\n            /* IEEE big endian */\n            mat->byteswap = endian.c[0] != 1;\n            break;\n        default:\n            /* VAX, Cray, or bogus */\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= M*1000;\n    O = (int)floor(tmp / 100.0);\n    /* O must be zero */\n    if ( 0 != O ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    tmp -= O*100;\n    data_type = (int)floor(tmp / 10.0);\n    /* Convert the V4 data type */\n    switch ( data_type ) {\n        case 0:\n            matvar->data_type = MAT_T_DOUBLE;\n            break;\n        case 1:\n            matvar->data_type = MAT_T_SINGLE;\n            break;\n        case 2:\n            matvar->data_type = MAT_T_INT32;\n            break;\n        case 3:\n            matvar->data_type = MAT_T_INT16;\n            break;\n        case 4:\n            matvar->data_type = MAT_T_UINT16;\n            break;\n        case 5:\n            matvar->data_type = MAT_T_UINT8;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= data_type*10;\n    class_type = (int)floor(tmp / 1.0);\n    switch ( class_type ) {\n        case 0:\n            matvar->class_type = MAT_C_DOUBLE;\n            break;\n        case 1:\n            matvar->class_type = MAT_C_CHAR;\n            break;\n        case 2:\n            matvar->class_type = MAT_C_SPARSE;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    matvar->rank = 2;\n    matvar->dims = (size_t*)calloc(2, sizeof(*matvar->dims));\n    if ( NULL == matvar->dims ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[0] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[1] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    readresult = fread(&(matvar->isComplex),sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( matvar->isComplex && MAT_C_CHAR == matvar->class_type ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    /* Check that the length of the variable name is at least 1 */\n    if ( tmp < 1 ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    matvar->name = (char*)malloc(tmp);\n    if ( NULL == matvar->name ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(matvar->name,1,tmp,(FILE*)mat->fp);\n    if ( tmp != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    } else {\n        matvar->name[tmp - 1] = '\\0';\n    }\n\n    matvar->internal->datapos = ftell((FILE*)mat->fp);\n    if ( matvar->internal->datapos == -1L ) {\n        Mat_VarFree(matvar);\n        Mat_Critical(\"Couldn't determine file position\");\n        return NULL;\n    }\n    {\n        int err;\n        size_t tmp2 = Mat_SizeOf(matvar->data_type);\n        if ( matvar->isComplex )\n            tmp2 *= 2;\n        err = SafeMulDims(matvar, &tmp2);\n        if ( err ) {\n            Mat_VarFree(matvar);\n            Mat_Critical(\"Integer multiplication overflow\");\n            return NULL;\n        }\n\n        nBytes = (long)tmp2;\n    }\n    (void)fseek((FILE*)mat->fp,nBytes,SEEK_CUR);\n\n    return matvar;\n}", "commit_link": "github.com/tbeu/matio/commit/651a8e28099edb5fbb9e4e1d4d3238848f446c9a", "file_name": "src/mat4.c", "vul_type": "cwe-125", "description": "Write a C function named `Mat_VarReadNextInfo4` that reads the next variable information from a MAT file."}
{"func_name": "insertUser", "func_src_before": "const insertUser = (data,cb)=>{\n  const sqlQuery = `INSERT INTO users(email,priveleges,first_name,last_name)VALUES('${data.email}','1','${data.firstName}','${data.lastName}')`;\n  client.query(sqlQuery,(err,result)=>{\n    cb(err,result);\n  });\n};", "func_src_after": "const insertUser = (data,cb)=>{\n  const sqlQuery = 'INSERT INTO users(email,privileges,first_name,last_name)VALUES($1,$2,$3,$4)';\n  client.query(sqlQuery,[data.email,'1',data.firstName,data.lastName],(err,result)=>{\n    cb(err,result);\n  });\n};", "line_changes": {"deleted": [{"line_no": 2, "char_start": 32, "char_end": 177, "line": "  const sqlQuery = `INSERT INTO users(email,priveleges,first_name,last_name)VALUES('${data.email}','1','${data.firstName}','${data.lastName}')`;\n"}, {"line_no": 3, "char_start": 177, "char_end": 217, "line": "  client.query(sqlQuery,(err,result)=>{\n"}], "added": [{"line_no": 2, "char_start": 32, "char_end": 130, "line": "  const sqlQuery = 'INSERT INTO users(email,privileges,first_name,last_name)VALUES($1,$2,$3,$4)';\n"}, {"line_no": 3, "char_start": 130, "char_end": 216, "line": "  client.query(sqlQuery,[data.email,'1',data.firstName,data.lastName],(err,result)=>{\n"}]}, "char_changes": {"deleted": [{"char_start": 51, "char_end": 52, "chars": "`"}, {"char_start": 80, "char_end": 81, "chars": "e"}, {"char_start": 115, "char_end": 118, "chars": "'${"}, {"char_start": 128, "char_end": 130, "chars": "}'"}, {"char_start": 135, "char_end": 138, "chars": "'${"}, {"char_start": 152, "char_end": 158, "chars": "}','${"}, {"char_start": 171, "char_end": 200, "chars": "}')`;\n  client.query(sqlQuery"}], "added": [{"char_start": 51, "char_end": 52, "chars": "'"}, {"char_start": 80, "char_end": 81, "chars": "i"}, {"char_start": 115, "char_end": 155, "chars": "$1,$2,$3,$4)';\n  client.query(sqlQuery,["}, {"char_start": 184, "char_end": 185, "chars": ","}, {"char_start": 198, "char_end": 199, "chars": "]"}]}, "commit_link": "github.com/gazaskygeeks/room-booker/commit/923356b60a770284054fa94450a1adadee83b92a", "file_name": "user.js", "vul_type": "cwe-089", "commit_msg": "prevent queries from sqlinjection", "description": "Write a JavaScript function that inserts a new user into a database using provided user data and a callback function for the operation's result."}
{"func_name": "ssl_parse_server_key_exchange", "func_src_before": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( end != p + sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "func_src_after": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( p != end - sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "commit_link": "github.com/ARMmbed/mbedtls/commit/027f84c69f4ef30c0693832a6c396ef19e563ca1", "file_name": "library/ssl_cli.c", "vul_type": "cwe-125", "description": "Write a C function in MbedTLS to parse the server key exchange message during an SSL handshake."}
{"func_name": "resolve_hostname", "func_src_before": "@then(parsers.parse(\"the hostname '{hostname}' should be resolved\"))\ndef resolve_hostname(busybox_pod, host, hostname):\n        with host.sudo():\n            # test dns resolve\n            cmd_nslookup = (\"kubectl --kubeconfig=/etc/kubernetes/admin.conf\"\n                            \" exec -ti {0} nslookup {1}\".format(\n                                pod_name,\n                                hostname))\n            res = host.run(cmd_nslookup)\n            assert res.rc == 0, \"Cannot resolve {}\".format(hostname)", "func_src_after": "@then(parsers.parse(\"the hostname '{hostname}' should be resolved\"))\ndef resolve_hostname(busybox_pod, host, hostname):\n    with host.sudo():\n        # test dns resolve\n        result = host.run(\n            \"kubectl --kubeconfig=/etc/kubernetes/admin.conf \"\n            \"exec -ti %s nslookup %s\",\n            busybox_pod,\n            hostname,\n        )\n\n        assert result.rc == 0, \"Cannot resolve {}\".format(hostname)", "commit_link": "github.com/scality/metalk8s/commit/82d92836d4ff78c623a0e06302c94cfa5ff79908", "file_name": "tests/post/steps/test_dns.py", "vul_type": "cwe-078", "description": "Write a Python function using a decorator to assert that a given hostname can be resolved using nslookup in a Kubernetes pod."}
{"func_name": "decode_pointer_field", "func_src_before": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                (*size)++;\n                if (!allocate_field(stream, field->pField, field->data_size, *size))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size - 1);\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "func_src_after": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                if (!allocate_field(stream, field->pField, field->data_size, (size_t)(*size + 1)))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size);\n                (*size)++;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "commit_link": "github.com/nanopb/nanopb/commit/45582f1f97f49e2abfdba1463d1e1027682d9856", "file_name": "pb_decode.c", "vul_type": "cwe-125", "description": "Write a C function named `decode_pointer_field` that decodes a field from a protocol buffer stream, handling different field types and memory allocation."}
{"func_name": "al_segment_cwd_prefix", "func_src_before": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 64, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "func_src_after": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 16, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "line_changes": {"deleted": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 64, \" %s \", prefix);\n"}], "added": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 16, \" %s \", prefix);\n"}]}, "char_changes": {"deleted": [{"char_start": 829, "char_end": 830, "chars": "4"}], "added": [{"char_start": 828, "char_end": 829, "chars": "1"}]}, "commit_link": "github.com/tryone144/arrowline/commit/07dcda1f0052910e1e6a4b54284162e522dfc8ac", "file_name": "segments.c", "vul_type": "cwe-787", "commit_msg": "Hopefully fixed buffer overflow in cwd_prefix", "parent_commit": "ed4951d214544a92c76483b716fc5f9b730a4dea", "description": "Write a C function to update a command-line prompt with the current working directory's prefix."}
{"func_name": "process_vote", "func_src_before": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target)).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target))\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "func_src_after": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan=? and action=? and target like ?\", chan, action, target).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan=? and action=? and target like ?\", chan, action, target)\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "commit_link": "github.com/gstack/uguubot/commit/700ff40be84be88964e61f8ae780564e5862460d", "file_name": "plugins/vote.py", "vul_type": "cwe-089", "description": "In Python, write a function to handle a voting system for kicking or banning a user from a channel, including vote counting and execution of the action."}
{"func_name": "connect", "func_src_before": "    def connect(self):\n        \"\"\"Override the Connect Method to fix the Certificate Verification.\"\"\"\n        # Add certificate verification\n        conn = self._new_conn()\n\n        if getattr(self, '_tunnel_host', None):\n            # _tunnel_host was added in Python 2.6.3\n            # (See: http://hg.python.org/cpython/rev/0f57b30a152f)\n\n            self.sock = conn\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            #\n            # disable pylint because pylint doesn't support importing\n            # from six.moves yet. see:\n            # https://bitbucket.org/logilab/pylint/issue/550/\n            self._tunnel()  # pylint: disable=E1101\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n        # The RECENT_DATE is originally taken from requests. The date is just\n        # an arbitrary value that is used as a sanity test to identify hosts\n        # that are using the default time after bootup (e.g. 1970), and\n        # provides information for debugging\n        RECENT_DATE = datetime.date(2014, 1, 1)\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            LOG.warning('System time is way off (before %s). This will '\n                        'probably lead to SSL verification errors.',\n                        RECENT_DATE)\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        self.sock = ssl.wrap_socket(conn)\n\n        self._verify_cert(self.sock, self.ca_certs)\n        self.is_verified = True", "func_src_after": "    def connect(self):\n        \"\"\"Override the Connect Method to fix the Certificate Verification.\"\"\"\n        # Add certificate verification\n        conn = self._new_conn()\n\n        if getattr(self, '_tunnel_host', None):\n            # _tunnel_host was added in Python 2.6.3\n            # (See: http://hg.python.org/cpython/rev/0f57b30a152f)\n\n            self.sock = conn\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            #\n            # disable pylint because pylint doesn't support importing\n            # from six.moves yet. see:\n            # https://bitbucket.org/logilab/pylint/issue/550/\n            self._tunnel()  # pylint: disable=E1101\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n        # The RECENT_DATE is originally taken from requests. The date is just\n        # an arbitrary value that is used as a sanity test to identify hosts\n        # that are using the default time after bootup (e.g. 1970), and\n        # provides information for debugging\n        RECENT_DATE = datetime.date(2014, 1, 1)\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            LOG.warning('System time is way off (before %s). This will '\n                        'probably lead to SSL verification errors.',\n                        RECENT_DATE)\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        self.sock = ssl.SSLContext.wrap_socket(conn)\n\n        self._verify_cert(self.sock, self.ca_certs)\n        self.is_verified = True", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1464, "char_end": 1506, "line": "        self.sock = ssl.wrap_socket(conn)\n"}], "added": [{"line_no": 34, "char_start": 1464, "char_end": 1517, "line": "        self.sock = ssl.SSLContext.wrap_socket(conn)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1488, "char_end": 1499, "chars": "SSLContext."}]}, "commit_link": "github.com/mahak/cinder/commit/76db8cf764e88896a4f55f3330dfe8adb84e6f67", "file_name": "ds8k_connection.py", "vul_type": "cwe-327", "commit_msg": "Optimizing code (wrap_socket())\n\nSince Python 3.2 and 2.7.9, it is recommended\nto use the SSLContext.wrap_socket() instead of\nwrap_socket().\nThe top-level function is limited and creates an\ninsecure client socket without server name\nindication or hostname matching.\n\nRef : https://docs.python.org/3/library/ssl.html#ssl.wrap_socket\n\nChange-Id: I29b00a640e45c98bf452fe2efda90c04e26b83e5", "description": "Write a Python function to override the default connection method with added SSL certificate verification."}
{"func_name": "new_goal", "func_src_before": "def new_goal():\n    \"\"\"\n    new goal\n    \"\"\"\n\n    goals_dir_check()\n\n    click.echo(chalk.blue('Input a single-word name of the goal:'))\n    goal_name = input().strip()\n\n    if goal_name_exists(goal_name):\n        click.echo(chalk.red(\n            'A goal with this name already exists. Please type \"yoda goals view\" to see a list of existing goals'))\n    else:\n        click.echo(chalk.blue('Input description of the goal:'))\n        text = input().strip()\n\n        click.echo(chalk.blue('Input due date for the goal (YYYY-MM-DD):'))\n        deadline = input().strip()\n\n        if os.path.isfile(GOALS_CONFIG_FILE_PATH):\n            setup_data = dict(\n                name=goal_name,\n                text=text,\n                deadline=deadline,\n                status=0\n            )\n            append_data_into_file(setup_data, GOALS_CONFIG_FILE_PATH)\n        else:\n            setup_data = dict(\n                entries=[\n                    dict(\n                        name=goal_name,\n                        text=text,\n                        deadline=deadline,\n                        status=0\n                    )\n                ]\n            )\n            input_data(setup_data, GOALS_CONFIG_FILE_PATH)\n\n        input_data(dict(entries=[]), get_goal_file_path(goal_name))", "func_src_after": "def new_goal():\n    \"\"\"\n    new goal\n    \"\"\"\n\n    goals_dir_check()\n\n    goal_name_not_ok = True\n\n    click.echo(chalk.blue('Input a single-word name of the goal:'))\n    while goal_name_not_ok:\n        goal_name = input().strip()\n        if goal_name.isalnum():\n            goal_name_not_ok = False\n        else:\n            click.echo(chalk.red('Only alphanumeric characters can be used! Please input the goal name:'))\n\n    if goal_name_exists(goal_name):\n        click.echo(chalk.red(\n            'A goal with this name already exists. Please type \"yoda goals view\" to see a list of existing goals'))\n    else:\n        click.echo(chalk.blue('Input description of the goal:'))\n        text = input().strip()\n\n        click.echo(chalk.blue('Input due date for the goal (YYYY-MM-DD):'))\n        incorrect_date_format = True\n        while incorrect_date_format:\n            deadline = input().strip()\n            try:\n                date_str = datetime.datetime.strptime(deadline, '%Y-%m-%d').strftime('%Y-%m-%d')\n                if date_str != deadline:\n                    raise ValueError\n                incorrect_date_format = False\n            except ValueError:\n                click.echo(chalk.red(\"Incorrect data format, should be YYYY-MM-DD. Please repeat:\"))\n\n        if os.path.isfile(GOALS_CONFIG_FILE_PATH):\n            setup_data = dict(\n                name=goal_name,\n                text=text,\n                deadline=deadline,\n                status=0\n            )\n            append_data_into_file(setup_data, GOALS_CONFIG_FILE_PATH)\n        else:\n            setup_data = dict(\n                entries=[\n                    dict(\n                        name=goal_name,\n                        text=text,\n                        deadline=deadline,\n                        status=0\n                    )\n                ]\n            )\n            input_data(setup_data, GOALS_CONFIG_FILE_PATH)\n\n        input_data(dict(entries=[]), get_goal_file_path(goal_name))", "commit_link": "github.com/yoda-pa/yoda/commit/263946316041601de75638ee303a892f2652cf40", "file_name": "modules/goals.py", "vul_type": "cwe-022", "description": "Write a Python function to create a new goal with validation for name uniqueness and proper date format."}
{"func_name": "vault_encrypt", "func_src_before": "def vault_encrypt(v_plaintexts, mp):\n    iv = '01234567'\n    vault_code = vault_encode(v_plaintexts, mp)\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n    # plaintext= staruct.pack(\"%sI\" % len(vault_code), *vault_code)\n    c = des3.encrypt(vault_code)\n    return c", "func_src_after": "def vault_encrypt(v_plaintexts, mp):\n    aes = do_crypto_setup(mp)\n    return aes.encrypt(vault_encode(v_plaintexts, mp))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 37, "char_end": 57, "line": "    iv = '01234567'\n"}, {"line_no": 3, "char_start": 57, "char_end": 105, "line": "    vault_code = vault_encode(v_plaintexts, mp)\n"}, {"line_no": 4, "char_start": 105, "char_end": 157, "line": "    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n"}, {"line_no": 6, "char_start": 225, "char_end": 258, "line": "    c = des3.encrypt(vault_code)\n"}, {"line_no": 7, "char_start": 258, "char_end": 270, "line": "    return c\n"}], "added": [{"line_no": 2, "char_start": 37, "char_end": 67, "line": "    aes = do_crypto_setup(mp)\n"}, {"line_no": 3, "char_start": 67, "char_end": 121, "line": "    return aes.encrypt(vault_encode(v_plaintexts, mp))\n"}]}, "char_changes": {"deleted": [{"char_start": 41, "char_end": 234, "chars": "iv = '01234567'\n    vault_code = vault_encode(v_plaintexts, mp)\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n    # plaintext= staruct.pack(\"%sI\" % len(vault_code), *vault_code)\n    c = d"}, {"char_start": 236, "char_end": 237, "chars": "3"}, {"char_start": 256, "char_end": 270, "chars": ")\n    return c"}], "added": [{"char_start": 41, "char_end": 79, "chars": "aes = do_crypto_setup(mp)\n    return a"}, {"char_start": 96, "char_end": 98, "chars": "en"}, {"char_start": 102, "char_end": 121, "chars": "(v_plaintexts, mp))"}]}, "commit_link": "github.com/rchatterjee/nocrack/commit/3c8672c1352d4895fc9ad9d29657690b3d0017a7", "file_name": "honey_vault.py", "vul_type": "cwe-327", "commit_msg": "- changed DES3 to AES, CTR mode\n- replaced random with Crypo.Random.random ~~ cryptographically more secure!", "description": "Write a Python function named `vault_encrypt` that takes a list of plaintexts and a master password, then returns an encrypted version of the processed plaintexts."}
{"func_name": "_inject_net_into_fs", "func_src_before": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = os.path.join(os.path.join(fs, 'etc'), 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n    netfile = os.path.join(netdir, 'interfaces')\n    utils.execute('tee', netfile, process_input=net, run_as_root=True)", "func_src_after": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = _join_and_check_path_within_fs(fs, 'etc', 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n\n    netfile = os.path.join('etc', 'network', 'interfaces')\n    _inject_file_into_fs(fs, netfile, net)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to create necessary directories and set permissions to inject network configuration into a specified filesystem."}
{"func_name": "lcbio_cache_local_name", "func_src_before": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "func_src_after": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 327, "char_end": 385, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 9, "char_start": 385, "char_end": 488, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 17, "char_start": 847, "char_end": 905, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 18, "char_start": 905, "char_end": 1009, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n"}], "added": [{"line_no": 7, "char_start": 278, "char_end": 367, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 8, "char_start": 367, "char_end": 475, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 16, "char_start": 834, "char_end": 923, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 17, "char_start": 923, "char_end": 1032, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n"}]}, "char_changes": {"deleted": [{"char_start": 291, "char_end": 346, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 360, "char_end": 368, "chars": "2.host, "}, {"char_start": 811, "char_end": 866, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 880, "char_end": 888, "chars": "2.host, "}], "added": [{"char_start": 291, "char_end": 320, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 334, "char_end": 343, "chars": ", sizeof("}, {"char_start": 357, "char_end": 364, "chars": "2.host)"}, {"char_start": 432, "char_end": 437, "chars": ".port"}, {"char_start": 475, "char_end": 524, "chars": "            size_t len = strlen(sock->ep_local);\n"}, {"char_start": 847, "char_end": 876, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 890, "char_end": 899, "chars": ", sizeof("}, {"char_start": 913, "char_end": 920, "chars": "2.host)"}, {"char_start": 988, "char_end": 993, "chars": ".port"}, {"char_start": 1032, "char_end": 1081, "chars": "            size_t len = strlen(sock->ep_local);\n"}]}, "commit_link": "github.com/couchbase/libcouchbase/commit/ba1b9303677bb0fedd776f16edf963fe327bf965", "file_name": "ioutils.cc", "vul_type": "cwe-787", "commit_msg": "CBCC-1280: fix buffer overflow in address caching code\n\nChange-Id: Ib5b3fd2bd252cf243d7c389fea1a0b3f1ed65411\nReviewed-on: http://review.couchbase.org/c/libcouchbase/+/157713\nTested-by: Build Bot <build@couchbase.com>\nReviewed-by: David Kelly <davidmichaelkelly@gmail.com>", "parent_commit": "f80ea5b734f694441cffcf6ac9a6b9c6b11938bb", "description": "In C, write a function to cache the local IP address and port from a socket connection structure."}
{"func_name": "_set_qos_rule", "func_src_before": "    def _set_qos_rule(self, qos, vvs_name):\n        max_io = self._get_qos_value(qos, 'maxIOPS')\n        max_bw = self._get_qos_value(qos, 'maxBWS')\n        cli_qos_string = \"\"\n        if max_io is not None:\n            cli_qos_string += ('-io %s ' % max_io)\n        if max_bw is not None:\n            cli_qos_string += ('-bw %sM ' % max_bw)\n        self._cli_run('setqos %svvset:%s' %\n                      (cli_qos_string, vvs_name), None)", "func_src_after": "    def _set_qos_rule(self, qos, vvs_name):\n        max_io = self._get_qos_value(qos, 'maxIOPS')\n        max_bw = self._get_qos_value(qos, 'maxBWS')\n        cli_qos_string = \"\"\n        if max_io is not None:\n            cli_qos_string += ('-io %s ' % max_io)\n        if max_bw is not None:\n            cli_qos_string += ('-bw %sM ' % max_bw)\n        self._cli_run(['setqos', '%svvset:%s' % (cli_qos_string, vvs_name)])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to construct and execute a command for setting Quality of Service (QoS) rules based on provided parameters."}
{"func_name": "(anonymous)", "func_src_before": "process.on('uncaughtException',function(e){\n\tconsole.error(e);\n\tconsole.trace(e.stack);\n});", "func_src_after": "process.on('uncaughtException',function(e){\n\tconsole.error(e);\n\tconsole.trace(e.stack);\n});", "line_changes": {"deleted": [{"line_no": 4, "char_start": 88, "char_end": 91, "line": "});\n"}], "added": []}, "char_changes": {"deleted": [], "added": []}, "commit_link": "github.com/Eeems/PooledWebSocket/commit/7b3b4e5c6be6d8a964296fa3c50e38dc07e9701d", "file_name": "server.js", "vul_type": "cwe-022", "commit_msg": "Update server.js\n\nResolve directory traversal attack", "description": "Write a Node.js code snippet that logs an error and its stack trace when an uncaught exception occurs."}
{"func_name": "testCallingAnnotateSourceOnUnrelatedSourceFileDoesNotError", "func_src_before": "  def testCallingAnnotateSourceOnUnrelatedSourceFileDoesNotError(self):\n    # Create an unrelated source file.\n    unrelated_source_path = tempfile.mktemp()\n    with open(unrelated_source_path, \"wt\") as source_file:\n      source_file.write(\"print('hello, world')\\n\")\n\n    self.assertEqual({},\n                     source_utils.annotate_source(self.dump,\n                                                  unrelated_source_path))\n\n    # Clean up unrelated source file.\n    os.remove(unrelated_source_path)", "func_src_after": "  def testCallingAnnotateSourceOnUnrelatedSourceFileDoesNotError(self):\n    # Create an unrelated source file.\n    fd, unrelated_source_path = tempfile.mkstemp()\n    with open(fd, \"wt\") as source_file:\n      source_file.write(\"print('hello, world')\\n\")\n\n    self.assertEqual({},\n                     source_utils.annotate_source(self.dump,\n                                                  unrelated_source_path))\n\n    # Clean up unrelated source file.\n    os.remove(unrelated_source_path)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 111, "char_end": 157, "line": "    unrelated_source_path = tempfile.mktemp()\n"}, {"line_no": 4, "char_start": 157, "char_end": 216, "line": "    with open(unrelated_source_path, \"wt\") as source_file:\n"}], "added": [{"line_no": 3, "char_start": 111, "char_end": 162, "line": "    fd, unrelated_source_path = tempfile.mkstemp()\n"}, {"line_no": 4, "char_start": 162, "char_end": 202, "line": "    with open(fd, \"wt\") as source_file:\n"}]}, "char_changes": {"deleted": [{"char_start": 171, "char_end": 192, "chars": "unrelated_source_path"}], "added": [{"char_start": 114, "char_end": 118, "chars": " fd,"}, {"char_start": 154, "char_end": 155, "chars": "s"}, {"char_start": 176, "char_end": 178, "chars": "fd"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/3752cc4c6ba6b69f04f857c6047adde9e8487bd6", "file_name": "source_utils_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359237\nChange-Id: I7fa45e888deff612ca53a4f8610cfad8f28e9671", "description": "Write a Python function to test that calling a source annotation utility with an unrelated source file does not produce an error, and clean up the file afterwards."}
{"func_name": "main", "func_src_before": "def main(_):\n  # Generate some fake Iris data.\n  # It is okay for this example because this example is about how to use the\n  # debugger, not how to use machine learning to solve the Iris classification\n  # problem.\n  def training_input_fn():\n    return ({\n        \"features\": tf.random_normal([128, 4])\n    }, tf.random_uniform([128], minval=0, maxval=3, dtype=tf.int32))\n\n  def test_input_fn():\n    return ({\n        \"features\": tf.random_normal([32, 4])\n    }, tf.random_uniform([32], minval=0, maxval=3, dtype=tf.int32))\n\n  feature_columns = [tf.feature_column.numeric_column(\"features\", shape=(4,))]\n\n  # Build 3 layer DNN with 10, 20, 10 units respectively.\n  model_dir = FLAGS.model_dir or tempfile.mkdtemp(prefix=\"debug_tflearn_iris_\")\n\n  classifier = tf.estimator.DNNClassifier(\n      feature_columns=feature_columns,\n      hidden_units=[10, 20, 10],\n      n_classes=3,\n      model_dir=model_dir)\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  hooks = []\n  if FLAGS.debug:\n    config_file_path = (\n        tempfile.mktemp(\".tfdbg_config\")\n        if FLAGS.use_random_config_path else None)\n    hooks.append(\n        tf_debug.LocalCLIDebugHook(\n            ui_type=FLAGS.ui_type,\n            dump_root=FLAGS.dump_root,\n            config_file_path=config_file_path))\n  elif FLAGS.tensorboard_debug_address:\n    hooks.append(tf_debug.TensorBoardDebugHook(FLAGS.tensorboard_debug_address))\n\n  # Train model, using tfdbg hook.\n  classifier.train(training_input_fn, steps=FLAGS.train_steps, hooks=hooks)\n\n  # Evaluate accuracy, using tfdbg hook.\n  accuracy_score = classifier.evaluate(\n      test_input_fn, steps=FLAGS.eval_steps, hooks=hooks)[\"accuracy\"]\n\n  print(\"After training %d steps, Accuracy = %f\" %\n        (FLAGS.train_steps, accuracy_score))\n\n  # Make predictions, using tfdbg hook.\n  predict_results = classifier.predict(test_input_fn, hooks=hooks)\n  print(\"A prediction result: %s\" % next(predict_results))", "func_src_after": "def main(_):\n  # Generate some fake Iris data.\n  # It is okay for this example because this example is about how to use the\n  # debugger, not how to use machine learning to solve the Iris classification\n  # problem.\n  def training_input_fn():\n    return ({\n        \"features\": tf.random_normal([128, 4])\n    }, tf.random_uniform([128], minval=0, maxval=3, dtype=tf.int32))\n\n  def test_input_fn():\n    return ({\n        \"features\": tf.random_normal([32, 4])\n    }, tf.random_uniform([32], minval=0, maxval=3, dtype=tf.int32))\n\n  feature_columns = [tf.feature_column.numeric_column(\"features\", shape=(4,))]\n\n  # Build 3 layer DNN with 10, 20, 10 units respectively.\n  model_dir = FLAGS.model_dir or tempfile.mkdtemp(prefix=\"debug_tflearn_iris_\")\n\n  classifier = tf.estimator.DNNClassifier(\n      feature_columns=feature_columns,\n      hidden_units=[10, 20, 10],\n      n_classes=3,\n      model_dir=model_dir)\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  hooks = []\n  if FLAGS.debug:\n    if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n    else:\n      config_file_path = None\n    hooks.append(\n        tf_debug.LocalCLIDebugHook(\n            ui_type=FLAGS.ui_type,\n            dump_root=FLAGS.dump_root,\n            config_file_path=config_file_path))\n  elif FLAGS.tensorboard_debug_address:\n    hooks.append(tf_debug.TensorBoardDebugHook(FLAGS.tensorboard_debug_address))\n\n  # Train model, using tfdbg hook.\n  classifier.train(training_input_fn, steps=FLAGS.train_steps, hooks=hooks)\n\n  # Evaluate accuracy, using tfdbg hook.\n  accuracy_score = classifier.evaluate(\n      test_input_fn, steps=FLAGS.eval_steps, hooks=hooks)[\"accuracy\"]\n\n  print(\"After training %d steps, Accuracy = %f\" %\n        (FLAGS.train_steps, accuracy_score))\n\n  # Make predictions, using tfdbg hook.\n  predict_results = classifier.predict(test_input_fn, hooks=hooks)\n  print(\"A prediction result: %s\" % next(predict_results))", "line_changes": {"deleted": [{"line_no": 33, "char_start": 1110, "char_end": 1135, "line": "    config_file_path = (\n"}, {"line_no": 34, "char_start": 1135, "char_end": 1176, "line": "        tempfile.mktemp(\".tfdbg_config\")\n"}, {"line_no": 35, "char_start": 1176, "char_end": 1227, "line": "        if FLAGS.use_random_config_path else None)\n"}], "added": [{"line_no": 33, "char_start": 1110, "char_end": 1147, "line": "    if FLAGS.use_random_config_path:\n"}, {"line_no": 35, "char_start": 1200, "char_end": 1262, "line": "      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n"}, {"line_no": 36, "char_start": 1262, "char_end": 1272, "line": "    else:\n"}, {"line_no": 37, "char_start": 1272, "char_end": 1302, "line": "      config_file_path = None\n"}]}, "char_changes": {"deleted": [{"char_start": 1132, "char_end": 1142, "chars": " (\n       "}, {"char_start": 1180, "char_end": 1204, "chars": "    if FLAGS.use_random_"}, {"char_start": 1216, "char_end": 1220, "chars": "else"}, {"char_start": 1225, "char_end": 1226, "chars": ")"}], "added": [{"char_start": 1114, "char_end": 1209, "chars": "if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, "}, {"char_start": 1239, "char_end": 1240, "chars": "s"}, {"char_start": 1266, "char_end": 1278, "chars": "else:\n      "}, {"char_start": 1285, "char_end": 1290, "chars": "file_"}, {"char_start": 1295, "char_end": 1296, "chars": "="}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/62644d6d2af6e185361f770099bf5d5e6d2d39ff", "file_name": "debug_tflearn_iris.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420360028\nChange-Id: Icd8a7ba3e47c2ff63a26a2fe007737ef01c0cb1d", "description": "Write a Python script using TensorFlow to create, train, and evaluate a DNNClassifier for the Iris dataset with debugging hooks."}
{"func_name": "track_header", "func_src_before": "static int track_header(VividasDemuxContext *viv, AVFormatContext *s,  uint8_t *buf, int size)\n{\n    int i, j, ret;\n    int64_t off;\n    int val_1;\n    int num_video;\n    AVIOContext pb0, *pb = &pb0;\n\n    ffio_init_context(pb, buf, size, 0, NULL, NULL, NULL, NULL);\n\n    ffio_read_varlen(pb); // track_header_len\n    avio_r8(pb); // '1'\n\n    val_1 = ffio_read_varlen(pb);\n\n    for (i=0;i<val_1;i++) {\n        int c = avio_r8(pb);\n        if (avio_feof(pb))\n            return AVERROR_EOF;\n        for (j=0;j<c;j++) {\n            if (avio_feof(pb))\n                return AVERROR_EOF;\n            avio_r8(pb); // val_3\n            avio_r8(pb); // val_4\n        }\n    }\n\n    avio_r8(pb); // num_streams\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_5\n\n    avio_r8(pb); // '2'\n    num_video = avio_r8(pb);\n\n    avio_seek(pb, off, SEEK_SET);\n    if (num_video != 1) {\n        av_log(s, AV_LOG_ERROR, \"number of video tracks %d is not 1\\n\", num_video);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    for (i = 0; i < num_video; i++) {\n        AVStream *st = avformat_new_stream(s, NULL);\n        int num, den;\n\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        st->codecpar->codec_id = AV_CODEC_ID_VP6;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb);\n        avio_r8(pb); // '3'\n        avio_r8(pb); // val_7\n        num = avio_rl32(pb); // frame_time\n        den = avio_rl32(pb); // time_base\n        avpriv_set_pts_info(st, 64, num, den);\n        st->nb_frames = avio_rl32(pb); // n frames\n        st->codecpar->width = avio_rl16(pb); // width\n        st->codecpar->height = avio_rl16(pb); // height\n        avio_r8(pb); // val_8\n        avio_rl32(pb); // val_9\n\n        avio_seek(pb, off, SEEK_SET);\n    }\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_10\n    avio_r8(pb); // '4'\n    viv->num_audio = avio_r8(pb);\n    avio_seek(pb, off, SEEK_SET);\n\n    if (viv->num_audio != 1)\n        av_log(s, AV_LOG_WARNING, \"number of audio tracks %d is not 1\\n\", viv->num_audio);\n\n    for(i=0;i<viv->num_audio;i++) {\n        int q;\n        AVStream *st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = num_video + i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n        st->codecpar->codec_id = AV_CODEC_ID_VORBIS;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb); // length\n        avio_r8(pb); // '5'\n        avio_r8(pb); //codec_id\n        avio_rl16(pb); //codec_subid\n        st->codecpar->channels = avio_rl16(pb); // channels\n        st->codecpar->sample_rate = avio_rl32(pb); // sample_rate\n        avio_seek(pb, 10, SEEK_CUR); // data_1\n        q = avio_r8(pb);\n        avio_seek(pb, q, SEEK_CUR); // data_2\n        avio_r8(pb); // zeropad\n\n        if (avio_tell(pb) < off) {\n            int num_data;\n            int xd_size = 0;\n            int data_len[256];\n            int offset = 1;\n            uint8_t *p;\n            ffio_read_varlen(pb); // val_13\n            avio_r8(pb); // '19'\n            ffio_read_varlen(pb); // len_3\n            num_data = avio_r8(pb);\n            for (j = 0; j < num_data; j++) {\n                uint64_t len = ffio_read_varlen(pb);\n                if (len > INT_MAX/2 - xd_size) {\n                    return AVERROR_INVALIDDATA;\n                }\n                data_len[j] = len;\n                xd_size += len;\n            }\n\n            ret = ff_alloc_extradata(st->codecpar, 64 + xd_size + xd_size / 255);\n            if (ret < 0)\n                return ret;\n\n            p = st->codecpar->extradata;\n            p[0] = 2;\n\n            for (j = 0; j < num_data - 1; j++) {\n                unsigned delta = av_xiphlacing(&p[offset], data_len[j]);\n                if (delta > data_len[j]) {\n                    return AVERROR_INVALIDDATA;\n                }\n                offset += delta;\n            }\n\n            for (j = 0; j < num_data; j++) {\n                int ret = avio_read(pb, &p[offset], data_len[j]);\n                if (ret < data_len[j]) {\n                    st->codecpar->extradata_size = 0;\n                    av_freep(&st->codecpar->extradata);\n                    break;\n                }\n                offset += data_len[j];\n            }\n\n            if (offset < st->codecpar->extradata_size)\n                st->codecpar->extradata_size = offset;\n        }\n    }\n\n    return 0;\n}", "func_src_after": "static int track_header(VividasDemuxContext *viv, AVFormatContext *s,  uint8_t *buf, int size)\n{\n    int i, j, ret;\n    int64_t off;\n    int val_1;\n    int num_video;\n    AVIOContext pb0, *pb = &pb0;\n\n    ffio_init_context(pb, buf, size, 0, NULL, NULL, NULL, NULL);\n\n    ffio_read_varlen(pb); // track_header_len\n    avio_r8(pb); // '1'\n\n    val_1 = ffio_read_varlen(pb);\n\n    for (i=0;i<val_1;i++) {\n        int c = avio_r8(pb);\n        if (avio_feof(pb))\n            return AVERROR_EOF;\n        for (j=0;j<c;j++) {\n            if (avio_feof(pb))\n                return AVERROR_EOF;\n            avio_r8(pb); // val_3\n            avio_r8(pb); // val_4\n        }\n    }\n\n    avio_r8(pb); // num_streams\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_5\n\n    avio_r8(pb); // '2'\n    num_video = avio_r8(pb);\n\n    avio_seek(pb, off, SEEK_SET);\n    if (num_video != 1) {\n        av_log(s, AV_LOG_ERROR, \"number of video tracks %d is not 1\\n\", num_video);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    for (i = 0; i < num_video; i++) {\n        AVStream *st = avformat_new_stream(s, NULL);\n        int num, den;\n\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        st->codecpar->codec_id = AV_CODEC_ID_VP6;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb);\n        avio_r8(pb); // '3'\n        avio_r8(pb); // val_7\n        num = avio_rl32(pb); // frame_time\n        den = avio_rl32(pb); // time_base\n        avpriv_set_pts_info(st, 64, num, den);\n        st->nb_frames = avio_rl32(pb); // n frames\n        st->codecpar->width = avio_rl16(pb); // width\n        st->codecpar->height = avio_rl16(pb); // height\n        avio_r8(pb); // val_8\n        avio_rl32(pb); // val_9\n\n        avio_seek(pb, off, SEEK_SET);\n    }\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_10\n    avio_r8(pb); // '4'\n    viv->num_audio = avio_r8(pb);\n    avio_seek(pb, off, SEEK_SET);\n\n    if (viv->num_audio != 1)\n        av_log(s, AV_LOG_WARNING, \"number of audio tracks %d is not 1\\n\", viv->num_audio);\n\n    for(i=0;i<viv->num_audio;i++) {\n        int q;\n        AVStream *st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = num_video + i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n        st->codecpar->codec_id = AV_CODEC_ID_VORBIS;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb); // length\n        avio_r8(pb); // '5'\n        avio_r8(pb); //codec_id\n        avio_rl16(pb); //codec_subid\n        st->codecpar->channels = avio_rl16(pb); // channels\n        st->codecpar->sample_rate = avio_rl32(pb); // sample_rate\n        avio_seek(pb, 10, SEEK_CUR); // data_1\n        q = avio_r8(pb);\n        avio_seek(pb, q, SEEK_CUR); // data_2\n        avio_r8(pb); // zeropad\n\n        if (avio_tell(pb) < off) {\n            int num_data;\n            int xd_size = 1;\n            int data_len[256];\n            int offset = 1;\n            uint8_t *p;\n            ffio_read_varlen(pb); // val_13\n            avio_r8(pb); // '19'\n            ffio_read_varlen(pb); // len_3\n            num_data = avio_r8(pb);\n            for (j = 0; j < num_data; j++) {\n                uint64_t len = ffio_read_varlen(pb);\n                if (len > INT_MAX/2 - xd_size) {\n                    return AVERROR_INVALIDDATA;\n                }\n                data_len[j] = len;\n                xd_size += len + 1 + len/255;\n            }\n\n            ret = ff_alloc_extradata(st->codecpar, xd_size);\n            if (ret < 0)\n                return ret;\n\n            p = st->codecpar->extradata;\n            p[0] = 2;\n\n            for (j = 0; j < num_data - 1; j++) {\n                unsigned delta = av_xiphlacing(&p[offset], data_len[j]);\n                av_assert0(delta <= xd_size - offset);\n                offset += delta;\n            }\n\n            for (j = 0; j < num_data; j++) {\n                int ret = avio_read(pb, &p[offset], data_len[j]);\n                if (ret < data_len[j]) {\n                    st->codecpar->extradata_size = 0;\n                    av_freep(&st->codecpar->extradata);\n                    break;\n                }\n                av_assert0(data_len[j] <= xd_size - offset);\n                offset += data_len[j];\n            }\n\n            if (offset < st->codecpar->extradata_size)\n                st->codecpar->extradata_size = offset;\n        }\n    }\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/27a99e2c7d450fef15594671eef4465c8a166bd7", "file_name": "libavformat/vividas.c", "vul_type": "cwe-787", "description": "Write a C function to parse video and audio track headers from a buffer in an AVFormatContext using FFmpeg libraries."}
{"func_name": "license_read_new_or_upgrade_license_packet", "func_src_before": "BOOL license_read_new_or_upgrade_license_packet(rdpLicense* license, wStream* s)\n{\n\tUINT32 os_major;\n\tUINT32 os_minor;\n\tUINT32 cbScope, cbCompanyName, cbProductId, cbLicenseInfo;\n\twStream* licenseStream = NULL;\n\tBOOL ret = FALSE;\n\tBYTE computedMac[16];\n\tLICENSE_BLOB* calBlob;\n\n\tDEBUG_LICENSE(\"Receiving Server New/Upgrade License Packet\");\n\n\tcalBlob = license_new_binary_blob(BB_DATA_BLOB);\n\tif (!calBlob)\n\t\treturn FALSE;\n\n\t/* EncryptedLicenseInfo */\n\tif (!license_read_encrypted_blob(license, s, calBlob))\n\t\tgoto out_free_blob;\n\n\t/* compute MAC and check it */\n\tif (Stream_GetRemainingLength(s) < 16)\n\t\tgoto out_free_blob;\n\n\tif (!security_mac_data(license->MacSaltKey, calBlob->data, calBlob->length, computedMac))\n\t\tgoto out_free_blob;\n\n\tif (memcmp(computedMac, Stream_Pointer(s), sizeof(computedMac)) != 0)\n\t{\n\t\tWLog_ERR(TAG, \"new or upgrade license MAC mismatch\");\n\t\tgoto out_free_blob;\n\t}\n\n\tif (!Stream_SafeSeek(s, 16))\n\t\tgoto out_free_blob;\n\n\tlicenseStream = Stream_New(calBlob->data, calBlob->length);\n\tif (!licenseStream)\n\t\tgoto out_free_blob;\n\n\tStream_Read_UINT16(licenseStream, os_minor);\n\tStream_Read_UINT16(licenseStream, os_major);\n\n\t/* Scope */\n\tStream_Read_UINT32(licenseStream, cbScope);\n\tif (Stream_GetRemainingLength(licenseStream) < cbScope)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Scope:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbScope);\n#endif\n\tStream_Seek(licenseStream, cbScope);\n\n\t/* CompanyName */\n\tStream_Read_UINT32(licenseStream, cbCompanyName);\n\tif (Stream_GetRemainingLength(licenseStream) < cbCompanyName)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Company name:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbCompanyName);\n#endif\n\tStream_Seek(licenseStream, cbCompanyName);\n\n\t/* productId */\n\tStream_Read_UINT32(licenseStream, cbProductId);\n\tif (Stream_GetRemainingLength(licenseStream) < cbProductId)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Product id:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbProductId);\n#endif\n\tStream_Seek(licenseStream, cbProductId);\n\n\t/* licenseInfo */\n\tStream_Read_UINT32(licenseStream, cbLicenseInfo);\n\tif (Stream_GetRemainingLength(licenseStream) < cbLicenseInfo)\n\t\tgoto out_free_stream;\n\n\tlicense->state = LICENSE_STATE_COMPLETED;\n\n\tret = TRUE;\n\tif (!license->rdp->settings->OldLicenseBehaviour)\n\t\tret = saveCal(license->rdp->settings, Stream_Pointer(licenseStream), cbLicenseInfo,\n\t\t              license->rdp->settings->ClientHostname);\n\nout_free_stream:\n\tStream_Free(licenseStream, FALSE);\nout_free_blob:\n\tlicense_free_binary_blob(calBlob);\n\treturn ret;\n}", "func_src_after": "BOOL license_read_new_or_upgrade_license_packet(rdpLicense* license, wStream* s)\n{\n\tUINT32 os_major;\n\tUINT32 os_minor;\n\tUINT32 cbScope, cbCompanyName, cbProductId, cbLicenseInfo;\n\twStream* licenseStream = NULL;\n\tBOOL ret = FALSE;\n\tBYTE computedMac[16];\n\tLICENSE_BLOB* calBlob;\n\n\tDEBUG_LICENSE(\"Receiving Server New/Upgrade License Packet\");\n\n\tcalBlob = license_new_binary_blob(BB_DATA_BLOB);\n\tif (!calBlob)\n\t\treturn FALSE;\n\n\t/* EncryptedLicenseInfo */\n\tif (!license_read_encrypted_blob(license, s, calBlob))\n\t\tgoto out_free_blob;\n\n\t/* compute MAC and check it */\n\tif (Stream_GetRemainingLength(s) < 16)\n\t\tgoto out_free_blob;\n\n\tif (!security_mac_data(license->MacSaltKey, calBlob->data, calBlob->length, computedMac))\n\t\tgoto out_free_blob;\n\n\tif (memcmp(computedMac, Stream_Pointer(s), sizeof(computedMac)) != 0)\n\t{\n\t\tWLog_ERR(TAG, \"new or upgrade license MAC mismatch\");\n\t\tgoto out_free_blob;\n\t}\n\n\tif (!Stream_SafeSeek(s, 16))\n\t\tgoto out_free_blob;\n\n\tlicenseStream = Stream_New(calBlob->data, calBlob->length);\n\tif (!licenseStream)\n\t\tgoto out_free_blob;\n\n\tif (Stream_GetRemainingLength(licenseStream) < 8)\n\t\tgoto out_free_stream;\n\n\tStream_Read_UINT16(licenseStream, os_minor);\n\tStream_Read_UINT16(licenseStream, os_major);\n\n\t/* Scope */\n\tStream_Read_UINT32(licenseStream, cbScope);\n\tif (Stream_GetRemainingLength(licenseStream) < cbScope)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Scope:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbScope);\n#endif\n\tStream_Seek(licenseStream, cbScope);\n\n\t/* CompanyName */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbCompanyName);\n\tif (Stream_GetRemainingLength(licenseStream) < cbCompanyName)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Company name:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbCompanyName);\n#endif\n\tStream_Seek(licenseStream, cbCompanyName);\n\n\t/* productId */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbProductId);\n\tif (Stream_GetRemainingLength(licenseStream) < cbProductId)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Product id:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbProductId);\n#endif\n\tStream_Seek(licenseStream, cbProductId);\n\n\t/* licenseInfo */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbLicenseInfo);\n\tif (Stream_GetRemainingLength(licenseStream) < cbLicenseInfo)\n\t\tgoto out_free_stream;\n\n\tlicense->state = LICENSE_STATE_COMPLETED;\n\n\tret = TRUE;\n\tif (!license->rdp->settings->OldLicenseBehaviour)\n\t\tret = saveCal(license->rdp->settings, Stream_Pointer(licenseStream), cbLicenseInfo,\n\t\t              license->rdp->settings->ClientHostname);\n\nout_free_stream:\n\tStream_Free(licenseStream, FALSE);\nout_free_blob:\n\tlicense_free_binary_blob(calBlob);\n\treturn ret;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/6ade7b4cbfd71c54b3d724e8f2d6ac76a58e879a", "file_name": "libfreerdp/core/license.c", "vul_type": "cwe-125", "description": "In C, write a function to process a new or upgraded license packet for Remote Desktop Protocol (RDP) licensing."}
{"func_name": "AcceptBasketRequests", "func_src_before": "func AcceptBasketRequests(w http.ResponseWriter, r *http.Request) {\n\tname := strings.Split(r.URL.Path, \"/\")[1]\n\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\trequest := basket.Add(r)\n\n\t\t// forward request if configured and it's a first forwarding\n\t\tconfig := basket.Config()\n\t\tif len(config.ForwardURL) > 0 && r.Header.Get(DoNotForwardHeader) != \"1\" {\n\t\t\tif config.ProxyResponse {\n\t\t\t\tforwardAndProxyResponse(w, request, config, name)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tgo forwardAndForget(request, config, name)\n\t\t}\n\n\t\twriteBasketResponse(w, r, name, basket)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n}", "func_src_after": "func AcceptBasketRequests(w http.ResponseWriter, r *http.Request) {\n\tname := strings.Split(r.URL.Path, \"/\")[1]\n\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\trequest := basket.Add(r)\n\n\t\t// forward request if configured and it's a first forwarding\n\t\tconfig := basket.Config()\n\t\tif len(config.ForwardURL) > 0 && r.Header.Get(DoNotForwardHeader) != \"1\" {\n\t\t\tif config.ProxyResponse {\n\t\t\t\tforwardAndProxyResponse(w, request, config, name)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tgo forwardAndForget(request, config, name)\n\t\t}\n\n\t\twriteBasketResponse(w, r, name, basket)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 153, "char_end": 277, "line": "\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}], "added": [{"line_no": 5, "char_start": 153, "char_end": 275, "line": "\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}]}, "char_changes": {"deleted": [{"char_start": 191, "char_end": 194, "chars": "[\"+"}, {"char_start": 198, "char_end": 201, "chars": "+\"]"}], "added": [{"char_start": 191, "char_end": 195, "chars": "the "}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go function to handle HTTP requests for a basket service, validating names and optionally forwarding requests."}
{"func_name": "process_packet_tail", "func_src_before": "void process_packet_tail(struct msg_digest *md)\n{\n\tstruct state *st = md->st;\n\tenum state_kind from_state = md->v1_from_state;\n\tconst struct state_v1_microcode *smc = md->smc;\n\tbool new_iv_set = md->new_iv_set;\n\tbool self_delete = FALSE;\n\n\tif (md->hdr.isa_flags & ISAKMP_FLAGS_v1_ENCRYPTION) {\n\t\tendpoint_buf b;\n\t\tdbg(\"received encrypted packet from %s\", str_endpoint(&md->sender, &b));\n\n\t\tif (st == NULL) {\n\t\t\tlibreswan_log(\n\t\t\t\t\"discarding encrypted message for an unknown ISAKMP SA\");\n\t\t\treturn;\n\t\t}\n\t\tif (st->st_skeyid_e_nss == NULL) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\"discarding encrypted message because we haven't yet negotiated keying material\");\n\t\t\treturn;\n\t\t}\n\n\t\t/* Mark as encrypted */\n\t\tmd->encrypted = TRUE;\n\n\t\t/* do the specified decryption\n\t\t *\n\t\t * IV is from st->st_iv or (if new_iv_set) st->st_new_iv.\n\t\t * The new IV is placed in st->st_new_iv\n\t\t *\n\t\t * See RFC 2409 \"IKE\" Appendix B\n\t\t *\n\t\t * XXX The IV should only be updated really if the packet\n\t\t * is successfully processed.\n\t\t * We should keep this value, check for a success return\n\t\t * value from the parsing routines and then replace.\n\t\t *\n\t\t * Each post phase 1 exchange generates IVs from\n\t\t * the last phase 1 block, not the last block sent.\n\t\t */\n\t\tconst struct encrypt_desc *e = st->st_oakley.ta_encrypt;\n\n\t\tif (pbs_left(&md->message_pbs) % e->enc_blocksize != 0) {\n\t\t\tloglog(RC_LOG_SERIOUS, \"malformed message: not a multiple of encryption blocksize\");\n\t\t\treturn;\n\t\t}\n\n\t\t/* XXX Detect weak keys */\n\n\t\t/* grab a copy of raw packet (for duplicate packet detection) */\n\t\tmd->raw_packet = clone_bytes_as_chunk(md->packet_pbs.start,\n\t\t\t\t\t\t      pbs_room(&md->packet_pbs),\n\t\t\t\t\t\t      \"raw packet\");\n\n\t\t/* Decrypt everything after header */\n\t\tif (!new_iv_set) {\n\t\t\tif (st->st_v1_iv.len == 0) {\n\t\t\t\tinit_phase2_iv(st, &md->hdr.isa_msgid);\n\t\t\t} else {\n\t\t\t\t/* use old IV */\n\t\t\t\trestore_new_iv(st, st->st_v1_iv);\n\t\t\t}\n\t\t}\n\n\t\tpassert(st->st_v1_new_iv.len >= e->enc_blocksize);\n\t\tst->st_v1_new_iv.len = e->enc_blocksize;   /* truncate */\n\n\t\tif (DBGP(DBG_CRYPT)) {\n\t\t\tDBG_log(\"decrypting %u bytes using algorithm %s\",\n\t\t\t\t(unsigned) pbs_left(&md->message_pbs),\n\t\t\t\tst->st_oakley.ta_encrypt->common.fqn);\n\t\t\tDBG_dump_hunk(\"IV before:\", st->st_v1_new_iv);\n\t\t}\n\t\te->encrypt_ops->do_crypt(e, md->message_pbs.cur,\n\t\t\t\t\t pbs_left(&md->message_pbs),\n\t\t\t\t\t st->st_enc_key_nss,\n\t\t\t\t\t st->st_v1_new_iv.ptr, FALSE);\n\t\tif (DBGP(DBG_CRYPT)) {\n\t\t\tDBG_dump_hunk(\"IV after:\", st->st_v1_new_iv);\n\t\t\tDBG_log(\"decrypted payload (starts at offset %td):\",\n\t\t\t\tmd->message_pbs.cur - md->message_pbs.roof);\n\t\t\tDBG_dump(NULL, md->message_pbs.start,\n\t\t\t\t md->message_pbs.roof - md->message_pbs.start);\n\t\t}\n\t} else {\n\t\t/* packet was not encryped -- should it have been? */\n\n\t\tif (smc->flags & SMF_INPUT_ENCRYPTED) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"packet rejected: should have been encrypted\");\n\t\t\tSEND_NOTIFICATION(INVALID_FLAGS);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Digest the message.\n\t * Padding must be removed to make hashing work.\n\t * Padding comes from encryption (so this code must be after decryption).\n\t * Padding rules are described before the definition of\n\t * struct isakmp_hdr in packet.h.\n\t */\n\t{\n\t\tenum next_payload_types_ikev1 np = md->hdr.isa_np;\n\t\tlset_t needed = smc->req_payloads;\n\t\tconst char *excuse =\n\t\t\tLIN(SMF_PSK_AUTH | SMF_FIRST_ENCRYPTED_INPUT,\n\t\t\t    smc->flags) ?\n\t\t\t\"probable authentication failure (mismatch of preshared secrets?): \"\n\t\t\t:\n\t\t\t\"\";\n\n\t\twhile (np != ISAKMP_NEXT_NONE) {\n\t\t\tstruct_desc *sd = v1_payload_desc(np);\n\n\t\t\tif (md->digest_roof >= elemsof(md->digest)) {\n\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t       \"more than %zu payloads in message; ignored\",\n\t\t\t\t       elemsof(md->digest));\n\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tstruct payload_digest *const pd = md->digest + md->digest_roof;\n\n\t\t\t/*\n\t\t\t * only do this in main mode. In aggressive mode, there\n\t\t\t * is no negotiation of NAT-T method. Get it right.\n\t\t\t */\n\t\t\tif (st != NULL && st->st_connection != NULL &&\n\t\t\t    (st->st_connection->policy & POLICY_AGGRESSIVE) == LEMPTY)\n\t\t\t{\n\t\t\t\tswitch (np) {\n\t\t\t\tcase ISAKMP_NEXT_NATD_RFC:\n\t\t\t\tcase ISAKMP_NEXT_NATOA_RFC:\n\t\t\t\t\tif ((st->hidden_variables.st_nat_traversal & NAT_T_WITH_RFC_VALUES) == LEMPTY) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * don't accept NAT-D/NAT-OA reloc directly in message,\n\t\t\t\t\t\t * unless we're using NAT-T RFC\n\t\t\t\t\t\t */\n\t\t\t\t\t\tDBG(DBG_NATT,\n\t\t\t\t\t\t    DBG_log(\"st_nat_traversal was: %s\",\n\t\t\t\t\t\t\t    bitnamesof(natt_bit_names,\n\t\t\t\t\t\t\t\t       st->hidden_variables.st_nat_traversal)));\n\t\t\t\t\t\tsd = NULL;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (sd == NULL) {\n\t\t\t\t/* payload type is out of range or requires special handling */\n\t\t\t\tswitch (np) {\n\t\t\t\tcase ISAKMP_NEXT_ID:\n\t\t\t\t\t/* ??? two kinds of ID payloads */\n\t\t\t\t\tsd = (IS_PHASE1(from_state) ||\n\t\t\t\t\t      IS_PHASE15(from_state)) ?\n\t\t\t\t\t\t&isakmp_identification_desc :\n\t\t\t\t\t\t&isakmp_ipsec_identification_desc;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_NATD_DRAFTS: /* out of range */\n\t\t\t\t\t/*\n\t\t\t\t\t * ISAKMP_NEXT_NATD_DRAFTS was a private use type before RFC-3947.\n\t\t\t\t\t * Since it has the same format as ISAKMP_NEXT_NATD_RFC,\n\t\t\t\t\t * just rewrite np and sd, and carry on.\n\t\t\t\t\t */\n\t\t\t\t\tnp = ISAKMP_NEXT_NATD_RFC;\n\t\t\t\t\tsd = &isakmp_nat_d_drafts;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_NATOA_DRAFTS: /* out of range */\n\t\t\t\t\t/* NAT-OA was a private use type before RFC-3947 -- same format */\n\t\t\t\t\tnp = ISAKMP_NEXT_NATOA_RFC;\n\t\t\t\t\tsd = &isakmp_nat_oa_drafts;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_SAK: /* or ISAKMP_NEXT_NATD_BADDRAFTS */\n\t\t\t\t\t/*\n\t\t\t\t\t * Official standards say that this is ISAKMP_NEXT_SAK,\n\t\t\t\t\t * a part of Group DOI, something we don't implement.\n\t\t\t\t\t * Old non-updated Cisco gear abused this number in ancient NAT drafts.\n\t\t\t\t\t * We ignore (rather than reject) this in support of people\n\t\t\t\t\t * with crufty Cisco machines.\n\t\t\t\t\t */\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage with unsupported payload ISAKMP_NEXT_SAK (or ISAKMP_NEXT_NATD_BADDRAFTS) ignored\",\n\t\t\t\t\t\texcuse);\n\t\t\t\t\t/*\n\t\t\t\t\t * Hack to discard payload, whatever it was.\n\t\t\t\t\t * Since we are skipping the rest of the loop\n\t\t\t\t\t * body we must do some things ourself:\n\t\t\t\t\t * - demarshall the payload\n\t\t\t\t\t * - grab the next payload number (np)\n\t\t\t\t\t * - don't keep payload (don't increment pd)\n\t\t\t\t\t * - skip rest of loop body\n\t\t\t\t\t */\n\t\t\t\t\tif (!in_struct(&pd->payload, &isakmp_ignore_desc, &md->message_pbs,\n\t\t\t\t\t\t       &pd->pbs)) {\n\t\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t       \"%smalformed payload in packet\",\n\t\t\t\t\t\t       excuse);\n\t\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tnp = pd->payload.generic.isag_np;\n\t\t\t\t\t/* NOTE: we do not increment pd! */\n\t\t\t\t\tcontinue;  /* skip rest of the loop */\n\n\t\t\t\tdefault:\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage ignored because it contains an unknown or unexpected payload type (%s) at the outermost level\",\n\t\t\t\t\t       excuse,\n\t\t\t\t\t       enum_show(&ikev1_payload_names, np));\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(INVALID_PAYLOAD_TYPE);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tpassert(sd != NULL);\n\t\t\t}\n\n\t\t\tpassert(np < LELEM_ROOF);\n\n\t\t\t{\n\t\t\t\tlset_t s = LELEM(np);\n\n\t\t\t\tif (LDISJOINT(s,\n\t\t\t\t\t      needed | smc->opt_payloads |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_VID) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_N) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_D) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_CR) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_CERT))) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage ignored because it contains a payload type (%s) unexpected by state %s\",\n\t\t\t\t\t\texcuse,\n\t\t\t\t\t\tenum_show(&ikev1_payload_names, np),\n\t\t\t\t\t\tst->st_state->name);\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(INVALID_PAYLOAD_TYPE);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tDBG(DBG_PARSING,\n\t\t\t\t    DBG_log(\"got payload 0x%\" PRIxLSET\"  (%s) needed: 0x%\" PRIxLSET \" opt: 0x%\" PRIxLSET,\n\t\t\t\t\t    s, enum_show(&ikev1_payload_names, np),\n\t\t\t\t\t    needed, smc->opt_payloads));\n\t\t\t\tneeded &= ~s;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Read in the payload recording what type it\n\t\t\t * should be\n\t\t\t */\n\t\t\tpd->payload_type = np;\n\t\t\tif (!in_struct(&pd->payload, sd, &md->message_pbs,\n\t\t\t\t       &pd->pbs)) {\n\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t       \"%smalformed payload in packet\",\n\t\t\t\t       excuse);\n\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t/* do payload-type specific debugging */\n\t\t\tswitch (np) {\n\t\t\tcase ISAKMP_NEXT_ID:\n\t\t\tcase ISAKMP_NEXT_NATOA_RFC:\n\t\t\t\t/* dump ID section */\n\t\t\t\tDBG(DBG_PARSING,\n\t\t\t\t    DBG_dump(\"     obj: \", pd->pbs.cur,\n\t\t\t\t\t     pbs_left(&pd->pbs)));\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\n\t\t\t/*\n\t\t\t * Place payload at the end of the chain for this type.\n\t\t\t * This code appears in ikev1.c and ikev2.c.\n\t\t\t */\n\t\t\t{\n\t\t\t\t/* np is a proper subscript for chain[] */\n\t\t\t\tpassert(np < elemsof(md->chain));\n\t\t\t\tstruct payload_digest **p = &md->chain[np];\n\n\t\t\t\twhile (*p != NULL)\n\t\t\t\t\tp = &(*p)->next;\n\t\t\t\t*p = pd;\n\t\t\t\tpd->next = NULL;\n\t\t\t}\n\n\t\t\tnp = pd->payload.generic.isag_np;\n\t\t\tmd->digest_roof++;\n\n\t\t\t/* since we've digested one payload happily, it is probably\n\t\t\t * the case that any decryption worked.  So we will not suggest\n\t\t\t * encryption failure as an excuse for subsequent payload\n\t\t\t * problems.\n\t\t\t */\n\t\t\texcuse = \"\";\n\t\t}\n\n\t\tDBG(DBG_PARSING, {\n\t\t\t    if (pbs_left(&md->message_pbs) != 0)\n\t\t\t\t    DBG_log(\"removing %d bytes of padding\",\n\t\t\t\t\t    (int) pbs_left(&md->message_pbs));\n\t\t    });\n\n\t\tmd->message_pbs.roof = md->message_pbs.cur;\n\n\t\t/* check that all mandatory payloads appeared */\n\n\t\tif (needed != 0) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"message for %s is missing payloads %s\",\n\t\t\t       finite_states[from_state]->name,\n\t\t\t       bitnamesof(payload_name_ikev1, needed));\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (!check_v1_HASH(smc->hash_type, smc->message, st, md)) {\n\t\t/*SEND_NOTIFICATION(INVALID_HASH_INFORMATION);*/\n\t\treturn;\n\t}\n\n\t/* more sanity checking: enforce most ordering constraints */\n\n\tif (IS_PHASE1(from_state) || IS_PHASE15(from_state)) {\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5 Exchanges:\n\t\t * \"The SA payload MUST precede all other payloads in a phase 1 exchange.\"\n\t\t */\n\t\tif (md->chain[ISAKMP_NEXT_SA] != NULL &&\n\t\t    md->hdr.isa_np != ISAKMP_NEXT_SA) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"malformed Phase 1 message: does not start with an SA payload\");\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t} else if (IS_QUICK(from_state)) {\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5.5 Phase 2 - Quick Mode\n\t\t *\n\t\t * \"In Quick Mode, a HASH payload MUST immediately follow the ISAKMP\n\t\t *  header and a SA payload MUST immediately follow the HASH.\"\n\t\t * [NOTE: there may be more than one SA payload, so this is not\n\t\t *  totally reasonable.  Probably all SAs should be so constrained.]\n\t\t *\n\t\t * \"If ISAKMP is acting as a client negotiator on behalf of another\n\t\t *  party, the identities of the parties MUST be passed as IDci and\n\t\t *  then IDcr.\"\n\t\t *\n\t\t * \"With the exception of the HASH, SA, and the optional ID payloads,\n\t\t *  there are no payload ordering restrictions on Quick Mode.\"\n\t\t */\n\n\t\tif (md->hdr.isa_np != ISAKMP_NEXT_HASH) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"malformed Quick Mode message: does not start with a HASH payload\");\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\n\t\t{\n\t\t\tstruct payload_digest *p;\n\t\t\tint i;\n\n\t\t\tp = md->chain[ISAKMP_NEXT_SA];\n\t\t\ti = 1;\n\t\t\twhile (p != NULL) {\n\t\t\t\tif (p != &md->digest[i]) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t       \"malformed Quick Mode message: SA payload is in wrong position\");\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tp = p->next;\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5.5 Phase 2 - Quick Mode:\n\t\t * \"If ISAKMP is acting as a client negotiator on behalf of another\n\t\t *  party, the identities of the parties MUST be passed as IDci and\n\t\t *  then IDcr.\"\n\t\t */\n\t\t{\n\t\t\tstruct payload_digest *id = md->chain[ISAKMP_NEXT_ID];\n\n\t\t\tif (id != NULL) {\n\t\t\t\tif (id->next == NULL ||\n\t\t\t\t    id->next->next != NULL) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"malformed Quick Mode message: if any ID payload is present, there must be exactly two\");\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif (id + 1 != id->next) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"malformed Quick Mode message: the ID payloads are not adjacent\");\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * Ignore payloads that we don't handle:\n\t */\n\t/* XXX Handle Notifications */\n\t{\n\t\tstruct payload_digest *p = md->chain[ISAKMP_NEXT_N];\n\n\t\twhile (p != NULL) {\n\t\t\tswitch (p->payload.notification.isan_type) {\n\t\t\tcase R_U_THERE:\n\t\t\tcase R_U_THERE_ACK:\n\t\t\tcase ISAKMP_N_CISCO_LOAD_BALANCE:\n\t\t\tcase PAYLOAD_MALFORMED:\n\t\t\tcase INVALID_MESSAGE_ID:\n\t\t\tcase IPSEC_RESPONDER_LIFETIME:\n\t\t\t\tif (md->hdr.isa_xchg == ISAKMP_XCHG_INFO) {\n\t\t\t\t\t/* these are handled later on in informational() */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/* FALL THROUGH */\n\t\t\tdefault:\n\t\t\t\tif (st == NULL) {\n\t\t\t\t\tDBG(DBG_CONTROL, DBG_log(\n\t\t\t\t\t       \"ignoring informational payload %s, no corresponding state\",\n\t\t\t\t\t       enum_show(& ikev1_notify_names,\n\t\t\t\t\t\t\t p->payload.notification.isan_type)));\n\t\t\t\t} else {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t       \"ignoring informational payload %s, msgid=%08\" PRIx32 \", length=%d\",\n\t\t\t\t\t       enum_show(&ikev1_notify_names,\n\t\t\t\t\t\t\t p->payload.notification.isan_type),\n\t\t\t\t\t       st->st_v1_msgid.id,\n\t\t\t\t\t       p->payload.notification.isan_length);\n\t\t\t\t\tDBG_dump_pbs(&p->pbs);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (DBGP(DBG_BASE)) {\n\t\t\t\tDBG_dump(\"info:\", p->pbs.cur,\n\t\t\t\t\t pbs_left(&p->pbs));\n\t\t\t}\n\n\t\t\tp = p->next;\n\t\t}\n\n\t\tp = md->chain[ISAKMP_NEXT_D];\n\t\twhile (p != NULL) {\n\t\t\tself_delete |= accept_delete(md, p);\n\t\t\tif (DBGP(DBG_BASE)) {\n\t\t\t\tDBG_dump(\"del:\", p->pbs.cur,\n\t\t\t\t\t pbs_left(&p->pbs));\n\t\t\t}\n\t\t\tif (md->st != st) {\n\t\t\t\tpexpect(md->st == NULL);\n\t\t\t\tdbg(\"zapping ST as accept_delete() zapped MD.ST\");\n\t\t\t\tst = md->st;\n\t\t\t}\n\t\t\tp = p->next;\n\t\t}\n\n\t\tp = md->chain[ISAKMP_NEXT_VID];\n\t\twhile (p != NULL) {\n\t\t\thandle_vendorid(md, (char *)p->pbs.cur,\n\t\t\t\t\tpbs_left(&p->pbs), FALSE);\n\t\t\tp = p->next;\n\t\t}\n\t}\n\n\tif (self_delete) {\n\t\taccept_self_delete(md);\n\t\tst = md->st;\n\t\t/* note: st ought to be NULL from here on */\n\t}\n\n\tpexpect(st == md->st);\n\tstatetime_t start = statetime_start(md->st);\n\t/*\n\t * XXX: danger - the .informational() processor deletes ST;\n\t * and then tunnels this loss through MD.ST.\n\t */\n\tcomplete_v1_state_transition(md, smc->processor(st, md));\n\tstatetime_stop(&start, \"%s()\", __func__);\n\t/* our caller will release_any_md(mdp); */\n}", "func_src_after": "void process_packet_tail(struct msg_digest *md)\n{\n\tstruct state *st = md->st;\n\tenum state_kind from_state = md->v1_from_state;\n\tconst struct state_v1_microcode *smc = md->smc;\n\tbool new_iv_set = md->new_iv_set;\n\tbool self_delete = FALSE;\n\n\tif (md->hdr.isa_flags & ISAKMP_FLAGS_v1_ENCRYPTION) {\n\t\tendpoint_buf b;\n\t\tdbg(\"received encrypted packet from %s\", str_endpoint(&md->sender, &b));\n\n\t\tif (st == NULL) {\n\t\t\tlibreswan_log(\n\t\t\t\t\"discarding encrypted message for an unknown ISAKMP SA\");\n\t\t\treturn;\n\t\t}\n\t\tif (st->st_skeyid_e_nss == NULL) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\"discarding encrypted message because we haven't yet negotiated keying material\");\n\t\t\treturn;\n\t\t}\n\n\t\t/* Mark as encrypted */\n\t\tmd->encrypted = TRUE;\n\n\t\t/* do the specified decryption\n\t\t *\n\t\t * IV is from st->st_iv or (if new_iv_set) st->st_new_iv.\n\t\t * The new IV is placed in st->st_new_iv\n\t\t *\n\t\t * See RFC 2409 \"IKE\" Appendix B\n\t\t *\n\t\t * XXX The IV should only be updated really if the packet\n\t\t * is successfully processed.\n\t\t * We should keep this value, check for a success return\n\t\t * value from the parsing routines and then replace.\n\t\t *\n\t\t * Each post phase 1 exchange generates IVs from\n\t\t * the last phase 1 block, not the last block sent.\n\t\t */\n\t\tconst struct encrypt_desc *e = st->st_oakley.ta_encrypt;\n\n\t\tif (pbs_left(&md->message_pbs) % e->enc_blocksize != 0) {\n\t\t\tloglog(RC_LOG_SERIOUS, \"malformed message: not a multiple of encryption blocksize\");\n\t\t\treturn;\n\t\t}\n\n\t\t/* XXX Detect weak keys */\n\n\t\t/* grab a copy of raw packet (for duplicate packet detection) */\n\t\tmd->raw_packet = clone_bytes_as_chunk(md->packet_pbs.start,\n\t\t\t\t\t\t      pbs_room(&md->packet_pbs),\n\t\t\t\t\t\t      \"raw packet\");\n\n\t\t/* Decrypt everything after header */\n\t\tif (!new_iv_set) {\n\t\t\tif (st->st_v1_iv.len == 0) {\n\t\t\t\tinit_phase2_iv(st, &md->hdr.isa_msgid);\n\t\t\t} else {\n\t\t\t\t/* use old IV */\n\t\t\t\trestore_new_iv(st, st->st_v1_iv);\n\t\t\t}\n\t\t}\n\n\t\tpassert(st->st_v1_new_iv.len >= e->enc_blocksize);\n\t\tst->st_v1_new_iv.len = e->enc_blocksize;   /* truncate */\n\n\t\tif (DBGP(DBG_CRYPT)) {\n\t\t\tDBG_log(\"decrypting %u bytes using algorithm %s\",\n\t\t\t\t(unsigned) pbs_left(&md->message_pbs),\n\t\t\t\tst->st_oakley.ta_encrypt->common.fqn);\n\t\t\tDBG_dump_hunk(\"IV before:\", st->st_v1_new_iv);\n\t\t}\n\t\te->encrypt_ops->do_crypt(e, md->message_pbs.cur,\n\t\t\t\t\t pbs_left(&md->message_pbs),\n\t\t\t\t\t st->st_enc_key_nss,\n\t\t\t\t\t st->st_v1_new_iv.ptr, FALSE);\n\t\tif (DBGP(DBG_CRYPT)) {\n\t\t\tDBG_dump_hunk(\"IV after:\", st->st_v1_new_iv);\n\t\t\tDBG_log(\"decrypted payload (starts at offset %td):\",\n\t\t\t\tmd->message_pbs.cur - md->message_pbs.roof);\n\t\t\tDBG_dump(NULL, md->message_pbs.start,\n\t\t\t\t md->message_pbs.roof - md->message_pbs.start);\n\t\t}\n\t} else {\n\t\t/* packet was not encryped -- should it have been? */\n\n\t\tif (smc->flags & SMF_INPUT_ENCRYPTED) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"packet rejected: should have been encrypted\");\n\t\t\tSEND_NOTIFICATION(INVALID_FLAGS);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Digest the message.\n\t * Padding must be removed to make hashing work.\n\t * Padding comes from encryption (so this code must be after decryption).\n\t * Padding rules are described before the definition of\n\t * struct isakmp_hdr in packet.h.\n\t */\n\t{\n\t\tenum next_payload_types_ikev1 np = md->hdr.isa_np;\n\t\tlset_t needed = smc->req_payloads;\n\t\tconst char *excuse =\n\t\t\tLIN(SMF_PSK_AUTH | SMF_FIRST_ENCRYPTED_INPUT,\n\t\t\t    smc->flags) ?\n\t\t\t\"probable authentication failure (mismatch of preshared secrets?): \"\n\t\t\t:\n\t\t\t\"\";\n\n\t\twhile (np != ISAKMP_NEXT_NONE) {\n\t\t\tstruct_desc *sd = v1_payload_desc(np);\n\n\t\t\tif (md->digest_roof >= elemsof(md->digest)) {\n\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t       \"more than %zu payloads in message; ignored\",\n\t\t\t\t       elemsof(md->digest));\n\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tstruct payload_digest *const pd = md->digest + md->digest_roof;\n\n\t\t\t/*\n\t\t\t * only do this in main mode. In aggressive mode, there\n\t\t\t * is no negotiation of NAT-T method. Get it right.\n\t\t\t */\n\t\t\tif (st != NULL && st->st_connection != NULL &&\n\t\t\t    (st->st_connection->policy & POLICY_AGGRESSIVE) == LEMPTY)\n\t\t\t{\n\t\t\t\tswitch (np) {\n\t\t\t\tcase ISAKMP_NEXT_NATD_RFC:\n\t\t\t\tcase ISAKMP_NEXT_NATOA_RFC:\n\t\t\t\t\tif ((st->hidden_variables.st_nat_traversal & NAT_T_WITH_RFC_VALUES) == LEMPTY) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * don't accept NAT-D/NAT-OA reloc directly in message,\n\t\t\t\t\t\t * unless we're using NAT-T RFC\n\t\t\t\t\t\t */\n\t\t\t\t\t\tDBG(DBG_NATT,\n\t\t\t\t\t\t    DBG_log(\"st_nat_traversal was: %s\",\n\t\t\t\t\t\t\t    bitnamesof(natt_bit_names,\n\t\t\t\t\t\t\t\t       st->hidden_variables.st_nat_traversal)));\n\t\t\t\t\t\tsd = NULL;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (sd == NULL) {\n\t\t\t\t/* payload type is out of range or requires special handling */\n\t\t\t\tswitch (np) {\n\t\t\t\tcase ISAKMP_NEXT_ID:\n\t\t\t\t\t/* ??? two kinds of ID payloads */\n\t\t\t\t\tsd = (IS_PHASE1(from_state) ||\n\t\t\t\t\t      IS_PHASE15(from_state)) ?\n\t\t\t\t\t\t&isakmp_identification_desc :\n\t\t\t\t\t\t&isakmp_ipsec_identification_desc;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_NATD_DRAFTS: /* out of range */\n\t\t\t\t\t/*\n\t\t\t\t\t * ISAKMP_NEXT_NATD_DRAFTS was a private use type before RFC-3947.\n\t\t\t\t\t * Since it has the same format as ISAKMP_NEXT_NATD_RFC,\n\t\t\t\t\t * just rewrite np and sd, and carry on.\n\t\t\t\t\t */\n\t\t\t\t\tnp = ISAKMP_NEXT_NATD_RFC;\n\t\t\t\t\tsd = &isakmp_nat_d_drafts;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_NATOA_DRAFTS: /* out of range */\n\t\t\t\t\t/* NAT-OA was a private use type before RFC-3947 -- same format */\n\t\t\t\t\tnp = ISAKMP_NEXT_NATOA_RFC;\n\t\t\t\t\tsd = &isakmp_nat_oa_drafts;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_SAK: /* or ISAKMP_NEXT_NATD_BADDRAFTS */\n\t\t\t\t\t/*\n\t\t\t\t\t * Official standards say that this is ISAKMP_NEXT_SAK,\n\t\t\t\t\t * a part of Group DOI, something we don't implement.\n\t\t\t\t\t * Old non-updated Cisco gear abused this number in ancient NAT drafts.\n\t\t\t\t\t * We ignore (rather than reject) this in support of people\n\t\t\t\t\t * with crufty Cisco machines.\n\t\t\t\t\t */\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage with unsupported payload ISAKMP_NEXT_SAK (or ISAKMP_NEXT_NATD_BADDRAFTS) ignored\",\n\t\t\t\t\t\texcuse);\n\t\t\t\t\t/*\n\t\t\t\t\t * Hack to discard payload, whatever it was.\n\t\t\t\t\t * Since we are skipping the rest of the loop\n\t\t\t\t\t * body we must do some things ourself:\n\t\t\t\t\t * - demarshall the payload\n\t\t\t\t\t * - grab the next payload number (np)\n\t\t\t\t\t * - don't keep payload (don't increment pd)\n\t\t\t\t\t * - skip rest of loop body\n\t\t\t\t\t */\n\t\t\t\t\tif (!in_struct(&pd->payload, &isakmp_ignore_desc, &md->message_pbs,\n\t\t\t\t\t\t       &pd->pbs)) {\n\t\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t       \"%smalformed payload in packet\",\n\t\t\t\t\t\t       excuse);\n\t\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tnp = pd->payload.generic.isag_np;\n\t\t\t\t\t/* NOTE: we do not increment pd! */\n\t\t\t\t\tcontinue;  /* skip rest of the loop */\n\n\t\t\t\tdefault:\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage ignored because it contains an unknown or unexpected payload type (%s) at the outermost level\",\n\t\t\t\t\t       excuse,\n\t\t\t\t\t       enum_show(&ikev1_payload_names, np));\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(INVALID_PAYLOAD_TYPE);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tpassert(sd != NULL);\n\t\t\t}\n\n\t\t\tpassert(np < LELEM_ROOF);\n\n\t\t\t{\n\t\t\t\tlset_t s = LELEM(np);\n\n\t\t\t\tif (LDISJOINT(s,\n\t\t\t\t\t      needed | smc->opt_payloads |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_VID) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_N) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_D) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_CR) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_CERT))) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage ignored because it contains a payload type (%s) unexpected by state %s\",\n\t\t\t\t\t\texcuse,\n\t\t\t\t\t\tenum_show(&ikev1_payload_names, np),\n\t\t\t\t\t\tfinite_states[smc->state]->name);\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(INVALID_PAYLOAD_TYPE);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tDBG(DBG_PARSING,\n\t\t\t\t    DBG_log(\"got payload 0x%\" PRIxLSET\"  (%s) needed: 0x%\" PRIxLSET \" opt: 0x%\" PRIxLSET,\n\t\t\t\t\t    s, enum_show(&ikev1_payload_names, np),\n\t\t\t\t\t    needed, smc->opt_payloads));\n\t\t\t\tneeded &= ~s;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Read in the payload recording what type it\n\t\t\t * should be\n\t\t\t */\n\t\t\tpd->payload_type = np;\n\t\t\tif (!in_struct(&pd->payload, sd, &md->message_pbs,\n\t\t\t\t       &pd->pbs)) {\n\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t       \"%smalformed payload in packet\",\n\t\t\t\t       excuse);\n\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t/* do payload-type specific debugging */\n\t\t\tswitch (np) {\n\t\t\tcase ISAKMP_NEXT_ID:\n\t\t\tcase ISAKMP_NEXT_NATOA_RFC:\n\t\t\t\t/* dump ID section */\n\t\t\t\tDBG(DBG_PARSING,\n\t\t\t\t    DBG_dump(\"     obj: \", pd->pbs.cur,\n\t\t\t\t\t     pbs_left(&pd->pbs)));\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\n\t\t\t/*\n\t\t\t * Place payload at the end of the chain for this type.\n\t\t\t * This code appears in ikev1.c and ikev2.c.\n\t\t\t */\n\t\t\t{\n\t\t\t\t/* np is a proper subscript for chain[] */\n\t\t\t\tpassert(np < elemsof(md->chain));\n\t\t\t\tstruct payload_digest **p = &md->chain[np];\n\n\t\t\t\twhile (*p != NULL)\n\t\t\t\t\tp = &(*p)->next;\n\t\t\t\t*p = pd;\n\t\t\t\tpd->next = NULL;\n\t\t\t}\n\n\t\t\tnp = pd->payload.generic.isag_np;\n\t\t\tmd->digest_roof++;\n\n\t\t\t/* since we've digested one payload happily, it is probably\n\t\t\t * the case that any decryption worked.  So we will not suggest\n\t\t\t * encryption failure as an excuse for subsequent payload\n\t\t\t * problems.\n\t\t\t */\n\t\t\texcuse = \"\";\n\t\t}\n\n\t\tDBG(DBG_PARSING, {\n\t\t\t    if (pbs_left(&md->message_pbs) != 0)\n\t\t\t\t    DBG_log(\"removing %d bytes of padding\",\n\t\t\t\t\t    (int) pbs_left(&md->message_pbs));\n\t\t    });\n\n\t\tmd->message_pbs.roof = md->message_pbs.cur;\n\n\t\t/* check that all mandatory payloads appeared */\n\n\t\tif (needed != 0) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"message for %s is missing payloads %s\",\n\t\t\t       finite_states[from_state]->name,\n\t\t\t       bitnamesof(payload_name_ikev1, needed));\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (!check_v1_HASH(smc->hash_type, smc->message, st, md)) {\n\t\t/*SEND_NOTIFICATION(INVALID_HASH_INFORMATION);*/\n\t\treturn;\n\t}\n\n\t/* more sanity checking: enforce most ordering constraints */\n\n\tif (IS_PHASE1(from_state) || IS_PHASE15(from_state)) {\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5 Exchanges:\n\t\t * \"The SA payload MUST precede all other payloads in a phase 1 exchange.\"\n\t\t */\n\t\tif (md->chain[ISAKMP_NEXT_SA] != NULL &&\n\t\t    md->hdr.isa_np != ISAKMP_NEXT_SA) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"malformed Phase 1 message: does not start with an SA payload\");\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t} else if (IS_QUICK(from_state)) {\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5.5 Phase 2 - Quick Mode\n\t\t *\n\t\t * \"In Quick Mode, a HASH payload MUST immediately follow the ISAKMP\n\t\t *  header and a SA payload MUST immediately follow the HASH.\"\n\t\t * [NOTE: there may be more than one SA payload, so this is not\n\t\t *  totally reasonable.  Probably all SAs should be so constrained.]\n\t\t *\n\t\t * \"If ISAKMP is acting as a client negotiator on behalf of another\n\t\t *  party, the identities of the parties MUST be passed as IDci and\n\t\t *  then IDcr.\"\n\t\t *\n\t\t * \"With the exception of the HASH, SA, and the optional ID payloads,\n\t\t *  there are no payload ordering restrictions on Quick Mode.\"\n\t\t */\n\n\t\tif (md->hdr.isa_np != ISAKMP_NEXT_HASH) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"malformed Quick Mode message: does not start with a HASH payload\");\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\n\t\t{\n\t\t\tstruct payload_digest *p;\n\t\t\tint i;\n\n\t\t\tp = md->chain[ISAKMP_NEXT_SA];\n\t\t\ti = 1;\n\t\t\twhile (p != NULL) {\n\t\t\t\tif (p != &md->digest[i]) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t       \"malformed Quick Mode message: SA payload is in wrong position\");\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tp = p->next;\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5.5 Phase 2 - Quick Mode:\n\t\t * \"If ISAKMP is acting as a client negotiator on behalf of another\n\t\t *  party, the identities of the parties MUST be passed as IDci and\n\t\t *  then IDcr.\"\n\t\t */\n\t\t{\n\t\t\tstruct payload_digest *id = md->chain[ISAKMP_NEXT_ID];\n\n\t\t\tif (id != NULL) {\n\t\t\t\tif (id->next == NULL ||\n\t\t\t\t    id->next->next != NULL) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"malformed Quick Mode message: if any ID payload is present, there must be exactly two\");\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif (id + 1 != id->next) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"malformed Quick Mode message: the ID payloads are not adjacent\");\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * Ignore payloads that we don't handle:\n\t */\n\t/* XXX Handle Notifications */\n\t{\n\t\tstruct payload_digest *p = md->chain[ISAKMP_NEXT_N];\n\n\t\twhile (p != NULL) {\n\t\t\tswitch (p->payload.notification.isan_type) {\n\t\t\tcase R_U_THERE:\n\t\t\tcase R_U_THERE_ACK:\n\t\t\tcase ISAKMP_N_CISCO_LOAD_BALANCE:\n\t\t\tcase PAYLOAD_MALFORMED:\n\t\t\tcase INVALID_MESSAGE_ID:\n\t\t\tcase IPSEC_RESPONDER_LIFETIME:\n\t\t\t\tif (md->hdr.isa_xchg == ISAKMP_XCHG_INFO) {\n\t\t\t\t\t/* these are handled later on in informational() */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/* FALL THROUGH */\n\t\t\tdefault:\n\t\t\t\tif (st == NULL) {\n\t\t\t\t\tDBG(DBG_CONTROL, DBG_log(\n\t\t\t\t\t       \"ignoring informational payload %s, no corresponding state\",\n\t\t\t\t\t       enum_show(& ikev1_notify_names,\n\t\t\t\t\t\t\t p->payload.notification.isan_type)));\n\t\t\t\t} else {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t       \"ignoring informational payload %s, msgid=%08\" PRIx32 \", length=%d\",\n\t\t\t\t\t       enum_show(&ikev1_notify_names,\n\t\t\t\t\t\t\t p->payload.notification.isan_type),\n\t\t\t\t\t       st->st_v1_msgid.id,\n\t\t\t\t\t       p->payload.notification.isan_length);\n\t\t\t\t\tDBG_dump_pbs(&p->pbs);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (DBGP(DBG_BASE)) {\n\t\t\t\tDBG_dump(\"info:\", p->pbs.cur,\n\t\t\t\t\t pbs_left(&p->pbs));\n\t\t\t}\n\n\t\t\tp = p->next;\n\t\t}\n\n\t\tp = md->chain[ISAKMP_NEXT_D];\n\t\twhile (p != NULL) {\n\t\t\tself_delete |= accept_delete(md, p);\n\t\t\tif (DBGP(DBG_BASE)) {\n\t\t\t\tDBG_dump(\"del:\", p->pbs.cur,\n\t\t\t\t\t pbs_left(&p->pbs));\n\t\t\t}\n\t\t\tif (md->st != st) {\n\t\t\t\tpexpect(md->st == NULL);\n\t\t\t\tdbg(\"zapping ST as accept_delete() zapped MD.ST\");\n\t\t\t\tst = md->st;\n\t\t\t}\n\t\t\tp = p->next;\n\t\t}\n\n\t\tp = md->chain[ISAKMP_NEXT_VID];\n\t\twhile (p != NULL) {\n\t\t\thandle_vendorid(md, (char *)p->pbs.cur,\n\t\t\t\t\tpbs_left(&p->pbs), FALSE);\n\t\t\tp = p->next;\n\t\t}\n\t}\n\n\tif (self_delete) {\n\t\taccept_self_delete(md);\n\t\tst = md->st;\n\t\t/* note: st ought to be NULL from here on */\n\t}\n\n\tpexpect(st == md->st);\n\tstatetime_t start = statetime_start(md->st);\n\t/*\n\t * XXX: danger - the .informational() processor deletes ST;\n\t * and then tunnels this loss through MD.ST.\n\t */\n\tcomplete_v1_state_transition(md, smc->processor(st, md));\n\tstatetime_stop(&start, \"%s()\", __func__);\n\t/* our caller will release_any_md(mdp); */\n}", "commit_link": "github.com/libreswan/libreswan/commit/471a3e41a449d7c753bc4edbba4239501bb62ba8", "file_name": "programs/pluto/ikev1.c", "vul_type": "cwe-125", "description": "Write a C function named `process_packet_tail` that processes an ISAKMP packet's tail end, handling encryption, payload digestion, and state transitions."}
{"func_name": "_inject_file_into_fs", "func_src_before": "def _inject_file_into_fs(fs, path, contents):\n    absolute_path = os.path.join(fs, path.lstrip('/'))\n    parent_dir = os.path.dirname(absolute_path)\n    utils.execute('mkdir', '-p', parent_dir, run_as_root=True)\n    utils.execute('tee', absolute_path, process_input=contents,\n          run_as_root=True)", "func_src_after": "def _inject_file_into_fs(fs, path, contents, append=False):\n    absolute_path = _join_and_check_path_within_fs(fs, path.lstrip('/'))\n\n    parent_dir = os.path.dirname(absolute_path)\n    utils.execute('mkdir', '-p', parent_dir, run_as_root=True)\n\n    args = []\n    if append:\n        args.append('-a')\n    args.append(absolute_path)\n\n    kwargs = dict(process_input=contents, run_as_root=True)\n\n    utils.execute('tee', *args, **kwargs)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to create or append contents to a file at a specified path within a virtual filesystem, ensuring the parent directories exist."}
{"func_name": "Exiv2::WebPImage::getHeaderOffset", "func_src_before": "    long WebPImage::getHeaderOffset(byte *data, long data_size,\n                                    byte *header, long header_size) {\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "func_src_after": "    long WebPImage::getHeaderOffset(byte* data, long data_size, byte* header, long header_size)\n    {\n        if (data_size < header_size) { return -1; }\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "commit_link": "github.com/Exiv2/exiv2/commit/e925bc5addd881543fa503470c8a859e112cca62", "file_name": "src/webpimage.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that finds the position of a header within a block of data and returns the index, or -1 if not found."}
{"func_name": "tcp_test", "func_src_before": "int tcp_test(const char* ip_str, const short port)\n{\n    int sock, i;\n    struct sockaddr_in s_in;\n    int packetsize = 1024;\n    unsigned char packet[packetsize];\n    struct timeval tv, tv2, tv3;\n    int caplen = 0;\n    int times[REQUESTS];\n    int min, avg, max, len;\n    struct net_hdr nh;\n\n    tv3.tv_sec=0;\n    tv3.tv_usec=1;\n\n    s_in.sin_family = PF_INET;\n    s_in.sin_port = htons(port);\n    if (!inet_aton(ip_str, &s_in.sin_addr))\n            return -1;\n\n    if ((sock = socket(s_in.sin_family, SOCK_STREAM, IPPROTO_TCP)) == -1)\n            return -1;\n\n    /* avoid blocking on reading the socket */\n    if( fcntl( sock, F_SETFL, O_NONBLOCK ) < 0 )\n    {\n        perror( \"fcntl(O_NONBLOCK) failed\" );\n        return( 1 );\n    }\n\n    gettimeofday( &tv, NULL );\n\n    while (1)  //waiting for relayed packet\n    {\n        if (connect(sock, (struct sockaddr*) &s_in, sizeof(s_in)) == -1)\n        {\n            if(errno != EINPROGRESS && errno != EALREADY)\n            {\n                perror(\"connect\");\n                close(sock);\n\n                printf(\"Failed to connect\\n\");\n\n                return -1;\n            }\n        }\n        else\n        {\n            gettimeofday( &tv2, NULL );\n            break;\n        }\n\n        gettimeofday( &tv2, NULL );\n        //wait 3000ms for a successful connect\n        if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (3000*1000))\n        {\n            printf(\"Connection timed out\\n\");\n            close(sock);\n            return(-1);\n        }\n        usleep(10);\n    }\n\n    PCT; printf(\"TCP connection successful\\n\");\n\n    //trying to identify airserv-ng\n    memset(&nh, 0, sizeof(nh));\n//     command: GET_CHAN\n    nh.nh_type\t= 2;\n    nh.nh_len\t= htonl(0);\n\n    if (send(sock, &nh, sizeof(nh), 0) != sizeof(nh))\n    {\n        perror(\"send\");\n        return -1;\n    }\n\n    gettimeofday( &tv, NULL );\n    i=0;\n\n    while (1)  //waiting for GET_CHAN answer\n    {\n        caplen = read(sock, &nh, sizeof(nh));\n\n        if(caplen == -1)\n        {\n            if( errno != EAGAIN )\n            {\n                perror(\"read\");\n                return -1;\n            }\n        }\n\n        if( (unsigned)caplen == sizeof(nh))\n        {\n            len = ntohl(nh.nh_len);\n            if( nh.nh_type == 1 && i==0 )\n            {\n                i=1;\n                caplen = read(sock, packet, len);\n                if(caplen == len)\n                {\n                    i=2;\n                    break;\n                }\n                else\n                {\n                    i=0;\n                }\n            }\n            else\n            {\n                caplen = read(sock, packet, len);\n            }\n        }\n\n        gettimeofday( &tv2, NULL );\n        //wait 1000ms for an answer\n        if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (1000*1000))\n        {\n            break;\n        }\n        if(caplen == -1)\n            usleep(10);\n    }\n\n    if(i==2)\n    {\n        PCT; printf(\"airserv-ng found\\n\");\n    }\n    else\n    {\n        PCT; printf(\"airserv-ng NOT found\\n\");\n    }\n\n    close(sock);\n\n    for(i=0; i<REQUESTS; i++)\n    {\n        if ((sock = socket(s_in.sin_family, SOCK_STREAM, IPPROTO_TCP)) == -1)\n                return -1;\n\n        /* avoid blocking on reading the socket */\n        if( fcntl( sock, F_SETFL, O_NONBLOCK ) < 0 )\n        {\n            perror( \"fcntl(O_NONBLOCK) failed\" );\n            return( 1 );\n        }\n\n        usleep(1000);\n\n        gettimeofday( &tv, NULL );\n\n        while (1)  //waiting for relayed packet\n        {\n            if (connect(sock, (struct sockaddr*) &s_in, sizeof(s_in)) == -1)\n            {\n                if(errno != EINPROGRESS && errno != EALREADY)\n                {\n                    perror(\"connect\");\n                    close(sock);\n\n                    printf(\"Failed to connect\\n\");\n\n                    return -1;\n                }\n            }\n            else\n            {\n                gettimeofday( &tv2, NULL );\n                break;\n            }\n\n            gettimeofday( &tv2, NULL );\n            //wait 1000ms for a successful connect\n            if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (1000*1000))\n            {\n                break;\n            }\n            //simple \"high-precision\" usleep\n            select(1, NULL, NULL, NULL, &tv3);\n        }\n        times[i] = ((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec));\n        printf( \"\\r%d/%d\\r\", i, REQUESTS);\n        fflush(stdout);\n        close(sock);\n    }\n\n    min = INT_MAX;\n    avg = 0;\n    max = 0;\n\n    for(i=0; i<REQUESTS; i++)\n    {\n        if(times[i] < min) min = times[i];\n        if(times[i] > max) max = times[i];\n        avg += times[i];\n    }\n    avg /= REQUESTS;\n\n    PCT; printf(\"ping %s:%d (min/avg/max): %.3fms/%.3fms/%.3fms\\n\", ip_str, port, min/1000.0, avg/1000.0, max/1000.0);\n\n    return 0;\n}", "func_src_after": "int tcp_test(const char* ip_str, const short port)\n{\n    int sock, i;\n    struct sockaddr_in s_in;\n    int packetsize = 1024;\n    unsigned char packet[packetsize];\n    struct timeval tv, tv2, tv3;\n    int caplen = 0;\n    int times[REQUESTS];\n    int min, avg, max, len;\n    struct net_hdr nh;\n\n    tv3.tv_sec=0;\n    tv3.tv_usec=1;\n\n    s_in.sin_family = PF_INET;\n    s_in.sin_port = htons(port);\n    if (!inet_aton(ip_str, &s_in.sin_addr))\n            return -1;\n\n    if ((sock = socket(s_in.sin_family, SOCK_STREAM, IPPROTO_TCP)) == -1)\n            return -1;\n\n    /* avoid blocking on reading the socket */\n    if( fcntl( sock, F_SETFL, O_NONBLOCK ) < 0 )\n    {\n        perror( \"fcntl(O_NONBLOCK) failed\" );\n        return( 1 );\n    }\n\n    gettimeofday( &tv, NULL );\n\n    while (1)  //waiting for relayed packet\n    {\n        if (connect(sock, (struct sockaddr*) &s_in, sizeof(s_in)) == -1)\n        {\n            if(errno != EINPROGRESS && errno != EALREADY)\n            {\n                perror(\"connect\");\n                close(sock);\n\n                printf(\"Failed to connect\\n\");\n\n                return -1;\n            }\n        }\n        else\n        {\n            gettimeofday( &tv2, NULL );\n            break;\n        }\n\n        gettimeofday( &tv2, NULL );\n        //wait 3000ms for a successful connect\n        if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (3000*1000))\n        {\n            printf(\"Connection timed out\\n\");\n            close(sock);\n            return(-1);\n        }\n        usleep(10);\n    }\n\n    PCT; printf(\"TCP connection successful\\n\");\n\n    //trying to identify airserv-ng\n    memset(&nh, 0, sizeof(nh));\n//     command: GET_CHAN\n    nh.nh_type\t= 2;\n    nh.nh_len\t= htonl(0);\n\n    if (send(sock, &nh, sizeof(nh), 0) != sizeof(nh))\n    {\n        perror(\"send\");\n        return -1;\n    }\n\n    gettimeofday( &tv, NULL );\n    i=0;\n\n    while (1)  //waiting for GET_CHAN answer\n    {\n        caplen = read(sock, &nh, sizeof(nh));\n\n        if(caplen == -1)\n        {\n            if( errno != EAGAIN )\n            {\n                perror(\"read\");\n                return -1;\n            }\n        }\n\n        if( (unsigned)caplen == sizeof(nh))\n        {\n            len = ntohl(nh.nh_len);\n            if (len > 1024 || len < 0)\n                continue;\n            if( nh.nh_type == 1 && i==0 )\n            {\n                i=1;\n                caplen = read(sock, packet, len);\n                if(caplen == len)\n                {\n                    i=2;\n                    break;\n                }\n                else\n                {\n                    i=0;\n                }\n            }\n            else\n            {\n                caplen = read(sock, packet, len);\n            }\n        }\n\n        gettimeofday( &tv2, NULL );\n        //wait 1000ms for an answer\n        if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (1000*1000))\n        {\n            break;\n        }\n        if(caplen == -1)\n            usleep(10);\n    }\n\n    if(i==2)\n    {\n        PCT; printf(\"airserv-ng found\\n\");\n    }\n    else\n    {\n        PCT; printf(\"airserv-ng NOT found\\n\");\n    }\n\n    close(sock);\n\n    for(i=0; i<REQUESTS; i++)\n    {\n        if ((sock = socket(s_in.sin_family, SOCK_STREAM, IPPROTO_TCP)) == -1)\n                return -1;\n\n        /* avoid blocking on reading the socket */\n        if( fcntl( sock, F_SETFL, O_NONBLOCK ) < 0 )\n        {\n            perror( \"fcntl(O_NONBLOCK) failed\" );\n            return( 1 );\n        }\n\n        usleep(1000);\n\n        gettimeofday( &tv, NULL );\n\n        while (1)  //waiting for relayed packet\n        {\n            if (connect(sock, (struct sockaddr*) &s_in, sizeof(s_in)) == -1)\n            {\n                if(errno != EINPROGRESS && errno != EALREADY)\n                {\n                    perror(\"connect\");\n                    close(sock);\n\n                    printf(\"Failed to connect\\n\");\n\n                    return -1;\n                }\n            }\n            else\n            {\n                gettimeofday( &tv2, NULL );\n                break;\n            }\n\n            gettimeofday( &tv2, NULL );\n            //wait 1000ms for a successful connect\n            if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (1000*1000))\n            {\n                break;\n            }\n            //simple \"high-precision\" usleep\n            select(1, NULL, NULL, NULL, &tv3);\n        }\n        times[i] = ((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec));\n        printf( \"\\r%d/%d\\r\", i, REQUESTS);\n        fflush(stdout);\n        close(sock);\n    }\n\n    min = INT_MAX;\n    avg = 0;\n    max = 0;\n\n    for(i=0; i<REQUESTS; i++)\n    {\n        if(times[i] < min) min = times[i];\n        if(times[i] > max) max = times[i];\n        avg += times[i];\n    }\n    avg /= REQUESTS;\n\n    PCT; printf(\"ping %s:%d (min/avg/max): %.3fms/%.3fms/%.3fms\\n\", ip_str, port, min/1000.0, avg/1000.0, max/1000.0);\n\n    return 0;\n}", "commit_link": "github.com/aircrack-ng/aircrack-ng/commit/091b153f294b9b695b0b2831e65936438b550d7b", "file_name": "src/aireplay-ng.c", "vul_type": "cwe-787", "description": "Write a C function named `tcp_test` that attempts to establish a TCP connection to a specified IP and port, sends a specific command, and measures connection times."}
{"func_name": "modbus_reply", "func_src_before": "int modbus_reply(modbus_t *ctx, const uint8_t *req,\n                 int req_length, modbus_mapping_t *mb_mapping)\n{\n    int offset;\n    int slave;\n    int function;\n    uint16_t address;\n    uint8_t rsp[MAX_MESSAGE_LENGTH];\n    int rsp_length = 0;\n    sft_t sft;\n\n    if (ctx == NULL) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    offset = ctx->backend->header_length;\n    slave = req[offset - 1];\n    function = req[offset];\n    address = (req[offset + 1] << 8) + req[offset + 2];\n\n    sft.slave = slave;\n    sft.function = function;\n    sft.t_id = ctx->backend->prepare_response_tid(req, &req_length);\n\n    /* Data are flushed on illegal number of values errors. */\n    switch (function) {\n    case MODBUS_FC_READ_COILS:\n    case MODBUS_FC_READ_DISCRETE_INPUTS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_DISCRETE_INPUTS);\n        int start_bits = is_input ? mb_mapping->start_input_bits : mb_mapping->start_bits;\n        int nb_bits = is_input ? mb_mapping->nb_input_bits : mb_mapping->nb_bits;\n        uint8_t *tab_bits = is_input ? mb_mapping->tab_input_bits : mb_mapping->tab_bits;\n        const char * const name = is_input ? \"read_input_bits\" : \"read_bits\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_bits;\n\n        if (nb < 1 || MODBUS_MAX_READ_BITS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_BITS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = (nb / 8) + ((nb % 8) ? 1 : 0);\n            rsp_length = response_io_status(tab_bits, mapping_address, nb,\n                                            rsp, rsp_length);\n        }\n    }\n        break;\n    case MODBUS_FC_READ_HOLDING_REGISTERS:\n    case MODBUS_FC_READ_INPUT_REGISTERS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_INPUT_REGISTERS);\n        int start_registers = is_input ? mb_mapping->start_input_registers : mb_mapping->start_registers;\n        int nb_registers = is_input ? mb_mapping->nb_input_registers : mb_mapping->nb_registers;\n        uint16_t *tab_registers = is_input ? mb_mapping->tab_input_registers : mb_mapping->tab_registers;\n        const char * const name = is_input ? \"read_input_registers\" : \"read_registers\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_registers;\n\n        if (nb < 1 || MODBUS_MAX_READ_REGISTERS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_REGISTERS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            int i;\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = tab_registers[i] >> 8;\n                rsp[rsp_length++] = tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_COIL: {\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bit\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            if (data == 0xFF00 || data == 0x0) {\n                mb_mapping->tab_bits[mapping_address] = data ? ON : OFF;\n                memcpy(rsp, req, req_length);\n                rsp_length = req_length;\n            } else {\n                rsp_length = response_exception(\n                    ctx, &sft,\n                    MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, FALSE,\n                    \"Illegal data value 0x%0X in write_bit request at address %0X\\n\",\n                    data, address);\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_COILS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_BITS < nb) {\n            /* May be the indication has been truncated on reading because of\n             * invalid address (eg. nb is 0 but the request contains values to\n             * write) so it's necessary to flush. */\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_bits (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_BITS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bits\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            /* 6 = byte count */\n            modbus_set_bits_from_bytes(mb_mapping->tab_bits, mapping_address, nb,\n                                       &req[offset + 6]);\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the bit address (2) and the quantity of bits */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_REGISTERS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_registers (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_registers\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            int i, j;\n            for (i = mapping_address, j = 6; i < mapping_address + nb; i++, j += 2) {\n                /* 6 and 7 = first value */\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the address (2) and the no. of registers */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_REPORT_SLAVE_ID: {\n        int str_len;\n        int byte_count_pos;\n\n        rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n        /* Skip byte count for now */\n        byte_count_pos = rsp_length++;\n        rsp[rsp_length++] = _REPORT_SLAVE_ID;\n        /* Run indicator status to ON */\n        rsp[rsp_length++] = 0xFF;\n        /* LMB + length of LIBMODBUS_VERSION_STRING */\n        str_len = 3 + strlen(LIBMODBUS_VERSION_STRING);\n        memcpy(rsp + rsp_length, \"LMB\" LIBMODBUS_VERSION_STRING, str_len);\n        rsp_length += str_len;\n        rsp[byte_count_pos] = rsp_length - byte_count_pos - 1;\n    }\n        break;\n    case MODBUS_FC_READ_EXCEPTION_STATUS:\n        if (ctx->debug) {\n            fprintf(stderr, \"FIXME Not implemented\\n\");\n        }\n        errno = ENOPROTOOPT;\n        return -1;\n        break;\n    case MODBUS_FC_MASK_WRITE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            uint16_t data = mb_mapping->tab_registers[mapping_address];\n            uint16_t and = (req[offset + 3] << 8) + req[offset + 4];\n            uint16_t or = (req[offset + 5] << 8) + req[offset + 6];\n\n            data = (data & and) | (or & (~and));\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_AND_READ_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        uint16_t address_write = (req[offset + 5] << 8) + req[offset + 6];\n        int nb_write = (req[offset + 7] << 8) + req[offset + 8];\n        int nb_write_bytes = req[offset + 9];\n        int mapping_address = address - mb_mapping->start_registers;\n        int mapping_address_write = address_write - mb_mapping->start_registers;\n\n        if (nb_write < 1 || MODBUS_MAX_WR_WRITE_REGISTERS < nb_write ||\n            nb < 1 || MODBUS_MAX_WR_READ_REGISTERS < nb ||\n            nb_write_bytes != nb_write * 2) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values (W%d, R%d) in write_and_read_registers (max W%d, R%d)\\n\",\n                nb_write, nb, MODBUS_MAX_WR_WRITE_REGISTERS, MODBUS_MAX_WR_READ_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers ||\n                   mapping_address < 0 ||\n                   (mapping_address_write + nb_write) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data read address 0x%0X or write address 0x%0X write_and_read_registers\\n\",\n                mapping_address < 0 ? address : address + nb,\n                mapping_address_write < 0 ? address_write : address_write + nb_write);\n        } else {\n            int i, j;\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n\n            /* Write first.\n               10 and 11 are the offset of the first values to write */\n            for (i = mapping_address_write, j = 10;\n                 i < mapping_address_write + nb_write; i++, j += 2) {\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            /* and read the data for the response */\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] >> 8;\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n\n    default:\n        rsp_length = response_exception(\n            ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_FUNCTION, rsp, TRUE,\n            \"Unknown Modbus function code: 0x%0X\\n\", function);\n        break;\n    }\n\n    /* Suppress any responses when the request was a broadcast */\n    return (ctx->backend->backend_type == _MODBUS_BACKEND_TYPE_RTU &&\n            slave == MODBUS_BROADCAST_ADDRESS) ? 0 : send_msg(ctx, rsp, rsp_length);\n}", "func_src_after": "int modbus_reply(modbus_t *ctx, const uint8_t *req,\n                 int req_length, modbus_mapping_t *mb_mapping)\n{\n    int offset;\n    int slave;\n    int function;\n    uint16_t address;\n    uint8_t rsp[MAX_MESSAGE_LENGTH];\n    int rsp_length = 0;\n    sft_t sft;\n\n    if (ctx == NULL) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    offset = ctx->backend->header_length;\n    slave = req[offset - 1];\n    function = req[offset];\n    address = (req[offset + 1] << 8) + req[offset + 2];\n\n    sft.slave = slave;\n    sft.function = function;\n    sft.t_id = ctx->backend->prepare_response_tid(req, &req_length);\n\n    /* Data are flushed on illegal number of values errors. */\n    switch (function) {\n    case MODBUS_FC_READ_COILS:\n    case MODBUS_FC_READ_DISCRETE_INPUTS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_DISCRETE_INPUTS);\n        int start_bits = is_input ? mb_mapping->start_input_bits : mb_mapping->start_bits;\n        int nb_bits = is_input ? mb_mapping->nb_input_bits : mb_mapping->nb_bits;\n        uint8_t *tab_bits = is_input ? mb_mapping->tab_input_bits : mb_mapping->tab_bits;\n        const char * const name = is_input ? \"read_input_bits\" : \"read_bits\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_bits;\n\n        if (nb < 1 || MODBUS_MAX_READ_BITS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_BITS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = (nb / 8) + ((nb % 8) ? 1 : 0);\n            rsp_length = response_io_status(tab_bits, mapping_address, nb,\n                                            rsp, rsp_length);\n        }\n    }\n        break;\n    case MODBUS_FC_READ_HOLDING_REGISTERS:\n    case MODBUS_FC_READ_INPUT_REGISTERS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_INPUT_REGISTERS);\n        int start_registers = is_input ? mb_mapping->start_input_registers : mb_mapping->start_registers;\n        int nb_registers = is_input ? mb_mapping->nb_input_registers : mb_mapping->nb_registers;\n        uint16_t *tab_registers = is_input ? mb_mapping->tab_input_registers : mb_mapping->tab_registers;\n        const char * const name = is_input ? \"read_input_registers\" : \"read_registers\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_registers;\n\n        if (nb < 1 || MODBUS_MAX_READ_REGISTERS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_REGISTERS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            int i;\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = tab_registers[i] >> 8;\n                rsp[rsp_length++] = tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_COIL: {\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bit\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            if (data == 0xFF00 || data == 0x0) {\n                mb_mapping->tab_bits[mapping_address] = data ? ON : OFF;\n                memcpy(rsp, req, req_length);\n                rsp_length = req_length;\n            } else {\n                rsp_length = response_exception(\n                    ctx, &sft,\n                    MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, FALSE,\n                    \"Illegal data value 0x%0X in write_bit request at address %0X\\n\",\n                    data, address);\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_COILS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int nb_bits = req[offset + 5];\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_BITS < nb || nb_bits * 8 < nb) {\n            /* May be the indication has been truncated on reading because of\n             * invalid address (eg. nb is 0 but the request contains values to\n             * write) so it's necessary to flush. */\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_bits (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_BITS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bits\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            /* 6 = byte count */\n            modbus_set_bits_from_bytes(mb_mapping->tab_bits, mapping_address, nb,\n                                       &req[offset + 6]);\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the bit address (2) and the quantity of bits */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int nb_bytes = req[offset + 5];\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_REGISTERS < nb || nb_bytes * 8 < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_registers (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_registers\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            int i, j;\n            for (i = mapping_address, j = 6; i < mapping_address + nb; i++, j += 2) {\n                /* 6 and 7 = first value */\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the address (2) and the no. of registers */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_REPORT_SLAVE_ID: {\n        int str_len;\n        int byte_count_pos;\n\n        rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n        /* Skip byte count for now */\n        byte_count_pos = rsp_length++;\n        rsp[rsp_length++] = _REPORT_SLAVE_ID;\n        /* Run indicator status to ON */\n        rsp[rsp_length++] = 0xFF;\n        /* LMB + length of LIBMODBUS_VERSION_STRING */\n        str_len = 3 + strlen(LIBMODBUS_VERSION_STRING);\n        memcpy(rsp + rsp_length, \"LMB\" LIBMODBUS_VERSION_STRING, str_len);\n        rsp_length += str_len;\n        rsp[byte_count_pos] = rsp_length - byte_count_pos - 1;\n    }\n        break;\n    case MODBUS_FC_READ_EXCEPTION_STATUS:\n        if (ctx->debug) {\n            fprintf(stderr, \"FIXME Not implemented\\n\");\n        }\n        errno = ENOPROTOOPT;\n        return -1;\n        break;\n    case MODBUS_FC_MASK_WRITE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            uint16_t data = mb_mapping->tab_registers[mapping_address];\n            uint16_t and = (req[offset + 3] << 8) + req[offset + 4];\n            uint16_t or = (req[offset + 5] << 8) + req[offset + 6];\n\n            data = (data & and) | (or & (~and));\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_AND_READ_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        uint16_t address_write = (req[offset + 5] << 8) + req[offset + 6];\n        int nb_write = (req[offset + 7] << 8) + req[offset + 8];\n        int nb_write_bytes = req[offset + 9];\n        int mapping_address = address - mb_mapping->start_registers;\n        int mapping_address_write = address_write - mb_mapping->start_registers;\n\n        if (nb_write < 1 || MODBUS_MAX_WR_WRITE_REGISTERS < nb_write ||\n            nb < 1 || MODBUS_MAX_WR_READ_REGISTERS < nb ||\n            nb_write_bytes != nb_write * 2) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values (W%d, R%d) in write_and_read_registers (max W%d, R%d)\\n\",\n                nb_write, nb, MODBUS_MAX_WR_WRITE_REGISTERS, MODBUS_MAX_WR_READ_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers ||\n                   mapping_address < 0 ||\n                   (mapping_address_write + nb_write) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data read address 0x%0X or write address 0x%0X write_and_read_registers\\n\",\n                mapping_address < 0 ? address : address + nb,\n                mapping_address_write < 0 ? address_write : address_write + nb_write);\n        } else {\n            int i, j;\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n\n            /* Write first.\n               10 and 11 are the offset of the first values to write */\n            for (i = mapping_address_write, j = 10;\n                 i < mapping_address_write + nb_write; i++, j += 2) {\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            /* and read the data for the response */\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] >> 8;\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n\n    default:\n        rsp_length = response_exception(\n            ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_FUNCTION, rsp, TRUE,\n            \"Unknown Modbus function code: 0x%0X\\n\", function);\n        break;\n    }\n\n    /* Suppress any responses when the request was a broadcast */\n    return (ctx->backend->backend_type == _MODBUS_BACKEND_TYPE_RTU &&\n            slave == MODBUS_BROADCAST_ADDRESS) ? 0 : send_msg(ctx, rsp, rsp_length);\n}", "commit_link": "github.com/stephane/libmodbus/commit/5ccdf5ef79d742640355d1132fa9e2abc7fbaefc", "file_name": "src/modbus.c", "vul_type": "cwe-125", "description": "Implement a function in C that processes Modbus requests and generates appropriate responses based on the function codes and data provided."}
{"func_name": "cut", "func_src_before": "    def cut(self, key):\n        try:\n            self.etcd.delete(os.path.join(self.namespace, key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "func_src_after": "    def cut(self, key):\n        try:\n            self.etcd.delete(self._absolute_key(key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `cut` that deletes a key from an etcd store and handles exceptions."}
{"func_name": "_execute_command_and_parse_attributes", "func_src_before": "    def _execute_command_and_parse_attributes(self, ssh_cmd):\n        \"\"\"Execute command on the Storwize/SVC and parse attributes.\n\n        Exception is raised if the information from the system\n        can not be obtained.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _execute_command_and_parse_attributes: '\n                    ' command %s') % ssh_cmd)\n\n        try:\n            out, err = self._run_ssh(ssh_cmd)\n        except exception.ProcessExecutionError as e:\n            # Didn't get details from the storage, return None\n            LOG.error(_('CLI Exception output:\\n command: %(cmd)s\\n '\n                        'stdout: %(out)s\\n stderr: %(err)s') %\n                      {'cmd': ssh_cmd,\n                       'out': e.stdout,\n                       'err': e.stderr})\n            return None\n\n        self._assert_ssh_return(len(out),\n                                '_execute_command_and_parse_attributes',\n                                ssh_cmd, out, err)\n        attributes = {}\n        for attrib_line in out.split('\\n'):\n            # If '!' not found, return the string and two empty strings\n            attrib_name, foo, attrib_value = attrib_line.partition('!')\n            if attrib_name is not None and len(attrib_name.strip()):\n                attributes[attrib_name] = attrib_value\n\n        LOG.debug(_('leave: _execute_command_and_parse_attributes:\\n'\n                    'command: %(cmd)s\\n'\n                    'attributes: %(attr)s')\n                  % {'cmd': ssh_cmd,\n                     'attr': str(attributes)})\n\n        return attributes", "func_src_after": "    def _execute_command_and_parse_attributes(self, ssh_cmd):\n        \"\"\"Execute command on the Storwize/SVC and parse attributes.\n\n        Exception is raised if the information from the system\n        can not be obtained.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _execute_command_and_parse_attributes: '\n                    ' command %s') % str(ssh_cmd))\n\n        try:\n            out, err = self._run_ssh(ssh_cmd)\n        except exception.ProcessExecutionError as e:\n            # Didn't get details from the storage, return None\n            LOG.error(_('CLI Exception output:\\n command: %(cmd)s\\n '\n                        'stdout: %(out)s\\n stderr: %(err)s') %\n                      {'cmd': ssh_cmd,\n                       'out': e.stdout,\n                       'err': e.stderr})\n            return None\n\n        self._assert_ssh_return(len(out),\n                                '_execute_command_and_parse_attributes',\n                                ssh_cmd, out, err)\n        attributes = {}\n        for attrib_line in out.split('\\n'):\n            # If '!' not found, return the string and two empty strings\n            attrib_name, foo, attrib_value = attrib_line.partition('!')\n            if attrib_name is not None and len(attrib_name.strip()):\n                attributes[attrib_name] = attrib_value\n\n        LOG.debug(_('leave: _execute_command_and_parse_attributes:\\n'\n                    'command: %(cmd)s\\n'\n                    'attributes: %(attr)s')\n                  % {'cmd': str(ssh_cmd),\n                     'attr': str(attributes)})\n\n        return attributes", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "In Python, write a function to execute an SSH command, parse the output into attributes, and handle any execution errors."}
{"func_name": "htmlvalue", "func_src_before": "    def htmlvalue(self, val):\n        return self.block.render_basic(val)", "func_src_after": "    def htmlvalue(self, val):\n        \"\"\"\n        Return an HTML representation of this block that is safe to be included\n        in comparison views\n        \"\"\"\n        return escape(text_from_html(self.block.render_basic(val)))", "commit_link": "github.com/wagtail/wagtail/commit/61045ceefea114c40ac4b680af58990dbe732389", "file_name": "wagtail/admin/compare.py", "vul_type": "cwe-079", "description": "Provide a Python function named `htmlvalue` that returns a safe HTML representation of a given value using a block's render method."}
{"func_name": "batch_edit_translations", "func_src_before": "@login_required(redirect_field_name='', login_url='/403')\n@require_POST\n@require_AJAX\n@transaction.atomic\ndef batch_edit_translations(request):\n    \"\"\"Perform an action on a list of translations.\n\n    Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view\n    are defined in `models.BatchActionsForm`.\n\n    \"\"\"\n    form = forms.BatchActionsForm(request.POST)\n    if not form.is_valid():\n        return HttpResponseBadRequest(form.errors.as_json())\n\n    locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n    entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n\n    if not entities.exists():\n        return JsonResponse({'count': 0})\n\n    # Batch editing is only available to translators. Check if user has\n    # translate permissions for all of the projects in passed entities.\n    # Also make sure projects are not enabled in read-only mode for a locale.\n    projects_pk = entities.values_list('resource__project__pk', flat=True)\n    projects = Project.objects.filter(pk__in=projects_pk.distinct())\n\n    for project in projects:\n        if (\n            not request.user.can_translate(project=project, locale=locale)\n            or readonly_exists(projects, locale)\n        ):\n            return HttpResponseForbidden(\n                \"Forbidden: You don't have permission for batch editing\"\n            )\n\n    # Find all impacted active translations, including plural forms.\n    active_translations = Translation.objects.filter(\n        active=True,\n        locale=locale,\n        entity__in=entities,\n    )\n\n    # Execute the actual action.\n    action_function = ACTIONS_FN_MAP[form.cleaned_data['action']]\n    action_status = action_function(\n        form,\n        request.user,\n        active_translations,\n        locale,\n    )\n\n    if action_status.get('error'):\n        return JsonResponse(action_status)\n\n    invalid_translation_count = len(action_status.get('invalid_translation_pks', []))\n    if action_status['count'] == 0:\n        return JsonResponse({\n            'count': 0,\n            'invalid_translation_count': invalid_translation_count,\n        })\n\n    update_stats(action_status['translated_resources'], locale)\n    mark_changed_translation(action_status['changed_entities'], locale)\n\n    # Update latest translation.\n    if action_status['latest_translation_pk']:\n        Translation.objects.get(\n            pk=action_status['latest_translation_pk']\n        ).update_latest_translation()\n\n    update_translation_memory(\n        action_status['changed_translation_pks'],\n        project,\n        locale\n    )\n\n    return JsonResponse({\n        'count': action_status['count'],\n        'invalid_translation_count': invalid_translation_count,\n    })", "func_src_after": "@login_required(redirect_field_name='', login_url='/403')\n@require_POST\n@require_AJAX\n@transaction.atomic\ndef batch_edit_translations(request):\n    \"\"\"Perform an action on a list of translations.\n\n    Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view\n    are defined in `models.BatchActionsForm`.\n\n    \"\"\"\n    form = forms.BatchActionsForm(request.POST)\n    if not form.is_valid():\n        return HttpResponseBadRequest(form.errors.as_json(escape_html=True))\n\n    locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n    entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n\n    if not entities.exists():\n        return JsonResponse({'count': 0})\n\n    # Batch editing is only available to translators. Check if user has\n    # translate permissions for all of the projects in passed entities.\n    # Also make sure projects are not enabled in read-only mode for a locale.\n    projects_pk = entities.values_list('resource__project__pk', flat=True)\n    projects = Project.objects.filter(pk__in=projects_pk.distinct())\n\n    for project in projects:\n        if (\n            not request.user.can_translate(project=project, locale=locale)\n            or readonly_exists(projects, locale)\n        ):\n            return HttpResponseForbidden(\n                \"Forbidden: You don't have permission for batch editing\"\n            )\n\n    # Find all impacted active translations, including plural forms.\n    active_translations = Translation.objects.filter(\n        active=True,\n        locale=locale,\n        entity__in=entities,\n    )\n\n    # Execute the actual action.\n    action_function = ACTIONS_FN_MAP[form.cleaned_data['action']]\n    action_status = action_function(\n        form,\n        request.user,\n        active_translations,\n        locale,\n    )\n\n    if action_status.get('error'):\n        return JsonResponse(action_status)\n\n    invalid_translation_count = len(action_status.get('invalid_translation_pks', []))\n    if action_status['count'] == 0:\n        return JsonResponse({\n            'count': 0,\n            'invalid_translation_count': invalid_translation_count,\n        })\n\n    update_stats(action_status['translated_resources'], locale)\n    mark_changed_translation(action_status['changed_entities'], locale)\n\n    # Update latest translation.\n    if action_status['latest_translation_pk']:\n        Translation.objects.get(\n            pk=action_status['latest_translation_pk']\n        ).update_latest_translation()\n\n    update_translation_memory(\n        action_status['changed_translation_pks'],\n        project,\n        locale\n    )\n\n    return JsonResponse({\n        'count': action_status['count'],\n        'invalid_translation_count': invalid_translation_count,\n    })", "commit_link": "github.com/onefork/pontoon-sr/commit/fc07ed9c68e08d41f74c078b4e7727f1a0888be8", "file_name": "pontoon/batch/views.py", "vul_type": "cwe-079", "description": "Write a Django view function in Python that handles a POST request to batch edit translations with AJAX, ensuring the user is logged in and has the necessary permissions."}
{"func_name": "ndpi_search_oracle", "func_src_before": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "func_src_after": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload_packet_len >= 3 && packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "commit_link": "github.com/ntop/nDPI/commit/b69177be2fbe01c2442239a61832c44e40136c05", "file_name": "src/lib/protocols/oracle.c", "vul_type": "cwe-125", "description": "In C, write a function to detect Oracle database traffic by examining TCP packets and their payload."}
{"func_name": "kvm_vm_ioctl_check_extension", "func_src_before": "int kvm_vm_ioctl_check_extension(struct kvm *kvm, long ext)\n{\n\tint r;\n\t/* Assume we're using HV mode when the HV module is loaded */\n\tint hv_enabled = kvmppc_hv_ops ? 1 : 0;\n\n\tif (kvm) {\n\t\t/*\n\t\t * Hooray - we know which VM type we're running on. Depend on\n\t\t * that rather than the guess above.\n\t\t */\n\t\thv_enabled = is_kvmppc_hv_enabled(kvm);\n\t}\n\n\tswitch (ext) {\n#ifdef CONFIG_BOOKE\n\tcase KVM_CAP_PPC_BOOKE_SREGS:\n\tcase KVM_CAP_PPC_BOOKE_WATCHDOG:\n\tcase KVM_CAP_PPC_EPR:\n#else\n\tcase KVM_CAP_PPC_SEGSTATE:\n\tcase KVM_CAP_PPC_HIOR:\n\tcase KVM_CAP_PPC_PAPR:\n#endif\n\tcase KVM_CAP_PPC_UNSET_IRQ:\n\tcase KVM_CAP_PPC_IRQ_LEVEL:\n\tcase KVM_CAP_ENABLE_CAP:\n\tcase KVM_CAP_ENABLE_CAP_VM:\n\tcase KVM_CAP_ONE_REG:\n\tcase KVM_CAP_IOEVENTFD:\n\tcase KVM_CAP_DEVICE_CTRL:\n\tcase KVM_CAP_IMMEDIATE_EXIT:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_PPC_PAIRED_SINGLES:\n\tcase KVM_CAP_PPC_OSI:\n\tcase KVM_CAP_PPC_GET_PVINFO:\n#if defined(CONFIG_KVM_E500V2) || defined(CONFIG_KVM_E500MC)\n\tcase KVM_CAP_SW_TLB:\n#endif\n\t\t/* We support this only for PR */\n\t\tr = !hv_enabled;\n\t\tbreak;\n#ifdef CONFIG_KVM_MPIC\n\tcase KVM_CAP_IRQ_MPIC:\n\t\tr = 1;\n\t\tbreak;\n#endif\n\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_SPAPR_TCE:\n\tcase KVM_CAP_SPAPR_TCE_64:\n\t\t/* fallthrough */\n\tcase KVM_CAP_SPAPR_TCE_VFIO:\n\tcase KVM_CAP_PPC_RTAS:\n\tcase KVM_CAP_PPC_FIXUP_HCALL:\n\tcase KVM_CAP_PPC_ENABLE_HCALL:\n#ifdef CONFIG_KVM_XICS\n\tcase KVM_CAP_IRQ_XICS:\n#endif\n\t\tr = 1;\n\t\tbreak;\n\n\tcase KVM_CAP_PPC_ALLOC_HTAB:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif /* CONFIG_PPC_BOOK3S_64 */\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_SMT:\n\t\tr = 0;\n\t\tif (kvm) {\n\t\t\tif (kvm->arch.emul_smt_mode > 1)\n\t\t\t\tr = kvm->arch.emul_smt_mode;\n\t\t\telse\n\t\t\t\tr = kvm->arch.smt_mode;\n\t\t} else if (hv_enabled) {\n\t\t\tif (cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = 1;\n\t\t\telse\n\t\t\t\tr = threads_per_subcore;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_SMT_POSSIBLE:\n\t\tr = 1;\n\t\tif (hv_enabled) {\n\t\t\tif (!cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = ((threads_per_subcore << 1) - 1);\n\t\t\telse\n\t\t\t\t/* P9 can emulate dbells, so allow any mode */\n\t\t\t\tr = 8 | 4 | 2 | 1;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_RMA:\n\t\tr = 0;\n\t\tbreak;\n\tcase KVM_CAP_PPC_HWRNG:\n\t\tr = kvmppc_hwrng_present();\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_RADIX:\n\t\tr = !!(hv_enabled && radix_enabled());\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_HASH_V3:\n\t\tr = !!(hv_enabled && !radix_enabled() &&\n\t\t       cpu_has_feature(CPU_FTR_ARCH_300));\n\t\tbreak;\n#endif\n\tcase KVM_CAP_SYNC_MMU:\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\t\tr = hv_enabled;\n#elif defined(KVM_ARCH_WANT_MMU_NOTIFIER)\n\t\tr = 1;\n#else\n\t\tr = 0;\n#endif\n\t\tbreak;\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_HTAB_FD:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_NR_VCPUS:\n\t\t/*\n\t\t * Recommending a number of CPUs is somewhat arbitrary; we\n\t\t * return the number of present CPUs for -HV (since a host\n\t\t * will have secondary threads \"offline\"), and for other KVM\n\t\t * implementations just count online CPUs.\n\t\t */\n\t\tif (hv_enabled)\n\t\t\tr = num_present_cpus();\n\t\telse\n\t\t\tr = num_online_cpus();\n\t\tbreak;\n\tcase KVM_CAP_NR_MEMSLOTS:\n\t\tr = KVM_USER_MEM_SLOTS;\n\t\tbreak;\n\tcase KVM_CAP_MAX_VCPUS:\n\t\tr = KVM_MAX_VCPUS;\n\t\tbreak;\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_PPC_GET_SMMU_INFO:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_MULTITCE:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_RESIZE_HPT:\n\t\t/* Disable this on POWER9 until code handles new HPTE format */\n\t\tr = !!hv_enabled && !cpu_has_feature(CPU_FTR_ARCH_300);\n\t\tbreak;\n#endif\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_FWNMI:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_PPC_HTM:\n\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) &&\n\t\t    is_kvmppc_hv_enabled(kvm);\n\t\tbreak;\n\tdefault:\n\t\tr = 0;\n\t\tbreak;\n\t}\n\treturn r;\n\n}", "func_src_after": "int kvm_vm_ioctl_check_extension(struct kvm *kvm, long ext)\n{\n\tint r;\n\t/* Assume we're using HV mode when the HV module is loaded */\n\tint hv_enabled = kvmppc_hv_ops ? 1 : 0;\n\n\tif (kvm) {\n\t\t/*\n\t\t * Hooray - we know which VM type we're running on. Depend on\n\t\t * that rather than the guess above.\n\t\t */\n\t\thv_enabled = is_kvmppc_hv_enabled(kvm);\n\t}\n\n\tswitch (ext) {\n#ifdef CONFIG_BOOKE\n\tcase KVM_CAP_PPC_BOOKE_SREGS:\n\tcase KVM_CAP_PPC_BOOKE_WATCHDOG:\n\tcase KVM_CAP_PPC_EPR:\n#else\n\tcase KVM_CAP_PPC_SEGSTATE:\n\tcase KVM_CAP_PPC_HIOR:\n\tcase KVM_CAP_PPC_PAPR:\n#endif\n\tcase KVM_CAP_PPC_UNSET_IRQ:\n\tcase KVM_CAP_PPC_IRQ_LEVEL:\n\tcase KVM_CAP_ENABLE_CAP:\n\tcase KVM_CAP_ENABLE_CAP_VM:\n\tcase KVM_CAP_ONE_REG:\n\tcase KVM_CAP_IOEVENTFD:\n\tcase KVM_CAP_DEVICE_CTRL:\n\tcase KVM_CAP_IMMEDIATE_EXIT:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_PPC_PAIRED_SINGLES:\n\tcase KVM_CAP_PPC_OSI:\n\tcase KVM_CAP_PPC_GET_PVINFO:\n#if defined(CONFIG_KVM_E500V2) || defined(CONFIG_KVM_E500MC)\n\tcase KVM_CAP_SW_TLB:\n#endif\n\t\t/* We support this only for PR */\n\t\tr = !hv_enabled;\n\t\tbreak;\n#ifdef CONFIG_KVM_MPIC\n\tcase KVM_CAP_IRQ_MPIC:\n\t\tr = 1;\n\t\tbreak;\n#endif\n\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_SPAPR_TCE:\n\tcase KVM_CAP_SPAPR_TCE_64:\n\t\t/* fallthrough */\n\tcase KVM_CAP_SPAPR_TCE_VFIO:\n\tcase KVM_CAP_PPC_RTAS:\n\tcase KVM_CAP_PPC_FIXUP_HCALL:\n\tcase KVM_CAP_PPC_ENABLE_HCALL:\n#ifdef CONFIG_KVM_XICS\n\tcase KVM_CAP_IRQ_XICS:\n#endif\n\t\tr = 1;\n\t\tbreak;\n\n\tcase KVM_CAP_PPC_ALLOC_HTAB:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif /* CONFIG_PPC_BOOK3S_64 */\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_SMT:\n\t\tr = 0;\n\t\tif (kvm) {\n\t\t\tif (kvm->arch.emul_smt_mode > 1)\n\t\t\t\tr = kvm->arch.emul_smt_mode;\n\t\t\telse\n\t\t\t\tr = kvm->arch.smt_mode;\n\t\t} else if (hv_enabled) {\n\t\t\tif (cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = 1;\n\t\t\telse\n\t\t\t\tr = threads_per_subcore;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_SMT_POSSIBLE:\n\t\tr = 1;\n\t\tif (hv_enabled) {\n\t\t\tif (!cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = ((threads_per_subcore << 1) - 1);\n\t\t\telse\n\t\t\t\t/* P9 can emulate dbells, so allow any mode */\n\t\t\t\tr = 8 | 4 | 2 | 1;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_RMA:\n\t\tr = 0;\n\t\tbreak;\n\tcase KVM_CAP_PPC_HWRNG:\n\t\tr = kvmppc_hwrng_present();\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_RADIX:\n\t\tr = !!(hv_enabled && radix_enabled());\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_HASH_V3:\n\t\tr = !!(hv_enabled && !radix_enabled() &&\n\t\t       cpu_has_feature(CPU_FTR_ARCH_300));\n\t\tbreak;\n#endif\n\tcase KVM_CAP_SYNC_MMU:\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\t\tr = hv_enabled;\n#elif defined(KVM_ARCH_WANT_MMU_NOTIFIER)\n\t\tr = 1;\n#else\n\t\tr = 0;\n#endif\n\t\tbreak;\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_HTAB_FD:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_NR_VCPUS:\n\t\t/*\n\t\t * Recommending a number of CPUs is somewhat arbitrary; we\n\t\t * return the number of present CPUs for -HV (since a host\n\t\t * will have secondary threads \"offline\"), and for other KVM\n\t\t * implementations just count online CPUs.\n\t\t */\n\t\tif (hv_enabled)\n\t\t\tr = num_present_cpus();\n\t\telse\n\t\t\tr = num_online_cpus();\n\t\tbreak;\n\tcase KVM_CAP_NR_MEMSLOTS:\n\t\tr = KVM_USER_MEM_SLOTS;\n\t\tbreak;\n\tcase KVM_CAP_MAX_VCPUS:\n\t\tr = KVM_MAX_VCPUS;\n\t\tbreak;\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_PPC_GET_SMMU_INFO:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_MULTITCE:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_RESIZE_HPT:\n\t\t/* Disable this on POWER9 until code handles new HPTE format */\n\t\tr = !!hv_enabled && !cpu_has_feature(CPU_FTR_ARCH_300);\n\t\tbreak;\n#endif\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_FWNMI:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_PPC_HTM:\n\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) && hv_enabled;\n\t\tbreak;\n\tdefault:\n\t\tr = 0;\n\t\tbreak;\n\t}\n\treturn r;\n\n}", "commit_link": "github.com/torvalds/linux/commit/ac64115a66c18c01745bbd3c47a36b124e5fd8c0", "file_name": "arch/powerpc/kvm/powerpc.c", "vul_type": "cwe-476", "description": "Write a C function named `kvm_vm_ioctl_check_extension` that checks if a specified KVM extension is supported, considering whether the system is running in HV mode."}
{"func_name": "__rds_rdma_map", "func_src_before": "static int __rds_rdma_map(struct rds_sock *rs, struct rds_get_mr_args *args,\n\t\t\t\tu64 *cookie_ret, struct rds_mr **mr_ret)\n{\n\tstruct rds_mr *mr = NULL, *found;\n\tunsigned int nr_pages;\n\tstruct page **pages = NULL;\n\tstruct scatterlist *sg;\n\tvoid *trans_private;\n\tunsigned long flags;\n\trds_rdma_cookie_t cookie;\n\tunsigned int nents;\n\tlong i;\n\tint ret;\n\n\tif (rs->rs_bound_addr == 0) {\n\t\tret = -ENOTCONN; /* XXX not a great errno */\n\t\tgoto out;\n\t}\n\n\tif (!rs->rs_transport->get_mr) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tnr_pages = rds_pages_in_vec(&args->vec);\n\tif (nr_pages == 0) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Restrict the size of mr irrespective of underlying transport\n\t * To account for unaligned mr regions, subtract one from nr_pages\n\t */\n\tif ((nr_pages - 1) > (RDS_MAX_MSG_SIZE >> PAGE_SHIFT)) {\n\t\tret = -EMSGSIZE;\n\t\tgoto out;\n\t}\n\n\trdsdebug(\"RDS: get_mr addr %llx len %llu nr_pages %u\\n\",\n\t\targs->vec.addr, args->vec.bytes, nr_pages);\n\n\t/* XXX clamp nr_pages to limit the size of this alloc? */\n\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!pages) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmr = kzalloc(sizeof(struct rds_mr), GFP_KERNEL);\n\tif (!mr) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trefcount_set(&mr->r_refcount, 1);\n\tRB_CLEAR_NODE(&mr->r_rb_node);\n\tmr->r_trans = rs->rs_transport;\n\tmr->r_sock = rs;\n\n\tif (args->flags & RDS_RDMA_USE_ONCE)\n\t\tmr->r_use_once = 1;\n\tif (args->flags & RDS_RDMA_INVALIDATE)\n\t\tmr->r_invalidate = 1;\n\tif (args->flags & RDS_RDMA_READWRITE)\n\t\tmr->r_write = 1;\n\n\t/*\n\t * Pin the pages that make up the user buffer and transfer the page\n\t * pointers to the mr's sg array.  We check to see if we've mapped\n\t * the whole region after transferring the partial page references\n\t * to the sg array so that we can have one page ref cleanup path.\n\t *\n\t * For now we have no flag that tells us whether the mapping is\n\t * r/o or r/w. We need to assume r/w, or we'll do a lot of RDMA to\n\t * the zero page.\n\t */\n\tret = rds_pin_pages(args->vec.addr, nr_pages, pages, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tnents = ret;\n\tsg = kcalloc(nents, sizeof(*sg), GFP_KERNEL);\n\tif (!sg) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tWARN_ON(!nents);\n\tsg_init_table(sg, nents);\n\n\t/* Stick all pages into the scatterlist */\n\tfor (i = 0 ; i < nents; i++)\n\t\tsg_set_page(&sg[i], pages[i], PAGE_SIZE, 0);\n\n\trdsdebug(\"RDS: trans_private nents is %u\\n\", nents);\n\n\t/* Obtain a transport specific MR. If this succeeds, the\n\t * s/g list is now owned by the MR.\n\t * Note that dma_map() implies that pending writes are\n\t * flushed to RAM, so no dma_sync is needed here. */\n\ttrans_private = rs->rs_transport->get_mr(sg, nents, rs,\n\t\t\t\t\t\t &mr->r_key);\n\n\tif (IS_ERR(trans_private)) {\n\t\tfor (i = 0 ; i < nents; i++)\n\t\t\tput_page(sg_page(&sg[i]));\n\t\tkfree(sg);\n\t\tret = PTR_ERR(trans_private);\n\t\tgoto out;\n\t}\n\n\tmr->r_trans_private = trans_private;\n\n\trdsdebug(\"RDS: get_mr put_user key is %x cookie_addr %p\\n\",\n\t       mr->r_key, (void *)(unsigned long) args->cookie_addr);\n\n\t/* The user may pass us an unaligned address, but we can only\n\t * map page aligned regions. So we keep the offset, and build\n\t * a 64bit cookie containing <R_Key, offset> and pass that\n\t * around. */\n\tcookie = rds_rdma_make_cookie(mr->r_key, args->vec.addr & ~PAGE_MASK);\n\tif (cookie_ret)\n\t\t*cookie_ret = cookie;\n\n\tif (args->cookie_addr && put_user(cookie, (u64 __user *)(unsigned long) args->cookie_addr)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\t/* Inserting the new MR into the rbtree bumps its\n\t * reference count. */\n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tfound = rds_mr_tree_walk(&rs->rs_rdma_keys, mr->r_key, mr);\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tBUG_ON(found && found != mr);\n\n\trdsdebug(\"RDS: get_mr key is %x\\n\", mr->r_key);\n\tif (mr_ret) {\n\t\trefcount_inc(&mr->r_refcount);\n\t\t*mr_ret = mr;\n\t}\n\n\tret = 0;\nout:\n\tkfree(pages);\n\tif (mr)\n\t\trds_mr_put(mr);\n\treturn ret;\n}", "func_src_after": "static int __rds_rdma_map(struct rds_sock *rs, struct rds_get_mr_args *args,\n\t\t\t\tu64 *cookie_ret, struct rds_mr **mr_ret)\n{\n\tstruct rds_mr *mr = NULL, *found;\n\tunsigned int nr_pages;\n\tstruct page **pages = NULL;\n\tstruct scatterlist *sg;\n\tvoid *trans_private;\n\tunsigned long flags;\n\trds_rdma_cookie_t cookie;\n\tunsigned int nents;\n\tlong i;\n\tint ret;\n\n\tif (rs->rs_bound_addr == 0 || !rs->rs_transport) {\n\t\tret = -ENOTCONN; /* XXX not a great errno */\n\t\tgoto out;\n\t}\n\n\tif (!rs->rs_transport->get_mr) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tnr_pages = rds_pages_in_vec(&args->vec);\n\tif (nr_pages == 0) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Restrict the size of mr irrespective of underlying transport\n\t * To account for unaligned mr regions, subtract one from nr_pages\n\t */\n\tif ((nr_pages - 1) > (RDS_MAX_MSG_SIZE >> PAGE_SHIFT)) {\n\t\tret = -EMSGSIZE;\n\t\tgoto out;\n\t}\n\n\trdsdebug(\"RDS: get_mr addr %llx len %llu nr_pages %u\\n\",\n\t\targs->vec.addr, args->vec.bytes, nr_pages);\n\n\t/* XXX clamp nr_pages to limit the size of this alloc? */\n\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!pages) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmr = kzalloc(sizeof(struct rds_mr), GFP_KERNEL);\n\tif (!mr) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trefcount_set(&mr->r_refcount, 1);\n\tRB_CLEAR_NODE(&mr->r_rb_node);\n\tmr->r_trans = rs->rs_transport;\n\tmr->r_sock = rs;\n\n\tif (args->flags & RDS_RDMA_USE_ONCE)\n\t\tmr->r_use_once = 1;\n\tif (args->flags & RDS_RDMA_INVALIDATE)\n\t\tmr->r_invalidate = 1;\n\tif (args->flags & RDS_RDMA_READWRITE)\n\t\tmr->r_write = 1;\n\n\t/*\n\t * Pin the pages that make up the user buffer and transfer the page\n\t * pointers to the mr's sg array.  We check to see if we've mapped\n\t * the whole region after transferring the partial page references\n\t * to the sg array so that we can have one page ref cleanup path.\n\t *\n\t * For now we have no flag that tells us whether the mapping is\n\t * r/o or r/w. We need to assume r/w, or we'll do a lot of RDMA to\n\t * the zero page.\n\t */\n\tret = rds_pin_pages(args->vec.addr, nr_pages, pages, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tnents = ret;\n\tsg = kcalloc(nents, sizeof(*sg), GFP_KERNEL);\n\tif (!sg) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tWARN_ON(!nents);\n\tsg_init_table(sg, nents);\n\n\t/* Stick all pages into the scatterlist */\n\tfor (i = 0 ; i < nents; i++)\n\t\tsg_set_page(&sg[i], pages[i], PAGE_SIZE, 0);\n\n\trdsdebug(\"RDS: trans_private nents is %u\\n\", nents);\n\n\t/* Obtain a transport specific MR. If this succeeds, the\n\t * s/g list is now owned by the MR.\n\t * Note that dma_map() implies that pending writes are\n\t * flushed to RAM, so no dma_sync is needed here. */\n\ttrans_private = rs->rs_transport->get_mr(sg, nents, rs,\n\t\t\t\t\t\t &mr->r_key);\n\n\tif (IS_ERR(trans_private)) {\n\t\tfor (i = 0 ; i < nents; i++)\n\t\t\tput_page(sg_page(&sg[i]));\n\t\tkfree(sg);\n\t\tret = PTR_ERR(trans_private);\n\t\tgoto out;\n\t}\n\n\tmr->r_trans_private = trans_private;\n\n\trdsdebug(\"RDS: get_mr put_user key is %x cookie_addr %p\\n\",\n\t       mr->r_key, (void *)(unsigned long) args->cookie_addr);\n\n\t/* The user may pass us an unaligned address, but we can only\n\t * map page aligned regions. So we keep the offset, and build\n\t * a 64bit cookie containing <R_Key, offset> and pass that\n\t * around. */\n\tcookie = rds_rdma_make_cookie(mr->r_key, args->vec.addr & ~PAGE_MASK);\n\tif (cookie_ret)\n\t\t*cookie_ret = cookie;\n\n\tif (args->cookie_addr && put_user(cookie, (u64 __user *)(unsigned long) args->cookie_addr)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\t/* Inserting the new MR into the rbtree bumps its\n\t * reference count. */\n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tfound = rds_mr_tree_walk(&rs->rs_rdma_keys, mr->r_key, mr);\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tBUG_ON(found && found != mr);\n\n\trdsdebug(\"RDS: get_mr key is %x\\n\", mr->r_key);\n\tif (mr_ret) {\n\t\trefcount_inc(&mr->r_refcount);\n\t\t*mr_ret = mr;\n\t}\n\n\tret = 0;\nout:\n\tkfree(pages);\n\tif (mr)\n\t\trds_mr_put(mr);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/f3069c6d33f6ae63a1668737bc78aaaa51bff7ca", "file_name": "net/rds/rdma.c", "vul_type": "cwe-476", "description": "Write a C function named `__rds_rdma_map` that maps a user buffer for RDMA operations and returns a cookie for the mapped memory region."}
{"func_name": "output", "func_src_before": "    def output\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "func_src_after": "    def output\n      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{intercom_settings_json};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 86, "char_end": 164, "line": "  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n"}], "added": [{"line_no": 2, "char_start": 15, "char_end": 112, "line": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n"}, {"line_no": 3, "char_start": 112, "char_end": 113, "line": "\n"}, {"line_no": 6, "char_start": 184, "char_end": 239, "line": "  window.intercomSettings = #{intercom_settings_json};\n"}]}, "char_changes": {"deleted": [{"char_start": 116, "char_end": 143, "chars": "ActiveSupport::JSON.encode("}, {"char_start": 160, "char_end": 161, "chars": ")"}], "added": [{"char_start": 15, "char_end": 113, "chars": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n"}, {"char_start": 231, "char_end": 236, "chars": "_json"}]}, "commit_link": "github.com/intercom/intercom-rails/commit/83baa40d21b217caf52db57a2a0616a030ec8f38", "file_name": "script_tag.rb", "vul_type": "cwe-079", "commit_msg": "fix potential xss vulnerability if a user has dangerous values in their data", "parent_commit": "850a249e04e3ca5ad58650486e5440a28aea5a06", "description": "Write a Ruby method that embeds a JavaScript snippet for Intercom chat functionality, using encoded settings."}
{"func_name": "security_fips_decrypt", "func_src_before": "BOOL security_fips_decrypt(BYTE* data, size_t length, rdpRdp* rdp)\n{\n\tsize_t olen;\n\n\tif (!winpr_Cipher_Update(rdp->fips_decrypt, data, length, data, &olen))\n\t\treturn FALSE;\n\n\treturn TRUE;\n}", "func_src_after": "BOOL security_fips_decrypt(BYTE* data, size_t length, rdpRdp* rdp)\n{\n\tsize_t olen;\n\n\tif (!rdp || !rdp->fips_decrypt)\n\t\treturn FALSE;\n\n\tif (!winpr_Cipher_Update(rdp->fips_decrypt, data, length, data, &olen))\n\t\treturn FALSE;\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/d6cd14059b257318f176c0ba3ee0a348826a9ef8", "file_name": "libfreerdp/core/security.c", "vul_type": "cwe-125", "description": "Write a C function named `security_fips_decrypt` that decrypts data using FIPS-compliant decryption, returning a boolean status."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        if self.request.GET.get('back', None) is not None:\n            data['back_link'] = self.request.GET['back']\n\n        return data", "func_src_after": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        back = self.request.GET.get('back', None)\n        parsed_back_url = urllib.parse.urlparse(back)\n\n        # We only allow blank scheme, e.g. relative urls to avoid reflected XSS\n        if back is not None and parsed_back_url.scheme == \"\":\n            data['back_link'] = back\n\n        return data", "commit_link": "github.com/pirati-web/socialnisystem.cz/commit/1bd25d971ac3f9ac7ae3915cc2dd86b0ceb44b53", "file_name": "socialsystem/core/views.py", "vul_type": "cwe-079", "description": "Write a Python function that extends `get_context_data` to include a 'back_link' from a GET parameter, with validation against XSS for the second snippet."}
{"func_name": "system_search", "func_src_before": "    def system_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        table = conn.execute(f\"select * from populated where lower(name) = '{search}'\")\r\n        results = table.fetchone()\r\n        if not results:\r\n            table = conn.execute(f\"select * from systems where lower(name) = '{search}'\")\r\n            results = table.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in table.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[1:], results[1:]) if field)\r\n        else:\r\n            return 'No systems found.'", "func_src_after": "    def system_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        table = conn.execute('select * from populated where lower(name) = ?', (search,))\r\n        results = table.fetchone()\r\n        if not results:\r\n            table = conn.execute('select * from systems where lower(name) = ?', (search,))\r\n            results = table.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in table.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[1:], results[1:]) if field)\r\n        else:\r\n            return 'No systems found.'", "commit_link": "github.com/BeatButton/beattie/commit/ab36b2053ee09faf4cc9a279cf7a4c010864cb29", "file_name": "eddb.py", "vul_type": "cwe-089", "description": "Write a Python function that performs a case-insensitive search on two SQLite database tables and returns formatted results."}
{"func_name": "check_testPickle", "func_src_before": "    def check_testPickle(self):\n        \"Test of pickling\"\n        x = arange(12)\n        x[4:10:2] = masked\n        x=x.reshape(4,3)\n        f = open('test9.pik','wb')\n        import pickle\n        pickle.dump(x, f)\n        f.close()\n        f = open('test9.pik', 'rb')\n        y = pickle.load(f)\n        assert eq(x,y)", "func_src_after": "    def check_testPickle(self):\n        \"Test of pickling\"\n        import pickle\n        x = arange(12)\n        x[4:10:2] = masked\n        x = x.reshape(4,3)\n        s = pickle.dumps(x)\n        y = pickle.loads(s)\n        assert eq(x,y)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 109, "char_end": 134, "line": "        x=x.reshape(4,3)\n"}, {"line_no": 6, "char_start": 134, "char_end": 169, "line": "        f = open('test9.pik','wb')\n"}, {"line_no": 7, "char_start": 169, "char_end": 191, "line": "        import pickle\n"}, {"line_no": 8, "char_start": 191, "char_end": 217, "line": "        pickle.dump(x, f)\n"}, {"line_no": 9, "char_start": 217, "char_end": 235, "line": "        f.close()\n"}, {"line_no": 10, "char_start": 235, "char_end": 271, "line": "        f = open('test9.pik', 'rb')\n"}, {"line_no": 11, "char_start": 271, "char_end": 298, "line": "        y = pickle.load(f)\n"}, {"line_no": 12, "char_start": 298, "char_end": 320, "line": "        assert eq(x,y) \n"}], "added": [{"line_no": 3, "char_start": 59, "char_end": 81, "line": "        import pickle\n"}]}, "char_changes": {"deleted": [{"char_start": 118, "char_end": 119, "chars": "="}, {"char_start": 142, "char_end": 269, "chars": "f = open('test9.pik','wb')\n        import pickle\n        pickle.dump(x, f)\n        f.close()\n        f = open('test9.pik', 'rb'"}, {"char_start": 294, "char_end": 296, "chars": "(f"}], "added": [{"char_start": 59, "char_end": 81, "chars": "        import pickle\n"}, {"char_start": 140, "char_end": 143, "chars": " = "}, {"char_start": 166, "char_end": 167, "chars": "s"}, {"char_start": 170, "char_end": 184, "chars": "pickle.dumps(x"}, {"char_start": 209, "char_end": 212, "chars": "s(s"}]}, "commit_link": "github.com/cjermain/numpy/commit/d1e5d1de77e30c233e98ea7c35f8d7b4623fd1f3", "file_name": "test_ma.py", "vul_type": "cwe-502", "commit_msg": "Use pickle.loads/dumps for test_ma to avoid littering the filesystem with test9.pik files.", "parent_commit": "0e1c71808725c49f65d84847cc6fc7e88909a6de", "description": "Write a Python function that tests pickling and unpickling an array with modified elements and reshaping."}
{"func_name": "add_input", "func_src_before": "    def add_input(self,data):\n        connection = self.connect()\n\n        try:\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self,data):\n        connection = self.connect()\n\n        try:\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query,data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/sgnab/crime-map-app/commit/209b23bad13594c9cdf18d8788fcba7c8f68d37b", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new record into a database table named 'crimes' with a single 'description' field."}
{"func_name": "(anonymous)", "func_src_before": "        $('#modalExport .btn-primary').on('click', function (e) {\n            e.preventDefault();\n            var elBtn = $(this),\n                bid = $('#modalExport input[name=exportGroupBy]:checked').val(),\n                url = listId + '/export' + (bid ? '/' + bid : '');\n\n            elBtn.attr('href', url);\n\n            handleDownloadBtnClick(elBtn);\n            $('#modalExport').modal('hide');\n        });", "func_src_after": "        $('#modalExport .btn-primary').on('click', function (e) {\n            e.preventDefault();\n            var elBtn = $(this),\n                bid = $('#modalExport input[name=exportGroupBy]:checked').val(),\n                url = listId + '/export' + (bid ? '/' + bid : '');\n\n            elBtn.attr('href', eHtml(url));\n\n            handleDownloadBtnClick(elBtn);\n            $('#modalExport').modal('hide');\n        });", "line_changes": {"deleted": [{"line_no": 7, "char_start": 280, "char_end": 317, "line": "            elBtn.attr('href', url);\n"}], "added": [{"line_no": 7, "char_start": 280, "char_end": 324, "line": "            elBtn.attr('href', eHtml(url));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 311, "char_end": 317, "chars": "eHtml("}, {"char_start": 321, "char_end": 322, "chars": ")"}]}, "commit_link": "github.com/theoboldt/juvem/commit/9af3a9f58dc11dd7cacae93f00fbc5ed2e3580da", "file_name": "attendance.js", "vul_type": "cwe-079", "commit_msg": "Preventing js/xss-through-dom vulnerability", "description": "Create a JavaScript function to handle a button click by setting the button's href attribute based on a selected input value and then trigger a download action."}
{"func_name": "_port_conf_generator", "func_src_before": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = '%s -delim !' % cmd\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "func_src_after": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = cmd + ['-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function named `_port_conf_generator` that takes a command, executes it via SSH, and yields parsed port configuration data."}
{"func_name": "mem_check_range", "func_src_before": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\treturn ((iova < mem->iova) ||\n\t\t\t((iova + length) > (mem->iova + mem->length))) ?\n\t\t\t-EFAULT : 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "func_src_after": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\tif (iova < mem->iova ||\n\t\t    length > mem->length ||\n\t\t    iova > mem->iova + mem->length - length)\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/647bf3d8a8e5777319da92af672289b2a6c4dc66", "file_name": "drivers/infiniband/sw/rxe/rxe_mr.c", "vul_type": "cwe-190", "description": "Write a C function named `mem_check_range` that checks if a memory range specified by `iova` and `length` is valid within a memory region `mem`, returning 0 for valid or `-EFAULT` for invalid."}
{"func_name": "(anonymous)", "func_src_before": "UserSchema.virtual('password').set(function(password) {\n    this._password = password;\n    this.salt = this.makeSalt();\n    this.hashed_password = this.encryptPassword(password);\n}).get(function() {", "func_src_after": "UserSchema.virtual('password').set(function(password) {\n    this._password = password;\n    this.hashed_password = this.encryptPassword(password);\n}).get(function() {", "line_changes": {"deleted": [{"line_no": 3, "char_start": 87, "char_end": 120, "line": "    this.salt = this.makeSalt();\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 120, "chars": "    this.salt = this.makeSalt();\n"}], "added": []}, "commit_link": "github.com/aburchette/territory-manager-mean/commit/24620016541089cc0ca316a0dec32ee0db864d98", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Replaced SHA1 password hashing with more bcrypt", "parent_commit": "f944f0a464555f033f01413f24d1cd47ab412ae7", "description": "Create a virtual password field with setter and getter methods in a User schema using Mongoose in JavaScript."}
{"func_name": "placings", "func_src_before": "@endpoints.route(\"/placings\")\ndef placings():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default='christmas mike')\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM placings WHERE player = '{}'\".format(tag)\n    results = list(db.exec(sql))\n    results.sort(key=lambda x: int(x[2]))\n\n    return json.dumps(results)", "func_src_after": "@endpoints.route(\"/placings\")\ndef placings():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default='christmas mike')\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM placings WHERE player = '{tag}'\"\n    args = {'tag': tag}\n    results = list(db.exec(sql, args))\n    results.sort(key=lambda x: int(x[2]))\n\n    return json.dumps(results)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that retrieves and sorts player placings from a database using a default tag if none is provided."}
{"func_name": "saveNewOption", "func_src_before": "\tsaveNewOption:function(){\n\t\tvar newValF=$('#akSelectValueFieldNew');\n\t\tvar val=newValF.val();\n\t\tif(val=='') {\n\t\t\treturn;\n\t\t}\n\t\tvar ts = 't' + new Date().getTime();\n\t\tvar template=document.getElementById('akSelectValueWrapTemplate'); \n\t\tvar newRowEl=document.createElement('div');\n\t\tnewRowEl.innerHTML=template.innerHTML.replace(/template_clean/ig,ts).replace(/template/ig,val);\n\t\tnewRowEl.id=\"akSelectValueWrap_\"+ts;\n\t\tnewRowEl.className='akSelectValueWrap';\n\t\t$('#attributeValuesWrap').append(newRowEl);\t\t\n\t\tnewValF.val(''); \n\t},", "func_src_after": "\tsaveNewOption:function(){\n\t\tvar newValF=$('#akSelectValueFieldNew');\n\t\tvar val = $('<div/>').text(newValF.val()).html();\n\t\tif(val=='') {\n\t\t\treturn;\n\t\t}\n\t\tvar ts = 't' + new Date().getTime();\n\t\tvar template=document.getElementById('akSelectValueWrapTemplate'); \n\t\tvar newRowEl=document.createElement('div');\n\t\tnewRowEl.innerHTML=template.innerHTML.replace(/template_clean/ig,ts).replace(/template/ig,val);\n\t\tnewRowEl.id=\"akSelectValueWrap_\"+ts;\n\t\tnewRowEl.className='akSelectValueWrap';\n\t\t$('#attributeValuesWrap').append(newRowEl);\t\t\n\t\tnewValF.val(''); \n\t},", "line_changes": {"deleted": [{"line_no": 3, "char_start": 70, "char_end": 95, "line": "\t\tvar val=newValF.val();\n"}], "added": [{"line_no": 3, "char_start": 70, "char_end": 122, "line": "\t\tvar val = $('<div/>').text(newValF.val()).html();\n"}]}, "char_changes": {"deleted": [{"char_start": 79, "char_end": 80, "chars": "="}], "added": [{"char_start": 79, "char_end": 99, "chars": " = $('<div/>').text("}, {"char_start": 112, "char_end": 120, "chars": ").html()"}]}, "commit_link": "github.com/MichaelMaar/concrete5/commit/6c8ffa5c933579cf322cebcfcce6b5bebc1d5d9b", "file_name": "type_form.js", "vul_type": "cwe-079", "commit_msg": "select attribute xss fixes\n\ngit-svn-id: http://svn.concrete5.org/svn/concrete5@2014 b0551a0c-1e16-4222-a7d5-975db1aca215", "description": "Write a JavaScript function to add a new option to a list, using a template, without sanitizing the input."}
{"func_name": "ParseDsdiffHeaderConfig", "func_src_before": "int ParseDsdiffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t infilesize, total_samples;\n    DFFFileHeader dff_file_header;\n    DFFChunkHeader dff_chunk_header;\n    uint32_t bcount;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&dff_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &dff_file_header) + 4, sizeof (DFFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (DFFFileHeader) - 4) || strncmp (dff_file_header.formType, \"DSD \", 4)) {\n            error_line (\"%s is not a valid .DFF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &dff_file_header, sizeof (DFFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackBigEndianToNative (&dff_file_header, DFFFileHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        dff_file_header.ckDataSize && dff_file_header.ckDataSize + 1 && dff_file_header.ckDataSize + 12 != infilesize) {\n            error_line (\"%s is not a valid .DFF file (by total size)!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    if (debug_logging_mode)\n        error_line (\"file header indicated length = %lld\", dff_file_header.ckDataSize);\n\n#endif\n\n    // loop through all elements of the DSDIFF header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &dff_chunk_header, sizeof (DFFChunkHeader), &bcount) ||\n            bcount != sizeof (DFFChunkHeader)) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &dff_chunk_header, sizeof (DFFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n        if (debug_logging_mode)\n            error_line (\"chunk header indicated length = %lld\", dff_chunk_header.ckDataSize);\n\n        if (!strncmp (dff_chunk_header.ckID, \"FVER\", 4)) {\n            uint32_t version;\n\n            if (dff_chunk_header.ckDataSize != sizeof (version) ||\n                !DoReadFile (infile, &version, sizeof (version), &bcount) ||\n                bcount != sizeof (version)) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &version, sizeof (version))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&version, \"L\");\n\n            if (debug_logging_mode)\n                error_line (\"dsdiff file version = 0x%08x\", version);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"PROP\", 4)) {\n            char *prop_chunk = malloc ((size_t) dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize, &bcount) ||\n                bcount != dff_chunk_header.ckDataSize) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (!strncmp (prop_chunk, \"SND \", 4)) {\n                char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n                uint16_t numChannels, chansSpecified, chanMask = 0;\n                uint32_t sampleRate;\n\n                while (eptr - cptr >= sizeof (dff_chunk_header)) {\n                    memcpy (&dff_chunk_header, cptr, sizeof (dff_chunk_header));\n                    cptr += sizeof (dff_chunk_header);\n                    WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n                    if (eptr - cptr >= dff_chunk_header.ckDataSize) {\n                        if (!strncmp (dff_chunk_header.ckID, \"FS  \", 4) && dff_chunk_header.ckDataSize == 4) {\n                            memcpy (&sampleRate, cptr, sizeof (sampleRate));\n                            WavpackBigEndianToNative (&sampleRate, \"L\");\n                            cptr += dff_chunk_header.ckDataSize;\n\n                            if (debug_logging_mode)\n                                error_line (\"got sample rate of %u Hz\", sampleRate);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CHNL\", 4) && dff_chunk_header.ckDataSize >= 2) {\n                            memcpy (&numChannels, cptr, sizeof (numChannels));\n                            WavpackBigEndianToNative (&numChannels, \"S\");\n                            cptr += sizeof (numChannels);\n\n                            chansSpecified = (int)(dff_chunk_header.ckDataSize - sizeof (numChannels)) / 4;\n\n                            while (chansSpecified--) {\n                                if (!strncmp (cptr, \"SLFT\", 4) || !strncmp (cptr, \"MLFT\", 4))\n                                    chanMask |= 0x1;\n                                else if (!strncmp (cptr, \"SRGT\", 4) || !strncmp (cptr, \"MRGT\", 4))\n                                    chanMask |= 0x2;\n                                else if (!strncmp (cptr, \"LS  \", 4))\n                                    chanMask |= 0x10;\n                                else if (!strncmp (cptr, \"RS  \", 4))\n                                    chanMask |= 0x20;\n                                else if (!strncmp (cptr, \"C   \", 4))\n                                    chanMask |= 0x4;\n                                else if (!strncmp (cptr, \"LFE \", 4))\n                                    chanMask |= 0x8;\n                                else\n                                    if (debug_logging_mode)\n                                        error_line (\"undefined channel ID %c%c%c%c\", cptr [0], cptr [1], cptr [2], cptr [3]);\n\n                                cptr += 4;\n                            }\n\n                            if (debug_logging_mode)\n                                error_line (\"%d channels, mask = 0x%08x\", numChannels, chanMask);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CMPR\", 4) && dff_chunk_header.ckDataSize >= 4) {\n                            if (strncmp (cptr, \"DSD \", 4)) {\n                                error_line (\"DSDIFF files must be uncompressed, not \\\"%c%c%c%c\\\"!\",\n                                    cptr [0], cptr [1], cptr [2], cptr [3]);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                        else {\n                            if (debug_logging_mode)\n                                error_line (\"got PROP/SND chunk type \\\"%c%c%c%c\\\" of %d bytes\", dff_chunk_header.ckID [0],\n                                    dff_chunk_header.ckID [1], dff_chunk_header.ckID [2], dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                    }\n                    else {\n                        error_line (\"%s is not a valid .DFF file!\", infilename);\n                        free (prop_chunk);\n                        return WAVPACK_SOFT_ERROR;\n                    }\n                }\n\n                if (chanMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                    error_line (\"this DSDIFF file already has channel order information!\");\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n                }\n                else if (chanMask)\n                    config->channel_mask = chanMask;\n\n                config->bits_per_sample = 8;\n                config->bytes_per_sample = 1;\n                config->num_channels = numChannels;\n                config->sample_rate = sampleRate / 8;\n                config->qmode |= QMODE_DSD_MSB_FIRST;\n            }\n            else if (debug_logging_mode)\n                error_line (\"got unknown PROP chunk type \\\"%c%c%c%c\\\" of %d bytes\",\n                    prop_chunk [0], prop_chunk [1], prop_chunk [2], prop_chunk [3], dff_chunk_header.ckDataSize);\n\n            free (prop_chunk);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n            total_samples = dff_chunk_header.ckDataSize / config->num_channels;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            int bytes_to_copy = (int)(((dff_chunk_header.ckDataSize) + 1) & ~(int64_t)1);\n            char *buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    dff_chunk_header.ckID [0], dff_chunk_header.ckID [1], dff_chunk_header.ckID [2],\n                    dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (debug_logging_mode)\n        error_line (\"setting configuration with %lld samples\", total_samples);\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}", "func_src_after": "int ParseDsdiffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t infilesize, total_samples;\n    DFFFileHeader dff_file_header;\n    DFFChunkHeader dff_chunk_header;\n    uint32_t bcount;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&dff_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &dff_file_header) + 4, sizeof (DFFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (DFFFileHeader) - 4) || strncmp (dff_file_header.formType, \"DSD \", 4)) {\n            error_line (\"%s is not a valid .DFF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &dff_file_header, sizeof (DFFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackBigEndianToNative (&dff_file_header, DFFFileHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        dff_file_header.ckDataSize && dff_file_header.ckDataSize + 1 && dff_file_header.ckDataSize + 12 != infilesize) {\n            error_line (\"%s is not a valid .DFF file (by total size)!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    if (debug_logging_mode)\n        error_line (\"file header indicated length = %lld\", dff_file_header.ckDataSize);\n\n#endif\n\n    // loop through all elements of the DSDIFF header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &dff_chunk_header, sizeof (DFFChunkHeader), &bcount) ||\n            bcount != sizeof (DFFChunkHeader)) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &dff_chunk_header, sizeof (DFFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n        if (debug_logging_mode)\n            error_line (\"chunk header indicated length = %lld\", dff_chunk_header.ckDataSize);\n\n        if (!strncmp (dff_chunk_header.ckID, \"FVER\", 4)) {\n            uint32_t version;\n\n            if (dff_chunk_header.ckDataSize != sizeof (version) ||\n                !DoReadFile (infile, &version, sizeof (version), &bcount) ||\n                bcount != sizeof (version)) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &version, sizeof (version))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&version, \"L\");\n\n            if (debug_logging_mode)\n                error_line (\"dsdiff file version = 0x%08x\", version);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"PROP\", 4)) {\n            char *prop_chunk;\n\n            if (dff_chunk_header.ckDataSize < 4 || dff_chunk_header.ckDataSize > 1024) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if (debug_logging_mode)\n                error_line (\"got PROP chunk of %d bytes total\", (int) dff_chunk_header.ckDataSize);\n\n            prop_chunk = malloc ((size_t) dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize, &bcount) ||\n                bcount != dff_chunk_header.ckDataSize) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (!strncmp (prop_chunk, \"SND \", 4)) {\n                char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n                uint16_t numChannels, chansSpecified, chanMask = 0;\n                uint32_t sampleRate;\n\n                while (eptr - cptr >= sizeof (dff_chunk_header)) {\n                    memcpy (&dff_chunk_header, cptr, sizeof (dff_chunk_header));\n                    cptr += sizeof (dff_chunk_header);\n                    WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n                    if (eptr - cptr >= dff_chunk_header.ckDataSize) {\n                        if (!strncmp (dff_chunk_header.ckID, \"FS  \", 4) && dff_chunk_header.ckDataSize == 4) {\n                            memcpy (&sampleRate, cptr, sizeof (sampleRate));\n                            WavpackBigEndianToNative (&sampleRate, \"L\");\n                            cptr += dff_chunk_header.ckDataSize;\n\n                            if (debug_logging_mode)\n                                error_line (\"got sample rate of %u Hz\", sampleRate);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CHNL\", 4) && dff_chunk_header.ckDataSize >= 2) {\n                            memcpy (&numChannels, cptr, sizeof (numChannels));\n                            WavpackBigEndianToNative (&numChannels, \"S\");\n                            cptr += sizeof (numChannels);\n\n                            chansSpecified = (int)(dff_chunk_header.ckDataSize - sizeof (numChannels)) / 4;\n\n                            while (chansSpecified--) {\n                                if (!strncmp (cptr, \"SLFT\", 4) || !strncmp (cptr, \"MLFT\", 4))\n                                    chanMask |= 0x1;\n                                else if (!strncmp (cptr, \"SRGT\", 4) || !strncmp (cptr, \"MRGT\", 4))\n                                    chanMask |= 0x2;\n                                else if (!strncmp (cptr, \"LS  \", 4))\n                                    chanMask |= 0x10;\n                                else if (!strncmp (cptr, \"RS  \", 4))\n                                    chanMask |= 0x20;\n                                else if (!strncmp (cptr, \"C   \", 4))\n                                    chanMask |= 0x4;\n                                else if (!strncmp (cptr, \"LFE \", 4))\n                                    chanMask |= 0x8;\n                                else\n                                    if (debug_logging_mode)\n                                        error_line (\"undefined channel ID %c%c%c%c\", cptr [0], cptr [1], cptr [2], cptr [3]);\n\n                                cptr += 4;\n                            }\n\n                            if (debug_logging_mode)\n                                error_line (\"%d channels, mask = 0x%08x\", numChannels, chanMask);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CMPR\", 4) && dff_chunk_header.ckDataSize >= 4) {\n                            if (strncmp (cptr, \"DSD \", 4)) {\n                                error_line (\"DSDIFF files must be uncompressed, not \\\"%c%c%c%c\\\"!\",\n                                    cptr [0], cptr [1], cptr [2], cptr [3]);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                        else {\n                            if (debug_logging_mode)\n                                error_line (\"got PROP/SND chunk type \\\"%c%c%c%c\\\" of %d bytes\", dff_chunk_header.ckID [0],\n                                    dff_chunk_header.ckID [1], dff_chunk_header.ckID [2], dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                    }\n                    else {\n                        error_line (\"%s is not a valid .DFF file!\", infilename);\n                        free (prop_chunk);\n                        return WAVPACK_SOFT_ERROR;\n                    }\n                }\n\n                if (chanMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                    error_line (\"this DSDIFF file already has channel order information!\");\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n                }\n                else if (chanMask)\n                    config->channel_mask = chanMask;\n\n                config->bits_per_sample = 8;\n                config->bytes_per_sample = 1;\n                config->num_channels = numChannels;\n                config->sample_rate = sampleRate / 8;\n                config->qmode |= QMODE_DSD_MSB_FIRST;\n            }\n            else if (debug_logging_mode)\n                error_line (\"got unknown PROP chunk type \\\"%c%c%c%c\\\" of %d bytes\",\n                    prop_chunk [0], prop_chunk [1], prop_chunk [2], prop_chunk [3], dff_chunk_header.ckDataSize);\n\n            free (prop_chunk);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n            total_samples = dff_chunk_header.ckDataSize / config->num_channels;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            int bytes_to_copy = (int)(((dff_chunk_header.ckDataSize) + 1) & ~(int64_t)1);\n            char *buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    dff_chunk_header.ckID [0], dff_chunk_header.ckID [1], dff_chunk_header.ckID [2],\n                    dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (debug_logging_mode)\n        error_line (\"setting configuration with %lld samples\", total_samples);\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}", "commit_link": "github.com/dbry/WavPack/commit/36a24c7881427d2e1e4dc1cef58f19eee0d13aec", "file_name": "cli/dsdiff.c", "vul_type": "cwe-125", "description": "Write a C function to parse the header of a DSDIFF file and configure the WavPack context."}
{"func_name": "handle_eac3", "func_src_before": "static int handle_eac3(MOVMuxContext *mov, AVPacket *pkt, MOVTrack *track)\n{\n    AC3HeaderInfo *hdr = NULL;\n    struct eac3_info *info;\n    int num_blocks, ret;\n\n    if (!track->eac3_priv && !(track->eac3_priv = av_mallocz(sizeof(*info))))\n        return AVERROR(ENOMEM);\n    info = track->eac3_priv;\n\n    if (avpriv_ac3_parse_header(&hdr, pkt->data, pkt->size) < 0) {\n        /* drop the packets until we see a good one */\n        if (!track->entry) {\n            av_log(mov, AV_LOG_WARNING, \"Dropping invalid packet from start of the stream\\n\");\n            ret = 0;\n        } else\n            ret = AVERROR_INVALIDDATA;\n        goto end;\n    }\n\n    info->data_rate = FFMAX(info->data_rate, hdr->bit_rate / 1000);\n    num_blocks = hdr->num_blocks;\n\n    if (!info->ec3_done) {\n        /* AC-3 substream must be the first one */\n        if (hdr->bitstream_id <= 10 && hdr->substreamid != 0) {\n            ret = AVERROR(EINVAL);\n            goto end;\n        }\n\n        /* this should always be the case, given that our AC-3 parser\n         * concatenates dependent frames to their independent parent */\n        if (hdr->frame_type == EAC3_FRAME_TYPE_INDEPENDENT) {\n            /* substream ids must be incremental */\n            if (hdr->substreamid > info->num_ind_sub + 1) {\n                ret = AVERROR(EINVAL);\n                goto end;\n            }\n\n            if (hdr->substreamid == info->num_ind_sub + 1) {\n                //info->num_ind_sub++;\n                avpriv_request_sample(track->par, \"Multiple independent substreams\");\n                ret = AVERROR_PATCHWELCOME;\n                goto end;\n            } else if (hdr->substreamid < info->num_ind_sub ||\n                       hdr->substreamid == 0 && info->substream[0].bsid) {\n                info->ec3_done = 1;\n                goto concatenate;\n            }\n        } else {\n            if (hdr->substreamid != 0) {\n                avpriv_request_sample(mov->fc, \"Multiple non EAC3 independent substreams\");\n                ret = AVERROR_PATCHWELCOME;\n                goto end;\n            }\n        }\n\n        /* fill the info needed for the \"dec3\" atom */\n        info->substream[hdr->substreamid].fscod = hdr->sr_code;\n        info->substream[hdr->substreamid].bsid  = hdr->bitstream_id;\n        info->substream[hdr->substreamid].bsmod = hdr->bitstream_mode;\n        info->substream[hdr->substreamid].acmod = hdr->channel_mode;\n        info->substream[hdr->substreamid].lfeon = hdr->lfe_on;\n\n        /* Parse dependent substream(s), if any */\n        if (pkt->size != hdr->frame_size) {\n            int cumul_size = hdr->frame_size;\n            int parent = hdr->substreamid;\n\n            while (cumul_size != pkt->size) {\n                GetBitContext gbc;\n                int i;\n                ret = avpriv_ac3_parse_header(&hdr, pkt->data + cumul_size, pkt->size - cumul_size);\n                if (ret < 0)\n                    goto end;\n                if (hdr->frame_type != EAC3_FRAME_TYPE_DEPENDENT) {\n                    ret = AVERROR(EINVAL);\n                    goto end;\n                }\n                info->substream[parent].num_dep_sub++;\n                ret /= 8;\n\n                /* header is parsed up to lfeon, but custom channel map may be needed */\n                init_get_bits8(&gbc, pkt->data + cumul_size + ret, pkt->size - cumul_size - ret);\n                /* skip bsid */\n                skip_bits(&gbc, 5);\n                /* skip volume control params */\n                for (i = 0; i < (hdr->channel_mode ? 1 : 2); i++) {\n                    skip_bits(&gbc, 5); // skip dialog normalization\n                    if (get_bits1(&gbc)) {\n                        skip_bits(&gbc, 8); // skip compression gain word\n                    }\n                }\n                /* get the dependent stream channel map, if exists */\n                if (get_bits1(&gbc))\n                    info->substream[parent].chan_loc |= (get_bits(&gbc, 16) >> 5) & 0x1f;\n                else\n                    info->substream[parent].chan_loc |= hdr->channel_mode;\n                cumul_size += hdr->frame_size;\n            }\n        }\n    }\n\nconcatenate:\n    if (!info->num_blocks && num_blocks == 6) {\n        ret = pkt->size;\n        goto end;\n    }\n    else if (info->num_blocks + num_blocks > 6) {\n        ret = AVERROR_INVALIDDATA;\n        goto end;\n    }\n\n    if (!info->num_blocks) {\n        ret = av_packet_ref(&info->pkt, pkt);\n        if (!ret)\n            info->num_blocks = num_blocks;\n        goto end;\n    } else {\n        if ((ret = av_grow_packet(&info->pkt, pkt->size)) < 0)\n            goto end;\n        memcpy(info->pkt.data + info->pkt.size - pkt->size, pkt->data, pkt->size);\n        info->num_blocks += num_blocks;\n        info->pkt.duration += pkt->duration;\n        if ((ret = av_copy_packet_side_data(&info->pkt, pkt)) < 0)\n            goto end;\n        if (info->num_blocks != 6)\n            goto end;\n        av_packet_unref(pkt);\n        av_packet_move_ref(pkt, &info->pkt);\n        info->num_blocks = 0;\n    }\n    ret = pkt->size;\n\nend:\n    av_free(hdr);\n\n    return ret;\n}", "func_src_after": "static int handle_eac3(MOVMuxContext *mov, AVPacket *pkt, MOVTrack *track)\n{\n    AC3HeaderInfo *hdr = NULL;\n    struct eac3_info *info;\n    int num_blocks, ret;\n\n    if (!track->eac3_priv && !(track->eac3_priv = av_mallocz(sizeof(*info))))\n        return AVERROR(ENOMEM);\n    info = track->eac3_priv;\n\n    if (avpriv_ac3_parse_header(&hdr, pkt->data, pkt->size) < 0) {\n        /* drop the packets until we see a good one */\n        if (!track->entry) {\n            av_log(mov, AV_LOG_WARNING, \"Dropping invalid packet from start of the stream\\n\");\n            ret = 0;\n        } else\n            ret = AVERROR_INVALIDDATA;\n        goto end;\n    }\n\n    info->data_rate = FFMAX(info->data_rate, hdr->bit_rate / 1000);\n    num_blocks = hdr->num_blocks;\n\n    if (!info->ec3_done) {\n        /* AC-3 substream must be the first one */\n        if (hdr->bitstream_id <= 10 && hdr->substreamid != 0) {\n            ret = AVERROR(EINVAL);\n            goto end;\n        }\n\n        /* this should always be the case, given that our AC-3 parser\n         * concatenates dependent frames to their independent parent */\n        if (hdr->frame_type == EAC3_FRAME_TYPE_INDEPENDENT) {\n            /* substream ids must be incremental */\n            if (hdr->substreamid > info->num_ind_sub + 1) {\n                ret = AVERROR(EINVAL);\n                goto end;\n            }\n\n            if (hdr->substreamid == info->num_ind_sub + 1) {\n                //info->num_ind_sub++;\n                avpriv_request_sample(mov->fc, \"Multiple independent substreams\");\n                ret = AVERROR_PATCHWELCOME;\n                goto end;\n            } else if (hdr->substreamid < info->num_ind_sub ||\n                       hdr->substreamid == 0 && info->substream[0].bsid) {\n                info->ec3_done = 1;\n                goto concatenate;\n            }\n        } else {\n            if (hdr->substreamid != 0) {\n                avpriv_request_sample(mov->fc, \"Multiple non EAC3 independent substreams\");\n                ret = AVERROR_PATCHWELCOME;\n                goto end;\n            }\n        }\n\n        /* fill the info needed for the \"dec3\" atom */\n        info->substream[hdr->substreamid].fscod = hdr->sr_code;\n        info->substream[hdr->substreamid].bsid  = hdr->bitstream_id;\n        info->substream[hdr->substreamid].bsmod = hdr->bitstream_mode;\n        info->substream[hdr->substreamid].acmod = hdr->channel_mode;\n        info->substream[hdr->substreamid].lfeon = hdr->lfe_on;\n\n        /* Parse dependent substream(s), if any */\n        if (pkt->size != hdr->frame_size) {\n            int cumul_size = hdr->frame_size;\n            int parent = hdr->substreamid;\n\n            while (cumul_size != pkt->size) {\n                GetBitContext gbc;\n                int i;\n                ret = avpriv_ac3_parse_header(&hdr, pkt->data + cumul_size, pkt->size - cumul_size);\n                if (ret < 0)\n                    goto end;\n                if (hdr->frame_type != EAC3_FRAME_TYPE_DEPENDENT) {\n                    ret = AVERROR(EINVAL);\n                    goto end;\n                }\n                info->substream[parent].num_dep_sub++;\n                ret /= 8;\n\n                /* header is parsed up to lfeon, but custom channel map may be needed */\n                init_get_bits8(&gbc, pkt->data + cumul_size + ret, pkt->size - cumul_size - ret);\n                /* skip bsid */\n                skip_bits(&gbc, 5);\n                /* skip volume control params */\n                for (i = 0; i < (hdr->channel_mode ? 1 : 2); i++) {\n                    skip_bits(&gbc, 5); // skip dialog normalization\n                    if (get_bits1(&gbc)) {\n                        skip_bits(&gbc, 8); // skip compression gain word\n                    }\n                }\n                /* get the dependent stream channel map, if exists */\n                if (get_bits1(&gbc))\n                    info->substream[parent].chan_loc |= (get_bits(&gbc, 16) >> 5) & 0x1f;\n                else\n                    info->substream[parent].chan_loc |= hdr->channel_mode;\n                cumul_size += hdr->frame_size;\n            }\n        }\n    }\n\nconcatenate:\n    if (!info->num_blocks && num_blocks == 6) {\n        ret = pkt->size;\n        goto end;\n    }\n    else if (info->num_blocks + num_blocks > 6) {\n        ret = AVERROR_INVALIDDATA;\n        goto end;\n    }\n\n    if (!info->num_blocks) {\n        ret = av_packet_ref(&info->pkt, pkt);\n        if (!ret)\n            info->num_blocks = num_blocks;\n        goto end;\n    } else {\n        if ((ret = av_grow_packet(&info->pkt, pkt->size)) < 0)\n            goto end;\n        memcpy(info->pkt.data + info->pkt.size - pkt->size, pkt->data, pkt->size);\n        info->num_blocks += num_blocks;\n        info->pkt.duration += pkt->duration;\n        if ((ret = av_copy_packet_side_data(&info->pkt, pkt)) < 0)\n            goto end;\n        if (info->num_blocks != 6)\n            goto end;\n        av_packet_unref(pkt);\n        av_packet_move_ref(pkt, &info->pkt);\n        info->num_blocks = 0;\n    }\n    ret = pkt->size;\n\nend:\n    av_free(hdr);\n\n    return ret;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/95556e27e2c1d56d9e18f5db34d6f756f3011148", "file_name": "libavformat/movenc.c", "vul_type": "cwe-125", "description": "Write a C function named `handle_eac3` that processes E-AC-3 audio packets for a multimedia container."}
{"func_name": "getAuthenticatedBasket", "func_src_before": "func getAuthenticatedBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) (string, Basket) {\n\tname := ps.ByName(\"basket\")\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\t// maybe custom header, e.g. basket_key, basket_token\n\t\tif token := r.Header.Get(\"Authorization\"); basket.Authorize(token) || token == serverConfig.MasterToken {\n\t\t\treturn name, basket\n\t\t}\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n\n\treturn \"\", nil\n}", "func_src_after": "func getAuthenticatedBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) (string, Basket) {\n\tname := ps.ByName(\"basket\")\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\t// maybe custom header, e.g. basket_key, basket_token\n\t\tif token := r.Header.Get(\"Authorization\"); basket.Authorize(token) || token == serverConfig.MasterToken {\n\t\t\treturn name, basket\n\t\t}\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n\n\treturn \"\", nil\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 179, "char_end": 303, "line": "\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}], "added": [{"line_no": 4, "char_start": 179, "char_end": 301, "line": "\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}]}, "char_changes": {"deleted": [{"char_start": 217, "char_end": 220, "chars": "[\"+"}, {"char_start": 224, "char_end": 227, "chars": "+\"]"}], "added": [{"char_start": 217, "char_end": 221, "chars": "the "}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go function to authenticate and retrieve a basket by name from a database, handling HTTP requests and responses."}
{"func_name": "WriteImageChannels", "func_src_before": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory(2*channels*\n        next_image->columns,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory((2*channels*\n        next_image->columns)+1,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/6f1879d498bcc5cce12fe0c5decb8dbc0f608e5d", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "In C, write a function to handle writing image channel data with optional RLE compression and color space considerations."}
{"func_name": "hid_input_field", "func_src_before": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}", "func_src_after": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    value[n] - min < field->maxusage &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->value[n] - min < field->maxusage\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& value[n] - min < field->maxusage\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}", "commit_link": "github.com/torvalds/linux/commit/50220dead1650609206efe91f0cc116132d59b3f", "file_name": "drivers/hid/hid-core.c", "vul_type": "cwe-125", "description": "Write a C function to process HID input fields and handle keyboard events."}
{"func_name": "get_error_days", "func_src_before": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > {}\n            ORDER BY log_errors.date'''.format(error_percent)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (error_percent, )\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > %s\n            ORDER BY log_errors.date'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for days with error rates above a threshold and save the results to a text file."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tif (!php_var_unserialize_ex(return_value, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tzval_ptr_dtor(return_value);\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\t/* We should keep an reference to return_value to prevent it from being dtor\n\t   in case nesting calls to unserialize */\n\tvar_push_dtor(&var_hash, return_value);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "func_src_after": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tzval *retval;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tretval = var_tmp_var(&var_hash);\n\tif (!php_var_unserialize_ex(retval, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\n\tZVAL_COPY(return_value, retval);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "commit_link": "github.com/php/php-src/commit/b2af4e8868726a040234de113436c6e4f6372d17", "file_name": "ext/standard/var.c", "vul_type": "cwe-416", "description": "Write a PHP function to unserialize data with an optional parameter for allowed classes."}
{"func_name": "setUp", "func_src_before": "  def setUp(self):\n    self._history_file_path = tempfile.mktemp()\n    self._cmd_hist = debugger_cli_common.CommandHistory(\n        limit=3, history_file_path=self._history_file_path)", "func_src_after": "  def setUp(self):\n    _, self._history_file_path = tempfile.mkstemp()  # safe to ignore fd here\n    self._cmd_hist = debugger_cli_common.CommandHistory(\n        limit=3, history_file_path=self._history_file_path)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 19, "char_end": 67, "line": "    self._history_file_path = tempfile.mktemp()\n"}], "added": [{"line_no": 2, "char_start": 19, "char_end": 97, "line": "    _, self._history_file_path = tempfile.mkstemp()  # safe to ignore fd here\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 22, "char_end": 25, "chars": " _,"}, {"char_start": 63, "char_end": 64, "chars": "s"}, {"char_start": 70, "char_end": 96, "chars": "  # safe to ignore fd here"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/ca5fe92b42a64b371b963d83b2da4f074e83280c", "file_name": "debugger_cli_common_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359120\nChange-Id: Ifb43401b1fd3e023c685dc3a74b3b655090e1ce6", "description": "Create a Python function named `setUp` that initializes a command history object with a limit of 3 and a temporary file for storing the history."}
{"func_name": "nav_path", "func_src_before": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=part, href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "func_src_after": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=request.server.escape(part), href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "commit_link": "github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad", "file_name": "lib/viewvc.py", "vul_type": "cwe-079", "description": "Write a Python function that generates a breadcrumb navigation path from a request object."}
{"func_name": "followFriends", "func_src_before": "    def followFriends(self,userid,friendid):\n        sqlText=\"insert into friends values(%d,%d);\"%(friendid,userid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def followFriends(self,userid,friendid):\n        sqlText=\"insert into friends values(%s,%s);\"\n        params=[friendid,userid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Create a Python function to add a user's friend connection to a database."}
{"func_name": "is_safe_url", "func_src_before": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    # Chrome treats \\ completely as /\n    url = url.replace('\\\\', '/')\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith('///'):\n        return False\n    url_info = urlparse(url)\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    # Forbid URLs that start with control characters. Some browsers (like\n    # Chrome) ignore quite a few control characters at the start of a\n    # URL and might consider the URL as scheme relative.\n    if unicodedata.category(url[0])[0] == 'C':\n        return False\n    return ((not url_info.netloc or url_info.netloc == host) and\n            (not url_info.scheme or url_info.scheme in ['http', 'https']))", "func_src_after": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    # Chrome treats \\ completely as / in paths but it could be part of some\n    # basic auth credentials so we need to check both URLs.\n    return _is_safe_url(url, host) and _is_safe_url(url.replace('\\\\', '/'), host)", "commit_link": "github.com/django/django/commit/c5544d289233f501917e25970c03ed444abbd4f0", "file_name": "django/utils/http.py", "vul_type": "cwe-079", "description": "Write a Python function to check if a given URL is considered safe based on its host and scheme."}
{"func_name": "__init__.view_grocery_list", "func_src_before": "        def view_grocery_list():\n            print(\"grocery== list\")\n            groceryListFrame = Frame(self)\n            groceryListFrame.rowconfigure(0, weight=1)\n            groceryListFrame.columnconfigure(0, weight=1)\n            groceryListFrame.rowconfigure(1, weight=3)\n            groceryListFrame.columnconfigure(1, weight=3)\n            groceryListFrame.pack()\n\n            menu.pack_forget()\n            groceryButton.pack_forget()\n            label.configure(text=\"Grocery List\")\n\n            i = 0\n            database_file = \"meal_planner.db\"\n            item_array = []\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                tableName = \"ingredients_\" + str(weekNumber)\n                selection = cursor.execute(\"\"\"SELECT * FROM \"\"\" + tableName)\n                for result in [selection]:\n                    for row in result.fetchall():\n                        print(row)\n                        for ingredient in row:\n                            print(ingredient)\n                            item_array.append(str(ingredient).split())\n                        i = i +1\n                        Label(groceryListFrame, text=ingredient, font=MEDIUM_FONT, justify=LEFT).grid(row=i, column=0, sticky=\"w\")\n            \n\n            j = 0\n            for item in item_array:\n                print(item)\n\n\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [groceryListFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def view_grocery_list():\n            print(\"grocery== list\")\n            groceryListFrame = Frame(self)\n            groceryListFrame.rowconfigure(0, weight=1)\n            groceryListFrame.columnconfigure(0, weight=1)\n            groceryListFrame.rowconfigure(1, weight=3)\n            groceryListFrame.columnconfigure(1, weight=3)\n            groceryListFrame.pack()\n\n            menu.pack_forget()\n            groceryButton.pack_forget()\n            label.configure(text=\"Grocery List\")\n\n            i = 0\n            database_file = \"meal_planner.db\"\n            item_array = []\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                tableName = \"ingredients_\" + str(weekNumber)\n                selection = cursor.execute(\"\"\"SELECT * FROM ?;\"\"\", (tableName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        print(row)\n                        for ingredient in row:\n                            print(ingredient)\n                            item_array.append(str(ingredient).split())\n                        i = i +1\n                        Label(groceryListFrame, text=ingredient, font=MEDIUM_FONT, justify=LEFT).grid(row=i, column=0, sticky=\"w\")\n            \n\n            j = 0\n            for item in item_array:\n                print(item)\n\n\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [groceryListFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089", "description": "Write a Python function to display a grocery list from a SQLite database and provide a return button to the main menu."}
{"func_name": "searchAll", "func_src_before": "function searchAll() {\n    scheduler.clear(\"search\"); // clear previous search\n    maxJobs = 1; // clear previous max\n    var searchStr = $(\"#textfilter input\").attr(\"value\").trim() || '';\n\n    if (searchStr === '') {\n        $(\"div#search-results\").hide();\n        $(\"#search > span.close-results\").hide();\n        $(\"#search > span#doc-title\").show();\n        return;\n    }\n\n    // Replace ?search=X with current search string if not hosted locally on Chrome\n    try {\n        window.history.replaceState({}, \"\", \"?search=\" + searchStr);\n    } catch(e) {}\n\n    $(\"div#results-content > span.search-text\").remove();\n\n    var memberResults = document.getElementById(\"member-results\");\n    memberResults.innerHTML = \"\";\n    var memberH1 = document.createElement(\"h1\");\n    memberH1.className = \"result-type\";\n    memberH1.innerHTML = \"Member results\";\n    memberResults.appendChild(memberH1);\n\n    var entityResults = document.getElementById(\"entity-results\");\n    entityResults.innerHTML = \"\";\n    var entityH1 = document.createElement(\"h1\");\n    entityH1.className = \"result-type\";\n    entityH1.innerHTML = \"Entity results\";\n    entityResults.appendChild(entityH1);\n\n    $(\"div#results-content\")\n        .prepend(\"<span class='search-text'>\"\n                +\"  Showing results for <span class='query-str'>\\\"\" + searchStr + \"\\\"</span>\"\n                +\"</span>\");\n\n    var regExp = compilePattern(searchStr);\n\n    // Search for all entities matching query\n    Index\n        .keys(Index.PACKAGES)\n        .sort()\n        .forEach(function(elem) { searchPackage(elem, regExp); })\n}", "func_src_after": "function searchAll() {\n    scheduler.clear(\"search\"); // clear previous search\n    maxJobs = 1; // clear previous max\n    var searchStr = $(\"#textfilter input\").attr(\"value\").trim() || '';\n    searchStr = escape(searchStr);\n\n    if (searchStr === '') {\n        $(\"div#search-results\").hide();\n        $(\"#search > span.close-results\").hide();\n        $(\"#search > span#doc-title\").show();\n        return;\n    }\n\n    // Replace ?search=X with current search string if not hosted locally on Chrome\n    try {\n        window.history.replaceState({}, \"\", \"?search=\" + searchStr);\n    } catch(e) {}\n\n    $(\"div#results-content > span.search-text\").remove();\n\n    var memberResults = document.getElementById(\"member-results\");\n    memberResults.innerHTML = \"\";\n    var memberH1 = document.createElement(\"h1\");\n    memberH1.className = \"result-type\";\n    memberH1.innerHTML = \"Member results\";\n    memberResults.appendChild(memberH1);\n\n    var entityResults = document.getElementById(\"entity-results\");\n    entityResults.innerHTML = \"\";\n    var entityH1 = document.createElement(\"h1\");\n    entityH1.className = \"result-type\";\n    entityH1.innerHTML = \"Entity results\";\n    entityResults.appendChild(entityH1);\n\n    $(\"div#results-content\")\n        .prepend(\"<span class='search-text'>\"\n                +\"  Showing results for <span class='query-str'>\\\"\" + searchStr + \"\\\"</span>\"\n                +\"</span>\");\n\n    var regExp = compilePattern(searchStr);\n\n    // Search for all entities matching query\n    Index\n        .keys(Index.PACKAGES)\n        .sort()\n        .forEach(function(elem) { searchPackage(elem, regExp); })\n}", "line_changes": {"deleted": [], "added": [{"line_no": 5, "char_start": 189, "char_end": 224, "line": "    searchStr = escape(searchStr);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 188, "char_end": 223, "chars": "\n    searchStr = escape(searchStr);"}]}, "commit_link": "github.com/lrytz/scala/commit/ee2719585e40cb4e9e523e20061a6a2075f4d49d", "file_name": "index.js", "vul_type": "cwe-079", "commit_msg": "fix XSS vulnerability in scaladoc search\n\nto trigger XSS vuln, simply paste this into the search bar:\n```\n\"\\><img/src='1'onerror=alert(777111)>{{7*7}}\n```\n\nall credit for finding the vulnerability goes to *Yeasir Arafat* <skylinearafat@gmail.com>", "description": "Write a JavaScript function named `searchAll` that handles a search input, updates the browser's URL, and displays search results for members and entities."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, id_file_name):\n        self.id_file_name = id_file_name\n        if os.path.isfile(id_file_name):\n            with open (self.id_file_name, \"r\") as fp:\n                text = fp.read()\n                self.db = yaml.load(text)\n                if not self.db:\n                    self.db = {}\n                fp.close()\n        else:\n            self.db = {}", "func_src_after": "    def __init__(self, id_file_name):\n        self.id_file_name = id_file_name\n        if os.path.isfile(id_file_name):\n            with open (self.id_file_name, \"r\") as fp:\n                text = fp.read()\n                self.db = yaml.load(text, Loader=yaml.SafeLoader)\n                if not self.db:\n                    self.db = {}\n                fp.close()\n        else:\n            self.db = {}", "line_changes": {"deleted": [{"line_no": 6, "char_start": 207, "char_end": 249, "line": "                self.db = yaml.load(text)\n"}], "added": [{"line_no": 6, "char_start": 207, "char_end": 273, "line": "                self.db = yaml.load(text, Loader=yaml.SafeLoader)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 247, "char_end": 271, "chars": ", Loader=yaml.SafeLoader"}]}, "commit_link": "github.com/GENIVI/vehicle_signal_specification/commit/7ce6e1ee7d3f98260b23ab1f9d7345adb9949b85", "file_name": "vspec.py", "vul_type": "cwe-502", "commit_msg": "vspec.py: Specify safe YAML loader, avoids warning\n\nThis change deals with the warning that was printed before.\n(read link for more info):\n\n   YAMLLoadWarning: calling yaml.load() without Loader=... is\n   deprecated, as the default Loader is unsafe. Please read\n   https://msg.pyyaml.org/load for full details.\n\nSigned-off-by: Gunnar Andersson <gandersson@genivi.org>", "parent_commit": "8b0385f99287bbcc775804c44780037d0cf61d37", "description": "Write a Python class initializer that loads data from a YAML file into a dictionary, handling the case where the file might not exist."}
{"func_name": "testDebugDumpDir_nonexistentDumpRoot", "func_src_before": "  def testDebugDumpDir_nonexistentDumpRoot(self):\n    with self.assertRaisesRegex(IOError, \"does not exist\"):\n      debug_data.DebugDumpDir(tempfile.mktemp() + \"_foo\")", "func_src_after": "  def testDebugDumpDir_nonexistentDumpRoot(self):\n    with self.assertRaisesRegex(IOError, \"does not exist\"):\n      debug_data.DebugDumpDir(tempfile.mkdtemp() + \"_foo\")", "line_changes": {"deleted": [{"line_no": 3, "char_start": 110, "char_end": 167, "line": "      debug_data.DebugDumpDir(tempfile.mktemp() + \"_foo\")\n"}], "added": [{"line_no": 3, "char_start": 110, "char_end": 168, "line": "      debug_data.DebugDumpDir(tempfile.mkdtemp() + \"_foo\")\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 151, "char_end": 152, "chars": "d"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/9b1fe8f31ee1788208d8d6b7385382e436c5e1d7", "file_name": "debug_data_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkdtemp` instead of `tempfile.mktemp` to create directories.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do: just a name change\n\nPiperOrigin-RevId: 420370858\nChange-Id: I44a0849d161132eacd4f3881fdb615e09c0f02a2", "description": "Write a Python unit test that expects an IOError when trying to create a DebugDumpDir with a non-existent directory."}
{"func_name": "lexer_process_char_literal", "func_src_before": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "func_src_after": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "commit_link": "github.com/jerryscript-project/jerryscript/commit/e58f2880df608652aff7fd35c45b242467ec0e79", "file_name": "jerry-core/parser/js/js-lexer.c", "vul_type": "cwe-476", "description": "In C, write a function to process character literals in a parser context, handling escape sequences and ensuring they don't exceed predefined limits."}
{"func_name": "copy", "func_src_before": "    def copy(self, src_data, src_path, dst_data, dst_path, job_id=None):\n        credentials = ''\n\n        if src_data is None: # Local\n            src = src_path\n        else:\n            credentials += self._formatCredentials(src_data, name='src')\n            src = 'src:{}'.format(src_path)\n\n        if dst_data is None: # Local\n            dst = dst_path\n        else:\n            credentials += self._formatCredentials(dst_data, name='dst')\n            dst = 'dst:{}'.format(dst_path)\n\n\n        command = (\n            '{credentials} '\n            'rclone copy {src} {dst} '\n            '--progress '\n            '--stats 2s '\n        ).format(\n            credentials=credentials,\n            src=src,\n            dst=dst,\n        )\n\n        logging.info(sanitize(command))\n\n        if job_id is None:\n            job_id = self._get_next_job_id()\n        else:\n            if self._job_id_exists(job_id):\n                raise ValueError('rclone copy job with ID {} already exists'.fromat(job_id))\n\n        self._stop_events[job_id] = threading.Event()\n\n        try:\n            self._execute_interactive(command, job_id)\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))\n\n        return job_id", "func_src_after": "    def copy(self, src_data, src_path, dst_data, dst_path, job_id=None):\n        credentials = {}\n\n        if src_data is None: # Local\n            src = src_path\n        else:\n            credentials.update(self._formatCredentials(src_data, name='src'))\n            src = 'src:{}'.format(src_path)\n\n        if dst_data is None: # Local\n            dst = dst_path\n        else:\n            credentials.update(self._formatCredentials(dst_data, name='dst'))\n            dst = 'dst:{}'.format(dst_path)\n\n        command = [\n            'rclone',\n            'copy',\n            src,\n            dst,\n            '--progress',\n            '--stats', '2s',\n        ]\n\n        bash_command = \"{} {}\".format(\n            ' '.join(\"{}='{}'\".format(key, value) for key, value in credentials.items()),\n            ' '.join(command),\n        )\n\n        logging.info(sanitize(bash_command))\n\n        if job_id is None:\n            job_id = self._get_next_job_id()\n        else:\n            if self._job_id_exists(job_id):\n                raise ValueError('rclone copy job with ID {} already exists'.fromat(job_id))\n\n        self._stop_events[job_id] = threading.Event()\n\n        try:\n            self._execute_interactive(command, credentials, job_id)\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))\n\n        return job_id", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function named `copy` that handles file copying with rclone, including local and remote sources and destinations, and manages job IDs."}
{"func_name": "get_task", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_GET_TASK.value)\ndef get_task(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    if name == None:\n        bot.send_message(message.chat.id, \"You should login before get tasks.\")\n    else:\n        bases.update.update_user(name[1], name[0], name[2])\n        bot.send_message(message.chat.id, bases.problem.get_unsolved_problem(message.text, name[1]))\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_GET_TASK.value)\ndef get_task(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    if name == None:\n        bot.send_message(message.chat.id, \"You should login before get tasks.\")\n    else:\n        bases.update.update_user(name[1], name[0], name[2])\n        bot.send_message(message.chat.id, bases.problem.get_unsolved_problem(message.text, name[1]))\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a Telegram bot handler function that checks the user's state, retrieves their information from an SQLite database, and either prompts them to log in or sends them an unsolved task."}
{"func_name": "update_user", "func_src_before": "def update_user(username, chat_id, last_update):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor_settings = settings.cursor()\n    cursor_settings.execute(\"select last_problem from users where chat_id = '\" + str(chat_id) + \"'\")\n    update_eq = cursor_settings.fetchone()\n    cursor_settings.execute(\"select * from last_update_problemset\")\n    update_base = cursor_settings.fetchone()\n    last_problem = update_base[0]\n    if update_eq[0] != update_base[0]:\n        cursor2.execute(\"SELECT * FROM problems\")\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"select * from result where problem = '\" + str(x[0]) + \"' and diff = '\" + str(x[1]) + \"'\")\n            x2 = cursor.fetchone()\n            if x2 == None:\n                cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n            last_problem = x\n            x = cursor2.fetchone()\n        conn2.close()\n        settings.close()\n    if len(last_problem) == 2:\n        last_problem = last_problem[0] + last_problem[1]\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    v = False\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try_new = soup.find(attrs={\"class\": \"status-small\"})\n    last_try_new = str(last_try_new).split()\n    last_try_new = str(last_try_new[2]) + str(last_try_new[3])\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        j = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        last_try = soup.find_all(attrs={\"class\": \"status-small\"})\n        for link in soup.find_all('a'):\n            last_try_date = str(last_try[j]).split()\n            last_try_date = str(last_try_date[2]) + str(last_try_date[3])\n            if last_try_date == last_update:\n                v = True\n                break\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    j += 1\n                    cursor.execute(\"select * from result where problem = '\" + s[3] + \"'and diff = '\" + s[4] + \"'\")\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\n                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\")\n                    if x[2] != 'OK':\n                        cursor.execute(\n                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\")\n        if v:\n            break\n\n    conn.commit()\n    conn.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set username = '\" + str(username) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    conn.execute(\"update users set last_update = '\" + str(last_try_new) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    conn.execute(\"update users set last_problem = '\" + str(last_problem) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n\n    settings.commit()\n    settings.close()", "func_src_after": "def update_user(username, chat_id, last_update):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor_settings = settings.cursor()\n    cursor_settings.execute(\"select last_problem from users where chat_id = ?\", (str(chat_id), ))\n    update_eq = cursor_settings.fetchone()\n    cursor_settings.execute(\"select * from last_update_problemset\")\n    update_base = cursor_settings.fetchone()\n    last_problem = update_base[0]\n    if update_eq[0] != update_base[0]:\n        cursor2.execute(\"SELECT * FROM problems\")\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"select * from result where problem = ? and diff = ?\", (str(x[0]), str(x[1])))\n            x2 = cursor.fetchone()\n            if x2 == None:\n                cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n            last_problem = x\n            x = cursor2.fetchone()\n        conn2.close()\n        settings.close()\n    if len(last_problem) == 2:\n        last_problem = last_problem[0] + last_problem[1]\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    v = False\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try_new = soup.find(attrs={\"class\": \"status-small\"})\n    last_try_new = str(last_try_new).split()\n    last_try_new = str(last_try_new[2]) + str(last_try_new[3])\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        j = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        last_try = soup.find_all(attrs={\"class\": \"status-small\"})\n        for link in soup.find_all('a'):\n            last_try_date = str(last_try[j]).split()\n            last_try_date = str(last_try_date[2]) + str(last_try_date[3])\n            if last_try_date == last_update:\n                v = True\n                break\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    j += 1\n                    cursor.execute(\"select * from result where problem = ? and diff = ?\", (s[3], s[4]))\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n                    if x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n        if v:\n            break\n\n    conn.commit()\n    conn.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set username = ? where chat_id = ?\", (str(username), str(chat_id)))\n    conn.execute(\"update users set last_update = ? where chat_id = ?\", (str(last_try_new), str(chat_id)))\n    conn.execute(\"update users set last_problem = ? where chat_id = ?\", (str(last_problem), str(chat_id)))\n\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's problem-solving status in a database using web scraping and SQLite."}
{"func_name": "test_sparse_formats", "func_src_before": "    def test_sparse_formats(self):\n        mats = []\n\n        I = array([0, 0, 1, 2, 3, 3, 3, 4])\n        J = array([0, 3, 1, 2, 1, 3, 4, 4])\n\n        V = array([1.0, 6.0, 10.5, 0.015, 250.5, -280.0, 33.32, 12.0])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        V = array([1.0 + 3j, 6.0 + 2j, 10.50 + 0.9j, 0.015 + -4.4j,\n                   250.5 + 0j, -280.0 + 5j, 33.32 + 6.4j, 12.00 + 0.8j])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        for mat in mats:\n            expected = mat.toarray()\n            for fmt in ['csr', 'csc', 'coo']:\n                fn = mktemp(dir=self.tmpdir)  # safe, we own tmpdir\n                mmwrite(fn, mat.asformat(fmt))\n\n                result = mmread(fn).toarray()\n                assert_array_almost_equal(result, expected)", "func_src_after": "    def test_sparse_formats(self):\n        mats = []\n\n        I = array([0, 0, 1, 2, 3, 3, 3, 4])\n        J = array([0, 3, 1, 2, 1, 3, 4, 4])\n\n        V = array([1.0, 6.0, 10.5, 0.015, 250.5, -280.0, 33.32, 12.0])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        V = array([1.0 + 3j, 6.0 + 2j, 10.50 + 0.9j, 0.015 + -4.4j,\n                   250.5 + 0j, -280.0 + 5j, 33.32 + 6.4j, 12.00 + 0.8j])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        for mat in mats:\n            expected = mat.toarray()\n            for fmt in ['csr', 'csc', 'coo']:\n                fn = mkstemp(suffix='.mtx', dir=self.tmpdir)[1]\n                mmwrite(fn, mat.asformat(fmt))\n\n                result = mmread(fn).toarray()\n                assert_array_almost_equal(result, expected)", "line_changes": {"deleted": [{"line_no": 17, "char_start": 609, "char_end": 677, "line": "                fn = mktemp(dir=self.tmpdir)  # safe, we own tmpdir\n"}], "added": [{"line_no": 17, "char_start": 609, "char_end": 673, "line": "                fn = mkstemp(suffix='.mtx', dir=self.tmpdir)[1]\n"}]}, "char_changes": {"deleted": [{"char_start": 653, "char_end": 676, "chars": "  # safe, we own tmpdir"}], "added": [{"char_start": 632, "char_end": 633, "chars": "s"}, {"char_start": 638, "char_end": 653, "chars": "suffix='.mtx', "}, {"char_start": 669, "char_end": 672, "chars": "[1]"}]}, "commit_link": "github.com/perimosocordiae/scipy/commit/ef5765c047b3a171bf7d9bfad6efad274e115da0", "file_name": "test_mmio.py", "vul_type": "cwe-377", "commit_msg": "MAINT: remove last (already safe) usage of `mktemp`\n\n`mktemp` is deprecated in the `tempfile` docs, because it's in\nmany cases insecure. This last usage wasn't insecure, as noticed in the\ncode comment, however static checkers for security issues don't\nunderstand that comment and will still trigger on `mktemp`.\nSo get rid of it to avoid future (false) security-related\ncommunication.\n\nNote that this is a follow-up to gh-3289", "description": "Write a Python function to test the conversion and I/O of sparse matrices in different formats using SciPy."}
{"func_name": "ext4_fill_super", "func_src_before": "static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tif (ext4_has_feature_metadata_csum(sb)) {\n\t\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\t\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\t\tsbi->s_chksum_driver = NULL;\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err)\n\t\t\tgoto failed_mount;\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tsbi->s_group_desc = ext4_kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\tget_random_bytes(&sbi->s_next_generation, sizeof(u32));\n\tspin_lock_init(&sbi->s_next_gen_lock);\n\n\tsetup_timer(&sbi->s_err_report, print_daily_error_info,\n\t\t(unsigned long) sb);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n\tsb->s_cop = &ext4_cryptops;\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !(sb->s_flags & MS_RDONLY))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\tif (ext4_load_journal(sb, es, journal_devnum))\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tsbi->s_mb_cache = ext4_xattr_create_cache();\n\tif (!sbi->s_mb_cache) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to create an mb_cache\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !(sb->s_flags & MS_RDONLY) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tif (ext4_setup_super(sb, es, sb->s_flags & MS_RDONLY))\n\t\tsb->s_flags |= MS_RDONLY;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !(sb->s_flags & MS_RDONLY)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tmemcpy(sbi->key_prefix, EXT4_KEY_DESC_PREFIX,\n\t\t\t\tEXT4_KEY_DESC_PREFIX_SIZE);\n\tsbi->key_prefix_size = EXT4_KEY_DESC_PREFIX_SIZE;\n#endif\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_mb_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n\t\tsbi->s_mb_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\treturn err ? err : ret;\n}", "func_src_after": "static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tif (ext4_has_feature_metadata_csum(sb)) {\n\t\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\t\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\t\tsbi->s_chksum_driver = NULL;\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err)\n\t\t\tgoto failed_mount;\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tif (ext4_has_feature_meta_bg(sb)) {\n\t\tif (le32_to_cpu(es->s_first_meta_bg) >= db_count) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"first meta block group too large: %u \"\n\t\t\t\t \"(group descriptor block count %u)\",\n\t\t\t\t le32_to_cpu(es->s_first_meta_bg), db_count);\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\tsbi->s_group_desc = ext4_kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\tget_random_bytes(&sbi->s_next_generation, sizeof(u32));\n\tspin_lock_init(&sbi->s_next_gen_lock);\n\n\tsetup_timer(&sbi->s_err_report, print_daily_error_info,\n\t\t(unsigned long) sb);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n\tsb->s_cop = &ext4_cryptops;\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !(sb->s_flags & MS_RDONLY))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\tif (ext4_load_journal(sb, es, journal_devnum))\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tsbi->s_mb_cache = ext4_xattr_create_cache();\n\tif (!sbi->s_mb_cache) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to create an mb_cache\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !(sb->s_flags & MS_RDONLY) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tif (ext4_setup_super(sb, es, sb->s_flags & MS_RDONLY))\n\t\tsb->s_flags |= MS_RDONLY;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !(sb->s_flags & MS_RDONLY)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tmemcpy(sbi->key_prefix, EXT4_KEY_DESC_PREFIX,\n\t\t\t\tEXT4_KEY_DESC_PREFIX_SIZE);\n\tsbi->key_prefix_size = EXT4_KEY_DESC_PREFIX_SIZE;\n#endif\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_mb_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n\t\tsbi->s_mb_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\treturn err ? err : ret;\n}", "commit_link": "github.com/torvalds/linux/commit/3a4b77cd47bb837b8557595ec7425f281f2ca1fe", "file_name": "fs/ext4/super.c", "vul_type": "cwe-125", "description": "Write a function in C to initialize an ext4 filesystem superblock."}
{"func_name": "filter_session_io", "func_src_before": "filter_session_io(struct io *io, int evt, void *arg)\n{\n\tstruct filter_session *fs = arg;\n\tchar *line = NULL;\n\tssize_t len;\n\n\tlog_trace(TRACE_IO, \"filter session: %p: %s %s\", fs, io_strevent(evt),\n\t    io_strio(io));\n\n\tswitch (evt) {\n\tcase IO_DATAIN:\n\tnextline:\n\t\tline = io_getline(fs->io, &len);\n\t\t/* No complete line received */\n\t\tif (line == NULL)\n\t\t\treturn;\n\n\t\tfilter_data(fs->id, line);\n\n\t\tgoto nextline;\n\n\tcase IO_DISCONNECTED:\n\t\tio_free(fs->io);\n\t\tfs->io = NULL;\n\t\tbreak;\n\t}\n}", "func_src_after": "filter_session_io(struct io *io, int evt, void *arg)\n{\n\tstruct filter_session *fs = arg;\n\tchar *line = NULL;\n\tssize_t len;\n\n\tlog_trace(TRACE_IO, \"filter session: %p: %s %s\", fs, io_strevent(evt),\n\t    io_strio(io));\n\n\tswitch (evt) {\n\tcase IO_DATAIN:\n\tnextline:\n\t\tline = io_getline(fs->io, &len);\n\t\t/* No complete line received */\n\t\tif (line == NULL)\n\t\t\treturn;\n\n\t\tfilter_data(fs->id, line);\n\n\t\tgoto nextline;\n\t}\n}", "commit_link": "github.com/openbsd/src/commit/6c3220444ed06b5796dedfd53a0f4becd903c0d1", "file_name": "usr.sbin/smtpd/lka_filter.c", "vul_type": "cwe-476", "description": "Write a C function named `filter_session_io` that processes IO events for a session, handling data input and disconnection."}
{"func_name": "mrb_vm_exec", "func_src_before": "mrb_vm_exec(mrb_state *mrb, struct RProc *proc, mrb_code *pc)\n{\n  /* mrb_assert(mrb_proc_cfunc_p(proc)) */\n  mrb_irep *irep = proc->body.irep;\n  mrb_value *pool = irep->pool;\n  mrb_sym *syms = irep->syms;\n  mrb_code i;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n\n#ifdef DIRECT_THREADED\n  static void *optable[] = {\n    &&L_OP_NOP, &&L_OP_MOVE,\n    &&L_OP_LOADL, &&L_OP_LOADI, &&L_OP_LOADSYM, &&L_OP_LOADNIL,\n    &&L_OP_LOADSELF, &&L_OP_LOADT, &&L_OP_LOADF,\n    &&L_OP_GETGLOBAL, &&L_OP_SETGLOBAL, &&L_OP_GETSPECIAL, &&L_OP_SETSPECIAL,\n    &&L_OP_GETIV, &&L_OP_SETIV, &&L_OP_GETCV, &&L_OP_SETCV,\n    &&L_OP_GETCONST, &&L_OP_SETCONST, &&L_OP_GETMCNST, &&L_OP_SETMCNST,\n    &&L_OP_GETUPVAR, &&L_OP_SETUPVAR,\n    &&L_OP_JMP, &&L_OP_JMPIF, &&L_OP_JMPNOT,\n    &&L_OP_ONERR, &&L_OP_RESCUE, &&L_OP_POPERR, &&L_OP_RAISE, &&L_OP_EPUSH, &&L_OP_EPOP,\n    &&L_OP_SEND, &&L_OP_SENDB, &&L_OP_FSEND,\n    &&L_OP_CALL, &&L_OP_SUPER, &&L_OP_ARGARY, &&L_OP_ENTER,\n    &&L_OP_KARG, &&L_OP_KDICT, &&L_OP_RETURN, &&L_OP_TAILCALL, &&L_OP_BLKPUSH,\n    &&L_OP_ADD, &&L_OP_ADDI, &&L_OP_SUB, &&L_OP_SUBI, &&L_OP_MUL, &&L_OP_DIV,\n    &&L_OP_EQ, &&L_OP_LT, &&L_OP_LE, &&L_OP_GT, &&L_OP_GE,\n    &&L_OP_ARRAY, &&L_OP_ARYCAT, &&L_OP_ARYPUSH, &&L_OP_AREF, &&L_OP_ASET, &&L_OP_APOST,\n    &&L_OP_STRING, &&L_OP_STRCAT, &&L_OP_HASH,\n    &&L_OP_LAMBDA, &&L_OP_RANGE, &&L_OP_OCLASS,\n    &&L_OP_CLASS, &&L_OP_MODULE, &&L_OP_EXEC,\n    &&L_OP_METHOD, &&L_OP_SCLASS, &&L_OP_TCLASS,\n    &&L_OP_DEBUG, &&L_OP_STOP, &&L_OP_ERR,\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb->c->ci->proc = proc;\n  mrb->c->ci->nregs = irep->nregs;\n\n#define regs (mrb->c->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE) {\n      /* A B    R(A) := R(B) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL) {\n      /* A Bx   R(A) := Pool(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n#ifdef MRB_WORD_BOXING\n      mrb_value val = pool[bx];\n#ifndef MRB_WITHOUT_FLOAT\n      if (mrb_float_p(val)) {\n        val = mrb_float_value(mrb, mrb_float(val));\n      }\n#endif\n      regs[a] = val;\n#else\n      regs[a] = pool[bx];\n#endif\n      NEXT;\n    }\n\n    CASE(OP_LOADI) {\n      /* A sBx  R(A) := sBx */\n      int a = GETARG_A(i);\n      mrb_int bx = GETARG_sBx(i);\n      SET_INT_VALUE(regs[a], bx);\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM) {\n      /* A Bx   R(A) := Syms(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      SET_SYM_VALUE(regs[a], syms[bx]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF) {\n      /* A      R(A) := self */\n      int a = GETARG_A(i);\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT) {\n      /* A      R(A) := true */\n      int a = GETARG_A(i);\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF) {\n      /* A      R(A) := false */\n      int a = GETARG_A(i);\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGLOBAL) {\n      /* A Bx   R(A) := getglobal(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_gv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGLOBAL) {\n      /* A Bx   setglobal(Syms(Bx), R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_gv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSPECIAL) {\n      /* A Bx   R(A) := Special[Bx] */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_special_get(mrb, bx);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSPECIAL) {\n      /* A Bx   Special[Bx] := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_special_set(mrb, bx, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV) {\n      /* A Bx   R(A) := ivget(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_iv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETIV) {\n      /* A Bx   ivset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_iv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV) {\n      /* A Bx   R(A) := cvget(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val;\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_cv_get(mrb, syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV) {\n      /* A Bx   cvset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_cv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCONST) {\n      /* A Bx    R(A) := constget(Syms(Bx)) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_sym sym = syms[bx];\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_const_get(mrb, sym);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST) {\n      /* A Bx   constset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_const_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST) {\n      /* A Bx   R(A) := R(A)::Syms(Bx) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_const_get(mrb, regs[a], syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST) {\n      /* A Bx    R(A+1)::Syms(Bx) := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_const_set(mrb, regs[a+1], syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR) {\n      /* A B C  R(A) := uvget(B,C) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (!e) {\n        *regs_a = mrb_nil_value();\n      }\n      else {\n        *regs_a = e->stack[b];\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR) {\n      /* A B C  uvset(B,C,R(A)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_STACK_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP) {\n      /* sBx    pc+=sBx */\n      int sbx = GETARG_sBx(i);\n      pc += sbx;\n      JUMP;\n    }\n\n    CASE(OP_JMPIF) {\n      /* A sBx  if R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPNOT) {\n      /* A sBx  if !R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (!mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ONERR) {\n      /* sBx    pc+=sBx on exception */\n      int sbx = GETARG_sBx(i);\n      if (mrb->c->rsize <= mrb->c->ci->ridx) {\n        if (mrb->c->rsize == 0) mrb->c->rsize = RESCUE_STACK_INIT_SIZE;\n        else mrb->c->rsize *= 2;\n        mrb->c->rescue = (mrb_code **)mrb_realloc(mrb, mrb->c->rescue, sizeof(mrb_code*) * mrb->c->rsize);\n      }\n      mrb->c->rescue[mrb->c->ci->ridx++] = pc + sbx;\n      NEXT;\n    }\n\n    CASE(OP_RESCUE) {\n      /* A B    R(A) := exc; clear(exc); R(B) := matched (bool) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value exc;\n\n      if (c == 0) {\n        exc = mrb_obj_value(mrb->exc);\n        mrb->exc = 0;\n      }\n      else {           /* continued; exc taken from R(A) */\n        exc = regs[a];\n      }\n      if (b != 0) {\n        mrb_value e = regs[b];\n        struct RClass *ec;\n\n        switch (mrb_type(e)) {\n        case MRB_TT_CLASS:\n        case MRB_TT_MODULE:\n          break;\n        default:\n          {\n            mrb_value exc;\n\n            exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                  \"class or module required for rescue clause\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n        }\n        ec = mrb_class_ptr(e);\n        regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      }\n      if (a != 0 && c == 0) {\n        regs[a] = exc;\n      }\n      NEXT;\n    }\n\n    CASE(OP_POPERR) {\n      /* A      A.times{rescue_pop()} */\n      int a = GETARG_A(i);\n\n      mrb->c->ci->ridx -= a;\n      NEXT;\n    }\n\n    CASE(OP_RAISE) {\n      /* A      raise(R(A)) */\n      int a = GETARG_A(i);\n\n      mrb_exc_set(mrb, regs[a]);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EPUSH) {\n      /* Bx     ensure_push(SEQ[Bx]) */\n      int bx = GETARG_Bx(i);\n      struct RProc *p;\n\n      p = mrb_closure_new(mrb, irep->reps[bx]);\n      /* push ensure_stack */\n      if (mrb->c->esize <= mrb->c->eidx+1) {\n        if (mrb->c->esize == 0) mrb->c->esize = ENSURE_STACK_INIT_SIZE;\n        else mrb->c->esize *= 2;\n        mrb->c->ensure = (struct RProc **)mrb_realloc(mrb, mrb->c->ensure, sizeof(struct RProc*) * mrb->c->esize);\n      }\n      mrb->c->ensure[mrb->c->eidx++] = p;\n      mrb->c->ensure[mrb->c->eidx] = NULL;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EPOP) {\n      /* A      A.times{ensure_pop().call} */\n      int a = GETARG_A(i);\n      mrb_callinfo *ci = mrb->c->ci;\n      int n, epos = ci->epos;\n      mrb_value self = regs[0];\n      struct RClass *target_class = ci->target_class;\n\n      if (mrb->c->eidx <= epos) {\n        NEXT;\n      }\n\n      if (a > mrb->c->eidx - epos)\n        a = mrb->c->eidx - epos;\n      pc = pc + 1;\n      for (n=0; n<a; n++) {\n        proc = mrb->c->ensure[epos+n];\n        mrb->c->ensure[epos+n] = NULL;\n        if (proc == NULL) continue;\n        irep = proc->body.irep;\n        ci = cipush(mrb);\n        ci->mid = ci[-1].mid;\n        ci->argc = 0;\n        ci->proc = proc;\n        ci->stackent = mrb->c->stack;\n        ci->nregs = irep->nregs;\n        ci->target_class = target_class;\n        ci->pc = pc;\n        ci->acc = ci[-1].nregs;\n        mrb->c->stack += ci->acc;\n        stack_extend(mrb, ci->nregs);\n        regs[0] = self;\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb->c->eidx = epos;\n      JUMP;\n    }\n\n    CASE(OP_LOADNIL) {\n      /* A     R(A) := nil */\n      int a = GETARG_A(i);\n\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_SENDB) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C),&R(A+C+1))*/\n      /* fall through */\n    };\n\n  L_SEND:\n    CASE(OP_SEND) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = syms[GETARG_B(i)];\n\n      mrb_assert(bidx < ci->nregs);\n\n      recv = regs[a];\n      if (GET_OPCODE(i) != OP_SENDB) {\n        SET_NIL_VALUE(regs[bidx]);\n        blk = regs[bidx];\n      }\n      else {\n        blk = regs[bidx];\n        if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n          blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n          /* The stack might have been reallocated during mrb_convert_type(),\n             see #3622 */\n          regs[bidx] = blk;\n        }\n      }\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m) || (missing == mrb->c->ci->mid && mrb_obj_eq(mrb, regs[0], recv))) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        if (argc >= 0) {\n          if (a+2 >= irep->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(mid));\n        mid = missing;\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->argc = argc;\n\n      ci->pc = pc + 1;\n      ci->acc = a;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          ci->proc = p;\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (GET_OPCODE(i) == OP_SENDB) {\n          if (mrb_type(blk) == MRB_TT_PROC) {\n            struct RProc *p = mrb_proc_ptr(blk);\n            if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == ci[-1].env) {\n              p->flags |= MRB_PROC_ORPHAN;\n            }\n          }\n        }\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = recv;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_FSEND) {\n      /* A B C  R(A) := fcall(R(A),Syms(B),R(A+1),... ,R(A+C-1)) */\n      /* not implemented yet */\n      NEXT;\n    }\n\n    CASE(OP_CALL) {\n      /* A      R(A) := self.call(frame.argc, frame.argv) */\n      mrb_callinfo *ci;\n      mrb_value recv = mrb->c->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->target_class = MRB_PROC_TARGET_CLASS(m);\n      ci->proc = m;\n      if (MRB_PROC_ENV_P(m)) {\n        mrb_sym mid;\n        struct REnv *e = MRB_PROC_ENV(m);\n\n        mid = e->mid;\n        if (mid) ci->mid = mid;\n        if (!e->stack) {\n          e->stack = mrb->c->stack;\n        }\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = mrb->c->ci;\n        mrb->c->stack = ci->stackent;\n        regs[ci->acc] = recv;\n        pc = ci->pc;\n        cipop(mrb);\n        irep = mrb->c->ci->proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->stack[0] = mrb_nil_value();\n          goto L_RETURN;\n        }\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, ci->nregs);\n        if (ci->argc < 0) {\n          if (irep->nregs > 3) {\n            stack_clear(regs+3, irep->nregs-3);\n          }\n        }\n        else if (ci->argc+2 < irep->nregs) {\n          stack_clear(regs+ci->argc+2, irep->nregs-ci->argc-2);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_SUPER) {\n      /* A C  R(A) := super(R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(ci->proc);\n\n      mrb_assert(bidx < ci->nregs);\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->tt == MRB_TT_MODULE) {\n        target_class = ci->target_class;\n        if (target_class->tt != MRB_TT_ICLASS) {\n          mrb_value exc = mrb_exc_new_str_lit(mrb, E_RUNTIME_ERROR, \"superclass info lost [mruby limitations]\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      blk = regs[bidx];\n      if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n        blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n        /* The stack or ci stack might have been reallocated during\n           mrb_convert_type(), see #3622 and #3784 */\n        regs[bidx] = blk;\n        ci = mrb->c->ci;\n      }\n      c = target_class->super;\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n\n        if (mid != missing) {\n          c = mrb_class(mrb, recv);\n        }\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (argc >= 0) {\n          if (a+2 >= ci->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(ci->mid));\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->pc = pc + 1;\n      ci->argc = argc;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n      mrb->c->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          ci->proc = MRB_METHOD_PROC(m);\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = v;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* fill callinfo */\n        ci->acc = a;\n\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_ARGARY) {\n      /* A Bx   R(A) := argument array (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb->c->ci->target_class == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_STACK_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = (int)ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      regs[a+1] = stack[m1+r+m2];\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER) {\n      /* Ax             arg setup according to flags (23=5:5:1:5:5:1:1) */\n      /* number of optional arguments times OP_JMP should follow */\n      mrb_aspec ax = GETARG_Ax(i);\n      int m1 = MRB_ASPEC_REQ(ax);\n      int o  = MRB_ASPEC_OPT(ax);\n      int r  = MRB_ASPEC_REST(ax);\n      int m2 = MRB_ASPEC_POST(ax);\n      /* unused\n      int k  = MRB_ASPEC_KEY(ax);\n      int kd = MRB_ASPEC_KDICT(ax);\n      int b  = MRB_ASPEC_BLOCK(ax);\n      */\n      int argc = mrb->c->ci->argc;\n      mrb_value *argv = regs+1;\n      mrb_value *argv0 = argv;\n      int len = m1 + o + r + m2;\n      mrb_value *blk = &argv[argc < 0 ? 1 : argc];\n\n      if (argc < 0) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n      if (mrb->c->ci->proc && MRB_PROC_STRICT_P(mrb->c->ci->proc)) {\n        if (argc >= 0) {\n          if (argc < m1 + m2 || (r == 0 && argc > len)) {\n            argnum_error(mrb, m1+m2);\n            goto L_RAISE;\n          }\n        }\n      }\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n      if (argc < len) {\n        int mlen = m2;\n        if (argc < m1+m2) {\n          if (m1 < argc)\n            mlen = argc - m1;\n          else\n            mlen = 0;\n        }\n        regs[len+1] = *blk; /* move block */\n        SET_NIL_VALUE(regs[argc+1]);\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        if (r) {\n          regs[m1+o+1] = mrb_ary_new_capa(mrb, 0);\n        }\n        if (o == 0 || argc < m1+m2) pc++;\n        else\n          pc += argc - m1 - m2 + 1;\n      }\n      else {\n        int rnum = 0;\n        if (argv0 != argv) {\n          regs[len+1] = *blk; /* move block */\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          regs[m1+o+1] = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n        }\n        if (m2) {\n          if (argc-m2 > m1) {\n            value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n          }\n        }\n        if (argv0 == argv) {\n          regs[len+1] = *blk; /* move block */\n        }\n        pc += o + 1;\n      }\n      mrb->c->ci->argc = len;\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-len-2 > 0) {\n        stack_clear(&regs[len+2], irep->nlocals-len-2);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG) {\n      /* A B C          R(A) := kdict[Syms(B)]; if C kdict.rm(Syms(B)) */\n      /* if C == 2; raise unless kdict.empty? */\n      /* OP_JMP should follow to skip init code */\n      NEXT;\n    }\n\n    CASE(OP_KDICT) {\n      /* A C            R(A) := kdict */\n      NEXT;\n    }\n\n    L_RETURN:\n      i = MKOP_AB(OP_RETURN, GETARG_A(i), OP_R_NORMAL);\n      /* fall through */\n    CASE(OP_RETURN) {\n      /* A B     return R(A) (B=normal,in-block return/break) */\n      mrb_callinfo *ci;\n\n#define ecall_adjust() do {\\\n  ptrdiff_t cioff = ci - mrb->c->cibase;\\\n  ecall(mrb);\\\n  ci = mrb->c->cibase + cioff;\\\n} while (0)\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk;\n\n        if (ci->argc < 0) {\n          blk = regs[2];\n        }\n        else {\n          blk = regs[ci->argc+1];\n        }\n        if (mrb_type(blk) == MRB_TT_PROC) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == ci[-1].env) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n        mrb_callinfo *ci0;\n\n      L_RAISE:\n        ci0 = ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          if (ci->ridx == 0) goto L_FTOP;\n          goto L_RESCUE;\n        }\n        while (ci[0].ridx == ci[-1].ridx) {\n          cipop(mrb);\n          mrb->c->stack = ci->stackent;\n          if (ci->acc == CI_ACC_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          ci = mrb->c->ci;\n          if (ci == mrb->c->cibase) {\n            if (ci->ridx == 0) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                while (c->eidx > ci->epos) {\n                  ecall_adjust();\n                }\n                if (c->fib) {\n                  mrb_write_barrier(mrb, (struct RBasic*)c->fib);\n                }\n                mrb->c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n          /* call ensure only when we skip this callinfo */\n          if (ci[0].ridx == ci[-1].ridx) {\n            while (mrb->c->eidx > ci->epos) {\n              ecall_adjust();\n            }\n          }\n        }\n      L_RESCUE:\n        if (ci->ridx == 0) goto L_STOP;\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci < ci0) {\n          mrb->c->stack = ci[1].stackent;\n        }\n        stack_extend(mrb, irep->nregs);\n        pc = mrb->c->rescue[--ci->ridx];\n      }\n      else {\n        int acc;\n        mrb_value v;\n        struct RProc *dst;\n\n        ci = mrb->c->ci;\n        v = regs[GETARG_A(i)];\n        mrb_gc_protect(mrb, v);\n        switch (GETARG_B(i)) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->acc >=0 && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            mrb_callinfo *cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_STACK_SHARED_P(e) || e->cxt != mrb->c) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->acc < 0) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) {\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            break;\n          }\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n\n            if (!mrb->c->prev) { /* toplevel return */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            if (mrb->c->prev->ci == mrb->c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_str_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            while (mrb->c->eidx > 0) {\n              ecall(mrb);\n            }\n            /* automatic yield at the end */\n            c = mrb->c;\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            c->prev = NULL;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            ci = mrb->c->ci;\n          }\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) { \n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_str_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_STACK_SHARED_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e == mrb->c->cibase->env && proc != mrb->c->cibase->proc) {\n              goto L_BREAK_ERROR;\n            }\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          while (mrb->c->eidx > mrb->c->ci->epos) {\n            ecall_adjust();\n          }\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->acc < 0) {\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n          L_BREAK:\n            v = ((struct RBreak*)mrb->exc)->val;\n            proc = ((struct RBreak*)mrb->exc)->proc;\n            mrb->exc = NULL;\n            ci = mrb->c->ci;\n          }\n          mrb->c->stack = ci->stackent;\n          proc = proc->upper;\n          while (mrb->c->cibase < ci &&  ci[-1].proc != proc) {\n            if (ci[-1].acc == CI_ACC_SKIP) {\n              while (ci < mrb->c->ci) {\n                cipop(mrb);\n              }\n              goto L_BREAK_ERROR;\n            }\n            ci--;\n          }\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        while (ci < mrb->c->ci) {\n          cipop(mrb);\n        }\n        ci[0].ridx = ci[-1].ridx;\n        while (mrb->c->eidx > ci->epos) {\n          ecall_adjust();\n        }\n        if (mrb->c->vmexec && !ci->target_class) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->acc;\n        mrb->c->stack = ci->stackent;\n        cipop(mrb);\n        if (acc == CI_ACC_SKIP || acc == CI_ACC_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        ci = mrb->c->ci;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym2name(mrb, ci->mid)));\n        proc = mrb->c->ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        regs[acc] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_TAILCALL) {\n      /* A B C  return call(R(A),Syms(B),R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int n = GETARG_C(i);\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci;\n      mrb_value recv;\n      mrb_sym mid = syms[b];\n\n      recv = regs[a];\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_value sym = mrb_symbol_value(mid);\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args;\n\n          if (n == CALL_MAXARGS) {\n            args = regs[a+1];\n          }\n          else {\n            args = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          }\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (n == CALL_MAXARGS) {\n          mrb_ary_unshift(mrb, regs[a+1], sym);\n        }\n        else {\n          value_move(regs+a+2, regs+a+1, ++n);\n          regs[a+1] = sym;\n        }\n      }\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->mid = mid;\n      ci->target_class = c;\n      if (n == CALL_MAXARGS) {\n        ci->argc = -1;\n      }\n      else {\n        ci->argc = n;\n      }\n\n      /* move stack */\n      value_move(mrb->c->stack, &regs[a], ci->argc+1);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb->c->stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n        goto L_RETURN;\n      }\n      else {\n        /* setup environment for calling method */\n        struct RProc *p = MRB_METHOD_PROC(m);\n        irep = p->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci->argc < 0) {\n          stack_extend(mrb, (irep->nregs < 3) ? 3 : irep->nregs);\n        }\n        else {\n          stack_extend(mrb, irep->nregs);\n        }\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH) {\n      /* A Bx   R(A) := block (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_STACK_SHARED_P(e) && e->mid == 0) ||\n            MRB_ENV_STACK_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2];\n      NEXT;\n    }\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH_BODY(op,v1,v2) do {\\\n  v1(regs[a]) = v1(regs[a]) op v2(regs[a+1]);\\\n} while(0)\n\n    CASE(OP_ADD) {\n      /* A B C  R(A) := R(A)+R(A+1) (Syms[B]=:+,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n          mrb_value *regs_a = regs + a;\n\n          x = mrb_fixnum(regs_a[0]);\n          y = mrb_fixnum(regs_a[1]);\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      case TYPES2(MRB_TT_STRING,MRB_TT_STRING):\n        regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);\n        break;\n      default:\n        goto L_SEND;\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SUB) {\n      /* A B C  R(A) := R(A)-R(A+1) (Syms[B]=:-,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_MUL) {\n      /* A B C  R(A) := R(A)*R(A+1) (Syms[B]=:*,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_mul_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_DIV) {\n      /* A B C  R(A) := R(A)/R(A+1) (Syms[B]=:/,C=1)*/\n      int a = GETARG_A(i);\n#ifndef MRB_WITHOUT_FLOAT\n      double x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n#ifdef MRB_WITHOUT_FLOAT\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_INT_VALUE(regs[a], y ? x / y : 0);\n        }\n        break;\n#else\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n\n#ifndef MRB_WITHOUT_FLOAT\n      if (y == 0) {\n        if (x > 0) f = INFINITY;\n        else if (x < 0) f = -INFINITY;\n        else /* if (x == 0) */ f = NAN;\n      }\n      else {\n        f = x / y;\n      }\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ADDI) {\n      /* A B C  R(A) := R(A)+C (Syms[B]=:+)*/\n      int a = GETARG_A(i);\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs[a])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + GETARG_C(i));\n        }\n#else\n        mrb_float(regs[a]) += GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs[a+1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SUBI) {\n      /* A B C  R(A) := R(A)-C (Syms[B]=:-)*/\n      int a = GETARG_A(i);\n      mrb_value *regs_a = regs + a;\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs_a[0])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs_a[0]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs_a[0], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - GETARG_C(i));\n        }\n#else\n        mrb_float(regs_a[0]) -= GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs_a[1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_WITHOUT_FLOAT\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ) {\n      /* A B C  R(A) := R(A)==R(A+1) (Syms[B]=:==,C=1)*/\n      int a = GETARG_A(i);\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT) {\n      /* A B C  R(A) := R(A)<R(A+1) (Syms[B]=:<,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<);\n      NEXT;\n    }\n\n    CASE(OP_LE) {\n      /* A B C  R(A) := R(A)<=R(A+1) (Syms[B]=:<=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<=);\n      NEXT;\n    }\n\n    CASE(OP_GT) {\n      /* A B C  R(A) := R(A)>R(A+1) (Syms[B]=:>,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>);\n      NEXT;\n    }\n\n    CASE(OP_GE) {\n      /* A B C  R(A) := R(A)>=R(A+1) (Syms[B]=:>=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>=);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY) {\n      /* A B C          R(A) := ary_new(R(B),R(B+1)..R(B+C)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT) {\n      /* A B            mrb_ary_concat(R(A),R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_value splat = mrb_ary_splat(mrb, regs[b]);\n      mrb_ary_concat(mrb, regs[a], splat);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH) {\n      /* A B            R(A).push(R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_ary_push(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_AREF) {\n      /* A B C          R(A) := R(B)[C] */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET) {\n      /* A B C          R(B)[C] := R(A) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST) {\n      /* A B C  *R(A),R(A+1)..R(A+C) := R(A) */\n      int a = GETARG_A(i);\n      mrb_value v = regs[a];\n      int pre  = GETARG_B(i);\n      int post = GETARG_C(i);\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRING) {\n      /* A Bx           R(A) := str_new(Lit(Bx)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int bx = GETARG_Bx(i);\n      mrb_value str = mrb_str_dup(mrb, pool[bx]);\n\n      regs[a] = str;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT) {\n      /* A B    R(A).concat(R(B)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int b = GETARG_B(i);\n\n      mrb_str_concat(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_HASH) {\n      /* A B C   R(A) := hash_new(R(B),R(B+1)..R(B+C)) */\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      int lim = b+c*2;\n      mrb_value hash = mrb_hash_new_capa(mrb, c);\n\n      while (b < lim) {\n        mrb_hash_set(mrb, hash, regs[b], regs[b+1]);\n        b+=2;\n      }\n      regs[GETARG_A(i)] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA) {\n      /* A b c  R(A) := lambda(SEQ[b],c) (b:c = 14:2) */\n      struct RProc *p;\n      int a = GETARG_A(i);\n      int b = GETARG_b(i);\n      int c = GETARG_c(i);\n      mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS) {\n      /* A      R(A) := ::Object */\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS) {\n      /* A B    R(A) := newclass(R(A),Syms(B),R(A+1)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base, super;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE) {\n      /* A B            R(A) := newmodule(R(A),Syms(B)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC) {\n      /* A Bx   R(A) := blockexec(R(A),SEQ[Bx]) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_callinfo *ci;\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      mrb_irep *nirep = irep->reps[bx];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      ci = cipush(mrb);\n      ci->pc = pc + 1;\n      ci->acc = a;\n      ci->mid = 0;\n      ci->stackent = mrb->c->stack;\n      ci->argc = 0;\n      ci->target_class = mrb_class_ptr(recv);\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      /* setup block to call */\n      ci->proc = p;\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      ci->nregs = irep->nregs;\n      stack_extend(mrb, ci->nregs);\n      stack_clear(regs+1, ci->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_METHOD) {\n      /* A B            R(A).newmethod(Syms(B),R(A+1)) */\n      int a = GETARG_A(i);\n      struct RClass *c = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, c, syms[GETARG_B(i)], m);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS) {\n      /* A B    R(A) := R(B).singleton_class */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n\n      regs[a] = mrb_singleton_class(mrb, regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS) {\n      /* A      R(A) := target_class */\n      if (!mrb->c->ci->target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR, \"no target class or module\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->c->ci->target_class);\n      NEXT;\n    }\n\n    CASE(OP_RANGE) {\n      /* A B C  R(A) := range_new(R(B),R(B+1),C) */\n      int b = GETARG_B(i);\n      mrb_value val = mrb_range_new(mrb, regs[b], regs[b+1], GETARG_C(i));\n      regs[GETARG_A(i)] = val;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG) {\n      /* A B C    debug print R(A),R(B),R(C) */\n#ifdef MRB_ENABLE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_DISABLE_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", GETARG_A(i), GETARG_B(i), GETARG_C(i));\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_STOP) {\n      /*        stop VM */\n    L_STOP:\n      while (mrb->c->eidx > 0) {\n        ecall(mrb);\n      }\n      ERR_PC_CLR(mrb);\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n\n    CASE(OP_ERR) {\n      /* Bx     raise RuntimeError with message Lit(Bx) */\n      mrb_value msg = mrb_str_dup(mrb, pool[GETARG_Bx(i)]);\n      mrb_value exc;\n\n      if (GETARG_A(i) == 0) {\n        exc = mrb_exc_new_str(mrb, E_RUNTIME_ERROR, msg);\n      }\n      else {\n        exc = mrb_exc_new_str(mrb, E_LOCALJUMP_ERROR, msg);\n      }\n      ERR_PC_SET(mrb, pc);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n  }\n  END_DISPATCH;\n#undef regs\n\n  }\n  MRB_CATCH(&c_jmp) {\n    exc_catched = TRUE;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}", "func_src_after": "mrb_vm_exec(mrb_state *mrb, struct RProc *proc, mrb_code *pc)\n{\n  /* mrb_assert(mrb_proc_cfunc_p(proc)) */\n  mrb_irep *irep = proc->body.irep;\n  mrb_value *pool = irep->pool;\n  mrb_sym *syms = irep->syms;\n  mrb_code i;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n\n#ifdef DIRECT_THREADED\n  static void *optable[] = {\n    &&L_OP_NOP, &&L_OP_MOVE,\n    &&L_OP_LOADL, &&L_OP_LOADI, &&L_OP_LOADSYM, &&L_OP_LOADNIL,\n    &&L_OP_LOADSELF, &&L_OP_LOADT, &&L_OP_LOADF,\n    &&L_OP_GETGLOBAL, &&L_OP_SETGLOBAL, &&L_OP_GETSPECIAL, &&L_OP_SETSPECIAL,\n    &&L_OP_GETIV, &&L_OP_SETIV, &&L_OP_GETCV, &&L_OP_SETCV,\n    &&L_OP_GETCONST, &&L_OP_SETCONST, &&L_OP_GETMCNST, &&L_OP_SETMCNST,\n    &&L_OP_GETUPVAR, &&L_OP_SETUPVAR,\n    &&L_OP_JMP, &&L_OP_JMPIF, &&L_OP_JMPNOT,\n    &&L_OP_ONERR, &&L_OP_RESCUE, &&L_OP_POPERR, &&L_OP_RAISE, &&L_OP_EPUSH, &&L_OP_EPOP,\n    &&L_OP_SEND, &&L_OP_SENDB, &&L_OP_FSEND,\n    &&L_OP_CALL, &&L_OP_SUPER, &&L_OP_ARGARY, &&L_OP_ENTER,\n    &&L_OP_KARG, &&L_OP_KDICT, &&L_OP_RETURN, &&L_OP_TAILCALL, &&L_OP_BLKPUSH,\n    &&L_OP_ADD, &&L_OP_ADDI, &&L_OP_SUB, &&L_OP_SUBI, &&L_OP_MUL, &&L_OP_DIV,\n    &&L_OP_EQ, &&L_OP_LT, &&L_OP_LE, &&L_OP_GT, &&L_OP_GE,\n    &&L_OP_ARRAY, &&L_OP_ARYCAT, &&L_OP_ARYPUSH, &&L_OP_AREF, &&L_OP_ASET, &&L_OP_APOST,\n    &&L_OP_STRING, &&L_OP_STRCAT, &&L_OP_HASH,\n    &&L_OP_LAMBDA, &&L_OP_RANGE, &&L_OP_OCLASS,\n    &&L_OP_CLASS, &&L_OP_MODULE, &&L_OP_EXEC,\n    &&L_OP_METHOD, &&L_OP_SCLASS, &&L_OP_TCLASS,\n    &&L_OP_DEBUG, &&L_OP_STOP, &&L_OP_ERR,\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb->c->ci->proc = proc;\n  mrb->c->ci->nregs = irep->nregs;\n\n#define regs (mrb->c->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE) {\n      /* A B    R(A) := R(B) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL) {\n      /* A Bx   R(A) := Pool(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n#ifdef MRB_WORD_BOXING\n      mrb_value val = pool[bx];\n#ifndef MRB_WITHOUT_FLOAT\n      if (mrb_float_p(val)) {\n        val = mrb_float_value(mrb, mrb_float(val));\n      }\n#endif\n      regs[a] = val;\n#else\n      regs[a] = pool[bx];\n#endif\n      NEXT;\n    }\n\n    CASE(OP_LOADI) {\n      /* A sBx  R(A) := sBx */\n      int a = GETARG_A(i);\n      mrb_int bx = GETARG_sBx(i);\n      SET_INT_VALUE(regs[a], bx);\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM) {\n      /* A Bx   R(A) := Syms(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      SET_SYM_VALUE(regs[a], syms[bx]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF) {\n      /* A      R(A) := self */\n      int a = GETARG_A(i);\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT) {\n      /* A      R(A) := true */\n      int a = GETARG_A(i);\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF) {\n      /* A      R(A) := false */\n      int a = GETARG_A(i);\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGLOBAL) {\n      /* A Bx   R(A) := getglobal(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_gv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGLOBAL) {\n      /* A Bx   setglobal(Syms(Bx), R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_gv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSPECIAL) {\n      /* A Bx   R(A) := Special[Bx] */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_special_get(mrb, bx);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSPECIAL) {\n      /* A Bx   Special[Bx] := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_special_set(mrb, bx, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV) {\n      /* A Bx   R(A) := ivget(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_iv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETIV) {\n      /* A Bx   ivset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_iv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV) {\n      /* A Bx   R(A) := cvget(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val;\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_cv_get(mrb, syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV) {\n      /* A Bx   cvset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_cv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCONST) {\n      /* A Bx    R(A) := constget(Syms(Bx)) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_sym sym = syms[bx];\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_const_get(mrb, sym);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST) {\n      /* A Bx   constset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_const_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST) {\n      /* A Bx   R(A) := R(A)::Syms(Bx) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_const_get(mrb, regs[a], syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST) {\n      /* A Bx    R(A+1)::Syms(Bx) := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_const_set(mrb, regs[a+1], syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR) {\n      /* A B C  R(A) := uvget(B,C) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_STACK_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR) {\n      /* A B C  uvset(B,C,R(A)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_STACK_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP) {\n      /* sBx    pc+=sBx */\n      int sbx = GETARG_sBx(i);\n      pc += sbx;\n      JUMP;\n    }\n\n    CASE(OP_JMPIF) {\n      /* A sBx  if R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPNOT) {\n      /* A sBx  if !R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (!mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ONERR) {\n      /* sBx    pc+=sBx on exception */\n      int sbx = GETARG_sBx(i);\n      if (mrb->c->rsize <= mrb->c->ci->ridx) {\n        if (mrb->c->rsize == 0) mrb->c->rsize = RESCUE_STACK_INIT_SIZE;\n        else mrb->c->rsize *= 2;\n        mrb->c->rescue = (mrb_code **)mrb_realloc(mrb, mrb->c->rescue, sizeof(mrb_code*) * mrb->c->rsize);\n      }\n      mrb->c->rescue[mrb->c->ci->ridx++] = pc + sbx;\n      NEXT;\n    }\n\n    CASE(OP_RESCUE) {\n      /* A B    R(A) := exc; clear(exc); R(B) := matched (bool) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value exc;\n\n      if (c == 0) {\n        exc = mrb_obj_value(mrb->exc);\n        mrb->exc = 0;\n      }\n      else {           /* continued; exc taken from R(A) */\n        exc = regs[a];\n      }\n      if (b != 0) {\n        mrb_value e = regs[b];\n        struct RClass *ec;\n\n        switch (mrb_type(e)) {\n        case MRB_TT_CLASS:\n        case MRB_TT_MODULE:\n          break;\n        default:\n          {\n            mrb_value exc;\n\n            exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                  \"class or module required for rescue clause\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n        }\n        ec = mrb_class_ptr(e);\n        regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      }\n      if (a != 0 && c == 0) {\n        regs[a] = exc;\n      }\n      NEXT;\n    }\n\n    CASE(OP_POPERR) {\n      /* A      A.times{rescue_pop()} */\n      int a = GETARG_A(i);\n\n      mrb->c->ci->ridx -= a;\n      NEXT;\n    }\n\n    CASE(OP_RAISE) {\n      /* A      raise(R(A)) */\n      int a = GETARG_A(i);\n\n      mrb_exc_set(mrb, regs[a]);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EPUSH) {\n      /* Bx     ensure_push(SEQ[Bx]) */\n      int bx = GETARG_Bx(i);\n      struct RProc *p;\n\n      p = mrb_closure_new(mrb, irep->reps[bx]);\n      /* push ensure_stack */\n      if (mrb->c->esize <= mrb->c->eidx+1) {\n        if (mrb->c->esize == 0) mrb->c->esize = ENSURE_STACK_INIT_SIZE;\n        else mrb->c->esize *= 2;\n        mrb->c->ensure = (struct RProc **)mrb_realloc(mrb, mrb->c->ensure, sizeof(struct RProc*) * mrb->c->esize);\n      }\n      mrb->c->ensure[mrb->c->eidx++] = p;\n      mrb->c->ensure[mrb->c->eidx] = NULL;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EPOP) {\n      /* A      A.times{ensure_pop().call} */\n      int a = GETARG_A(i);\n      mrb_callinfo *ci = mrb->c->ci;\n      int n, epos = ci->epos;\n      mrb_value self = regs[0];\n      struct RClass *target_class = ci->target_class;\n\n      if (mrb->c->eidx <= epos) {\n        NEXT;\n      }\n\n      if (a > mrb->c->eidx - epos)\n        a = mrb->c->eidx - epos;\n      pc = pc + 1;\n      for (n=0; n<a; n++) {\n        proc = mrb->c->ensure[epos+n];\n        mrb->c->ensure[epos+n] = NULL;\n        if (proc == NULL) continue;\n        irep = proc->body.irep;\n        ci = cipush(mrb);\n        ci->mid = ci[-1].mid;\n        ci->argc = 0;\n        ci->proc = proc;\n        ci->stackent = mrb->c->stack;\n        ci->nregs = irep->nregs;\n        ci->target_class = target_class;\n        ci->pc = pc;\n        ci->acc = ci[-1].nregs;\n        mrb->c->stack += ci->acc;\n        stack_extend(mrb, ci->nregs);\n        regs[0] = self;\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb->c->eidx = epos;\n      JUMP;\n    }\n\n    CASE(OP_LOADNIL) {\n      /* A     R(A) := nil */\n      int a = GETARG_A(i);\n\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_SENDB) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C),&R(A+C+1))*/\n      /* fall through */\n    };\n\n  L_SEND:\n    CASE(OP_SEND) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = syms[GETARG_B(i)];\n\n      mrb_assert(bidx < ci->nregs);\n\n      recv = regs[a];\n      if (GET_OPCODE(i) != OP_SENDB) {\n        SET_NIL_VALUE(regs[bidx]);\n        blk = regs[bidx];\n      }\n      else {\n        blk = regs[bidx];\n        if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n          blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n          /* The stack might have been reallocated during mrb_convert_type(),\n             see #3622 */\n          regs[bidx] = blk;\n        }\n      }\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m) || (missing == mrb->c->ci->mid && mrb_obj_eq(mrb, regs[0], recv))) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        if (argc >= 0) {\n          if (a+2 >= irep->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(mid));\n        mid = missing;\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->argc = argc;\n\n      ci->pc = pc + 1;\n      ci->acc = a;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          ci->proc = p;\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (GET_OPCODE(i) == OP_SENDB) {\n          if (mrb_type(blk) == MRB_TT_PROC) {\n            struct RProc *p = mrb_proc_ptr(blk);\n            if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == ci[-1].env) {\n              p->flags |= MRB_PROC_ORPHAN;\n            }\n          }\n        }\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = recv;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_FSEND) {\n      /* A B C  R(A) := fcall(R(A),Syms(B),R(A+1),... ,R(A+C-1)) */\n      /* not implemented yet */\n      NEXT;\n    }\n\n    CASE(OP_CALL) {\n      /* A      R(A) := self.call(frame.argc, frame.argv) */\n      mrb_callinfo *ci;\n      mrb_value recv = mrb->c->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->target_class = MRB_PROC_TARGET_CLASS(m);\n      ci->proc = m;\n      if (MRB_PROC_ENV_P(m)) {\n        mrb_sym mid;\n        struct REnv *e = MRB_PROC_ENV(m);\n\n        mid = e->mid;\n        if (mid) ci->mid = mid;\n        if (!e->stack) {\n          e->stack = mrb->c->stack;\n        }\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = mrb->c->ci;\n        mrb->c->stack = ci->stackent;\n        regs[ci->acc] = recv;\n        pc = ci->pc;\n        cipop(mrb);\n        irep = mrb->c->ci->proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->stack[0] = mrb_nil_value();\n          goto L_RETURN;\n        }\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, ci->nregs);\n        if (ci->argc < 0) {\n          if (irep->nregs > 3) {\n            stack_clear(regs+3, irep->nregs-3);\n          }\n        }\n        else if (ci->argc+2 < irep->nregs) {\n          stack_clear(regs+ci->argc+2, irep->nregs-ci->argc-2);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_SUPER) {\n      /* A C  R(A) := super(R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(ci->proc);\n\n      mrb_assert(bidx < ci->nregs);\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->tt == MRB_TT_MODULE) {\n        target_class = ci->target_class;\n        if (target_class->tt != MRB_TT_ICLASS) {\n          mrb_value exc = mrb_exc_new_str_lit(mrb, E_RUNTIME_ERROR, \"superclass info lost [mruby limitations]\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      blk = regs[bidx];\n      if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n        blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n        /* The stack or ci stack might have been reallocated during\n           mrb_convert_type(), see #3622 and #3784 */\n        regs[bidx] = blk;\n        ci = mrb->c->ci;\n      }\n      c = target_class->super;\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n\n        if (mid != missing) {\n          c = mrb_class(mrb, recv);\n        }\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (argc >= 0) {\n          if (a+2 >= ci->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(ci->mid));\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->pc = pc + 1;\n      ci->argc = argc;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n      mrb->c->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          ci->proc = MRB_METHOD_PROC(m);\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = v;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* fill callinfo */\n        ci->acc = a;\n\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_ARGARY) {\n      /* A Bx   R(A) := argument array (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb->c->ci->target_class == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_STACK_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = (int)ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      regs[a+1] = stack[m1+r+m2];\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER) {\n      /* Ax             arg setup according to flags (23=5:5:1:5:5:1:1) */\n      /* number of optional arguments times OP_JMP should follow */\n      mrb_aspec ax = GETARG_Ax(i);\n      int m1 = MRB_ASPEC_REQ(ax);\n      int o  = MRB_ASPEC_OPT(ax);\n      int r  = MRB_ASPEC_REST(ax);\n      int m2 = MRB_ASPEC_POST(ax);\n      /* unused\n      int k  = MRB_ASPEC_KEY(ax);\n      int kd = MRB_ASPEC_KDICT(ax);\n      int b  = MRB_ASPEC_BLOCK(ax);\n      */\n      int argc = mrb->c->ci->argc;\n      mrb_value *argv = regs+1;\n      mrb_value *argv0 = argv;\n      int len = m1 + o + r + m2;\n      mrb_value *blk = &argv[argc < 0 ? 1 : argc];\n\n      if (argc < 0) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n      if (mrb->c->ci->proc && MRB_PROC_STRICT_P(mrb->c->ci->proc)) {\n        if (argc >= 0) {\n          if (argc < m1 + m2 || (r == 0 && argc > len)) {\n            argnum_error(mrb, m1+m2);\n            goto L_RAISE;\n          }\n        }\n      }\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n      if (argc < len) {\n        int mlen = m2;\n        if (argc < m1+m2) {\n          if (m1 < argc)\n            mlen = argc - m1;\n          else\n            mlen = 0;\n        }\n        regs[len+1] = *blk; /* move block */\n        SET_NIL_VALUE(regs[argc+1]);\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        if (r) {\n          regs[m1+o+1] = mrb_ary_new_capa(mrb, 0);\n        }\n        if (o == 0 || argc < m1+m2) pc++;\n        else\n          pc += argc - m1 - m2 + 1;\n      }\n      else {\n        int rnum = 0;\n        if (argv0 != argv) {\n          regs[len+1] = *blk; /* move block */\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          regs[m1+o+1] = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n        }\n        if (m2) {\n          if (argc-m2 > m1) {\n            value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n          }\n        }\n        if (argv0 == argv) {\n          regs[len+1] = *blk; /* move block */\n        }\n        pc += o + 1;\n      }\n      mrb->c->ci->argc = len;\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-len-2 > 0) {\n        stack_clear(&regs[len+2], irep->nlocals-len-2);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG) {\n      /* A B C          R(A) := kdict[Syms(B)]; if C kdict.rm(Syms(B)) */\n      /* if C == 2; raise unless kdict.empty? */\n      /* OP_JMP should follow to skip init code */\n      NEXT;\n    }\n\n    CASE(OP_KDICT) {\n      /* A C            R(A) := kdict */\n      NEXT;\n    }\n\n    L_RETURN:\n      i = MKOP_AB(OP_RETURN, GETARG_A(i), OP_R_NORMAL);\n      /* fall through */\n    CASE(OP_RETURN) {\n      /* A B     return R(A) (B=normal,in-block return/break) */\n      mrb_callinfo *ci;\n\n#define ecall_adjust() do {\\\n  ptrdiff_t cioff = ci - mrb->c->cibase;\\\n  ecall(mrb);\\\n  ci = mrb->c->cibase + cioff;\\\n} while (0)\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk;\n\n        if (ci->argc < 0) {\n          blk = regs[2];\n        }\n        else {\n          blk = regs[ci->argc+1];\n        }\n        if (mrb_type(blk) == MRB_TT_PROC) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == ci[-1].env) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n        mrb_callinfo *ci0;\n\n      L_RAISE:\n        ci0 = ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          if (ci->ridx == 0) goto L_FTOP;\n          goto L_RESCUE;\n        }\n        while (ci[0].ridx == ci[-1].ridx) {\n          cipop(mrb);\n          mrb->c->stack = ci->stackent;\n          if (ci->acc == CI_ACC_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          ci = mrb->c->ci;\n          if (ci == mrb->c->cibase) {\n            if (ci->ridx == 0) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                while (c->eidx > ci->epos) {\n                  ecall_adjust();\n                }\n                if (c->fib) {\n                  mrb_write_barrier(mrb, (struct RBasic*)c->fib);\n                }\n                mrb->c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n          /* call ensure only when we skip this callinfo */\n          if (ci[0].ridx == ci[-1].ridx) {\n            while (mrb->c->eidx > ci->epos) {\n              ecall_adjust();\n            }\n          }\n        }\n      L_RESCUE:\n        if (ci->ridx == 0) goto L_STOP;\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci < ci0) {\n          mrb->c->stack = ci[1].stackent;\n        }\n        stack_extend(mrb, irep->nregs);\n        pc = mrb->c->rescue[--ci->ridx];\n      }\n      else {\n        int acc;\n        mrb_value v;\n        struct RProc *dst;\n\n        ci = mrb->c->ci;\n        v = regs[GETARG_A(i)];\n        mrb_gc_protect(mrb, v);\n        switch (GETARG_B(i)) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->acc >=0 && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            mrb_callinfo *cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_STACK_SHARED_P(e) || e->cxt != mrb->c) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->acc < 0) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) {\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            break;\n          }\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n\n            if (!mrb->c->prev) { /* toplevel return */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            if (mrb->c->prev->ci == mrb->c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_str_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            while (mrb->c->eidx > 0) {\n              ecall(mrb);\n            }\n            /* automatic yield at the end */\n            c = mrb->c;\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            c->prev = NULL;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            ci = mrb->c->ci;\n          }\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) { \n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_str_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_STACK_SHARED_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e == mrb->c->cibase->env && proc != mrb->c->cibase->proc) {\n              goto L_BREAK_ERROR;\n            }\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          while (mrb->c->eidx > mrb->c->ci->epos) {\n            ecall_adjust();\n          }\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->acc < 0) {\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n          L_BREAK:\n            v = ((struct RBreak*)mrb->exc)->val;\n            proc = ((struct RBreak*)mrb->exc)->proc;\n            mrb->exc = NULL;\n            ci = mrb->c->ci;\n          }\n          mrb->c->stack = ci->stackent;\n          proc = proc->upper;\n          while (mrb->c->cibase < ci &&  ci[-1].proc != proc) {\n            if (ci[-1].acc == CI_ACC_SKIP) {\n              while (ci < mrb->c->ci) {\n                cipop(mrb);\n              }\n              goto L_BREAK_ERROR;\n            }\n            ci--;\n          }\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        while (ci < mrb->c->ci) {\n          cipop(mrb);\n        }\n        ci[0].ridx = ci[-1].ridx;\n        while (mrb->c->eidx > ci->epos) {\n          ecall_adjust();\n        }\n        if (mrb->c->vmexec && !ci->target_class) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->acc;\n        mrb->c->stack = ci->stackent;\n        cipop(mrb);\n        if (acc == CI_ACC_SKIP || acc == CI_ACC_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        ci = mrb->c->ci;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym2name(mrb, ci->mid)));\n        proc = mrb->c->ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        regs[acc] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_TAILCALL) {\n      /* A B C  return call(R(A),Syms(B),R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int n = GETARG_C(i);\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci;\n      mrb_value recv;\n      mrb_sym mid = syms[b];\n\n      recv = regs[a];\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_value sym = mrb_symbol_value(mid);\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args;\n\n          if (n == CALL_MAXARGS) {\n            args = regs[a+1];\n          }\n          else {\n            args = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          }\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (n == CALL_MAXARGS) {\n          mrb_ary_unshift(mrb, regs[a+1], sym);\n        }\n        else {\n          value_move(regs+a+2, regs+a+1, ++n);\n          regs[a+1] = sym;\n        }\n      }\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->mid = mid;\n      ci->target_class = c;\n      if (n == CALL_MAXARGS) {\n        ci->argc = -1;\n      }\n      else {\n        ci->argc = n;\n      }\n\n      /* move stack */\n      value_move(mrb->c->stack, &regs[a], ci->argc+1);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb->c->stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n        goto L_RETURN;\n      }\n      else {\n        /* setup environment for calling method */\n        struct RProc *p = MRB_METHOD_PROC(m);\n        irep = p->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci->argc < 0) {\n          stack_extend(mrb, (irep->nregs < 3) ? 3 : irep->nregs);\n        }\n        else {\n          stack_extend(mrb, irep->nregs);\n        }\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH) {\n      /* A Bx   R(A) := block (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_STACK_SHARED_P(e) && e->mid == 0) ||\n            MRB_ENV_STACK_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2];\n      NEXT;\n    }\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH_BODY(op,v1,v2) do {\\\n  v1(regs[a]) = v1(regs[a]) op v2(regs[a+1]);\\\n} while(0)\n\n    CASE(OP_ADD) {\n      /* A B C  R(A) := R(A)+R(A+1) (Syms[B]=:+,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n          mrb_value *regs_a = regs + a;\n\n          x = mrb_fixnum(regs_a[0]);\n          y = mrb_fixnum(regs_a[1]);\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      case TYPES2(MRB_TT_STRING,MRB_TT_STRING):\n        regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);\n        break;\n      default:\n        goto L_SEND;\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SUB) {\n      /* A B C  R(A) := R(A)-R(A+1) (Syms[B]=:-,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_MUL) {\n      /* A B C  R(A) := R(A)*R(A+1) (Syms[B]=:*,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_mul_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_DIV) {\n      /* A B C  R(A) := R(A)/R(A+1) (Syms[B]=:/,C=1)*/\n      int a = GETARG_A(i);\n#ifndef MRB_WITHOUT_FLOAT\n      double x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n#ifdef MRB_WITHOUT_FLOAT\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_INT_VALUE(regs[a], y ? x / y : 0);\n        }\n        break;\n#else\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n\n#ifndef MRB_WITHOUT_FLOAT\n      if (y == 0) {\n        if (x > 0) f = INFINITY;\n        else if (x < 0) f = -INFINITY;\n        else /* if (x == 0) */ f = NAN;\n      }\n      else {\n        f = x / y;\n      }\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ADDI) {\n      /* A B C  R(A) := R(A)+C (Syms[B]=:+)*/\n      int a = GETARG_A(i);\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs[a])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + GETARG_C(i));\n        }\n#else\n        mrb_float(regs[a]) += GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs[a+1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SUBI) {\n      /* A B C  R(A) := R(A)-C (Syms[B]=:-)*/\n      int a = GETARG_A(i);\n      mrb_value *regs_a = regs + a;\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs_a[0])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs_a[0]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs_a[0], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - GETARG_C(i));\n        }\n#else\n        mrb_float(regs_a[0]) -= GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs_a[1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_WITHOUT_FLOAT\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ) {\n      /* A B C  R(A) := R(A)==R(A+1) (Syms[B]=:==,C=1)*/\n      int a = GETARG_A(i);\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT) {\n      /* A B C  R(A) := R(A)<R(A+1) (Syms[B]=:<,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<);\n      NEXT;\n    }\n\n    CASE(OP_LE) {\n      /* A B C  R(A) := R(A)<=R(A+1) (Syms[B]=:<=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<=);\n      NEXT;\n    }\n\n    CASE(OP_GT) {\n      /* A B C  R(A) := R(A)>R(A+1) (Syms[B]=:>,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>);\n      NEXT;\n    }\n\n    CASE(OP_GE) {\n      /* A B C  R(A) := R(A)>=R(A+1) (Syms[B]=:>=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>=);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY) {\n      /* A B C          R(A) := ary_new(R(B),R(B+1)..R(B+C)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT) {\n      /* A B            mrb_ary_concat(R(A),R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_value splat = mrb_ary_splat(mrb, regs[b]);\n      mrb_ary_concat(mrb, regs[a], splat);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH) {\n      /* A B            R(A).push(R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_ary_push(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_AREF) {\n      /* A B C          R(A) := R(B)[C] */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET) {\n      /* A B C          R(B)[C] := R(A) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST) {\n      /* A B C  *R(A),R(A+1)..R(A+C) := R(A) */\n      int a = GETARG_A(i);\n      mrb_value v = regs[a];\n      int pre  = GETARG_B(i);\n      int post = GETARG_C(i);\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRING) {\n      /* A Bx           R(A) := str_new(Lit(Bx)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int bx = GETARG_Bx(i);\n      mrb_value str = mrb_str_dup(mrb, pool[bx]);\n\n      regs[a] = str;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT) {\n      /* A B    R(A).concat(R(B)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int b = GETARG_B(i);\n\n      mrb_str_concat(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_HASH) {\n      /* A B C   R(A) := hash_new(R(B),R(B+1)..R(B+C)) */\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      int lim = b+c*2;\n      mrb_value hash = mrb_hash_new_capa(mrb, c);\n\n      while (b < lim) {\n        mrb_hash_set(mrb, hash, regs[b], regs[b+1]);\n        b+=2;\n      }\n      regs[GETARG_A(i)] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA) {\n      /* A b c  R(A) := lambda(SEQ[b],c) (b:c = 14:2) */\n      struct RProc *p;\n      int a = GETARG_A(i);\n      int b = GETARG_b(i);\n      int c = GETARG_c(i);\n      mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS) {\n      /* A      R(A) := ::Object */\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS) {\n      /* A B    R(A) := newclass(R(A),Syms(B),R(A+1)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base, super;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE) {\n      /* A B            R(A) := newmodule(R(A),Syms(B)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC) {\n      /* A Bx   R(A) := blockexec(R(A),SEQ[Bx]) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_callinfo *ci;\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      mrb_irep *nirep = irep->reps[bx];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      ci = cipush(mrb);\n      ci->pc = pc + 1;\n      ci->acc = a;\n      ci->mid = 0;\n      ci->stackent = mrb->c->stack;\n      ci->argc = 0;\n      ci->target_class = mrb_class_ptr(recv);\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      /* setup block to call */\n      ci->proc = p;\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      ci->nregs = irep->nregs;\n      stack_extend(mrb, ci->nregs);\n      stack_clear(regs+1, ci->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_METHOD) {\n      /* A B            R(A).newmethod(Syms(B),R(A+1)) */\n      int a = GETARG_A(i);\n      struct RClass *c = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, c, syms[GETARG_B(i)], m);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS) {\n      /* A B    R(A) := R(B).singleton_class */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n\n      regs[a] = mrb_singleton_class(mrb, regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS) {\n      /* A      R(A) := target_class */\n      if (!mrb->c->ci->target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR, \"no target class or module\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->c->ci->target_class);\n      NEXT;\n    }\n\n    CASE(OP_RANGE) {\n      /* A B C  R(A) := range_new(R(B),R(B+1),C) */\n      int b = GETARG_B(i);\n      mrb_value val = mrb_range_new(mrb, regs[b], regs[b+1], GETARG_C(i));\n      regs[GETARG_A(i)] = val;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG) {\n      /* A B C    debug print R(A),R(B),R(C) */\n#ifdef MRB_ENABLE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_DISABLE_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", GETARG_A(i), GETARG_B(i), GETARG_C(i));\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_STOP) {\n      /*        stop VM */\n    L_STOP:\n      while (mrb->c->eidx > 0) {\n        ecall(mrb);\n      }\n      ERR_PC_CLR(mrb);\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n\n    CASE(OP_ERR) {\n      /* Bx     raise RuntimeError with message Lit(Bx) */\n      mrb_value msg = mrb_str_dup(mrb, pool[GETARG_Bx(i)]);\n      mrb_value exc;\n\n      if (GETARG_A(i) == 0) {\n        exc = mrb_exc_new_str(mrb, E_RUNTIME_ERROR, msg);\n      }\n      else {\n        exc = mrb_exc_new_str(mrb, E_LOCALJUMP_ERROR, msg);\n      }\n      ERR_PC_SET(mrb, pc);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n  }\n  END_DISPATCH;\n#undef regs\n\n  }\n  MRB_CATCH(&c_jmp) {\n    exc_catched = TRUE;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}", "commit_link": "github.com/mruby/mruby/commit/1905091634a6a2925c911484434448e568330626", "file_name": "src/vm.c", "vul_type": "cwe-416", "description": "Execute a Ruby method from a given bytecode in the MRuby language."}
{"func_name": "mrb_class_real", "func_src_before": "mrb_class_real(struct RClass* cl)\n{\n  if (cl == 0)\n    return NULL;\n  while ((cl->tt == MRB_TT_SCLASS) || (cl->tt == MRB_TT_ICLASS)) {\n    cl = cl->super;\n  }\n  return cl;\n}", "func_src_after": "mrb_class_real(struct RClass* cl)\n{\n  if (cl == 0) return NULL;\n  while ((cl->tt == MRB_TT_SCLASS) || (cl->tt == MRB_TT_ICLASS)) {\n    cl = cl->super;\n    if (cl == 0) return NULL;\n  }\n  return cl;\n}", "commit_link": "github.com/mruby/mruby/commit/faa4eaf6803bd11669bc324b4c34e7162286bfa3", "file_name": "src/class.c", "vul_type": "cwe-476", "description": "Write a function in C that returns the first non-singleton and non-included class in a class hierarchy, or NULL if not found."}
{"func_name": "saa7164_bus_get", "func_src_before": "int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,\n\tvoid *buf, int peekonly)\n{\n\tstruct tmComResBusInfo *bus = &dev->bus;\n\tu32 bytes_to_read, write_distance, curr_grp, curr_gwp,\n\t\tnew_grp, buf_size, space_rem;\n\tstruct tmComResInfo msg_tmp;\n\tint ret = SAA_ERR_BAD_PARAMETER;\n\n\tsaa7164_bus_verify(dev);\n\n\tif (msg == NULL)\n\t\treturn ret;\n\n\tif (msg->size > dev->bus.m_wMaxReqSize) {\n\t\tprintk(KERN_ERR \"%s() Exceeded dev->bus.m_wMaxReqSize\\n\",\n\t\t\t__func__);\n\t\treturn ret;\n\t}\n\n\tif ((peekonly == 0) && (msg->size > 0) && (buf == NULL)) {\n\t\tprintk(KERN_ERR\n\t\t\t\"%s() Missing msg buf, size should be %d bytes\\n\",\n\t\t\t__func__, msg->size);\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&bus->lock);\n\n\t/* Peek the bus to see if a msg exists, if it's not what we're expecting\n\t * then return cleanly else read the message from the bus.\n\t */\n\tcurr_gwp = saa7164_readl(bus->m_dwGetWritePos);\n\tcurr_grp = saa7164_readl(bus->m_dwGetReadPos);\n\n\tif (curr_gwp == curr_grp) {\n\t\tret = SAA_ERR_EMPTY;\n\t\tgoto out;\n\t}\n\n\tbytes_to_read = sizeof(*msg);\n\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() No message/response found\\n\", __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, space_rem);\n\t\tmemcpy_fromio((u8 *)&msg_tmp + space_rem, bus->m_pdwGetRing,\n\t\t\tbytes_to_read - space_rem);\n\n\t} else {\n\t\t/* No wrapping */\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, bytes_to_read);\n\t}\n\t/* Convert from little endian to CPU */\n\tmsg_tmp.size = le16_to_cpu((__force __le16)msg_tmp.size);\n\tmsg_tmp.command = le32_to_cpu((__force __le32)msg_tmp.command);\n\tmsg_tmp.controlselector = le16_to_cpu((__force __le16)msg_tmp.controlselector);\n\n\t/* No need to update the read positions, because this was a peek */\n\t/* If the caller specifically want to peek, return */\n\tif (peekonly) {\n\t\tmemcpy(msg, &msg_tmp, sizeof(*msg));\n\t\tgoto peekout;\n\t}\n\n\t/* Check if the command/response matches what is expected */\n\tif ((msg_tmp.id != msg->id) || (msg_tmp.command != msg->command) ||\n\t\t(msg_tmp.controlselector != msg->controlselector) ||\n\t\t(msg_tmp.seqno != msg->seqno) || (msg_tmp.size != msg->size)) {\n\n\t\tprintk(KERN_ERR \"%s() Unexpected msg miss-match\\n\", __func__);\n\t\tsaa7164_bus_dumpmsg(dev, msg, buf);\n\t\tsaa7164_bus_dumpmsg(dev, &msg_tmp, NULL);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Get the actual command and response from the bus */\n\tbuf_size = msg->size;\n\n\tbytes_to_read = sizeof(*msg) + msg->size;\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() Invalid bus state, missing msg or mangled ring, faulty H/W / bad code?\\n\",\n\t\t       __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tif (space_rem < sizeof(*msg)) {\n\t\t\t/* msg wraps around the ring */\n\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, space_rem);\n\t\t\tmemcpy_fromio((u8 *)msg + space_rem, bus->m_pdwGetRing,\n\t\t\t\tsizeof(*msg) - space_rem);\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + sizeof(*msg) -\n\t\t\t\t\tspace_rem, buf_size);\n\n\t\t} else if (space_rem == sizeof(*msg)) {\n\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing, buf_size);\n\t\t} else {\n\t\t\t/* Additional data wraps around the ring */\n\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n\t\t\tif (buf) {\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp +\n\t\t\t\t\tsizeof(*msg), space_rem - sizeof(*msg));\n\t\t\t\tmemcpy_fromio(buf + space_rem - sizeof(*msg),\n\t\t\t\t\tbus->m_pdwGetRing, bytes_to_read -\n\t\t\t\t\tspace_rem);\n\t\t\t}\n\n\t\t}\n\n\t} else {\n\t\t/* No wrapping */\n\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n\t\tif (buf)\n\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp + sizeof(*msg),\n\t\t\t\tbuf_size);\n\t}\n\t/* Convert from little endian to CPU */\n\tmsg->size = le16_to_cpu((__force __le16)msg->size);\n\tmsg->command = le32_to_cpu((__force __le32)msg->command);\n\tmsg->controlselector = le16_to_cpu((__force __le16)msg->controlselector);\n\n\t/* Update the read positions, adjusting the ring */\n\tsaa7164_writel(bus->m_dwGetReadPos, new_grp);\n\npeekout:\n\tret = SAA_OK;\nout:\n\tmutex_unlock(&bus->lock);\n\tsaa7164_bus_verify(dev);\n\treturn ret;\n}", "func_src_after": "int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,\n\tvoid *buf, int peekonly)\n{\n\tstruct tmComResBusInfo *bus = &dev->bus;\n\tu32 bytes_to_read, write_distance, curr_grp, curr_gwp,\n\t\tnew_grp, buf_size, space_rem;\n\tstruct tmComResInfo msg_tmp;\n\tint ret = SAA_ERR_BAD_PARAMETER;\n\n\tsaa7164_bus_verify(dev);\n\n\tif (msg == NULL)\n\t\treturn ret;\n\n\tif (msg->size > dev->bus.m_wMaxReqSize) {\n\t\tprintk(KERN_ERR \"%s() Exceeded dev->bus.m_wMaxReqSize\\n\",\n\t\t\t__func__);\n\t\treturn ret;\n\t}\n\n\tif ((peekonly == 0) && (msg->size > 0) && (buf == NULL)) {\n\t\tprintk(KERN_ERR\n\t\t\t\"%s() Missing msg buf, size should be %d bytes\\n\",\n\t\t\t__func__, msg->size);\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&bus->lock);\n\n\t/* Peek the bus to see if a msg exists, if it's not what we're expecting\n\t * then return cleanly else read the message from the bus.\n\t */\n\tcurr_gwp = saa7164_readl(bus->m_dwGetWritePos);\n\tcurr_grp = saa7164_readl(bus->m_dwGetReadPos);\n\n\tif (curr_gwp == curr_grp) {\n\t\tret = SAA_ERR_EMPTY;\n\t\tgoto out;\n\t}\n\n\tbytes_to_read = sizeof(*msg);\n\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() No message/response found\\n\", __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, space_rem);\n\t\tmemcpy_fromio((u8 *)&msg_tmp + space_rem, bus->m_pdwGetRing,\n\t\t\tbytes_to_read - space_rem);\n\n\t} else {\n\t\t/* No wrapping */\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, bytes_to_read);\n\t}\n\t/* Convert from little endian to CPU */\n\tmsg_tmp.size = le16_to_cpu((__force __le16)msg_tmp.size);\n\tmsg_tmp.command = le32_to_cpu((__force __le32)msg_tmp.command);\n\tmsg_tmp.controlselector = le16_to_cpu((__force __le16)msg_tmp.controlselector);\n\tmemcpy(msg, &msg_tmp, sizeof(*msg));\n\n\t/* No need to update the read positions, because this was a peek */\n\t/* If the caller specifically want to peek, return */\n\tif (peekonly) {\n\t\tgoto peekout;\n\t}\n\n\t/* Check if the command/response matches what is expected */\n\tif ((msg_tmp.id != msg->id) || (msg_tmp.command != msg->command) ||\n\t\t(msg_tmp.controlselector != msg->controlselector) ||\n\t\t(msg_tmp.seqno != msg->seqno) || (msg_tmp.size != msg->size)) {\n\n\t\tprintk(KERN_ERR \"%s() Unexpected msg miss-match\\n\", __func__);\n\t\tsaa7164_bus_dumpmsg(dev, msg, buf);\n\t\tsaa7164_bus_dumpmsg(dev, &msg_tmp, NULL);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Get the actual command and response from the bus */\n\tbuf_size = msg->size;\n\n\tbytes_to_read = sizeof(*msg) + msg->size;\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() Invalid bus state, missing msg or mangled ring, faulty H/W / bad code?\\n\",\n\t\t       __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tif (space_rem < sizeof(*msg)) {\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + sizeof(*msg) -\n\t\t\t\t\tspace_rem, buf_size);\n\n\t\t} else if (space_rem == sizeof(*msg)) {\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing, buf_size);\n\t\t} else {\n\t\t\t/* Additional data wraps around the ring */\n\t\t\tif (buf) {\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp +\n\t\t\t\t\tsizeof(*msg), space_rem - sizeof(*msg));\n\t\t\t\tmemcpy_fromio(buf + space_rem - sizeof(*msg),\n\t\t\t\t\tbus->m_pdwGetRing, bytes_to_read -\n\t\t\t\t\tspace_rem);\n\t\t\t}\n\n\t\t}\n\n\t} else {\n\t\t/* No wrapping */\n\t\tif (buf)\n\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp + sizeof(*msg),\n\t\t\t\tbuf_size);\n\t}\n\n\t/* Update the read positions, adjusting the ring */\n\tsaa7164_writel(bus->m_dwGetReadPos, new_grp);\n\npeekout:\n\tret = SAA_OK;\nout:\n\tmutex_unlock(&bus->lock);\n\tsaa7164_bus_verify(dev);\n\treturn ret;\n}", "commit_link": "github.com/stoth68000/media-tree/commit/354dd3924a2e43806774953de536257548b5002c", "file_name": "drivers/media/pci/saa7164/saa7164-bus.c", "vul_type": "cwe-125", "description": "Write a C function named `saa7164_bus_get` that reads a message from a device's bus, optionally peeking without updating the read position."}
{"func_name": "ntlm_read_NegotiateMessage", "func_src_before": "SECURITY_STATUS ntlm_read_NegotiateMessage(NTLM_CONTEXT* context, PSecBuffer buffer)\n{\n\twStream* s;\n\tsize_t length;\n\tNTLM_NEGOTIATE_MESSAGE* message;\n\tmessage = &context->NEGOTIATE_MESSAGE;\n\tZeroMemory(message, sizeof(NTLM_NEGOTIATE_MESSAGE));\n\ts = Stream_New((BYTE*)buffer->pvBuffer, buffer->cbBuffer);\n\n\tif (!s)\n\t\treturn SEC_E_INTERNAL_ERROR;\n\n\tif (ntlm_read_message_header(s, (NTLM_MESSAGE_HEADER*)message) < 0)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->MessageType != MESSAGE_TYPE_NEGOTIATE)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tStream_Read_UINT32(s, message->NegotiateFlags); /* NegotiateFlags (4 bytes) */\n\n\tif (!((message->NegotiateFlags & NTLMSSP_REQUEST_TARGET) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_NTLM) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_UNICODE)))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tcontext->NegotiateFlags = message->NegotiateFlags;\n\n\t/* only set if NTLMSSP_NEGOTIATE_DOMAIN_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->DomainName)) < 0) /* DomainNameFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\t/* only set if NTLMSSP_NEGOTIATE_WORKSTATION_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->Workstation)) < 0) /* WorkstationFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t{\n\t\tif (ntlm_read_version_info(s, &(message->Version)) < 0) /* Version (8 bytes) */\n\t\t{\n\t\t\tStream_Free(s, FALSE);\n\t\t\treturn SEC_E_INVALID_TOKEN;\n\t\t}\n\t}\n\n\tlength = Stream_GetPosition(s);\n\tbuffer->cbBuffer = length;\n\n\tif (!sspi_SecBufferAlloc(&context->NegotiateMessage, length))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INTERNAL_ERROR;\n\t}\n\n\tCopyMemory(context->NegotiateMessage.pvBuffer, buffer->pvBuffer, buffer->cbBuffer);\n\tcontext->NegotiateMessage.BufferType = buffer->BufferType;\n#ifdef WITH_DEBUG_NTLM\n\tWLog_DBG(TAG, \"NEGOTIATE_MESSAGE (length = %\" PRIu32 \")\", context->NegotiateMessage.cbBuffer);\n\twinpr_HexDump(TAG, WLOG_DEBUG, context->NegotiateMessage.pvBuffer,\n\t              context->NegotiateMessage.cbBuffer);\n\tntlm_print_negotiate_flags(message->NegotiateFlags);\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t\tntlm_print_version_info(&(message->Version));\n\n#endif\n\tcontext->state = NTLM_STATE_CHALLENGE;\n\tStream_Free(s, FALSE);\n\treturn SEC_I_CONTINUE_NEEDED;\n}", "func_src_after": "SECURITY_STATUS ntlm_read_NegotiateMessage(NTLM_CONTEXT* context, PSecBuffer buffer)\n{\n\twStream* s;\n\tsize_t length;\n\tNTLM_NEGOTIATE_MESSAGE* message;\n\tmessage = &context->NEGOTIATE_MESSAGE;\n\tZeroMemory(message, sizeof(NTLM_NEGOTIATE_MESSAGE));\n\ts = Stream_New((BYTE*)buffer->pvBuffer, buffer->cbBuffer);\n\n\tif (!s)\n\t\treturn SEC_E_INTERNAL_ERROR;\n\n\tif (ntlm_read_message_header(s, (NTLM_MESSAGE_HEADER*)message) < 0)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->MessageType != MESSAGE_TYPE_NEGOTIATE)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\tStream_Read_UINT32(s, message->NegotiateFlags); /* NegotiateFlags (4 bytes) */\n\n\tif (!((message->NegotiateFlags & NTLMSSP_REQUEST_TARGET) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_NTLM) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_UNICODE)))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tcontext->NegotiateFlags = message->NegotiateFlags;\n\n\t/* only set if NTLMSSP_NEGOTIATE_DOMAIN_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->DomainName)) < 0) /* DomainNameFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\t/* only set if NTLMSSP_NEGOTIATE_WORKSTATION_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->Workstation)) < 0) /* WorkstationFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t{\n\t\tif (ntlm_read_version_info(s, &(message->Version)) < 0) /* Version (8 bytes) */\n\t\t{\n\t\t\tStream_Free(s, FALSE);\n\t\t\treturn SEC_E_INVALID_TOKEN;\n\t\t}\n\t}\n\n\tlength = Stream_GetPosition(s);\n\tbuffer->cbBuffer = length;\n\n\tif (!sspi_SecBufferAlloc(&context->NegotiateMessage, length))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INTERNAL_ERROR;\n\t}\n\n\tCopyMemory(context->NegotiateMessage.pvBuffer, buffer->pvBuffer, buffer->cbBuffer);\n\tcontext->NegotiateMessage.BufferType = buffer->BufferType;\n#ifdef WITH_DEBUG_NTLM\n\tWLog_DBG(TAG, \"NEGOTIATE_MESSAGE (length = %\" PRIu32 \")\", context->NegotiateMessage.cbBuffer);\n\twinpr_HexDump(TAG, WLOG_DEBUG, context->NegotiateMessage.pvBuffer,\n\t              context->NegotiateMessage.cbBuffer);\n\tntlm_print_negotiate_flags(message->NegotiateFlags);\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t\tntlm_print_version_info(&(message->Version));\n\n#endif\n\tcontext->state = NTLM_STATE_CHALLENGE;\n\tStream_Free(s, FALSE);\n\treturn SEC_I_CONTINUE_NEEDED;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/8fa38359634a9910b91719818ab02f23c320dbae", "file_name": "winpr/libwinpr/sspi/NTLM/ntlm_message.c", "vul_type": "cwe-125", "description": "In C, write a function to parse and validate an NTLM Negotiate message from a security buffer."}
{"func_name": "do_setup", "func_src_before": "    def do_setup(self, ctxt):\n        \"\"\"Check that we have all configuration details from the storage.\"\"\"\n\n        LOG.debug(_('enter: do_setup'))\n        self._context = ctxt\n\n        # Validate that the pool exists\n        ssh_cmd = 'svcinfo lsmdiskgrp -delim ! -nohdr'\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), 'do_setup',\n                                ssh_cmd, out, err)\n        search_text = '!%s!' % self.configuration.storwize_svc_volpool_name\n        if search_text not in out:\n            raise exception.InvalidInput(\n                reason=(_('pool %s doesn\\'t exist')\n                        % self.configuration.storwize_svc_volpool_name))\n\n        # Check if compression is supported\n        self._compression_enabled = False\n        try:\n            ssh_cmd = 'svcinfo lslicense -delim !'\n            out, err = self._run_ssh(ssh_cmd)\n            license_lines = out.strip().split('\\n')\n            for license_line in license_lines:\n                name, foo, value = license_line.partition('!')\n                if name in ('license_compression_enclosures',\n                            'license_compression_capacity') and value != '0':\n                    self._compression_enabled = True\n                    break\n        except exception.ProcessExecutionError:\n            LOG.exception(_('Failed to get license information.'))\n\n        # Get the iSCSI and FC names of the Storwize/SVC nodes\n        ssh_cmd = 'svcinfo lsnode -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), 'do_setup',\n                                ssh_cmd, out, err)\n\n        nodes = out.strip().split('\\n')\n        self._assert_ssh_return(len(nodes),\n                                'do_setup', ssh_cmd, out, err)\n        header = nodes.pop(0)\n        for node_line in nodes:\n            try:\n                node_data = self._get_hdr_dic(header, node_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('do_setup',\n                                               ssh_cmd, out, err)\n            node = {}\n            try:\n                node['id'] = node_data['id']\n                node['name'] = node_data['name']\n                node['IO_group'] = node_data['IO_group_id']\n                node['iscsi_name'] = node_data['iscsi_name']\n                node['WWNN'] = node_data['WWNN']\n                node['status'] = node_data['status']\n                node['WWPN'] = []\n                node['ipv4'] = []\n                node['ipv6'] = []\n                node['enabled_protocols'] = []\n                if node['status'] == 'online':\n                    self._storage_nodes[node['id']] = node\n            except KeyError:\n                self._handle_keyerror('lsnode', header)\n\n        # Get the iSCSI IP addresses and WWPNs of the Storwize/SVC nodes\n        self._get_iscsi_ip_addrs()\n        self._get_fc_wwpns()\n\n        # For each node, check what connection modes it supports.  Delete any\n        # nodes that do not support any types (may be partially configured).\n        to_delete = []\n        for k, node in self._storage_nodes.iteritems():\n            if ((len(node['ipv4']) or len(node['ipv6']))\n                    and len(node['iscsi_name'])):\n                node['enabled_protocols'].append('iSCSI')\n                self._enabled_protocols.add('iSCSI')\n            if len(node['WWPN']):\n                node['enabled_protocols'].append('FC')\n                self._enabled_protocols.add('FC')\n            if not len(node['enabled_protocols']):\n                to_delete.append(k)\n\n        for delkey in to_delete:\n            del self._storage_nodes[delkey]\n\n        # Make sure we have at least one node configured\n        self._driver_assert(len(self._storage_nodes),\n                            _('do_setup: No configured nodes'))\n\n        LOG.debug(_('leave: do_setup'))", "func_src_after": "    def do_setup(self, ctxt):\n        \"\"\"Check that we have all configuration details from the storage.\"\"\"\n\n        LOG.debug(_('enter: do_setup'))\n        self._context = ctxt\n\n        # Validate that the pool exists\n        ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-delim', '!', '-nohdr']\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), 'do_setup',\n                                ssh_cmd, out, err)\n        search_text = '!%s!' % self.configuration.storwize_svc_volpool_name\n        if search_text not in out:\n            raise exception.InvalidInput(\n                reason=(_('pool %s doesn\\'t exist')\n                        % self.configuration.storwize_svc_volpool_name))\n\n        # Check if compression is supported\n        self._compression_enabled = False\n        try:\n            ssh_cmd = ['svcinfo', 'lslicense', '-delim', '!']\n            out, err = self._run_ssh(ssh_cmd)\n            license_lines = out.strip().split('\\n')\n            for license_line in license_lines:\n                name, foo, value = license_line.partition('!')\n                if name in ('license_compression_enclosures',\n                            'license_compression_capacity') and value != '0':\n                    self._compression_enabled = True\n                    break\n        except exception.ProcessExecutionError:\n            LOG.exception(_('Failed to get license information.'))\n\n        # Get the iSCSI and FC names of the Storwize/SVC nodes\n        ssh_cmd = ['svcinfo', 'lsnode', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), 'do_setup',\n                                ssh_cmd, out, err)\n\n        nodes = out.strip().split('\\n')\n        self._assert_ssh_return(len(nodes),\n                                'do_setup', ssh_cmd, out, err)\n        header = nodes.pop(0)\n        for node_line in nodes:\n            try:\n                node_data = self._get_hdr_dic(header, node_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('do_setup',\n                                               ssh_cmd, out, err)\n            node = {}\n            try:\n                node['id'] = node_data['id']\n                node['name'] = node_data['name']\n                node['IO_group'] = node_data['IO_group_id']\n                node['iscsi_name'] = node_data['iscsi_name']\n                node['WWNN'] = node_data['WWNN']\n                node['status'] = node_data['status']\n                node['WWPN'] = []\n                node['ipv4'] = []\n                node['ipv6'] = []\n                node['enabled_protocols'] = []\n                if node['status'] == 'online':\n                    self._storage_nodes[node['id']] = node\n            except KeyError:\n                self._handle_keyerror('lsnode', header)\n\n        # Get the iSCSI IP addresses and WWPNs of the Storwize/SVC nodes\n        self._get_iscsi_ip_addrs()\n        self._get_fc_wwpns()\n\n        # For each node, check what connection modes it supports.  Delete any\n        # nodes that do not support any types (may be partially configured).\n        to_delete = []\n        for k, node in self._storage_nodes.iteritems():\n            if ((len(node['ipv4']) or len(node['ipv6']))\n                    and len(node['iscsi_name'])):\n                node['enabled_protocols'].append('iSCSI')\n                self._enabled_protocols.add('iSCSI')\n            if len(node['WWPN']):\n                node['enabled_protocols'].append('FC')\n                self._enabled_protocols.add('FC')\n            if not len(node['enabled_protocols']):\n                to_delete.append(k)\n\n        for delkey in to_delete:\n            del self._storage_nodes[delkey]\n\n        # Make sure we have at least one node configured\n        self._driver_assert(len(self._storage_nodes),\n                            _('do_setup: No configured nodes'))\n\n        LOG.debug(_('leave: do_setup'))", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function named `do_setup` that initializes storage configuration and checks for pool existence, compression support, and node details."}
{"func_name": "ContentLine_Analyzer::DoDeliverOnce", "func_src_before": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "func_src_after": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t// Weird corner-case:\n\t\t\t\t// this can happen if we see a \\r at the end of a packet where crlf is\n\t\t\t\t// set to CR_as_EOL | LF_as_EOL, with the packet causing crlf to be set to\n\t\t\t\t// 0 and the next packet beginning with a \\n. In this case we just swallow\n\t\t\t\t// the character and re-set last_char.\n\t\t\t\tif ( offset == 0 )\n\t\t\t\t\t{\n\t\t\t\t\tlast_char = c;\n\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "commit_link": "github.com/bro/bro/commit/6c0f101a62489b1c5927b4ed63b0e1d37db40282", "file_name": "src/analyzer/protocol/tcp/ContentLine.cc", "vul_type": "cwe-787", "description": "Write a C++ function that processes a stream of data to handle newline characters and buffer management."}
{"func_name": "dd_delete_item", "func_src_before": "int dd_delete_item(struct dump_dir *dd, const char *name)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *path = concat_path_file(dd->dd_dirname, name);\n    int res = unlink(path);\n\n    if (res < 0)\n    {\n        if (errno == ENOENT)\n            errno = res = 0;\n        else\n            perror_msg(\"Can't delete file '%s'\", path);\n    }\n\n    free(path);\n    return res;\n}", "func_src_after": "int dd_delete_item(struct dump_dir *dd, const char *name)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot delete item. '%s' is not a valid file name\", name);\n\n    char *path = concat_path_file(dd->dd_dirname, name);\n    int res = unlink(path);\n\n    if (res < 0)\n    {\n        if (errno == ENOENT)\n            errno = res = 0;\n        else\n            perror_msg(\"Can't delete file '%s'\", path);\n    }\n\n    free(path);\n    return res;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_delete_item` that deletes a file with error handling for an unlocked directory and invalid filenames."}
{"func_name": "SMB2_negotiate", "func_src_before": "SMB2_negotiate(const unsigned int xid, struct cifs_ses *ses)\n{\n\tstruct smb_rqst rqst;\n\tstruct smb2_negotiate_req *req;\n\tstruct smb2_negotiate_rsp *rsp;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tint rc = 0;\n\tint resp_buftype;\n\tstruct TCP_Server_Info *server = ses->server;\n\tint blob_offset, blob_length;\n\tchar *security_blob;\n\tint flags = CIFS_NEG_OP;\n\tunsigned int total_len;\n\n\tcifs_dbg(FYI, \"Negotiate protocol\\n\");\n\n\tif (!server) {\n\t\tWARN(1, \"%s: server is NULL!\\n\", __func__);\n\t\treturn -EIO;\n\t}\n\n\trc = smb2_plain_req_init(SMB2_NEGOTIATE, NULL, (void **) &req, &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\treq->sync_hdr.SessionId = 0;\n\n\tmemset(server->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\tmemset(ses->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(2);\n\t\ttotal_len += 4;\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB21_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[2] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->Dialects[3] = cpu_to_le16(SMB311_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(4);\n\t\ttotal_len += 8;\n\t} else {\n\t\t/* otherwise send specific dialect */\n\t\treq->Dialects[0] = cpu_to_le16(ses->server->vals->protocol_id);\n\t\treq->DialectCount = cpu_to_le16(1);\n\t\ttotal_len += 2;\n\t}\n\n\t/* only one of SMB2 signing flags may be set in SMB2 request */\n\tif (ses->sign)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_REQUIRED);\n\telse if (global_secflags & CIFSSEC_MAY_SIGN)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_ENABLED);\n\telse\n\t\treq->SecurityMode = 0;\n\n\treq->Capabilities = cpu_to_le32(ses->server->vals->req_capabilities);\n\n\t/* ClientGUID must be zero for SMB2.02 dialect */\n\tif (ses->server->vals->protocol_id == SMB20_PROT_ID)\n\t\tmemset(req->ClientGUID, 0, SMB2_CLIENT_GUID_SIZE);\n\telse {\n\t\tmemcpy(req->ClientGUID, server->client_guid,\n\t\t\tSMB2_CLIENT_GUID_SIZE);\n\t\tif ((ses->server->vals->protocol_id == SMB311_PROT_ID) ||\n\t\t    (strcmp(ses->server->vals->version_string,\n\t\t     SMBDEFAULT_VERSION_STRING) == 0))\n\t\t\tassemble_neg_contexts(req, &total_len);\n\t}\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_negotiate_rsp *)rsp_iov.iov_base;\n\t/*\n\t * No tcon so can't do\n\t * cifs_stats_inc(&tcon->stats.smb2_stats.smb2_com_fail[SMB2...]);\n\t */\n\tif (rc == -EOPNOTSUPP) {\n\t\tcifs_dbg(VFS, \"Dialect not supported by server. Consider \"\n\t\t\t\"specifying vers=1.0 or vers=2.0 on mount for accessing\"\n\t\t\t\" older servers\\n\");\n\t\tgoto neg_exit;\n\t} else if (rc != 0)\n\t\tgoto neg_exit;\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2.1 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\t/* ops set to 3.0 by default for default so update */\n\t\t\tses->server->ops = &smb21_operations;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n\t\t\tses->server->ops = &smb311_operations;\n\t} else if (le16_to_cpu(rsp->DialectRevision) !=\n\t\t\t\tses->server->vals->protocol_id) {\n\t\t/* if requested single dialect ensure returned dialect matched */\n\t\tcifs_dbg(VFS, \"Illegal 0x%x dialect returned: not requested\\n\",\n\t\t\tle16_to_cpu(rsp->DialectRevision));\n\t\treturn -EIO;\n\t}\n\n\tcifs_dbg(FYI, \"mode 0x%x\\n\", rsp->SecurityMode);\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.1 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB30_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB302_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.02 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.1.1 dialect\\n\");\n\telse {\n\t\tcifs_dbg(VFS, \"Illegal dialect returned by server 0x%x\\n\",\n\t\t\t le16_to_cpu(rsp->DialectRevision));\n\t\trc = -EIO;\n\t\tgoto neg_exit;\n\t}\n\tserver->dialect = le16_to_cpu(rsp->DialectRevision);\n\n\t/*\n\t * Keep a copy of the hash after negprot. This hash will be\n\t * the starting hash value for all sessions made from this\n\t * server.\n\t */\n\tmemcpy(server->preauth_sha_hash, ses->preauth_sha_hash,\n\t       SMB2_PREAUTH_HASH_SIZE);\n\n\t/* SMB2 only has an extended negflavor */\n\tserver->negflavor = CIFS_NEGFLAVOR_EXTENDED;\n\t/* set it to the maximum buffer size value we can send with 1 credit */\n\tserver->maxBuf = min_t(unsigned int, le32_to_cpu(rsp->MaxTransactSize),\n\t\t\t       SMB2_MAX_BUFFER_SIZE);\n\tserver->max_read = le32_to_cpu(rsp->MaxReadSize);\n\tserver->max_write = le32_to_cpu(rsp->MaxWriteSize);\n\tserver->sec_mode = le16_to_cpu(rsp->SecurityMode);\n\tif ((server->sec_mode & SMB2_SEC_MODE_FLAGS_ALL) != server->sec_mode)\n\t\tcifs_dbg(FYI, \"Server returned unexpected security mode 0x%x\\n\",\n\t\t\t\tserver->sec_mode);\n\tserver->capabilities = le32_to_cpu(rsp->Capabilities);\n\t/* Internal types */\n\tserver->capabilities |= SMB2_NT_FIND | SMB2_LARGE_FILES;\n\n\tsecurity_blob = smb2_get_data_area_len(&blob_offset, &blob_length,\n\t\t\t\t\t       (struct smb2_sync_hdr *)rsp);\n\t/*\n\t * See MS-SMB2 section 2.2.4: if no blob, client picks default which\n\t * for us will be\n\t *\tses->sectype = RawNTLMSSP;\n\t * but for time being this is our only auth choice so doesn't matter.\n\t * We just found a server which sets blob length to zero expecting raw.\n\t */\n\tif (blob_length == 0) {\n\t\tcifs_dbg(FYI, \"missing security blob on negprot\\n\");\n\t\tserver->sec_ntlmssp = true;\n\t}\n\n\trc = cifs_enable_signing(server, ses->sign);\n\tif (rc)\n\t\tgoto neg_exit;\n\tif (blob_length) {\n\t\trc = decode_negTokenInit(security_blob, blob_length, server);\n\t\tif (rc == 1)\n\t\t\trc = 0;\n\t\telse if (rc == 0)\n\t\t\trc = -EIO;\n\t}\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n\t\tif (rsp->NegotiateContextCount)\n\t\t\trc = smb311_decode_neg_context(rsp, server,\n\t\t\t\t\t\t       rsp_iov.iov_len);\n\t\telse\n\t\t\tcifs_dbg(VFS, \"Missing expected negotiate contexts\\n\");\n\t}\nneg_exit:\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "func_src_after": "SMB2_negotiate(const unsigned int xid, struct cifs_ses *ses)\n{\n\tstruct smb_rqst rqst;\n\tstruct smb2_negotiate_req *req;\n\tstruct smb2_negotiate_rsp *rsp;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tint rc = 0;\n\tint resp_buftype;\n\tstruct TCP_Server_Info *server = ses->server;\n\tint blob_offset, blob_length;\n\tchar *security_blob;\n\tint flags = CIFS_NEG_OP;\n\tunsigned int total_len;\n\n\tcifs_dbg(FYI, \"Negotiate protocol\\n\");\n\n\tif (!server) {\n\t\tWARN(1, \"%s: server is NULL!\\n\", __func__);\n\t\treturn -EIO;\n\t}\n\n\trc = smb2_plain_req_init(SMB2_NEGOTIATE, NULL, (void **) &req, &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\treq->sync_hdr.SessionId = 0;\n\n\tmemset(server->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\tmemset(ses->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(2);\n\t\ttotal_len += 4;\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB21_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[2] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->Dialects[3] = cpu_to_le16(SMB311_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(4);\n\t\ttotal_len += 8;\n\t} else {\n\t\t/* otherwise send specific dialect */\n\t\treq->Dialects[0] = cpu_to_le16(ses->server->vals->protocol_id);\n\t\treq->DialectCount = cpu_to_le16(1);\n\t\ttotal_len += 2;\n\t}\n\n\t/* only one of SMB2 signing flags may be set in SMB2 request */\n\tif (ses->sign)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_REQUIRED);\n\telse if (global_secflags & CIFSSEC_MAY_SIGN)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_ENABLED);\n\telse\n\t\treq->SecurityMode = 0;\n\n\treq->Capabilities = cpu_to_le32(ses->server->vals->req_capabilities);\n\n\t/* ClientGUID must be zero for SMB2.02 dialect */\n\tif (ses->server->vals->protocol_id == SMB20_PROT_ID)\n\t\tmemset(req->ClientGUID, 0, SMB2_CLIENT_GUID_SIZE);\n\telse {\n\t\tmemcpy(req->ClientGUID, server->client_guid,\n\t\t\tSMB2_CLIENT_GUID_SIZE);\n\t\tif ((ses->server->vals->protocol_id == SMB311_PROT_ID) ||\n\t\t    (strcmp(ses->server->vals->version_string,\n\t\t     SMBDEFAULT_VERSION_STRING) == 0))\n\t\t\tassemble_neg_contexts(req, &total_len);\n\t}\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_negotiate_rsp *)rsp_iov.iov_base;\n\t/*\n\t * No tcon so can't do\n\t * cifs_stats_inc(&tcon->stats.smb2_stats.smb2_com_fail[SMB2...]);\n\t */\n\tif (rc == -EOPNOTSUPP) {\n\t\tcifs_dbg(VFS, \"Dialect not supported by server. Consider \"\n\t\t\t\"specifying vers=1.0 or vers=2.0 on mount for accessing\"\n\t\t\t\" older servers\\n\");\n\t\tgoto neg_exit;\n\t} else if (rc != 0)\n\t\tgoto neg_exit;\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2.1 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\t/* ops set to 3.0 by default for default so update */\n\t\t\tses->server->ops = &smb21_operations;\n\t\t\tses->server->vals = &smb21_values;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n\t\t\tses->server->ops = &smb311_operations;\n\t\t\tses->server->vals = &smb311_values;\n\t\t}\n\t} else if (le16_to_cpu(rsp->DialectRevision) !=\n\t\t\t\tses->server->vals->protocol_id) {\n\t\t/* if requested single dialect ensure returned dialect matched */\n\t\tcifs_dbg(VFS, \"Illegal 0x%x dialect returned: not requested\\n\",\n\t\t\tle16_to_cpu(rsp->DialectRevision));\n\t\treturn -EIO;\n\t}\n\n\tcifs_dbg(FYI, \"mode 0x%x\\n\", rsp->SecurityMode);\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.1 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB30_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB302_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.02 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.1.1 dialect\\n\");\n\telse {\n\t\tcifs_dbg(VFS, \"Illegal dialect returned by server 0x%x\\n\",\n\t\t\t le16_to_cpu(rsp->DialectRevision));\n\t\trc = -EIO;\n\t\tgoto neg_exit;\n\t}\n\tserver->dialect = le16_to_cpu(rsp->DialectRevision);\n\n\t/*\n\t * Keep a copy of the hash after negprot. This hash will be\n\t * the starting hash value for all sessions made from this\n\t * server.\n\t */\n\tmemcpy(server->preauth_sha_hash, ses->preauth_sha_hash,\n\t       SMB2_PREAUTH_HASH_SIZE);\n\n\t/* SMB2 only has an extended negflavor */\n\tserver->negflavor = CIFS_NEGFLAVOR_EXTENDED;\n\t/* set it to the maximum buffer size value we can send with 1 credit */\n\tserver->maxBuf = min_t(unsigned int, le32_to_cpu(rsp->MaxTransactSize),\n\t\t\t       SMB2_MAX_BUFFER_SIZE);\n\tserver->max_read = le32_to_cpu(rsp->MaxReadSize);\n\tserver->max_write = le32_to_cpu(rsp->MaxWriteSize);\n\tserver->sec_mode = le16_to_cpu(rsp->SecurityMode);\n\tif ((server->sec_mode & SMB2_SEC_MODE_FLAGS_ALL) != server->sec_mode)\n\t\tcifs_dbg(FYI, \"Server returned unexpected security mode 0x%x\\n\",\n\t\t\t\tserver->sec_mode);\n\tserver->capabilities = le32_to_cpu(rsp->Capabilities);\n\t/* Internal types */\n\tserver->capabilities |= SMB2_NT_FIND | SMB2_LARGE_FILES;\n\n\tsecurity_blob = smb2_get_data_area_len(&blob_offset, &blob_length,\n\t\t\t\t\t       (struct smb2_sync_hdr *)rsp);\n\t/*\n\t * See MS-SMB2 section 2.2.4: if no blob, client picks default which\n\t * for us will be\n\t *\tses->sectype = RawNTLMSSP;\n\t * but for time being this is our only auth choice so doesn't matter.\n\t * We just found a server which sets blob length to zero expecting raw.\n\t */\n\tif (blob_length == 0) {\n\t\tcifs_dbg(FYI, \"missing security blob on negprot\\n\");\n\t\tserver->sec_ntlmssp = true;\n\t}\n\n\trc = cifs_enable_signing(server, ses->sign);\n\tif (rc)\n\t\tgoto neg_exit;\n\tif (blob_length) {\n\t\trc = decode_negTokenInit(security_blob, blob_length, server);\n\t\tif (rc == 1)\n\t\t\trc = 0;\n\t\telse if (rc == 0)\n\t\t\trc = -EIO;\n\t}\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n\t\tif (rsp->NegotiateContextCount)\n\t\t\trc = smb311_decode_neg_context(rsp, server,\n\t\t\t\t\t\t       rsp_iov.iov_len);\n\t\telse\n\t\t\tcifs_dbg(VFS, \"Missing expected negotiate contexts\\n\");\n\t}\nneg_exit:\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/b57a55e2200ede754e4dc9cce4ba9402544b9365", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-125", "description": "Write a C function named `SMB2_negotiate` that initiates a negotiation request for the SMB2 protocol in C."}
{"func_name": "get_top_author", "func_src_before": "def get_top_author(top_num):\r\n    \"\"\" query the top(top_num) popular author\r\n        top_num => list of [author, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT authors.name,author_result.num\r\n                    FROM authors JOIN\r\n                    (SELECT SUM(article_result.num) as num,\r\n                    article_result.author\r\n                    from (SELECT articles.title, articles.author,\r\n                    SUM(log.views) AS num\r\n                    FROM articles\r\n                    INNER JOIN (\r\n                    SELECT path, count(path) AS views\r\n                    FROM log GROUP BY log.path\r\n                    ) AS log ON log.path = '/article/'\r\n                    || articles.slug\r\n                    GROUP BY articles.title, articles.author)\r\n                    AS article_result\r\n                    GROUP BY article_result.author) as author_result\r\n                    ON authors.id = author_result.author\r\n                    ORDER BY num DESC LIMIT {}\"\"\".format(top_num)\r\n    return execute_query(cmd)", "func_src_after": "def get_top_author(top_num):\r\n    \"\"\" query the top(top_num) popular author\r\n        top_num => list of [author, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT authors.name,author_result.num\r\n                    FROM authors JOIN\r\n                    (SELECT SUM(article_result.num) as num,\r\n                    article_result.author\r\n                    from (SELECT articles.title, articles.author,\r\n                    SUM(log.views) AS num\r\n                    FROM articles\r\n                    INNER JOIN (\r\n                    SELECT path, count(path) AS views\r\n                    FROM log GROUP BY log.path\r\n                    ) AS log ON log.path = '/article/'\r\n                    || articles.slug\r\n                    GROUP BY articles.title, articles.author)\r\n                    AS article_result\r\n                    GROUP BY article_result.author) as author_result\r\n                    ON authors.id = author_result.author\r\n                    ORDER BY num DESC LIMIT %s\"\"\"\r\n    data = [top_num, ]\r\n    return execute_query(cmd, data)", "commit_link": "github.com/thugasin/udacity-homework-logAnalyzer/commit/506f25f9a1caee7f17034adf7c75e0efbc88082b", "file_name": "logAnalyzerDb.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the top N authors by popularity from a database, using SQL queries."}
{"func_name": "imap_hcache_open", "func_src_before": "header_cache_t *imap_hcache_open(struct ImapData *idata, const char *path)\n{\n  struct ImapMbox mx;\n  struct Url url;\n  char cachepath[PATH_MAX];\n  char mbox[PATH_MAX];\n\n  if (path)\n    imap_cachepath(idata, path, mbox, sizeof(mbox));\n  else\n  {\n    if (!idata->ctx || imap_parse_path(idata->ctx->path, &mx) < 0)\n      return NULL;\n\n    imap_cachepath(idata, mx.mbox, mbox, sizeof(mbox));\n    FREE(&mx.mbox);\n  }\n\n  mutt_account_tourl(&idata->conn->account, &url);\n  url.path = mbox;\n  url_tostring(&url, cachepath, sizeof(cachepath), U_PATH);\n\n  return mutt_hcache_open(HeaderCache, cachepath, imap_hcache_namer);\n}", "func_src_after": "header_cache_t *imap_hcache_open(struct ImapData *idata, const char *path)\n{\n  struct ImapMbox mx;\n  struct Url url;\n  char cachepath[PATH_MAX];\n  char mbox[PATH_MAX];\n\n  if (path)\n    imap_cachepath(idata, path, mbox, sizeof(mbox));\n  else\n  {\n    if (!idata->ctx || imap_parse_path(idata->ctx->path, &mx) < 0)\n      return NULL;\n\n    imap_cachepath(idata, mx.mbox, mbox, sizeof(mbox));\n    FREE(&mx.mbox);\n  }\n\n  if (strstr(mbox, \"/../\") || (strcmp(mbox, \"..\") == 0) || (strncmp(mbox, \"../\", 3) == 0))\n    return NULL;\n  size_t len = strlen(mbox);\n  if ((len > 3) && (strcmp(mbox + len - 3, \"/..\") == 0))\n    return NULL;\n\n  mutt_account_tourl(&idata->conn->account, &url);\n  url.path = mbox;\n  url_tostring(&url, cachepath, sizeof(cachepath), U_PATH);\n\n  return mutt_hcache_open(HeaderCache, cachepath, imap_hcache_namer);\n}", "commit_link": "github.com/neomutt/neomutt/commit/57971dba06346b2d7179294f4528b8d4427a7c5d", "file_name": "imap/util.c", "vul_type": "cwe-022", "description": "Write a C function named `imap_hcache_open` that opens an IMAP header cache, optionally using a provided path."}
{"func_name": "top_proxies", "func_src_before": "@app.route('/top_proxies')\ndef top_proxies():\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT sum(amount) FROM holders\"\n    cur.execute(query)\n    total = cur.fetchone()\n    total_votes = total[0]\n\n    query = \"SELECT voting_as FROM holders WHERE voting_as<>'1.2.5' group by voting_as\"\n    cur.execute(query)\n    results = cur.fetchall()\n    #con.close()\n\n    proxies = []\n\n    for p in range(0, len(results)):\n\n        proxy_line = [0] * 5\n\n        proxy_id = results[p][0]\n        proxy_line[0] = proxy_id\n\n        query = \"SELECT account_name, amount FROM holders WHERE account_id='\"+proxy_id+\"' LIMIT 1\"\n        cur.execute(query)\n        proxy = cur.fetchone()\n\n        try:\n            proxy_name = proxy[0]\n            proxy_amount = proxy[1]\n        except:\n            proxy_name = \"unknown\"\n            proxy_amount = 0\n\n\n        proxy_line[1] = proxy_name\n\n        query = \"SELECT amount, account_id FROM holders WHERE voting_as='\"+proxy_id+\"'\"\n        cur.execute(query)\n        results2 = cur.fetchall()\n\n        proxy_line[2] = int(proxy_amount)\n\n        for p2 in range(0, len(results2)):\n            amount = results2[p2][0]\n            account_id = results2[p2][1]\n            proxy_line[2] = proxy_line[2] + int(amount)  # total proxy votes\n            proxy_line[3] = proxy_line[3] + 1       # followers\n\n        if proxy_line[3] > 2:\n            percentage = float(float(proxy_line[2]) * 100.0/ float(total_votes))\n            proxy_line[4] = percentage\n            proxies.append(proxy_line)\n\n    con.close()\n\n    proxies = sorted(proxies, key=lambda k: int(k[2]))\n    r_proxies = proxies[::-1]\n\n    return jsonify(filter(None, r_proxies))", "func_src_after": "@app.route('/top_proxies')\ndef top_proxies():\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT sum(amount) FROM holders\"\n    cur.execute(query)\n    total = cur.fetchone()\n    total_votes = total[0]\n\n    query = \"SELECT voting_as FROM holders WHERE voting_as<>'1.2.5' group by voting_as\"\n    cur.execute(query)\n    results = cur.fetchall()\n    #con.close()\n\n    proxies = []\n\n    for p in range(0, len(results)):\n\n        proxy_line = [0] * 5\n\n        proxy_id = results[p][0]\n        proxy_line[0] = proxy_id\n\n        query = \"SELECT account_name, amount FROM holders WHERE account_id=%s LIMIT 1\"\n        cur.execute(query, (proxy_id,))\n        proxy = cur.fetchone()\n\n        try:\n            proxy_name = proxy[0]\n            proxy_amount = proxy[1]\n        except:\n            proxy_name = \"unknown\"\n            proxy_amount = 0\n\n\n        proxy_line[1] = proxy_name\n\n        query = \"SELECT amount, account_id FROM holders WHERE voting_as=%s\"\n        cur.execute(query, (proxy_id,))\n        results2 = cur.fetchall()\n\n        proxy_line[2] = int(proxy_amount)\n\n        for p2 in range(0, len(results2)):\n            amount = results2[p2][0]\n            account_id = results2[p2][1]\n            proxy_line[2] = proxy_line[2] + int(amount)  # total proxy votes\n            proxy_line[3] = proxy_line[3] + 1       # followers\n\n        if proxy_line[3] > 2:\n            percentage = float(float(proxy_line[2]) * 100.0/ float(total_votes))\n            proxy_line[4] = percentage\n            proxies.append(proxy_line)\n\n    con.close()\n\n    proxies = sorted(proxies, key=lambda k: int(k[2]))\n    r_proxies = proxies[::-1]\n\n    return jsonify(filter(None, r_proxies))", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "In Python, create a Flask endpoint '/top_proxies' that queries a PostgreSQL database to retrieve and return a JSON list of top proxy voters and their details."}
{"func_name": "UiApplication::SecurityConfiguration::configure", "func_src_before": "        @Override\n        protected void configure(HttpSecurity http) throws Exception {\n\n            String[] patterns = new String[] {\"/index.html\", \"/home.html\", \"/login1.html\", \"/xss2.html\", \"/\", \"/xss\",\n                \"/login\", \"/xss1.html\", \"/resource\", \"/postcustomer\", \"/getallcustomer\", \"/getinfo\", \"/postxss\"};\n\n            // @formatter:off\n            //http.httpBasic();\n            //http.authorizeRequests().antMatchers(\"/**\").permitAll(); //.anyRequest().authenticated();\n\n            http.headers().httpStrictTransportSecurity();\n            http.csrf().disable();\n            http.httpBasic().and().authorizeRequests().antMatchers(patterns).permitAll().anyRequest().authenticated();\n            http.csrf().and().addFilterAfter(new CsrfGrantingFilter(), SessionManagementFilter.class);\n            //http.csrf().csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());\n\n            // @formatter:on\n        }", "func_src_after": "        @Override\n        protected void configure(HttpSecurity http) throws Exception {\n\n            String[] patterns = new String[] {\"/index.html\", \"/home.html\", \"/login1.html\", \"/xss2.html\", \"/\", \"/xss\",\n                \"/login\", \"/xss1.html\", \"/resource\", \"/postcustomer\", \"/getallcustomer\", \"/getinfo\", \"/postxss\"};\n\n            // @formatter:off\n            //http.httpBasic();\n            //http.authorizeRequests().antMatchers(\"/**\").permitAll(); //.anyRequest().authenticated();\n            //http.csrf().disable();\n\n\n            http.headers().httpStrictTransportSecurity();\n            http.httpBasic().and().authorizeRequests().antMatchers(patterns).permitAll().anyRequest().authenticated();\n            http.csrf().and().addFilterAfter(new CsrfGrantingFilter(), SessionManagementFilter.class);\n            //http.csrf().csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());\n\n            // @formatter:on\n        }", "line_changes": {"deleted": [{"line_no": 12, "char_start": 548, "char_end": 583, "line": "            http.csrf().disable();\n"}], "added": [{"line_no": 11, "char_start": 526, "char_end": 527, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 548, "char_end": 583, "chars": "            http.csrf().disable();\n"}], "added": [{"char_start": 489, "char_end": 527, "chars": "            //http.csrf().disable();\n\n"}]}, "commit_link": "github.com/barbaraisabelvieira/VulnerableDemoApp/commit/a64bbb524722f63134826a7d0424d71518a0aae6", "file_name": "UiApplication.java", "vul_type": "cwe-352", "commit_msg": "Fixing CSRF - enabled now", "parent_commit": "1faf96211c58f44a8510497e08d31757160c6367", "description": "Write a Java method using Spring Security to configure HTTP security, allowing unrestricted access to specific URL patterns and requiring authentication for all other requests."}
{"func_name": "match_at", "func_src_before": "match_at(regex_t* reg, const UChar* str, const UChar* end,\n#ifdef USE_MATCH_RANGE_MUST_BE_INSIDE_OF_SPECIFIED_RANGE\n\t const UChar* right_range,\n#endif\n\t const UChar* sstart, UChar* sprev, OnigMatchArg* msa)\n{\n  static UChar FinishCode[] = { OP_FINISH };\n\n  int i, n, num_mem, best_len, pop_level;\n  LengthType tlen, tlen2;\n  MemNumType mem;\n  RelAddrType addr;\n  UChar *s, *q, *sbegin;\n  int is_alloca;\n  char *alloc_base;\n  OnigStackType *stk_base, *stk, *stk_end;\n  OnigStackType *stkp; /* used as any purpose. */\n  OnigStackIndex si;\n  OnigStackIndex *repeat_stk;\n  OnigStackIndex *mem_start_stk, *mem_end_stk;\n#ifdef USE_COMBINATION_EXPLOSION_CHECK\n  int scv;\n  unsigned char* state_check_buff = msa->state_check_buff;\n  int num_comb_exp_check = reg->num_comb_exp_check;\n#endif\n  UChar *p = reg->p;\n  OnigOptionType option = reg->options;\n  OnigEncoding encode = reg->enc;\n  OnigCaseFoldType case_fold_flag = reg->case_fold_flag;\n\n  //n = reg->num_repeat + reg->num_mem * 2;\n  pop_level = reg->stack_pop_level;\n  num_mem = reg->num_mem;\n  STACK_INIT(INIT_MATCH_STACK_SIZE);\n  UPDATE_FOR_STACK_REALLOC;\n  for (i = 1; i <= num_mem; i++) {\n    mem_start_stk[i] = mem_end_stk[i] = INVALID_STACK_INDEX;\n  }\n\n#ifdef ONIG_DEBUG_MATCH\n  fprintf(stderr, \"match_at: str: %d, end: %d, start: %d, sprev: %d\\n\",\n\t  (int )str, (int )end, (int )sstart, (int )sprev);\n  fprintf(stderr, \"size: %d, start offset: %d\\n\",\n\t  (int )(end - str), (int )(sstart - str));\n#endif\n\n  STACK_PUSH_ENSURED(STK_ALT, FinishCode);  /* bottom stack */\n  best_len = ONIG_MISMATCH;\n  s = (UChar* )sstart;\n  while (1) {\n#ifdef ONIG_DEBUG_MATCH\n    {\n      UChar *q, *bp, buf[50];\n      int len;\n      fprintf(stderr, \"%4d> \\\"\", (int )(s - str));\n      bp = buf;\n      for (i = 0, q = s; i < 7 && q < end; i++) {\n\tlen = enclen(encode, q);\n\twhile (len-- > 0) *bp++ = *q++;\n      }\n      if (q < end) { xmemcpy(bp, \"...\\\"\", 4); bp += 4; }\n      else         { xmemcpy(bp, \"\\\"\",    1); bp += 1; }\n      *bp = 0;\n      fputs((char* )buf, stderr);\n      for (i = 0; i < 20 - (bp - buf); i++) fputc(' ', stderr);\n      onig_print_compiled_byte_code(stderr, p, NULL, encode);\n      fprintf(stderr, \"\\n\");\n    }\n#endif\n\n    sbegin = s;\n    switch (*p++) {\n    case OP_END:  MOP_IN(OP_END);\n      n = s - sstart;\n      if (n > best_len) {\n        OnigRegion* region;\n#ifdef USE_FIND_LONGEST_SEARCH_ALL_OF_RANGE\n        if (IS_FIND_LONGEST(option)) {\n          if (n > msa->best_len) {\n            msa->best_len = n;\n            msa->best_s   = (UChar* )sstart;\n          }\n          else\n            goto end_best_len;\n        }\n#endif\n        best_len = n;\n        region = msa->region;\n        if (region) {\n#ifdef USE_POSIX_API_REGION_OPTION\n          if (IS_POSIX_REGION(msa->options)) {\n            posix_regmatch_t* rmt = (posix_regmatch_t* )region;\n\n            rmt[0].rm_so = sstart - str;\n            rmt[0].rm_eo = s      - str;\n            for (i = 1; i <= num_mem; i++) {\n              if (mem_end_stk[i] != INVALID_STACK_INDEX) {\n                if (BIT_STATUS_AT(reg->bt_mem_start, i))\n                  rmt[i].rm_so = STACK_AT(mem_start_stk[i])->u.mem.pstr - str;\n                else\n                  rmt[i].rm_so = (UChar* )((void* )(mem_start_stk[i])) - str;\n\n                rmt[i].rm_eo = (BIT_STATUS_AT(reg->bt_mem_end, i)\n                                ? STACK_AT(mem_end_stk[i])->u.mem.pstr\n                                : (UChar* )((void* )mem_end_stk[i])) - str;\n              }\n              else {\n                rmt[i].rm_so = rmt[i].rm_eo = ONIG_REGION_NOTPOS;\n              }\n            }\n          }\n          else {\n#endif /* USE_POSIX_API_REGION_OPTION */\n            region->beg[0] = sstart - str;\n            region->end[0] = s      - str;\n            for (i = 1; i <= num_mem; i++) {\n              if (mem_end_stk[i] != INVALID_STACK_INDEX) {\n                if (BIT_STATUS_AT(reg->bt_mem_start, i))\n                  region->beg[i] = STACK_AT(mem_start_stk[i])->u.mem.pstr - str;\n                else\n                  region->beg[i] = (UChar* )((void* )mem_start_stk[i]) - str;\n\n                region->end[i] = (BIT_STATUS_AT(reg->bt_mem_end, i)\n                                  ? STACK_AT(mem_end_stk[i])->u.mem.pstr\n                                  : (UChar* )((void* )mem_end_stk[i])) - str;\n              }\n              else {\n                region->beg[i] = region->end[i] = ONIG_REGION_NOTPOS;\n              }\n            }\n\n#ifdef USE_CAPTURE_HISTORY\n            if (reg->capture_history != 0) {\n              int r;\n              OnigCaptureTreeNode* node;\n\n              if (IS_NULL(region->history_root)) {\n                region->history_root = node = history_node_new();\n                CHECK_NULL_RETURN_MEMERR(node);\n              }\n              else {\n                node = region->history_root;\n                history_tree_clear(node);\n              }\n\n              node->group = 0;\n              node->beg   = sstart - str;\n              node->end   = s      - str;\n\n              stkp = stk_base;\n              r = make_capture_history_tree(region->history_root, &stkp,\n                                            stk, (UChar* )str, reg);\n              if (r < 0) {\n                best_len = r; /* error code */\n                goto finish;\n              }\n            }\n#endif /* USE_CAPTURE_HISTORY */\n#ifdef USE_POSIX_API_REGION_OPTION\n          } /* else IS_POSIX_REGION() */\n#endif\n        } /* if (region) */\n      } /* n > best_len */\n\n#ifdef USE_FIND_LONGEST_SEARCH_ALL_OF_RANGE\n    end_best_len:\n#endif\n      MOP_OUT;\n\n      if (IS_FIND_CONDITION(option)) {\n        if (IS_FIND_NOT_EMPTY(option) && s == sstart) {\n          best_len = ONIG_MISMATCH;\n          goto fail; /* for retry */\n        }\n        if (IS_FIND_LONGEST(option) && DATA_ENSURE_CHECK1) {\n          goto fail; /* for retry */\n        }\n      }\n\n      /* default behavior: return first-matching result. */\n      goto finish;\n      break;\n\n    case OP_EXACT1:  MOP_IN(OP_EXACT1);\n#if 0\n      DATA_ENSURE(1);\n      if (*p != *s) goto fail;\n      p++; s++;\n#endif\n      if (*p != *s++) goto fail;\n      DATA_ENSURE(0);\n      p++;\n      MOP_OUT;\n      break;\n\n    case OP_EXACT1_IC:  MOP_IN(OP_EXACT1_IC);\n      {\n        int len;\n        UChar *q, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n        DATA_ENSURE(1);\n        len = ONIGENC_MBC_CASE_FOLD(encode,\n                 /* DISABLE_CASE_FOLD_MULTI_CHAR(case_fold_flag), */\n                                    case_fold_flag,\n                                    &s, end, lowbuf);\n        DATA_ENSURE(0);\n        q = lowbuf;\n        while (len-- > 0) {\n          if (*p != *q) {\n            goto fail;\n          }\n          p++; q++;\n        }\n      }\n      MOP_OUT;\n      break;\n\n    case OP_EXACT2:  MOP_IN(OP_EXACT2);\n      DATA_ENSURE(2);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      sprev = s;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACT3:  MOP_IN(OP_EXACT3);\n      DATA_ENSURE(3);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      sprev = s;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACT4:  MOP_IN(OP_EXACT4);\n      DATA_ENSURE(4);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      sprev = s;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACT5:  MOP_IN(OP_EXACT5);\n      DATA_ENSURE(5);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      sprev = s;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTN:  MOP_IN(OP_EXACTN);\n      GET_LENGTH_INC(tlen, p);\n      DATA_ENSURE(tlen);\n      while (tlen-- > 0) {\n        if (*p++ != *s++) goto fail;\n      }\n      sprev = s - 1;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTN_IC:  MOP_IN(OP_EXACTN_IC);\n      {\n        int len;\n        UChar *q, *endp, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n        GET_LENGTH_INC(tlen, p);\n        endp = p + tlen;\n\n        while (p < endp) {\n          sprev = s;\n          DATA_ENSURE(1);\n          len = ONIGENC_MBC_CASE_FOLD(encode,\n                        /* DISABLE_CASE_FOLD_MULTI_CHAR(case_fold_flag), */\n                                      case_fold_flag,\n                                      &s, end, lowbuf);\n          DATA_ENSURE(0);\n          q = lowbuf;\n          while (len-- > 0) {\n            if (*p != *q) goto fail;\n            p++; q++;\n          }\n        }\n      }\n\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMB2N1:  MOP_IN(OP_EXACTMB2N1);\n      DATA_ENSURE(2);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      MOP_OUT;\n      break;\n\n    case OP_EXACTMB2N2:  MOP_IN(OP_EXACTMB2N2);\n      DATA_ENSURE(4);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      sprev = s;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMB2N3:  MOP_IN(OP_EXACTMB2N3);\n      DATA_ENSURE(6);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      sprev = s;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMB2N:  MOP_IN(OP_EXACTMB2N);\n      GET_LENGTH_INC(tlen, p);\n      DATA_ENSURE(tlen * 2);\n      while (tlen-- > 0) {\n        if (*p != *s) goto fail;\n        p++; s++;\n        if (*p != *s) goto fail;\n        p++; s++;\n      }\n      sprev = s - 2;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMB3N:  MOP_IN(OP_EXACTMB3N);\n      GET_LENGTH_INC(tlen, p);\n      DATA_ENSURE(tlen * 3);\n      while (tlen-- > 0) {\n        if (*p != *s) goto fail;\n        p++; s++;\n        if (*p != *s) goto fail;\n        p++; s++;\n        if (*p != *s) goto fail;\n        p++; s++;\n      }\n      sprev = s - 3;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMBN:  MOP_IN(OP_EXACTMBN);\n      GET_LENGTH_INC(tlen,  p);  /* mb-len */\n      GET_LENGTH_INC(tlen2, p);  /* string len */\n      tlen2 *= tlen;\n      DATA_ENSURE(tlen2);\n      while (tlen2-- > 0) {\n        if (*p != *s) goto fail;\n        p++; s++;\n      }\n      sprev = s - tlen;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_CCLASS:  MOP_IN(OP_CCLASS);\n      DATA_ENSURE(1);\n      if (BITSET_AT(((BitSetRef )p), *s) == 0) goto fail;\n      p += SIZE_BITSET;\n      s += enclen(encode, s);   /* OP_CCLASS can match mb-code. \\D, \\S */\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_MB:  MOP_IN(OP_CCLASS_MB);\n      if (! ONIGENC_IS_MBC_HEAD(encode, s)) goto fail;\n\n    cclass_mb:\n      GET_LENGTH_INC(tlen, p);\n      {\n        OnigCodePoint code;\n        UChar *ss;\n        int mb_len;\n\n        DATA_ENSURE(1);\n        mb_len = enclen(encode, s);\n        DATA_ENSURE(mb_len);\n        ss = s;\n        s += mb_len;\n        code = ONIGENC_MBC_TO_CODE(encode, ss, s);\n\n#ifdef PLATFORM_UNALIGNED_WORD_ACCESS\n        if (! onig_is_in_code_range(p, code)) goto fail;\n#else\n        q = p;\n        ALIGNMENT_RIGHT(q);\n        if (! onig_is_in_code_range(q, code)) goto fail;\n#endif\n      }\n      p += tlen;\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_MIX:  MOP_IN(OP_CCLASS_MIX);\n      DATA_ENSURE(1);\n      if (ONIGENC_IS_MBC_HEAD(encode, s)) {\n        p += SIZE_BITSET;\n        goto cclass_mb;\n      }\n      else {\n        if (BITSET_AT(((BitSetRef )p), *s) == 0)\n          goto fail;\n\n        p += SIZE_BITSET;\n        GET_LENGTH_INC(tlen, p);\n        p += tlen;\n        s++;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_NOT:  MOP_IN(OP_CCLASS_NOT);\n      DATA_ENSURE(1);\n      if (BITSET_AT(((BitSetRef )p), *s) != 0) goto fail;\n      p += SIZE_BITSET;\n      s += enclen(encode, s);\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_MB_NOT:  MOP_IN(OP_CCLASS_MB_NOT);\n      DATA_ENSURE(1);\n      if (! ONIGENC_IS_MBC_HEAD(encode, s)) {\n        s++;\n        GET_LENGTH_INC(tlen, p);\n        p += tlen;\n        goto cc_mb_not_success;\n      }\n\n    cclass_mb_not:\n      GET_LENGTH_INC(tlen, p);\n      {\n        OnigCodePoint code;\n        UChar *ss;\n        int mb_len = enclen(encode, s);\n\n        if (! DATA_ENSURE_CHECK(mb_len)) {\n          DATA_ENSURE(1);\n          s = (UChar* )end;\n          p += tlen;\n          goto cc_mb_not_success;\n        }\n\n        ss = s;\n        s += mb_len;\n        code = ONIGENC_MBC_TO_CODE(encode, ss, s);\n\n#ifdef PLATFORM_UNALIGNED_WORD_ACCESS\n        if (onig_is_in_code_range(p, code)) goto fail;\n#else\n        q = p;\n        ALIGNMENT_RIGHT(q);\n        if (onig_is_in_code_range(q, code)) goto fail;\n#endif\n      }\n      p += tlen;\n\n    cc_mb_not_success:\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_MIX_NOT:  MOP_IN(OP_CCLASS_MIX_NOT);\n      DATA_ENSURE(1);\n      if (ONIGENC_IS_MBC_HEAD(encode, s)) {\n        p += SIZE_BITSET;\n        goto cclass_mb_not;\n      }\n      else {\n        if (BITSET_AT(((BitSetRef )p), *s) != 0)\n          goto fail;\n\n        p += SIZE_BITSET;\n        GET_LENGTH_INC(tlen, p);\n        p += tlen;\n        s++;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_NODE:  MOP_IN(OP_CCLASS_NODE);\n      {\n        OnigCodePoint code;\n        void *node;\n        int mb_len;\n        UChar *ss;\n\n        DATA_ENSURE(1);\n        GET_POINTER_INC(node, p);\n        mb_len = enclen(encode, s);\n        ss = s;\n        s += mb_len;\n        DATA_ENSURE(0);\n        code = ONIGENC_MBC_TO_CODE(encode, ss, s);\n        if (onig_is_code_in_cc_len(mb_len, code, node) == 0) goto fail;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR:  MOP_IN(OP_ANYCHAR);\n      DATA_ENSURE(1);\n      n = enclen(encode, s);\n      DATA_ENSURE(n);\n      if (ONIGENC_IS_MBC_NEWLINE(encode, s, end)) goto fail;\n      s += n;\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_ML:  MOP_IN(OP_ANYCHAR_ML);\n      DATA_ENSURE(1);\n      n = enclen(encode, s);\n      DATA_ENSURE(n);\n      s += n;\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_STAR:  MOP_IN(OP_ANYCHAR_STAR);\n      while (DATA_ENSURE_CHECK1) {\n        STACK_PUSH_ALT(p, s, sprev);\n        n = enclen(encode, s);\n        DATA_ENSURE(n);\n        if (ONIGENC_IS_MBC_NEWLINE(encode, s, end))  goto fail;\n        sprev = s;\n        s += n;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_ML_STAR:  MOP_IN(OP_ANYCHAR_ML_STAR);\n      while (DATA_ENSURE_CHECK1) {\n        STACK_PUSH_ALT(p, s, sprev);\n        n = enclen(encode, s);\n        if (n > 1) {\n          DATA_ENSURE(n);\n          sprev = s;\n          s += n;\n        }\n        else {\n          sprev = s;\n          s++;\n        }\n      }\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_STAR_PEEK_NEXT:  MOP_IN(OP_ANYCHAR_STAR_PEEK_NEXT);\n      while (DATA_ENSURE_CHECK1) {\n        if (*p == *s) {\n          STACK_PUSH_ALT(p + 1, s, sprev);\n        }\n        n = enclen(encode, s);\n        DATA_ENSURE(n);\n        if (ONIGENC_IS_MBC_NEWLINE(encode, s, end))  goto fail;\n        sprev = s;\n        s += n;\n      }\n      p++;\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_ML_STAR_PEEK_NEXT:MOP_IN(OP_ANYCHAR_ML_STAR_PEEK_NEXT);\n      while (DATA_ENSURE_CHECK1) {\n        if (*p == *s) {\n          STACK_PUSH_ALT(p + 1, s, sprev);\n        }\n        n = enclen(encode, s);\n        if (n > 1) {\n          DATA_ENSURE(n);\n          sprev = s;\n          s += n;\n        }\n        else {\n          sprev = s;\n          s++;\n        }\n      }\n      p++;\n      MOP_OUT;\n      break;\n\n#ifdef USE_COMBINATION_EXPLOSION_CHECK\n    case OP_STATE_CHECK_ANYCHAR_STAR:  MOP_IN(OP_STATE_CHECK_ANYCHAR_STAR);\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      while (DATA_ENSURE_CHECK1) {\n        STATE_CHECK_VAL(scv, mem);\n        if (scv) goto fail;\n\n        STACK_PUSH_ALT_WITH_STATE_CHECK(p, s, sprev, mem);\n        n = enclen(encode, s);\n        DATA_ENSURE(n);\n        if (ONIGENC_IS_MBC_NEWLINE(encode, s, end))  goto fail;\n        sprev = s;\n        s += n;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_STATE_CHECK_ANYCHAR_ML_STAR:\n      MOP_IN(OP_STATE_CHECK_ANYCHAR_ML_STAR);\n\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      while (DATA_ENSURE_CHECK1) {\n        STATE_CHECK_VAL(scv, mem);\n        if (scv) goto fail;\n\n        STACK_PUSH_ALT_WITH_STATE_CHECK(p, s, sprev, mem);\n        n = enclen(encode, s);\n        if (n > 1) {\n          DATA_ENSURE(n);\n          sprev = s;\n          s += n;\n        }\n        else {\n          sprev = s;\n          s++;\n        }\n      }\n      MOP_OUT;\n      break;\n#endif /* USE_COMBINATION_EXPLOSION_CHECK */\n\n    case OP_WORD:  MOP_IN(OP_WORD);\n      DATA_ENSURE(1);\n      if (! ONIGENC_IS_MBC_WORD(encode, s, end))\n        goto fail;\n\n      s += enclen(encode, s);\n      MOP_OUT;\n      break;\n\n    case OP_NOT_WORD:  MOP_IN(OP_NOT_WORD);\n      DATA_ENSURE(1);\n      if (ONIGENC_IS_MBC_WORD(encode, s, end))\n        goto fail;\n\n      s += enclen(encode, s);\n      MOP_OUT;\n      break;\n\n    case OP_WORD_BOUND:  MOP_IN(OP_WORD_BOUND);\n      if (ON_STR_BEGIN(s)) {\n        DATA_ENSURE(1);\n        if (! ONIGENC_IS_MBC_WORD(encode, s, end))\n          goto fail;\n      }\n      else if (ON_STR_END(s)) {\n        if (! ONIGENC_IS_MBC_WORD(encode, sprev, end))\n          goto fail;\n      }\n      else {\n        if (ONIGENC_IS_MBC_WORD(encode, s, end)\n            == ONIGENC_IS_MBC_WORD(encode, sprev, end))\n          goto fail;\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_NOT_WORD_BOUND:  MOP_IN(OP_NOT_WORD_BOUND);\n      if (ON_STR_BEGIN(s)) {\n        if (DATA_ENSURE_CHECK1 && ONIGENC_IS_MBC_WORD(encode, s, end))\n          goto fail;\n      }\n      else if (ON_STR_END(s)) {\n        if (ONIGENC_IS_MBC_WORD(encode, sprev, end))\n          goto fail;\n      }\n      else {\n        if (ONIGENC_IS_MBC_WORD(encode, s, end)\n            != ONIGENC_IS_MBC_WORD(encode, sprev, end))\n          goto fail;\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n#ifdef USE_WORD_BEGIN_END\n    case OP_WORD_BEGIN:  MOP_IN(OP_WORD_BEGIN);\n      if (DATA_ENSURE_CHECK1 && ONIGENC_IS_MBC_WORD(encode, s, end)) {\n        if (ON_STR_BEGIN(s) || !ONIGENC_IS_MBC_WORD(encode, sprev, end)) {\n          MOP_OUT;\n          continue;\n        }\n      }\n      goto fail;\n      break;\n\n    case OP_WORD_END:  MOP_IN(OP_WORD_END);\n      if (!ON_STR_BEGIN(s) && ONIGENC_IS_MBC_WORD(encode, sprev, end)) {\n        if (ON_STR_END(s) || !ONIGENC_IS_MBC_WORD(encode, s, end)) {\n          MOP_OUT;\n          continue;\n        }\n      }\n      goto fail;\n      break;\n#endif\n\n    case OP_BEGIN_BUF:  MOP_IN(OP_BEGIN_BUF);\n      if (! ON_STR_BEGIN(s)) goto fail;\n\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_END_BUF:  MOP_IN(OP_END_BUF);\n      if (! ON_STR_END(s)) goto fail;\n\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_BEGIN_LINE:  MOP_IN(OP_BEGIN_LINE);\n      if (ON_STR_BEGIN(s)) {\n        if (IS_NOTBOL(msa->options)) goto fail;\n        MOP_OUT;\n        continue;\n      }\n      else if (ONIGENC_IS_MBC_NEWLINE(encode, sprev, end) && !ON_STR_END(s)) {\n        MOP_OUT;\n        continue;\n      }\n      goto fail;\n      break;\n\n    case OP_END_LINE:  MOP_IN(OP_END_LINE);\n      if (ON_STR_END(s)) {\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n        if (IS_EMPTY_STR || !ONIGENC_IS_MBC_NEWLINE(encode, sprev, end)) {\n#endif\n          if (IS_NOTEOL(msa->options)) goto fail;\n          MOP_OUT;\n          continue;\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n        }\n#endif\n      }\n      else if (ONIGENC_IS_MBC_NEWLINE(encode, s, end)) {\n        MOP_OUT;\n        continue;\n      }\n#ifdef USE_CRNL_AS_LINE_TERMINATOR\n      else if (ONIGENC_IS_MBC_CRNL(encode, s, end)) {\n        MOP_OUT;\n        continue;\n      }\n#endif\n      goto fail;\n      break;\n\n    case OP_SEMI_END_BUF:  MOP_IN(OP_SEMI_END_BUF);\n      if (ON_STR_END(s)) {\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n        if (IS_EMPTY_STR || !ONIGENC_IS_MBC_NEWLINE(encode, sprev, end)) {\n#endif\n          if (IS_NOTEOL(msa->options)) goto fail;\n          MOP_OUT;\n          continue;\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n        }\n#endif\n      }\n      else if (ONIGENC_IS_MBC_NEWLINE(encode, s, end) &&\n               ON_STR_END(s + enclen(encode, s))) {\n        MOP_OUT;\n        continue;\n      }\n#ifdef USE_CRNL_AS_LINE_TERMINATOR\n      else if (ONIGENC_IS_MBC_CRNL(encode, s, end)) {\n        UChar* ss = s + enclen(encode, s);\n        ss += enclen(encode, ss);\n        if (ON_STR_END(ss)) {\n          MOP_OUT;\n          continue;\n        }\n      }\n#endif\n      goto fail;\n      break;\n\n    case OP_BEGIN_POSITION:  MOP_IN(OP_BEGIN_POSITION);\n      if (s != msa->start)\n        goto fail;\n\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_START_PUSH:  MOP_IN(OP_MEMORY_START_PUSH);\n      GET_MEMNUM_INC(mem, p);\n      STACK_PUSH_MEM_START(mem, s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_START:  MOP_IN(OP_MEMORY_START);\n      GET_MEMNUM_INC(mem, p);\n      mem_start_stk[mem] = (OnigStackIndex )((void* )s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_END_PUSH:  MOP_IN(OP_MEMORY_END_PUSH);\n      GET_MEMNUM_INC(mem, p);\n      STACK_PUSH_MEM_END(mem, s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_END:  MOP_IN(OP_MEMORY_END);\n      GET_MEMNUM_INC(mem, p);\n      mem_end_stk[mem] = (OnigStackIndex )((void* )s);\n      MOP_OUT;\n      continue;\n      break;\n\n#ifdef USE_SUBEXP_CALL\n    case OP_MEMORY_END_PUSH_REC:  MOP_IN(OP_MEMORY_END_PUSH_REC);\n      GET_MEMNUM_INC(mem, p);\n      STACK_GET_MEM_START(mem, stkp); /* should be before push mem-end. */\n      STACK_PUSH_MEM_END(mem, s);\n      mem_start_stk[mem] = GET_STACK_INDEX(stkp);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_END_REC:  MOP_IN(OP_MEMORY_END_REC);\n      GET_MEMNUM_INC(mem, p);\n      mem_end_stk[mem] = (OnigStackIndex )((void* )s);\n      STACK_GET_MEM_START(mem, stkp);\n\n      if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n        mem_start_stk[mem] = GET_STACK_INDEX(stkp);\n      else\n        mem_start_stk[mem] = (OnigStackIndex )((void* )stkp->u.mem.pstr);\n\n      STACK_PUSH_MEM_END_MARK(mem);\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n    case OP_BACKREF1:  MOP_IN(OP_BACKREF1);\n      mem = 1;\n      goto backref;\n      break;\n\n    case OP_BACKREF2:  MOP_IN(OP_BACKREF2);\n      mem = 2;\n      goto backref;\n      break;\n\n    case OP_BACKREFN:  MOP_IN(OP_BACKREFN);\n      GET_MEMNUM_INC(mem, p);\n    backref:\n      {\n        int len;\n        UChar *pstart, *pend;\n\n        /* if you want to remove following line, \n           you should check in parse and compile time. */\n        if (mem > num_mem) goto fail;\n        if (mem_end_stk[mem]   == INVALID_STACK_INDEX) goto fail;\n        if (mem_start_stk[mem] == INVALID_STACK_INDEX) goto fail;\n\n        if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n          pstart = STACK_AT(mem_start_stk[mem])->u.mem.pstr;\n        else\n          pstart = (UChar* )((void* )mem_start_stk[mem]);\n\n        pend = (BIT_STATUS_AT(reg->bt_mem_end, mem)\n                ? STACK_AT(mem_end_stk[mem])->u.mem.pstr\n                : (UChar* )((void* )mem_end_stk[mem]));\n        n = pend - pstart;\n        DATA_ENSURE(n);\n        sprev = s;\n        STRING_CMP(pstart, s, n);\n        while (sprev + (len = enclen(encode, sprev)) < s)\n          sprev += len;\n\n        MOP_OUT;\n        continue;\n      }\n      break;\n\n    case OP_BACKREFN_IC:  MOP_IN(OP_BACKREFN_IC);\n      GET_MEMNUM_INC(mem, p);\n      {\n        int len;\n        UChar *pstart, *pend;\n\n        /* if you want to remove following line, \n           you should check in parse and compile time. */\n        if (mem > num_mem) goto fail;\n        if (mem_end_stk[mem]   == INVALID_STACK_INDEX) goto fail;\n        if (mem_start_stk[mem] == INVALID_STACK_INDEX) goto fail;\n\n        if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n          pstart = STACK_AT(mem_start_stk[mem])->u.mem.pstr;\n        else\n          pstart = (UChar* )((void* )mem_start_stk[mem]);\n\n        pend = (BIT_STATUS_AT(reg->bt_mem_end, mem)\n                ? STACK_AT(mem_end_stk[mem])->u.mem.pstr\n                : (UChar* )((void* )mem_end_stk[mem]));\n        n = pend - pstart;\n        DATA_ENSURE(n);\n        sprev = s;\n        STRING_CMP_IC(case_fold_flag, pstart, &s, n);\n        while (sprev + (len = enclen(encode, sprev)) < s)\n          sprev += len;\n\n        MOP_OUT;\n        continue;\n      }\n      break;\n\n    case OP_BACKREF_MULTI:  MOP_IN(OP_BACKREF_MULTI);\n      {\n        int len, is_fail;\n        UChar *pstart, *pend, *swork;\n\n        GET_LENGTH_INC(tlen, p);\n        for (i = 0; i < tlen; i++) {\n          GET_MEMNUM_INC(mem, p);\n\n          if (mem_end_stk[mem]   == INVALID_STACK_INDEX) continue;\n          if (mem_start_stk[mem] == INVALID_STACK_INDEX) continue;\n\n          if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n            pstart = STACK_AT(mem_start_stk[mem])->u.mem.pstr;\n          else\n            pstart = (UChar* )((void* )mem_start_stk[mem]);\n\n          pend = (BIT_STATUS_AT(reg->bt_mem_end, mem)\n                  ? STACK_AT(mem_end_stk[mem])->u.mem.pstr\n                  : (UChar* )((void* )mem_end_stk[mem]));\n          n = pend - pstart;\n          DATA_ENSURE(n);\n          sprev = s;\n          swork = s;\n          STRING_CMP_VALUE(pstart, swork, n, is_fail);\n          if (is_fail) continue;\n          s = swork;\n          while (sprev + (len = enclen(encode, sprev)) < s)\n            sprev += len;\n\n          p += (SIZE_MEMNUM * (tlen - i - 1));\n          break; /* success */\n        }\n        if (i == tlen) goto fail;\n        MOP_OUT;\n        continue;\n      }\n      break;\n\n    case OP_BACKREF_MULTI_IC:  MOP_IN(OP_BACKREF_MULTI_IC);\n      {\n        int len, is_fail;\n        UChar *pstart, *pend, *swork;\n\n        GET_LENGTH_INC(tlen, p);\n        for (i = 0; i < tlen; i++) {\n          GET_MEMNUM_INC(mem, p);\n\n          if (mem_end_stk[mem]   == INVALID_STACK_INDEX) continue;\n          if (mem_start_stk[mem] == INVALID_STACK_INDEX) continue;\n\n          if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n            pstart = STACK_AT(mem_start_stk[mem])->u.mem.pstr;\n          else\n            pstart = (UChar* )((void* )mem_start_stk[mem]);\n\n          pend = (BIT_STATUS_AT(reg->bt_mem_end, mem)\n                  ? STACK_AT(mem_end_stk[mem])->u.mem.pstr\n                  : (UChar* )((void* )mem_end_stk[mem]));\n          n = pend - pstart;\n          DATA_ENSURE(n);\n          sprev = s;\n          swork = s;\n          STRING_CMP_VALUE_IC(case_fold_flag, pstart, &swork, n, is_fail);\n          if (is_fail) continue;\n          s = swork;\n          while (sprev + (len = enclen(encode, sprev)) < s)\n            sprev += len;\n\n          p += (SIZE_MEMNUM * (tlen - i - 1));\n          break; /* success */\n        }\n        if (i == tlen) goto fail;\n        MOP_OUT;\n        continue;\n      }\n      break;\n\n#ifdef USE_BACKREF_WITH_LEVEL\n    case OP_BACKREF_WITH_LEVEL:\n      {\n        int len;\n        OnigOptionType ic;\n        LengthType level;\n\n        GET_OPTION_INC(ic,    p);\n        GET_LENGTH_INC(level, p);\n        GET_LENGTH_INC(tlen,  p);\n\n        sprev = s;\n        if (backref_match_at_nested_level(reg, stk, stk_base, ic\n                     , case_fold_flag, (int )level, (int )tlen, p, &s, end)) {\n          while (sprev + (len = enclen(encode, sprev)) < s)\n            sprev += len;\n\n          p += (SIZE_MEMNUM * tlen);\n        }\n        else\n          goto fail;\n\n        MOP_OUT;\n        continue;\n      }\n      break;\n#endif\n\n#if 0   /* no need: IS_DYNAMIC_OPTION() == 0 */\n    case OP_SET_OPTION_PUSH:  MOP_IN(OP_SET_OPTION_PUSH);\n      GET_OPTION_INC(option, p);\n      STACK_PUSH_ALT(p, s, sprev);\n      p += SIZE_OP_SET_OPTION + SIZE_OP_FAIL;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_SET_OPTION:  MOP_IN(OP_SET_OPTION);\n      GET_OPTION_INC(option, p);\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n    case OP_NULL_CHECK_START:  MOP_IN(OP_NULL_CHECK_START);\n      GET_MEMNUM_INC(mem, p);    /* mem: null check id */\n      STACK_PUSH_NULL_CHECK_START(mem, s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_NULL_CHECK_END:  MOP_IN(OP_NULL_CHECK_END);\n      {\n        int isnull;\n\n        GET_MEMNUM_INC(mem, p); /* mem: null check id */\n        STACK_NULL_CHECK(isnull, mem, s);\n        if (isnull) {\n#ifdef ONIG_DEBUG_MATCH\n          fprintf(stderr, \"NULL_CHECK_END: skip  id:%d, s:%d\\n\",\n                  (int )mem, (int )s);\n#endif\n        null_check_found:\n          /* empty loop founded, skip next instruction */\n          switch (*p++) {\n          case OP_JUMP:\n          case OP_PUSH:\n            p += SIZE_RELADDR;\n            break;\n          case OP_REPEAT_INC:\n          case OP_REPEAT_INC_NG:\n          case OP_REPEAT_INC_SG:\n          case OP_REPEAT_INC_NG_SG:\n            p += SIZE_MEMNUM;\n            break;\n          default:\n            goto unexpected_bytecode_error;\n            break;\n          }\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n#ifdef USE_MONOMANIAC_CHECK_CAPTURES_IN_ENDLESS_REPEAT\n    case OP_NULL_CHECK_END_MEMST:  MOP_IN(OP_NULL_CHECK_END_MEMST);\n      {\n        int isnull;\n\n        GET_MEMNUM_INC(mem, p); /* mem: null check id */\n        STACK_NULL_CHECK_MEMST(isnull, mem, s, reg);\n        if (isnull) {\n#ifdef ONIG_DEBUG_MATCH\n          fprintf(stderr, \"NULL_CHECK_END_MEMST: skip  id:%d, s:%d\\n\",\n                  (int )mem, (int )s);\n#endif\n          if (isnull == -1) goto fail;\n          goto \tnull_check_found;\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n#ifdef USE_SUBEXP_CALL\n    case OP_NULL_CHECK_END_MEMST_PUSH:\n      MOP_IN(OP_NULL_CHECK_END_MEMST_PUSH);\n      {\n        int isnull;\n\n        GET_MEMNUM_INC(mem, p); /* mem: null check id */\n#ifdef USE_MONOMANIAC_CHECK_CAPTURES_IN_ENDLESS_REPEAT\n        STACK_NULL_CHECK_MEMST_REC(isnull, mem, s, reg);\n#else\n        STACK_NULL_CHECK_REC(isnull, mem, s);\n#endif\n        if (isnull) {\n#ifdef ONIG_DEBUG_MATCH\n          fprintf(stderr, \"NULL_CHECK_END_MEMST_PUSH: skip  id:%d, s:%d\\n\",\n                  (int )mem, (int )s);\n#endif\n          if (isnull == -1) goto fail;\n          goto \tnull_check_found;\n        }\n        else {\n          STACK_PUSH_NULL_CHECK_END(mem);\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n    case OP_JUMP:  MOP_IN(OP_JUMP);\n      GET_RELADDR_INC(addr, p);\n      p += addr;\n      MOP_OUT;\n      CHECK_INTERRUPT_IN_MATCH_AT;\n      continue;\n      break;\n\n    case OP_PUSH:  MOP_IN(OP_PUSH);\n      GET_RELADDR_INC(addr, p);\n      STACK_PUSH_ALT(p + addr, s, sprev);\n      MOP_OUT;\n      continue;\n      break;\n\n#ifdef USE_COMBINATION_EXPLOSION_CHECK\n    case OP_STATE_CHECK_PUSH:  MOP_IN(OP_STATE_CHECK_PUSH);\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      STATE_CHECK_VAL(scv, mem);\n      if (scv) goto fail;\n\n      GET_RELADDR_INC(addr, p);\n      STACK_PUSH_ALT_WITH_STATE_CHECK(p + addr, s, sprev, mem);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_STATE_CHECK_PUSH_OR_JUMP:  MOP_IN(OP_STATE_CHECK_PUSH_OR_JUMP);\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      GET_RELADDR_INC(addr, p);\n      STATE_CHECK_VAL(scv, mem);\n      if (scv) {\n        p += addr;\n      }\n      else {\n        STACK_PUSH_ALT_WITH_STATE_CHECK(p + addr, s, sprev, mem);\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_STATE_CHECK:  MOP_IN(OP_STATE_CHECK);\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      STATE_CHECK_VAL(scv, mem);\n      if (scv) goto fail;\n\n      STACK_PUSH_STATE_CHECK(s, mem);\n      MOP_OUT;\n      continue;\n      break;\n#endif /* USE_COMBINATION_EXPLOSION_CHECK */\n\n    case OP_POP:  MOP_IN(OP_POP);\n      STACK_POP_ONE;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_PUSH_OR_JUMP_EXACT1:  MOP_IN(OP_PUSH_OR_JUMP_EXACT1);\n      GET_RELADDR_INC(addr, p);\n      if (*p == *s && DATA_ENSURE_CHECK1) {\n        p++;\n        STACK_PUSH_ALT(p + addr, s, sprev);\n        MOP_OUT;\n        continue;\n      }\n      p += (addr + 1);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_PUSH_IF_PEEK_NEXT:  MOP_IN(OP_PUSH_IF_PEEK_NEXT);\n      GET_RELADDR_INC(addr, p);\n      if (*p == *s) {\n        p++;\n        STACK_PUSH_ALT(p + addr, s, sprev);\n        MOP_OUT;\n        continue;\n      }\n      p++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_REPEAT:  MOP_IN(OP_REPEAT);\n      {\n        GET_MEMNUM_INC(mem, p);    /* mem: OP_REPEAT ID */\n        GET_RELADDR_INC(addr, p);\n\n        STACK_ENSURE(1);\n        repeat_stk[mem] = GET_STACK_INDEX(stk);\n        STACK_PUSH_REPEAT(mem, p);\n\n        if (reg->repeat_range[mem].lower == 0) {\n          STACK_PUSH_ALT(p + addr, s, sprev);\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_REPEAT_NG:  MOP_IN(OP_REPEAT_NG);\n      {\n        GET_MEMNUM_INC(mem, p);    /* mem: OP_REPEAT ID */\n        GET_RELADDR_INC(addr, p);\n\n        STACK_ENSURE(1);\n        repeat_stk[mem] = GET_STACK_INDEX(stk);\n        STACK_PUSH_REPEAT(mem, p);\n\n        if (reg->repeat_range[mem].lower == 0) {\n          STACK_PUSH_ALT(p, s, sprev);\n          p += addr;\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_REPEAT_INC:  MOP_IN(OP_REPEAT_INC);\n      GET_MEMNUM_INC(mem, p); /* mem: OP_REPEAT ID */\n      si = repeat_stk[mem];\n      stkp = STACK_AT(si);\n\n    repeat_inc:\n      stkp->u.repeat.count++;\n      if (stkp->u.repeat.count >= reg->repeat_range[mem].upper) {\n        /* end of repeat. Nothing to do. */\n      }\n      else if (stkp->u.repeat.count >= reg->repeat_range[mem].lower) {\n        STACK_PUSH_ALT(p, s, sprev);\n        p = STACK_AT(si)->u.repeat.pcode; /* Don't use stkp after PUSH. */\n      }\n      else {\n        p = stkp->u.repeat.pcode;\n      }\n      STACK_PUSH_REPEAT_INC(si);\n      MOP_OUT;\n      CHECK_INTERRUPT_IN_MATCH_AT;\n      continue;\n      break;\n\n    case OP_REPEAT_INC_SG:  MOP_IN(OP_REPEAT_INC_SG);\n      GET_MEMNUM_INC(mem, p); /* mem: OP_REPEAT ID */\n      STACK_GET_REPEAT(mem, stkp);\n      si = GET_STACK_INDEX(stkp);\n      goto repeat_inc;\n      break;\n\n    case OP_REPEAT_INC_NG:  MOP_IN(OP_REPEAT_INC_NG);\n      GET_MEMNUM_INC(mem, p); /* mem: OP_REPEAT ID */\n      si = repeat_stk[mem];\n      stkp = STACK_AT(si);\n\n    repeat_inc_ng:\n      stkp->u.repeat.count++;\n      if (stkp->u.repeat.count < reg->repeat_range[mem].upper) {\n        if (stkp->u.repeat.count >= reg->repeat_range[mem].lower) {\n          UChar* pcode = stkp->u.repeat.pcode;\n\n          STACK_PUSH_REPEAT_INC(si);\n          STACK_PUSH_ALT(pcode, s, sprev);\n        }\n        else {\n          p = stkp->u.repeat.pcode;\n          STACK_PUSH_REPEAT_INC(si);\n        }\n      }\n      else if (stkp->u.repeat.count == reg->repeat_range[mem].upper) {\n        STACK_PUSH_REPEAT_INC(si);\n      }\n      MOP_OUT;\n      CHECK_INTERRUPT_IN_MATCH_AT;\n      continue;\n      break;\n\n    case OP_REPEAT_INC_NG_SG:  MOP_IN(OP_REPEAT_INC_NG_SG);\n      GET_MEMNUM_INC(mem, p); /* mem: OP_REPEAT ID */\n      STACK_GET_REPEAT(mem, stkp);\n      si = GET_STACK_INDEX(stkp);\n      goto repeat_inc_ng;\n      break;\n\n    case OP_PUSH_POS:  MOP_IN(OP_PUSH_POS);\n      STACK_PUSH_POS(s, sprev);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_POP_POS:  MOP_IN(OP_POP_POS);\n      {\n        STACK_POS_END(stkp);\n        s     = stkp->u.state.pstr;\n        sprev = stkp->u.state.pstr_prev;\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_PUSH_POS_NOT:  MOP_IN(OP_PUSH_POS_NOT);\n      GET_RELADDR_INC(addr, p);\n      STACK_PUSH_POS_NOT(p + addr, s, sprev);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_FAIL_POS:  MOP_IN(OP_FAIL_POS);\n      STACK_POP_TIL_POS_NOT;\n      goto fail;\n      break;\n\n    case OP_PUSH_STOP_BT:  MOP_IN(OP_PUSH_STOP_BT);\n      STACK_PUSH_STOP_BT;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_POP_STOP_BT:  MOP_IN(OP_POP_STOP_BT);\n      STACK_STOP_BT_END;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_LOOK_BEHIND:  MOP_IN(OP_LOOK_BEHIND);\n      GET_LENGTH_INC(tlen, p);\n      s = (UChar* )ONIGENC_STEP_BACK(encode, str, s, (int )tlen);\n      if (IS_NULL(s)) goto fail;\n      sprev = (UChar* )onigenc_get_prev_char_head(encode, str, s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_PUSH_LOOK_BEHIND_NOT:  MOP_IN(OP_PUSH_LOOK_BEHIND_NOT);\n      GET_RELADDR_INC(addr, p);\n      GET_LENGTH_INC(tlen, p);\n      q = (UChar* )ONIGENC_STEP_BACK(encode, str, s, (int )tlen);\n      if (IS_NULL(q)) {\n        /* too short case -> success. ex. /(?<!XXX)a/.match(\"a\")\n           If you want to change to fail, replace following line. */\n        p += addr;\n        /* goto fail; */\n      }\n      else {\n        STACK_PUSH_LOOK_BEHIND_NOT(p + addr, s, sprev);\n        s = q;\n        sprev = (UChar* )onigenc_get_prev_char_head(encode, str, s);\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_FAIL_LOOK_BEHIND_NOT:  MOP_IN(OP_FAIL_LOOK_BEHIND_NOT);\n      STACK_POP_TIL_LOOK_BEHIND_NOT;\n      goto fail;\n      break;\n\n#ifdef USE_SUBEXP_CALL\n    case OP_CALL:  MOP_IN(OP_CALL);\n      GET_ABSADDR_INC(addr, p);\n      STACK_PUSH_CALL_FRAME(p);\n      p = reg->p + addr;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_RETURN:  MOP_IN(OP_RETURN);\n      STACK_RETURN(p);\n      STACK_PUSH_RETURN;\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n    case OP_FINISH:\n      goto finish;\n      break;\n\n    fail:\n      MOP_OUT;\n      /* fall */\n    case OP_FAIL:  MOP_IN(OP_FAIL);\n      STACK_POP;\n      p     = stk->u.state.pcode;\n      s     = stk->u.state.pstr;\n      sprev = stk->u.state.pstr_prev;\n\n#ifdef USE_COMBINATION_EXPLOSION_CHECK\n      if (stk->u.state.state_check != 0) {\n        stk->type = STK_STATE_CHECK_MARK;\n        stk++;\n      }\n#endif\n\n      MOP_OUT;\n      continue;\n      break;\n\n    default:\n      goto bytecode_error;\n\n    } /* end of switch */\n    sprev = sbegin;\n  } /* end of while(1) */\n\n finish:\n  STACK_SAVE;\n  return best_len;\n\n#ifdef ONIG_DEBUG\n stack_error:\n  STACK_SAVE;\n  return ONIGERR_STACK_BUG;\n#endif\n\n bytecode_error:\n  STACK_SAVE;\n  return ONIGERR_UNDEFINED_BYTECODE;\n\n unexpected_bytecode_error:\n  STACK_SAVE;\n  return ONIGERR_UNEXPECTED_BYTECODE;\n}", "func_src_after": "match_at(regex_t* reg, const UChar* str, const UChar* end,\n#ifdef USE_MATCH_RANGE_MUST_BE_INSIDE_OF_SPECIFIED_RANGE\n\t const UChar* right_range,\n#endif\n\t const UChar* sstart, UChar* sprev, OnigMatchArg* msa)\n{\n  static UChar FinishCode[] = { OP_FINISH };\n\n  int i, n, num_mem, best_len, pop_level;\n  LengthType tlen, tlen2;\n  MemNumType mem;\n  RelAddrType addr;\n  UChar *s, *q, *sbegin;\n  int is_alloca;\n  char *alloc_base;\n  OnigStackType *stk_base, *stk, *stk_end;\n  OnigStackType *stkp; /* used as any purpose. */\n  OnigStackIndex si;\n  OnigStackIndex *repeat_stk;\n  OnigStackIndex *mem_start_stk, *mem_end_stk;\n#ifdef USE_COMBINATION_EXPLOSION_CHECK\n  int scv;\n  unsigned char* state_check_buff = msa->state_check_buff;\n  int num_comb_exp_check = reg->num_comb_exp_check;\n#endif\n  UChar *p = reg->p;\n  OnigOptionType option = reg->options;\n  OnigEncoding encode = reg->enc;\n  OnigCaseFoldType case_fold_flag = reg->case_fold_flag;\n\n  //n = reg->num_repeat + reg->num_mem * 2;\n  pop_level = reg->stack_pop_level;\n  num_mem = reg->num_mem;\n  STACK_INIT(INIT_MATCH_STACK_SIZE);\n  UPDATE_FOR_STACK_REALLOC;\n  for (i = 1; i <= num_mem; i++) {\n    mem_start_stk[i] = mem_end_stk[i] = INVALID_STACK_INDEX;\n  }\n\n#ifdef ONIG_DEBUG_MATCH\n  fprintf(stderr, \"match_at: str: %d, end: %d, start: %d, sprev: %d\\n\",\n\t  (int )str, (int )end, (int )sstart, (int )sprev);\n  fprintf(stderr, \"size: %d, start offset: %d\\n\",\n\t  (int )(end - str), (int )(sstart - str));\n#endif\n\n  STACK_PUSH_ENSURED(STK_ALT, FinishCode);  /* bottom stack */\n  best_len = ONIG_MISMATCH;\n  s = (UChar* )sstart;\n  while (1) {\n#ifdef ONIG_DEBUG_MATCH\n    {\n      UChar *q, *bp, buf[50];\n      int len;\n      fprintf(stderr, \"%4d> \\\"\", (int )(s - str));\n      bp = buf;\n      for (i = 0, q = s; i < 7 && q < end; i++) {\n\tlen = enclen(encode, q);\n\twhile (len-- > 0) *bp++ = *q++;\n      }\n      if (q < end) { xmemcpy(bp, \"...\\\"\", 4); bp += 4; }\n      else         { xmemcpy(bp, \"\\\"\",    1); bp += 1; }\n      *bp = 0;\n      fputs((char* )buf, stderr);\n      for (i = 0; i < 20 - (bp - buf); i++) fputc(' ', stderr);\n      onig_print_compiled_byte_code(stderr, p, NULL, encode);\n      fprintf(stderr, \"\\n\");\n    }\n#endif\n\n    sbegin = s;\n    switch (*p++) {\n    case OP_END:  MOP_IN(OP_END);\n      n = s - sstart;\n      if (n > best_len) {\n        OnigRegion* region;\n#ifdef USE_FIND_LONGEST_SEARCH_ALL_OF_RANGE\n        if (IS_FIND_LONGEST(option)) {\n          if (n > msa->best_len) {\n            msa->best_len = n;\n            msa->best_s   = (UChar* )sstart;\n          }\n          else\n            goto end_best_len;\n        }\n#endif\n        best_len = n;\n        region = msa->region;\n        if (region) {\n#ifdef USE_POSIX_API_REGION_OPTION\n          if (IS_POSIX_REGION(msa->options)) {\n            posix_regmatch_t* rmt = (posix_regmatch_t* )region;\n\n            rmt[0].rm_so = sstart - str;\n            rmt[0].rm_eo = s      - str;\n            for (i = 1; i <= num_mem; i++) {\n              if (mem_end_stk[i] != INVALID_STACK_INDEX) {\n                if (BIT_STATUS_AT(reg->bt_mem_start, i))\n                  rmt[i].rm_so = STACK_AT(mem_start_stk[i])->u.mem.pstr - str;\n                else\n                  rmt[i].rm_so = (UChar* )((void* )(mem_start_stk[i])) - str;\n\n                rmt[i].rm_eo = (BIT_STATUS_AT(reg->bt_mem_end, i)\n                                ? STACK_AT(mem_end_stk[i])->u.mem.pstr\n                                : (UChar* )((void* )mem_end_stk[i])) - str;\n              }\n              else {\n                rmt[i].rm_so = rmt[i].rm_eo = ONIG_REGION_NOTPOS;\n              }\n            }\n          }\n          else {\n#endif /* USE_POSIX_API_REGION_OPTION */\n            region->beg[0] = sstart - str;\n            region->end[0] = s      - str;\n            for (i = 1; i <= num_mem; i++) {\n              if (mem_end_stk[i] != INVALID_STACK_INDEX) {\n                if (BIT_STATUS_AT(reg->bt_mem_start, i))\n                  region->beg[i] = STACK_AT(mem_start_stk[i])->u.mem.pstr - str;\n                else\n                  region->beg[i] = (UChar* )((void* )mem_start_stk[i]) - str;\n\n                region->end[i] = (BIT_STATUS_AT(reg->bt_mem_end, i)\n                                  ? STACK_AT(mem_end_stk[i])->u.mem.pstr\n                                  : (UChar* )((void* )mem_end_stk[i])) - str;\n              }\n              else {\n                region->beg[i] = region->end[i] = ONIG_REGION_NOTPOS;\n              }\n            }\n\n#ifdef USE_CAPTURE_HISTORY\n            if (reg->capture_history != 0) {\n              int r;\n              OnigCaptureTreeNode* node;\n\n              if (IS_NULL(region->history_root)) {\n                region->history_root = node = history_node_new();\n                CHECK_NULL_RETURN_MEMERR(node);\n              }\n              else {\n                node = region->history_root;\n                history_tree_clear(node);\n              }\n\n              node->group = 0;\n              node->beg   = sstart - str;\n              node->end   = s      - str;\n\n              stkp = stk_base;\n              r = make_capture_history_tree(region->history_root, &stkp,\n                                            stk, (UChar* )str, reg);\n              if (r < 0) {\n                best_len = r; /* error code */\n                goto finish;\n              }\n            }\n#endif /* USE_CAPTURE_HISTORY */\n#ifdef USE_POSIX_API_REGION_OPTION\n          } /* else IS_POSIX_REGION() */\n#endif\n        } /* if (region) */\n      } /* n > best_len */\n\n#ifdef USE_FIND_LONGEST_SEARCH_ALL_OF_RANGE\n    end_best_len:\n#endif\n      MOP_OUT;\n\n      if (IS_FIND_CONDITION(option)) {\n        if (IS_FIND_NOT_EMPTY(option) && s == sstart) {\n          best_len = ONIG_MISMATCH;\n          goto fail; /* for retry */\n        }\n        if (IS_FIND_LONGEST(option) && DATA_ENSURE_CHECK1) {\n          goto fail; /* for retry */\n        }\n      }\n\n      /* default behavior: return first-matching result. */\n      goto finish;\n      break;\n\n    case OP_EXACT1:  MOP_IN(OP_EXACT1);\n      DATA_ENSURE(1);\n      if (*p != *s) goto fail;\n      p++; s++;\n      MOP_OUT;\n      break;\n\n    case OP_EXACT1_IC:  MOP_IN(OP_EXACT1_IC);\n      {\n        int len;\n        UChar *q, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n        DATA_ENSURE(1);\n        len = ONIGENC_MBC_CASE_FOLD(encode,\n                 /* DISABLE_CASE_FOLD_MULTI_CHAR(case_fold_flag), */\n                                    case_fold_flag,\n                                    &s, end, lowbuf);\n        DATA_ENSURE(0);\n        q = lowbuf;\n        while (len-- > 0) {\n          if (*p != *q) {\n            goto fail;\n          }\n          p++; q++;\n        }\n      }\n      MOP_OUT;\n      break;\n\n    case OP_EXACT2:  MOP_IN(OP_EXACT2);\n      DATA_ENSURE(2);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      sprev = s;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACT3:  MOP_IN(OP_EXACT3);\n      DATA_ENSURE(3);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      sprev = s;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACT4:  MOP_IN(OP_EXACT4);\n      DATA_ENSURE(4);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      sprev = s;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACT5:  MOP_IN(OP_EXACT5);\n      DATA_ENSURE(5);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      sprev = s;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTN:  MOP_IN(OP_EXACTN);\n      GET_LENGTH_INC(tlen, p);\n      DATA_ENSURE(tlen);\n      while (tlen-- > 0) {\n        if (*p++ != *s++) goto fail;\n      }\n      sprev = s - 1;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTN_IC:  MOP_IN(OP_EXACTN_IC);\n      {\n        int len;\n        UChar *q, *endp, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n        GET_LENGTH_INC(tlen, p);\n        endp = p + tlen;\n\n        while (p < endp) {\n          sprev = s;\n          DATA_ENSURE(1);\n          len = ONIGENC_MBC_CASE_FOLD(encode,\n                        /* DISABLE_CASE_FOLD_MULTI_CHAR(case_fold_flag), */\n                                      case_fold_flag,\n                                      &s, end, lowbuf);\n          DATA_ENSURE(0);\n          q = lowbuf;\n          while (len-- > 0) {\n            if (*p != *q) goto fail;\n            p++; q++;\n          }\n        }\n      }\n\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMB2N1:  MOP_IN(OP_EXACTMB2N1);\n      DATA_ENSURE(2);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      MOP_OUT;\n      break;\n\n    case OP_EXACTMB2N2:  MOP_IN(OP_EXACTMB2N2);\n      DATA_ENSURE(4);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      sprev = s;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMB2N3:  MOP_IN(OP_EXACTMB2N3);\n      DATA_ENSURE(6);\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      sprev = s;\n      if (*p != *s) goto fail;\n      p++; s++;\n      if (*p != *s) goto fail;\n      p++; s++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMB2N:  MOP_IN(OP_EXACTMB2N);\n      GET_LENGTH_INC(tlen, p);\n      DATA_ENSURE(tlen * 2);\n      while (tlen-- > 0) {\n        if (*p != *s) goto fail;\n        p++; s++;\n        if (*p != *s) goto fail;\n        p++; s++;\n      }\n      sprev = s - 2;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMB3N:  MOP_IN(OP_EXACTMB3N);\n      GET_LENGTH_INC(tlen, p);\n      DATA_ENSURE(tlen * 3);\n      while (tlen-- > 0) {\n        if (*p != *s) goto fail;\n        p++; s++;\n        if (*p != *s) goto fail;\n        p++; s++;\n        if (*p != *s) goto fail;\n        p++; s++;\n      }\n      sprev = s - 3;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_EXACTMBN:  MOP_IN(OP_EXACTMBN);\n      GET_LENGTH_INC(tlen,  p);  /* mb-len */\n      GET_LENGTH_INC(tlen2, p);  /* string len */\n      tlen2 *= tlen;\n      DATA_ENSURE(tlen2);\n      while (tlen2-- > 0) {\n        if (*p != *s) goto fail;\n        p++; s++;\n      }\n      sprev = s - tlen;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_CCLASS:  MOP_IN(OP_CCLASS);\n      DATA_ENSURE(1);\n      if (BITSET_AT(((BitSetRef )p), *s) == 0) goto fail;\n      p += SIZE_BITSET;\n      s += enclen(encode, s);   /* OP_CCLASS can match mb-code. \\D, \\S */\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_MB:  MOP_IN(OP_CCLASS_MB);\n      if (! ONIGENC_IS_MBC_HEAD(encode, s)) goto fail;\n\n    cclass_mb:\n      GET_LENGTH_INC(tlen, p);\n      {\n        OnigCodePoint code;\n        UChar *ss;\n        int mb_len;\n\n        DATA_ENSURE(1);\n        mb_len = enclen(encode, s);\n        DATA_ENSURE(mb_len);\n        ss = s;\n        s += mb_len;\n        code = ONIGENC_MBC_TO_CODE(encode, ss, s);\n\n#ifdef PLATFORM_UNALIGNED_WORD_ACCESS\n        if (! onig_is_in_code_range(p, code)) goto fail;\n#else\n        q = p;\n        ALIGNMENT_RIGHT(q);\n        if (! onig_is_in_code_range(q, code)) goto fail;\n#endif\n      }\n      p += tlen;\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_MIX:  MOP_IN(OP_CCLASS_MIX);\n      DATA_ENSURE(1);\n      if (ONIGENC_IS_MBC_HEAD(encode, s)) {\n        p += SIZE_BITSET;\n        goto cclass_mb;\n      }\n      else {\n        if (BITSET_AT(((BitSetRef )p), *s) == 0)\n          goto fail;\n\n        p += SIZE_BITSET;\n        GET_LENGTH_INC(tlen, p);\n        p += tlen;\n        s++;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_NOT:  MOP_IN(OP_CCLASS_NOT);\n      DATA_ENSURE(1);\n      if (BITSET_AT(((BitSetRef )p), *s) != 0) goto fail;\n      p += SIZE_BITSET;\n      s += enclen(encode, s);\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_MB_NOT:  MOP_IN(OP_CCLASS_MB_NOT);\n      DATA_ENSURE(1);\n      if (! ONIGENC_IS_MBC_HEAD(encode, s)) {\n        s++;\n        GET_LENGTH_INC(tlen, p);\n        p += tlen;\n        goto cc_mb_not_success;\n      }\n\n    cclass_mb_not:\n      GET_LENGTH_INC(tlen, p);\n      {\n        OnigCodePoint code;\n        UChar *ss;\n        int mb_len = enclen(encode, s);\n\n        if (! DATA_ENSURE_CHECK(mb_len)) {\n          DATA_ENSURE(1);\n          s = (UChar* )end;\n          p += tlen;\n          goto cc_mb_not_success;\n        }\n\n        ss = s;\n        s += mb_len;\n        code = ONIGENC_MBC_TO_CODE(encode, ss, s);\n\n#ifdef PLATFORM_UNALIGNED_WORD_ACCESS\n        if (onig_is_in_code_range(p, code)) goto fail;\n#else\n        q = p;\n        ALIGNMENT_RIGHT(q);\n        if (onig_is_in_code_range(q, code)) goto fail;\n#endif\n      }\n      p += tlen;\n\n    cc_mb_not_success:\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_MIX_NOT:  MOP_IN(OP_CCLASS_MIX_NOT);\n      DATA_ENSURE(1);\n      if (ONIGENC_IS_MBC_HEAD(encode, s)) {\n        p += SIZE_BITSET;\n        goto cclass_mb_not;\n      }\n      else {\n        if (BITSET_AT(((BitSetRef )p), *s) != 0)\n          goto fail;\n\n        p += SIZE_BITSET;\n        GET_LENGTH_INC(tlen, p);\n        p += tlen;\n        s++;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_CCLASS_NODE:  MOP_IN(OP_CCLASS_NODE);\n      {\n        OnigCodePoint code;\n        void *node;\n        int mb_len;\n        UChar *ss;\n\n        DATA_ENSURE(1);\n        GET_POINTER_INC(node, p);\n        mb_len = enclen(encode, s);\n        ss = s;\n        s += mb_len;\n        DATA_ENSURE(0);\n        code = ONIGENC_MBC_TO_CODE(encode, ss, s);\n        if (onig_is_code_in_cc_len(mb_len, code, node) == 0) goto fail;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR:  MOP_IN(OP_ANYCHAR);\n      DATA_ENSURE(1);\n      n = enclen(encode, s);\n      DATA_ENSURE(n);\n      if (ONIGENC_IS_MBC_NEWLINE(encode, s, end)) goto fail;\n      s += n;\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_ML:  MOP_IN(OP_ANYCHAR_ML);\n      DATA_ENSURE(1);\n      n = enclen(encode, s);\n      DATA_ENSURE(n);\n      s += n;\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_STAR:  MOP_IN(OP_ANYCHAR_STAR);\n      while (DATA_ENSURE_CHECK1) {\n        STACK_PUSH_ALT(p, s, sprev);\n        n = enclen(encode, s);\n        DATA_ENSURE(n);\n        if (ONIGENC_IS_MBC_NEWLINE(encode, s, end))  goto fail;\n        sprev = s;\n        s += n;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_ML_STAR:  MOP_IN(OP_ANYCHAR_ML_STAR);\n      while (DATA_ENSURE_CHECK1) {\n        STACK_PUSH_ALT(p, s, sprev);\n        n = enclen(encode, s);\n        if (n > 1) {\n          DATA_ENSURE(n);\n          sprev = s;\n          s += n;\n        }\n        else {\n          sprev = s;\n          s++;\n        }\n      }\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_STAR_PEEK_NEXT:  MOP_IN(OP_ANYCHAR_STAR_PEEK_NEXT);\n      while (DATA_ENSURE_CHECK1) {\n        if (*p == *s) {\n          STACK_PUSH_ALT(p + 1, s, sprev);\n        }\n        n = enclen(encode, s);\n        DATA_ENSURE(n);\n        if (ONIGENC_IS_MBC_NEWLINE(encode, s, end))  goto fail;\n        sprev = s;\n        s += n;\n      }\n      p++;\n      MOP_OUT;\n      break;\n\n    case OP_ANYCHAR_ML_STAR_PEEK_NEXT:MOP_IN(OP_ANYCHAR_ML_STAR_PEEK_NEXT);\n      while (DATA_ENSURE_CHECK1) {\n        if (*p == *s) {\n          STACK_PUSH_ALT(p + 1, s, sprev);\n        }\n        n = enclen(encode, s);\n        if (n > 1) {\n          DATA_ENSURE(n);\n          sprev = s;\n          s += n;\n        }\n        else {\n          sprev = s;\n          s++;\n        }\n      }\n      p++;\n      MOP_OUT;\n      break;\n\n#ifdef USE_COMBINATION_EXPLOSION_CHECK\n    case OP_STATE_CHECK_ANYCHAR_STAR:  MOP_IN(OP_STATE_CHECK_ANYCHAR_STAR);\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      while (DATA_ENSURE_CHECK1) {\n        STATE_CHECK_VAL(scv, mem);\n        if (scv) goto fail;\n\n        STACK_PUSH_ALT_WITH_STATE_CHECK(p, s, sprev, mem);\n        n = enclen(encode, s);\n        DATA_ENSURE(n);\n        if (ONIGENC_IS_MBC_NEWLINE(encode, s, end))  goto fail;\n        sprev = s;\n        s += n;\n      }\n      MOP_OUT;\n      break;\n\n    case OP_STATE_CHECK_ANYCHAR_ML_STAR:\n      MOP_IN(OP_STATE_CHECK_ANYCHAR_ML_STAR);\n\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      while (DATA_ENSURE_CHECK1) {\n        STATE_CHECK_VAL(scv, mem);\n        if (scv) goto fail;\n\n        STACK_PUSH_ALT_WITH_STATE_CHECK(p, s, sprev, mem);\n        n = enclen(encode, s);\n        if (n > 1) {\n          DATA_ENSURE(n);\n          sprev = s;\n          s += n;\n        }\n        else {\n          sprev = s;\n          s++;\n        }\n      }\n      MOP_OUT;\n      break;\n#endif /* USE_COMBINATION_EXPLOSION_CHECK */\n\n    case OP_WORD:  MOP_IN(OP_WORD);\n      DATA_ENSURE(1);\n      if (! ONIGENC_IS_MBC_WORD(encode, s, end))\n        goto fail;\n\n      s += enclen(encode, s);\n      MOP_OUT;\n      break;\n\n    case OP_NOT_WORD:  MOP_IN(OP_NOT_WORD);\n      DATA_ENSURE(1);\n      if (ONIGENC_IS_MBC_WORD(encode, s, end))\n        goto fail;\n\n      s += enclen(encode, s);\n      MOP_OUT;\n      break;\n\n    case OP_WORD_BOUND:  MOP_IN(OP_WORD_BOUND);\n      if (ON_STR_BEGIN(s)) {\n        DATA_ENSURE(1);\n        if (! ONIGENC_IS_MBC_WORD(encode, s, end))\n          goto fail;\n      }\n      else if (ON_STR_END(s)) {\n        if (! ONIGENC_IS_MBC_WORD(encode, sprev, end))\n          goto fail;\n      }\n      else {\n        if (ONIGENC_IS_MBC_WORD(encode, s, end)\n            == ONIGENC_IS_MBC_WORD(encode, sprev, end))\n          goto fail;\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_NOT_WORD_BOUND:  MOP_IN(OP_NOT_WORD_BOUND);\n      if (ON_STR_BEGIN(s)) {\n        if (DATA_ENSURE_CHECK1 && ONIGENC_IS_MBC_WORD(encode, s, end))\n          goto fail;\n      }\n      else if (ON_STR_END(s)) {\n        if (ONIGENC_IS_MBC_WORD(encode, sprev, end))\n          goto fail;\n      }\n      else {\n        if (ONIGENC_IS_MBC_WORD(encode, s, end)\n            != ONIGENC_IS_MBC_WORD(encode, sprev, end))\n          goto fail;\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n#ifdef USE_WORD_BEGIN_END\n    case OP_WORD_BEGIN:  MOP_IN(OP_WORD_BEGIN);\n      if (DATA_ENSURE_CHECK1 && ONIGENC_IS_MBC_WORD(encode, s, end)) {\n        if (ON_STR_BEGIN(s) || !ONIGENC_IS_MBC_WORD(encode, sprev, end)) {\n          MOP_OUT;\n          continue;\n        }\n      }\n      goto fail;\n      break;\n\n    case OP_WORD_END:  MOP_IN(OP_WORD_END);\n      if (!ON_STR_BEGIN(s) && ONIGENC_IS_MBC_WORD(encode, sprev, end)) {\n        if (ON_STR_END(s) || !ONIGENC_IS_MBC_WORD(encode, s, end)) {\n          MOP_OUT;\n          continue;\n        }\n      }\n      goto fail;\n      break;\n#endif\n\n    case OP_BEGIN_BUF:  MOP_IN(OP_BEGIN_BUF);\n      if (! ON_STR_BEGIN(s)) goto fail;\n\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_END_BUF:  MOP_IN(OP_END_BUF);\n      if (! ON_STR_END(s)) goto fail;\n\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_BEGIN_LINE:  MOP_IN(OP_BEGIN_LINE);\n      if (ON_STR_BEGIN(s)) {\n        if (IS_NOTBOL(msa->options)) goto fail;\n        MOP_OUT;\n        continue;\n      }\n      else if (ONIGENC_IS_MBC_NEWLINE(encode, sprev, end) && !ON_STR_END(s)) {\n        MOP_OUT;\n        continue;\n      }\n      goto fail;\n      break;\n\n    case OP_END_LINE:  MOP_IN(OP_END_LINE);\n      if (ON_STR_END(s)) {\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n        if (IS_EMPTY_STR || !ONIGENC_IS_MBC_NEWLINE(encode, sprev, end)) {\n#endif\n          if (IS_NOTEOL(msa->options)) goto fail;\n          MOP_OUT;\n          continue;\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n        }\n#endif\n      }\n      else if (ONIGENC_IS_MBC_NEWLINE(encode, s, end)) {\n        MOP_OUT;\n        continue;\n      }\n#ifdef USE_CRNL_AS_LINE_TERMINATOR\n      else if (ONIGENC_IS_MBC_CRNL(encode, s, end)) {\n        MOP_OUT;\n        continue;\n      }\n#endif\n      goto fail;\n      break;\n\n    case OP_SEMI_END_BUF:  MOP_IN(OP_SEMI_END_BUF);\n      if (ON_STR_END(s)) {\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n        if (IS_EMPTY_STR || !ONIGENC_IS_MBC_NEWLINE(encode, sprev, end)) {\n#endif\n          if (IS_NOTEOL(msa->options)) goto fail;\n          MOP_OUT;\n          continue;\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n        }\n#endif\n      }\n      else if (ONIGENC_IS_MBC_NEWLINE(encode, s, end) &&\n               ON_STR_END(s + enclen(encode, s))) {\n        MOP_OUT;\n        continue;\n      }\n#ifdef USE_CRNL_AS_LINE_TERMINATOR\n      else if (ONIGENC_IS_MBC_CRNL(encode, s, end)) {\n        UChar* ss = s + enclen(encode, s);\n        ss += enclen(encode, ss);\n        if (ON_STR_END(ss)) {\n          MOP_OUT;\n          continue;\n        }\n      }\n#endif\n      goto fail;\n      break;\n\n    case OP_BEGIN_POSITION:  MOP_IN(OP_BEGIN_POSITION);\n      if (s != msa->start)\n        goto fail;\n\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_START_PUSH:  MOP_IN(OP_MEMORY_START_PUSH);\n      GET_MEMNUM_INC(mem, p);\n      STACK_PUSH_MEM_START(mem, s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_START:  MOP_IN(OP_MEMORY_START);\n      GET_MEMNUM_INC(mem, p);\n      mem_start_stk[mem] = (OnigStackIndex )((void* )s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_END_PUSH:  MOP_IN(OP_MEMORY_END_PUSH);\n      GET_MEMNUM_INC(mem, p);\n      STACK_PUSH_MEM_END(mem, s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_END:  MOP_IN(OP_MEMORY_END);\n      GET_MEMNUM_INC(mem, p);\n      mem_end_stk[mem] = (OnigStackIndex )((void* )s);\n      MOP_OUT;\n      continue;\n      break;\n\n#ifdef USE_SUBEXP_CALL\n    case OP_MEMORY_END_PUSH_REC:  MOP_IN(OP_MEMORY_END_PUSH_REC);\n      GET_MEMNUM_INC(mem, p);\n      STACK_GET_MEM_START(mem, stkp); /* should be before push mem-end. */\n      STACK_PUSH_MEM_END(mem, s);\n      mem_start_stk[mem] = GET_STACK_INDEX(stkp);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_MEMORY_END_REC:  MOP_IN(OP_MEMORY_END_REC);\n      GET_MEMNUM_INC(mem, p);\n      mem_end_stk[mem] = (OnigStackIndex )((void* )s);\n      STACK_GET_MEM_START(mem, stkp);\n\n      if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n        mem_start_stk[mem] = GET_STACK_INDEX(stkp);\n      else\n        mem_start_stk[mem] = (OnigStackIndex )((void* )stkp->u.mem.pstr);\n\n      STACK_PUSH_MEM_END_MARK(mem);\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n    case OP_BACKREF1:  MOP_IN(OP_BACKREF1);\n      mem = 1;\n      goto backref;\n      break;\n\n    case OP_BACKREF2:  MOP_IN(OP_BACKREF2);\n      mem = 2;\n      goto backref;\n      break;\n\n    case OP_BACKREFN:  MOP_IN(OP_BACKREFN);\n      GET_MEMNUM_INC(mem, p);\n    backref:\n      {\n        int len;\n        UChar *pstart, *pend;\n\n        /* if you want to remove following line, \n           you should check in parse and compile time. */\n        if (mem > num_mem) goto fail;\n        if (mem_end_stk[mem]   == INVALID_STACK_INDEX) goto fail;\n        if (mem_start_stk[mem] == INVALID_STACK_INDEX) goto fail;\n\n        if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n          pstart = STACK_AT(mem_start_stk[mem])->u.mem.pstr;\n        else\n          pstart = (UChar* )((void* )mem_start_stk[mem]);\n\n        pend = (BIT_STATUS_AT(reg->bt_mem_end, mem)\n                ? STACK_AT(mem_end_stk[mem])->u.mem.pstr\n                : (UChar* )((void* )mem_end_stk[mem]));\n        n = pend - pstart;\n        DATA_ENSURE(n);\n        sprev = s;\n        STRING_CMP(pstart, s, n);\n        while (sprev + (len = enclen(encode, sprev)) < s)\n          sprev += len;\n\n        MOP_OUT;\n        continue;\n      }\n      break;\n\n    case OP_BACKREFN_IC:  MOP_IN(OP_BACKREFN_IC);\n      GET_MEMNUM_INC(mem, p);\n      {\n        int len;\n        UChar *pstart, *pend;\n\n        /* if you want to remove following line, \n           you should check in parse and compile time. */\n        if (mem > num_mem) goto fail;\n        if (mem_end_stk[mem]   == INVALID_STACK_INDEX) goto fail;\n        if (mem_start_stk[mem] == INVALID_STACK_INDEX) goto fail;\n\n        if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n          pstart = STACK_AT(mem_start_stk[mem])->u.mem.pstr;\n        else\n          pstart = (UChar* )((void* )mem_start_stk[mem]);\n\n        pend = (BIT_STATUS_AT(reg->bt_mem_end, mem)\n                ? STACK_AT(mem_end_stk[mem])->u.mem.pstr\n                : (UChar* )((void* )mem_end_stk[mem]));\n        n = pend - pstart;\n        DATA_ENSURE(n);\n        sprev = s;\n        STRING_CMP_IC(case_fold_flag, pstart, &s, n);\n        while (sprev + (len = enclen(encode, sprev)) < s)\n          sprev += len;\n\n        MOP_OUT;\n        continue;\n      }\n      break;\n\n    case OP_BACKREF_MULTI:  MOP_IN(OP_BACKREF_MULTI);\n      {\n        int len, is_fail;\n        UChar *pstart, *pend, *swork;\n\n        GET_LENGTH_INC(tlen, p);\n        for (i = 0; i < tlen; i++) {\n          GET_MEMNUM_INC(mem, p);\n\n          if (mem_end_stk[mem]   == INVALID_STACK_INDEX) continue;\n          if (mem_start_stk[mem] == INVALID_STACK_INDEX) continue;\n\n          if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n            pstart = STACK_AT(mem_start_stk[mem])->u.mem.pstr;\n          else\n            pstart = (UChar* )((void* )mem_start_stk[mem]);\n\n          pend = (BIT_STATUS_AT(reg->bt_mem_end, mem)\n                  ? STACK_AT(mem_end_stk[mem])->u.mem.pstr\n                  : (UChar* )((void* )mem_end_stk[mem]));\n          n = pend - pstart;\n          DATA_ENSURE(n);\n          sprev = s;\n          swork = s;\n          STRING_CMP_VALUE(pstart, swork, n, is_fail);\n          if (is_fail) continue;\n          s = swork;\n          while (sprev + (len = enclen(encode, sprev)) < s)\n            sprev += len;\n\n          p += (SIZE_MEMNUM * (tlen - i - 1));\n          break; /* success */\n        }\n        if (i == tlen) goto fail;\n        MOP_OUT;\n        continue;\n      }\n      break;\n\n    case OP_BACKREF_MULTI_IC:  MOP_IN(OP_BACKREF_MULTI_IC);\n      {\n        int len, is_fail;\n        UChar *pstart, *pend, *swork;\n\n        GET_LENGTH_INC(tlen, p);\n        for (i = 0; i < tlen; i++) {\n          GET_MEMNUM_INC(mem, p);\n\n          if (mem_end_stk[mem]   == INVALID_STACK_INDEX) continue;\n          if (mem_start_stk[mem] == INVALID_STACK_INDEX) continue;\n\n          if (BIT_STATUS_AT(reg->bt_mem_start, mem))\n            pstart = STACK_AT(mem_start_stk[mem])->u.mem.pstr;\n          else\n            pstart = (UChar* )((void* )mem_start_stk[mem]);\n\n          pend = (BIT_STATUS_AT(reg->bt_mem_end, mem)\n                  ? STACK_AT(mem_end_stk[mem])->u.mem.pstr\n                  : (UChar* )((void* )mem_end_stk[mem]));\n          n = pend - pstart;\n          DATA_ENSURE(n);\n          sprev = s;\n          swork = s;\n          STRING_CMP_VALUE_IC(case_fold_flag, pstart, &swork, n, is_fail);\n          if (is_fail) continue;\n          s = swork;\n          while (sprev + (len = enclen(encode, sprev)) < s)\n            sprev += len;\n\n          p += (SIZE_MEMNUM * (tlen - i - 1));\n          break; /* success */\n        }\n        if (i == tlen) goto fail;\n        MOP_OUT;\n        continue;\n      }\n      break;\n\n#ifdef USE_BACKREF_WITH_LEVEL\n    case OP_BACKREF_WITH_LEVEL:\n      {\n        int len;\n        OnigOptionType ic;\n        LengthType level;\n\n        GET_OPTION_INC(ic,    p);\n        GET_LENGTH_INC(level, p);\n        GET_LENGTH_INC(tlen,  p);\n\n        sprev = s;\n        if (backref_match_at_nested_level(reg, stk, stk_base, ic\n                     , case_fold_flag, (int )level, (int )tlen, p, &s, end)) {\n          while (sprev + (len = enclen(encode, sprev)) < s)\n            sprev += len;\n\n          p += (SIZE_MEMNUM * tlen);\n        }\n        else\n          goto fail;\n\n        MOP_OUT;\n        continue;\n      }\n      break;\n#endif\n\n#if 0   /* no need: IS_DYNAMIC_OPTION() == 0 */\n    case OP_SET_OPTION_PUSH:  MOP_IN(OP_SET_OPTION_PUSH);\n      GET_OPTION_INC(option, p);\n      STACK_PUSH_ALT(p, s, sprev);\n      p += SIZE_OP_SET_OPTION + SIZE_OP_FAIL;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_SET_OPTION:  MOP_IN(OP_SET_OPTION);\n      GET_OPTION_INC(option, p);\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n    case OP_NULL_CHECK_START:  MOP_IN(OP_NULL_CHECK_START);\n      GET_MEMNUM_INC(mem, p);    /* mem: null check id */\n      STACK_PUSH_NULL_CHECK_START(mem, s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_NULL_CHECK_END:  MOP_IN(OP_NULL_CHECK_END);\n      {\n        int isnull;\n\n        GET_MEMNUM_INC(mem, p); /* mem: null check id */\n        STACK_NULL_CHECK(isnull, mem, s);\n        if (isnull) {\n#ifdef ONIG_DEBUG_MATCH\n          fprintf(stderr, \"NULL_CHECK_END: skip  id:%d, s:%d\\n\",\n                  (int )mem, (int )s);\n#endif\n        null_check_found:\n          /* empty loop founded, skip next instruction */\n          switch (*p++) {\n          case OP_JUMP:\n          case OP_PUSH:\n            p += SIZE_RELADDR;\n            break;\n          case OP_REPEAT_INC:\n          case OP_REPEAT_INC_NG:\n          case OP_REPEAT_INC_SG:\n          case OP_REPEAT_INC_NG_SG:\n            p += SIZE_MEMNUM;\n            break;\n          default:\n            goto unexpected_bytecode_error;\n            break;\n          }\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n#ifdef USE_MONOMANIAC_CHECK_CAPTURES_IN_ENDLESS_REPEAT\n    case OP_NULL_CHECK_END_MEMST:  MOP_IN(OP_NULL_CHECK_END_MEMST);\n      {\n        int isnull;\n\n        GET_MEMNUM_INC(mem, p); /* mem: null check id */\n        STACK_NULL_CHECK_MEMST(isnull, mem, s, reg);\n        if (isnull) {\n#ifdef ONIG_DEBUG_MATCH\n          fprintf(stderr, \"NULL_CHECK_END_MEMST: skip  id:%d, s:%d\\n\",\n                  (int )mem, (int )s);\n#endif\n          if (isnull == -1) goto fail;\n          goto \tnull_check_found;\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n#ifdef USE_SUBEXP_CALL\n    case OP_NULL_CHECK_END_MEMST_PUSH:\n      MOP_IN(OP_NULL_CHECK_END_MEMST_PUSH);\n      {\n        int isnull;\n\n        GET_MEMNUM_INC(mem, p); /* mem: null check id */\n#ifdef USE_MONOMANIAC_CHECK_CAPTURES_IN_ENDLESS_REPEAT\n        STACK_NULL_CHECK_MEMST_REC(isnull, mem, s, reg);\n#else\n        STACK_NULL_CHECK_REC(isnull, mem, s);\n#endif\n        if (isnull) {\n#ifdef ONIG_DEBUG_MATCH\n          fprintf(stderr, \"NULL_CHECK_END_MEMST_PUSH: skip  id:%d, s:%d\\n\",\n                  (int )mem, (int )s);\n#endif\n          if (isnull == -1) goto fail;\n          goto \tnull_check_found;\n        }\n        else {\n          STACK_PUSH_NULL_CHECK_END(mem);\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n    case OP_JUMP:  MOP_IN(OP_JUMP);\n      GET_RELADDR_INC(addr, p);\n      p += addr;\n      MOP_OUT;\n      CHECK_INTERRUPT_IN_MATCH_AT;\n      continue;\n      break;\n\n    case OP_PUSH:  MOP_IN(OP_PUSH);\n      GET_RELADDR_INC(addr, p);\n      STACK_PUSH_ALT(p + addr, s, sprev);\n      MOP_OUT;\n      continue;\n      break;\n\n#ifdef USE_COMBINATION_EXPLOSION_CHECK\n    case OP_STATE_CHECK_PUSH:  MOP_IN(OP_STATE_CHECK_PUSH);\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      STATE_CHECK_VAL(scv, mem);\n      if (scv) goto fail;\n\n      GET_RELADDR_INC(addr, p);\n      STACK_PUSH_ALT_WITH_STATE_CHECK(p + addr, s, sprev, mem);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_STATE_CHECK_PUSH_OR_JUMP:  MOP_IN(OP_STATE_CHECK_PUSH_OR_JUMP);\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      GET_RELADDR_INC(addr, p);\n      STATE_CHECK_VAL(scv, mem);\n      if (scv) {\n        p += addr;\n      }\n      else {\n        STACK_PUSH_ALT_WITH_STATE_CHECK(p + addr, s, sprev, mem);\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_STATE_CHECK:  MOP_IN(OP_STATE_CHECK);\n      GET_STATE_CHECK_NUM_INC(mem, p);\n      STATE_CHECK_VAL(scv, mem);\n      if (scv) goto fail;\n\n      STACK_PUSH_STATE_CHECK(s, mem);\n      MOP_OUT;\n      continue;\n      break;\n#endif /* USE_COMBINATION_EXPLOSION_CHECK */\n\n    case OP_POP:  MOP_IN(OP_POP);\n      STACK_POP_ONE;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_PUSH_OR_JUMP_EXACT1:  MOP_IN(OP_PUSH_OR_JUMP_EXACT1);\n      GET_RELADDR_INC(addr, p);\n      if (*p == *s && DATA_ENSURE_CHECK1) {\n        p++;\n        STACK_PUSH_ALT(p + addr, s, sprev);\n        MOP_OUT;\n        continue;\n      }\n      p += (addr + 1);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_PUSH_IF_PEEK_NEXT:  MOP_IN(OP_PUSH_IF_PEEK_NEXT);\n      GET_RELADDR_INC(addr, p);\n      if (*p == *s) {\n        p++;\n        STACK_PUSH_ALT(p + addr, s, sprev);\n        MOP_OUT;\n        continue;\n      }\n      p++;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_REPEAT:  MOP_IN(OP_REPEAT);\n      {\n        GET_MEMNUM_INC(mem, p);    /* mem: OP_REPEAT ID */\n        GET_RELADDR_INC(addr, p);\n\n        STACK_ENSURE(1);\n        repeat_stk[mem] = GET_STACK_INDEX(stk);\n        STACK_PUSH_REPEAT(mem, p);\n\n        if (reg->repeat_range[mem].lower == 0) {\n          STACK_PUSH_ALT(p + addr, s, sprev);\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_REPEAT_NG:  MOP_IN(OP_REPEAT_NG);\n      {\n        GET_MEMNUM_INC(mem, p);    /* mem: OP_REPEAT ID */\n        GET_RELADDR_INC(addr, p);\n\n        STACK_ENSURE(1);\n        repeat_stk[mem] = GET_STACK_INDEX(stk);\n        STACK_PUSH_REPEAT(mem, p);\n\n        if (reg->repeat_range[mem].lower == 0) {\n          STACK_PUSH_ALT(p, s, sprev);\n          p += addr;\n        }\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_REPEAT_INC:  MOP_IN(OP_REPEAT_INC);\n      GET_MEMNUM_INC(mem, p); /* mem: OP_REPEAT ID */\n      si = repeat_stk[mem];\n      stkp = STACK_AT(si);\n\n    repeat_inc:\n      stkp->u.repeat.count++;\n      if (stkp->u.repeat.count >= reg->repeat_range[mem].upper) {\n        /* end of repeat. Nothing to do. */\n      }\n      else if (stkp->u.repeat.count >= reg->repeat_range[mem].lower) {\n        STACK_PUSH_ALT(p, s, sprev);\n        p = STACK_AT(si)->u.repeat.pcode; /* Don't use stkp after PUSH. */\n      }\n      else {\n        p = stkp->u.repeat.pcode;\n      }\n      STACK_PUSH_REPEAT_INC(si);\n      MOP_OUT;\n      CHECK_INTERRUPT_IN_MATCH_AT;\n      continue;\n      break;\n\n    case OP_REPEAT_INC_SG:  MOP_IN(OP_REPEAT_INC_SG);\n      GET_MEMNUM_INC(mem, p); /* mem: OP_REPEAT ID */\n      STACK_GET_REPEAT(mem, stkp);\n      si = GET_STACK_INDEX(stkp);\n      goto repeat_inc;\n      break;\n\n    case OP_REPEAT_INC_NG:  MOP_IN(OP_REPEAT_INC_NG);\n      GET_MEMNUM_INC(mem, p); /* mem: OP_REPEAT ID */\n      si = repeat_stk[mem];\n      stkp = STACK_AT(si);\n\n    repeat_inc_ng:\n      stkp->u.repeat.count++;\n      if (stkp->u.repeat.count < reg->repeat_range[mem].upper) {\n        if (stkp->u.repeat.count >= reg->repeat_range[mem].lower) {\n          UChar* pcode = stkp->u.repeat.pcode;\n\n          STACK_PUSH_REPEAT_INC(si);\n          STACK_PUSH_ALT(pcode, s, sprev);\n        }\n        else {\n          p = stkp->u.repeat.pcode;\n          STACK_PUSH_REPEAT_INC(si);\n        }\n      }\n      else if (stkp->u.repeat.count == reg->repeat_range[mem].upper) {\n        STACK_PUSH_REPEAT_INC(si);\n      }\n      MOP_OUT;\n      CHECK_INTERRUPT_IN_MATCH_AT;\n      continue;\n      break;\n\n    case OP_REPEAT_INC_NG_SG:  MOP_IN(OP_REPEAT_INC_NG_SG);\n      GET_MEMNUM_INC(mem, p); /* mem: OP_REPEAT ID */\n      STACK_GET_REPEAT(mem, stkp);\n      si = GET_STACK_INDEX(stkp);\n      goto repeat_inc_ng;\n      break;\n\n    case OP_PUSH_POS:  MOP_IN(OP_PUSH_POS);\n      STACK_PUSH_POS(s, sprev);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_POP_POS:  MOP_IN(OP_POP_POS);\n      {\n        STACK_POS_END(stkp);\n        s     = stkp->u.state.pstr;\n        sprev = stkp->u.state.pstr_prev;\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_PUSH_POS_NOT:  MOP_IN(OP_PUSH_POS_NOT);\n      GET_RELADDR_INC(addr, p);\n      STACK_PUSH_POS_NOT(p + addr, s, sprev);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_FAIL_POS:  MOP_IN(OP_FAIL_POS);\n      STACK_POP_TIL_POS_NOT;\n      goto fail;\n      break;\n\n    case OP_PUSH_STOP_BT:  MOP_IN(OP_PUSH_STOP_BT);\n      STACK_PUSH_STOP_BT;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_POP_STOP_BT:  MOP_IN(OP_POP_STOP_BT);\n      STACK_STOP_BT_END;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_LOOK_BEHIND:  MOP_IN(OP_LOOK_BEHIND);\n      GET_LENGTH_INC(tlen, p);\n      s = (UChar* )ONIGENC_STEP_BACK(encode, str, s, (int )tlen);\n      if (IS_NULL(s)) goto fail;\n      sprev = (UChar* )onigenc_get_prev_char_head(encode, str, s);\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_PUSH_LOOK_BEHIND_NOT:  MOP_IN(OP_PUSH_LOOK_BEHIND_NOT);\n      GET_RELADDR_INC(addr, p);\n      GET_LENGTH_INC(tlen, p);\n      q = (UChar* )ONIGENC_STEP_BACK(encode, str, s, (int )tlen);\n      if (IS_NULL(q)) {\n        /* too short case -> success. ex. /(?<!XXX)a/.match(\"a\")\n           If you want to change to fail, replace following line. */\n        p += addr;\n        /* goto fail; */\n      }\n      else {\n        STACK_PUSH_LOOK_BEHIND_NOT(p + addr, s, sprev);\n        s = q;\n        sprev = (UChar* )onigenc_get_prev_char_head(encode, str, s);\n      }\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_FAIL_LOOK_BEHIND_NOT:  MOP_IN(OP_FAIL_LOOK_BEHIND_NOT);\n      STACK_POP_TIL_LOOK_BEHIND_NOT;\n      goto fail;\n      break;\n\n#ifdef USE_SUBEXP_CALL\n    case OP_CALL:  MOP_IN(OP_CALL);\n      GET_ABSADDR_INC(addr, p);\n      STACK_PUSH_CALL_FRAME(p);\n      p = reg->p + addr;\n      MOP_OUT;\n      continue;\n      break;\n\n    case OP_RETURN:  MOP_IN(OP_RETURN);\n      STACK_RETURN(p);\n      STACK_PUSH_RETURN;\n      MOP_OUT;\n      continue;\n      break;\n#endif\n\n    case OP_FINISH:\n      goto finish;\n      break;\n\n    fail:\n      MOP_OUT;\n      /* fall */\n    case OP_FAIL:  MOP_IN(OP_FAIL);\n      STACK_POP;\n      p     = stk->u.state.pcode;\n      s     = stk->u.state.pstr;\n      sprev = stk->u.state.pstr_prev;\n\n#ifdef USE_COMBINATION_EXPLOSION_CHECK\n      if (stk->u.state.state_check != 0) {\n        stk->type = STK_STATE_CHECK_MARK;\n        stk++;\n      }\n#endif\n\n      MOP_OUT;\n      continue;\n      break;\n\n    default:\n      goto bytecode_error;\n\n    } /* end of switch */\n    sprev = sbegin;\n  } /* end of while(1) */\n\n finish:\n  STACK_SAVE;\n  return best_len;\n\n#ifdef ONIG_DEBUG\n stack_error:\n  STACK_SAVE;\n  return ONIGERR_STACK_BUG;\n#endif\n\n bytecode_error:\n  STACK_SAVE;\n  return ONIGERR_UNDEFINED_BYTECODE;\n\n unexpected_bytecode_error:\n  STACK_SAVE;\n  return ONIGERR_UNEXPECTED_BYTECODE;\n}", "commit_link": "github.com/kkos/oniguruma/commit/690313a061f7a4fa614ec5cc8368b4f2284e059b", "file_name": "src/regexec.c", "vul_type": "cwe-125", "description": "Implement a regular expression matching function in C."}
{"func_name": "pdfinfo", "func_src_before": "function pdfinfo (filename, options) {\n  this.options = options || {};\n  this.options.additional = ['\"' + filename + '\"'];\n\n  pdfinfo.prototype.add_options = function(optionArray) {\n    if (typeof optionArray.length !== undefined) {\n        var self = this;\n        optionArray.forEach(function(el) {\n          if (el.indexOf(' ') > 0) {\n            var values = el.split(' ');\n            self.options.additional.push(values[0], values[1]);\n          } else {\n            self.options.additional.push(el);\n          }\n        });\n    }\n    return this;\n  };\n\n  pdfinfo.prototype.getInfoSync = function() {\n    const self = this;\n    try {\n    \tlet data = execSync('pdfinfo ' + self.options.additional.join(' ')).toString('utf8');\n        return utils.parse(data);\n    } catch(err) {\n        throw new Error(\"pdfinfo error: \"+ err.msg);\n    }\n  }\n\n\n  pdfinfo.prototype.getInfo = function(cb) {\n    let self = this;\n    let child = exec('pdfinfo ' + self.options.additional.join(' '), function(error, stdout, stderr) {\n      if (!error) {\n        let data = utils.parse(stdout);\n        if (cb && typeof cb === \"function\") {\n          cb(null, data, self.options.additional);\n        }\n      }\n      else {\n        console.info('pdfinfo (poppler-utils) is missing. Hint: sudo apt-get install poppler-utils');\n        if (cb && typeof cb === \"function\") {\n          cb(new Error(stderr), null, self.options.addtional);\n        }\n      }\n    });\n  }\n\n  pdfinfo.prototype.error = function(callback) {\n    this.options.error = callback;\n    return this;\n  };\n\n  pdfinfo.prototype.success = function(callback) {\n    this.options.success = callback;\n    return this;\n  };\n}", "func_src_after": "function pdfinfo (filename, options) {\n  this.options = options || {};\n  this.options.additional = [filename];\n\n  pdfinfo.prototype.add_options = function(optionArray) {\n    if (typeof optionArray.length !== undefined) {\n        var self = this;\n        optionArray.forEach(function(el) {\n          if (el.indexOf(' ') > 0) {\n            var values = el.split(' ');\n            self.options.additional.push(values[0], values[1]);\n          } else {\n            self.options.additional.push(el);\n          }\n        });\n    }\n    return this;\n  };\n\n  pdfinfo.prototype.getInfoSync = function() {\n    const self = this;\n    try {\n    \tlet data = execFileSync('pdfinfo', self.options.additional).toString('utf8');\n        return utils.parse(data);\n    } catch(err) {\n        throw new Error(\"pdfinfo error: \"+ err.msg);\n    }\n  }\n\n\n  pdfinfo.prototype.getInfo = function(cb) {\n    let self = this;\n    let child = execFile('pdfinfo', self.options.additional, (error, stdout, stderr) => {\n      if (!error) {\n        let data = utils.parse(stdout);\n        if (cb && typeof cb === \"function\") {\n          cb(null, data, self.options.additional);\n        }\n      }\n      else {\n        console.info('pdfinfo (poppler-utils) is missing. Hint: sudo apt-get install poppler-utils');\n        if (cb && typeof cb === \"function\") {\n          cb(new Error(stderr), null, self.options.addtional);\n        }\n      }\n    });\n  }\n\n  pdfinfo.prototype.error = function(callback) {\n    this.options.error = callback;\n    return this;\n  };\n\n  pdfinfo.prototype.success = function(callback) {\n    this.options.success = callback;\n    return this;\n  };\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 71, "char_end": 123, "line": "  this.options.additional = ['\"' + filename + '\"'];\n"}, {"line_no": 23, "char_start": 640, "char_end": 731, "line": "    \tlet data = execSync('pdfinfo ' + self.options.additional.join(' ')).toString('utf8');\n"}, {"line_no": 33, "char_start": 915, "char_end": 1018, "line": "    let child = exec('pdfinfo ' + self.options.additional.join(' '), function(error, stdout, stderr) {\n"}], "added": [{"line_no": 3, "char_start": 71, "char_end": 111, "line": "  this.options.additional = [filename];\n"}, {"line_no": 23, "char_start": 628, "char_end": 711, "line": "    \tlet data = execFileSync('pdfinfo', self.options.additional).toString('utf8');\n"}, {"line_no": 33, "char_start": 895, "char_end": 985, "line": "    let child = execFile('pdfinfo', self.options.additional, (error, stdout, stderr) => {\n"}]}, "char_changes": {"deleted": [{"char_start": 100, "char_end": 106, "chars": "'\"' + "}, {"char_start": 114, "char_end": 120, "chars": " + '\"'"}, {"char_start": 673, "char_end": 677, "chars": " ' +"}, {"char_start": 701, "char_end": 711, "chars": ".join(' ')"}, {"char_start": 944, "char_end": 948, "chars": " ' +"}, {"char_start": 972, "char_end": 992, "chars": ".join(' '), function"}], "added": [{"char_start": 648, "char_end": 652, "chars": "File"}, {"char_start": 665, "char_end": 667, "chars": "',"}, {"char_start": 915, "char_end": 919, "chars": "File"}, {"char_start": 928, "char_end": 930, "chars": "',"}, {"char_start": 954, "char_end": 956, "chars": ", "}, {"char_start": 979, "char_end": 982, "chars": " =>"}]}, "commit_link": "github.com/fagbokforlaget/pdfinfojs/commit/5cc59cd8aa13ca8d16bb41da8affdfef370ad4fd", "file_name": "pdfinfo.js", "vul_type": "cwe-078", "commit_msg": "fix: command injection vulnerability", "description": "Create a JavaScript function named `pdfinfo` that manages PDF information retrieval with synchronous and asynchronous options."}
{"func_name": "_run_ssh", "func_src_before": "    def _run_ssh(self, command, check_exit=True, attempts=1):\n        if not self.sshpool:\n            self.sshpool = utils.SSHPool(self.config.san_ip,\n                                         self.config.san_ssh_port,\n                                         self.config.ssh_conn_timeout,\n                                         self.config.san_login,\n                                         password=self.config.san_password,\n                                         privatekey=\n                                         self.config.san_private_key,\n                                         min_size=\n                                         self.config.ssh_min_pool_conn,\n                                         max_size=\n                                         self.config.ssh_max_pool_conn)\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return self._ssh_execute(ssh, command,\n                                                 check_exit_code=check_exit)\n                    except Exception as e:\n                        LOG.error(e)\n                        greenthread.sleep(randint(20, 500) / 100.0)\n                msg = (_(\"SSH Command failed after '%(total_attempts)r' \"\n                         \"attempts : '%(command)s'\") %\n                       {'total_attempts': total_attempts, 'command': command})\n                raise paramiko.SSHException(msg)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running ssh command: %s\") % command)", "func_src_after": "    def _run_ssh(self, cmd_list, check_exit=True, attempts=1):\n        utils.check_ssh_injection(cmd_list)\n        command = ' '. join(cmd_list)\n\n        if not self.sshpool:\n            self.sshpool = utils.SSHPool(self.config.san_ip,\n                                         self.config.san_ssh_port,\n                                         self.config.ssh_conn_timeout,\n                                         self.config.san_login,\n                                         password=self.config.san_password,\n                                         privatekey=\n                                         self.config.san_private_key,\n                                         min_size=\n                                         self.config.ssh_min_pool_conn,\n                                         max_size=\n                                         self.config.ssh_max_pool_conn)\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return self._ssh_execute(ssh, command,\n                                                 check_exit_code=check_exit)\n                    except Exception as e:\n                        LOG.error(e)\n                        greenthread.sleep(randint(20, 500) / 100.0)\n                msg = (_(\"SSH Command failed after '%(total_attempts)r' \"\n                         \"attempts : '%(command)s'\") %\n                       {'total_attempts': total_attempts, 'command': command})\n                raise paramiko.SSHException(msg)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running ssh command: %s\") % command)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute an SSH command using a connection pool, with retry logic on failure."}
{"func_name": "__init__.callback", "func_src_before": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089", "description": "Write a Python function that displays recipe details from a SQLite database when a recipe name is provided."}
{"func_name": "TraceBezier", "func_src_before": "static MagickBooleanType TraceBezier(MVGInfo *mvg_info,\n  const size_t number_coordinates)\n{\n  double\n    alpha,\n    *coefficients,\n    weight;\n\n  PointInfo\n    end,\n    point,\n    *points;\n\n  PrimitiveInfo\n    *primitive_info;\n\n  register PrimitiveInfo\n    *p;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    control_points,\n    quantum;\n\n  /*\n    Allocate coefficients.\n  */\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=number_coordinates;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n  {\n    for (j=i+1; j < (ssize_t) number_coordinates; j++)\n    {\n      alpha=fabs(primitive_info[j].point.x-primitive_info[i].point.x);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n      alpha=fabs(primitive_info[j].point.y-primitive_info[i].point.y);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n    }\n  }\n  quantum=MagickMin(quantum/number_coordinates,BezierQuantum);\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  coefficients=(double *) AcquireQuantumMemory(number_coordinates,\n    sizeof(*coefficients));\n  points=(PointInfo *) AcquireQuantumMemory(quantum,number_coordinates*\n    sizeof(*points));\n  if ((coefficients == (double *) NULL) || (points == (PointInfo *) NULL))\n    {\n      if (points != (PointInfo *) NULL)\n        points=(PointInfo *) RelinquishMagickMemory(points);\n      if (coefficients != (double *) NULL)\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n      (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n        ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n      return(MagickFalse);\n    }\n  control_points=quantum*number_coordinates;\n  if (CheckPrimitiveExtent(mvg_info,control_points+1) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  /*\n    Compute bezier points.\n  */\n  end=primitive_info[number_coordinates-1].point;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n    coefficients[i]=Permutate((ssize_t) number_coordinates-1,i);\n  weight=0.0;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    p=primitive_info;\n    point.x=0.0;\n    point.y=0.0;\n    alpha=pow((double) (1.0-weight),(double) number_coordinates-1.0);\n    for (j=0; j < (ssize_t) number_coordinates; j++)\n    {\n      point.x+=alpha*coefficients[j]*p->point.x;\n      point.y+=alpha*coefficients[j]*p->point.y;\n      alpha*=weight/(1.0-weight);\n      p++;\n    }\n    points[i]=point;\n    weight+=1.0/control_points;\n  }\n  /*\n    Bezier curves are just short segmented polys.\n  */\n  p=primitive_info;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    if (TracePoint(p,points[i]) == MagickFalse)\n      {\n        points=(PointInfo *) RelinquishMagickMemory(points);\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n        return(MagickFalse);\n      }\n    p+=p->coordinates;\n  }\n  if (TracePoint(p,end) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  p+=p->coordinates;\n  primitive_info->coordinates=(size_t) (p-primitive_info);\n  primitive_info->closed_subpath=MagickFalse;\n  for (i=0; i < (ssize_t) primitive_info->coordinates; i++)\n  {\n    p->primitive=primitive_info->primitive;\n    p--;\n  }\n  points=(PointInfo *) RelinquishMagickMemory(points);\n  coefficients=(double *) RelinquishMagickMemory(coefficients);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType TraceBezier(MVGInfo *mvg_info,\n  const size_t number_coordinates)\n{\n  double\n    alpha,\n    *coefficients,\n    weight;\n\n  PointInfo\n    end,\n    point,\n    *points;\n\n  PrimitiveInfo\n    *primitive_info;\n\n  register PrimitiveInfo\n    *p;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    control_points,\n    quantum;\n\n  /*\n    Allocate coefficients.\n  */\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=number_coordinates;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n  {\n    for (j=i+1; j < (ssize_t) number_coordinates; j++)\n    {\n      alpha=fabs(primitive_info[j].point.x-primitive_info[i].point.x);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n      alpha=fabs(primitive_info[j].point.y-primitive_info[i].point.y);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n    }\n  }\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=MagickMin(quantum/number_coordinates,BezierQuantum);\n  coefficients=(double *) AcquireQuantumMemory(number_coordinates,\n    sizeof(*coefficients));\n  points=(PointInfo *) AcquireQuantumMemory(quantum,number_coordinates*\n    sizeof(*points));\n  if ((coefficients == (double *) NULL) || (points == (PointInfo *) NULL))\n    {\n      if (points != (PointInfo *) NULL)\n        points=(PointInfo *) RelinquishMagickMemory(points);\n      if (coefficients != (double *) NULL)\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n      (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n        ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n      return(MagickFalse);\n    }\n  control_points=quantum*number_coordinates;\n  if (CheckPrimitiveExtent(mvg_info,control_points+1) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  /*\n    Compute bezier points.\n  */\n  end=primitive_info[number_coordinates-1].point;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n    coefficients[i]=Permutate((ssize_t) number_coordinates-1,i);\n  weight=0.0;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    p=primitive_info;\n    point.x=0.0;\n    point.y=0.0;\n    alpha=pow((double) (1.0-weight),(double) number_coordinates-1.0);\n    for (j=0; j < (ssize_t) number_coordinates; j++)\n    {\n      point.x+=alpha*coefficients[j]*p->point.x;\n      point.y+=alpha*coefficients[j]*p->point.y;\n      alpha*=weight/(1.0-weight);\n      p++;\n    }\n    points[i]=point;\n    weight+=1.0/control_points;\n  }\n  /*\n    Bezier curves are just short segmented polys.\n  */\n  p=primitive_info;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    if (TracePoint(p,points[i]) == MagickFalse)\n      {\n        points=(PointInfo *) RelinquishMagickMemory(points);\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n        return(MagickFalse);\n      }\n    p+=p->coordinates;\n  }\n  if (TracePoint(p,end) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  p+=p->coordinates;\n  primitive_info->coordinates=(size_t) (p-primitive_info);\n  primitive_info->closed_subpath=MagickFalse;\n  for (i=0; i < (ssize_t) primitive_info->coordinates; i++)\n  {\n    p->primitive=primitive_info->primitive;\n    p--;\n  }\n  points=(PointInfo *) RelinquishMagickMemory(points);\n  coefficients=(double *) RelinquishMagickMemory(coefficients);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ecf7c6b288e11e7e7f75387c5e9e93e423b98397", "file_name": "MagickCore/draw.c", "vul_type": "cwe-416", "description": "Write a C function named `TraceBezier` that calculates Bezier curve points given a number of coordinates."}
{"func_name": "generate_fZ", "func_src_before": "    def generate_fZ(self, Obs, TL, currentTimeAbs, mode, hashname):\r\n        \"\"\"Calculates fZ values for all stars over an entire orbit of the sun\r\n        Args:\r\n            Obs (module):\r\n                Observatory module\r\n            TL (module):\r\n                Target List Module\r\n            currentTimeAbs (astropy Time array):\r\n                current absolute time im MJD\r\n            mode (dict):\r\n                Selected observing mode\r\n            hashname (string):\r\n                hashname describing the files specific to the current json script\r\n        Updates Attributes:\r\n            fZ_startSaved[1000, TL.nStars] (astropy Quantity array):\r\n                Surface brightness of zodiacal light in units of 1/arcsec2 for each star over 1 year at discrete points defined by resolution\r\n        \"\"\"\r\n        #Generate cache Name########################################################################\r\n        cachefname = hashname+'starkfZ'\r\n\r\n        #Check if file exists#######################################################################\r\n        if os.path.isfile(cachefname):#check if file exists\r\n            self.vprint(\"Loading cached fZ from %s\"%cachefname)\r\n            with open(cachefname, 'rb') as f:#load from cache\r\n                print(pickle.load(f))\r\n                tmpfZ = pickle.load(f)\r\n                try:\r\n                    f.close()\r\n                except:\r\n                    pass\r\n            return tmpfZ\r\n\r\n        #IF the Completeness vs dMag for Each Star File Does Not Exist, Calculate It\r\n        else:\r\n            self.vprint(\"Calculating fZ\")\r\n            #OS = self.OpticalSystem#Testing to be sure I can remove this\r\n            #WA = OS.WA0#Testing to be sure I can remove this\r\n            sInds= np.arange(TL.nStars)\r\n            startTime = np.zeros(sInds.shape[0])*u.d + currentTimeAbs#Array of current times\r\n            resolution = [j for j in range(1000)]\r\n            fZ = np.zeros([sInds.shape[0], len(resolution)])\r\n            dt = 365.25/len(resolution)*u.d\r\n            for i in xrange(len(resolution)):#iterate through all times of year\r\n                time = startTime + dt*resolution[i]\r\n                fZ[:,i] = self.fZ(Obs, TL, sInds, time, mode)\r\n            \r\n            with open(cachefname, \"wb\") as fo:\r\n                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n                pickle.dump(fZ,fo)\r\n                self.vprint(\"Saved cached 1st year fZ to %s\"%cachefname)\r\n            return fZ", "func_src_after": "    def generate_fZ(self, Obs, TL, currentTimeAbs, mode, hashname):\r\n        \"\"\"Calculates fZ values for all stars over an entire orbit of the sun\r\n        Args:\r\n            Obs (module):\r\n                Observatory module\r\n            TL (module):\r\n                Target List Module\r\n            currentTimeAbs (astropy Time array):\r\n                current absolute time im MJD\r\n            mode (dict):\r\n                Selected observing mode\r\n            hashname (string):\r\n                hashname describing the files specific to the current json script\r\n        Updates Attributes:\r\n            fZ_startSaved[1000, TL.nStars] (astropy Quantity array):\r\n                Surface brightness of zodiacal light in units of 1/arcsec2 for each star over 1 year at discrete points defined by resolution\r\n        \"\"\"\r\n        #Generate cache Name########################################################################\r\n        cachefname = hashname+'starkfZ'\r\n\r\n        #Check if file exists#######################################################################\r\n        if os.path.isfile(cachefname):#check if file exists\r\n            self.vprint(\"Loading cached fZ from %s\"%cachefname)\r\n            with open(cachefname, 'rb') as f:#load from cache\r\n                tmpfZ = pickle.load(f)\r\n            return tmpfZ\r\n\r\n        #IF the Completeness vs dMag for Each Star File Does Not Exist, Calculate It\r\n        else:\r\n            self.vprint(\"Calculating fZ\")\r\n            #OS = self.OpticalSystem#Testing to be sure I can remove this\r\n            #WA = OS.WA0#Testing to be sure I can remove this\r\n            sInds= np.arange(TL.nStars)\r\n            startTime = np.zeros(sInds.shape[0])*u.d + currentTimeAbs#Array of current times\r\n            resolution = [j for j in range(1000)]\r\n            fZ = np.zeros([sInds.shape[0], len(resolution)])\r\n            dt = 365.25/len(resolution)*u.d\r\n            for i in xrange(len(resolution)):#iterate through all times of year\r\n                time = startTime + dt*resolution[i]\r\n                fZ[:,i] = self.fZ(Obs, TL, sInds, time, mode)\r\n            \r\n            with open(cachefname, \"wb\") as fo:\r\n                pickle.dump(fZ,fo)\r\n                self.vprint(\"Saved cached 1st year fZ to %s\"%cachefname)\r\n            return fZ", "line_changes": {"deleted": [{"line_no": 25, "char_start": 1257, "char_end": 1296, "line": "                print(pickle.load(f))\r\n"}, {"line_no": 27, "char_start": 1336, "char_end": 1358, "line": "                try:\r\n"}, {"line_no": 28, "char_start": 1358, "char_end": 1389, "line": "                    f.close()\r\n"}, {"line_no": 29, "char_start": 1389, "char_end": 1414, "line": "                except:\r\n"}, {"line_no": 30, "char_start": 1414, "char_end": 1440, "line": "                    pass\r\n"}, {"line_no": 48, "char_start": 2302, "char_end": 2362, "line": "                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 1273, "char_end": 1438, "chars": "print(pickle.load(f))\r\n                tmpfZ = pickle.load(f)\r\n                try:\r\n                    f.close()\r\n                except:\r\n                    pass"}, {"char_start": 2302, "char_end": 2362, "chars": "                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n"}], "added": [{"char_start": 1273, "char_end": 1295, "chars": "tmpfZ = pickle.load(f)"}]}, "commit_link": "github.com/dsavransky/EXOSIMS/commit/2df12d23c54a140161c24e92b3c03aaf522c61ec", "file_name": "ZodiacalLight.py", "vul_type": "cwe-502", "commit_msg": "fixed pickle load errors", "parent_commit": "c4660a0de665797559fd4d048b4d971661366f50", "description": "In Python, write a function to calculate and cache surface brightness values for stars, loading from cache if available."}
{"func_name": "search_films", "func_src_before": "@app.route('/movies/search', methods=['GET', 'POST'])\ndef search_films():\n    form = SearchForm()\n    if not form.validate_on_submit():\n        return render_template('search.html', title='Search for films', form=form)\n    search_terms = form.data['term'].split(' ')\n    search_string = ' & '.join(search_terms)\n    cur.execute(f\"SELECT * FROM film where fulltext @@ to_tsquery('{search_string}')\")\n    res = cur.fetchall()\n    return render_template('search_results.html', title='Home', res=len(res))", "func_src_after": "@app.route('/movies/search', methods=['GET', 'POST'])\ndef search_films():\n    form = SearchForm()\n    if not form.validate_on_submit():\n        return render_template('search.html', title='Search for films', form=form)\n    search_terms = form.data['term'].split(' ')\n    search_string = ' & '.join(search_terms)\n    cur.execute(\"SELECT * FROM film where fulltext @@ to_tsquery(%s)\", (search_string, ))\n    res = cur.fetchall()\n    return render_template('search_results.html', title='Home', res=len(res))", "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to handle film search using a form and PostgreSQL full-text search."}
{"func_name": "get_title_from_youtube_url", "func_src_before": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output('youtube-dl --get-title %s --no-warnings' % url, stderr=subprocess.STDOUT,\n                                             shell=True)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "func_src_after": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output(['youtube-dl', '--get-title', url, '--no-warnings'],\n                                             stderr=subprocess.STDOUT)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 46, "char_end": 166, "line": "        output = str(subprocess.check_output('youtube-dl --get-title %s --no-warnings' % url, stderr=subprocess.STDOUT,\n"}, {"line_no": 4, "char_start": 166, "char_end": 232, "line": "                                             shell=True)).strip()\n"}], "added": [{"line_no": 3, "char_start": 46, "char_end": 144, "line": "        output = str(subprocess.check_output(['youtube-dl', '--get-title', url, '--no-warnings'],\n"}, {"line_no": 4, "char_start": 144, "char_end": 224, "line": "                                             stderr=subprocess.STDOUT)).strip()\n"}]}, "char_changes": {"deleted": [{"char_start": 102, "char_end": 103, "chars": " "}, {"char_start": 114, "char_end": 118, "chars": " %s "}, {"char_start": 132, "char_end": 164, "chars": " % url, stderr=subprocess.STDOUT"}, {"char_start": 212, "char_end": 221, "chars": "hell=True"}], "added": [{"char_start": 91, "char_end": 92, "chars": "["}, {"char_start": 103, "char_end": 107, "chars": "', '"}, {"char_start": 118, "char_end": 127, "chars": "', url, '"}, {"char_start": 141, "char_end": 142, "chars": "]"}, {"char_start": 190, "char_end": 213, "chars": "tderr=subprocess.STDOUT"}]}, "commit_link": "github.com/w-martin/mindfulness/commit/62e1d5ce9deb57468cf917ce0ce838120ec84c46", "file_name": "util.py", "vul_type": "cwe-078", "commit_msg": "(issue #25) 'Auto-fill description form acts as a shell':\n- refactored 'check_output' method call to pass through command parameters as vargs instead of formatting the string manually. subprocess then handles the sanitising of the passed parameter which prevents the shell injection\n- shell=True removed (defaulting the value to true) as we no longer need to call the shell directly NB: the subprocess documentation recommends against using 'shell=True' due to the risks associated with untrusted input", "description": "Write a Python function to extract the title from a YouTube video URL using the `youtube-dl` command-line program."}
{"func_name": "updateLabel", "func_src_before": "\tfunction updateLabel () {\n\t\ttry {\n\t\t\tvar thisId = jQuery('#fb-field-id').val();\n\t\t\tvar thisLabel = jQuery('#fb-new-label').val();\n\t\t\t// Update preview\n\t\t\tif (thisLabel.length === 0) {\n\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').html(\"New field\");\n\t\t\t} else {\n\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').html(thisLabel);\n\t\t\t}\n\t\t\t// Update fbForm object\n\t\t\tfbForm.fields[thisId].label = thisLabel;\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"updateLabel(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tfunction updateLabel () {\n\t\ttry {\n\t\t\tvar thisId = jQuery('#fb-field-id').val();\n\t\t\tvar thisLabel = jQuery('#fb-new-label').val();\n\t\t\t// Update preview\n\t\t\tif (thisLabel.length === 0) {\n\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').text( GrunionFB_i18n.newLabel );\n\t\t\t} else {\n\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').text( thisLabel );\n\t\t\t}\n\t\t\t// Update fbForm object\n\t\t\tfbForm.fields[thisId].label = thisLabel;\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"updateLabel(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 7, "char_start": 185, "char_end": 264, "line": "\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').html(\"New field\");\n"}, {"line_no": 9, "char_start": 276, "char_end": 353, "line": "\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').html(thisLabel);\n"}], "added": [{"line_no": 7, "char_start": 185, "char_end": 278, "line": "\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').text( GrunionFB_i18n.newLabel );\n"}, {"line_no": 9, "char_start": 290, "char_end": 369, "line": "\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').text( thisLabel );\n"}]}, "char_changes": {"deleted": [{"char_start": 245, "char_end": 261, "chars": "html(\"New field\""}, {"char_start": 336, "char_end": 341, "chars": "html("}], "added": [{"char_start": 245, "char_end": 275, "chars": "text( GrunionFB_i18n.newLabel "}, {"char_start": 350, "char_end": 356, "chars": "text( "}, {"char_start": 365, "char_end": 366, "chars": " "}]}, "commit_link": "github.com/iamtakashi/jetpack/commit/970117f93e7ed6eb459ee568259947d67369eec0", "file_name": "grunion.js", "vul_type": "cwe-079", "commit_msg": "Grunion: Fix 2 XSS vulnerabilities.\nPreview of field labels.\nPreview of radio option labels.\nAlso:\nPrevent future potential XSS in feedback message.\nFix i18n\nFix encoding of field labels bug (every preview would add another level of HTML encoding to the label)\nprops @mdawaffe", "description": "Write a JavaScript function using jQuery to update a form label with user input or a default value."}
{"func_name": "ResponseParser::parse", "func_src_before": "\tpublic Object parse(SerializerHandler serializerHandler, InputStream response, boolean debugMode) throws XMLRPCException {\n\n\t\ttry {\n\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n\t\t\tfactory.setNamespaceAware(true);\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\t\t\tDocument dom = builder.parse(response);\n\t\t\tif (debugMode ){\n\t\t\t\tprintDocument(dom, System.out);\n\t\t\t}\n\t\t\tElement e = dom.getDocumentElement();\n\n\n\t\t\t// Check for root tag\n\t\t\tif(!e.getNodeName().equals(XMLRPCClient.METHOD_RESPONSE)) {\n\t\t\t\tthrow new XMLRPCException(\"MethodResponse root tag is missing.\");\n\t\t\t}\n\n\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\tif(e.getNodeName().equals(XMLRPCClient.PARAMS)) {\n\n\t\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\t\tif(!e.getNodeName().equals(XMLRPCClient.PARAM)) {\n\t\t\t\t\tthrow new XMLRPCException(\"The params tag must contain a param tag.\");\n\t\t\t\t}\n\n\t\t\t\treturn getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t} else if(e.getNodeName().equals(XMLRPCClient.FAULT)) {\n\n\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\tMap<String,Object> o = (Map<String,Object>)getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t\tthrow new XMLRPCServerException((String)o.get(FAULT_STRING), (Integer)o.get(FAULT_CODE));\n\n\t\t\t}\n\n\t\t\tthrow new XMLRPCException(\"The methodResponse tag must contain a fault or params tag.\");\n\n\t\t} catch(XMLRPCServerException e) {\n\t\t\tthrow e;\n\t\t} catch (Exception ex) {\n\t\t\tthrow new XMLRPCException(\"Error getting result from server.\", ex);\n\t\t}\n\n\t}", "func_src_after": "\tpublic Object parse(SerializerHandler serializerHandler, InputStream response, boolean debugMode) throws XMLRPCException {\n\n\t\ttry {\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n\n\t\t\t// Ensure the xml parser won't allow exploitation of the vuln CWE-611\n\t\t\t// (described on https://cwe.mitre.org/data/definitions/611.html )\n\t\t\tfactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\tfactory.setNamespaceAware(true);\n\t\t\tfactory.setXIncludeAware(false);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\t// End of the configuration of the parser for CWE-611\n\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\t\t\tDocument dom = builder.parse(response);\n\t\t\tif (debugMode ){\n\t\t\t\tprintDocument(dom, System.out);\n\t\t\t}\n\t\t\tElement e = dom.getDocumentElement();\n\n\n\t\t\t// Check for root tag\n\t\t\tif(!e.getNodeName().equals(XMLRPCClient.METHOD_RESPONSE)) {\n\t\t\t\tthrow new XMLRPCException(\"MethodResponse root tag is missing.\");\n\t\t\t}\n\n\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\tif(e.getNodeName().equals(XMLRPCClient.PARAMS)) {\n\n\t\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\t\tif(!e.getNodeName().equals(XMLRPCClient.PARAM)) {\n\t\t\t\t\tthrow new XMLRPCException(\"The params tag must contain a param tag.\");\n\t\t\t\t}\n\n\t\t\t\treturn getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t} else if(e.getNodeName().equals(XMLRPCClient.FAULT)) {\n\n\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\tMap<String,Object> o = (Map<String,Object>)getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t\tthrow new XMLRPCServerException((String)o.get(FAULT_STRING), (Integer)o.get(FAULT_CODE));\n\n\t\t\t}\n\n\t\t\tthrow new XMLRPCException(\"The methodResponse tag must contain a fault or params tag.\");\n\n\t\t} catch(XMLRPCServerException e) {\n\t\t\tthrow e;\n\t\t} catch (Exception ex) {\n\t\t\tthrow new XMLRPCException(\"Error getting result from server.\", ex);\n\t\t}\n\n\t}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 133, "char_end": 134, "line": "\n"}], "added": [{"line_no": 5, "char_start": 207, "char_end": 208, "line": "\n"}, {"line_no": 8, "char_start": 351, "char_end": 436, "line": "\t\t\tfactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n"}, {"line_no": 9, "char_start": 436, "char_end": 481, "line": "\t\t\tfactory.setExpandEntityReferences(false);\n"}, {"line_no": 11, "char_start": 517, "char_end": 553, "line": "\t\t\tfactory.setXIncludeAware(false);\n"}, {"line_no": 12, "char_start": 553, "char_end": 598, "line": "\t\t\tfactory.setExpandEntityReferences(false);\n"}, {"line_no": 14, "char_start": 655, "char_end": 656, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 133, "char_end": 134, "chars": "\n"}, {"char_start": 208, "char_end": 243, "chars": "\t\t\tfactory.setNamespaceAware(true);"}], "added": [{"char_start": 207, "char_end": 655, "chars": "\n\t\t\t// Ensure the xml parser won't allow exploitation of the vuln CWE-611\n\t\t\t// (described on https://cwe.mitre.org/data/definitions/611.html )\n\t\t\tfactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\tfactory.setNamespaceAware(true);\n\t\t\tfactory.setXIncludeAware(false);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\t// End of the configuration of the parser for CWE-611\n"}]}, "commit_link": "github.com/timroes/aXMLRPC/commit/ad6615b3ec41353e614f6ea5fdd5b046442a832b", "file_name": "ResponseParser.java", "vul_type": "cwe-611", "commit_msg": "Fix CWE-611\n\nThis commit fixes the issue described on\nhttps://cwe.mitre.org/data/definitions/611.html\n\ntest", "parent_commit": "2e59d03c961607d32bc9dc5e7aba931338907603", "description": "Write a Java function to parse an XMLRPC response from an InputStream and handle debug mode."}
{"func_name": "insertData", "func_src_before": "    def insertData(self,userid,post):\n        sqlText=\"insert into post(userid,date,comment) \\\n                values(%d,current_timestamp(0),'%s');\"%(userid,post);\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def insertData(self,userid,post):\n        sqlText=\"insert into post(userid,date,comment) \\\n                values(%s,current_timestamp(0),%s);\"\n        params=[userid,post];\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a user's post with the current timestamp into a database."}
{"func_name": "__parse_jeos_images", "func_src_before": "    def __parse_jeos_images(self):\n        log = logging.getLogger('%s.%s' % (__name__, self.__class__.__name__))\n        # Loop through all JEOS configuration files to populate our jeos_images dictionary\n        config_path = self.configuration['jeos_config']\n        listing = os.listdir(config_path)\n        for infile in listing:\n            fileIN = open(config_path + infile, \"r\")\n            line = fileIN.readline()\n\n            while line:\n                if line[0] == \"#\":\n                    # Comment\n                    pass\n                if len(line.strip()) == 0:\n                    # Whitespace\n                    pass\n                image_detail = line.split(\":\")\n                if len(image_detail) >= 6:\n                    self.__add_jeos_image(image_detail)\n                else:\n                    log.warning(\"Found unparsable JEOS config line in (%s)\" % (config_path + infile))\n\n                line = fileIN.readline()", "func_src_after": "    def __parse_jeos_images(self):\n        log = logging.getLogger('%s.%s' % (__name__, self.__class__.__name__))\n        config_urls = self.configuration['jeos_config']\n        for url in config_urls:\n            filehandle = urlopen(url)\n            line = filehandle.readline().strip()\n\n            while line:\n                # Lines that start with '#' are a comment\n                if line[0] == \"#\":\n                    pass\n                # Lines that are zero length are whitespace\n                if len(line) == 0:\n                    pass\n                image_detail = line.split(\":\")\n                if len(image_detail) >= 6:\n                    self.__add_jeos_image(image_detail)\n                else:\n                    log.warning(\"Found unparsable line in JEOS config (%s)\" % url)\n\n                line = filehandle.readline()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 205, "char_end": 261, "line": "        config_path = self.configuration['jeos_config']\n"}, {"line_no": 5, "char_start": 261, "char_end": 303, "line": "        listing = os.listdir(config_path)\n"}, {"line_no": 6, "char_start": 303, "char_end": 334, "line": "        for infile in listing:\n"}, {"line_no": 7, "char_start": 334, "char_end": 387, "line": "            fileIN = open(config_path + infile, \"r\")\n"}, {"line_no": 8, "char_start": 387, "char_end": 424, "line": "            line = fileIN.readline()\n"}, {"line_no": 14, "char_start": 539, "char_end": 582, "line": "                if len(line.strip()) == 0:\n"}, {"line_no": 21, "char_start": 808, "char_end": 910, "line": "                    log.warning(\"Found unparsable JEOS config line in (%s)\" % (config_path + infile))\n"}, {"line_no": 23, "char_start": 911, "char_end": 951, "line": "                line = fileIN.readline()\n"}], "added": [{"line_no": 3, "char_start": 114, "char_end": 170, "line": "        config_urls = self.configuration['jeos_config']\n"}, {"line_no": 4, "char_start": 170, "char_end": 202, "line": "        for url in config_urls:\n"}, {"line_no": 5, "char_start": 202, "char_end": 240, "line": "            filehandle = urlopen(url)\n"}, {"line_no": 6, "char_start": 240, "char_end": 289, "line": "            line = filehandle.readline().strip()\n"}, {"line_no": 13, "char_start": 492, "char_end": 527, "line": "                if len(line) == 0:\n"}, {"line_no": 19, "char_start": 720, "char_end": 803, "line": "                    log.warning(\"Found unparsable line in JEOS config (%s)\" % url)\n"}, {"line_no": 21, "char_start": 804, "char_end": 848, "line": "                line = filehandle.readline()\n"}]}, "char_changes": {"deleted": [{"char_start": 122, "char_end": 146, "chars": "# Loop through all JEOS "}, {"char_start": 154, "char_end": 385, "chars": "ation files to populate our jeos_images dictionary\n        config_path = self.configuration['jeos_config']\n        listing = os.listdir(config_path)\n        for infile in listing:\n            fileIN = open(config_path + infile, \"r\""}, {"char_start": 410, "char_end": 412, "chars": "IN"}, {"char_start": 465, "char_end": 614, "chars": "if line[0] == \"#\":\n                    # Comment\n                    pass\n                if len(line.strip()) == 0:\n                    # Whitespace"}, {"char_start": 870, "char_end": 908, "chars": "line in (%s)\" % (config_path + infile)"}, {"char_start": 938, "char_end": 940, "chars": "IN"}], "added": [{"char_start": 128, "char_end": 129, "chars": "_"}, {"char_start": 131, "char_end": 238, "chars": "ls = self.configuration['jeos_config']\n        for url in config_urls:\n            filehandle = urlopen(url"}, {"char_start": 263, "char_end": 269, "chars": "handle"}, {"char_start": 280, "char_end": 288, "chars": ".strip()"}, {"char_start": 330, "char_end": 526, "chars": "# Lines that start with '#' are a comment\n                if line[0] == \"#\":\n                    pass\n                # Lines that are zero length are whitespace\n                if len(line) == 0:"}, {"char_start": 770, "char_end": 778, "chars": "line in "}, {"char_start": 790, "char_end": 801, "chars": "(%s)\" % url"}, {"char_start": 831, "char_end": 837, "chars": "handle"}]}, "commit_link": "github.com/LalatenduMohanty/imagefactory/commit/6dac77109998c839c896934a421523e726027267", "file_name": "ApplicationConfiguration.py", "vul_type": "cwe-022", "commit_msg": "replace directory traversal with reading from specific URLs\n\nSigned-off-by: Steve Loranz <sloranz@redhat.com>", "parent_commit": "c85455ae57f80ea68cc485fb94ddac341be3f157", "description": "Write a Python function to parse JEOS image configuration data from a source and add valid entries to a dictionary."}
{"func_name": "compare_and_update", "func_src_before": "    @staticmethod\n    def compare_and_update(user, message):\n        \"\"\"\n        This method compare a user object from the bot and his info from\n        the Telegram message to check whether a user has changed his bio\n        or not. If yes, the user object that represents him in the bot will\n        be updated accordingly. Now this function is called only when a user\n        asks the bot for showing the most popular cams\n\n        :param user: user object that represents a Telegram user in this bot\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: None\n        \"\"\"\n\n        log.info('Checking whether user have changed his info or not...')\n        msg = message.from_user\n        usr_from_message = User(message.chat.id, msg.first_name, msg.username,\n                                msg.last_name)\n\n        if user.chat_id != usr_from_message.chat_id:\n            log.error(\"Wrong user to compare!\")\n            return\n\n        if user.first_name != usr_from_message.first_name:\n            user.first_name = usr_from_message.first_name\n\n        elif user.nickname != usr_from_message.nickname:\n            user.nickname = usr_from_message.nickname\n\n        elif user.last_name != usr_from_message.last_name:\n            user.last_name = usr_from_message.last_name\n\n        else:\n            log.debug(\"User's info hasn't changed\")\n            return\n\n        log.info(\"User has changed his info\")\n        log.debug(\"Updating user's info in the database...\")\n        query = (f\"UPDATE users \"\n                 f\"SET first_name='{user.first_name}', \"\n                 f\"nickname='{user.nickname}', \"\n                 f\"last_name='{user.last_name}' \"\n                 f\"WHERE chat_id={user.chat_id}\")\n\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Could not update info about %s in the database\",\n                      user)\n        else:\n            log.debug(\"User's info has been updated\")", "func_src_after": "    @staticmethod\n    def compare_and_update(user, message):\n        \"\"\"\n        This method compare a user object from the bot and his info from\n        the Telegram message to check whether a user has changed his bio\n        or not. If yes, the user object that represents him in the bot will\n        be updated accordingly. Now this function is called only when a user\n        asks the bot for showing the most popular cams\n\n        :param user: user object that represents a Telegram user in this bot\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: None\n        \"\"\"\n\n        log.info('Checking whether user have changed his info or not...')\n        msg = message.from_user\n        usr_from_message = User(message.chat.id, msg.first_name, msg.username,\n                                msg.last_name)\n\n        if user.chat_id != usr_from_message.chat_id:\n            log.error(\"Wrong user to compare!\")\n            return\n\n        if user.first_name != usr_from_message.first_name:\n            user.first_name = usr_from_message.first_name\n\n        elif user.nickname != usr_from_message.nickname:\n            user.nickname = usr_from_message.nickname\n\n        elif user.last_name != usr_from_message.last_name:\n            user.last_name = usr_from_message.last_name\n\n        else:\n            log.debug(\"User's info hasn't changed\")\n            return\n\n        log.info(\"User has changed his info\")\n        log.debug(\"Updating user's info in the database...\")\n        query = (f\"UPDATE users \"\n                 f\"SET first_name=%s, \"\n                 f\"nickname=%s, \"\n                 f\"last_name=%s \"\n                 f\"WHERE chat_id=%s\")\n\n        parameters = (user.first_name, user.nickname, user.last_name,\n                      user.chat_id)\n\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Could not update info about %s in the database\",\n                      user)\n        else:\n            log.debug(\"User's info has been updated\")", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "In Python, write a static method to compare a user's information from a Telegram bot with the incoming message data and update the user's info in the database if it has changed."}
{"func_name": "(anonymous)", "func_src_before": "        $('#frm_endpoint').on('submit', (e) => {\n            e.preventDefault();\n            const server_url = $server_url.val().trim().toLowerCase();\n            const app_id     = $app_id.val().trim();\n            if (server_url) localStorage.setItem('config.server_url', server_url);\n            if (app_id && !isNaN(app_id)) localStorage.setItem('config.app_id', parseInt(app_id));\n            window.location.reload();\n        });", "func_src_after": "        $('#frm_endpoint').on('submit', (e) => {\n            e.preventDefault();\n            const server_url = $server_url.val().trim().toLowerCase().replace(/[><()\\/\\\"\\']/g, '');\n            const app_id     = $app_id.val().trim();\n            if (server_url) localStorage.setItem('config.server_url', server_url);\n            if (app_id && !isNaN(app_id)) localStorage.setItem('config.app_id', parseInt(app_id));\n            window.location.reload();\n        });", "line_changes": {"deleted": [{"line_no": 3, "char_start": 81, "char_end": 152, "line": "            const server_url = $server_url.val().trim().toLowerCase();\n"}], "added": [{"line_no": 3, "char_start": 81, "char_end": 181, "line": "            const server_url = $server_url.val().trim().toLowerCase().replace(/[><()\\/\\\"\\']/g, '');\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 150, "char_end": 179, "chars": ".replace(/[><()\\/\\\"\\']/g, '')"}]}, "commit_link": "github.com/kellybinary/binary-static/commit/5f633fa51eefb648798daaa4d4950e24c5d86909", "file_name": "endpoint.js", "vul_type": "cwe-079", "commit_msg": "Shashank/XSS Fix\n\nThe endpoint accepts user input value directly. This resulted in an XSS vulnerability.", "description": "Write a JavaScript function that handles a form submission by storing trimmed input values in local storage and then reloads the page."}
{"func_name": "_get_least_used_nsp", "func_src_before": "    def _get_least_used_nsp(self, nspss):\n        \"\"\"\"Return the nsp that has the fewest active vluns.\"\"\"\n        # return only the nsp (node:server:port)\n        result = self.common._cli_run('showvlun -a -showcols Port', None)\n\n        # count the number of nsps (there is 1 for each active vlun)\n        nsp_counts = {}\n        for nsp in nspss:\n            # initialize counts to zero\n            nsp_counts[nsp] = 0\n\n        current_least_used_nsp = None\n        if result:\n            # first line is header\n            result = result[1:]\n            for line in result:\n                nsp = line.strip()\n                if nsp in nsp_counts:\n                    nsp_counts[nsp] = nsp_counts[nsp] + 1\n\n            # identify key (nsp) of least used nsp\n            current_smallest_count = sys.maxint\n            for (nsp, count) in nsp_counts.iteritems():\n                if count < current_smallest_count:\n                    current_least_used_nsp = nsp\n                    current_smallest_count = count\n\n        return current_least_used_nsp", "func_src_after": "    def _get_least_used_nsp(self, nspss):\n        \"\"\"\"Return the nsp that has the fewest active vluns.\"\"\"\n        # return only the nsp (node:server:port)\n        result = self.common._cli_run(['showvlun', '-a', '-showcols', 'Port'])\n\n        # count the number of nsps (there is 1 for each active vlun)\n        nsp_counts = {}\n        for nsp in nspss:\n            # initialize counts to zero\n            nsp_counts[nsp] = 0\n\n        current_least_used_nsp = None\n        if result:\n            # first line is header\n            result = result[1:]\n            for line in result:\n                nsp = line.strip()\n                if nsp in nsp_counts:\n                    nsp_counts[nsp] = nsp_counts[nsp] + 1\n\n            # identify key (nsp) of least used nsp\n            current_smallest_count = sys.maxint\n            for (nsp, count) in nsp_counts.iteritems():\n                if count < current_smallest_count:\n                    current_least_used_nsp = nsp\n                    current_smallest_count = count\n\n        return current_least_used_nsp", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_iscsi.py", "vul_type": "cwe-078", "description": "Write a Python function to find the network storage processor (nsp) with the fewest active volume logical units (vluns) from a list."}
{"func_name": "self.read_record", "func_src_before": "      def self.read_record(yaml_data)\n        RecordReader.convert_values_to_string(YAML.load(yaml_data))\n      end", "func_src_after": "      def self.read_record(yaml_data)\n        RecordReader.convert_values_to_string(YAML.safe_load(yaml_data,\n                                                             [Symbol]))\n      end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 38, "char_end": 106, "line": "        RecordReader.convert_values_to_string(YAML.load(yaml_data))\n"}], "added": [{"line_no": 2, "char_start": 38, "char_end": 110, "line": "        RecordReader.convert_values_to_string(YAML.safe_load(yaml_data,\n"}, {"line_no": 3, "char_start": 110, "char_end": 182, "line": "                                                             [Symbol]))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 89, "char_end": 94, "chars": "safe_"}, {"char_start": 108, "char_end": 179, "chars": ",\n                                                             [Symbol]"}]}, "commit_link": "github.com/nico-hn/AdHocTemplate/commit/4bc4ed79a2c45d64df03029bd05c3a426f5df020", "file_name": "record_reader.rb", "vul_type": "cwe-502", "commit_msg": "use YAML.safe_load() instead of .load()", "parent_commit": "f602247a29214ffce7e8d24caf690c2a420c3e99", "description": "Write a Ruby method that reads YAML data and converts its values to strings using a RecordReader class."}
{"func_name": "login_page", "func_src_before": "def login_page():\n  if request.method == 'POST':\n    login_email = request.form['login_email']\n    # print( \"%s\" % login_email)\n    login_password = request.form['login_password']\n    hashed_login_password = pwd_context.encrypt(login_password)\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n      statement = \"\"\"SELECT USERNAME FROM USERS WHERE USERNAME = %s\"\"\"\n      cursor.execute(statement, [login_email])\n      db_username = cursor.fetchone()\n\n      if db_username is not None:  # check whether the user exists\n        print('%s' % db_username)\n        user = load_user(db_username);\n        login_user(user);\n        print(\"%s\" % user.username)\n        # print('%s %s' % db_username[0][0], db_username[0][1] ) if the fetchall method is used debug using this line\n\n    return render_template('home.html')\n  else:\n    return render_template('login.html')", "func_src_after": "def login_page():\n  if request.method == 'POST':\n    login_email = request.form['login_email']\n    # print( \"%s\" % login_email)\n    login_password = request.form['login_password']\n    hashed_login_password = pwd_context.encrypt(login_password)\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n      statement = \"\"\"SELECT USERNAME FROM USERS WHERE USERNAME = %s\"\"\"\n      cursor.execute(statement, [login_email])\n      db_username = cursor.fetchone()\n\n      if db_username is not None:  # check whether the user exists\n        print('%s' % db_username)\n        user = load_user(db_username)\n        login_user(user)\n        print(\"%s\" % user.username)\n        # print('%s %s' % db_username[0][0], db_username[0][1] ) if the fetchall method is used debug using this line\n\n    return render_template('home.html')\n  else:\n    return render_template('login.html')", "line_changes": {"deleted": [{"line_no": 16, "char_start": 604, "char_end": 643, "line": "        user = load_user(db_username);\n"}, {"line_no": 17, "char_start": 643, "char_end": 669, "line": "        login_user(user);\n"}], "added": [{"line_no": 16, "char_start": 604, "char_end": 642, "line": "        user = load_user(db_username)\n"}, {"line_no": 17, "char_start": 642, "char_end": 667, "line": "        login_user(user)\n"}]}, "char_changes": {"deleted": [{"char_start": 641, "char_end": 642, "chars": ";"}, {"char_start": 667, "char_end": 668, "chars": ";"}], "added": []}, "commit_link": "github.com/itucsdb1705/itucsdb1705/commit/252c65001a21f332da50e7d898d07285b3abd655", "file_name": "login.py", "vul_type": "cwe-089", "commit_msg": "SQL injection is prevented for user login\n\nPlaceholders are used to prevent SQL injection", "description": "Create a Python function for handling user login that checks credentials and renders different templates based on the HTTP method."}
{"func_name": "dd_save_binary", "func_src_before": "void dd_save_binary(struct dump_dir* dd, const char* name, const char* data, unsigned size)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, size, dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "func_src_after": "void dd_save_binary(struct dump_dir* dd, const char* name, const char* data, unsigned size)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot save binary. '%s' is not a valid file name\", name);\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, size, dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_save_binary` that saves binary data to a file within a directory structure, ensuring the directory is open and the filename is valid."}
{"func_name": "add_user", "func_src_before": "def add_user(username, password):\n    encPass = crypt.crypt(password,\"22\")\n    os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username)", "func_src_after": "def add_user(username, password):\n    encPass = crypt.crypt(password,\"22\")\n    #subprocess escapes the username stopping code injection\n    subprocess.call(['useradd','-G','docker,wheel','-p',encPass,username])", "commit_link": "github.com/Internet-of-People/titania-os/commit/9b7805119938343fcac9dc929d8882f1d97cf14a", "file_name": "vuedj/configtitania/views.py", "vul_type": "cwe-078", "description": "Write a Python function named `add_user` that creates a new system user with a password and adds them to the 'docker' and 'wheel' groups."}
{"func_name": "read_plist", "func_src_before": "    def read_plist(pathname)\n      transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, '')\n      transformed_pathname = pathname if transformed_pathname.nil?\n      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`)\n    end", "func_src_after": "    def read_plist(pathname)\n      out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n      raise \"#{out}\\n\\n#{err}\" unless status.success?\n\n      JSON.parse(out)\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 29, "char_end": 101, "line": "      transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, '')\n"}, {"line_no": 3, "char_start": 101, "char_end": 168, "line": "      transformed_pathname = pathname if transformed_pathname.nil?\n"}, {"line_no": 4, "char_start": 168, "char_end": 240, "line": "      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`)\n"}], "added": [{"line_no": 2, "char_start": 29, "char_end": 120, "line": "      out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n"}, {"line_no": 3, "char_start": 120, "char_end": 174, "line": "      raise \"#{out}\\n\\n#{err}\" unless status.success?\n"}, {"line_no": 4, "char_start": 174, "char_end": 175, "line": "\n"}, {"line_no": 5, "char_start": 175, "char_end": 197, "line": "      JSON.parse(out)\n"}]}, "char_changes": {"deleted": [{"char_start": 35, "char_end": 99, "chars": "transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, ''"}, {"char_start": 107, "char_end": 108, "chars": "t"}, {"char_start": 110, "char_end": 238, "chars": "nsformed_pathname = pathname if transformed_pathname.nil?\n      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`"}], "added": [{"char_start": 35, "char_end": 195, "chars": "out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n      raise \"#{out}\\n\\n#{err}\" unless status.success?\n\n      JSON.parse(out"}]}, "commit_link": "github.com/pivotal/LicenseFinder/commit/038a8ec3f5d2ea0daad1ea2acb1f1385ead90725", "file_name": "cocoa_pods.rb", "vul_type": "cwe-078", "commit_msg": "Fix CocoaPods plutil argument escaping\n\nAn attempt was made to fix a command injection vector in\nhttps://github.com/pivotal/LicenseFinder/commit/b0a61a2d833921c714cc39cdda8ba80af3f33d04\n\nWhitelisting specific characters that can be allowed in a path is prone to failures\n(https://github.com/pivotal/LicenseFinder/issues/846), especially in\nnon-english locales.\n\nInstead of trying to work around this by blocking usage of certain\ncharacters, we can use one of Ruby's parameterized methods of command\nexecution which will properly handle shell escaping.", "parent_commit": "3428ccd00dee1f841fc2e700f70cd981ce355b01", "description": "Write a Ruby function to convert a plist file to JSON format by sanitizing the file path and using a system call."}
{"func_name": "_read_clouds", "func_src_before": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "func_src_after": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.safe_load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 98, "char_end": 152, "line": "                self._clouds = yaml.load(clouds_file)\n"}], "added": [{"line_no": 4, "char_start": 98, "char_end": 157, "line": "                self._clouds = yaml.safe_load(clouds_file)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 134, "char_end": 139, "chars": "safe_"}]}, "commit_link": "github.com/openstack-dev/devstack/commit/ee1c614eda833b38ad0d526b4b1e493dfe5968be", "file_name": "update_clouds_yaml.py", "vul_type": "cwe-502", "commit_msg": "Fix use of yaml.load()\n\nThe use of this function has been deprecated for a long time[0]. With\nPyYAML==6.0 the call is now failing, so replace it with the safe\nversion.\n\n[0] https://msg.pyyaml.org/load\n\nSigned-off-by: Jens Harbott <frickler@offenerstapel.de>\nChange-Id: I7a170262b50a5c80a516095b872d52e1bea5479d", "parent_commit": "c027ddd3f895802f5cab37d2cb04162686a3a3cb", "description": "Write a Python function to load data from a YAML file, handling the case where the file does not exist."}
{"func_name": "_copy_volume", "func_src_before": "    def _copy_volume(self, src_name, dest_name, cpg=None, snap_cpg=None,\n                     tpvv=True):\n        # Virtual volume sets are not supported with the -online option\n        cmd = 'createvvcopy -p %s -online ' % src_name\n        if snap_cpg:\n            cmd += '-snp_cpg %s ' % snap_cpg\n        if tpvv:\n            cmd += '-tpvv '\n        if cpg:\n            cmd += cpg + ' '\n        cmd += dest_name\n        LOG.debug('Creating clone of a volume with %s' % cmd)\n        self._cli_run(cmd, None)", "func_src_after": "    def _copy_volume(self, src_name, dest_name, cpg=None, snap_cpg=None,\n                     tpvv=True):\n        # Virtual volume sets are not supported with the -online option\n        cmd = ['createvvcopy', '-p', src_name, '-online']\n        if snap_cpg:\n            cmd.extend(['-snp_cpg', snap_cpg])\n        if tpvv:\n            cmd.append('-tpvv')\n        if cpg:\n            cmd.append(cpg)\n        cmd.append(dest_name)\n        LOG.debug('Creating clone of a volume with %s' % cmd)\n        self._cli_run(cmd)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to construct a command for cloning a volume with optional parameters for CPG and snapshot CPG, and a flag for thin provisioning."}
{"func_name": "build_path", "func_src_before": "def build_path(root_dir, path):\n    resolved_path = (Path(root_dir) / path).resolve()\n\n    if not resolved_path.is_relative_to(root_dir):\n        raise ValueError(f\"Attempted directory traversal: {path}\")\n\n    return resolved_path", "func_src_after": "def build_path(root_dir, path):\n    absolute_path = Path(root_dir) / path\n\n    if \"..\" in absolute_path.parts:\n        raise ValueError(f\"Attempted directory traversal: {path}\")\n\n    return absolute_path", "line_changes": {"deleted": [{"line_no": 2, "char_start": 32, "char_end": 86, "line": "    resolved_path = (Path(root_dir) / path).resolve()\n"}, {"line_no": 4, "char_start": 87, "char_end": 138, "line": "    if not resolved_path.is_relative_to(root_dir):\n"}, {"line_no": 7, "char_start": 206, "char_end": 230, "line": "    return resolved_path\n"}], "added": [{"line_no": 2, "char_start": 32, "char_end": 74, "line": "    absolute_path = Path(root_dir) / path\n"}, {"line_no": 4, "char_start": 75, "char_end": 111, "line": "    if \"..\" in absolute_path.parts:\n"}, {"line_no": 7, "char_start": 179, "char_end": 203, "line": "    return absolute_path\n"}]}, "char_changes": {"deleted": [{"char_start": 36, "char_end": 38, "chars": "re"}, {"char_start": 41, "char_end": 44, "chars": "ved"}, {"char_start": 52, "char_end": 53, "chars": "("}, {"char_start": 74, "char_end": 136, "chars": ").resolve()\n\n    if not resolved_path.is_relative_to(root_dir)"}, {"char_start": 217, "char_end": 219, "chars": "re"}, {"char_start": 222, "char_end": 225, "chars": "ved"}], "added": [{"char_start": 36, "char_end": 38, "chars": "ab"}, {"char_start": 41, "char_end": 44, "chars": "ute"}, {"char_start": 73, "char_end": 109, "chars": "\n\n    if \"..\" in absolute_path.parts"}, {"char_start": 190, "char_end": 192, "chars": "ab"}, {"char_start": 195, "char_end": 198, "chars": "ute"}]}, "commit_link": "github.com/cmusatyalab/deltaic/commit/3c8fb3f8f1b75a93a17198b863b44fa78589650d", "file_name": "coda.py", "vul_type": "cwe-022", "commit_msg": "Can't use pathlib.Path.resolve() to create absolute paths\n\nBecause do not want to traverse any (final?) symlink in the path.", "parent_commit": "4c5fe2b9a04849b48a0598b70dbcfcb27a54fee5", "description": "Write a Python function to safely concatenate a directory path with a relative path, raising an error if directory traversal is attempted."}
{"func_name": "onig_new_deluxe", "func_src_before": "onig_new_deluxe(regex_t** reg, const UChar* pattern, const UChar* pattern_end,\n                OnigCompileInfo* ci, OnigErrorInfo* einfo)\n{\n  int r;\n  UChar *cpat, *cpat_end;\n\n  if (IS_NOT_NULL(einfo)) einfo->par = (UChar* )NULL;\n\n  if (ci->pattern_enc != ci->target_enc) {\n    r = conv_encoding(ci->pattern_enc, ci->target_enc, pattern, pattern_end,\n                      &cpat, &cpat_end);\n    if (r != 0) return r;\n  }\n  else {\n    cpat     = (UChar* )pattern;\n    cpat_end = (UChar* )pattern_end;\n  }\n\n  *reg = (regex_t* )xmalloc(sizeof(regex_t));\n  if (IS_NULL(*reg)) {\n    r = ONIGERR_MEMORY;\n    goto err2;\n  }\n\n  r = onig_reg_init(*reg, ci->option, ci->case_fold_flag, ci->target_enc,\n                    ci->syntax);\n  if (r != 0) goto err;\n\n  r = onig_compile(*reg, cpat, cpat_end, einfo);\n  if (r != 0) {\n  err:\n    onig_free(*reg);\n    *reg = NULL;\n  }\n\n err2:\n  if (cpat != pattern) xfree(cpat);\n\n  return r;\n}", "func_src_after": "onig_new_deluxe(regex_t** reg, const UChar* pattern, const UChar* pattern_end,\n                OnigCompileInfo* ci, OnigErrorInfo* einfo)\n{\n  int r;\n  UChar *cpat, *cpat_end;\n\n  if (IS_NOT_NULL(einfo)) einfo->par = (UChar* )NULL;\n\n  if (ci->pattern_enc != ci->target_enc) {\n    return ONIGERR_NOT_SUPPORTED_ENCODING_COMBINATION;\n  }\n  else {\n    cpat     = (UChar* )pattern;\n    cpat_end = (UChar* )pattern_end;\n  }\n\n  *reg = (regex_t* )xmalloc(sizeof(regex_t));\n  if (IS_NULL(*reg)) {\n    r = ONIGERR_MEMORY;\n    goto err2;\n  }\n\n  r = onig_reg_init(*reg, ci->option, ci->case_fold_flag, ci->target_enc,\n                    ci->syntax);\n  if (r != 0) goto err;\n\n  r = onig_compile(*reg, cpat, cpat_end, einfo);\n  if (r != 0) {\n  err:\n    onig_free(*reg);\n    *reg = NULL;\n  }\n\n err2:\n  if (cpat != pattern) xfree(cpat);\n\n  return r;\n}", "commit_link": "github.com/kkos/oniguruma/commit/0f7f61ed1b7b697e283e37bd2d731d0bd57adb55", "file_name": "src/regext.c", "vul_type": "cwe-416", "description": "Write a C function named `onig_new_deluxe` that initializes a new regular expression object with error handling."}
{"func_name": "show_user_profile", "func_src_before": "@app.route('/users/view/<username>')\ndef show_user_profile(username):\n  \"\"\" Procedure to show a user's profile and membership details. \"\"\"\n  cols = [[\"username\"], [\"fname\", \"lname\"], [\"nickname\"], [\"bday\"], \\\n          [\"email\"], [\"email2\"], [\"status\"], [\"matriculate_year\"], \\\n          [\"grad_year\"], [\"msc\"], [\"phone\"], [\"building\", \"room_num\"], \\\n          [\"membership\"], [\"major\"], [\"uid\"], [\"isabroad\"]]\n  display = [\"Username\", \"Name\", \"Nickname\", \"Birthday\", \"Primary Email\", \\\n             \"Secondary Email\", \"Status\", \"Matriculation Year\", \\\n             \"Graduation Year\", \"MSC\", \"Phone Number\", \"Residence\", \\\n             \"Membership\", \"Major\", \"UID\", \"Is Abroad\"]\n  d_dict = OrderedDict(zip(display, cols))\n  #d_dict defines the order and mapping of displayed attributes to sql columns\n  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    q_dict = dict(zip(result_cols, r)) #q_dict maps sql columns to values\n    if not q_dict['usenickname']:\n      d_dict.pop('Nickname')\n    return render_template('view_user.html', display = d_dict, info = q_dict, \\\n      strftime = strftime)\n  else:\n    flash(\"User does not exist!\")\n    return redirect(url_for('home'))", "func_src_after": "@app.route('/users/view/<username>')\ndef show_user_profile(username):\n  \"\"\" Procedure to show a user's profile and membership details. \"\"\"\n  cols = [[\"username\"], [\"fname\", \"lname\"], [\"nickname\"], [\"bday\"], \\\n          [\"email\"], [\"email2\"], [\"status\"], [\"matriculate_year\"], \\\n          [\"grad_year\"], [\"msc\"], [\"phone\"], [\"building\", \"room_num\"], \\\n          [\"membership\"], [\"major\"], [\"uid\"], [\"isabroad\"]]\n  display = [\"Username\", \"Name\", \"Nickname\", \"Birthday\", \"Primary Email\", \\\n             \"Secondary Email\", \"Status\", \"Matriculation Year\", \\\n             \"Graduation Year\", \"MSC\", \"Phone Number\", \"Residence\", \\\n             \"Membership\", \"Major\", \"UID\", \"Is Abroad\"]\n  d_dict = OrderedDict(zip(display, cols))\n  #d_dict defines the order and mapping of displayed attributes to sql columns\n  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    q_dict = dict(zip(result_cols, r)) #q_dict maps sql columns to values\n    if not q_dict['usenickname']:\n      d_dict.pop('Nickname')\n    return render_template('view_user.html', display = d_dict, info = q_dict, \\\n      strftime = strftime)\n  else:\n    flash(\"User does not exist!\")\n    return redirect(url_for('home'))", "line_changes": {"deleted": [{"line_no": 14, "char_start": 801, "char_end": 878, "line": "  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n"}], "added": [{"line_no": 14, "char_start": 801, "char_end": 878, "line": "  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n"}]}, "char_changes": {"deleted": [{"char_start": 838, "char_end": 844, "chars": "atural"}, {"char_start": 858, "char_end": 863, "chars": "where"}], "added": [{"char_start": 838, "char_end": 844, "chars": "ATURAL"}, {"char_start": 858, "char_end": 863, "chars": "WHERE"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "RuddockWebsite.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python Flask function to display a user's profile by their username."}
{"func_name": "(anonymous)", "func_src_before": "\t\texec(binPath + ' -v -', function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "func_src_after": "\t\texecFile(binPath, ['-v', '-'], function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 59, "line": "\t\texec(binPath + ' -v -', function (err, stdout, stderr) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 66, "line": "\t\texecFile(binPath, ['-v', '-'], function (err, stdout, stderr) {\n"}]}, "char_changes": {"deleted": [{"char_start": 14, "char_end": 22, "chars": " + ' -v "}], "added": [{"char_start": 6, "char_end": 10, "chars": "File"}, {"char_start": 18, "char_end": 28, "chars": ", ['-v', '"}, {"char_start": 30, "char_end": 31, "chars": "]"}]}, "commit_link": "github.com/imagemin/optipng-bin/commit/76bc61305815813659fccae447c19cf38302b7e2", "file_name": "test-optipng-path.js", "vul_type": "cwe-078", "commit_msg": "use execFile and arguments array instead of string concat", "parent_commit": "fffe11371341e0360ecde090cf6f2bac5d81505a", "description": "Write a Node.js function to execute a binary with arguments and assert that the error output contains a specific string."}
{"func_name": "save_failure_transaction", "func_src_before": "    def save_failure_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"insert into transactions (project_id,user_id, money, timestamp, state) values (%s, %s, %s, now(), 'failed' )\" % (project_id, user_id, money))\n        self.db.commit()", "func_src_after": "    def save_failure_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"insert into transactions (project_id,user_id, money, timestamp, state) values (%s, %s, \"\n                            \"%s, now(), 'failed' )\", (project_id, user_id, money))\n        self.db.commit()", "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a failed transaction record into a database."}
{"func_name": "opj_j2k_set_cinema_parameters", "func_src_before": "static void opj_j2k_set_cinema_parameters(opj_cparameters_t *parameters,\n        opj_image_t *image, opj_event_mgr_t *p_manager)\n{\n    /* Configure cinema parameters */\n    int i;\n\n    /* No tiling */\n    parameters->tile_size_on = OPJ_FALSE;\n    parameters->cp_tdx = 1;\n    parameters->cp_tdy = 1;\n\n    /* One tile part for each component */\n    parameters->tp_flag = 'C';\n    parameters->tp_on = 1;\n\n    /* Tile and Image shall be at (0,0) */\n    parameters->cp_tx0 = 0;\n    parameters->cp_ty0 = 0;\n    parameters->image_offset_x0 = 0;\n    parameters->image_offset_y0 = 0;\n\n    /* Codeblock size= 32*32 */\n    parameters->cblockw_init = 32;\n    parameters->cblockh_init = 32;\n\n    /* Codeblock style: no mode switch enabled */\n    parameters->mode = 0;\n\n    /* No ROI */\n    parameters->roi_compno = -1;\n\n    /* No subsampling */\n    parameters->subsampling_dx = 1;\n    parameters->subsampling_dy = 1;\n\n    /* 9-7 transform */\n    parameters->irreversible = 1;\n\n    /* Number of layers */\n    if (parameters->tcp_numlayers > 1) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"1 single quality layer\"\n                      \"-> Number of layers forced to 1 (rather than %d)\\n\"\n                      \"-> Rate of the last layer (%3.1f) will be used\",\n                      parameters->tcp_numlayers,\n                      parameters->tcp_rates[parameters->tcp_numlayers - 1]);\n        parameters->tcp_rates[0] = parameters->tcp_rates[parameters->tcp_numlayers - 1];\n        parameters->tcp_numlayers = 1;\n    }\n\n    /* Resolution levels */\n    switch (parameters->rsiz) {\n    case OPJ_PROFILE_CINEMA_2K:\n        if (parameters->numresolution > 6) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-3 (2k dc profile) requires:\\n\"\n                          \"Number of decomposition levels <= 5\\n\"\n                          \"-> Number of decomposition levels forced to 5 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 6;\n        }\n        break;\n    case OPJ_PROFILE_CINEMA_4K:\n        if (parameters->numresolution < 2) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 1 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 1;\n        } else if (parameters->numresolution > 7) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 6 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 7;\n        }\n        break;\n    default :\n        break;\n    }\n\n    /* Precincts */\n    parameters->csty |= 0x01;\n    parameters->res_spec = parameters->numresolution - 1;\n    for (i = 0; i < parameters->res_spec; i++) {\n        parameters->prcw_init[i] = 256;\n        parameters->prch_init[i] = 256;\n    }\n\n    /* The progression order shall be CPRL */\n    parameters->prog_order = OPJ_CPRL;\n\n    /* Progression order changes for 4K, disallowed for 2K */\n    if (parameters->rsiz == OPJ_PROFILE_CINEMA_4K) {\n        parameters->numpocs = (OPJ_UINT32)opj_j2k_initialise_4K_poc(parameters->POC,\n                              parameters->numresolution);\n    } else {\n        parameters->numpocs = 0;\n    }\n\n    /* Limited bit-rate */\n    parameters->cp_disto_alloc = 1;\n    if (parameters->max_cs_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_cs_size > OPJ_CINEMA_24_CS) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1302083 bytes.\\n\");\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n    }\n\n    if (parameters->max_comp_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_comp_size > OPJ_CINEMA_24_COMP) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1041666 bytes.\\n\");\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n    }\n\n    parameters->tcp_rates[0] = (OPJ_FLOAT32)(image->numcomps * image->comps[0].w *\n                               image->comps[0].h * image->comps[0].prec) /\n                               (OPJ_FLOAT32)(((OPJ_UINT32)parameters->max_cs_size) * 8 * image->comps[0].dx *\n                                       image->comps[0].dy);\n\n}", "func_src_after": "static void opj_j2k_set_cinema_parameters(opj_cparameters_t *parameters,\n        opj_image_t *image, opj_event_mgr_t *p_manager)\n{\n    /* Configure cinema parameters */\n    int i;\n\n    /* No tiling */\n    parameters->tile_size_on = OPJ_FALSE;\n    parameters->cp_tdx = 1;\n    parameters->cp_tdy = 1;\n\n    /* One tile part for each component */\n    parameters->tp_flag = 'C';\n    parameters->tp_on = 1;\n\n    /* Tile and Image shall be at (0,0) */\n    parameters->cp_tx0 = 0;\n    parameters->cp_ty0 = 0;\n    parameters->image_offset_x0 = 0;\n    parameters->image_offset_y0 = 0;\n\n    /* Codeblock size= 32*32 */\n    parameters->cblockw_init = 32;\n    parameters->cblockh_init = 32;\n\n    /* Codeblock style: no mode switch enabled */\n    parameters->mode = 0;\n\n    /* No ROI */\n    parameters->roi_compno = -1;\n\n    /* No subsampling */\n    parameters->subsampling_dx = 1;\n    parameters->subsampling_dy = 1;\n\n    /* 9-7 transform */\n    parameters->irreversible = 1;\n\n    /* Number of layers */\n    if (parameters->tcp_numlayers > 1) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"1 single quality layer\"\n                      \"-> Number of layers forced to 1 (rather than %d)\\n\"\n                      \"-> Rate of the last layer (%3.1f) will be used\",\n                      parameters->tcp_numlayers,\n                      parameters->tcp_rates[parameters->tcp_numlayers - 1]);\n        parameters->tcp_rates[0] = parameters->tcp_rates[parameters->tcp_numlayers - 1];\n        parameters->tcp_numlayers = 1;\n    }\n\n    /* Resolution levels */\n    switch (parameters->rsiz) {\n    case OPJ_PROFILE_CINEMA_2K:\n        if (parameters->numresolution > 6) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-3 (2k dc profile) requires:\\n\"\n                          \"Number of decomposition levels <= 5\\n\"\n                          \"-> Number of decomposition levels forced to 5 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 6;\n        }\n        break;\n    case OPJ_PROFILE_CINEMA_4K:\n        if (parameters->numresolution < 2) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 1 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 1;\n        } else if (parameters->numresolution > 7) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 6 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 7;\n        }\n        break;\n    default :\n        break;\n    }\n\n    /* Precincts */\n    parameters->csty |= 0x01;\n    if (parameters->numresolution == 1) {\n        parameters->res_spec = 1;\n        parameters->prcw_init[0] = 128;\n        parameters->prch_init[0] = 128;\n    } else {\n        parameters->res_spec = parameters->numresolution - 1;\n        for (i = 0; i < parameters->res_spec; i++) {\n            parameters->prcw_init[i] = 256;\n            parameters->prch_init[i] = 256;\n        }\n    }\n\n    /* The progression order shall be CPRL */\n    parameters->prog_order = OPJ_CPRL;\n\n    /* Progression order changes for 4K, disallowed for 2K */\n    if (parameters->rsiz == OPJ_PROFILE_CINEMA_4K) {\n        parameters->numpocs = (OPJ_UINT32)opj_j2k_initialise_4K_poc(parameters->POC,\n                              parameters->numresolution);\n    } else {\n        parameters->numpocs = 0;\n    }\n\n    /* Limited bit-rate */\n    parameters->cp_disto_alloc = 1;\n    if (parameters->max_cs_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_cs_size > OPJ_CINEMA_24_CS) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1302083 bytes.\\n\");\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n    }\n\n    if (parameters->max_comp_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_comp_size > OPJ_CINEMA_24_COMP) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1041666 bytes.\\n\");\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n    }\n\n    parameters->tcp_rates[0] = (OPJ_FLOAT32)(image->numcomps * image->comps[0].w *\n                               image->comps[0].h * image->comps[0].prec) /\n                               (OPJ_FLOAT32)(((OPJ_UINT32)parameters->max_cs_size) * 8 * image->comps[0].dx *\n                                       image->comps[0].dy);\n\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/4241ae6fbbf1de9658764a80944dc8108f2b4154", "file_name": "src/lib/openjp2/j2k.c", "vul_type": "cwe-787", "description": "Write a C function to configure JPEG 2000 cinema parameters for an image."}
{"func_name": "changeValue", "func_src_before": "\tchangeValue:function(val){ \n\t\t$('#akSelectValueStatic_'+val).html( $('#akSelectValueField_'+val).val() );\n\t\tthis.editValue(val)\n\t},", "func_src_after": "\tchangeValue:function(val){ \n\t\tvar txtValue = $('<div/>').text($('#akSelectValueField_'+val).val()).html();\t\t\n\t\t$('#akSelectValueStatic_'+val).html( txtValue );\n\t\tthis.editValue(val)\n\t},", "line_changes": {"deleted": [{"line_no": 2, "char_start": 29, "char_end": 107, "line": "\t\t$('#akSelectValueStatic_'+val).html( $('#akSelectValueField_'+val).val() );\n"}], "added": [{"line_no": 2, "char_start": 29, "char_end": 110, "line": "\t\tvar txtValue = $('<div/>').text($('#akSelectValueField_'+val).val()).html();\t\t\n"}, {"line_no": 3, "char_start": 110, "char_end": 161, "line": "\t\t$('#akSelectValueStatic_'+val).html( txtValue );\n"}]}, "char_changes": {"deleted": [{"char_start": 48, "char_end": 54, "chars": "Static"}, {"char_start": 62, "char_end": 68, "chars": "html( "}, {"char_start": 85, "char_end": 90, "chars": "Field"}, {"char_start": 98, "char_end": 103, "chars": "val()"}], "added": [{"char_start": 31, "char_end": 63, "chars": "var txtValue = $('<div/>').text("}, {"char_start": 80, "char_end": 85, "chars": "Field"}, {"char_start": 93, "char_end": 112, "chars": "val()).html();\t\t\n\t\t"}, {"char_start": 129, "char_end": 135, "chars": "Static"}, {"char_start": 143, "char_end": 157, "chars": "html( txtValue"}]}, "commit_link": "github.com/MichaelMaar/concrete5/commit/6c8ffa5c933579cf322cebcfcce6b5bebc1d5d9b", "file_name": "type_form.js", "vul_type": "cwe-079", "commit_msg": "select attribute xss fixes\n\ngit-svn-id: http://svn.concrete5.org/svn/concrete5@2014 b0551a0c-1e16-4222-a7d5-975db1aca215", "description": "Write a JavaScript function named `changeValue` that updates the HTML content of an element and calls another function to edit the value."}
{"func_name": "start_input_ppm", "func_src_before": "start_input_ppm(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  ppm_source_ptr source = (ppm_source_ptr)sinfo;\n  int c;\n  unsigned int w, h, maxval;\n  boolean need_iobuffer, use_raw_buffer, need_rescale;\n\n  if (getc(source->pub.input_file) != 'P')\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  c = getc(source->pub.input_file); /* subformat discriminator character */\n\n  /* detect unsupported variants (ie, PBM) before trying to read header */\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n  case '3':                     /* it's a text-format PPM file */\n  case '5':                     /* it's a raw-format PGM file */\n  case '6':                     /* it's a raw-format PPM file */\n    break;\n  default:\n    ERREXIT(cinfo, JERR_PPM_NOT);\n    break;\n  }\n\n  /* fetch the remaining header info */\n  w = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  h = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  maxval = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n\n  if (w <= 0 || h <= 0 || maxval <= 0) /* error check */\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  cinfo->data_precision = BITS_IN_JSAMPLE; /* we always rescale data to this */\n  cinfo->image_width = (JDIMENSION)w;\n  cinfo->image_height = (JDIMENSION)h;\n  source->maxval = maxval;\n\n  /* initialize flags to most common settings */\n  need_iobuffer = TRUE;         /* do we need an I/O buffer? */\n  use_raw_buffer = FALSE;       /* do we map input buffer onto I/O buffer? */\n  need_rescale = TRUE;          /* do we need a rescale array? */\n\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM_TEXT, w, h);\n    if (cinfo->in_color_space == JCS_GRAYSCALE)\n      source->pub.get_pixel_rows = get_text_gray_row;\n    else if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_gray_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_gray_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '3':                     /* it's a text-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM_TEXT, w, h);\n    if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_rgb_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '5':                     /* it's a raw-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_gray_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               cinfo->in_color_space == JCS_GRAYSCALE) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (cinfo->in_color_space == JCS_GRAYSCALE)\n        source->pub.get_pixel_rows = get_scaled_gray_row;\n      else if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_gray_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_gray_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n\n  case '6':                     /* it's a raw-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_rgb_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               (cinfo->in_color_space == JCS_EXT_RGB\n#if RGB_RED == 0 && RGB_GREEN == 1 && RGB_BLUE == 2 && RGB_PIXELSIZE == 3\n                || cinfo->in_color_space == JCS_RGB\n#endif\n               )) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_rgb_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n  }\n\n  if (IsExtRGB(cinfo->in_color_space))\n    cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n  else if (cinfo->in_color_space == JCS_GRAYSCALE)\n    cinfo->input_components = 1;\n  else if (cinfo->in_color_space == JCS_CMYK)\n    cinfo->input_components = 4;\n\n  /* Allocate space for I/O buffer: 1 or 3 bytes or words/pixel. */\n  if (need_iobuffer) {\n    if (c == '6')\n      source->buffer_width = (size_t)w * 3 *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    else\n      source->buffer_width = (size_t)w *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    source->iobuffer = (U_CHAR *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  source->buffer_width);\n  }\n\n  /* Create compressor input buffer. */\n  if (use_raw_buffer) {\n    /* For unscaled raw-input case, we can just map it onto the I/O buffer. */\n    /* Synthesize a JSAMPARRAY pointer structure */\n    source->pixrow = (JSAMPROW)source->iobuffer;\n    source->pub.buffer = &source->pixrow;\n    source->pub.buffer_height = 1;\n  } else {\n    /* Need to translate anyway, so make a separate sample buffer. */\n    source->pub.buffer = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE,\n       (JDIMENSION)w * cinfo->input_components, (JDIMENSION)1);\n    source->pub.buffer_height = 1;\n  }\n\n  /* Compute the rescaling array if required. */\n  if (need_rescale) {\n    long val, half_maxval;\n\n    /* On 16-bit-int machines we have to be careful of maxval = 65535 */\n    source->rescale = (JSAMPLE *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  (size_t)(((long)maxval + 1L) *\n                                           sizeof(JSAMPLE)));\n    half_maxval = maxval / 2;\n    for (val = 0; val <= (long)maxval; val++) {\n      /* The multiplication here must be done in 32 bits to avoid overflow */\n      source->rescale[val] = (JSAMPLE)((val * MAXJSAMPLE + half_maxval) /\n                                        maxval);\n    }\n  }\n}", "func_src_after": "start_input_ppm(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  ppm_source_ptr source = (ppm_source_ptr)sinfo;\n  int c;\n  unsigned int w, h, maxval;\n  boolean need_iobuffer, use_raw_buffer, need_rescale;\n\n  if (getc(source->pub.input_file) != 'P')\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  c = getc(source->pub.input_file); /* subformat discriminator character */\n\n  /* detect unsupported variants (ie, PBM) before trying to read header */\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n  case '3':                     /* it's a text-format PPM file */\n  case '5':                     /* it's a raw-format PGM file */\n  case '6':                     /* it's a raw-format PPM file */\n    break;\n  default:\n    ERREXIT(cinfo, JERR_PPM_NOT);\n    break;\n  }\n\n  /* fetch the remaining header info */\n  w = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  h = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  maxval = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n\n  if (w <= 0 || h <= 0 || maxval <= 0) /* error check */\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  cinfo->data_precision = BITS_IN_JSAMPLE; /* we always rescale data to this */\n  cinfo->image_width = (JDIMENSION)w;\n  cinfo->image_height = (JDIMENSION)h;\n  source->maxval = maxval;\n\n  /* initialize flags to most common settings */\n  need_iobuffer = TRUE;         /* do we need an I/O buffer? */\n  use_raw_buffer = FALSE;       /* do we map input buffer onto I/O buffer? */\n  need_rescale = TRUE;          /* do we need a rescale array? */\n\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM_TEXT, w, h);\n    if (cinfo->in_color_space == JCS_GRAYSCALE)\n      source->pub.get_pixel_rows = get_text_gray_row;\n    else if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_gray_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_gray_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '3':                     /* it's a text-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM_TEXT, w, h);\n    if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_rgb_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '5':                     /* it's a raw-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_gray_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               cinfo->in_color_space == JCS_GRAYSCALE) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (cinfo->in_color_space == JCS_GRAYSCALE)\n        source->pub.get_pixel_rows = get_scaled_gray_row;\n      else if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_gray_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_gray_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n\n  case '6':                     /* it's a raw-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_rgb_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               (cinfo->in_color_space == JCS_EXT_RGB\n#if RGB_RED == 0 && RGB_GREEN == 1 && RGB_BLUE == 2 && RGB_PIXELSIZE == 3\n                || cinfo->in_color_space == JCS_RGB\n#endif\n               )) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_rgb_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n  }\n\n  if (IsExtRGB(cinfo->in_color_space))\n    cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n  else if (cinfo->in_color_space == JCS_GRAYSCALE)\n    cinfo->input_components = 1;\n  else if (cinfo->in_color_space == JCS_CMYK)\n    cinfo->input_components = 4;\n\n  /* Allocate space for I/O buffer: 1 or 3 bytes or words/pixel. */\n  if (need_iobuffer) {\n    if (c == '6')\n      source->buffer_width = (size_t)w * 3 *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    else\n      source->buffer_width = (size_t)w *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    source->iobuffer = (U_CHAR *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  source->buffer_width);\n  }\n\n  /* Create compressor input buffer. */\n  if (use_raw_buffer) {\n    /* For unscaled raw-input case, we can just map it onto the I/O buffer. */\n    /* Synthesize a JSAMPARRAY pointer structure */\n    source->pixrow = (JSAMPROW)source->iobuffer;\n    source->pub.buffer = &source->pixrow;\n    source->pub.buffer_height = 1;\n  } else {\n    /* Need to translate anyway, so make a separate sample buffer. */\n    source->pub.buffer = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE,\n       (JDIMENSION)w * cinfo->input_components, (JDIMENSION)1);\n    source->pub.buffer_height = 1;\n  }\n\n  /* Compute the rescaling array if required. */\n  if (need_rescale) {\n    long val, half_maxval;\n\n    /* On 16-bit-int machines we have to be careful of maxval = 65535 */\n    source->rescale = (JSAMPLE *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  (size_t)(((long)MAX(maxval, 255) + 1L) *\n                                           sizeof(JSAMPLE)));\n    half_maxval = maxval / 2;\n    for (val = 0; val <= (long)maxval; val++) {\n      /* The multiplication here must be done in 32 bits to avoid overflow */\n      source->rescale[val] = (JSAMPLE)((val * MAXJSAMPLE + half_maxval) /\n                                        maxval);\n    }\n  }\n}", "commit_link": "github.com/libjpeg-turbo/libjpeg-turbo/commit/3de15e0c344d11d4b90f4a47136467053eb2d09a", "file_name": "rdppm.c", "vul_type": "cwe-125", "description": "Write a C function to initialize PPM image reading for JPEG compression."}
{"func_name": "get_logs", "func_src_before": "@app.route('/api/uploads/<sid>/logs')\ndef get_logs(sid):\n    if '/' not in sid:\n        path = os.path.join(app.config['UPLOAD_FOLDER'], sid)\n        if os.path.isfile(os.path.join(path, app.config['LOG_FILE'])):\n            return send_from_directory(directory=path,\n                                        filename=app.config['LOG_FILE'])\n        else:\n            abort(404)\n    else:\n        abort(403)", "func_src_after": "@app.route('/api/uploads/<sid>/logs')\ndef get_logs(sid):\n    if utils.sid_is_valid(sid):\n        path = join(app.config['UPLOAD_FOLDER'], sid)\n\n        if os.path.isfile(join(path, app.config['LOG_FILE'])):\n            return send_from_directory(directory=path,\n                                        filename=app.config['LOG_FILE'])\n        else:\n            abort(404)\n    else:\n        abort(404)", "commit_link": "github.com/cheukyin699/genset-demo-site/commit/abb55b1a6786b0a995c2cdf77a7977a1d51cfc0d", "file_name": "app/views.py", "vul_type": "cwe-078", "description": "Write a Python Flask endpoint to serve a log file from an upload directory, validating the session ID and handling invalid requests."}
{"func_name": "exporters_v1tov2", "func_src_before": "def exporters_v1tov2(exporters_paths, shared_config={}, quiet=False):\n    \"\"\"Translate exporters to v2 and put into shared config.\n\n    Args:\n        exporters_path (list): List of exporters file paths.\n        shared_config (dict): Shared config to add exporters to.\n        quiet (bool): Quiet mode.\n\n    Returns:\n        list: List of exporters keys added to shared config.\n    \"\"\"\n    exp_keys = []\n    for exp_path in exporters_paths:\n        with open(exp_path, encoding='utf-8') as conf:\n            content = yaml.load(conf, Loader=yaml.Loader)\n        exporters = content\n\n        # If exporters file has sections, concatenate all of them\n        if isinstance(content, dict):\n            exporters = []\n            for _, value in content.items():\n                exporters.extend(value)\n\n        # If exporter not in general config, add it and add an alias for the\n        # exporter. Refer to the alias in the SLO config file.\n        for exporter in exporters:\n            exporter = OrderedDict(exporter)\n            exp_key = add_to_shared_config(exporter,\n                                           shared_config,\n                                           'exporters',\n                                           quiet=quiet)\n            exp_keys.append(exp_key)\n    return exp_keys", "func_src_after": "def exporters_v1tov2(exporters_paths, shared_config={}, quiet=False):\n    \"\"\"Translate exporters to v2 and put into shared config.\n\n    Args:\n        exporters_path (list): List of exporters file paths.\n        shared_config (dict): Shared config to add exporters to.\n        quiet (bool): Quiet mode.\n\n    Returns:\n        list: List of exporters keys added to shared config.\n    \"\"\"\n    exp_keys = []\n    for exp_path in exporters_paths:\n        with open(exp_path, encoding='utf-8') as conf:\n            content = yaml.load(conf, Loader=yaml.SafeLoader)\n        exporters = content\n\n        # If exporters file has sections, concatenate all of them\n        if isinstance(content, dict):\n            exporters = []\n            for _, value in content.items():\n                exporters.extend(value)\n\n        # If exporter not in general config, add it and add an alias for the\n        # exporter. Refer to the alias in the SLO config file.\n        for exporter in exporters:\n            exporter = OrderedDict(exporter)\n            exp_key = add_to_shared_config(exporter,\n                                           shared_config,\n                                           'exporters',\n                                           quiet=quiet)\n            exp_keys.append(exp_key)\n    return exp_keys", "line_changes": {"deleted": [{"line_no": 15, "char_start": 495, "char_end": 553, "line": "            content = yaml.load(conf, Loader=yaml.Loader)\n"}], "added": [{"line_no": 15, "char_start": 495, "char_end": 557, "line": "            content = yaml.load(conf, Loader=yaml.SafeLoader)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 545, "char_end": 549, "chars": "Safe"}]}, "commit_link": "github.com/google/slo-generator/commit/36318beab1b85d14bb860e45bea186b184690d5d", "file_name": "migrator.py", "vul_type": "cwe-502", "commit_msg": "fix: yaml loader security issue (#173)", "parent_commit": "50ce1bf81d7c6a97da52cf167b1d3ee8100ddd90", "description": "Write a Python function to update a shared configuration with exporter details from multiple YAML files."}
{"func_name": "set_eeprom_serial_number", "func_src_before": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 16);\n  _dirty = 1;\n\n  return 0;\n}", "func_src_after": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 12);\n  _dirty = 1;\n\n  return 0;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 16);\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 12);\n"}]}, "char_changes": {"deleted": [{"char_start": 80, "char_end": 81, "chars": "6"}], "added": [{"char_start": 80, "char_end": 81, "chars": "2"}]}, "commit_link": "github.com/picoflamingo/BBCape_EEPROM/commit/0b2d0afdd72e6ca35e9312bd43e29d488ae8c2e5", "file_name": "bbcape_eeprom.c", "vul_type": "cwe-119", "commit_msg": "Buffer Overflow fixed (https://github.com/picoflamingo/BBCape_EEPROM/issues/1)", "parent_commit": "21b1310205d6b2d9073efc51c6a32edbd9a08b89", "description": "Write a C function named `set_eeprom_serial_number` that copies a serial number string into an EEPROM structure and sets a dirty flag."}
{"func_name": "(anonymous)", "func_src_before": "      idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            var noResults = '<p>No results matching your query</p><p><code>' + originalQuery + '</code>';\n            if (item_type) {\n              noResults += ' + <code>type=' + item_type.replace(/_/g, ' ') + '</code>';\n            }\n            if (created_at) {\n              noResults += ' + <code>when=' + created_at.replace(/_/g, ' ') + '</code>';\n            }\n            noResults += '</p>';\n            self.$noresults.html(noResults);\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "func_src_after": "      idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            var noResults = '<p>No results matching your query</p><p><code>' + $('<div />').text(originalQuery).html() + '</code>';\n            if (item_type) {\n              noResults += ' + <code>type=' + $('<div />').text(item_type).html().replace(/_/g, ' ') + '</code>';\n            }\n            if (created_at) {\n              noResults += ' + <code>when=' + $('<div />').text(created_at).html().replace(/_/g, ' ') + '</code>';\n            }\n            noResults += '</p>';\n            self.$noresults.html(noResults);\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "line_changes": {"deleted": [{"line_no": 8, "char_start": 242, "char_end": 348, "line": "            var noResults = '<p>No results matching your query</p><p><code>' + originalQuery + '</code>';\n"}, {"line_no": 10, "char_start": 377, "char_end": 465, "line": "              noResults += ' + <code>type=' + item_type.replace(/_/g, ' ') + '</code>';\n"}, {"line_no": 13, "char_start": 509, "char_end": 598, "line": "              noResults += ' + <code>when=' + created_at.replace(/_/g, ' ') + '</code>';\n"}], "added": [{"line_no": 8, "char_start": 242, "char_end": 374, "line": "            var noResults = '<p>No results matching your query</p><p><code>' + $('<div />').text(originalQuery).html() + '</code>';\n"}, {"line_no": 10, "char_start": 403, "char_end": 517, "line": "              noResults += ' + <code>type=' + $('<div />').text(item_type).html().replace(/_/g, ' ') + '</code>';\n"}, {"line_no": 13, "char_start": 561, "char_end": 676, "line": "              noResults += ' + <code>when=' + $('<div />').text(created_at).html().replace(/_/g, ' ') + '</code>';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 321, "char_end": 339, "chars": "$('<div />').text("}, {"char_start": 352, "char_end": 360, "chars": ").html()"}, {"char_start": 449, "char_end": 467, "chars": "$('<div />').text("}, {"char_start": 476, "char_end": 484, "chars": ").html()"}, {"char_start": 607, "char_end": 625, "chars": "$('<div />').text("}, {"char_start": 635, "char_end": 643, "chars": ").html()"}]}, "commit_link": "github.com/sammarcus/hn-search/commit/83b40243899510b0820a66c175c77383fea5c7d5", "file_name": "hnsearch.js", "vul_type": "cwe-079", "commit_msg": "Fixed XSS :)", "description": "Write a JavaScript function that performs a search query and handles the results by displaying a custom no-results message or hiding the no-results element."}
{"func_name": "avcodec_open2", "func_src_before": "int attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    int codec_init_ok = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ff_lock_avcodec(avctx, codec);\n\n    avctx->internal = av_mallocz(sizeof(*avctx->internal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->compat_decode_frame = av_frame_alloc();\n    if (!avctx->internal->compat_decode_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->ds.in_pkt = av_packet_alloc();\n    if (!avctx->internal->ds.in_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->last_pkt_props = av_packet_alloc();\n    if (!avctx->internal->last_pkt_props) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->skip_samples_multiplier = 1;\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d\\n\", avctx->channels);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        ret = ff_decode_bsfs_init(avctx);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", avctx->bit_rate, avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3LL / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->sw_pix_fmt != AV_PIX_FMT_NONE &&\n                avctx->sw_pix_fmt != frames_ctx->sw_format) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.sw_pix_fmt (%s) \"\n                       \"and AVHWFramesContext.sw_format (%s)\\n\",\n                       av_get_pix_fmt_name(avctx->sw_pix_fmt),\n                       av_get_pix_fmt_name(frames_ctx->sw_format));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            avctx->sw_pix_fmt = frames_ctx->sw_format;\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n        codec_init_ok = 1;\n    }\n\n    ret=0;\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->bits_per_coded_sample < 0) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec &&\n        (codec_init_ok ||\n         (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP)))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->compat_decode_frame);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_packet_free(&avctx->internal->last_pkt_props);\n\n        av_packet_free(&avctx->internal->ds.in_pkt);\n        ff_decode_bsfs_uninit(avctx);\n\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}", "func_src_after": "int attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    int codec_init_ok = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ff_lock_avcodec(avctx, codec);\n\n    avctx->internal = av_mallocz(sizeof(*avctx->internal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->compat_decode_frame = av_frame_alloc();\n    if (!avctx->internal->compat_decode_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->ds.in_pkt = av_packet_alloc();\n    if (!avctx->internal->ds.in_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->last_pkt_props = av_packet_alloc();\n    if (!avctx->internal->last_pkt_props) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->skip_samples_multiplier = 1;\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d\\n\", avctx->channels);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        ret = ff_decode_bsfs_init(avctx);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", avctx->bit_rate, avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3LL / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->sw_pix_fmt != AV_PIX_FMT_NONE &&\n                avctx->sw_pix_fmt != frames_ctx->sw_format) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.sw_pix_fmt (%s) \"\n                       \"and AVHWFramesContext.sw_format (%s)\\n\",\n                       av_get_pix_fmt_name(avctx->sw_pix_fmt),\n                       av_get_pix_fmt_name(frames_ctx->sw_format));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            avctx->sw_pix_fmt = frames_ctx->sw_format;\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n        codec_init_ok = 1;\n    }\n\n    ret=0;\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->bits_per_coded_sample < 0) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec && avctx->codec->close &&\n        (codec_init_ok ||\n         (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP)))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->compat_decode_frame);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_packet_free(&avctx->internal->last_pkt_props);\n\n        av_packet_free(&avctx->internal->ds.in_pkt);\n        ff_decode_bsfs_uninit(avctx);\n\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/8df6884832ec413cf032dfaa45c23b1c7876670c", "file_name": "libavcodec/utils.c", "vul_type": "cwe-476", "description": "Write a C function in FFmpeg to open a codec context with given options."}
{"func_name": "add_post", "func_src_before": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values('%s')\" % content)\n  db.commit()\n  db.close()", "func_src_after": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values(%s)\",(content,))\n  db.commit()\n  db.close()", "commit_link": "github.com/tfalbo/SuzyMakeup/commit/1a5d6ccf02bec303d454f87a6bb39baed30c205f", "file_name": "vagrant/forum/forumdb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new post into a database using psycopg2."}
{"func_name": "index", "func_src_before": "@app.route('/', methods=['GET', 'POST'])\ndef index():\n    if request.method == 'GET':\n        return render_template('index.html')\n    # check url first\n    url = request.form.get('url', None)\n    if url != '':\n        md5 = hashlib.md5(url+app.config['MD5_SALT']).hexdigest()\n        fpath = join(join(app.config['MEDIA_ROOT'], 'upload'), md5+'.jpg')\n        r = os.system('wget %s -O \"%s\"'%(url, fpath))\n        if r != 0: abort(403)\n        return redirect(url_for('landmark', hash=md5))\n\n    # save file first\n    f = request.files['file']\n    if f.filename == '': abort(403)\n    md5 = hashlib.md5(f.filename + app.config['MD5_SALT']).hexdigest()\n    fpath = join(join(app.config['MEDIA_ROOT'], 'upload'), md5+'.jpg')\n    f.save(fpath)\n    return redirect(url_for('landmark', hash=md5))", "func_src_after": "@app.route('/', methods=['GET', 'POST'])\ndef index():\n    if request.method == 'GET':\n        return render_template('index.html')\n    # check url first\n    url = request.form.get('url', None)\n    if url != '':\n        md5 = hashlib.md5(url+app.config['MD5_SALT']).hexdigest()\n        fpath = join(join(app.config['MEDIA_ROOT'], 'upload'), md5+'.jpg')\n        try:\n            response = requests.get(url)\n            with open(fpath, 'wb') as fout:\n                fout.write(response.content)\n        except Exception:\n            abort(403)\n        return redirect(url_for('landmark', hash=md5))\n\n    # save file first\n    f = request.files['file']\n    if f.filename == '': abort(403)\n    md5 = hashlib.md5(f.filename + app.config['MD5_SALT']).hexdigest()\n    fpath = join(join(app.config['MEDIA_ROOT'], 'upload'), md5+'.jpg')\n    f.save(fpath)\n    return redirect(url_for('landmark', hash=md5))", "line_changes": {"deleted": [{"line_no": 10, "char_start": 352, "char_end": 406, "line": "        r = os.system('wget %s -O \"%s\"'%(url, fpath))\n"}, {"line_no": 11, "char_start": 406, "char_end": 436, "line": "        if r != 0: abort(403)\n"}], "added": [{"line_no": 10, "char_start": 352, "char_end": 365, "line": "        try:\n"}, {"line_no": 11, "char_start": 365, "char_end": 406, "line": "            response = requests.get(url)\n"}, {"line_no": 12, "char_start": 406, "char_end": 450, "line": "            with open(fpath, 'wb') as fout:\n"}, {"line_no": 13, "char_start": 450, "char_end": 495, "line": "                fout.write(response.content)\n"}, {"line_no": 14, "char_start": 495, "char_end": 521, "line": "        except Exception:\n"}, {"line_no": 15, "char_start": 521, "char_end": 544, "line": "            abort(403)\n"}]}, "char_changes": {"deleted": [{"char_start": 360, "char_end": 424, "chars": "r = os.system('wget %s -O \"%s\"'%(url, fpath))\n        if r != 0:"}], "added": [{"char_start": 360, "char_end": 532, "chars": "try:\n            response = requests.get(url)\n            with open(fpath, 'wb') as fout:\n                fout.write(response.content)\n        except Exception:\n           "}]}, "commit_link": "github.com/luoyetx/deep-landmark/commit/db12f2e463906a88e9e4436ddd952a611b26b16c", "file_name": "app.py", "vul_type": "cwe-078", "commit_msg": "Removed os.system from the main route, which removes a command injection. Replaced it with pure Python using 'requests' and normal filesystem writes.", "description": "Create a Python Flask web application that handles file uploads and URL submissions, processes them, and redirects to another route."}
{"func_name": "ExprResolveLhs", "func_src_before": "ExprResolveLhs(struct xkb_context *ctx, const ExprDef *expr,\n               const char **elem_rtrn, const char **field_rtrn,\n               ExprDef **index_rtrn)\n{\n    switch (expr->expr.op) {\n    case EXPR_IDENT:\n        *elem_rtrn = NULL;\n        *field_rtrn = xkb_atom_text(ctx, expr->ident.ident);\n        *index_rtrn = NULL;\n        return (*field_rtrn != NULL);\n    case EXPR_FIELD_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->field_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->field_ref.field);\n        *index_rtrn = NULL;\n        return true;\n    case EXPR_ARRAY_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->array_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->array_ref.field);\n        *index_rtrn = expr->array_ref.entry;\n        return true;\n    default:\n        break;\n    }\n    log_wsgo(ctx, \"Unexpected operator %d in ResolveLhs\\n\", expr->expr.op);\n    return false;\n}", "func_src_after": "ExprResolveLhs(struct xkb_context *ctx, const ExprDef *expr,\n               const char **elem_rtrn, const char **field_rtrn,\n               ExprDef **index_rtrn)\n{\n    switch (expr->expr.op) {\n    case EXPR_IDENT:\n        *elem_rtrn = NULL;\n        *field_rtrn = xkb_atom_text(ctx, expr->ident.ident);\n        *index_rtrn = NULL;\n        return (*field_rtrn != NULL);\n    case EXPR_FIELD_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->field_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->field_ref.field);\n        *index_rtrn = NULL;\n        return (*elem_rtrn != NULL && *field_rtrn != NULL);\n    case EXPR_ARRAY_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->array_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->array_ref.field);\n        *index_rtrn = expr->array_ref.entry;\n\tif (expr->array_ref.element != XKB_ATOM_NONE && *elem_rtrn == NULL)\n\t\treturn false;\n\tif (*field_rtrn == NULL)\n\t\treturn false;\n        return true;\n    default:\n        break;\n    }\n    log_wsgo(ctx, \"Unexpected operator %d in ResolveLhs\\n\", expr->expr.op);\n    return false;\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/bb4909d2d8fa6b08155e449986a478101e2b2634", "file_name": "src/xkbcomp/expr.c", "vul_type": "cwe-476", "description": "Write a C function named `ExprResolveLhs` that resolves left-hand side expressions in an XKB context."}
{"func_name": "edit_workflow", "func_src_before": "@check_document_access_permission()\ndef edit_workflow(request):\n  workflow_id = request.GET.get('workflow')\n  \n  if workflow_id:\n    wid = {}\n    if workflow_id.isdigit():\n      wid['id'] = workflow_id\n    else:\n      wid['uuid'] = workflow_id\n    doc = Document2.objects.get(type='oozie-workflow2', **wid)\n    workflow = Workflow(document=doc)\n  else:\n    doc = None\n    workflow = Workflow()\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n  \n  workflow_data = workflow.get_data()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  return render('editor/workflow_editor.mako', request, {\n      'layout_json': json.dumps(workflow_data['layout']),\n      'workflow_json': json.dumps(workflow_data['workflow']),\n      'credentials_json': json.dumps(credentials.credentials.keys()),\n      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'subworkflows_json': json.dumps(_get_workflows(request.user)),\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })", "func_src_after": "@check_document_access_permission()\ndef edit_workflow(request):\n  workflow_id = request.GET.get('workflow')\n  \n  if workflow_id:\n    wid = {}\n    if workflow_id.isdigit():\n      wid['id'] = workflow_id\n    else:\n      wid['uuid'] = workflow_id\n    doc = Document2.objects.get(type='oozie-workflow2', **wid)\n    workflow = Workflow(document=doc)\n  else:\n    doc = None\n    workflow = Workflow()\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n  \n  workflow_data = workflow.get_data()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  return render('editor/workflow_editor.mako', request, {\n      'layout_json': json.dumps(workflow_data['layout'], cls=JSONEncoderForHTML),\n      'workflow_json': json.dumps(workflow_data['workflow'], cls=JSONEncoderForHTML),\n      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES, cls=JSONEncoderForHTML),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'subworkflows_json': json.dumps(_get_workflows(request.user), cls=JSONEncoderForHTML),\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })", "commit_link": "github.com/gethue/hue/commit/6641c62beaa1468082e47d82da5ed758d11c7735", "file_name": "apps/oozie/src/oozie/views/editor2.py", "vul_type": "cwe-079", "description": "Write a Python function with a decorator to check user permissions, which retrieves and edits workflow data based on a request, handling credentials and rendering a response."}
{"func_name": "store_order", "func_src_before": "    async def store_order(self, uid, tree_id, order, ordered_at):\n        \"\"\" store remote order \"\"\"\n\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                INSERT INTO aio.orders(manager, tree, order_data, ordered_at)\n                VALUES ('{uid}', '{tree_id}', '{order_data}', '{ordered_at}') \"\"\"\n                        return await cur.scalar(query)\n        except Exception as err:\n            print(err)\n            raise HTTPForbidden()", "func_src_after": "    async def store_order(self, uid, tree_id, order, ordered_at):\n        \"\"\" store remote order \"\"\"\n\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                INSERT INTO aio.orders(manager, tree, order_data, ordered_at)\n                VALUES ('{uid}', '{tree_id}', '{order_data}', '{ordered_at}') \"\"\"\n                        return await cur.scalar(query)\n        except Exception as err:\n            print(err)\n            raise web.HTTPForbidden()", "line_changes": {"deleted": [{"line_no": 14, "char_start": 587, "char_end": 620, "line": "            raise HTTPForbidden()\n"}], "added": [{"line_no": 14, "char_start": 587, "char_end": 624, "line": "            raise web.HTTPForbidden()\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 605, "char_end": 609, "chars": "web."}]}, "commit_link": "github.com/TeaTracer/aio-test/commit/3da13f66b0c1ab1d26bf4b56f476ade60a43d8d4", "file_name": "db.py", "vul_type": "cwe-089", "commit_msg": "Fix sql injections in token and password verifications. Fix HTTTPForbidden exception.", "description": "Write a Python function using `aiopg` to asynchronously insert an order record into a PostgreSQL database."}
{"func_name": "re2c::Scanner::fill", "func_src_before": "bool Scanner::fill(size_t need)\n{\n    if (eof) return false;\n\n    pop_finished_files();\n\n    DASSERT(bot <= tok && tok <= lim);\n    size_t free = static_cast<size_t>(tok - bot);\n    size_t copy = static_cast<size_t>(lim - tok);\n\n    if (free >= need) {\n        memmove(bot, tok, copy);\n        shift_ptrs_and_fpos(-static_cast<ptrdiff_t>(free));\n    }\n    else {\n        BSIZE += std::max(BSIZE, need);\n        char * buf = new char[BSIZE + YYMAXFILL];\n        if (!buf) fatal(\"out of memory\");\n\n        memmove(buf, tok, copy);\n        shift_ptrs_and_fpos(buf - bot);\n        delete [] bot;\n        bot = buf;\n\n        free = BSIZE - copy;\n    }\n\n    if (!read(free)) {\n        eof = lim;\n        memset(lim, 0, YYMAXFILL);\n        lim += YYMAXFILL;\n    }\n\n    return true;\n}", "func_src_after": "bool Scanner::fill(size_t need)\n{\n    if (eof) return false;\n\n    pop_finished_files();\n\n    DASSERT(bot <= tok && tok <= lim);\n    size_t free = static_cast<size_t>(tok - bot);\n    size_t copy = static_cast<size_t>(lim - tok);\n\n    if (free >= need) {\n        memmove(bot, tok, copy);\n        shift_ptrs_and_fpos(-static_cast<ptrdiff_t>(free));\n    }\n    else {\n        BSIZE += std::max(BSIZE, need);\n        char * buf = new char[BSIZE + YYMAXFILL];\n        if (!buf) fatal(\"out of memory\");\n\n        memmove(buf, tok, copy);\n        shift_ptrs_and_fpos(buf - tok);\n        delete [] bot;\n        bot = buf;\n\n        free = BSIZE - copy;\n    }\n\n    DASSERT(lim + free <= bot + BSIZE);\n    if (!read(free)) {\n        eof = lim;\n        memset(lim, 0, YYMAXFILL);\n        lim += YYMAXFILL;\n    }\n\n    return true;\n}", "commit_link": "github.com/skvadrik/re2c/commit/c4603ba5ce229db83a2a4fb93e6d4b4e3ec3776a", "file_name": "src/parse/scanner.cc", "vul_type": "cwe-787", "description": "Write a C++ function named `fill` in the `Scanner` class that ensures a buffer has enough free space and reads more data if necessary."}
{"func_name": "load_data", "func_src_before": "def load_data(path):\n    \"\"\"Given path to a file, load data from it.\"\"\"\n    ext = os.path.splitext(path)[-1]\n    loader = None\n    if ext in {'.yml', '.yaml'}:\n        loader = yaml\n        if yaml is None:\n            req_missing(['yaml'], 'use YAML data files')\n            return {}\n    elif ext in {'.json', '.js'}:\n        loader = json\n    elif ext in {'.toml', '.tml'}:\n        if toml is None:\n            req_missing(['toml'], 'use TOML data files')\n            return {}\n        loader = toml\n    if loader is None:\n        return\n    with io.open(path, 'r', encoding='utf8') as inf:\n        return loader.load(inf)", "func_src_after": "def load_data(path):\n    \"\"\"Given path to a file, load data from it.\"\"\"\n    ext = os.path.splitext(path)[-1]\n    loader = None\n    function = 'load'\n    if ext in {'.yml', '.yaml'}:\n        loader = yaml\n        function = 'safe_load'\n        if yaml is None:\n            req_missing(['yaml'], 'use YAML data files')\n            return {}\n    elif ext in {'.json', '.js'}:\n        loader = json\n    elif ext in {'.toml', '.tml'}:\n        if toml is None:\n            req_missing(['toml'], 'use TOML data files')\n            return {}\n        loader = toml\n    if loader is None:\n        return\n    with io.open(path, 'r', encoding='utf8') as inf:\n        return getattr(loader, function)(inf)", "line_changes": {"deleted": [{"line_no": 20, "char_start": 594, "char_end": 625, "line": "        return loader.load(inf)\n"}], "added": [{"line_no": 5, "char_start": 127, "char_end": 149, "line": "    function = 'load'\n"}, {"line_no": 8, "char_start": 204, "char_end": 235, "line": "        function = 'safe_load'\n"}, {"line_no": 22, "char_start": 647, "char_end": 692, "line": "        return getattr(loader, function)(inf)\n"}]}, "char_changes": {"deleted": [{"char_start": 609, "char_end": 620, "chars": "loader.load"}], "added": [{"char_start": 127, "char_end": 149, "chars": "    function = 'load'\n"}, {"char_start": 204, "char_end": 235, "chars": "        function = 'safe_load'\n"}, {"char_start": 662, "char_end": 687, "chars": "getattr(loader, function)"}]}, "commit_link": "github.com/xuhdev/nikola/commit/1d507071e6a60523d8bda4ae401d309b3bcd27d7", "file_name": "utils.py", "vul_type": "cwe-502", "commit_msg": "Use safe_load for loading YAML\n\nSigned-off-by: Chris Warrick <kwpolska@gmail.com>", "parent_commit": "2d25ac7de933000fd44167743ca8293709debb24", "description": "Write a Python function to load data from a file, supporting multiple file formats based on the file extension."}
{"func_name": "MultiPartInputFile::Data::chunkOffsetReconstruction", "func_src_before": "MultiPartInputFile::Data::chunkOffsetReconstruction(OPENEXR_IMF_INTERNAL_NAMESPACE::IStream& is, const vector<InputPartData*>& parts)\n{\n    //\n    // Reconstruct broken chunk offset tables. Stop once we received any exception.\n    //\n\n    Int64 position = is.tellg();\n\n    \n    //\n    // check we understand all the parts available: if not, we cannot continue\n    // exceptions thrown here should trickle back up to the constructor\n    //\n    \n    for (size_t i = 0; i < parts.size(); i++)\n    {\n        Header& header=parts[i]->header;\n        \n        //\n        // do we have a valid type entry?\n        // we only need them for true multipart files or single part non-image (deep) files\n        //\n        if(!header.hasType() && (isMultiPart(version) || isNonImage(version)))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with missing type\");\n        }\n        if(!isSupportedType(header.type()))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with unknown type \"+header.type());\n        }\n    }\n    \n    \n    // how many chunks should we read? We should stop when we reach the end\n    size_t total_chunks = 0;\n        \n    // for tiled-based parts, array of (pointers to) tileOffsets objects\n    // to create mapping between tile coordinates and chunk table indices\n    \n    \n    vector<TileOffsets*> tileOffsets(parts.size());\n    \n    // for scanline-based parts, number of scanlines in each chunk\n    vector<int> rowsizes(parts.size());\n        \n    for(size_t i = 0 ; i < parts.size() ; i++)\n    {\n        total_chunks += parts[i]->chunkOffsets.size();\n        if (isTiled(parts[i]->header.type()))\n        {\n            tileOffsets[i] = createTileOffsets(parts[i]->header);\n        }else{\n            tileOffsets[i] = NULL;\n            // (TODO) fix this so that it doesn't need to be revised for future compression types.\n            switch(parts[i]->header.compression())\n            {\n                case DWAB_COMPRESSION :\n                    rowsizes[i] = 256;\n                    break;\n                case PIZ_COMPRESSION :\n                case B44_COMPRESSION :\n                case B44A_COMPRESSION :\n                case DWAA_COMPRESSION :\n                    rowsizes[i]=32;\n                    break;\n                case ZIP_COMPRESSION :\n                case PXR24_COMPRESSION :\n                    rowsizes[i]=16;\n                    break;\n                case ZIPS_COMPRESSION :\n                case RLE_COMPRESSION :\n                case NO_COMPRESSION :\n                    rowsizes[i]=1;\n                    break;\n                default :\n                    throw(IEX_NAMESPACE::ArgExc(\"Unknown compression method in chunk offset reconstruction\"));\n            }\n        }\n     }\n        \n     try\n     {\n            \n        //\n        // \n        //\n        \n        Int64 chunk_start = position;\n        for (size_t i = 0; i < total_chunks ; i++)\n        {\n            //\n            // do we have a part number?\n            //\n            \n            int partNumber = 0;\n            if(isMultiPart(version))\n            {\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, partNumber);\n            }\n            \n            \n            \n            if(partNumber<0 || partNumber> static_cast<int>(parts.size()))\n            {\n                throw IEX_NAMESPACE::IoExc(\"part number out of range\");\n            }\n            \n            Header& header = parts[partNumber]->header;\n\n            // size of chunk NOT including multipart field\n            \n            Int64 size_of_chunk=0;\n\n            if (isTiled(header.type()))\n            {\n                //\n                // \n                //\n                int tilex,tiley,levelx,levely;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tilex);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tiley);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levelx);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levely);\n                \n                //std::cout << \"chunk_start for \" << tilex <<',' << tiley << ',' << levelx << ' ' << levely << ':' << chunk_start << std::endl;\n                    \n                \n                if(!tileOffsets[partNumber])\n                {\n                    // this shouldn't actually happen - we should have allocated a valid\n                    // tileOffsets for any part which isTiled\n                    throw IEX_NAMESPACE::IoExc(\"part not tiled\");\n                    \n                }\n                \n                if(!tileOffsets[partNumber]->isValidTile(tilex,tiley,levelx,levely))\n                {\n                    throw IEX_NAMESPACE::IoExc(\"invalid tile coordinates\");\n                }\n                \n                (*tileOffsets[partNumber])(tilex,tiley,levelx,levely)=chunk_start;\n                \n                // compute chunk sizes - different procedure for deep tiles and regular\n                // ones\n                if(header.type()==DEEPTILE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    //add 40 byte header to packed sizes (tile coordinates, packed sizes, unpacked size)\n                    size_of_chunk=packed_offset+packed_sample+40;\n                }\n                else\n                {\n                    \n                    // regular image has 20 bytes of header, 4 byte chunksize;\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);\n                    size_of_chunk=chunksize+20;\n                }\n            }\n            else\n            {\n                int y_coordinate;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, y_coordinate);\n                \n                \n                if(y_coordinate < header.dataWindow().min.y || y_coordinate > header.dataWindow().max.y)\n                {\n                   throw IEX_NAMESPACE::IoExc(\"y out of range\");\n                }\n                y_coordinate -= header.dataWindow().min.y;\n                y_coordinate /= rowsizes[partNumber];   \n                \n                if(y_coordinate < 0 || y_coordinate >= int(parts[partNumber]->chunkOffsets.size()))\n                {\n                   throw IEX_NAMESPACE::IoExc(\"chunk index out of range\");\n                }\n                \n                parts[partNumber]->chunkOffsets[y_coordinate]=chunk_start;\n                \n                if(header.type()==DEEPSCANLINE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    \n                    size_of_chunk=packed_offset+packed_sample+28;\n                }\n                else\n                {\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);   \n                    size_of_chunk=chunksize+8;\n                }\n                \n            }\n            \n            if(isMultiPart(version))\n            {\n                chunk_start+=4;\n            }\n            \n            chunk_start+=size_of_chunk;\n            \n            is.seekg(chunk_start);\n            \n        }\n        \n    }\n    catch (...)\n    {\n        //\n        // Suppress all exceptions.  This functions is\n        // called only to reconstruct the line offset\n        // table for incomplete files, and exceptions\n        // are likely.\n        //\n    }\n\n    // copy tiled part data back to chunk offsets\n    \n    for(size_t partNumber=0;partNumber<parts.size();partNumber++)\n    {\n        if(tileOffsets[partNumber])\n        {\n            size_t pos=0;\n            vector<vector<vector <Int64> > > offsets = tileOffsets[partNumber]->getOffsets();\n            for (size_t l = 0; l < offsets.size(); l++)\n                for (size_t y = 0; y < offsets[l].size(); y++)\n                    for (size_t x = 0; x < offsets[l][y].size(); x++)\n                    {\n                        parts[ partNumber ]->chunkOffsets[pos] = offsets[l][y][x];\n                        pos++;\n                    }\n           delete tileOffsets[partNumber];\n        }\n    }\n\n    is.clear();\n    is.seekg (position);\n}", "func_src_after": "MultiPartInputFile::Data::chunkOffsetReconstruction(OPENEXR_IMF_INTERNAL_NAMESPACE::IStream& is, const vector<InputPartData*>& parts)\n{\n    //\n    // Reconstruct broken chunk offset tables. Stop once we received any exception.\n    //\n\n    Int64 position = is.tellg();\n\n    \n    //\n    // check we understand all the parts available: if not, we cannot continue\n    // exceptions thrown here should trickle back up to the constructor\n    //\n    \n    for (size_t i = 0; i < parts.size(); i++)\n    {\n        Header& header=parts[i]->header;\n        \n        //\n        // do we have a valid type entry?\n        // we only need them for true multipart files or single part non-image (deep) files\n        //\n        if(!header.hasType() && (isMultiPart(version) || isNonImage(version)))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with missing type\");\n        }\n        if(!isSupportedType(header.type()))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with unknown type \"+header.type());\n        }\n    }\n    \n    \n    // how many chunks should we read? We should stop when we reach the end\n    size_t total_chunks = 0;\n        \n    // for tiled-based parts, array of (pointers to) tileOffsets objects\n    // to create mapping between tile coordinates and chunk table indices\n    \n    \n    vector<TileOffsets*> tileOffsets(parts.size());\n    \n    // for scanline-based parts, number of scanlines in each chunk\n    vector<int> rowsizes(parts.size());\n        \n    for(size_t i = 0 ; i < parts.size() ; i++)\n    {\n        total_chunks += parts[i]->chunkOffsets.size();\n        if (isTiled(parts[i]->header.type()))\n        {\n            tileOffsets[i] = createTileOffsets(parts[i]->header);\n        }else{\n            tileOffsets[i] = NULL;\n            // (TODO) fix this so that it doesn't need to be revised for future compression types.\n            switch(parts[i]->header.compression())\n            {\n                case DWAB_COMPRESSION :\n                    rowsizes[i] = 256;\n                    break;\n                case PIZ_COMPRESSION :\n                case B44_COMPRESSION :\n                case B44A_COMPRESSION :\n                case DWAA_COMPRESSION :\n                    rowsizes[i]=32;\n                    break;\n                case ZIP_COMPRESSION :\n                case PXR24_COMPRESSION :\n                    rowsizes[i]=16;\n                    break;\n                case ZIPS_COMPRESSION :\n                case RLE_COMPRESSION :\n                case NO_COMPRESSION :\n                    rowsizes[i]=1;\n                    break;\n                default :\n                    throw(IEX_NAMESPACE::ArgExc(\"Unknown compression method in chunk offset reconstruction\"));\n            }\n        }\n     }\n        \n     try\n     {\n            \n        //\n        // \n        //\n        \n        Int64 chunk_start = position;\n        for (size_t i = 0; i < total_chunks ; i++)\n        {\n            //\n            // do we have a part number?\n            //\n            \n            int partNumber = 0;\n            if(isMultiPart(version))\n            {\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, partNumber);\n            }\n            \n            \n            \n            if(partNumber<0 || partNumber>= static_cast<int>(parts.size()))\n            {\n                throw IEX_NAMESPACE::IoExc(\"part number out of range\");\n            }\n            \n            Header& header = parts[partNumber]->header;\n\n            // size of chunk NOT including multipart field\n            \n            Int64 size_of_chunk=0;\n\n            if (isTiled(header.type()))\n            {\n                //\n                // \n                //\n                int tilex,tiley,levelx,levely;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tilex);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tiley);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levelx);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levely);\n                \n                //std::cout << \"chunk_start for \" << tilex <<',' << tiley << ',' << levelx << ' ' << levely << ':' << chunk_start << std::endl;\n                    \n                \n                if(!tileOffsets[partNumber])\n                {\n                    // this shouldn't actually happen - we should have allocated a valid\n                    // tileOffsets for any part which isTiled\n                    throw IEX_NAMESPACE::IoExc(\"part not tiled\");\n                    \n                }\n                \n                if(!tileOffsets[partNumber]->isValidTile(tilex,tiley,levelx,levely))\n                {\n                    throw IEX_NAMESPACE::IoExc(\"invalid tile coordinates\");\n                }\n                \n                (*tileOffsets[partNumber])(tilex,tiley,levelx,levely)=chunk_start;\n                \n                // compute chunk sizes - different procedure for deep tiles and regular\n                // ones\n                if(header.type()==DEEPTILE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    //add 40 byte header to packed sizes (tile coordinates, packed sizes, unpacked size)\n                    size_of_chunk=packed_offset+packed_sample+40;\n                }\n                else\n                {\n                    \n                    // regular image has 20 bytes of header, 4 byte chunksize;\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);\n                    size_of_chunk=chunksize+20;\n                }\n            }\n            else\n            {\n                int y_coordinate;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, y_coordinate);\n                \n                \n                if(y_coordinate < header.dataWindow().min.y || y_coordinate > header.dataWindow().max.y)\n                {\n                   throw IEX_NAMESPACE::IoExc(\"y out of range\");\n                }\n                y_coordinate -= header.dataWindow().min.y;\n                y_coordinate /= rowsizes[partNumber];   \n                \n                if(y_coordinate < 0 || y_coordinate >= int(parts[partNumber]->chunkOffsets.size()))\n                {\n                   throw IEX_NAMESPACE::IoExc(\"chunk index out of range\");\n                }\n                \n                parts[partNumber]->chunkOffsets[y_coordinate]=chunk_start;\n                \n                if(header.type()==DEEPSCANLINE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    \n                    size_of_chunk=packed_offset+packed_sample+28;\n                }\n                else\n                {\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);   \n                    size_of_chunk=chunksize+8;\n                }\n                \n            }\n            \n            if(isMultiPart(version))\n            {\n                chunk_start+=4;\n            }\n            \n            chunk_start+=size_of_chunk;\n            \n            is.seekg(chunk_start);\n            \n        }\n        \n    }\n    catch (...)\n    {\n        //\n        // Suppress all exceptions.  This functions is\n        // called only to reconstruct the line offset\n        // table for incomplete files, and exceptions\n        // are likely.\n        //\n    }\n\n    // copy tiled part data back to chunk offsets\n    \n    for(size_t partNumber=0;partNumber<parts.size();partNumber++)\n    {\n        if(tileOffsets[partNumber])\n        {\n            size_t pos=0;\n            vector<vector<vector <Int64> > > offsets = tileOffsets[partNumber]->getOffsets();\n            for (size_t l = 0; l < offsets.size(); l++)\n                for (size_t y = 0; y < offsets[l].size(); y++)\n                    for (size_t x = 0; x < offsets[l][y].size(); x++)\n                    {\n                        parts[ partNumber ]->chunkOffsets[pos] = offsets[l][y][x];\n                        pos++;\n                    }\n           delete tileOffsets[partNumber];\n        }\n    }\n\n    is.clear();\n    is.seekg (position);\n}", "commit_link": "github.com/AcademySoftwareFoundation/openexr/commit/8b5370c688a7362673c3a5256d93695617a4cd9a", "file_name": "OpenEXR/IlmImf/ImfMultiPartInputFile.cpp", "vul_type": "cwe-787", "description": "Write a C++ function to reconstruct chunk offset tables from an OpenEXR file stream, handling exceptions silently."}
{"func_name": "insertNPC", "func_src_before": "def insertNPC(name, race,classe,sex,level,image,legit):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO npc VALUES ('\"+date+\"','\"+str(name)+\"','\"+race+\"','\"+classe+\"','\"+sex+\"','\"+str(level)+\"','\"+image+\"','\"+str(legit)+\"')\")\n\tconn.commit()\n\tconn.close()", "func_src_after": "def insertNPC(name, race,classe,sex,level,image,legit):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO npc VALUES (?,?,?,?,?,?,?,?)\",(date,str(name),race,classe,sex,str(level),image,str(legit)))\n\tconn.commit()\n\tconn.close()", "commit_link": "github.com/DangerBlack/DungeonsAndDragonsMasterBot/commit/63f980c6dff746f5fcf3005d0646b6c24f81cdc0", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new NPC with attributes into a database using SQL."}
{"func_name": "unicode_unfold_key", "func_src_before": "unicode_unfold_key(OnigCodePoint code)\n{\n  static const struct ByUnfoldKey wordlist[] =\n    {\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0x1040a, 3267, 1},\n\n      {0x1e0a, 1727, 1},\n\n      {0x040a, 1016, 1},\n\n      {0x010a, 186, 1},\n\n      {0x1f0a, 2088, 1},\n\n      {0x2c0a, 2451, 1},\n\n      {0x0189, 619, 1},\n\n      {0x1f89, 134, 2},\n\n      {0x1f85, 154, 2},\n\n      {0x0389, 733, 1},\n\n      {0x03ff, 724, 1},\n\n      {0xab89, 1523, 1},\n\n      {0xab85, 1511, 1},\n\n      {0x10c89, 3384, 1},\n\n      {0x10c85, 3372, 1},\n\n      {0x1e84, 1911, 1},\n\n      {0x03f5, 752, 1},\n\n      {0x0184, 360, 1},\n\n      {0x1f84, 149, 2},\n\n      {0x2c84, 2592, 1},\n\n      {0x017d, 351, 1},\n\n      {0x1ff3, 96, 2},\n\n      {0xab84, 1508, 1},\n\n      {0xa784, 3105, 1},\n\n      {0x10c84, 3369, 1},\n\n      {0xab7d, 1487, 1},\n\n      {0xa77d, 1706, 1},\n\n      {0x1e98, 38, 2},\n\n      {0x0498, 1106, 1},\n\n      {0x0198, 375, 1},\n\n      {0x1f98, 169, 2},\n\n      {0x2c98, 2622, 1},\n\n      {0x0398, 762, 1},\n\n      {0xa684, 2940, 1},\n\n      {0xab98, 1568, 1},\n\n      {0xa798, 3123, 1},\n\n      {0x10c98, 3429, 1},\n\n      {0x050a, 1277, 1},\n\n      {0x1ffb, 2265, 1},\n\n      {0x1e96, 16, 2},\n\n      {0x0496, 1103, 1},\n\n      {0x0196, 652, 1},\n\n      {0x1f96, 199, 2},\n\n      {0x2c96, 2619, 1},\n\n      {0x0396, 756, 1},\n\n      {0xa698, 2970, 1},\n\n      {0xab96, 1562, 1},\n\n      {0xa796, 3120, 1},\n\n      {0x10c96, 3423, 1},\n\n      {0x1feb, 2259, 1},\n\n      {0x2ceb, 2736, 1},\n\n      {0x1e90, 1929, 1},\n\n      {0x0490, 1094, 1},\n\n      {0x0190, 628, 1},\n\n      {0x1f90, 169, 2},\n\n      {0x2c90, 2610, 1},\n\n      {0x0390, 25, 3},\n\n      {0xa696, 2967, 1},\n\n      {0xab90, 1544, 1},\n\n      {0xa790, 3114, 1},\n\n      {0x10c90, 3405, 1},\n\n      {0x01d7, 444, 1},\n\n      {0x1fd7, 31, 3},\n\n      {0x1ea6, 1947, 1},\n\n      {0x04a6, 1127, 1},\n\n      {0x01a6, 676, 1},\n\n      {0x1fa6, 239, 2},\n\n      {0x2ca6, 2643, 1},\n\n      {0x03a6, 810, 1},\n\n      {0xa690, 2958, 1},\n\n      {0xaba6, 1610, 1},\n\n      {0xa7a6, 3144, 1},\n\n      {0x10ca6, 3471, 1},\n\n      {0x1ea4, 1944, 1},\n\n      {0x04a4, 1124, 1},\n\n      {0x01a4, 390, 1},\n\n      {0x1fa4, 229, 2},\n\n      {0x2ca4, 2640, 1},\n\n      {0x03a4, 804, 1},\n\n      {0x10a6, 2763, 1},\n\n      {0xaba4, 1604, 1},\n\n      {0xa7a4, 3141, 1},\n\n      {0x10ca4, 3465, 1},\n\n      {0x1ea0, 1938, 1},\n\n      {0x04a0, 1118, 1},\n\n      {0x01a0, 384, 1},\n\n      {0x1fa0, 209, 2},\n\n      {0x2ca0, 2634, 1},\n\n      {0x03a0, 792, 1},\n\n      {0x10a4, 2757, 1},\n\n      {0xaba0, 1592, 1},\n\n      {0xa7a0, 3135, 1},\n\n      {0x10ca0, 3453, 1},\n\n      {0x1eb2, 1965, 1},\n\n      {0x04b2, 1145, 1},\n\n      {0x01b2, 694, 1},\n\n      {0x1fb2, 249, 2},\n\n      {0x2cb2, 2661, 1},\n\n      {0x03fd, 718, 1},\n\n      {0x10a0, 2745, 1},\n\n      {0xabb2, 1646, 1},\n\n      {0xa7b2, 703, 1},\n\n      {0x10cb2, 3507, 1},\n\n      {0x1eac, 1956, 1},\n\n      {0x04ac, 1136, 1},\n\n      {0x01ac, 396, 1},\n\n      {0x1fac, 229, 2},\n\n      {0x2cac, 2652, 1},\n\n      {0x0537, 1352, 1},\n\n      {0x10b2, 2799, 1},\n\n      {0xabac, 1628, 1},\n\n      {0xa7ac, 637, 1},\n\n      {0x10cac, 3489, 1},\n\n      {0x1eaa, 1953, 1},\n\n      {0x04aa, 1133, 1},\n\n      {0x00dd, 162, 1},\n\n      {0x1faa, 219, 2},\n\n      {0x2caa, 2649, 1},\n\n      {0x03aa, 824, 1},\n\n      {0x10ac, 2781, 1},\n\n      {0xabaa, 1622, 1},\n\n      {0xa7aa, 646, 1},\n\n      {0x10caa, 3483, 1},\n\n      {0x1ea8, 1950, 1},\n\n      {0x04a8, 1130, 1},\n\n      {0x020a, 517, 1},\n\n      {0x1fa8, 209, 2},\n\n      {0x2ca8, 2646, 1},\n\n      {0x03a8, 817, 1},\n\n      {0x10aa, 2775, 1},\n\n      {0xaba8, 1616, 1},\n\n      {0xa7a8, 3147, 1},\n\n      {0x10ca8, 3477, 1},\n\n      {0x1ea2, 1941, 1},\n\n      {0x04a2, 1121, 1},\n\n      {0x01a2, 387, 1},\n\n      {0x1fa2, 219, 2},\n\n      {0x2ca2, 2637, 1},\n\n      {0x118a6, 3528, 1},\n\n      {0x10a8, 2769, 1},\n\n      {0xaba2, 1598, 1},\n\n      {0xa7a2, 3138, 1},\n\n      {0x10ca2, 3459, 1},\n\n      {0x2ced, 2739, 1},\n\n      {0x1fe9, 2283, 1},\n\n      {0x1fe7, 47, 3},\n\n      {0x1eb0, 1962, 1},\n\n      {0x04b0, 1142, 1},\n\n      {0x118a4, 3522, 1},\n\n      {0x10a2, 2751, 1},\n\n      {0x2cb0, 2658, 1},\n\n      {0x03b0, 41, 3},\n\n      {0x1fe3, 41, 3},\n\n      {0xabb0, 1640, 1},\n\n      {0xa7b0, 706, 1},\n\n      {0x10cb0, 3501, 1},\n\n      {0x01d9, 447, 1},\n\n      {0x1fd9, 2277, 1},\n\n      {0x118a0, 3510, 1},\n\n      {0x00df, 24, 2},\n\n      {0x00d9, 150, 1},\n\n      {0xab77, 1469, 1},\n\n      {0x10b0, 2793, 1},\n\n      {0x1eae, 1959, 1},\n\n      {0x04ae, 1139, 1},\n\n      {0x01ae, 685, 1},\n\n      {0x1fae, 239, 2},\n\n      {0x2cae, 2655, 1},\n\n      {0x118b2, 3564, 1},\n\n      {0xab73, 1457, 1},\n\n      {0xabae, 1634, 1},\n\n      {0xab71, 1451, 1},\n\n      {0x10cae, 3495, 1},\n\n      {0x1e2a, 1775, 1},\n\n      {0x042a, 968, 1},\n\n      {0x012a, 234, 1},\n\n      {0x1f2a, 2130, 1},\n\n      {0x2c2a, 2547, 1},\n\n      {0x118ac, 3546, 1},\n\n      {0x10ae, 2787, 1},\n\n      {0x0535, 1346, 1},\n\n      {0xa72a, 2988, 1},\n\n      {0x1e9a, 0, 2},\n\n      {0x049a, 1109, 1},\n\n      {0xff37, 3225, 1},\n\n      {0x1f9a, 179, 2},\n\n      {0x2c9a, 2625, 1},\n\n      {0x039a, 772, 1},\n\n      {0x118aa, 3540, 1},\n\n      {0xab9a, 1574, 1},\n\n      {0xa79a, 3126, 1},\n\n      {0x10c9a, 3435, 1},\n\n      {0x1e94, 1935, 1},\n\n      {0x0494, 1100, 1},\n\n      {0x0194, 640, 1},\n\n      {0x1f94, 189, 2},\n\n      {0x2c94, 2616, 1},\n\n      {0x0394, 749, 1},\n\n      {0x118a8, 3534, 1},\n\n      {0xab94, 1556, 1},\n\n      {0xa69a, 2973, 1},\n\n      {0x10c94, 3417, 1},\n\n      {0x10402, 3243, 1},\n\n      {0x1e02, 1715, 1},\n\n      {0x0402, 992, 1},\n\n      {0x0102, 174, 1},\n\n      {0x0533, 1340, 1},\n\n      {0x2c02, 2427, 1},\n\n      {0x118a2, 3516, 1},\n\n      {0x052a, 1325, 1},\n\n      {0xa694, 2964, 1},\n\n      {0x1e92, 1932, 1},\n\n      {0x0492, 1097, 1},\n\n      {0x2165, 2307, 1},\n\n      {0x1f92, 179, 2},\n\n      {0x2c92, 2613, 1},\n\n      {0x0392, 742, 1},\n\n      {0x2161, 2295, 1},\n\n      {0xab92, 1550, 1},\n\n      {0xa792, 3117, 1},\n\n      {0x10c92, 3411, 1},\n\n      {0x118b0, 3558, 1},\n\n      {0x1f5f, 2199, 1},\n\n      {0x1e8e, 1926, 1},\n\n      {0x048e, 1091, 1},\n\n      {0x018e, 453, 1},\n\n      {0x1f8e, 159, 2},\n\n      {0x2c8e, 2607, 1},\n\n      {0x038e, 833, 1},\n\n      {0xa692, 2961, 1},\n\n      {0xab8e, 1538, 1},\n\n      {0x0055, 59, 1},\n\n      {0x10c8e, 3399, 1},\n\n      {0x1f5d, 2196, 1},\n\n      {0x212a, 27, 1},\n\n      {0x04cb, 1181, 1},\n\n      {0x01cb, 425, 1},\n\n      {0x1fcb, 2241, 1},\n\n      {0x118ae, 3552, 1},\n\n      {0x0502, 1265, 1},\n\n      {0x00cb, 111, 1},\n\n      {0xa68e, 2955, 1},\n\n      {0x1e8a, 1920, 1},\n\n      {0x048a, 1085, 1},\n\n      {0x018a, 622, 1},\n\n      {0x1f8a, 139, 2},\n\n      {0x2c8a, 2601, 1},\n\n      {0x038a, 736, 1},\n\n      {0x2c67, 2571, 1},\n\n      {0xab8a, 1526, 1},\n\n      {0x1e86, 1914, 1},\n\n      {0x10c8a, 3387, 1},\n\n      {0x0186, 616, 1},\n\n      {0x1f86, 159, 2},\n\n      {0x2c86, 2595, 1},\n\n      {0x0386, 727, 1},\n\n      {0xff35, 3219, 1},\n\n      {0xab86, 1514, 1},\n\n      {0xa786, 3108, 1},\n\n      {0x10c86, 3375, 1},\n\n      {0xa68a, 2949, 1},\n\n      {0x0555, 1442, 1},\n\n      {0x1ebc, 1980, 1},\n\n      {0x04bc, 1160, 1},\n\n      {0x01bc, 411, 1},\n\n      {0x1fbc, 62, 2},\n\n      {0x2cbc, 2676, 1},\n\n      {0x1f5b, 2193, 1},\n\n      {0xa686, 2943, 1},\n\n      {0xabbc, 1676, 1},\n\n      {0x1eb8, 1974, 1},\n\n      {0x04b8, 1154, 1},\n\n      {0x01b8, 408, 1},\n\n      {0x1fb8, 2268, 1},\n\n      {0x2cb8, 2670, 1},\n\n      {0x01db, 450, 1},\n\n      {0x1fdb, 2247, 1},\n\n      {0xabb8, 1664, 1},\n\n      {0x10bc, 2829, 1},\n\n      {0x00db, 156, 1},\n\n      {0x1eb6, 1971, 1},\n\n      {0x04b6, 1151, 1},\n\n      {0xff33, 3213, 1},\n\n      {0x1fb6, 58, 2},\n\n      {0x2cb6, 2667, 1},\n\n      {0xff2a, 3186, 1},\n\n      {0x10b8, 2817, 1},\n\n      {0xabb6, 1658, 1},\n\n      {0xa7b6, 3153, 1},\n\n      {0x10426, 3351, 1},\n\n      {0x1e26, 1769, 1},\n\n      {0x0426, 956, 1},\n\n      {0x0126, 228, 1},\n\n      {0x0053, 52, 1},\n\n      {0x2c26, 2535, 1},\n\n      {0x0057, 65, 1},\n\n      {0x10b6, 2811, 1},\n\n      {0x022a, 562, 1},\n\n      {0xa726, 2982, 1},\n\n      {0x1e2e, 1781, 1},\n\n      {0x042e, 980, 1},\n\n      {0x012e, 240, 1},\n\n      {0x1f2e, 2142, 1},\n\n      {0x2c2e, 2559, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2167, 2313, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa72e, 2994, 1},\n\n      {0x1e2c, 1778, 1},\n\n      {0x042c, 974, 1},\n\n      {0x012c, 237, 1},\n\n      {0x1f2c, 2136, 1},\n\n      {0x2c2c, 2553, 1},\n\n      {0x1f6f, 2223, 1},\n\n      {0x2c6f, 604, 1},\n\n      {0xabbf, 1685, 1},\n\n      {0xa72c, 2991, 1},\n\n      {0x1e28, 1772, 1},\n\n      {0x0428, 962, 1},\n\n      {0x0128, 231, 1},\n\n      {0x1f28, 2124, 1},\n\n      {0x2c28, 2541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0553, 1436, 1},\n\n      {0x10bf, 2838, 1},\n\n      {0xa728, 2985, 1},\n\n      {0x0526, 1319, 1},\n\n      {0x0202, 505, 1},\n\n      {0x1e40, 1808, 1},\n\n      {0x10424, 3345, 1},\n\n      {0x1e24, 1766, 1},\n\n      {0x0424, 950, 1},\n\n      {0x0124, 225, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c24, 2529, 1},\n\n      {0x052e, 1331, 1},\n\n      {0xa740, 3018, 1},\n\n      {0x118bc, 3594, 1},\n\n      {0xa724, 2979, 1},\n\n      {0x1ef2, 2061, 1},\n\n      {0x04f2, 1241, 1},\n\n      {0x01f2, 483, 1},\n\n      {0x1ff2, 257, 2},\n\n      {0x2cf2, 2742, 1},\n\n      {0x052c, 1328, 1},\n\n      {0x118b8, 3582, 1},\n\n      {0xa640, 2865, 1},\n\n      {0x10422, 3339, 1},\n\n      {0x1e22, 1763, 1},\n\n      {0x0422, 944, 1},\n\n      {0x0122, 222, 1},\n\n      {0x2126, 820, 1},\n\n      {0x2c22, 2523, 1},\n\n      {0x0528, 1322, 1},\n\n      {0x01f1, 483, 1},\n\n      {0x118b6, 3576, 1},\n\n      {0xa722, 2976, 1},\n\n      {0x03f1, 796, 1},\n\n      {0x1ebe, 1983, 1},\n\n      {0x04be, 1163, 1},\n\n      {0xfb02, 12, 2},\n\n      {0x1fbe, 767, 1},\n\n      {0x2cbe, 2679, 1},\n\n      {0x01b5, 405, 1},\n\n      {0x0540, 1379, 1},\n\n      {0xabbe, 1682, 1},\n\n      {0x0524, 1316, 1},\n\n      {0x00b5, 779, 1},\n\n      {0xabb5, 1655, 1},\n\n      {0x1eba, 1977, 1},\n\n      {0x04ba, 1157, 1},\n\n      {0x216f, 2337, 1},\n\n      {0x1fba, 2226, 1},\n\n      {0x2cba, 2673, 1},\n\n      {0x10be, 2835, 1},\n\n      {0x0051, 46, 1},\n\n      {0xabba, 1670, 1},\n\n      {0x10b5, 2808, 1},\n\n      {0x1e6e, 1878, 1},\n\n      {0x046e, 1055, 1},\n\n      {0x016e, 330, 1},\n\n      {0x1f6e, 2220, 1},\n\n      {0x2c6e, 664, 1},\n\n      {0x118bf, 3603, 1},\n\n      {0x0522, 1313, 1},\n\n      {0x10ba, 2823, 1},\n\n      {0xa76e, 3087, 1},\n\n      {0x1eb4, 1968, 1},\n\n      {0x04b4, 1148, 1},\n\n      {0x2c75, 2583, 1},\n\n      {0x1fb4, 50, 2},\n\n      {0x2cb4, 2664, 1},\n\n      {0xab75, 1463, 1},\n\n      {0x1ec2, 1989, 1},\n\n      {0xabb4, 1652, 1},\n\n      {0xa7b4, 3150, 1},\n\n      {0x1fc2, 253, 2},\n\n      {0x2cc2, 2685, 1},\n\n      {0x03c2, 800, 1},\n\n      {0x00c2, 83, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff26, 3174, 1},\n\n      {0x10b4, 2805, 1},\n\n      {0x1eca, 2001, 1},\n\n      {0x0551, 1430, 1},\n\n      {0x01ca, 425, 1},\n\n      {0x1fca, 2238, 1},\n\n      {0x2cca, 2697, 1},\n\n      {0x10c2, 2847, 1},\n\n      {0x00ca, 108, 1},\n\n      {0xff2e, 3198, 1},\n\n      {0x1e8c, 1923, 1},\n\n      {0x048c, 1088, 1},\n\n      {0x0226, 556, 1},\n\n      {0x1f8c, 149, 2},\n\n      {0x2c8c, 2604, 1},\n\n      {0x038c, 830, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8c, 1532, 1},\n\n      {0xff2c, 3192, 1},\n\n      {0x10c8c, 3393, 1},\n\n      {0x1ec4, 1992, 1},\n\n      {0x022e, 568, 1},\n\n      {0x01c4, 417, 1},\n\n      {0x1fc4, 54, 2},\n\n      {0x2cc4, 2688, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c4, 89, 1},\n\n      {0xff28, 3180, 1},\n\n      {0xa68c, 2952, 1},\n\n      {0x01cf, 432, 1},\n\n      {0x022c, 565, 1},\n\n      {0x118be, 3600, 1},\n\n      {0x03cf, 839, 1},\n\n      {0x00cf, 123, 1},\n\n      {0x118b5, 3573, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c4, 2853, 1},\n\n      {0x216e, 2334, 1},\n\n      {0x24cb, 2406, 1},\n\n      {0x0228, 559, 1},\n\n      {0xff24, 3168, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ba, 3588, 1},\n\n      {0x1efe, 2079, 1},\n\n      {0x04fe, 1259, 1},\n\n      {0x01fe, 499, 1},\n\n      {0x1e9e, 24, 2},\n\n      {0x049e, 1115, 1},\n\n      {0x03fe, 721, 1},\n\n      {0x1f9e, 199, 2},\n\n      {0x2c9e, 2631, 1},\n\n      {0x039e, 786, 1},\n\n      {0x0224, 553, 1},\n\n      {0xab9e, 1586, 1},\n\n      {0xa79e, 3132, 1},\n\n      {0x10c9e, 3447, 1},\n\n      {0x01f7, 414, 1},\n\n      {0x1ff7, 67, 3},\n\n      {0xff22, 3162, 1},\n\n      {0x03f7, 884, 1},\n\n      {0x118b4, 3570, 1},\n\n      {0x049c, 1112, 1},\n\n      {0x019c, 661, 1},\n\n      {0x1f9c, 189, 2},\n\n      {0x2c9c, 2628, 1},\n\n      {0x039c, 779, 1},\n\n      {0x24bc, 2361, 1},\n\n      {0xab9c, 1580, 1},\n\n      {0xa79c, 3129, 1},\n\n      {0x10c9c, 3441, 1},\n\n      {0x0222, 550, 1},\n\n      {0x1e7c, 1899, 1},\n\n      {0x047c, 1076, 1},\n\n      {0x1e82, 1908, 1},\n\n      {0x24b8, 2349, 1},\n\n      {0x0182, 357, 1},\n\n      {0x1f82, 139, 2},\n\n      {0x2c82, 2589, 1},\n\n      {0xab7c, 1484, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab82, 1502, 1},\n\n      {0xa782, 3102, 1},\n\n      {0x10c82, 3363, 1},\n\n      {0x2c63, 1709, 1},\n\n      {0x24b6, 2343, 1},\n\n      {0x1e80, 1905, 1},\n\n      {0x0480, 1082, 1},\n\n      {0x1f59, 2190, 1},\n\n      {0x1f80, 129, 2},\n\n      {0x2c80, 2586, 1},\n\n      {0x0059, 71, 1},\n\n      {0xa682, 2937, 1},\n\n      {0xab80, 1496, 1},\n\n      {0xa780, 3099, 1},\n\n      {0x10c80, 3357, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1e4c, 1826, 1},\n\n      {0x0145, 270, 1},\n\n      {0x014c, 279, 1},\n\n      {0x1f4c, 2184, 1},\n\n      {0x0345, 767, 1},\n\n      {0x0045, 12, 1},\n\n      {0x004c, 31, 1},\n\n      {0xa680, 2934, 1},\n\n      {0xa74c, 3036, 1},\n\n      {0x1e4a, 1823, 1},\n\n      {0x01d5, 441, 1},\n\n      {0x014a, 276, 1},\n\n      {0x1f4a, 2178, 1},\n\n      {0x03d5, 810, 1},\n\n      {0x00d5, 141, 1},\n\n      {0x004a, 24, 1},\n\n      {0x24bf, 2370, 1},\n\n      {0xa74a, 3033, 1},\n\n      {0xa64c, 2883, 1},\n\n      {0x1041c, 3321, 1},\n\n      {0x1e1c, 1754, 1},\n\n      {0x041c, 926, 1},\n\n      {0x011c, 213, 1},\n\n      {0x1f1c, 2118, 1},\n\n      {0x2c1c, 2505, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xa64a, 2880, 1},\n\n      {0x1041a, 3315, 1},\n\n      {0x1e1a, 1751, 1},\n\n      {0x041a, 920, 1},\n\n      {0x011a, 210, 1},\n\n      {0x1f1a, 2112, 1},\n\n      {0x2c1a, 2499, 1},\n\n      {0xabbd, 1679, 1},\n\n      {0x0545, 1394, 1},\n\n      {0x054c, 1415, 1},\n\n      {0x10418, 3309, 1},\n\n      {0x1e18, 1748, 1},\n\n      {0x0418, 914, 1},\n\n      {0x0118, 207, 1},\n\n      {0x1f18, 2106, 1},\n\n      {0x2c18, 2493, 1},\n\n      {0x10bd, 2832, 1},\n\n      {0x2163, 2301, 1},\n\n      {0x054a, 1409, 1},\n\n      {0x1040e, 3279, 1},\n\n      {0x1e0e, 1733, 1},\n\n      {0x040e, 1028, 1},\n\n      {0x010e, 192, 1},\n\n      {0x1f0e, 2100, 1},\n\n      {0x2c0e, 2463, 1},\n\n      {0x1efc, 2076, 1},\n\n      {0x04fc, 1256, 1},\n\n      {0x01fc, 496, 1},\n\n      {0x1ffc, 96, 2},\n\n      {0x051c, 1304, 1},\n\n      {0x1040c, 3273, 1},\n\n      {0x1e0c, 1730, 1},\n\n      {0x040c, 1022, 1},\n\n      {0x010c, 189, 1},\n\n      {0x1f0c, 2094, 1},\n\n      {0x2c0c, 2457, 1},\n\n      {0x1f6d, 2217, 1},\n\n      {0x2c6d, 607, 1},\n\n      {0x051a, 1301, 1},\n\n      {0x24be, 2367, 1},\n\n      {0x10408, 3261, 1},\n\n      {0x1e08, 1724, 1},\n\n      {0x0408, 1010, 1},\n\n      {0x0108, 183, 1},\n\n      {0x1f08, 2082, 1},\n\n      {0x2c08, 2445, 1},\n\n      {0x04c9, 1178, 1},\n\n      {0x0518, 1298, 1},\n\n      {0x1fc9, 2235, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ba, 2355, 1},\n\n      {0x00c9, 105, 1},\n\n      {0x10416, 3303, 1},\n\n      {0x1e16, 1745, 1},\n\n      {0x0416, 908, 1},\n\n      {0x0116, 204, 1},\n\n      {0x050e, 1283, 1},\n\n      {0x2c16, 2487, 1},\n\n      {0x10414, 3297, 1},\n\n      {0x1e14, 1742, 1},\n\n      {0x0414, 902, 1},\n\n      {0x0114, 201, 1},\n\n      {0x042b, 971, 1},\n\n      {0x2c14, 2481, 1},\n\n      {0x1f2b, 2133, 1},\n\n      {0x2c2b, 2550, 1},\n      {0xffffffff, -1, 0},\n\n      {0x050c, 1280, 1},\n\n      {0x10406, 3255, 1},\n\n      {0x1e06, 1721, 1},\n\n      {0x0406, 1004, 1},\n\n      {0x0106, 180, 1},\n\n      {0x13fb, 1697, 1},\n\n      {0x2c06, 2439, 1},\n\n      {0x24c2, 2379, 1},\n\n      {0x118bd, 3597, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0508, 1274, 1},\n\n      {0x10404, 3249, 1},\n\n      {0x1e04, 1718, 1},\n\n      {0x0404, 998, 1},\n\n      {0x0104, 177, 1},\n\n      {0x1f95, 194, 2},\n\n      {0x2c04, 2433, 1},\n\n      {0x0395, 752, 1},\n\n      {0x24ca, 2403, 1},\n\n      {0xab95, 1559, 1},\n\n      {0x0531, 1334, 1},\n\n      {0x10c95, 3420, 1},\n\n      {0x0516, 1295, 1},\n\n      {0x1e6c, 1875, 1},\n\n      {0x046c, 1052, 1},\n\n      {0x016c, 327, 1},\n\n      {0x1f6c, 2214, 1},\n\n      {0x216d, 2331, 1},\n\n      {0x0514, 1292, 1},\n\n      {0x0245, 697, 1},\n\n      {0x024c, 598, 1},\n\n      {0xa76c, 3084, 1},\n\n      {0x10400, 3237, 1},\n\n      {0x1e00, 1712, 1},\n\n      {0x0400, 986, 1},\n\n      {0x0100, 171, 1},\n\n      {0x24c4, 2385, 1},\n\n      {0x2c00, 2421, 1},\n\n      {0x0506, 1271, 1},\n\n      {0x024a, 595, 1},\n\n      {0x1fab, 224, 2},\n\n      {0xa66c, 2931, 1},\n\n      {0x03ab, 827, 1},\n\n      {0x24cf, 2418, 1},\n\n      {0xabab, 1625, 1},\n\n      {0xa7ab, 631, 1},\n\n      {0x10cab, 3486, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0504, 1268, 1},\n      {0xffffffff, -1, 0},\n\n      {0x021c, 544, 1},\n\n      {0x01a9, 679, 1},\n\n      {0x1fa9, 214, 2},\n\n      {0x10ab, 2778, 1},\n\n      {0x03a9, 820, 1},\n\n      {0x212b, 92, 1},\n\n      {0xaba9, 1619, 1},\n\n      {0x1e88, 1917, 1},\n\n      {0x10ca9, 3480, 1},\n\n      {0x021a, 541, 1},\n\n      {0x1f88, 129, 2},\n\n      {0x2c88, 2598, 1},\n\n      {0x0388, 730, 1},\n\n      {0x13fd, 1703, 1},\n\n      {0xab88, 1520, 1},\n\n      {0x10a9, 2772, 1},\n\n      {0x10c88, 3381, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0218, 538, 1},\n\n      {0x0500, 1262, 1},\n\n      {0x1f4d, 2187, 1},\n\n      {0x01a7, 393, 1},\n\n      {0x1fa7, 244, 2},\n\n      {0x004d, 34, 1},\n\n      {0x03a7, 814, 1},\n\n      {0xa688, 2946, 1},\n\n      {0xaba7, 1613, 1},\n\n      {0x020e, 523, 1},\n\n      {0x10ca7, 3474, 1},\n\n      {0x1e6a, 1872, 1},\n\n      {0x046a, 1049, 1},\n\n      {0x016a, 324, 1},\n\n      {0x1f6a, 2208, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216c, 2328, 1},\n\n      {0x10a7, 2766, 1},\n\n      {0x01d1, 435, 1},\n\n      {0xa76a, 3081, 1},\n\n      {0x020c, 520, 1},\n\n      {0x03d1, 762, 1},\n\n      {0x00d1, 129, 1},\n\n      {0x1e68, 1869, 1},\n\n      {0x0468, 1046, 1},\n\n      {0x0168, 321, 1},\n\n      {0x1f68, 2202, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff31, 3207, 1},\n\n      {0xa66a, 2928, 1},\n\n      {0x0208, 514, 1},\n\n      {0xa768, 3078, 1},\n\n      {0x1e64, 1863, 1},\n\n      {0x0464, 1040, 1},\n\n      {0x0164, 315, 1},\n\n      {0x054d, 1418, 1},\n\n      {0x2c64, 673, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff2b, 3189, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa764, 3072, 1},\n\n      {0xa668, 2925, 1},\n\n      {0x0216, 535, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ab, 3543, 1},\n\n      {0x1e62, 1860, 1},\n\n      {0x0462, 1037, 1},\n\n      {0x0162, 312, 1},\n\n      {0x0214, 532, 1},\n\n      {0x2c62, 655, 1},\n\n      {0xa664, 2919, 1},\n\n      {0x1ed2, 2013, 1},\n\n      {0x04d2, 1193, 1},\n\n      {0xa762, 3069, 1},\n\n      {0x1fd2, 20, 3},\n\n      {0x2cd2, 2709, 1},\n\n      {0x118a9, 3537, 1},\n\n      {0x00d2, 132, 1},\n\n      {0x0206, 511, 1},\n\n      {0x10420, 3333, 1},\n\n      {0x1e20, 1760, 1},\n\n      {0x0420, 938, 1},\n\n      {0x0120, 219, 1},\n\n      {0xa662, 2916, 1},\n\n      {0x2c20, 2517, 1},\n\n      {0x1e60, 1856, 1},\n\n      {0x0460, 1034, 1},\n\n      {0x0160, 309, 1},\n\n      {0x0204, 508, 1},\n\n      {0x2c60, 2562, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24bd, 2364, 1},\n\n      {0x216a, 2322, 1},\n\n      {0xa760, 3066, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb16, 125, 2},\n\n      {0x118a7, 3531, 1},\n\n      {0x1efa, 2073, 1},\n\n      {0x04fa, 1253, 1},\n\n      {0x01fa, 493, 1},\n\n      {0x1ffa, 2262, 1},\n\n      {0xfb14, 109, 2},\n\n      {0x03fa, 887, 1},\n\n      {0xa660, 2913, 1},\n\n      {0x2168, 2316, 1},\n\n      {0x01b7, 700, 1},\n\n      {0x1fb7, 10, 3},\n\n      {0x1f6b, 2211, 1},\n\n      {0x2c6b, 2577, 1},\n\n      {0x0200, 502, 1},\n\n      {0xabb7, 1661, 1},\n\n      {0xfb06, 29, 2},\n\n      {0x1e56, 1841, 1},\n\n      {0x2164, 2304, 1},\n\n      {0x0156, 294, 1},\n\n      {0x1f56, 62, 3},\n\n      {0x0520, 1310, 1},\n\n      {0x004f, 40, 1},\n\n      {0x0056, 62, 1},\n\n      {0x10b7, 2814, 1},\n\n      {0xa756, 3051, 1},\n\n      {0xfb04, 5, 3},\n\n      {0x1e78, 1893, 1},\n\n      {0x0478, 1070, 1},\n\n      {0x0178, 168, 1},\n\n      {0x1e54, 1838, 1},\n\n      {0x2162, 2298, 1},\n\n      {0x0154, 291, 1},\n\n      {0x1f54, 57, 3},\n\n      {0xab78, 1472, 1},\n\n      {0xa656, 2898, 1},\n\n      {0x0054, 56, 1},\n\n      {0x1e52, 1835, 1},\n\n      {0xa754, 3048, 1},\n\n      {0x0152, 288, 1},\n\n      {0x1f52, 52, 3},\n\n      {0x24c9, 2400, 1},\n\n      {0x1e32, 1787, 1},\n\n      {0x0052, 49, 1},\n\n      {0x0132, 243, 1},\n\n      {0xa752, 3045, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb00, 4, 2},\n\n      {0xa654, 2895, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa732, 2997, 1},\n\n      {0x2160, 2292, 1},\n\n      {0x054f, 1424, 1},\n\n      {0x0556, 1445, 1},\n\n      {0x1e50, 1832, 1},\n\n      {0xa652, 2892, 1},\n\n      {0x0150, 285, 1},\n\n      {0x1f50, 84, 2},\n\n      {0x017b, 348, 1},\n\n      {0x1e4e, 1829, 1},\n\n      {0x0050, 43, 1},\n\n      {0x014e, 282, 1},\n\n      {0xa750, 3042, 1},\n\n      {0xab7b, 1481, 1},\n\n      {0xa77b, 3093, 1},\n\n      {0x004e, 37, 1},\n\n      {0x0554, 1439, 1},\n\n      {0xa74e, 3039, 1},\n\n      {0x1e48, 1820, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216b, 2325, 1},\n\n      {0x1f48, 2172, 1},\n\n      {0xa650, 2889, 1},\n\n      {0x0552, 1433, 1},\n\n      {0x0048, 21, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa748, 3030, 1},\n\n      {0xa64e, 2886, 1},\n\n      {0x0532, 1337, 1},\n\n      {0x1041e, 3327, 1},\n\n      {0x1e1e, 1757, 1},\n\n      {0x041e, 932, 1},\n\n      {0x011e, 216, 1},\n\n      {0x118b7, 3579, 1},\n\n      {0x2c1e, 2511, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa648, 2877, 1},\n\n      {0x1ff9, 2253, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03f9, 878, 1},\n\n      {0x0550, 1427, 1},\n\n      {0x10412, 3291, 1},\n\n      {0x1e12, 1739, 1},\n\n      {0x0412, 896, 1},\n\n      {0x0112, 198, 1},\n\n      {0x054e, 1421, 1},\n\n      {0x2c12, 2475, 1},\n\n      {0x10410, 3285, 1},\n\n      {0x1e10, 1736, 1},\n\n      {0x0410, 890, 1},\n\n      {0x0110, 195, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c10, 2469, 1},\n\n      {0x2132, 2289, 1},\n\n      {0x0548, 1403, 1},\n\n      {0x1ef8, 2070, 1},\n\n      {0x04f8, 1250, 1},\n\n      {0x01f8, 490, 1},\n\n      {0x1ff8, 2250, 1},\n\n      {0x0220, 381, 1},\n\n      {0x1ee2, 2037, 1},\n\n      {0x04e2, 1217, 1},\n\n      {0x01e2, 462, 1},\n\n      {0x1fe2, 36, 3},\n\n      {0x2ce2, 2733, 1},\n\n      {0x03e2, 857, 1},\n\n      {0x051e, 1307, 1},\n\n      {0x1ede, 2031, 1},\n\n      {0x04de, 1211, 1},\n\n      {0x01de, 456, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cde, 2727, 1},\n\n      {0x03de, 851, 1},\n\n      {0x00de, 165, 1},\n\n      {0x1f69, 2205, 1},\n\n      {0x2c69, 2574, 1},\n\n      {0x1eda, 2025, 1},\n\n      {0x04da, 1205, 1},\n\n      {0x0512, 1289, 1},\n\n      {0x1fda, 2244, 1},\n\n      {0x2cda, 2721, 1},\n\n      {0x03da, 845, 1},\n\n      {0x00da, 153, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0510, 1286, 1},\n\n      {0x1ed8, 2022, 1},\n\n      {0x04d8, 1202, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd8, 2274, 1},\n\n      {0x2cd8, 2718, 1},\n\n      {0x03d8, 842, 1},\n\n      {0x00d8, 147, 1},\n\n      {0x1ed6, 2019, 1},\n\n      {0x04d6, 1199, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd6, 76, 2},\n\n      {0x2cd6, 2715, 1},\n\n      {0x03d6, 792, 1},\n\n      {0x00d6, 144, 1},\n\n      {0x1ec8, 1998, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01c8, 421, 1},\n\n      {0x1fc8, 2232, 1},\n\n      {0x2cc8, 2694, 1},\n\n      {0xff32, 3210, 1},\n\n      {0x00c8, 102, 1},\n\n      {0x04c7, 1175, 1},\n\n      {0x01c7, 421, 1},\n\n      {0x1fc7, 15, 3},\n\n      {0x1ec0, 1986, 1},\n\n      {0x04c0, 1187, 1},\n\n      {0x00c7, 99, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cc0, 2682, 1},\n\n      {0x0179, 345, 1},\n\n      {0x00c0, 77, 1},\n\n      {0x0232, 574, 1},\n\n      {0x01b3, 402, 1},\n\n      {0x1fb3, 62, 2},\n\n      {0xab79, 1475, 1},\n\n      {0xa779, 3090, 1},\n\n      {0x10c7, 2859, 1},\n\n      {0xabb3, 1649, 1},\n\n      {0xa7b3, 3156, 1},\n\n      {0x1fa5, 234, 2},\n\n      {0x10c0, 2841, 1},\n\n      {0x03a5, 807, 1},\n      {0xffffffff, -1, 0},\n\n      {0xaba5, 1607, 1},\n\n      {0x01b1, 691, 1},\n\n      {0x10ca5, 3468, 1},\n\n      {0x10b3, 2802, 1},\n\n      {0x2169, 2319, 1},\n\n      {0x024e, 601, 1},\n\n      {0xabb1, 1643, 1},\n\n      {0xa7b1, 682, 1},\n\n      {0x10cb1, 3504, 1},\n\n      {0x10a5, 2760, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01af, 399, 1},\n\n      {0x1faf, 244, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0248, 592, 1},\n\n      {0x10b1, 2796, 1},\n\n      {0xabaf, 1637, 1},\n\n      {0x1fad, 234, 2},\n\n      {0x10caf, 3498, 1},\n\n      {0x04cd, 1184, 1},\n\n      {0x01cd, 429, 1},\n\n      {0xabad, 1631, 1},\n\n      {0xa7ad, 658, 1},\n\n      {0x10cad, 3492, 1},\n\n      {0x00cd, 117, 1},\n\n      {0x10af, 2790, 1},\n\n      {0x021e, 547, 1},\n\n      {0x1fa3, 224, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03a3, 800, 1},\n\n      {0x10ad, 2784, 1},\n\n      {0xaba3, 1601, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10ca3, 3462, 1},\n\n      {0x10cd, 2862, 1},\n\n      {0x1fa1, 214, 2},\n\n      {0x24b7, 2346, 1},\n\n      {0x03a1, 796, 1},\n\n      {0x0212, 529, 1},\n\n      {0xaba1, 1595, 1},\n\n      {0x10a3, 2754, 1},\n\n      {0x10ca1, 3456, 1},\n\n      {0x01d3, 438, 1},\n\n      {0x1fd3, 25, 3},\n\n      {0x0210, 526, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00d3, 135, 1},\n\n      {0x1e97, 34, 2},\n\n      {0x10a1, 2748, 1},\n\n      {0x0197, 649, 1},\n\n      {0x1f97, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0397, 759, 1},\n\n      {0x1041d, 3324, 1},\n\n      {0xab97, 1565, 1},\n\n      {0x041d, 929, 1},\n\n      {0x10c97, 3426, 1},\n\n      {0x1f1d, 2121, 1},\n\n      {0x2c1d, 2508, 1},\n\n      {0x1e72, 1884, 1},\n\n      {0x0472, 1061, 1},\n\n      {0x0172, 336, 1},\n\n      {0x118b3, 3567, 1},\n\n      {0x2c72, 2580, 1},\n\n      {0x0372, 712, 1},\n\n      {0x1041b, 3318, 1},\n\n      {0xab72, 1454, 1},\n\n      {0x041b, 923, 1},\n\n      {0x118a5, 3525, 1},\n\n      {0x1f1b, 2115, 1},\n\n      {0x2c1b, 2502, 1},\n\n      {0x1e70, 1881, 1},\n\n      {0x0470, 1058, 1},\n\n      {0x0170, 333, 1},\n\n      {0x118b1, 3561, 1},\n\n      {0x2c70, 610, 1},\n\n      {0x0370, 709, 1},\n\n      {0x1e46, 1817, 1},\n\n      {0xab70, 1448, 1},\n\n      {0x1e66, 1866, 1},\n\n      {0x0466, 1043, 1},\n\n      {0x0166, 318, 1},\n\n      {0x1e44, 1814, 1},\n\n      {0x0046, 15, 1},\n\n      {0x118af, 3555, 1},\n\n      {0xa746, 3027, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa766, 3075, 1},\n\n      {0x0044, 9, 1},\n\n      {0x118ad, 3549, 1},\n\n      {0xa744, 3024, 1},\n\n      {0x1e7a, 1896, 1},\n\n      {0x047a, 1073, 1},\n\n      {0x1e3a, 1799, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa646, 2874, 1},\n\n      {0x1f3a, 2154, 1},\n\n      {0xa666, 2922, 1},\n\n      {0xab7a, 1478, 1},\n\n      {0x118a3, 3519, 1},\n\n      {0xa644, 2871, 1},\n\n      {0xa73a, 3009, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1ef4, 2064, 1},\n\n      {0x04f4, 1244, 1},\n\n      {0x01f4, 487, 1},\n\n      {0x1ff4, 101, 2},\n\n      {0x118a1, 3513, 1},\n\n      {0x03f4, 762, 1},\n\n      {0x1eec, 2052, 1},\n\n      {0x04ec, 1232, 1},\n\n      {0x01ec, 477, 1},\n\n      {0x1fec, 2286, 1},\n\n      {0x0546, 1397, 1},\n\n      {0x03ec, 872, 1},\n      {0xffffffff, -1, 0},\n\n      {0x013f, 261, 1},\n\n      {0x1f3f, 2169, 1},\n\n      {0x0544, 1391, 1},\n\n      {0x1eea, 2049, 1},\n\n      {0x04ea, 1229, 1},\n\n      {0x01ea, 474, 1},\n\n      {0x1fea, 2256, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03ea, 869, 1},\n\n      {0x1ee8, 2046, 1},\n\n      {0x04e8, 1226, 1},\n\n      {0x01e8, 471, 1},\n\n      {0x1fe8, 2280, 1},\n\n      {0x053a, 1361, 1},\n\n      {0x03e8, 866, 1},\n\n      {0x1ee6, 2043, 1},\n\n      {0x04e6, 1223, 1},\n\n      {0x01e6, 468, 1},\n\n      {0x1fe6, 88, 2},\n\n      {0x1f4b, 2181, 1},\n\n      {0x03e6, 863, 1},\n\n      {0x1e5e, 1853, 1},\n\n      {0x004b, 27, 1},\n\n      {0x015e, 306, 1},\n\n      {0x2166, 2310, 1},\n\n      {0x1ee4, 2040, 1},\n\n      {0x04e4, 1220, 1},\n\n      {0x01e4, 465, 1},\n\n      {0x1fe4, 80, 2},\n\n      {0xa75e, 3063, 1},\n\n      {0x03e4, 860, 1},\n\n      {0x1ee0, 2034, 1},\n\n      {0x04e0, 1214, 1},\n\n      {0x01e0, 459, 1},\n\n      {0x053f, 1376, 1},\n\n      {0x2ce0, 2730, 1},\n\n      {0x03e0, 854, 1},\n\n      {0x1edc, 2028, 1},\n\n      {0x04dc, 1208, 1},\n\n      {0xa65e, 2910, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cdc, 2724, 1},\n\n      {0x03dc, 848, 1},\n\n      {0x00dc, 159, 1},\n\n      {0x1ed0, 2010, 1},\n\n      {0x04d0, 1190, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x2cd0, 2706, 1},\n\n      {0x03d0, 742, 1},\n\n      {0x00d0, 126, 1},\n\n      {0x1ecc, 2004, 1},\n\n      {0x054b, 1412, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fcc, 71, 2},\n\n      {0x2ccc, 2700, 1},\n\n      {0x1ec6, 1995, 1},\n\n      {0x00cc, 114, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fc6, 67, 2},\n\n      {0x2cc6, 2691, 1},\n\n      {0x24c8, 2397, 1},\n\n      {0x00c6, 96, 1},\n\n      {0x04c5, 1172, 1},\n\n      {0x01c5, 417, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fbb, 2229, 1},\n\n      {0x24c7, 2394, 1},\n\n      {0x00c5, 92, 1},\n\n      {0x1fb9, 2271, 1},\n\n      {0xabbb, 1673, 1},\n\n      {0x24c0, 2373, 1},\n\n      {0x04c3, 1169, 1},\n\n      {0xabb9, 1667, 1},\n\n      {0x1fc3, 71, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x00c3, 86, 1},\n\n      {0x10c5, 2856, 1},\n\n      {0x10bb, 2826, 1},\n\n      {0x1ed4, 2016, 1},\n\n      {0x04d4, 1196, 1},\n\n      {0x10b9, 2820, 1},\n\n      {0x13fc, 1700, 1},\n\n      {0x2cd4, 2712, 1},\n\n      {0x0246, 589, 1},\n\n      {0x00d4, 138, 1},\n\n      {0x10c3, 2850, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff3a, 3234, 1},\n\n      {0x0244, 688, 1},\n\n      {0x019f, 670, 1},\n\n      {0x1f9f, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x039f, 789, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab9f, 1589, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c9f, 3450, 1},\n\n      {0x019d, 667, 1},\n\n      {0x1f9d, 194, 2},\n\n      {0x023a, 2565, 1},\n\n      {0x039d, 783, 1},\n\n      {0x1e5a, 1847, 1},\n\n      {0xab9d, 1583, 1},\n\n      {0x015a, 300, 1},\n\n      {0x10c9d, 3444, 1},\n\n      {0x1e9b, 1856, 1},\n\n      {0x24cd, 2412, 1},\n\n      {0x005a, 74, 1},\n\n      {0x1f9b, 184, 2},\n\n      {0xa75a, 3057, 1},\n\n      {0x039b, 776, 1},\n\n      {0x1ece, 2007, 1},\n\n      {0xab9b, 1577, 1},\n\n      {0x1e99, 42, 2},\n\n      {0x10c9b, 3438, 1},\n\n      {0x2cce, 2703, 1},\n\n      {0x1f99, 174, 2},\n\n      {0x00ce, 120, 1},\n\n      {0x0399, 767, 1},\n\n      {0xa65a, 2904, 1},\n\n      {0xab99, 1571, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c99, 3432, 1},\n\n      {0x0193, 634, 1},\n\n      {0x1f93, 184, 2},\n\n      {0x1e58, 1844, 1},\n\n      {0x0393, 746, 1},\n\n      {0x0158, 297, 1},\n\n      {0xab93, 1553, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c93, 3414, 1},\n\n      {0x0058, 68, 1},\n\n      {0x042d, 977, 1},\n\n      {0xa758, 3054, 1},\n\n      {0x1f2d, 2139, 1},\n\n      {0x2c2d, 2556, 1},\n\n      {0x118bb, 3591, 1},\n\n      {0x0191, 369, 1},\n\n      {0x1f91, 174, 2},\n\n      {0x118b9, 3585, 1},\n\n      {0x0391, 739, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab91, 1547, 1},\n\n      {0xa658, 2901, 1},\n\n      {0x10c91, 3408, 1},\n\n      {0x018f, 625, 1},\n\n      {0x1f8f, 164, 2},\n      {0xffffffff, -1, 0},\n\n      {0x038f, 836, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8f, 1541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c8f, 3402, 1},\n\n      {0x018b, 366, 1},\n\n      {0x1f8b, 144, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0187, 363, 1},\n\n      {0x1f87, 164, 2},\n\n      {0xab8b, 1529, 1},\n\n      {0xa78b, 3111, 1},\n\n      {0x10c8b, 3390, 1},\n\n      {0xab87, 1517, 1},\n\n      {0x04c1, 1166, 1},\n\n      {0x10c87, 3378, 1},\n\n      {0x1e7e, 1902, 1},\n\n      {0x047e, 1079, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c1, 80, 1},\n\n      {0x2c7e, 580, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab7e, 1490, 1},\n\n      {0xa77e, 3096, 1},\n\n      {0x1e76, 1890, 1},\n\n      {0x0476, 1067, 1},\n\n      {0x0176, 342, 1},\n\n      {0x1e42, 1811, 1},\n\n      {0x10c1, 2844, 1},\n\n      {0x0376, 715, 1},\n\n      {0x1e36, 1793, 1},\n\n      {0xab76, 1466, 1},\n\n      {0x0136, 249, 1},\n\n      {0x0042, 3, 1},\n\n      {0x1e3e, 1805, 1},\n\n      {0xa742, 3021, 1},\n\n      {0x1e38, 1796, 1},\n\n      {0x1f3e, 2166, 1},\n\n      {0xa736, 3003, 1},\n\n      {0x1f38, 2148, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0587, 105, 2},\n\n      {0xa73e, 3015, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa738, 3006, 1},\n\n      {0xa642, 2868, 1},\n\n      {0x1e5c, 1850, 1},\n\n      {0x1e34, 1790, 1},\n\n      {0x015c, 303, 1},\n\n      {0x0134, 246, 1},\n\n      {0x1ef6, 2067, 1},\n\n      {0x04f6, 1247, 1},\n\n      {0x01f6, 372, 1},\n\n      {0x1ff6, 92, 2},\n\n      {0xa75c, 3060, 1},\n\n      {0xa734, 3000, 1},\n\n      {0x1ef0, 2058, 1},\n\n      {0x04f0, 1238, 1},\n\n      {0x01f0, 20, 2},\n      {0xffffffff, -1, 0},\n\n      {0x1e30, 1784, 1},\n\n      {0x03f0, 772, 1},\n\n      {0x0130, 261, 2},\n\n      {0x0542, 1385, 1},\n\n      {0xa65c, 2907, 1},\n\n      {0x1f83, 144, 2},\n\n      {0x0536, 1349, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab83, 1505, 1},\n\n      {0x053e, 1373, 1},\n\n      {0x10c83, 3366, 1},\n\n      {0x0538, 1355, 1},\n\n      {0x1eee, 2055, 1},\n\n      {0x04ee, 1235, 1},\n\n      {0x01ee, 480, 1},\n\n      {0x1f8d, 154, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03ee, 875, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8d, 1535, 1},\n\n      {0xa78d, 643, 1},\n\n      {0x10c8d, 3396, 1},\n\n      {0x0534, 1343, 1},\n\n      {0x0181, 613, 1},\n\n      {0x1f81, 134, 2},\n\n      {0x013d, 258, 1},\n\n      {0x1f3d, 2163, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab81, 1499, 1},\n\n      {0x017f, 52, 1},\n\n      {0x10c81, 3360, 1},\n\n      {0x2c7f, 583, 1},\n\n      {0x037f, 881, 1},\n\n      {0xff2d, 3195, 1},\n\n      {0xab7f, 1493, 1},\n\n      {0x1e74, 1887, 1},\n\n      {0x0474, 1064, 1},\n\n      {0x0174, 339, 1},\n\n      {0x1e3c, 1802, 1},\n\n      {0x0149, 46, 2},\n\n      {0x1f49, 2175, 1},\n\n      {0x1f3c, 2160, 1},\n\n      {0xab74, 1460, 1},\n\n      {0x0049, 3606, 1},\n\n      {0x0143, 267, 1},\n\n      {0x24cc, 2409, 1},\n\n      {0xa73c, 3012, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0043, 6, 1},\n\n      {0x0141, 264, 1},\n\n      {0x24c6, 2391, 1},\n\n      {0x013b, 255, 1},\n\n      {0x1f3b, 2157, 1},\n\n      {0x0041, 0, 1},\n\n      {0x0139, 252, 1},\n\n      {0x1f39, 2151, 1},\n\n      {0x24c5, 2388, 1},\n\n      {0x24bb, 2358, 1},\n\n      {0x13fa, 1694, 1},\n\n      {0x053d, 1370, 1},\n\n      {0x24b9, 2352, 1},\n\n      {0x0429, 965, 1},\n\n      {0x2183, 2340, 1},\n\n      {0x1f29, 2127, 1},\n\n      {0x2c29, 2544, 1},\n\n      {0x24c3, 2382, 1},\n\n      {0x10427, 3354, 1},\n\n      {0x10425, 3348, 1},\n\n      {0x0427, 959, 1},\n\n      {0x0425, 953, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c27, 2538, 1},\n\n      {0x2c25, 2532, 1},\n\n      {0x0549, 1406, 1},\n\n      {0x053c, 1367, 1},\n\n      {0x10423, 3342, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0423, 947, 1},\n\n      {0x0543, 1388, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c23, 2526, 1},\n\n      {0xff36, 3222, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0541, 1382, 1},\n\n      {0x10421, 3336, 1},\n\n      {0x053b, 1364, 1},\n\n      {0x0421, 941, 1},\n\n      {0xff38, 3228, 1},\n\n      {0x0539, 1358, 1},\n\n      {0x2c21, 2520, 1},\n\n      {0x10419, 3312, 1},\n\n      {0x10417, 3306, 1},\n\n      {0x0419, 917, 1},\n\n      {0x0417, 911, 1},\n\n      {0x1f19, 2109, 1},\n\n      {0x2c19, 2496, 1},\n\n      {0x2c17, 2490, 1},\n\n      {0x023e, 2568, 1},\n\n      {0xff34, 3216, 1},\n\n      {0x10415, 3300, 1},\n\n      {0x10413, 3294, 1},\n\n      {0x0415, 905, 1},\n\n      {0x0413, 899, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c15, 2484, 1},\n\n      {0x2c13, 2478, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ce, 2415, 1},\n\n      {0x1040f, 3282, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040f, 1031, 1},\n\n      {0xff30, 3204, 1},\n\n      {0x1f0f, 2103, 1},\n\n      {0x2c0f, 2466, 1},\n\n      {0x1040d, 3276, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040d, 1025, 1},\n\n      {0x0147, 273, 1},\n\n      {0x1f0d, 2097, 1},\n\n      {0x2c0d, 2460, 1},\n\n      {0x1040b, 3270, 1},\n\n      {0x0047, 18, 1},\n\n      {0x040b, 1019, 1},\n\n      {0x0230, 571, 1},\n\n      {0x1f0b, 2091, 1},\n\n      {0x2c0b, 2454, 1},\n\n      {0x10409, 3264, 1},\n\n      {0x10405, 3252, 1},\n\n      {0x0409, 1013, 1},\n\n      {0x0405, 1001, 1},\n\n      {0x1f09, 2085, 1},\n\n      {0x2c09, 2448, 1},\n\n      {0x2c05, 2436, 1},\n\n      {0x10403, 3246, 1},\n\n      {0x10401, 3240, 1},\n\n      {0x0403, 995, 1},\n\n      {0x0401, 989, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c03, 2430, 1},\n\n      {0x2c01, 2424, 1},\n\n      {0x13f9, 1691, 1},\n\n      {0x042f, 983, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1f2f, 2145, 1},\n\n      {0x1041f, 3330, 1},\n      {0xffffffff, -1, 0},\n\n      {0x041f, 935, 1},\n\n      {0x023d, 378, 1},\n\n      {0x10411, 3288, 1},\n\n      {0x2c1f, 2514, 1},\n\n      {0x0411, 893, 1},\n\n      {0x0547, 1400, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c11, 2472, 1},\n\n      {0x10407, 3258, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0407, 1007, 1},\n\n      {0x24c1, 2376, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c07, 2442, 1},\n      {0xffffffff, -1, 0},\n\n      {0x13f8, 1688, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff39, 3231, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0243, 354, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x0241, 586, 1},\n\n      {0xff29, 3183, 1},\n\n      {0x023b, 577, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff27, 3177, 1},\n\n      {0xff25, 3171, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff23, 3165, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff21, 3159, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb17, 117, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff2f, 3201, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb15, 113, 2},\n\n      {0xfb13, 121, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb05, 29, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb03, 0, 3},\n\n      {0xfb01, 8, 2}\n    };\n\n  if (0 == 0)\n    {\n      int key = hash(&code);\n\n      if (key <= MAX_HASH_VALUE && key >= 0)\n        {\n          OnigCodePoint gcode = wordlist[key].code;\n\n          if (code == gcode)\n            return &wordlist[key];\n        }\n    }\n  return 0;\n}", "func_src_after": "unicode_unfold_key(OnigCodePoint code)\n{\n  static const struct ByUnfoldKey wordlist[] =\n    {\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0x1040a, 3267, 1},\n\n      {0x1e0a, 1727, 1},\n\n      {0x040a, 1016, 1},\n\n      {0x010a, 186, 1},\n\n      {0x1f0a, 2088, 1},\n\n      {0x2c0a, 2451, 1},\n\n      {0x0189, 619, 1},\n\n      {0x1f89, 134, 2},\n\n      {0x1f85, 154, 2},\n\n      {0x0389, 733, 1},\n\n      {0x03ff, 724, 1},\n\n      {0xab89, 1523, 1},\n\n      {0xab85, 1511, 1},\n\n      {0x10c89, 3384, 1},\n\n      {0x10c85, 3372, 1},\n\n      {0x1e84, 1911, 1},\n\n      {0x03f5, 752, 1},\n\n      {0x0184, 360, 1},\n\n      {0x1f84, 149, 2},\n\n      {0x2c84, 2592, 1},\n\n      {0x017d, 351, 1},\n\n      {0x1ff3, 96, 2},\n\n      {0xab84, 1508, 1},\n\n      {0xa784, 3105, 1},\n\n      {0x10c84, 3369, 1},\n\n      {0xab7d, 1487, 1},\n\n      {0xa77d, 1706, 1},\n\n      {0x1e98, 38, 2},\n\n      {0x0498, 1106, 1},\n\n      {0x0198, 375, 1},\n\n      {0x1f98, 169, 2},\n\n      {0x2c98, 2622, 1},\n\n      {0x0398, 762, 1},\n\n      {0xa684, 2940, 1},\n\n      {0xab98, 1568, 1},\n\n      {0xa798, 3123, 1},\n\n      {0x10c98, 3429, 1},\n\n      {0x050a, 1277, 1},\n\n      {0x1ffb, 2265, 1},\n\n      {0x1e96, 16, 2},\n\n      {0x0496, 1103, 1},\n\n      {0x0196, 652, 1},\n\n      {0x1f96, 199, 2},\n\n      {0x2c96, 2619, 1},\n\n      {0x0396, 756, 1},\n\n      {0xa698, 2970, 1},\n\n      {0xab96, 1562, 1},\n\n      {0xa796, 3120, 1},\n\n      {0x10c96, 3423, 1},\n\n      {0x1feb, 2259, 1},\n\n      {0x2ceb, 2736, 1},\n\n      {0x1e90, 1929, 1},\n\n      {0x0490, 1094, 1},\n\n      {0x0190, 628, 1},\n\n      {0x1f90, 169, 2},\n\n      {0x2c90, 2610, 1},\n\n      {0x0390, 25, 3},\n\n      {0xa696, 2967, 1},\n\n      {0xab90, 1544, 1},\n\n      {0xa790, 3114, 1},\n\n      {0x10c90, 3405, 1},\n\n      {0x01d7, 444, 1},\n\n      {0x1fd7, 31, 3},\n\n      {0x1ea6, 1947, 1},\n\n      {0x04a6, 1127, 1},\n\n      {0x01a6, 676, 1},\n\n      {0x1fa6, 239, 2},\n\n      {0x2ca6, 2643, 1},\n\n      {0x03a6, 810, 1},\n\n      {0xa690, 2958, 1},\n\n      {0xaba6, 1610, 1},\n\n      {0xa7a6, 3144, 1},\n\n      {0x10ca6, 3471, 1},\n\n      {0x1ea4, 1944, 1},\n\n      {0x04a4, 1124, 1},\n\n      {0x01a4, 390, 1},\n\n      {0x1fa4, 229, 2},\n\n      {0x2ca4, 2640, 1},\n\n      {0x03a4, 804, 1},\n\n      {0x10a6, 2763, 1},\n\n      {0xaba4, 1604, 1},\n\n      {0xa7a4, 3141, 1},\n\n      {0x10ca4, 3465, 1},\n\n      {0x1ea0, 1938, 1},\n\n      {0x04a0, 1118, 1},\n\n      {0x01a0, 384, 1},\n\n      {0x1fa0, 209, 2},\n\n      {0x2ca0, 2634, 1},\n\n      {0x03a0, 792, 1},\n\n      {0x10a4, 2757, 1},\n\n      {0xaba0, 1592, 1},\n\n      {0xa7a0, 3135, 1},\n\n      {0x10ca0, 3453, 1},\n\n      {0x1eb2, 1965, 1},\n\n      {0x04b2, 1145, 1},\n\n      {0x01b2, 694, 1},\n\n      {0x1fb2, 249, 2},\n\n      {0x2cb2, 2661, 1},\n\n      {0x03fd, 718, 1},\n\n      {0x10a0, 2745, 1},\n\n      {0xabb2, 1646, 1},\n\n      {0xa7b2, 703, 1},\n\n      {0x10cb2, 3507, 1},\n\n      {0x1eac, 1956, 1},\n\n      {0x04ac, 1136, 1},\n\n      {0x01ac, 396, 1},\n\n      {0x1fac, 229, 2},\n\n      {0x2cac, 2652, 1},\n\n      {0x0537, 1352, 1},\n\n      {0x10b2, 2799, 1},\n\n      {0xabac, 1628, 1},\n\n      {0xa7ac, 637, 1},\n\n      {0x10cac, 3489, 1},\n\n      {0x1eaa, 1953, 1},\n\n      {0x04aa, 1133, 1},\n\n      {0x00dd, 162, 1},\n\n      {0x1faa, 219, 2},\n\n      {0x2caa, 2649, 1},\n\n      {0x03aa, 824, 1},\n\n      {0x10ac, 2781, 1},\n\n      {0xabaa, 1622, 1},\n\n      {0xa7aa, 646, 1},\n\n      {0x10caa, 3483, 1},\n\n      {0x1ea8, 1950, 1},\n\n      {0x04a8, 1130, 1},\n\n      {0x020a, 517, 1},\n\n      {0x1fa8, 209, 2},\n\n      {0x2ca8, 2646, 1},\n\n      {0x03a8, 817, 1},\n\n      {0x10aa, 2775, 1},\n\n      {0xaba8, 1616, 1},\n\n      {0xa7a8, 3147, 1},\n\n      {0x10ca8, 3477, 1},\n\n      {0x1ea2, 1941, 1},\n\n      {0x04a2, 1121, 1},\n\n      {0x01a2, 387, 1},\n\n      {0x1fa2, 219, 2},\n\n      {0x2ca2, 2637, 1},\n\n      {0x118a6, 3528, 1},\n\n      {0x10a8, 2769, 1},\n\n      {0xaba2, 1598, 1},\n\n      {0xa7a2, 3138, 1},\n\n      {0x10ca2, 3459, 1},\n\n      {0x2ced, 2739, 1},\n\n      {0x1fe9, 2283, 1},\n\n      {0x1fe7, 47, 3},\n\n      {0x1eb0, 1962, 1},\n\n      {0x04b0, 1142, 1},\n\n      {0x118a4, 3522, 1},\n\n      {0x10a2, 2751, 1},\n\n      {0x2cb0, 2658, 1},\n\n      {0x03b0, 41, 3},\n\n      {0x1fe3, 41, 3},\n\n      {0xabb0, 1640, 1},\n\n      {0xa7b0, 706, 1},\n\n      {0x10cb0, 3501, 1},\n\n      {0x01d9, 447, 1},\n\n      {0x1fd9, 2277, 1},\n\n      {0x118a0, 3510, 1},\n\n      {0x00df, 24, 2},\n\n      {0x00d9, 150, 1},\n\n      {0xab77, 1469, 1},\n\n      {0x10b0, 2793, 1},\n\n      {0x1eae, 1959, 1},\n\n      {0x04ae, 1139, 1},\n\n      {0x01ae, 685, 1},\n\n      {0x1fae, 239, 2},\n\n      {0x2cae, 2655, 1},\n\n      {0x118b2, 3564, 1},\n\n      {0xab73, 1457, 1},\n\n      {0xabae, 1634, 1},\n\n      {0xab71, 1451, 1},\n\n      {0x10cae, 3495, 1},\n\n      {0x1e2a, 1775, 1},\n\n      {0x042a, 968, 1},\n\n      {0x012a, 234, 1},\n\n      {0x1f2a, 2130, 1},\n\n      {0x2c2a, 2547, 1},\n\n      {0x118ac, 3546, 1},\n\n      {0x10ae, 2787, 1},\n\n      {0x0535, 1346, 1},\n\n      {0xa72a, 2988, 1},\n\n      {0x1e9a, 0, 2},\n\n      {0x049a, 1109, 1},\n\n      {0xff37, 3225, 1},\n\n      {0x1f9a, 179, 2},\n\n      {0x2c9a, 2625, 1},\n\n      {0x039a, 772, 1},\n\n      {0x118aa, 3540, 1},\n\n      {0xab9a, 1574, 1},\n\n      {0xa79a, 3126, 1},\n\n      {0x10c9a, 3435, 1},\n\n      {0x1e94, 1935, 1},\n\n      {0x0494, 1100, 1},\n\n      {0x0194, 640, 1},\n\n      {0x1f94, 189, 2},\n\n      {0x2c94, 2616, 1},\n\n      {0x0394, 749, 1},\n\n      {0x118a8, 3534, 1},\n\n      {0xab94, 1556, 1},\n\n      {0xa69a, 2973, 1},\n\n      {0x10c94, 3417, 1},\n\n      {0x10402, 3243, 1},\n\n      {0x1e02, 1715, 1},\n\n      {0x0402, 992, 1},\n\n      {0x0102, 174, 1},\n\n      {0x0533, 1340, 1},\n\n      {0x2c02, 2427, 1},\n\n      {0x118a2, 3516, 1},\n\n      {0x052a, 1325, 1},\n\n      {0xa694, 2964, 1},\n\n      {0x1e92, 1932, 1},\n\n      {0x0492, 1097, 1},\n\n      {0x2165, 2307, 1},\n\n      {0x1f92, 179, 2},\n\n      {0x2c92, 2613, 1},\n\n      {0x0392, 742, 1},\n\n      {0x2161, 2295, 1},\n\n      {0xab92, 1550, 1},\n\n      {0xa792, 3117, 1},\n\n      {0x10c92, 3411, 1},\n\n      {0x118b0, 3558, 1},\n\n      {0x1f5f, 2199, 1},\n\n      {0x1e8e, 1926, 1},\n\n      {0x048e, 1091, 1},\n\n      {0x018e, 453, 1},\n\n      {0x1f8e, 159, 2},\n\n      {0x2c8e, 2607, 1},\n\n      {0x038e, 833, 1},\n\n      {0xa692, 2961, 1},\n\n      {0xab8e, 1538, 1},\n\n      {0x0055, 59, 1},\n\n      {0x10c8e, 3399, 1},\n\n      {0x1f5d, 2196, 1},\n\n      {0x212a, 27, 1},\n\n      {0x04cb, 1181, 1},\n\n      {0x01cb, 425, 1},\n\n      {0x1fcb, 2241, 1},\n\n      {0x118ae, 3552, 1},\n\n      {0x0502, 1265, 1},\n\n      {0x00cb, 111, 1},\n\n      {0xa68e, 2955, 1},\n\n      {0x1e8a, 1920, 1},\n\n      {0x048a, 1085, 1},\n\n      {0x018a, 622, 1},\n\n      {0x1f8a, 139, 2},\n\n      {0x2c8a, 2601, 1},\n\n      {0x038a, 736, 1},\n\n      {0x2c67, 2571, 1},\n\n      {0xab8a, 1526, 1},\n\n      {0x1e86, 1914, 1},\n\n      {0x10c8a, 3387, 1},\n\n      {0x0186, 616, 1},\n\n      {0x1f86, 159, 2},\n\n      {0x2c86, 2595, 1},\n\n      {0x0386, 727, 1},\n\n      {0xff35, 3219, 1},\n\n      {0xab86, 1514, 1},\n\n      {0xa786, 3108, 1},\n\n      {0x10c86, 3375, 1},\n\n      {0xa68a, 2949, 1},\n\n      {0x0555, 1442, 1},\n\n      {0x1ebc, 1980, 1},\n\n      {0x04bc, 1160, 1},\n\n      {0x01bc, 411, 1},\n\n      {0x1fbc, 62, 2},\n\n      {0x2cbc, 2676, 1},\n\n      {0x1f5b, 2193, 1},\n\n      {0xa686, 2943, 1},\n\n      {0xabbc, 1676, 1},\n\n      {0x1eb8, 1974, 1},\n\n      {0x04b8, 1154, 1},\n\n      {0x01b8, 408, 1},\n\n      {0x1fb8, 2268, 1},\n\n      {0x2cb8, 2670, 1},\n\n      {0x01db, 450, 1},\n\n      {0x1fdb, 2247, 1},\n\n      {0xabb8, 1664, 1},\n\n      {0x10bc, 2829, 1},\n\n      {0x00db, 156, 1},\n\n      {0x1eb6, 1971, 1},\n\n      {0x04b6, 1151, 1},\n\n      {0xff33, 3213, 1},\n\n      {0x1fb6, 58, 2},\n\n      {0x2cb6, 2667, 1},\n\n      {0xff2a, 3186, 1},\n\n      {0x10b8, 2817, 1},\n\n      {0xabb6, 1658, 1},\n\n      {0xa7b6, 3153, 1},\n\n      {0x10426, 3351, 1},\n\n      {0x1e26, 1769, 1},\n\n      {0x0426, 956, 1},\n\n      {0x0126, 228, 1},\n\n      {0x0053, 52, 1},\n\n      {0x2c26, 2535, 1},\n\n      {0x0057, 65, 1},\n\n      {0x10b6, 2811, 1},\n\n      {0x022a, 562, 1},\n\n      {0xa726, 2982, 1},\n\n      {0x1e2e, 1781, 1},\n\n      {0x042e, 980, 1},\n\n      {0x012e, 240, 1},\n\n      {0x1f2e, 2142, 1},\n\n      {0x2c2e, 2559, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2167, 2313, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa72e, 2994, 1},\n\n      {0x1e2c, 1778, 1},\n\n      {0x042c, 974, 1},\n\n      {0x012c, 237, 1},\n\n      {0x1f2c, 2136, 1},\n\n      {0x2c2c, 2553, 1},\n\n      {0x1f6f, 2223, 1},\n\n      {0x2c6f, 604, 1},\n\n      {0xabbf, 1685, 1},\n\n      {0xa72c, 2991, 1},\n\n      {0x1e28, 1772, 1},\n\n      {0x0428, 962, 1},\n\n      {0x0128, 231, 1},\n\n      {0x1f28, 2124, 1},\n\n      {0x2c28, 2541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0553, 1436, 1},\n\n      {0x10bf, 2838, 1},\n\n      {0xa728, 2985, 1},\n\n      {0x0526, 1319, 1},\n\n      {0x0202, 505, 1},\n\n      {0x1e40, 1808, 1},\n\n      {0x10424, 3345, 1},\n\n      {0x1e24, 1766, 1},\n\n      {0x0424, 950, 1},\n\n      {0x0124, 225, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c24, 2529, 1},\n\n      {0x052e, 1331, 1},\n\n      {0xa740, 3018, 1},\n\n      {0x118bc, 3594, 1},\n\n      {0xa724, 2979, 1},\n\n      {0x1ef2, 2061, 1},\n\n      {0x04f2, 1241, 1},\n\n      {0x01f2, 483, 1},\n\n      {0x1ff2, 257, 2},\n\n      {0x2cf2, 2742, 1},\n\n      {0x052c, 1328, 1},\n\n      {0x118b8, 3582, 1},\n\n      {0xa640, 2865, 1},\n\n      {0x10422, 3339, 1},\n\n      {0x1e22, 1763, 1},\n\n      {0x0422, 944, 1},\n\n      {0x0122, 222, 1},\n\n      {0x2126, 820, 1},\n\n      {0x2c22, 2523, 1},\n\n      {0x0528, 1322, 1},\n\n      {0x01f1, 483, 1},\n\n      {0x118b6, 3576, 1},\n\n      {0xa722, 2976, 1},\n\n      {0x03f1, 796, 1},\n\n      {0x1ebe, 1983, 1},\n\n      {0x04be, 1163, 1},\n\n      {0xfb02, 12, 2},\n\n      {0x1fbe, 767, 1},\n\n      {0x2cbe, 2679, 1},\n\n      {0x01b5, 405, 1},\n\n      {0x0540, 1379, 1},\n\n      {0xabbe, 1682, 1},\n\n      {0x0524, 1316, 1},\n\n      {0x00b5, 779, 1},\n\n      {0xabb5, 1655, 1},\n\n      {0x1eba, 1977, 1},\n\n      {0x04ba, 1157, 1},\n\n      {0x216f, 2337, 1},\n\n      {0x1fba, 2226, 1},\n\n      {0x2cba, 2673, 1},\n\n      {0x10be, 2835, 1},\n\n      {0x0051, 46, 1},\n\n      {0xabba, 1670, 1},\n\n      {0x10b5, 2808, 1},\n\n      {0x1e6e, 1878, 1},\n\n      {0x046e, 1055, 1},\n\n      {0x016e, 330, 1},\n\n      {0x1f6e, 2220, 1},\n\n      {0x2c6e, 664, 1},\n\n      {0x118bf, 3603, 1},\n\n      {0x0522, 1313, 1},\n\n      {0x10ba, 2823, 1},\n\n      {0xa76e, 3087, 1},\n\n      {0x1eb4, 1968, 1},\n\n      {0x04b4, 1148, 1},\n\n      {0x2c75, 2583, 1},\n\n      {0x1fb4, 50, 2},\n\n      {0x2cb4, 2664, 1},\n\n      {0xab75, 1463, 1},\n\n      {0x1ec2, 1989, 1},\n\n      {0xabb4, 1652, 1},\n\n      {0xa7b4, 3150, 1},\n\n      {0x1fc2, 253, 2},\n\n      {0x2cc2, 2685, 1},\n\n      {0x03c2, 800, 1},\n\n      {0x00c2, 83, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff26, 3174, 1},\n\n      {0x10b4, 2805, 1},\n\n      {0x1eca, 2001, 1},\n\n      {0x0551, 1430, 1},\n\n      {0x01ca, 425, 1},\n\n      {0x1fca, 2238, 1},\n\n      {0x2cca, 2697, 1},\n\n      {0x10c2, 2847, 1},\n\n      {0x00ca, 108, 1},\n\n      {0xff2e, 3198, 1},\n\n      {0x1e8c, 1923, 1},\n\n      {0x048c, 1088, 1},\n\n      {0x0226, 556, 1},\n\n      {0x1f8c, 149, 2},\n\n      {0x2c8c, 2604, 1},\n\n      {0x038c, 830, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8c, 1532, 1},\n\n      {0xff2c, 3192, 1},\n\n      {0x10c8c, 3393, 1},\n\n      {0x1ec4, 1992, 1},\n\n      {0x022e, 568, 1},\n\n      {0x01c4, 417, 1},\n\n      {0x1fc4, 54, 2},\n\n      {0x2cc4, 2688, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c4, 89, 1},\n\n      {0xff28, 3180, 1},\n\n      {0xa68c, 2952, 1},\n\n      {0x01cf, 432, 1},\n\n      {0x022c, 565, 1},\n\n      {0x118be, 3600, 1},\n\n      {0x03cf, 839, 1},\n\n      {0x00cf, 123, 1},\n\n      {0x118b5, 3573, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c4, 2853, 1},\n\n      {0x216e, 2334, 1},\n\n      {0x24cb, 2406, 1},\n\n      {0x0228, 559, 1},\n\n      {0xff24, 3168, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ba, 3588, 1},\n\n      {0x1efe, 2079, 1},\n\n      {0x04fe, 1259, 1},\n\n      {0x01fe, 499, 1},\n\n      {0x1e9e, 24, 2},\n\n      {0x049e, 1115, 1},\n\n      {0x03fe, 721, 1},\n\n      {0x1f9e, 199, 2},\n\n      {0x2c9e, 2631, 1},\n\n      {0x039e, 786, 1},\n\n      {0x0224, 553, 1},\n\n      {0xab9e, 1586, 1},\n\n      {0xa79e, 3132, 1},\n\n      {0x10c9e, 3447, 1},\n\n      {0x01f7, 414, 1},\n\n      {0x1ff7, 67, 3},\n\n      {0xff22, 3162, 1},\n\n      {0x03f7, 884, 1},\n\n      {0x118b4, 3570, 1},\n\n      {0x049c, 1112, 1},\n\n      {0x019c, 661, 1},\n\n      {0x1f9c, 189, 2},\n\n      {0x2c9c, 2628, 1},\n\n      {0x039c, 779, 1},\n\n      {0x24bc, 2361, 1},\n\n      {0xab9c, 1580, 1},\n\n      {0xa79c, 3129, 1},\n\n      {0x10c9c, 3441, 1},\n\n      {0x0222, 550, 1},\n\n      {0x1e7c, 1899, 1},\n\n      {0x047c, 1076, 1},\n\n      {0x1e82, 1908, 1},\n\n      {0x24b8, 2349, 1},\n\n      {0x0182, 357, 1},\n\n      {0x1f82, 139, 2},\n\n      {0x2c82, 2589, 1},\n\n      {0xab7c, 1484, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab82, 1502, 1},\n\n      {0xa782, 3102, 1},\n\n      {0x10c82, 3363, 1},\n\n      {0x2c63, 1709, 1},\n\n      {0x24b6, 2343, 1},\n\n      {0x1e80, 1905, 1},\n\n      {0x0480, 1082, 1},\n\n      {0x1f59, 2190, 1},\n\n      {0x1f80, 129, 2},\n\n      {0x2c80, 2586, 1},\n\n      {0x0059, 71, 1},\n\n      {0xa682, 2937, 1},\n\n      {0xab80, 1496, 1},\n\n      {0xa780, 3099, 1},\n\n      {0x10c80, 3357, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1e4c, 1826, 1},\n\n      {0x0145, 270, 1},\n\n      {0x014c, 279, 1},\n\n      {0x1f4c, 2184, 1},\n\n      {0x0345, 767, 1},\n\n      {0x0045, 12, 1},\n\n      {0x004c, 31, 1},\n\n      {0xa680, 2934, 1},\n\n      {0xa74c, 3036, 1},\n\n      {0x1e4a, 1823, 1},\n\n      {0x01d5, 441, 1},\n\n      {0x014a, 276, 1},\n\n      {0x1f4a, 2178, 1},\n\n      {0x03d5, 810, 1},\n\n      {0x00d5, 141, 1},\n\n      {0x004a, 24, 1},\n\n      {0x24bf, 2370, 1},\n\n      {0xa74a, 3033, 1},\n\n      {0xa64c, 2883, 1},\n\n      {0x1041c, 3321, 1},\n\n      {0x1e1c, 1754, 1},\n\n      {0x041c, 926, 1},\n\n      {0x011c, 213, 1},\n\n      {0x1f1c, 2118, 1},\n\n      {0x2c1c, 2505, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xa64a, 2880, 1},\n\n      {0x1041a, 3315, 1},\n\n      {0x1e1a, 1751, 1},\n\n      {0x041a, 920, 1},\n\n      {0x011a, 210, 1},\n\n      {0x1f1a, 2112, 1},\n\n      {0x2c1a, 2499, 1},\n\n      {0xabbd, 1679, 1},\n\n      {0x0545, 1394, 1},\n\n      {0x054c, 1415, 1},\n\n      {0x10418, 3309, 1},\n\n      {0x1e18, 1748, 1},\n\n      {0x0418, 914, 1},\n\n      {0x0118, 207, 1},\n\n      {0x1f18, 2106, 1},\n\n      {0x2c18, 2493, 1},\n\n      {0x10bd, 2832, 1},\n\n      {0x2163, 2301, 1},\n\n      {0x054a, 1409, 1},\n\n      {0x1040e, 3279, 1},\n\n      {0x1e0e, 1733, 1},\n\n      {0x040e, 1028, 1},\n\n      {0x010e, 192, 1},\n\n      {0x1f0e, 2100, 1},\n\n      {0x2c0e, 2463, 1},\n\n      {0x1efc, 2076, 1},\n\n      {0x04fc, 1256, 1},\n\n      {0x01fc, 496, 1},\n\n      {0x1ffc, 96, 2},\n\n      {0x051c, 1304, 1},\n\n      {0x1040c, 3273, 1},\n\n      {0x1e0c, 1730, 1},\n\n      {0x040c, 1022, 1},\n\n      {0x010c, 189, 1},\n\n      {0x1f0c, 2094, 1},\n\n      {0x2c0c, 2457, 1},\n\n      {0x1f6d, 2217, 1},\n\n      {0x2c6d, 607, 1},\n\n      {0x051a, 1301, 1},\n\n      {0x24be, 2367, 1},\n\n      {0x10408, 3261, 1},\n\n      {0x1e08, 1724, 1},\n\n      {0x0408, 1010, 1},\n\n      {0x0108, 183, 1},\n\n      {0x1f08, 2082, 1},\n\n      {0x2c08, 2445, 1},\n\n      {0x04c9, 1178, 1},\n\n      {0x0518, 1298, 1},\n\n      {0x1fc9, 2235, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ba, 2355, 1},\n\n      {0x00c9, 105, 1},\n\n      {0x10416, 3303, 1},\n\n      {0x1e16, 1745, 1},\n\n      {0x0416, 908, 1},\n\n      {0x0116, 204, 1},\n\n      {0x050e, 1283, 1},\n\n      {0x2c16, 2487, 1},\n\n      {0x10414, 3297, 1},\n\n      {0x1e14, 1742, 1},\n\n      {0x0414, 902, 1},\n\n      {0x0114, 201, 1},\n\n      {0x042b, 971, 1},\n\n      {0x2c14, 2481, 1},\n\n      {0x1f2b, 2133, 1},\n\n      {0x2c2b, 2550, 1},\n      {0xffffffff, -1, 0},\n\n      {0x050c, 1280, 1},\n\n      {0x10406, 3255, 1},\n\n      {0x1e06, 1721, 1},\n\n      {0x0406, 1004, 1},\n\n      {0x0106, 180, 1},\n\n      {0x13fb, 1697, 1},\n\n      {0x2c06, 2439, 1},\n\n      {0x24c2, 2379, 1},\n\n      {0x118bd, 3597, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0508, 1274, 1},\n\n      {0x10404, 3249, 1},\n\n      {0x1e04, 1718, 1},\n\n      {0x0404, 998, 1},\n\n      {0x0104, 177, 1},\n\n      {0x1f95, 194, 2},\n\n      {0x2c04, 2433, 1},\n\n      {0x0395, 752, 1},\n\n      {0x24ca, 2403, 1},\n\n      {0xab95, 1559, 1},\n\n      {0x0531, 1334, 1},\n\n      {0x10c95, 3420, 1},\n\n      {0x0516, 1295, 1},\n\n      {0x1e6c, 1875, 1},\n\n      {0x046c, 1052, 1},\n\n      {0x016c, 327, 1},\n\n      {0x1f6c, 2214, 1},\n\n      {0x216d, 2331, 1},\n\n      {0x0514, 1292, 1},\n\n      {0x0245, 697, 1},\n\n      {0x024c, 598, 1},\n\n      {0xa76c, 3084, 1},\n\n      {0x10400, 3237, 1},\n\n      {0x1e00, 1712, 1},\n\n      {0x0400, 986, 1},\n\n      {0x0100, 171, 1},\n\n      {0x24c4, 2385, 1},\n\n      {0x2c00, 2421, 1},\n\n      {0x0506, 1271, 1},\n\n      {0x024a, 595, 1},\n\n      {0x1fab, 224, 2},\n\n      {0xa66c, 2931, 1},\n\n      {0x03ab, 827, 1},\n\n      {0x24cf, 2418, 1},\n\n      {0xabab, 1625, 1},\n\n      {0xa7ab, 631, 1},\n\n      {0x10cab, 3486, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0504, 1268, 1},\n      {0xffffffff, -1, 0},\n\n      {0x021c, 544, 1},\n\n      {0x01a9, 679, 1},\n\n      {0x1fa9, 214, 2},\n\n      {0x10ab, 2778, 1},\n\n      {0x03a9, 820, 1},\n\n      {0x212b, 92, 1},\n\n      {0xaba9, 1619, 1},\n\n      {0x1e88, 1917, 1},\n\n      {0x10ca9, 3480, 1},\n\n      {0x021a, 541, 1},\n\n      {0x1f88, 129, 2},\n\n      {0x2c88, 2598, 1},\n\n      {0x0388, 730, 1},\n\n      {0x13fd, 1703, 1},\n\n      {0xab88, 1520, 1},\n\n      {0x10a9, 2772, 1},\n\n      {0x10c88, 3381, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0218, 538, 1},\n\n      {0x0500, 1262, 1},\n\n      {0x1f4d, 2187, 1},\n\n      {0x01a7, 393, 1},\n\n      {0x1fa7, 244, 2},\n\n      {0x004d, 34, 1},\n\n      {0x03a7, 814, 1},\n\n      {0xa688, 2946, 1},\n\n      {0xaba7, 1613, 1},\n\n      {0x020e, 523, 1},\n\n      {0x10ca7, 3474, 1},\n\n      {0x1e6a, 1872, 1},\n\n      {0x046a, 1049, 1},\n\n      {0x016a, 324, 1},\n\n      {0x1f6a, 2208, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216c, 2328, 1},\n\n      {0x10a7, 2766, 1},\n\n      {0x01d1, 435, 1},\n\n      {0xa76a, 3081, 1},\n\n      {0x020c, 520, 1},\n\n      {0x03d1, 762, 1},\n\n      {0x00d1, 129, 1},\n\n      {0x1e68, 1869, 1},\n\n      {0x0468, 1046, 1},\n\n      {0x0168, 321, 1},\n\n      {0x1f68, 2202, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff31, 3207, 1},\n\n      {0xa66a, 2928, 1},\n\n      {0x0208, 514, 1},\n\n      {0xa768, 3078, 1},\n\n      {0x1e64, 1863, 1},\n\n      {0x0464, 1040, 1},\n\n      {0x0164, 315, 1},\n\n      {0x054d, 1418, 1},\n\n      {0x2c64, 673, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff2b, 3189, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa764, 3072, 1},\n\n      {0xa668, 2925, 1},\n\n      {0x0216, 535, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ab, 3543, 1},\n\n      {0x1e62, 1860, 1},\n\n      {0x0462, 1037, 1},\n\n      {0x0162, 312, 1},\n\n      {0x0214, 532, 1},\n\n      {0x2c62, 655, 1},\n\n      {0xa664, 2919, 1},\n\n      {0x1ed2, 2013, 1},\n\n      {0x04d2, 1193, 1},\n\n      {0xa762, 3069, 1},\n\n      {0x1fd2, 20, 3},\n\n      {0x2cd2, 2709, 1},\n\n      {0x118a9, 3537, 1},\n\n      {0x00d2, 132, 1},\n\n      {0x0206, 511, 1},\n\n      {0x10420, 3333, 1},\n\n      {0x1e20, 1760, 1},\n\n      {0x0420, 938, 1},\n\n      {0x0120, 219, 1},\n\n      {0xa662, 2916, 1},\n\n      {0x2c20, 2517, 1},\n\n      {0x1e60, 1856, 1},\n\n      {0x0460, 1034, 1},\n\n      {0x0160, 309, 1},\n\n      {0x0204, 508, 1},\n\n      {0x2c60, 2562, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24bd, 2364, 1},\n\n      {0x216a, 2322, 1},\n\n      {0xa760, 3066, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb16, 125, 2},\n\n      {0x118a7, 3531, 1},\n\n      {0x1efa, 2073, 1},\n\n      {0x04fa, 1253, 1},\n\n      {0x01fa, 493, 1},\n\n      {0x1ffa, 2262, 1},\n\n      {0xfb14, 109, 2},\n\n      {0x03fa, 887, 1},\n\n      {0xa660, 2913, 1},\n\n      {0x2168, 2316, 1},\n\n      {0x01b7, 700, 1},\n\n      {0x1fb7, 10, 3},\n\n      {0x1f6b, 2211, 1},\n\n      {0x2c6b, 2577, 1},\n\n      {0x0200, 502, 1},\n\n      {0xabb7, 1661, 1},\n\n      {0xfb06, 29, 2},\n\n      {0x1e56, 1841, 1},\n\n      {0x2164, 2304, 1},\n\n      {0x0156, 294, 1},\n\n      {0x1f56, 62, 3},\n\n      {0x0520, 1310, 1},\n\n      {0x004f, 40, 1},\n\n      {0x0056, 62, 1},\n\n      {0x10b7, 2814, 1},\n\n      {0xa756, 3051, 1},\n\n      {0xfb04, 5, 3},\n\n      {0x1e78, 1893, 1},\n\n      {0x0478, 1070, 1},\n\n      {0x0178, 168, 1},\n\n      {0x1e54, 1838, 1},\n\n      {0x2162, 2298, 1},\n\n      {0x0154, 291, 1},\n\n      {0x1f54, 57, 3},\n\n      {0xab78, 1472, 1},\n\n      {0xa656, 2898, 1},\n\n      {0x0054, 56, 1},\n\n      {0x1e52, 1835, 1},\n\n      {0xa754, 3048, 1},\n\n      {0x0152, 288, 1},\n\n      {0x1f52, 52, 3},\n\n      {0x24c9, 2400, 1},\n\n      {0x1e32, 1787, 1},\n\n      {0x0052, 49, 1},\n\n      {0x0132, 243, 1},\n\n      {0xa752, 3045, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb00, 4, 2},\n\n      {0xa654, 2895, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa732, 2997, 1},\n\n      {0x2160, 2292, 1},\n\n      {0x054f, 1424, 1},\n\n      {0x0556, 1445, 1},\n\n      {0x1e50, 1832, 1},\n\n      {0xa652, 2892, 1},\n\n      {0x0150, 285, 1},\n\n      {0x1f50, 84, 2},\n\n      {0x017b, 348, 1},\n\n      {0x1e4e, 1829, 1},\n\n      {0x0050, 43, 1},\n\n      {0x014e, 282, 1},\n\n      {0xa750, 3042, 1},\n\n      {0xab7b, 1481, 1},\n\n      {0xa77b, 3093, 1},\n\n      {0x004e, 37, 1},\n\n      {0x0554, 1439, 1},\n\n      {0xa74e, 3039, 1},\n\n      {0x1e48, 1820, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216b, 2325, 1},\n\n      {0x1f48, 2172, 1},\n\n      {0xa650, 2889, 1},\n\n      {0x0552, 1433, 1},\n\n      {0x0048, 21, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa748, 3030, 1},\n\n      {0xa64e, 2886, 1},\n\n      {0x0532, 1337, 1},\n\n      {0x1041e, 3327, 1},\n\n      {0x1e1e, 1757, 1},\n\n      {0x041e, 932, 1},\n\n      {0x011e, 216, 1},\n\n      {0x118b7, 3579, 1},\n\n      {0x2c1e, 2511, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa648, 2877, 1},\n\n      {0x1ff9, 2253, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03f9, 878, 1},\n\n      {0x0550, 1427, 1},\n\n      {0x10412, 3291, 1},\n\n      {0x1e12, 1739, 1},\n\n      {0x0412, 896, 1},\n\n      {0x0112, 198, 1},\n\n      {0x054e, 1421, 1},\n\n      {0x2c12, 2475, 1},\n\n      {0x10410, 3285, 1},\n\n      {0x1e10, 1736, 1},\n\n      {0x0410, 890, 1},\n\n      {0x0110, 195, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c10, 2469, 1},\n\n      {0x2132, 2289, 1},\n\n      {0x0548, 1403, 1},\n\n      {0x1ef8, 2070, 1},\n\n      {0x04f8, 1250, 1},\n\n      {0x01f8, 490, 1},\n\n      {0x1ff8, 2250, 1},\n\n      {0x0220, 381, 1},\n\n      {0x1ee2, 2037, 1},\n\n      {0x04e2, 1217, 1},\n\n      {0x01e2, 462, 1},\n\n      {0x1fe2, 36, 3},\n\n      {0x2ce2, 2733, 1},\n\n      {0x03e2, 857, 1},\n\n      {0x051e, 1307, 1},\n\n      {0x1ede, 2031, 1},\n\n      {0x04de, 1211, 1},\n\n      {0x01de, 456, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cde, 2727, 1},\n\n      {0x03de, 851, 1},\n\n      {0x00de, 165, 1},\n\n      {0x1f69, 2205, 1},\n\n      {0x2c69, 2574, 1},\n\n      {0x1eda, 2025, 1},\n\n      {0x04da, 1205, 1},\n\n      {0x0512, 1289, 1},\n\n      {0x1fda, 2244, 1},\n\n      {0x2cda, 2721, 1},\n\n      {0x03da, 845, 1},\n\n      {0x00da, 153, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0510, 1286, 1},\n\n      {0x1ed8, 2022, 1},\n\n      {0x04d8, 1202, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd8, 2274, 1},\n\n      {0x2cd8, 2718, 1},\n\n      {0x03d8, 842, 1},\n\n      {0x00d8, 147, 1},\n\n      {0x1ed6, 2019, 1},\n\n      {0x04d6, 1199, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd6, 76, 2},\n\n      {0x2cd6, 2715, 1},\n\n      {0x03d6, 792, 1},\n\n      {0x00d6, 144, 1},\n\n      {0x1ec8, 1998, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01c8, 421, 1},\n\n      {0x1fc8, 2232, 1},\n\n      {0x2cc8, 2694, 1},\n\n      {0xff32, 3210, 1},\n\n      {0x00c8, 102, 1},\n\n      {0x04c7, 1175, 1},\n\n      {0x01c7, 421, 1},\n\n      {0x1fc7, 15, 3},\n\n      {0x1ec0, 1986, 1},\n\n      {0x04c0, 1187, 1},\n\n      {0x00c7, 99, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cc0, 2682, 1},\n\n      {0x0179, 345, 1},\n\n      {0x00c0, 77, 1},\n\n      {0x0232, 574, 1},\n\n      {0x01b3, 402, 1},\n\n      {0x1fb3, 62, 2},\n\n      {0xab79, 1475, 1},\n\n      {0xa779, 3090, 1},\n\n      {0x10c7, 2859, 1},\n\n      {0xabb3, 1649, 1},\n\n      {0xa7b3, 3156, 1},\n\n      {0x1fa5, 234, 2},\n\n      {0x10c0, 2841, 1},\n\n      {0x03a5, 807, 1},\n      {0xffffffff, -1, 0},\n\n      {0xaba5, 1607, 1},\n\n      {0x01b1, 691, 1},\n\n      {0x10ca5, 3468, 1},\n\n      {0x10b3, 2802, 1},\n\n      {0x2169, 2319, 1},\n\n      {0x024e, 601, 1},\n\n      {0xabb1, 1643, 1},\n\n      {0xa7b1, 682, 1},\n\n      {0x10cb1, 3504, 1},\n\n      {0x10a5, 2760, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01af, 399, 1},\n\n      {0x1faf, 244, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0248, 592, 1},\n\n      {0x10b1, 2796, 1},\n\n      {0xabaf, 1637, 1},\n\n      {0x1fad, 234, 2},\n\n      {0x10caf, 3498, 1},\n\n      {0x04cd, 1184, 1},\n\n      {0x01cd, 429, 1},\n\n      {0xabad, 1631, 1},\n\n      {0xa7ad, 658, 1},\n\n      {0x10cad, 3492, 1},\n\n      {0x00cd, 117, 1},\n\n      {0x10af, 2790, 1},\n\n      {0x021e, 547, 1},\n\n      {0x1fa3, 224, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03a3, 800, 1},\n\n      {0x10ad, 2784, 1},\n\n      {0xaba3, 1601, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10ca3, 3462, 1},\n\n      {0x10cd, 2862, 1},\n\n      {0x1fa1, 214, 2},\n\n      {0x24b7, 2346, 1},\n\n      {0x03a1, 796, 1},\n\n      {0x0212, 529, 1},\n\n      {0xaba1, 1595, 1},\n\n      {0x10a3, 2754, 1},\n\n      {0x10ca1, 3456, 1},\n\n      {0x01d3, 438, 1},\n\n      {0x1fd3, 25, 3},\n\n      {0x0210, 526, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00d3, 135, 1},\n\n      {0x1e97, 34, 2},\n\n      {0x10a1, 2748, 1},\n\n      {0x0197, 649, 1},\n\n      {0x1f97, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0397, 759, 1},\n\n      {0x1041d, 3324, 1},\n\n      {0xab97, 1565, 1},\n\n      {0x041d, 929, 1},\n\n      {0x10c97, 3426, 1},\n\n      {0x1f1d, 2121, 1},\n\n      {0x2c1d, 2508, 1},\n\n      {0x1e72, 1884, 1},\n\n      {0x0472, 1061, 1},\n\n      {0x0172, 336, 1},\n\n      {0x118b3, 3567, 1},\n\n      {0x2c72, 2580, 1},\n\n      {0x0372, 712, 1},\n\n      {0x1041b, 3318, 1},\n\n      {0xab72, 1454, 1},\n\n      {0x041b, 923, 1},\n\n      {0x118a5, 3525, 1},\n\n      {0x1f1b, 2115, 1},\n\n      {0x2c1b, 2502, 1},\n\n      {0x1e70, 1881, 1},\n\n      {0x0470, 1058, 1},\n\n      {0x0170, 333, 1},\n\n      {0x118b1, 3561, 1},\n\n      {0x2c70, 610, 1},\n\n      {0x0370, 709, 1},\n\n      {0x1e46, 1817, 1},\n\n      {0xab70, 1448, 1},\n\n      {0x1e66, 1866, 1},\n\n      {0x0466, 1043, 1},\n\n      {0x0166, 318, 1},\n\n      {0x1e44, 1814, 1},\n\n      {0x0046, 15, 1},\n\n      {0x118af, 3555, 1},\n\n      {0xa746, 3027, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa766, 3075, 1},\n\n      {0x0044, 9, 1},\n\n      {0x118ad, 3549, 1},\n\n      {0xa744, 3024, 1},\n\n      {0x1e7a, 1896, 1},\n\n      {0x047a, 1073, 1},\n\n      {0x1e3a, 1799, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa646, 2874, 1},\n\n      {0x1f3a, 2154, 1},\n\n      {0xa666, 2922, 1},\n\n      {0xab7a, 1478, 1},\n\n      {0x118a3, 3519, 1},\n\n      {0xa644, 2871, 1},\n\n      {0xa73a, 3009, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1ef4, 2064, 1},\n\n      {0x04f4, 1244, 1},\n\n      {0x01f4, 487, 1},\n\n      {0x1ff4, 101, 2},\n\n      {0x118a1, 3513, 1},\n\n      {0x03f4, 762, 1},\n\n      {0x1eec, 2052, 1},\n\n      {0x04ec, 1232, 1},\n\n      {0x01ec, 477, 1},\n\n      {0x1fec, 2286, 1},\n\n      {0x0546, 1397, 1},\n\n      {0x03ec, 872, 1},\n      {0xffffffff, -1, 0},\n\n      {0x013f, 261, 1},\n\n      {0x1f3f, 2169, 1},\n\n      {0x0544, 1391, 1},\n\n      {0x1eea, 2049, 1},\n\n      {0x04ea, 1229, 1},\n\n      {0x01ea, 474, 1},\n\n      {0x1fea, 2256, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03ea, 869, 1},\n\n      {0x1ee8, 2046, 1},\n\n      {0x04e8, 1226, 1},\n\n      {0x01e8, 471, 1},\n\n      {0x1fe8, 2280, 1},\n\n      {0x053a, 1361, 1},\n\n      {0x03e8, 866, 1},\n\n      {0x1ee6, 2043, 1},\n\n      {0x04e6, 1223, 1},\n\n      {0x01e6, 468, 1},\n\n      {0x1fe6, 88, 2},\n\n      {0x1f4b, 2181, 1},\n\n      {0x03e6, 863, 1},\n\n      {0x1e5e, 1853, 1},\n\n      {0x004b, 27, 1},\n\n      {0x015e, 306, 1},\n\n      {0x2166, 2310, 1},\n\n      {0x1ee4, 2040, 1},\n\n      {0x04e4, 1220, 1},\n\n      {0x01e4, 465, 1},\n\n      {0x1fe4, 80, 2},\n\n      {0xa75e, 3063, 1},\n\n      {0x03e4, 860, 1},\n\n      {0x1ee0, 2034, 1},\n\n      {0x04e0, 1214, 1},\n\n      {0x01e0, 459, 1},\n\n      {0x053f, 1376, 1},\n\n      {0x2ce0, 2730, 1},\n\n      {0x03e0, 854, 1},\n\n      {0x1edc, 2028, 1},\n\n      {0x04dc, 1208, 1},\n\n      {0xa65e, 2910, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cdc, 2724, 1},\n\n      {0x03dc, 848, 1},\n\n      {0x00dc, 159, 1},\n\n      {0x1ed0, 2010, 1},\n\n      {0x04d0, 1190, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x2cd0, 2706, 1},\n\n      {0x03d0, 742, 1},\n\n      {0x00d0, 126, 1},\n\n      {0x1ecc, 2004, 1},\n\n      {0x054b, 1412, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fcc, 71, 2},\n\n      {0x2ccc, 2700, 1},\n\n      {0x1ec6, 1995, 1},\n\n      {0x00cc, 114, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fc6, 67, 2},\n\n      {0x2cc6, 2691, 1},\n\n      {0x24c8, 2397, 1},\n\n      {0x00c6, 96, 1},\n\n      {0x04c5, 1172, 1},\n\n      {0x01c5, 417, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fbb, 2229, 1},\n\n      {0x24c7, 2394, 1},\n\n      {0x00c5, 92, 1},\n\n      {0x1fb9, 2271, 1},\n\n      {0xabbb, 1673, 1},\n\n      {0x24c0, 2373, 1},\n\n      {0x04c3, 1169, 1},\n\n      {0xabb9, 1667, 1},\n\n      {0x1fc3, 71, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x00c3, 86, 1},\n\n      {0x10c5, 2856, 1},\n\n      {0x10bb, 2826, 1},\n\n      {0x1ed4, 2016, 1},\n\n      {0x04d4, 1196, 1},\n\n      {0x10b9, 2820, 1},\n\n      {0x13fc, 1700, 1},\n\n      {0x2cd4, 2712, 1},\n\n      {0x0246, 589, 1},\n\n      {0x00d4, 138, 1},\n\n      {0x10c3, 2850, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff3a, 3234, 1},\n\n      {0x0244, 688, 1},\n\n      {0x019f, 670, 1},\n\n      {0x1f9f, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x039f, 789, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab9f, 1589, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c9f, 3450, 1},\n\n      {0x019d, 667, 1},\n\n      {0x1f9d, 194, 2},\n\n      {0x023a, 2565, 1},\n\n      {0x039d, 783, 1},\n\n      {0x1e5a, 1847, 1},\n\n      {0xab9d, 1583, 1},\n\n      {0x015a, 300, 1},\n\n      {0x10c9d, 3444, 1},\n\n      {0x1e9b, 1856, 1},\n\n      {0x24cd, 2412, 1},\n\n      {0x005a, 74, 1},\n\n      {0x1f9b, 184, 2},\n\n      {0xa75a, 3057, 1},\n\n      {0x039b, 776, 1},\n\n      {0x1ece, 2007, 1},\n\n      {0xab9b, 1577, 1},\n\n      {0x1e99, 42, 2},\n\n      {0x10c9b, 3438, 1},\n\n      {0x2cce, 2703, 1},\n\n      {0x1f99, 174, 2},\n\n      {0x00ce, 120, 1},\n\n      {0x0399, 767, 1},\n\n      {0xa65a, 2904, 1},\n\n      {0xab99, 1571, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c99, 3432, 1},\n\n      {0x0193, 634, 1},\n\n      {0x1f93, 184, 2},\n\n      {0x1e58, 1844, 1},\n\n      {0x0393, 746, 1},\n\n      {0x0158, 297, 1},\n\n      {0xab93, 1553, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c93, 3414, 1},\n\n      {0x0058, 68, 1},\n\n      {0x042d, 977, 1},\n\n      {0xa758, 3054, 1},\n\n      {0x1f2d, 2139, 1},\n\n      {0x2c2d, 2556, 1},\n\n      {0x118bb, 3591, 1},\n\n      {0x0191, 369, 1},\n\n      {0x1f91, 174, 2},\n\n      {0x118b9, 3585, 1},\n\n      {0x0391, 739, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab91, 1547, 1},\n\n      {0xa658, 2901, 1},\n\n      {0x10c91, 3408, 1},\n\n      {0x018f, 625, 1},\n\n      {0x1f8f, 164, 2},\n      {0xffffffff, -1, 0},\n\n      {0x038f, 836, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8f, 1541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c8f, 3402, 1},\n\n      {0x018b, 366, 1},\n\n      {0x1f8b, 144, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0187, 363, 1},\n\n      {0x1f87, 164, 2},\n\n      {0xab8b, 1529, 1},\n\n      {0xa78b, 3111, 1},\n\n      {0x10c8b, 3390, 1},\n\n      {0xab87, 1517, 1},\n\n      {0x04c1, 1166, 1},\n\n      {0x10c87, 3378, 1},\n\n      {0x1e7e, 1902, 1},\n\n      {0x047e, 1079, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c1, 80, 1},\n\n      {0x2c7e, 580, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab7e, 1490, 1},\n\n      {0xa77e, 3096, 1},\n\n      {0x1e76, 1890, 1},\n\n      {0x0476, 1067, 1},\n\n      {0x0176, 342, 1},\n\n      {0x1e42, 1811, 1},\n\n      {0x10c1, 2844, 1},\n\n      {0x0376, 715, 1},\n\n      {0x1e36, 1793, 1},\n\n      {0xab76, 1466, 1},\n\n      {0x0136, 249, 1},\n\n      {0x0042, 3, 1},\n\n      {0x1e3e, 1805, 1},\n\n      {0xa742, 3021, 1},\n\n      {0x1e38, 1796, 1},\n\n      {0x1f3e, 2166, 1},\n\n      {0xa736, 3003, 1},\n\n      {0x1f38, 2148, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0587, 105, 2},\n\n      {0xa73e, 3015, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa738, 3006, 1},\n\n      {0xa642, 2868, 1},\n\n      {0x1e5c, 1850, 1},\n\n      {0x1e34, 1790, 1},\n\n      {0x015c, 303, 1},\n\n      {0x0134, 246, 1},\n\n      {0x1ef6, 2067, 1},\n\n      {0x04f6, 1247, 1},\n\n      {0x01f6, 372, 1},\n\n      {0x1ff6, 92, 2},\n\n      {0xa75c, 3060, 1},\n\n      {0xa734, 3000, 1},\n\n      {0x1ef0, 2058, 1},\n\n      {0x04f0, 1238, 1},\n\n      {0x01f0, 20, 2},\n      {0xffffffff, -1, 0},\n\n      {0x1e30, 1784, 1},\n\n      {0x03f0, 772, 1},\n\n      {0x0130, 261, 2},\n\n      {0x0542, 1385, 1},\n\n      {0xa65c, 2907, 1},\n\n      {0x1f83, 144, 2},\n\n      {0x0536, 1349, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab83, 1505, 1},\n\n      {0x053e, 1373, 1},\n\n      {0x10c83, 3366, 1},\n\n      {0x0538, 1355, 1},\n\n      {0x1eee, 2055, 1},\n\n      {0x04ee, 1235, 1},\n\n      {0x01ee, 480, 1},\n\n      {0x1f8d, 154, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03ee, 875, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8d, 1535, 1},\n\n      {0xa78d, 643, 1},\n\n      {0x10c8d, 3396, 1},\n\n      {0x0534, 1343, 1},\n\n      {0x0181, 613, 1},\n\n      {0x1f81, 134, 2},\n\n      {0x013d, 258, 1},\n\n      {0x1f3d, 2163, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab81, 1499, 1},\n\n      {0x017f, 52, 1},\n\n      {0x10c81, 3360, 1},\n\n      {0x2c7f, 583, 1},\n\n      {0x037f, 881, 1},\n\n      {0xff2d, 3195, 1},\n\n      {0xab7f, 1493, 1},\n\n      {0x1e74, 1887, 1},\n\n      {0x0474, 1064, 1},\n\n      {0x0174, 339, 1},\n\n      {0x1e3c, 1802, 1},\n\n      {0x0149, 46, 2},\n\n      {0x1f49, 2175, 1},\n\n      {0x1f3c, 2160, 1},\n\n      {0xab74, 1460, 1},\n\n      {0x0049, 3606, 1},\n\n      {0x0143, 267, 1},\n\n      {0x24cc, 2409, 1},\n\n      {0xa73c, 3012, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0043, 6, 1},\n\n      {0x0141, 264, 1},\n\n      {0x24c6, 2391, 1},\n\n      {0x013b, 255, 1},\n\n      {0x1f3b, 2157, 1},\n\n      {0x0041, 0, 1},\n\n      {0x0139, 252, 1},\n\n      {0x1f39, 2151, 1},\n\n      {0x24c5, 2388, 1},\n\n      {0x24bb, 2358, 1},\n\n      {0x13fa, 1694, 1},\n\n      {0x053d, 1370, 1},\n\n      {0x24b9, 2352, 1},\n\n      {0x0429, 965, 1},\n\n      {0x2183, 2340, 1},\n\n      {0x1f29, 2127, 1},\n\n      {0x2c29, 2544, 1},\n\n      {0x24c3, 2382, 1},\n\n      {0x10427, 3354, 1},\n\n      {0x10425, 3348, 1},\n\n      {0x0427, 959, 1},\n\n      {0x0425, 953, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c27, 2538, 1},\n\n      {0x2c25, 2532, 1},\n\n      {0x0549, 1406, 1},\n\n      {0x053c, 1367, 1},\n\n      {0x10423, 3342, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0423, 947, 1},\n\n      {0x0543, 1388, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c23, 2526, 1},\n\n      {0xff36, 3222, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0541, 1382, 1},\n\n      {0x10421, 3336, 1},\n\n      {0x053b, 1364, 1},\n\n      {0x0421, 941, 1},\n\n      {0xff38, 3228, 1},\n\n      {0x0539, 1358, 1},\n\n      {0x2c21, 2520, 1},\n\n      {0x10419, 3312, 1},\n\n      {0x10417, 3306, 1},\n\n      {0x0419, 917, 1},\n\n      {0x0417, 911, 1},\n\n      {0x1f19, 2109, 1},\n\n      {0x2c19, 2496, 1},\n\n      {0x2c17, 2490, 1},\n\n      {0x023e, 2568, 1},\n\n      {0xff34, 3216, 1},\n\n      {0x10415, 3300, 1},\n\n      {0x10413, 3294, 1},\n\n      {0x0415, 905, 1},\n\n      {0x0413, 899, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c15, 2484, 1},\n\n      {0x2c13, 2478, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ce, 2415, 1},\n\n      {0x1040f, 3282, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040f, 1031, 1},\n\n      {0xff30, 3204, 1},\n\n      {0x1f0f, 2103, 1},\n\n      {0x2c0f, 2466, 1},\n\n      {0x1040d, 3276, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040d, 1025, 1},\n\n      {0x0147, 273, 1},\n\n      {0x1f0d, 2097, 1},\n\n      {0x2c0d, 2460, 1},\n\n      {0x1040b, 3270, 1},\n\n      {0x0047, 18, 1},\n\n      {0x040b, 1019, 1},\n\n      {0x0230, 571, 1},\n\n      {0x1f0b, 2091, 1},\n\n      {0x2c0b, 2454, 1},\n\n      {0x10409, 3264, 1},\n\n      {0x10405, 3252, 1},\n\n      {0x0409, 1013, 1},\n\n      {0x0405, 1001, 1},\n\n      {0x1f09, 2085, 1},\n\n      {0x2c09, 2448, 1},\n\n      {0x2c05, 2436, 1},\n\n      {0x10403, 3246, 1},\n\n      {0x10401, 3240, 1},\n\n      {0x0403, 995, 1},\n\n      {0x0401, 989, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c03, 2430, 1},\n\n      {0x2c01, 2424, 1},\n\n      {0x13f9, 1691, 1},\n\n      {0x042f, 983, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1f2f, 2145, 1},\n\n      {0x1041f, 3330, 1},\n      {0xffffffff, -1, 0},\n\n      {0x041f, 935, 1},\n\n      {0x023d, 378, 1},\n\n      {0x10411, 3288, 1},\n\n      {0x2c1f, 2514, 1},\n\n      {0x0411, 893, 1},\n\n      {0x0547, 1400, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c11, 2472, 1},\n\n      {0x10407, 3258, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0407, 1007, 1},\n\n      {0x24c1, 2376, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c07, 2442, 1},\n      {0xffffffff, -1, 0},\n\n      {0x13f8, 1688, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff39, 3231, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0243, 354, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x0241, 586, 1},\n\n      {0xff29, 3183, 1},\n\n      {0x023b, 577, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff27, 3177, 1},\n\n      {0xff25, 3171, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff23, 3165, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff21, 3159, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb17, 117, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff2f, 3201, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb15, 113, 2},\n\n      {0xfb13, 121, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb05, 29, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb03, 0, 3},\n\n      {0xfb01, 8, 2}\n    };\n\n  if (0 == 0)\n    {\n      int key = hash(&code);\n\n      if (key <= MAX_HASH_VALUE && key >= 0)\n        {\n          OnigCodePoint gcode = wordlist[key].code;\n\n          if (code == gcode && wordlist[key].index >= 0)\n            return &wordlist[key];\n        }\n    }\n  return 0;\n}", "commit_link": "github.com/kkos/oniguruma/commit/166a6c3999bf06b4de0ab4ce6b088a468cc4029f", "file_name": "src/unicode_unfold_key.c", "vul_type": "cwe-787", "description": "Write a function in C that searches for a Unicode code point in a static array using a hash lookup."}
{"func_name": "to_ods", "func_src_before": "    def to_ods(self, *selection):\n        if not ODFLIB_INSTALLED:\n            raise ODFLIBNotInstalled(_('odfpy not installed.'))\n        if self.fcn_list:\n            stat_list = self.fcn_list[:]\n            order_text = \"   Ordered by: \" + self.sort_type + '\\n'\n        else:\n            stat_list = self.stats.keys()\n            order_text = \"   Random listing order was used\\n\"\n        for s in selection:\n            stat_list, __ = self.eval_print_amount(s, stat_list, '')\n        spreadsheet = OpenDocumentSpreadsheet()\n        table = Table(name=\"Profile\")\n        for fn in self.files:\n            tcf = TableCell()\n            tcf.addElement(P(text=fn))\n            trf = TableRow()\n            trf.addElement(tcf)\n            table.addElement(trf)\n\n        tc_summary = TableCell()\n        summary_text = '%d function calls (%d primitive calls) in %.6f \\\n                        seconds' % (self.total_calls, self.prim_calls,\n                                    self.total_tt)\n        tc_summary.addElement(P(text=summary_text))\n        tr_summary = TableRow()\n        tr_summary.addElement(tc_summary)\n        table.addElement(tr_summary)\n\n        tc_order = TableCell()\n        tc_order.addElement(P(text=order_text))\n        tr_order = TableRow()\n        tr_order.addElement(tc_order)\n        table.addElement(tr_order)\n\n        tr_header = TableRow()\n        tc_cc = TableCell()\n        tc_cc.addElement(P(text='Total Call Count'))\n        tr_header.addElement(tc_cc)\n\n        tc_pc = TableCell()\n        tc_pc.addElement(P(text='Primitive Call Count'))\n        tr_header.addElement(tc_pc)\n\n        tc_tt = TableCell()\n        tc_tt.addElement(P(text='Total Time(seconds)'))\n        tr_header.addElement(tc_tt)\n\n        tc_pc = TableCell()\n        tc_pc.addElement(P(text='Time Per call(seconds)'))\n        tr_header.addElement(tc_pc)\n\n        tc_ct = TableCell()\n        tc_ct.addElement(P(text='Cumulative Time(seconds)'))\n        tr_header.addElement(tc_ct)\n\n        tc_pt = TableCell()\n        tc_pt.addElement(P(text='Cumulative Time per call(seconds)'))\n        tr_header.addElement(tc_pt)\n\n        tc_nfl = TableCell()\n        tc_nfl.addElement(P(text='filename:lineno(function)'))\n        tr_header.addElement(tc_nfl)\n\n        table.addElement(tr_header)\n\n        for func in stat_list:\n            cc, nc, tt, ct, __ = self.stats[func]\n            tr_header = TableRow()\n            tc_nc = TableCell()\n            tc_nc.addElement(P(text=nc))\n            tr_header.addElement(tc_nc)\n\n            tc_pc = TableCell()\n            tc_pc.addElement(P(text=cc))\n            tr_header.addElement(tc_pc)\n\n            tc_tt = TableCell()\n            tc_tt.addElement(P(text=tt))\n            tr_header.addElement(tc_tt)\n\n            tc_tpc = TableCell()\n            tc_tpc.addElement(P(text=(None if nc == 0 else float(tt) / nc)))\n            tr_header.addElement(tc_tpc)\n\n            tc_ct = TableCell()\n            tc_ct.addElement(P(text=ct))\n            tr_header.addElement(tc_ct)\n\n            tc_tpt = TableCell()\n            tc_tpt.addElement(P(text=(None if cc == 0 else float(ct) / cc)))\n            tr_header.addElement(tc_tpt)\n\n            tc_nfl = TableCell()\n            tc_nfl.addElement(P(text=func))\n            tr_header.addElement(tc_nfl)\n            table.addElement(tr_header)\n\n        spreadsheet.spreadsheet.addElement(table)\n        tmp_ods = tempfile.mktemp('.ods', 'stats')\n        spreadsheet.save(tmp_ods, False)\n        data = open(tmp_ods).read()\n        os.remove(tmp_ods)\n        return data", "func_src_after": "    def to_ods(self, *selection):\n        if not ODFLIB_INSTALLED:\n            raise ODFLIBNotInstalled(_('odfpy not installed.'))\n        if self.fcn_list:\n            stat_list = self.fcn_list[:]\n            order_text = \"   Ordered by: \" + self.sort_type + '\\n'\n        else:\n            stat_list = self.stats.keys()\n            order_text = \"   Random listing order was used\\n\"\n        for s in selection:\n            stat_list, __ = self.eval_print_amount(s, stat_list, '')\n        spreadsheet = OpenDocumentSpreadsheet()\n        table = Table(name=\"Profile\")\n        for fn in self.files:\n            tcf = TableCell()\n            tcf.addElement(P(text=fn))\n            trf = TableRow()\n            trf.addElement(tcf)\n            table.addElement(trf)\n\n        tc_summary = TableCell()\n        summary_text = '%d function calls (%d primitive calls) in %.6f \\\n                        seconds' % (self.total_calls, self.prim_calls,\n                                    self.total_tt)\n        tc_summary.addElement(P(text=summary_text))\n        tr_summary = TableRow()\n        tr_summary.addElement(tc_summary)\n        table.addElement(tr_summary)\n\n        tc_order = TableCell()\n        tc_order.addElement(P(text=order_text))\n        tr_order = TableRow()\n        tr_order.addElement(tc_order)\n        table.addElement(tr_order)\n\n        tr_header = TableRow()\n        tc_cc = TableCell()\n        tc_cc.addElement(P(text='Total Call Count'))\n        tr_header.addElement(tc_cc)\n\n        tc_pc = TableCell()\n        tc_pc.addElement(P(text='Primitive Call Count'))\n        tr_header.addElement(tc_pc)\n\n        tc_tt = TableCell()\n        tc_tt.addElement(P(text='Total Time(seconds)'))\n        tr_header.addElement(tc_tt)\n\n        tc_pc = TableCell()\n        tc_pc.addElement(P(text='Time Per call(seconds)'))\n        tr_header.addElement(tc_pc)\n\n        tc_ct = TableCell()\n        tc_ct.addElement(P(text='Cumulative Time(seconds)'))\n        tr_header.addElement(tc_ct)\n\n        tc_pt = TableCell()\n        tc_pt.addElement(P(text='Cumulative Time per call(seconds)'))\n        tr_header.addElement(tc_pt)\n\n        tc_nfl = TableCell()\n        tc_nfl.addElement(P(text='filename:lineno(function)'))\n        tr_header.addElement(tc_nfl)\n\n        table.addElement(tr_header)\n\n        for func in stat_list:\n            cc, nc, tt, ct, __ = self.stats[func]\n            tr_header = TableRow()\n            tc_nc = TableCell()\n            tc_nc.addElement(P(text=nc))\n            tr_header.addElement(tc_nc)\n\n            tc_pc = TableCell()\n            tc_pc.addElement(P(text=cc))\n            tr_header.addElement(tc_pc)\n\n            tc_tt = TableCell()\n            tc_tt.addElement(P(text=tt))\n            tr_header.addElement(tc_tt)\n\n            tc_tpc = TableCell()\n            tc_tpc.addElement(P(text=(None if nc == 0 else float(tt) / nc)))\n            tr_header.addElement(tc_tpc)\n\n            tc_ct = TableCell()\n            tc_ct.addElement(P(text=ct))\n            tr_header.addElement(tc_ct)\n\n            tc_tpt = TableCell()\n            tc_tpt.addElement(P(text=(None if cc == 0 else float(ct) / cc)))\n            tr_header.addElement(tc_tpt)\n\n            tc_nfl = TableCell()\n            tc_nfl.addElement(P(text=func))\n            tr_header.addElement(tc_nfl)\n            table.addElement(tr_header)\n\n        spreadsheet.spreadsheet.addElement(table)\n        tmp_ods = tempfile.TemporaryFile()\n        spreadsheet.write(tmp_ods)\n        tmp_ods.seek(0)\n        data = tmp_ods.read()\n        os.close(tmp_ods)\n        return data", "line_changes": {"deleted": [{"line_no": 100, "char_start": 3365, "char_end": 3416, "line": "        tmp_ods = tempfile.mktemp('.ods', 'stats')\n"}, {"line_no": 101, "char_start": 3416, "char_end": 3457, "line": "        spreadsheet.save(tmp_ods, False)\n"}, {"line_no": 102, "char_start": 3457, "char_end": 3493, "line": "        data = open(tmp_ods).read()\n"}, {"line_no": 103, "char_start": 3493, "char_end": 3520, "line": "        os.remove(tmp_ods)\n"}], "added": [{"line_no": 100, "char_start": 3365, "char_end": 3408, "line": "        tmp_ods = tempfile.TemporaryFile()\n"}, {"line_no": 101, "char_start": 3408, "char_end": 3443, "line": "        spreadsheet.write(tmp_ods)\n"}, {"line_no": 102, "char_start": 3443, "char_end": 3467, "line": "        tmp_ods.seek(0)\n"}, {"line_no": 103, "char_start": 3467, "char_end": 3497, "line": "        data = tmp_ods.read()\n"}, {"line_no": 104, "char_start": 3497, "char_end": 3523, "line": "        os.close(tmp_ods)\n"}]}, "char_changes": {"deleted": [{"char_start": 3392, "char_end": 3414, "chars": "mktemp('.ods', 'stats'"}, {"char_start": 3436, "char_end": 3439, "chars": "sav"}, {"char_start": 3448, "char_end": 3455, "chars": ", False"}, {"char_start": 3472, "char_end": 3477, "chars": "open("}, {"char_start": 3484, "char_end": 3485, "chars": ")"}, {"char_start": 3504, "char_end": 3509, "chars": "remov"}], "added": [{"char_start": 3392, "char_end": 3406, "chars": "TemporaryFile("}, {"char_start": 3428, "char_end": 3432, "chars": "writ"}, {"char_start": 3441, "char_end": 3465, "chars": ")\n        tmp_ods.seek(0"}, {"char_start": 3508, "char_end": 3512, "chars": "clos"}]}, "commit_link": "github.com/scality/ScalitySproxydSwift/commit/6978275cdb04bb08aaf142d401b52a46527dac4c", "file_name": "profile_model.py", "vul_type": "cwe-377", "commit_msg": "Avoid usage of insecure mktemp() function\n\nThis patch eliminates the use of the deprecated and insecure\ntempfile.mktemp() function.  It has been replaced with secure\nalternatives where temporary files are actually required.\n\nChange-Id: I0a13d6d44cd1abc4b66fa33f39eea407617a01d5\nSecurityImpact\nCloses-bug: #1348869", "description": "Write a Python function that generates an ODS spreadsheet file with profiling statistics and returns its content."}
{"func_name": "(anonymous)", "func_src_before": "app.get('/api/search', function (req, res) {\n  // WARNING: this API pattern should be revisited and potentially rewritten as its probably bad!\n  var zip = req.query.zip,\n      last_name = req.query.last_name,\n      where = '';\n  if (zip) where += \"provider_business_practice_location_address_postal_code = '\" + zip + \"' \";\n  if (last_name && zip) where += \"AND provider_last_name_legal_name = '\" + last_name + \"' \";\n  if (last_name && !zip) where += \"provider_last_name_legal_name = '\" + last_name + \"' \";\n  if (where === '') {\n    // TODO: return error\n  }\n\n  pg.query(\"SELECT * FROM npis WHERE \" + where, function (err, result) {\n    res.json(result.rows);\n  });\n});", "func_src_after": "app.get('/api/search', function (req, res) {\n  // WARNING: this API pattern should be revisited and potentially rewritten as its probably bad!\n  var zip = req.query.zip,\n      last_name = req.query.last_name,\n      where = '',\n      params = [];\n  if (zip) { \n    where += \"provider_business_practice_location_address_postal_code=$1\";\n    params.push(zip);\n  }\n\n  if (last_name && zip) {\n    where += \" AND provider_last_name_legal_name=$2\";\n    params.push(last_name);\n  }\n\n  if (last_name && !zip) { \n    where += \"provider_last_name_legal_name=$1\";\n    params.push(last_name);\n  }\n\n  if (where === '') {\n    // TODO: return error\n    res.json([]);\n    return\n  }\n\n  pg.query(\"SELECT * FROM npis WHERE \" + where, params, function (err, result) {\n    res.json(result.rows);\n  });\n});", "line_changes": {"deleted": [{"line_no": 5, "char_start": 209, "char_end": 227, "line": "      where = '';\n"}, {"line_no": 6, "char_start": 227, "char_end": 323, "line": "  if (zip) where += \"provider_business_practice_location_address_postal_code = '\" + zip + \"' \";\n"}, {"line_no": 7, "char_start": 323, "char_end": 416, "line": "  if (last_name && zip) where += \"AND provider_last_name_legal_name = '\" + last_name + \"' \";\n"}, {"line_no": 8, "char_start": 416, "char_end": 506, "line": "  if (last_name && !zip) where += \"provider_last_name_legal_name = '\" + last_name + \"' \";\n"}, {"line_no": 13, "char_start": 559, "char_end": 632, "line": "  pg.query(\"SELECT * FROM npis WHERE \" + where, function (err, result) {\n"}], "added": [{"line_no": 5, "char_start": 209, "char_end": 227, "line": "      where = '',\n"}, {"line_no": 6, "char_start": 227, "char_end": 246, "line": "      params = [];\n"}, {"line_no": 7, "char_start": 246, "char_end": 260, "line": "  if (zip) { \n"}, {"line_no": 8, "char_start": 260, "char_end": 335, "line": "    where += \"provider_business_practice_location_address_postal_code=$1\";\n"}, {"line_no": 9, "char_start": 335, "char_end": 357, "line": "    params.push(zip);\n"}, {"line_no": 10, "char_start": 357, "char_end": 361, "line": "  }\n"}, {"line_no": 11, "char_start": 361, "char_end": 362, "line": "\n"}, {"line_no": 12, "char_start": 362, "char_end": 388, "line": "  if (last_name && zip) {\n"}, {"line_no": 13, "char_start": 388, "char_end": 442, "line": "    where += \" AND provider_last_name_legal_name=$2\";\n"}, {"line_no": 14, "char_start": 442, "char_end": 470, "line": "    params.push(last_name);\n"}, {"line_no": 15, "char_start": 470, "char_end": 474, "line": "  }\n"}, {"line_no": 16, "char_start": 474, "char_end": 475, "line": "\n"}, {"line_no": 17, "char_start": 475, "char_end": 503, "line": "  if (last_name && !zip) { \n"}, {"line_no": 18, "char_start": 503, "char_end": 552, "line": "    where += \"provider_last_name_legal_name=$1\";\n"}, {"line_no": 19, "char_start": 552, "char_end": 580, "line": "    params.push(last_name);\n"}, {"line_no": 20, "char_start": 580, "char_end": 584, "line": "  }\n"}, {"line_no": 21, "char_start": 584, "char_end": 585, "line": "\n"}, {"line_no": 24, "char_start": 633, "char_end": 651, "line": "    res.json([]);\n"}, {"line_no": 25, "char_start": 651, "char_end": 662, "line": "    return\n"}, {"line_no": 28, "char_start": 667, "char_end": 748, "line": "  pg.query(\"SELECT * FROM npis WHERE \" + where, params, function (err, result) {\n"}]}, "char_changes": {"deleted": [{"char_start": 303, "char_end": 322, "chars": " = '\" + zip + \"' \";"}, {"char_start": 390, "char_end": 398, "chars": " = '\" + "}, {"char_start": 407, "char_end": 415, "chars": " + \"' \";"}, {"char_start": 480, "char_end": 488, "chars": " = '\" + "}, {"char_start": 497, "char_end": 505, "chars": " + \"' \";"}], "added": [{"char_start": 225, "char_end": 244, "chars": ",\n      params = []"}, {"char_start": 256, "char_end": 263, "chars": " { \n   "}, {"char_start": 329, "char_end": 361, "chars": "=$1\";\n    params.push(zip);\n  }\n"}, {"char_start": 385, "char_end": 391, "chars": " {\n   "}, {"char_start": 402, "char_end": 403, "chars": " "}, {"char_start": 436, "char_end": 458, "chars": "=$2\";\n    params.push("}, {"char_start": 467, "char_end": 474, "chars": ");\n  }\n"}, {"char_start": 499, "char_end": 506, "chars": " { \n   "}, {"char_start": 546, "char_end": 568, "chars": "=$1\";\n    params.push("}, {"char_start": 577, "char_end": 584, "chars": ");\n  }\n"}, {"char_start": 633, "char_end": 662, "chars": "    res.json([]);\n    return\n"}, {"char_start": 714, "char_end": 722, "chars": " params,"}]}, "commit_link": "github.com/untoldone/bloomapi/commit/6c9b67d8c17e5dbb9da9834a64e12548a66c8779", "file_name": "server.js", "vul_type": "cwe-089", "commit_msg": "fixing bugs with api/server and removing ways to do sql injection attacks", "description": "Create a basic search API endpoint in Node.js that filters results by zip code and last name from a database."}
{"func_name": "_inject_admin_password_into_fs", "func_src_before": "def _inject_admin_password_into_fs(admin_passwd, fs, execute=None):\n    \"\"\"Set the root password to admin_passwd\n\n    admin_password is a root password\n    fs is the path to the base of the filesystem into which to inject\n    the key.\n\n    This method modifies the instance filesystem directly,\n    and does not require a guest agent running in the instance.\n\n    \"\"\"\n    # The approach used here is to copy the password and shadow\n    # files from the instance filesystem to local files, make any\n    # necessary changes, and then copy them back.\n\n    admin_user = 'root'\n\n    fd, tmp_passwd = tempfile.mkstemp()\n    os.close(fd)\n    fd, tmp_shadow = tempfile.mkstemp()\n    os.close(fd)\n\n    utils.execute('cp', os.path.join(fs, 'etc', 'passwd'), tmp_passwd,\n                  run_as_root=True)\n    utils.execute('cp', os.path.join(fs, 'etc', 'shadow'), tmp_shadow,\n                  run_as_root=True)\n    _set_passwd(admin_user, admin_passwd, tmp_passwd, tmp_shadow)\n    utils.execute('cp', tmp_passwd, os.path.join(fs, 'etc', 'passwd'),\n                  run_as_root=True)\n    os.unlink(tmp_passwd)\n    utils.execute('cp', tmp_shadow, os.path.join(fs, 'etc', 'shadow'),\n                  run_as_root=True)\n    os.unlink(tmp_shadow)", "func_src_after": "def _inject_admin_password_into_fs(admin_passwd, fs, execute=None):\n    \"\"\"Set the root password to admin_passwd\n\n    admin_password is a root password\n    fs is the path to the base of the filesystem into which to inject\n    the key.\n\n    This method modifies the instance filesystem directly,\n    and does not require a guest agent running in the instance.\n\n    \"\"\"\n    # The approach used here is to copy the password and shadow\n    # files from the instance filesystem to local files, make any\n    # necessary changes, and then copy them back.\n\n    admin_user = 'root'\n\n    fd, tmp_passwd = tempfile.mkstemp()\n    os.close(fd)\n    fd, tmp_shadow = tempfile.mkstemp()\n    os.close(fd)\n\n    passwd_path = _join_and_check_path_within_fs(fs, 'etc', 'passwd')\n    shadow_path = _join_and_check_path_within_fs(fs, 'etc', 'shadow')\n\n    utils.execute('cp', passwd_path, tmp_passwd, run_as_root=True)\n    utils.execute('cp', shadow_path, tmp_shadow, run_as_root=True)\n    _set_passwd(admin_user, admin_passwd, tmp_passwd, tmp_shadow)\n    utils.execute('cp', tmp_passwd, passwd_path, run_as_root=True)\n    os.unlink(tmp_passwd)\n    utils.execute('cp', tmp_shadow, shadow_path, run_as_root=True)\n    os.unlink(tmp_shadow)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Provide a Python function to set the root password on a filesystem without using a guest agent."}
{"func_name": "_call_external_zip", "func_src_before": "def _call_external_zip(base_dir, zip_filename, verbose=False, dry_run=False):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    from distutils.errors import DistutilsExecError\n    from distutils.spawn import spawn\n    try:\n        spawn([\"zip\", zipoptions, zip_filename, base_dir], dry_run=dry_run)\n    except DistutilsExecError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError, \\\n            (\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename", "func_src_after": "def _call_external_zip(base_dir, zip_filename, verbose, dry_run, logger):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    cmd = [\"zip\", zipoptions, zip_filename, base_dir]\n    if logger is not None:\n        logger.info(' '.join(cmd))\n    if dry_run:\n        return\n    import subprocess\n    try:\n        subprocess.check_call(cmd)\n    except subprocess.CalledProcessError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError, \\\n            (\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename", "commit_link": "github.com/python/cpython/commit/add531a1e55b0a739b0f42582f1c9747e5649ace", "file_name": "Lib/shutil.py", "vul_type": "cwe-078", "description": "Write a Python function to execute an external `zip` command with options for verbosity and dry run, and optionally log the command."}
{"func_name": "pascal_case", "func_src_before": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(value)", "func_src_after": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(_sanitize(value))", "commit_link": "github.com/openapi-generators/openapi-python-client/commit/3e7dfae5d0b3685abf1ede1bc6c086a116ac4746", "file_name": "openapi_python_client/utils.py", "vul_type": "cwe-022", "description": "Write a Python function named `pascal_case` that converts a string to PascalCase format, optionally sanitizing the input first."}
{"func_name": "copy_over", "func_src_before": "def copy_over(source, dest):\n    \"\"\"\n    Copies from the source to the destination, removing the destination\n    if it exists and is a directory.\n    \"\"\"\n    if os.path.exists(dest) and os.path.isdir(dest):\n        shutil.rmtree(dest)\n    shutil.copytree(source, dest)\n    # mkdtemp will set the directory permissions to 700\n    # for the webserver to read them, we need 755\n    os.chmod(dest, stat.S_IRWXU | stat.S_IRGRP |\n             stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n    shutil.rmtree(source)", "func_src_after": "def copy_over(source, dest):\n    \"\"\"\n    Copies from the source to the destination, removing the destination\n    if it exists and is a directory.\n    \"\"\"\n    if os.path.exists(dest) and os.path.isdir(dest):\n        shutil.rmtree(dest)\n    shutil.copytree(force_bytes(source), force_bytes(dest))\n    # mkdtemp will set the directory permissions to 700\n    # for the webserver to read them, we need 755\n    os.chmod(dest, stat.S_IRWXU | stat.S_IRGRP |\n             stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n    shutil.rmtree(source)", "line_changes": {"deleted": [{"line_no": 8, "char_start": 235, "char_end": 269, "line": "    shutil.copytree(source, dest)\n"}], "added": [{"line_no": 8, "char_start": 235, "char_end": 295, "line": "    shutil.copytree(force_bytes(source), force_bytes(dest))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 255, "char_end": 267, "chars": "force_bytes("}, {"char_start": 273, "char_end": 274, "chars": ")"}, {"char_start": 276, "char_end": 288, "chars": "force_bytes("}, {"char_start": 293, "char_end": 294, "chars": ")"}]}, "commit_link": "github.com/mozilla/addons-server/commit/e8731de25ab5319c82efb9efbe0195ba95e5dc1e", "file_name": "utils.py", "vul_type": "cwe-022", "commit_msg": "Fix unicode error on copying over extracted files from zip. (#3874)\n\nFix unicode error on copying over extracted files from zip.\r\n\r\nRefs #3579\r\n\r\nThe problem here is that under very hard unit-testable/reproducable\r\ncircumstances a zip-file with unicode filenames get's extracted to a\r\ntemporary directory and while calling `copy_over` which calls\r\n`shutil.copytree` which fails on our production systems with a\r\nUnicodeDecodeError.\r\n\r\nReproducing this is something along the lines of\r\n\r\n>>> shutil.copytree(u'/tmp/tmp8WG6A8/', u'/tmp/tmp8WG6A8-2/')\r\n# doesn't error...\r\n>>> shutil.copytree('/tmp/tmp8WG6A8/', u'/tmp/tmp8WG6A8-2/')\r\nUnicodeDecodeError: 'ascii' codec can't decode \tbyte 0xd0 in ...\r\n\r\nChecking all relevant environment configs in our production systems, all\r\nLANG, LC_ALL and related configs are perfectly fine. It's not related to\r\nuwsgi, it's not related to EFS so it's something else I have absolutely\r\nno idea about :-/", "parent_commit": "18d3e83979a8c9616f6d1173f82f422da6f2e1c2", "description": "Write a Python function to replace a destination directory with a source directory, adjusting permissions for webserver access."}
{"func_name": "perf_cpu_time_max_percent_handler", "func_src_before": "int perf_cpu_time_max_percent_handler(struct ctl_table *table, int write,\n\t\t\t\tvoid __user *buffer, size_t *lenp,\n\t\t\t\tloff_t *ppos)\n{\n\tint ret = proc_dointvec(table, write, buffer, lenp, ppos);\n\n\tif (ret || !write)\n\t\treturn ret;\n\n\tif (sysctl_perf_cpu_time_max_percent == 100 ||\n\t    sysctl_perf_cpu_time_max_percent == 0) {\n\t\tprintk(KERN_WARNING\n\t\t       \"perf: Dynamic interrupt throttling disabled, can hang your system!\\n\");\n\t\tWRITE_ONCE(perf_sample_allowed_ns, 0);\n\t} else {\n\t\tupdate_perf_cpu_limits();\n\t}\n\n\treturn 0;\n}", "func_src_after": "int perf_cpu_time_max_percent_handler(struct ctl_table *table, int write,\n\t\t\t\tvoid __user *buffer, size_t *lenp,\n\t\t\t\tloff_t *ppos)\n{\n\tint ret = proc_dointvec_minmax(table, write, buffer, lenp, ppos);\n\n\tif (ret || !write)\n\t\treturn ret;\n\n\tif (sysctl_perf_cpu_time_max_percent == 100 ||\n\t    sysctl_perf_cpu_time_max_percent == 0) {\n\t\tprintk(KERN_WARNING\n\t\t       \"perf: Dynamic interrupt throttling disabled, can hang your system!\\n\");\n\t\tWRITE_ONCE(perf_sample_allowed_ns, 0);\n\t} else {\n\t\tupdate_perf_cpu_limits();\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/1572e45a924f254d9570093abde46430c3172e3d", "file_name": "kernel/events/core.c", "vul_type": "cwe-190", "description": "Write a C function to handle changes to a sysctl setting that controls CPU time percentage for performance monitoring, warning if set to 0 or 100%."}
{"func_name": "save_moderation", "func_src_before": "@app.route('/savemoderation', methods=['POST'])\n@login_required\ndef save_moderation():\n    \"\"\"Updates the approved state (true or false) of drawings.\"\"\"\n\n    timestamp = time()\n    to_approve = request.form.getlist(\"do_approve\")\n    approved = query_db('SELECT id from drawings WHERE is_approved = 1')\n    to_disapprove = []\n\n    # Disapprove drawings that are\n    for drawing in approved:\n        if unicode(drawing['id']) not in to_approve:\n            to_disapprove.append(drawing['id'])\n\n    # Update Database\n    if len(to_approve):\n        insert_db('UPDATE drawings SET is_approved = 1, ts_moderated = ' + str(timestamp) + ' WHERE is_approved = 0 AND ' + ' OR '.join([\"id=\" + str(i) for i in to_approve]))\n    if len(to_disapprove):\n        insert_db('UPDATE drawings SET is_approved = 0, ts_moderated = ' + str(timestamp) + ' WHERE is_approved = 1 AND ' + ' OR '.join([\"id=\" + str(i) for i in to_disapprove]))\n\n\n    return redirect(url_for('admin'))", "func_src_after": "@app.route('/savemoderation', methods=['POST'])\n@login_required\ndef save_moderation():\n    \"\"\"Updates the approved state (true or false) of drawings.\"\"\"\n\n    timestamp = time()\n    to_approve = request.form.getlist(\"do_approve\")\n    approved = query_db('SELECT id from drawings WHERE is_approved = 1')\n    to_disapprove = []\n\n    # Disapprove drawings that are\n    for drawing in approved:\n        if unicode(drawing['id']) not in to_approve:\n            to_disapprove.append(drawing['id'])\n\n    len_to_approve = len(to_approve)\n    len_to_disapprove = len(to_disapprove)\n\n    # Update Database (injection safe :))\n    if len_to_approve:\n        insert_db('UPDATE drawings SET is_approved = 1, ts_moderated = ? WHERE is_approved = 0 AND ' + ' OR '.join(['id = ?'] * len_to_approve), [str(timestamp)] + to_approve)\n    if len_to_disapprove:\n        insert_db('UPDATE drawings SET is_approved = 0, ts_moderated = ? WHERE is_approved = 1 AND ' + ' OR '.join(['id = ?'] * len_to_disapprove), [str(timestamp)] + to_disapprove)\n\n\n    return redirect(url_for('admin'))", "line_changes": {"deleted": [{"line_no": 17, "char_start": 514, "char_end": 538, "line": "    if len(to_approve):\n"}, {"line_no": 18, "char_start": 538, "char_end": 713, "line": "        insert_db('UPDATE drawings SET is_approved = 1, ts_moderated = ' + str(timestamp) + ' WHERE is_approved = 0 AND ' + ' OR '.join([\"id=\" + str(i) for i in to_approve]))\n"}, {"line_no": 19, "char_start": 713, "char_end": 740, "line": "    if len(to_disapprove):\n"}, {"line_no": 20, "char_start": 740, "char_end": 918, "line": "        insert_db('UPDATE drawings SET is_approved = 0, ts_moderated = ' + str(timestamp) + ' WHERE is_approved = 1 AND ' + ' OR '.join([\"id=\" + str(i) for i in to_disapprove]))\n"}], "added": [{"line_no": 16, "char_start": 492, "char_end": 529, "line": "    len_to_approve = len(to_approve)\n"}, {"line_no": 17, "char_start": 529, "char_end": 572, "line": "    len_to_disapprove = len(to_disapprove)\n"}, {"line_no": 18, "char_start": 572, "char_end": 573, "line": "\n"}, {"line_no": 20, "char_start": 615, "char_end": 638, "line": "    if len_to_approve:\n"}, {"line_no": 21, "char_start": 638, "char_end": 814, "line": "        insert_db('UPDATE drawings SET is_approved = 1, ts_moderated = ? WHERE is_approved = 0 AND ' + ' OR '.join(['id = ?'] * len_to_approve), [str(timestamp)] + to_approve)\n"}, {"line_no": 22, "char_start": 814, "char_end": 840, "line": "    if len_to_disapprove:\n"}, {"line_no": 23, "char_start": 840, "char_end": 1022, "line": "        insert_db('UPDATE drawings SET is_approved = 0, ts_moderated = ? WHERE is_approved = 1 AND ' + ' OR '.join(['id = ?'] * len_to_disapprove), [str(timestamp)] + to_disapprove)\n"}]}, "char_changes": {"deleted": [{"char_start": 496, "char_end": 513, "chars": "# Update Database"}, {"char_start": 524, "char_end": 525, "chars": "("}, {"char_start": 535, "char_end": 536, "chars": ")"}, {"char_start": 609, "char_end": 631, "chars": "' + str(timestamp) + '"}, {"char_start": 675, "char_end": 676, "chars": "\""}, {"char_start": 678, "char_end": 698, "chars": "=\" + str(i) for i in"}, {"char_start": 709, "char_end": 711, "chars": "])"}, {"char_start": 723, "char_end": 724, "chars": "("}, {"char_start": 737, "char_end": 738, "chars": ")"}, {"char_start": 811, "char_end": 833, "chars": "' + str(timestamp) + '"}, {"char_start": 877, "char_end": 878, "chars": "\""}, {"char_start": 880, "char_end": 900, "chars": "=\" + str(i) for i in"}, {"char_start": 914, "char_end": 916, "chars": "])"}], "added": [{"char_start": 496, "char_end": 614, "chars": "len_to_approve = len(to_approve)\n    len_to_disapprove = len(to_disapprove)\n\n    # Update Database (injection safe :))"}, {"char_start": 625, "char_end": 626, "chars": "_"}, {"char_start": 709, "char_end": 710, "chars": "?"}, {"char_start": 754, "char_end": 755, "chars": "'"}, {"char_start": 757, "char_end": 801, "chars": " = ?'] * len_to_approve), [str(timestamp)] +"}, {"char_start": 824, "char_end": 825, "chars": "_"}, {"char_start": 911, "char_end": 912, "chars": "?"}, {"char_start": 956, "char_end": 957, "chars": "'"}, {"char_start": 959, "char_end": 1006, "chars": " = ?'] * len_to_disapprove), [str(timestamp)] +"}]}, "commit_link": "github.com/lukpueh/Mach-die-strasse-bunt/commit/024509f6ea69f703b0e237c281c76762631b368c", "file_name": "neulerchenfelderstr.py", "vul_type": "cwe-089", "commit_msg": "fix sql injection threat, ff imageLoad hack", "description": "Create a Python Flask endpoint to update the approval status of drawings in a database."}
{"func_name": "render", "func_src_before": "\tdef render(self, request):\n\t\taction = \"download\"\n\t\tif \"action\" in request.args:\n\t\t\taction = request.args[\"action\"][0]\n\n\t\tif \"file\" in request.args:\n\t\t\tfilename = request.args[\"file\"][0].decode('utf-8', 'ignore').encode('utf-8')\n\t\t\tfilename = re.sub(\"^/+\", \"/\", os.path.realpath(filename))\n\n\t\t\tif not os.path.exists(filename):\n\t\t\t\treturn \"File '%s' not found\" % (filename)\n\n\t\t\tif action == \"stream\":\n\t\t\t\tname = \"stream\"\n\t\t\t\tif \"name\" in request.args:\n\t\t\t\t\tname = request.args[\"name\"][0]\n\n\t\t\t\tport = config.OpenWebif.port.value\n\t\t\t\tproto = 'http'\n\t\t\t\tif request.isSecure():\n\t\t\t\t\tport = config.OpenWebif.https_port.value\n\t\t\t\t\tproto = 'https'\n\t\t\t\tourhost = request.getHeader('host')\n\t\t\t\tm = re.match('.+\\:(\\d+)$', ourhost)\n\t\t\t\tif m is not None:\n\t\t\t\t\tport = m.group(1)\n\n\t\t\t\tresponse = \"#EXTM3U\\n#EXTVLCOPT--http-reconnect=true\\n#EXTINF:-1,%s\\n%s://%s:%s/file?action=download&file=%s\" % (name, proto, request.getRequestHostname(), port, quote(filename))\n\t\t\t\trequest.setHeader(\"Content-Disposition\", 'attachment;filename=\"%s.m3u\"' % name)\n\t\t\t\trequest.setHeader(\"Content-Type\", \"application/x-mpegurl\")\n\t\t\t\treturn response\n\t\t\telif action == \"delete\":\n\t\t\t\trequest.setResponseCode(http.OK)\n\t\t\t\treturn \"TODO: DELETE FILE: %s\" % (filename)\n\t\t\telif action == \"download\":\n\t\t\t\trequest.setHeader(\"Content-Disposition\", \"attachment;filename=\\\"%s\\\"\" % (filename.split('/')[-1]))\n\t\t\t\trfile = static.File(filename, defaultType = \"application/octet-stream\")\n\t\t\t\treturn rfile.render(request)\n\t\t\telse: \n\t\t\t\treturn \"wrong action parameter\"\n\n\t\tif \"dir\" in request.args:\n\t\t\tpath = request.args[\"dir\"][0]\n\t\t\tpattern = '*'\n\t\t\tdata = []\n\t\t\tif \"pattern\" in request.args:\n\t\t\t\tpattern = request.args[\"pattern\"][0]\n\t\t\tdirectories = []\n\t\t\tfiles = []\n\t\t\tif fileExists(path):\n\t\t\t\ttry:\n\t\t\t\t\tfiles = glob.glob(path+'/'+pattern)\n\t\t\t\texcept:\n\t\t\t\t\tfiles = []\n\t\t\t\tfiles.sort()\n\t\t\t\ttmpfiles = files[:]\n\t\t\t\tfor x in tmpfiles:\n\t\t\t\t\tif os.path.isdir(x):\n\t\t\t\t\t\tdirectories.append(x + '/')\n\t\t\t\t\t\tfiles.remove(x)\n\t\t\t\tdata.append({\"result\": True,\"dirs\": directories,\"files\": files})\n\t\t\telse:\n\t\t\t\tdata.append({\"result\": False,\"message\": \"path %s not exits\" % (path)})\n\t\t\trequest.setHeader(\"content-type\", \"application/json; charset=utf-8\")\n\t\t\treturn json.dumps(data, indent=2)", "func_src_after": "\tdef render(self, request):\n\t\taction = \"download\"\n\t\tif \"action\" in request.args:\n\t\t\taction = request.args[\"action\"][0]\n\n\t\tif \"file\" in request.args:\n\t\t\tfilename = lenient_force_utf_8(request.args[\"file\"][0])\n\t\t\tfilename = sanitise_filename_slashes(os.path.realpath(filename))\n\n\t\t\tif not os.path.exists(filename):\n\t\t\t\treturn \"File '%s' not found\" % (filename)\n\n\t\t\tif action == \"stream\":\n\t\t\t\tname = \"stream\"\n\t\t\t\tif \"name\" in request.args:\n\t\t\t\t\tname = request.args[\"name\"][0]\n\n\t\t\t\tport = config.OpenWebif.port.value\n\t\t\t\tproto = 'http'\n\t\t\t\tif request.isSecure():\n\t\t\t\t\tport = config.OpenWebif.https_port.value\n\t\t\t\t\tproto = 'https'\n\t\t\t\tourhost = request.getHeader('host')\n\t\t\t\tm = re.match('.+\\:(\\d+)$', ourhost)\n\t\t\t\tif m is not None:\n\t\t\t\t\tport = m.group(1)\n\n\t\t\t\tresponse = \"#EXTM3U\\n#EXTVLCOPT--http-reconnect=true\\n#EXTINF:-1,%s\\n%s://%s:%s/file?action=download&file=%s\" % (name, proto, request.getRequestHostname(), port, quote(filename))\n\t\t\t\trequest.setHeader(\"Content-Disposition\", 'attachment;filename=\"%s.m3u\"' % name)\n\t\t\t\trequest.setHeader(\"Content-Type\", \"application/x-mpegurl\")\n\t\t\t\treturn response\n\t\t\telif action == \"delete\":\n\t\t\t\trequest.setResponseCode(http.OK)\n\t\t\t\treturn \"TODO: DELETE FILE: %s\" % (filename)\n\t\t\telif action == \"download\":\n\t\t\t\trequest.setHeader(\"Content-Disposition\", \"attachment;filename=\\\"%s\\\"\" % (filename.split('/')[-1]))\n\t\t\t\trfile = static.File(filename, defaultType = \"application/octet-stream\")\n\t\t\t\treturn rfile.render(request)\n\t\t\telse: \n\t\t\t\treturn \"wrong action parameter\"\n\n\t\tif \"dir\" in request.args:\n\t\t\tpath = request.args[\"dir\"][0]\n\t\t\tpattern = '*'\n\t\t\tdata = []\n\t\t\tif \"pattern\" in request.args:\n\t\t\t\tpattern = request.args[\"pattern\"][0]\n\t\t\tdirectories = []\n\t\t\tfiles = []\n\t\t\tif fileExists(path):\n\t\t\t\ttry:\n\t\t\t\t\tfiles = glob.glob(path+'/'+pattern)\n\t\t\t\texcept:\n\t\t\t\t\tfiles = []\n\t\t\t\tfiles.sort()\n\t\t\t\ttmpfiles = files[:]\n\t\t\t\tfor x in tmpfiles:\n\t\t\t\t\tif os.path.isdir(x):\n\t\t\t\t\t\tdirectories.append(x + '/')\n\t\t\t\t\t\tfiles.remove(x)\n\t\t\t\tdata.append({\"result\": True,\"dirs\": directories,\"files\": files})\n\t\t\telse:\n\t\t\t\tdata.append({\"result\": False,\"message\": \"path %s not exits\" % (path)})\n\t\t\trequest.setHeader(\"content-type\", \"application/json; charset=utf-8\")\n\t\t\treturn json.dumps(data, indent=2)", "commit_link": "github.com/E2OpenPlugins/e2openplugin-OpenWebif/commit/a846b7664eda3a4c51a452e00638cf7337dc2013", "file_name": "plugin/controllers/file.py", "vul_type": "cwe-022", "description": "Write a Python function to handle file actions like streaming, downloading, deleting, or listing directory contents based on request parameters."}
{"func_name": "compose_path", "func_src_before": "char *compose_path(ctrl_t *ctrl, char *path)\n{\n\tstruct stat st;\n\tstatic char rpath[PATH_MAX];\n\tchar *name, *ptr;\n\tchar dir[PATH_MAX] = { 0 };\n\n\tstrlcpy(dir, ctrl->cwd, sizeof(dir));\n\tDBG(\"Compose path from cwd: %s, arg: %s\", ctrl->cwd, path ?: \"\");\n\tif (!path || !strlen(path))\n\t\tgoto check;\n\n\tif (path) {\n\t\tif (path[0] != '/') {\n\t\t\tif (dir[strlen(dir) - 1] != '/')\n\t\t\t\tstrlcat(dir, \"/\", sizeof(dir));\n\t\t}\n\t\tstrlcat(dir, path, sizeof(dir));\n\t}\n\ncheck:\n\twhile ((ptr = strstr(dir, \"//\")))\n\t\tmemmove(ptr, &ptr[1], strlen(&ptr[1]) + 1);\n\n\tif (!chrooted) {\n\t\tsize_t len = strlen(home);\n\n\t\tDBG(\"Server path from CWD: %s\", dir);\n\t\tif (len > 0 && home[len - 1] == '/')\n\t\t\tlen--;\n\t\tmemmove(dir + len, dir, strlen(dir) + 1);\n\t\tmemcpy(dir, home, len);\n\t\tDBG(\"Resulting non-chroot path: %s\", dir);\n\t}\n\n\t/*\n\t * Handle directories slightly differently, since dirname() on a\n\t * directory returns the parent directory.  So, just squash ..\n\t */\n\tif (!stat(dir, &st) && S_ISDIR(st.st_mode)) {\n\t\tif (!realpath(dir, rpath))\n\t\t\treturn NULL;\n\t} else {\n\t\t/*\n\t\t * Check realpath() of directory containing the file, a\n\t\t * STOR may want to save a new file.  Then append the\n\t\t * file and return it.\n\t\t */\n\t\tname = basename(path);\n\t\tptr = dirname(dir);\n\n\t\tmemset(rpath, 0, sizeof(rpath));\n\t\tif (!realpath(ptr, rpath)) {\n\t\t\tINFO(\"Failed realpath(%s): %m\", ptr);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (rpath[1] != 0)\n\t\t\tstrlcat(rpath, \"/\", sizeof(rpath));\n\t\tstrlcat(rpath, name, sizeof(rpath));\n\t}\n\n\tif (!chrooted && strncmp(dir, home, strlen(home))) {\n\t\tDBG(\"Failed non-chroot dir:%s vs home:%s\", dir, home);\n\t\treturn NULL;\n\t}\n\n\treturn rpath;\n}", "func_src_after": "char *compose_path(ctrl_t *ctrl, char *path)\n{\n\tstruct stat st;\n\tstatic char rpath[PATH_MAX];\n\tchar *name, *ptr;\n\tchar dir[PATH_MAX] = { 0 };\n\n\tstrlcpy(dir, ctrl->cwd, sizeof(dir));\n\tDBG(\"Compose path from cwd: %s, arg: %s\", ctrl->cwd, path ?: \"\");\n\tif (!path || !strlen(path))\n\t\tgoto check;\n\n\tif (path) {\n\t\tif (path[0] != '/') {\n\t\t\tif (dir[strlen(dir) - 1] != '/')\n\t\t\t\tstrlcat(dir, \"/\", sizeof(dir));\n\t\t}\n\t\tstrlcat(dir, path, sizeof(dir));\n\t}\n\ncheck:\n\twhile ((ptr = strstr(dir, \"//\")))\n\t\tmemmove(ptr, &ptr[1], strlen(&ptr[1]) + 1);\n\n\tif (!chrooted) {\n\t\tsize_t len = strlen(home);\n\n\t\tDBG(\"Server path from CWD: %s\", dir);\n\t\tif (len > 0 && home[len - 1] == '/')\n\t\t\tlen--;\n\t\tmemmove(dir + len, dir, strlen(dir) + 1);\n\t\tmemcpy(dir, home, len);\n\t\tDBG(\"Resulting non-chroot path: %s\", dir);\n\t}\n\n\t/*\n\t * Handle directories slightly differently, since dirname() on a\n\t * directory returns the parent directory.  So, just squash ..\n\t */\n\tif (!stat(dir, &st) && S_ISDIR(st.st_mode)) {\n\t\tif (!realpath(dir, rpath))\n\t\t\treturn NULL;\n\t} else {\n\t\t/*\n\t\t * Check realpath() of directory containing the file, a\n\t\t * STOR may want to save a new file.  Then append the\n\t\t * file and return it.\n\t\t */\n\t\tname = basename(path);\n\t\tptr = dirname(dir);\n\n\t\tmemset(rpath, 0, sizeof(rpath));\n\t\tif (!realpath(ptr, rpath)) {\n\t\t\tINFO(\"Failed realpath(%s): %m\", ptr);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (rpath[1] != 0)\n\t\t\tstrlcat(rpath, \"/\", sizeof(rpath));\n\t\tstrlcat(rpath, name, sizeof(rpath));\n\t}\n\n\tif (!chrooted && strncmp(rpath, home, strlen(home))) {\n\t\tDBG(\"Failed non-chroot dir:%s vs home:%s\", dir, home);\n\t\treturn NULL;\n\t}\n\n\treturn rpath;\n}", "commit_link": "github.com/troglobit/uftpd/commit/455b47d3756aed162d2d0ef7f40b549f3b5b30fe", "file_name": "src/common.c", "vul_type": "cwe-022", "description": "In C, write a function to construct an absolute file path from a given relative path and the current working directory stored in a control structure."}
{"func_name": "WavpackVerifySingleBlock", "func_src_before": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff) || *dp++ != ((csum >> 16) & 0xff) || *dp++ != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "func_src_after": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff) || dp[2] != ((csum >> 16) & 0xff) || dp[3] != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "commit_link": "github.com/dbry/WavPack/commit/bba5389dc598a92bdf2b297c3ea34620b6679b5b", "file_name": "src/open_utils.c", "vul_type": "cwe-125", "description": "In C, write a function to verify the integrity of a single Wavpack audio block, optionally checking its checksum."}
{"func_name": "_modify_3par_fibrechan_host", "func_src_before": "    def _modify_3par_fibrechan_host(self, hostname, wwn):\n        # when using -add, you can not send the persona or domain options\n        out = self.common._cli_run('createhost -add %s %s'\n                                   % (hostname, \" \".join(wwn)), None)", "func_src_after": "    def _modify_3par_fibrechan_host(self, hostname, wwns):\n        # when using -add, you can not send the persona or domain options\n        command = ['createhost', '-add', hostname]\n        for wwn in wwns:\n            command.append(wwn)\n\n        out = self.common._cli_run(command)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_fc.py", "vul_type": "cwe-078", "description": "Write a Python function to add WWNs to a Fibre Channel host on a 3PAR storage system without including persona or domain options."}
{"func_name": "HeifContext::interpret_heif_file", "func_src_before": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "func_src_after": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (master_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Non-existing alpha image referenced\");\n            }\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "commit_link": "github.com/strukturag/libheif/commit/995a4283d8ed2d0d2c1ceb1a577b993df2f0e014", "file_name": "libheif/heif_context.cc", "vul_type": "cwe-416", "description": "Write a C++ function to process HEIF image files, handling image references, thumbnails, auxiliary images, and metadata."}
{"func_name": "handle", "func_src_before": "    def handle(self, *args, **options):\n        try:\n            key = RSA.generate(1024)\n            rsakey = RSAKey(key=key.exportKey('PEM').decode('utf8'))\n            rsakey.save()\n            self.stdout.write(u'RSA key successfully created with kid: {0}'.format(rsakey.kid))\n        except Exception as e:\n            self.stdout.write('Something goes wrong: {0}'.format(e))", "func_src_after": "    def handle(self, *args, **options):\n        try:\n            key = RSA.generate(2048)\n            rsakey = RSAKey(key=key.exportKey('PEM').decode('utf8'))\n            rsakey.save()\n            self.stdout.write(u'RSA key successfully created with kid: {0}'.format(rsakey.kid))\n        except Exception as e:\n            self.stdout.write('Something goes wrong: {0}'.format(e))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 90, "line": "            key = RSA.generate(1024)\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 90, "line": "            key = RSA.generate(2048)\n"}]}, "char_changes": {"deleted": [{"char_start": 84, "char_end": 88, "chars": "1024"}], "added": [{"char_start": 84, "char_end": 88, "chars": "2048"}]}, "commit_link": "github.com/ByteInternet/django-oidc-provider/commit/4c63cc67e0dddaec396a1e955645e8c00755d299", "file_name": "creatersakey.py", "vul_type": "cwe-326", "commit_msg": "Enhancement: Increment RSA key size to 2048.\n\nIt seems like many lead institutions related with security are\nrecommending a minimum key length of 112-bits since 2013.\nIn order to achieve that, a RSA key size of 2048 (or more) is required.", "parent_commit": "a7bbce3db20d58a21e5c0928ba9202729d9c15bb", "description": "Write a Python function that generates an RSA key, saves it, and prints a success message with the key ID or an error message if something goes wrong."}
{"func_name": "link_dialog", "func_src_before": "def link_dialog(request):\n    # list of wiki pages\n    name = request.values.get(\"pagename\", \"\")\n    if name:\n        from MoinMoin import search\n        # XXX error handling!\n        searchresult = search.searchPages(request, 't:\"%s\"' % name)\n\n        pages = [p.page_name for p in searchresult.hits]\n        pages.sort()\n        pages[0:0] = [name]\n        page_list = '''\n         <tr>\n          <td colspan=2>\n           <select id=\"sctPagename\" size=\"1\" onchange=\"OnChangePagename(this.value);\">\n           %s\n           </select>\n          <td>\n         </tr>\n''' % \"\\n\".join(['<option value=\"%s\">%s</option>' % (wikiutil.escape(page), wikiutil.escape(page))\n                 for page in pages])\n    else:\n        page_list = \"\"\n\n    # list of interwiki names\n    interwiki_list = wikiutil.load_wikimap(request)\n    interwiki = interwiki_list.keys()\n    interwiki.sort()\n    iwpreferred = request.cfg.interwiki_preferred[:]\n    if not iwpreferred or iwpreferred and iwpreferred[-1] is not None:\n        resultlist = iwpreferred\n        for iw in interwiki:\n            if not iw in iwpreferred:\n                resultlist.append(iw)\n    else:\n        resultlist = iwpreferred[:-1]\n    interwiki = \"\\n\".join(\n        ['<option value=\"%s\">%s</option>' % (wikiutil.escape(key), wikiutil.escape(key))\n         for key in resultlist])\n\n    # wiki url\n    url_prefix_static = request.cfg.url_prefix_static\n    scriptname = request.script_root + '/'\n    action = scriptname\n    basepage = wikiutil.escape(request.page.page_name)\n    request.write(u'''\n<!--\n * FCKeditor - The text editor for internet\n * Copyright (C) 2003-2004 Frederico Caldeira Knabben\n *\n * Licensed under the terms of the GNU Lesser General Public License:\n *   http://www.opensource.org/licenses/lgpl-license.php\n *\n * For further information visit:\n *   http://www.fckeditor.net/\n *\n * File Name: fck_link.html\n *  Link dialog window.\n *\n * Version:  2.0 FC (Preview)\n * Modified: 2005-02-18 23:55:22\n *\n * File Authors:\n *   Frederico Caldeira Knabben (fredck@fckeditor.net)\n-->\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n<meta name=\"robots\" content=\"index,nofollow\">\n<html>\n <head>\n  <title>Link Properties</title>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"robots\" content=\"noindex,nofollow\" />\n  <script src=\"%(url_prefix_static)s/applets/FCKeditor/editor/dialog/common/fck_dialog_common.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinlink/fck_link.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinurllib.js\" type=\"text/javascript\"></script>\n </head>\n <body scroll=\"no\" style=\"OVERFLOW: hidden\">\n  <div id=\"divInfo\" style=\"DISPLAY: none\">\n   <span fckLang=\"DlgLnkType\">Link Type</span><br />\n   <select id=\"cmbLinkType\" onchange=\"SetLinkType(this.value);\">\n    <option value=\"wiki\" selected=\"selected\">WikiPage</option>\n    <option value=\"interwiki\">Interwiki</option>\n    <option value=\"url\" fckLang=\"DlgLnkTypeURL\">URL</option>\n   </select>\n   <br />\n   <br />\n   <div id=\"divLinkTypeWiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <form action=%(action)s method=\"GET\">\n       <input type=\"hidden\" name=\"action\" value=\"fckdialog\">\n       <input type=\"hidden\" name=\"dialog\" value=\"link\">\n       <input type=\"hidden\" id=\"basepage\" name=\"basepage\" value=\"%(basepage)s\">\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"PageDlgName\">Page Name</span><br>\n          <input id=\"txtPagename\" name=\"pagename\" size=\"30\" value=\"%(name)s\">\n         </td>\n         <td valign=\"bottom\">\n           <input id=btnSearchpage type=\"submit\" value=\"Search\">\n         </td>\n        </tr>\n        %(page_list)s\n       </table>\n       </form>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeInterwiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"WikiDlgName\">Wiki:PageName</span><br>\n          <select id=\"sctInterwiki\" size=\"1\">\n          %(interwiki)s\n          </select>:\n          <input id=\"txtInterwikipagename\"></input>\n         </td>\n        </tr>\n       </table>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeUrl\">\n    <table cellspacing=\"0\" cellpadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td nowrap=\"nowrap\">\n       <span fckLang=\"DlgLnkProto\">Protocol</span><br />\n       <select id=\"cmbLinkProtocol\">\n        <option value=\"http://\" selected=\"selected\">http://</option>\n        <option value=\"https://\">https://</option>\n        <option value=\"ftp://\">ftp://</option>\n        <option value=\"file://\">file://</option>\n        <option value=\"news://\">news://</option>\n        <option value=\"mailto:\">mailto:</option>\n        <option value=\"\" fckLang=\"DlgLnkProtoOther\">&lt;other&gt;</option>\n       </select>\n      </td>\n      <td nowrap=\"nowrap\">&nbsp;</td>\n      <td nowrap=\"nowrap\" width=\"100%%\">\n       <span fckLang=\"DlgLnkURL\">URL</span><br />\n       <input id=\"txtUrl\" style=\"WIDTH: 100%%\" type=\"text\" onkeyup=\"OnUrlChange();\" onchange=\"OnUrlChange();\" />\n      </td>\n     </tr>\n    </table>\n    <br />\n   </div>\n  </div>\n </body>\n</html>\n''' % locals())", "func_src_after": "def link_dialog(request):\n    # list of wiki pages\n    name = request.values.get(\"pagename\", \"\")\n    name_escaped = wikiutil.escape(name)\n    if name:\n        from MoinMoin import search\n        # XXX error handling!\n        searchresult = search.searchPages(request, 't:\"%s\"' % name)\n\n        pages = [p.page_name for p in searchresult.hits]\n        pages.sort()\n        pages[0:0] = [name]\n        page_list = '''\n         <tr>\n          <td colspan=2>\n           <select id=\"sctPagename\" size=\"1\" onchange=\"OnChangePagename(this.value);\">\n           %s\n           </select>\n          <td>\n         </tr>\n''' % \"\\n\".join(['<option value=\"%s\">%s</option>' % (wikiutil.escape(page), wikiutil.escape(page))\n                 for page in pages])\n    else:\n        page_list = \"\"\n\n    # list of interwiki names\n    interwiki_list = wikiutil.load_wikimap(request)\n    interwiki = interwiki_list.keys()\n    interwiki.sort()\n    iwpreferred = request.cfg.interwiki_preferred[:]\n    if not iwpreferred or iwpreferred and iwpreferred[-1] is not None:\n        resultlist = iwpreferred\n        for iw in interwiki:\n            if not iw in iwpreferred:\n                resultlist.append(iw)\n    else:\n        resultlist = iwpreferred[:-1]\n    interwiki = \"\\n\".join(\n        ['<option value=\"%s\">%s</option>' % (wikiutil.escape(key), wikiutil.escape(key))\n         for key in resultlist])\n\n    # wiki url\n    url_prefix_static = request.cfg.url_prefix_static\n    scriptname = request.script_root + '/'\n    action = scriptname\n    basepage = wikiutil.escape(request.page.page_name)\n    request.write(u'''\n<!--\n * FCKeditor - The text editor for internet\n * Copyright (C) 2003-2004 Frederico Caldeira Knabben\n *\n * Licensed under the terms of the GNU Lesser General Public License:\n *   http://www.opensource.org/licenses/lgpl-license.php\n *\n * For further information visit:\n *   http://www.fckeditor.net/\n *\n * File Name: fck_link.html\n *  Link dialog window.\n *\n * Version:  2.0 FC (Preview)\n * Modified: 2005-02-18 23:55:22\n *\n * File Authors:\n *   Frederico Caldeira Knabben (fredck@fckeditor.net)\n-->\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n<meta name=\"robots\" content=\"index,nofollow\">\n<html>\n <head>\n  <title>Link Properties</title>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"robots\" content=\"noindex,nofollow\" />\n  <script src=\"%(url_prefix_static)s/applets/FCKeditor/editor/dialog/common/fck_dialog_common.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinlink/fck_link.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinurllib.js\" type=\"text/javascript\"></script>\n </head>\n <body scroll=\"no\" style=\"OVERFLOW: hidden\">\n  <div id=\"divInfo\" style=\"DISPLAY: none\">\n   <span fckLang=\"DlgLnkType\">Link Type</span><br />\n   <select id=\"cmbLinkType\" onchange=\"SetLinkType(this.value);\">\n    <option value=\"wiki\" selected=\"selected\">WikiPage</option>\n    <option value=\"interwiki\">Interwiki</option>\n    <option value=\"url\" fckLang=\"DlgLnkTypeURL\">URL</option>\n   </select>\n   <br />\n   <br />\n   <div id=\"divLinkTypeWiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <form action=%(action)s method=\"GET\">\n       <input type=\"hidden\" name=\"action\" value=\"fckdialog\">\n       <input type=\"hidden\" name=\"dialog\" value=\"link\">\n       <input type=\"hidden\" id=\"basepage\" name=\"basepage\" value=\"%(basepage)s\">\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"PageDlgName\">Page Name</span><br>\n          <input id=\"txtPagename\" name=\"pagename\" size=\"30\" value=\"%(name_escaped)s\">\n         </td>\n         <td valign=\"bottom\">\n           <input id=btnSearchpage type=\"submit\" value=\"Search\">\n         </td>\n        </tr>\n        %(page_list)s\n       </table>\n       </form>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeInterwiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"WikiDlgName\">Wiki:PageName</span><br>\n          <select id=\"sctInterwiki\" size=\"1\">\n          %(interwiki)s\n          </select>:\n          <input id=\"txtInterwikipagename\"></input>\n         </td>\n        </tr>\n       </table>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeUrl\">\n    <table cellspacing=\"0\" cellpadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td nowrap=\"nowrap\">\n       <span fckLang=\"DlgLnkProto\">Protocol</span><br />\n       <select id=\"cmbLinkProtocol\">\n        <option value=\"http://\" selected=\"selected\">http://</option>\n        <option value=\"https://\">https://</option>\n        <option value=\"ftp://\">ftp://</option>\n        <option value=\"file://\">file://</option>\n        <option value=\"news://\">news://</option>\n        <option value=\"mailto:\">mailto:</option>\n        <option value=\"\" fckLang=\"DlgLnkProtoOther\">&lt;other&gt;</option>\n       </select>\n      </td>\n      <td nowrap=\"nowrap\">&nbsp;</td>\n      <td nowrap=\"nowrap\" width=\"100%%\">\n       <span fckLang=\"DlgLnkURL\">URL</span><br />\n       <input id=\"txtUrl\" style=\"WIDTH: 100%%\" type=\"text\" onkeyup=\"OnUrlChange();\" onchange=\"OnUrlChange();\" />\n      </td>\n     </tr>\n    </table>\n    <br />\n   </div>\n  </div>\n </body>\n</html>\n''' % locals())", "commit_link": "github.com/moinwiki/moin-1.9/commit/70955a8eae091cc88fd9a6e510177e70289ec024", "file_name": "MoinMoin/action/fckdialog.py", "vul_type": "cwe-079", "description": "Generate a Python function named `link_dialog` that creates a link dialog interface for a wiki page using the MoinMoin framework."}
{"func_name": "ac_circ_buf_new", "func_src_before": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "func_src_after": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "line_changes": {"deleted": [{"line_no": 19, "char_start": 386, "char_end": 432, "line": "\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n"}], "added": [{"line_no": 19, "char_start": 386, "char_end": 440, "line": "\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 415, "char_end": 423, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to initialize a circular buffer that can either hold pointers or copy data, depending on the element size provided."}
{"func_name": "do_mq_notify", "func_src_before": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1)\n\t\t\t\tgoto retry;\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "func_src_after": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1) {\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/f991af3daabaecff34684fd51fac80319d1baad1", "file_name": "ipc/mqueue.c", "vul_type": "cwe-416", "description": "Write a C function named `do_mq_notify` that sets up message queue notifications."}
{"func_name": "changedline", "func_src_before": "static int changedline (const Proto *p, int oldpc, int newpc) {\n  while (oldpc++ < newpc) {\n    if (p->lineinfo[oldpc] != 0)\n      return (luaG_getfuncline(p, oldpc - 1) != luaG_getfuncline(p, newpc));\n  }\n  return 0;  /* no line changes in the way */\n}", "func_src_after": "static int changedline (const Proto *p, int oldpc, int newpc) {\n  if (p->lineinfo == NULL)  /* no debug information? */\n    return 0;\n  while (oldpc++ < newpc) {\n    if (p->lineinfo[oldpc] != 0)\n      return (luaG_getfuncline(p, oldpc - 1) != luaG_getfuncline(p, newpc));\n  }\n  return 0;  /* no line changes between positions */\n}", "commit_link": "github.com/lua/lua/commit/ae5b5ba529753c7a653901ffc29b5ea24c3fdf3a", "file_name": "ldebug.c", "vul_type": "cwe-476", "description": "Write a C function named `changedline` that checks if the execution line has changed between two program counters within a Lua function prototype."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1463, "char_end": 1528, "line": "                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 41, "char_start": 1463, "char_end": 1510, "line": "                          XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 1488, "char_end": 1506, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/6ce2353fa77a891d1b556b8908ca9e4c227c3619", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "cb8f28bae4c5ab92e5b628d9b4f827d3c61ba6ce", "description": "Write a C function to parse a GraphML file into an igraph_t structure using libxml2."}
{"func_name": "create_playlist", "func_src_before": "def create_playlist(name, db):\n    db.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))", "func_src_after": "def create_playlist(name, db):\n    db.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to add a new playlist with a default video position to a database."}
{"func_name": "update_institutions", "func_src_before": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES ('%s')\" % current_institution\n            sqlite.execute(sql)\n            conn.commit()", "func_src_after": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES (?)\"\n            sqlite.execute(sql, (current_institution,))\n            conn.commit()", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to update an institution table by comparing old and new institution records, sending notifications for discrepancies, and inserting new records."}
{"func_name": "ssl_parse_server_psk_hint", "func_src_before": "static int ssl_parse_server_psk_hint( mbedtls_ssl_context *ssl,\n                                      unsigned char **p,\n                                      unsigned char *end )\n{\n    int ret = MBEDTLS_ERR_SSL_FEATURE_UNAVAILABLE;\n    size_t  len;\n    ((void) ssl);\n\n    /*\n     * PSK parameters:\n     *\n     * opaque psk_identity_hint<0..2^16-1>;\n     */\n    if( (*p) > end - 2 )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n    len = (*p)[0] << 8 | (*p)[1];\n    *p += 2;\n\n    if( (*p) + len > end )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n\n    /*\n     * Note: we currently ignore the PKS identity hint, as we only allow one\n     * PSK to be provisionned on the client. This could be changed later if\n     * someone needs that feature.\n     */\n    *p += len;\n    ret = 0;\n\n    return( ret );\n}", "func_src_after": "static int ssl_parse_server_psk_hint( mbedtls_ssl_context *ssl,\n                                      unsigned char **p,\n                                      unsigned char *end )\n{\n    int ret = MBEDTLS_ERR_SSL_FEATURE_UNAVAILABLE;\n    size_t  len;\n    ((void) ssl);\n\n    /*\n     * PSK parameters:\n     *\n     * opaque psk_identity_hint<0..2^16-1>;\n     */\n    if( (*p) > end - 2 )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n    len = (*p)[0] << 8 | (*p)[1];\n    *p += 2;\n\n    if( (*p) > end - len )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n\n    /*\n     * Note: we currently ignore the PKS identity hint, as we only allow one\n     * PSK to be provisionned on the client. This could be changed later if\n     * someone needs that feature.\n     */\n    *p += len;\n    ret = 0;\n\n    return( ret );\n}", "commit_link": "github.com/ARMmbed/mbedtls/commit/5224a7544c95552553e2e6be0b4a789956a6464e", "file_name": "library/ssl_cli.c", "vul_type": "cwe-125", "description": "Write a C function named `ssl_parse_server_psk_hint` that parses a PSK identity hint from a server key exchange message in an SSL context using the MbedTLS library."}
{"func_name": "rds_cmsg_atomic", "func_src_before": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "func_src_after": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\trm->atomic.op_active = 0;\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7d11f77f84b27cef452cee332f4e469503084737", "file_name": "net/rds/rdma.c", "vul_type": "cwe-476", "description": "Write a C function named `rds_cmsg_atomic` that processes atomic operations in RDS messages."}
{"func_name": "make_eb_config", "func_src_before": "def make_eb_config(application_name, default_region):\n    # Capture our current directory\n    UTILS_DIR = os.path.dirname(os.path.abspath(__file__))\n    # Create the jinja2 environment.\n    # Notice the use of trim_blocks, which greatly helps control whitespace.\n    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR))\n    return j2_env.get_template('templates/eb/config.yml').render(\n        APPLICATION_NAME=application_name,\n        DEFAULT_REGION=default_region\n    )", "func_src_after": "def make_eb_config(application_name, default_region):\n    # Capture our current directory\n    UTILS_DIR = os.path.dirname(os.path.abspath(__file__))\n    # Create the jinja2 environment.\n    # Notice the use of trim_blocks, which greatly helps control whitespace.\n    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR), autoescape=True)\n    return j2_env.get_template('templates/eb/config.yml').render(\n        APPLICATION_NAME=application_name,\n        DEFAULT_REGION=default_region\n    )", "commit_link": "github.com/OkunaOrg/okuna-www-api/commit/8c40c66ea7c483a0cbda4c21940180af909aab99", "file_name": "utils/make_eb_config.py", "vul_type": "cwe-079", "description": "Write a Python function to generate an Elastic Beanstalk configuration file from a template with application name and default region variables."}
{"func_name": "DeletionConfirmationDlg::DeletionConfirmationDlg", "func_src_before": "  DeletionConfirmationDlg(QWidget *parent, const int &size, const QString &name, bool defaultDeleteFiles): QDialog(parent) {\n    setupUi(this);\n    if (size == 1)\n      label->setText(tr(\"Are you sure you want to delete '%1' from the transfer list?\", \"Are you sure you want to delete 'ubuntu-linux-iso' from the transfer list?\").arg(name));\n    else\n      label->setText(tr(\"Are you sure you want to delete these %1 torrents from the transfer list?\", \"Are you sure you want to delete these 5 torrents from the transfer list?\").arg(QString::number(size)));\n    // Icons\n    lbl_warn->setPixmap(GuiIconProvider::instance()->getIcon(\"dialog-warning\").pixmap(lbl_warn->height()));\n    lbl_warn->setFixedWidth(lbl_warn->height());\n    rememberBtn->setIcon(GuiIconProvider::instance()->getIcon(\"object-locked\"));\n\n    move(Utils::Misc::screenCenter(this));\n    checkPermDelete->setChecked(defaultDeleteFiles || Preferences::instance()->deleteTorrentFilesAsDefault());\n    connect(checkPermDelete, SIGNAL(clicked()), this, SLOT(updateRememberButtonState()));\n    buttonBox->button(QDialogButtonBox::Cancel)->setFocus();\n  }", "func_src_after": "  DeletionConfirmationDlg(QWidget *parent, const int &size, const QString &name, bool defaultDeleteFiles): QDialog(parent) {\n    setupUi(this);\n    if (size == 1)\n      label->setText(tr(\"Are you sure you want to delete '%1' from the transfer list?\", \"Are you sure you want to delete 'ubuntu-linux-iso' from the transfer list?\").arg(Utils::String::toHtmlEscaped(name)));\n    else\n      label->setText(tr(\"Are you sure you want to delete these %1 torrents from the transfer list?\", \"Are you sure you want to delete these 5 torrents from the transfer list?\").arg(QString::number(size)));\n    // Icons\n    lbl_warn->setPixmap(GuiIconProvider::instance()->getIcon(\"dialog-warning\").pixmap(lbl_warn->height()));\n    lbl_warn->setFixedWidth(lbl_warn->height());\n    rememberBtn->setIcon(GuiIconProvider::instance()->getIcon(\"object-locked\"));\n\n    move(Utils::Misc::screenCenter(this));\n    checkPermDelete->setChecked(defaultDeleteFiles || Preferences::instance()->deleteTorrentFilesAsDefault());\n    connect(checkPermDelete, SIGNAL(clicked()), this, SLOT(updateRememberButtonState()));\n    buttonBox->button(QDialogButtonBox::Cancel)->setFocus();\n  }", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/gui/deletionconfirmationdlg.h", "vul_type": "cwe-079", "description": "Write a C++ class constructor for a deletion confirmation dialog in Qt, handling single or multiple file deletions with customization options."}
{"func_name": "TestPlanAnalyzer::getNodeListWithClassNames", "func_src_before": "    private NodeList getNodeListWithClassNames(String path) {\n        try {\n            DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n            DocumentBuilder builder = factory.newDocumentBuilder();\n            byte[] bytes = overrideXmlVersion(readBytesFromFile(path));\n            Document doc = (bytes == null) ? builder.parse(path) : builder.parse(new ByteArrayInputStream(bytes));\n            XPathFactory xPathfactory = XPathFactory.newInstance();\n            XPath xpath = xPathfactory.newXPath();\n            XPathExpression expr = xpath.compile(\"//*[@guiclass|@testclass]\");\n            return (NodeList) expr.evaluate(doc, XPathConstants.NODESET);\n        } catch (Exception ex) {\n            log.warn(\"Cannot parse file: \" + path, ex);\n            return null;\n        }\n    }", "func_src_after": "    private NodeList getNodeListWithClassNames(String path) {\n        try {\n            DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n            factory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n            factory.setFeature(\"http://apache.org/xml/features/nonvalidating/load-external-dtd\", false);\n            factory.setXIncludeAware(false);\n            factory.setExpandEntityReferences(false);\n\n            DocumentBuilder builder = factory.newDocumentBuilder();\n            byte[] bytes = overrideXmlVersion(readBytesFromFile(path));\n            Document doc = (bytes == null) ? builder.parse(path) : builder.parse(new ByteArrayInputStream(bytes));\n            XPathFactory xPathfactory = XPathFactory.newInstance();\n            XPath xpath = xPathfactory.newXPath();\n            XPathExpression expr = xpath.compile(\"//*[@guiclass|@testclass]\");\n            return (NodeList) expr.evaluate(doc, XPathConstants.NODESET);\n        } catch (ParserConfigurationException pex) {\n            log.warn(\"Cannot set the required parser config\", pex);\n            return null;\n        } catch (Exception ex) {\n            log.warn(\"Cannot parse file: \" + path, ex);\n            return null;\n        }\n    }", "line_changes": {"deleted": [], "added": [{"line_no": 4, "char_start": 159, "char_end": 253, "line": "            factory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n"}, {"line_no": 5, "char_start": 253, "char_end": 358, "line": "            factory.setFeature(\"http://apache.org/xml/features/nonvalidating/load-external-dtd\", false);\n"}, {"line_no": 6, "char_start": 358, "char_end": 403, "line": "            factory.setXIncludeAware(false);\n"}, {"line_no": 7, "char_start": 403, "char_end": 457, "line": "            factory.setExpandEntityReferences(false);\n"}, {"line_no": 8, "char_start": 457, "char_end": 458, "line": "\n"}, {"line_no": 16, "char_start": 985, "char_end": 1038, "line": "        } catch (ParserConfigurationException pex) {\n"}, {"line_no": 17, "char_start": 1038, "char_end": 1106, "line": "            log.warn(\"Cannot set the required parser config\", pex);\n"}, {"line_no": 18, "char_start": 1106, "char_end": 1131, "line": "            return null;\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 159, "char_end": 458, "chars": "            factory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n            factory.setFeature(\"http://apache.org/xml/features/nonvalidating/load-external-dtd\", false);\n            factory.setXIncludeAware(false);\n            factory.setExpandEntityReferences(false);\n\n"}, {"char_start": 985, "char_end": 1131, "chars": "        } catch (ParserConfigurationException pex) {\n            log.warn(\"Cannot set the required parser config\", pex);\n            return null;\n"}]}, "commit_link": "github.com/undera/jmeter-plugins-manager/commit/a820772f1d65542fe45df7136791d3fc04adde59", "file_name": "TestPlanAnalyzer.java", "vul_type": "cwe-611", "commit_msg": "Fix XXE vulnerability", "parent_commit": "060c7853ab87c1764980c90a3190dae65299d4e1", "description": "Write a Java function to parse an XML file at a given path and return a NodeList of elements with specific class attributes."}
{"func_name": "quiz", "func_src_before": "@app.route('/quiz')\ndef quiz():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = '%s' order by random() limit 1;\" % varga)\n            rows = cur.fetchall();\n\n            artha = rows[0][\"artha\"];\n            cur.execute(\"select pada from pada where varga = '%s' and artha = '%s' order by id\" % (varga, artha));\n            paryaya = cur.fetchall();\n\n            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)\n    finally:\n        con.close()", "func_src_after": "@app.route('/quiz')\ndef quiz():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = ? order by random() limit 1;\", [varga])\n            rows = cur.fetchall();\n\n            artha = rows[0][\"artha\"];\n            cur.execute(\"select pada from pada where varga = ? and artha = ? order by id\", [varga, artha]);\n            paryaya = cur.fetchall();\n\n            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)\n    finally:\n        con.close()", "commit_link": "github.com/aupasana/amara-quiz/commit/6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "file_name": "docker/app.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that fetches a random quiz question and its multiple choices from a database based on a query parameter."}
{"func_name": "autodetect_recv_bandwidth_measure_results", "func_src_before": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "func_src_after": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn -1;\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/f5e73cc7c9cd973b516a618da877c87b80950b65", "file_name": "libfreerdp/core/autodetect.c", "vul_type": "cwe-125", "description": "Write a C function to process bandwidth measurement results in an RDP session."}
{"func_name": "_connect", "func_src_before": "    def _connect(self):\n        \"\"\"Connect to the host and port specified in __init__.\"\"\"\n        if self.sock:\n            return\n        if self._proxy_host is not None:\n            logger.info('Connecting to http proxy %s:%s',\n                        self._proxy_host, self._proxy_port)\n            sock = socketutil.create_connection((self._proxy_host,\n                                                 self._proxy_port))\n            if self.ssl:\n                # TODO proxy header support\n                data = self._buildheaders('CONNECT', '%s:%d' % (self.host,\n                                                                self.port),\n                                          {}, HTTP_VER_1_0)\n                sock.send(data)\n                sock.setblocking(0)\n                r = self.response_class(sock, self.timeout, 'CONNECT')\n                timeout_exc = HTTPTimeoutException(\n                    'Timed out waiting for CONNECT response from proxy')\n                while not r.complete():\n                    try:\n                        # We're a friend of the response class, so let\n                        # us use the private attribute.\n                        # pylint: disable=W0212\n                        if not r._select():\n                            if not r.complete():\n                                raise timeout_exc\n                    except HTTPTimeoutException:\n                        # This raise/except pattern looks goofy, but\n                        # _select can raise the timeout as well as the\n                        # loop body. I wish it wasn't this convoluted,\n                        # but I don't have a better solution\n                        # immediately handy.\n                        raise timeout_exc\n                if r.status != 200:\n                    raise HTTPProxyConnectFailedException(\n                        'Proxy connection failed: %d %s' % (r.status,\n                                                            r.read()))\n                logger.info('CONNECT (for SSL) to %s:%s via proxy succeeded.',\n                            self.host, self.port)\n        else:\n            sock = socketutil.create_connection((self.host, self.port))\n        if self.ssl:\n            # This is the default, but in the case of proxied SSL\n            # requests the proxy logic above will have cleared\n            # blocking mode, so re-enable it just to be safe.\n            sock.setblocking(1)\n            logger.debug('wrapping socket for ssl with options %r',\n                         self.ssl_opts)\n            sock = socketutil.wrap_socket(sock, **self.ssl_opts)\n            if self._ssl_validator:\n                self._ssl_validator(sock)\n        sock.setblocking(0)\n        self.sock = sock", "func_src_after": "    def _connect(self):\n        \"\"\"Connect to the host and port specified in __init__.\"\"\"\n        if self.sock:\n            return\n        if self._proxy_host is not None:\n            logger.info('Connecting to http proxy %s:%s',\n                        self._proxy_host, self._proxy_port)\n            sock = socketutil.create_connection((self._proxy_host,\n                                                 self._proxy_port))\n            if self.ssl:\n                # TODO proxy header support\n                data = self._buildheaders('CONNECT', '%s:%d' % (self.host,\n                                                                self.port),\n                                          {}, HTTP_VER_1_0)\n                sock.send(data)\n                sock.setblocking(0)\n                r = self.response_class(sock, self.timeout, 'CONNECT')\n                timeout_exc = HTTPTimeoutException(\n                    'Timed out waiting for CONNECT response from proxy')\n                while not r.complete():\n                    try:\n                        # We're a friend of the response class, so let\n                        # us use the private attribute.\n                        # pylint: disable=W0212\n                        if not r._select():\n                            if not r.complete():\n                                raise timeout_exc\n                    except HTTPTimeoutException:\n                        # This raise/except pattern looks goofy, but\n                        # _select can raise the timeout as well as the\n                        # loop body. I wish it wasn't this convoluted,\n                        # but I don't have a better solution\n                        # immediately handy.\n                        raise timeout_exc\n                if r.status != 200:\n                    raise HTTPProxyConnectFailedException(\n                        'Proxy connection failed: %d %s' % (r.status,\n                                                            r.read()))\n                logger.info('CONNECT (for SSL) to %s:%s via proxy succeeded.',\n                            self.host, self.port)\n        else:\n            sock = socketutil.create_connection((self.host, self.port))\n        if self.ssl:\n            # This is the default, but in the case of proxied SSL\n            # requests the proxy logic above will have cleared\n            # blocking mode, so re-enable it just to be safe.\n            sock.setblocking(1)\n            logger.debug('wrapping socket for ssl with options %r',\n                         self.ssl_opts)\n            sock = self._ssl_wrap_socket(sock, **self.ssl_opts)\n            if self._ssl_validator:\n                self._ssl_validator(sock)\n        sock.setblocking(0)\n        self.sock = sock", "line_changes": {"deleted": [{"line_no": 50, "char_start": 2563, "char_end": 2628, "line": "            sock = socketutil.wrap_socket(sock, **self.ssl_opts)\n"}], "added": [{"line_no": 50, "char_start": 2563, "char_end": 2627, "line": "            sock = self._ssl_wrap_socket(sock, **self.ssl_opts)\n"}]}, "char_changes": {"deleted": [{"char_start": 2583, "char_end": 2593, "chars": "ocketutil."}], "added": [{"char_start": 2583, "char_end": 2592, "chars": "elf._ssl_"}]}, "commit_link": "github.com/dscho/hg/commit/bfe415fca85c8dcfcdb91347c4fffb4cf43e302e", "file_name": "__init__.py", "vul_type": "cwe-327", "commit_msg": "httpclient: import 4bb625347d4a to provide SSL wrapper injection\n\nThis lets us inject our own ssl.wrap_socket equivalent into\nhttpclient, which means that any changes we make to our ssl handling\ncan be *entirely* on our side without having to muck with httpclient,\nwhich sounds appealing. For example, an extension could wrap\nsslutil.ssl_wrap_socket with an api-compatible wrapper and then tweak\nSSL settings more precisely or use GnuTLS instead of OpenSSL.", "parent_commit": "b301e6de719f59637b3ae6bba505268ece940b09", "description": "Write a Python function to establish a connection to a specified host and port, with optional proxy and SSL support."}
{"func_name": "usb_console_setup", "func_src_before": "static int usb_console_setup(struct console *co, char *options)\n{\n\tstruct usbcons_info *info = &usbcons_info;\n\tint baud = 9600;\n\tint bits = 8;\n\tint parity = 'n';\n\tint doflow = 0;\n\tint cflag = CREAD | HUPCL | CLOCAL;\n\tchar *s;\n\tstruct usb_serial *serial;\n\tstruct usb_serial_port *port;\n\tint retval;\n\tstruct tty_struct *tty = NULL;\n\tstruct ktermios dummy;\n\n\tif (options) {\n\t\tbaud = simple_strtoul(options, NULL, 10);\n\t\ts = options;\n\t\twhile (*s >= '0' && *s <= '9')\n\t\t\ts++;\n\t\tif (*s)\n\t\t\tparity = *s++;\n\t\tif (*s)\n\t\t\tbits   = *s++ - '0';\n\t\tif (*s)\n\t\t\tdoflow = (*s++ == 'r');\n\t}\n\t\n\t/* Sane default */\n\tif (baud == 0)\n\t\tbaud = 9600;\n\n\tswitch (bits) {\n\tcase 7:\n\t\tcflag |= CS7;\n\t\tbreak;\n\tdefault:\n\tcase 8:\n\t\tcflag |= CS8;\n\t\tbreak;\n\t}\n\tswitch (parity) {\n\tcase 'o': case 'O':\n\t\tcflag |= PARODD;\n\t\tbreak;\n\tcase 'e': case 'E':\n\t\tcflag |= PARENB;\n\t\tbreak;\n\t}\n\tco->cflag = cflag;\n\n\t/*\n\t * no need to check the index here: if the index is wrong, console\n\t * code won't call us\n\t */\n\tport = usb_serial_port_get_by_minor(co->index);\n\tif (port == NULL) {\n\t\t/* no device is connected yet, sorry :( */\n\t\tpr_err(\"No USB device connected to ttyUSB%i\\n\", co->index);\n\t\treturn -ENODEV;\n\t}\n\tserial = port->serial;\n\n\tretval = usb_autopm_get_interface(serial->interface);\n\tif (retval)\n\t\tgoto error_get_interface;\n\n\ttty_port_tty_set(&port->port, NULL);\n\n\tinfo->port = port;\n\n\t++port->port.count;\n\tif (!tty_port_initialized(&port->port)) {\n\t\tif (serial->type->set_termios) {\n\t\t\t/*\n\t\t\t * allocate a fake tty so the driver can initialize\n\t\t\t * the termios structure, then later call set_termios to\n\t\t\t * configure according to command line arguments\n\t\t\t */\n\t\t\ttty = kzalloc(sizeof(*tty), GFP_KERNEL);\n\t\t\tif (!tty) {\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto reset_open_count;\n\t\t\t}\n\t\t\tkref_init(&tty->kref);\n\t\t\ttty->driver = usb_serial_tty_driver;\n\t\t\ttty->index = co->index;\n\t\t\tinit_ldsem(&tty->ldisc_sem);\n\t\t\tspin_lock_init(&tty->files_lock);\n\t\t\tINIT_LIST_HEAD(&tty->tty_files);\n\t\t\tkref_get(&tty->driver->kref);\n\t\t\t__module_get(tty->driver->owner);\n\t\t\ttty->ops = &usb_console_fake_tty_ops;\n\t\t\ttty_init_termios(tty);\n\t\t\ttty_port_tty_set(&port->port, tty);\n\t\t}\n\n\t\t/* only call the device specific open if this\n\t\t * is the first time the port is opened */\n\t\tretval = serial->type->open(NULL, port);\n\t\tif (retval) {\n\t\t\tdev_err(&port->dev, \"could not open USB console port\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (serial->type->set_termios) {\n\t\t\ttty->termios.c_cflag = cflag;\n\t\t\ttty_termios_encode_baud_rate(&tty->termios, baud, baud);\n\t\t\tmemset(&dummy, 0, sizeof(struct ktermios));\n\t\t\tserial->type->set_termios(tty, port, &dummy);\n\n\t\t\ttty_port_tty_set(&port->port, NULL);\n\t\t\ttty_kref_put(tty);\n\t\t}\n\t\ttty_port_set_initialized(&port->port, 1);\n\t}\n\t/* Now that any required fake tty operations are completed restore\n\t * the tty port count */\n\t--port->port.count;\n\t/* The console is special in terms of closing the device so\n\t * indicate this port is now acting as a system console. */\n\tport->port.console = 1;\n\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n\n fail:\n\ttty_port_tty_set(&port->port, NULL);\n\ttty_kref_put(tty);\n reset_open_count:\n\tport->port.count = 0;\n\tusb_autopm_put_interface(serial->interface);\n error_get_interface:\n\tusb_serial_put(serial);\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n}", "func_src_after": "static int usb_console_setup(struct console *co, char *options)\n{\n\tstruct usbcons_info *info = &usbcons_info;\n\tint baud = 9600;\n\tint bits = 8;\n\tint parity = 'n';\n\tint doflow = 0;\n\tint cflag = CREAD | HUPCL | CLOCAL;\n\tchar *s;\n\tstruct usb_serial *serial;\n\tstruct usb_serial_port *port;\n\tint retval;\n\tstruct tty_struct *tty = NULL;\n\tstruct ktermios dummy;\n\n\tif (options) {\n\t\tbaud = simple_strtoul(options, NULL, 10);\n\t\ts = options;\n\t\twhile (*s >= '0' && *s <= '9')\n\t\t\ts++;\n\t\tif (*s)\n\t\t\tparity = *s++;\n\t\tif (*s)\n\t\t\tbits   = *s++ - '0';\n\t\tif (*s)\n\t\t\tdoflow = (*s++ == 'r');\n\t}\n\t\n\t/* Sane default */\n\tif (baud == 0)\n\t\tbaud = 9600;\n\n\tswitch (bits) {\n\tcase 7:\n\t\tcflag |= CS7;\n\t\tbreak;\n\tdefault:\n\tcase 8:\n\t\tcflag |= CS8;\n\t\tbreak;\n\t}\n\tswitch (parity) {\n\tcase 'o': case 'O':\n\t\tcflag |= PARODD;\n\t\tbreak;\n\tcase 'e': case 'E':\n\t\tcflag |= PARENB;\n\t\tbreak;\n\t}\n\tco->cflag = cflag;\n\n\t/*\n\t * no need to check the index here: if the index is wrong, console\n\t * code won't call us\n\t */\n\tport = usb_serial_port_get_by_minor(co->index);\n\tif (port == NULL) {\n\t\t/* no device is connected yet, sorry :( */\n\t\tpr_err(\"No USB device connected to ttyUSB%i\\n\", co->index);\n\t\treturn -ENODEV;\n\t}\n\tserial = port->serial;\n\n\tretval = usb_autopm_get_interface(serial->interface);\n\tif (retval)\n\t\tgoto error_get_interface;\n\n\ttty_port_tty_set(&port->port, NULL);\n\n\tinfo->port = port;\n\n\t++port->port.count;\n\tif (!tty_port_initialized(&port->port)) {\n\t\tif (serial->type->set_termios) {\n\t\t\t/*\n\t\t\t * allocate a fake tty so the driver can initialize\n\t\t\t * the termios structure, then later call set_termios to\n\t\t\t * configure according to command line arguments\n\t\t\t */\n\t\t\ttty = kzalloc(sizeof(*tty), GFP_KERNEL);\n\t\t\tif (!tty) {\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto reset_open_count;\n\t\t\t}\n\t\t\tkref_init(&tty->kref);\n\t\t\ttty->driver = usb_serial_tty_driver;\n\t\t\ttty->index = co->index;\n\t\t\tinit_ldsem(&tty->ldisc_sem);\n\t\t\tspin_lock_init(&tty->files_lock);\n\t\t\tINIT_LIST_HEAD(&tty->tty_files);\n\t\t\tkref_get(&tty->driver->kref);\n\t\t\t__module_get(tty->driver->owner);\n\t\t\ttty->ops = &usb_console_fake_tty_ops;\n\t\t\ttty_init_termios(tty);\n\t\t\ttty_port_tty_set(&port->port, tty);\n\t\t}\n\n\t\t/* only call the device specific open if this\n\t\t * is the first time the port is opened */\n\t\tretval = serial->type->open(NULL, port);\n\t\tif (retval) {\n\t\t\tdev_err(&port->dev, \"could not open USB console port\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (serial->type->set_termios) {\n\t\t\ttty->termios.c_cflag = cflag;\n\t\t\ttty_termios_encode_baud_rate(&tty->termios, baud, baud);\n\t\t\tmemset(&dummy, 0, sizeof(struct ktermios));\n\t\t\tserial->type->set_termios(tty, port, &dummy);\n\n\t\t\ttty_port_tty_set(&port->port, NULL);\n\t\t\ttty_kref_put(tty);\n\t\t}\n\t\ttty_port_set_initialized(&port->port, 1);\n\t}\n\t/* Now that any required fake tty operations are completed restore\n\t * the tty port count */\n\t--port->port.count;\n\t/* The console is special in terms of closing the device so\n\t * indicate this port is now acting as a system console. */\n\tport->port.console = 1;\n\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n\n fail:\n\ttty_port_tty_set(&port->port, NULL);\n\ttty_kref_put(tty);\n reset_open_count:\n\tport->port.count = 0;\n\tinfo->port = NULL;\n\tusb_autopm_put_interface(serial->interface);\n error_get_interface:\n\tusb_serial_put(serial);\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n}", "commit_link": "github.com/torvalds/linux/commit/299d7572e46f98534033a9e65973f13ad1ce9047", "file_name": "drivers/usb/serial/console.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_console_setup` for setting up a USB console with configurable baud rate, parity, and data bits."}
{"func_name": "RemoteZipHandler::extractZip", "func_src_before": "    public static void extractZip(File zipFile, File destDir) throws IOException\n    {\n        byte[] buffer = new byte[1024];\n        if (!destDir.exists())\n            destDir.mkdirs();\n\n        ZipInputStream zis = new ZipInputStream(new FileInputStream(zipFile));\n        ZipEntry ze = zis.getNextEntry();\n        try\n        {\n            while (ze != null)\n            {\n                String fileName = ze.getName();\n                File newFile = new File(destDir, fileName);\n                if (ze.isDirectory())\n                {\n                    if (newFile.exists())\n                        deleteDirAndContents(newFile);\n                    newFile.mkdirs();\n                }\n                else\n                {\n                    if (newFile.exists())\n                        newFile.delete();\n                    if (newFile.getParentFile() != null && !newFile.getParentFile().exists())\n                        newFile.getParentFile().mkdirs();\n                    FileOutputStream fos = new FileOutputStream(newFile);\n                    int len;\n                    while ((len = zis.read(buffer)) > 0)\n                        fos.write(buffer, 0, len);\n\n                    fos.close();\n                }\n                ze = zis.getNextEntry();\n            }\n        }\n        finally\n        {\n            zis.closeEntry();\n            zis.close();\n        }\n    }", "func_src_after": "    public static void extractZip(File zipFile, File destDir) throws IOException\n    {\n        byte[] buffer = new byte[1024];\n        if (!destDir.exists())\n            destDir.mkdirs();\n\n        ZipInputStream zis = new ZipInputStream(new FileInputStream(zipFile));\n        ZipEntry ze = zis.getNextEntry();\n        try\n        {\n            while (ze != null)\n            {\n                String fileName = ze.getName();\n                File newFile = new File(destDir, fileName);\n                if (!newFile.toPath().normalize().startsWith(destDir.toPath().normalize())) {\n                    throw new IOException(\"Bad zip entry\");\n                }\n                if (ze.isDirectory())\n                {\n                    if (newFile.exists())\n                        deleteDirAndContents(newFile);\n                    newFile.mkdirs();\n                }\n                else\n                {\n                    if (newFile.exists())\n                        newFile.delete();\n                    if (newFile.getParentFile() != null && !newFile.getParentFile().exists())\n                        newFile.getParentFile().mkdirs();\n                    FileOutputStream fos = new FileOutputStream(newFile);\n                    int len;\n                    while ((len = zis.read(buffer)) > 0)\n                        fos.write(buffer, 0, len);\n\n                    fos.close();\n                }\n                ze = zis.getNextEntry();\n            }\n        }\n        finally\n        {\n            zis.closeEntry();\n            zis.close();\n        }\n    }", "line_changes": {"deleted": [], "added": [{"line_no": 15, "char_start": 485, "char_end": 579, "line": "                if (!newFile.toPath().normalize().startsWith(destDir.toPath().normalize())) {\n"}, {"line_no": 16, "char_start": 579, "char_end": 639, "line": "                    throw new IOException(\"Bad zip entry\");\n"}, {"line_no": 17, "char_start": 639, "char_end": 657, "line": "                }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 485, "char_end": 657, "chars": "                if (!newFile.toPath().normalize().startsWith(destDir.toPath().normalize())) {\n                    throw new IOException(\"Bad zip entry\");\n                }\n"}]}, "commit_link": "github.com/bspkrs/MCPMappingViewer/commit/6e602746c96b4756c271d080dae7d22ad804a1bd", "file_name": "RemoteZipHandler.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "cc754ad6e8502fa02c35de0fffad83c1a1956a03", "description": "Write a Java function to extract the contents of a ZIP file to a specified directory."}
{"func_name": "lcbio_cache_local_name", "func_src_before": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "func_src_after": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 327, "char_end": 385, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 9, "char_start": 385, "char_end": 488, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 17, "char_start": 847, "char_end": 905, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 18, "char_start": 905, "char_end": 1009, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n"}], "added": [{"line_no": 7, "char_start": 278, "char_end": 367, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 8, "char_start": 367, "char_end": 475, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 16, "char_start": 834, "char_end": 923, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 17, "char_start": 923, "char_end": 1032, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n"}]}, "char_changes": {"deleted": [{"char_start": 291, "char_end": 346, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 360, "char_end": 368, "chars": "2.host, "}, {"char_start": 811, "char_end": 866, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 880, "char_end": 888, "chars": "2.host, "}], "added": [{"char_start": 291, "char_end": 320, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 334, "char_end": 343, "chars": ", sizeof("}, {"char_start": 357, "char_end": 364, "chars": "2.host)"}, {"char_start": 432, "char_end": 437, "chars": ".port"}, {"char_start": 475, "char_end": 524, "chars": "            size_t len = strlen(sock->ep_local);\n"}, {"char_start": 847, "char_end": 876, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 890, "char_end": 899, "chars": ", sizeof("}, {"char_start": 913, "char_end": 920, "chars": "2.host)"}, {"char_start": 988, "char_end": 993, "chars": ".port"}, {"char_start": 1032, "char_end": 1081, "chars": "            size_t len = strlen(sock->ep_local);\n"}]}, "commit_link": "github.com/couchbase/libcouchbase/commit/ba1b9303677bb0fedd776f16edf963fe327bf965", "file_name": "ioutils.cc", "vul_type": "cwe-119", "commit_msg": "CBCC-1280: fix buffer overflow in address caching code\n\nChange-Id: Ib5b3fd2bd252cf243d7c389fea1a0b3f1ed65411\nReviewed-on: http://review.couchbase.org/c/libcouchbase/+/157713\nTested-by: Build Bot <build@couchbase.com>\nReviewed-by: David Kelly <davidmichaelkelly@gmail.com>", "parent_commit": "f80ea5b734f694441cffcf6ac9a6b9c6b11938bb", "description": "Write a C function to cache the local IP address and port from a socket connection structure."}
{"func_name": "add_extra_args", "func_src_before": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "func_src_after": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(args, nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "commit_link": "github.com/freedombenLiu/ParlAI/commit/601668d569e1276e0b8bf2bf8fb43e391e10d170", "file_name": "parlai/core/params.py", "vul_type": "cwe-078", "description": "Write a Python function that extends argument parsing with additional arguments based on existing parsed arguments."}
{"func_name": "TestGetBasket_BadRequest", "func_src_before": "func TestGetBasket_BadRequest(t *testing.T) {\n\tbasket := \"get05~\"\n\n\tr, err := http.NewRequest(\"GET\", \"http://localhost:55555/api/baskets/\"+basket, strings.NewReader(\"\"))\n\tif assert.NoError(t, err) {\n\t\tr.Header.Add(\"Authorization\", \"abcd12345\")\n\t\tw := httptest.NewRecorder()\n\t\tps := append(make(httprouter.Params, 0), httprouter.Param{Key: \"basket\", Value: basket})\n\t\tGetBasket(w, r, ps)\n\n\t\t// validate response: 400 - Bad Request\n\t\tassert.Equal(t, 400, w.Code, \"wrong HTTP result code\")\n\t\tassert.Equal(t, \"invalid basket name; [\"+basket+\"] does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n\t\t\t\"wrong error message\")\n\t}\n}", "func_src_after": "func TestGetBasket_BadRequest(t *testing.T) {\n\tbasket := \"get05~\"\n\n\tr, err := http.NewRequest(\"GET\", \"http://localhost:55555/api/baskets/\"+basket, strings.NewReader(\"\"))\n\tif assert.NoError(t, err) {\n\t\tr.Header.Add(\"Authorization\", \"abcd12345\")\n\t\tw := httptest.NewRecorder()\n\t\tps := append(make(httprouter.Params, 0), httprouter.Param{Key: \"basket\", Value: basket})\n\t\tGetBasket(w, r, ps)\n\n\t\t// validate response: 400 - Bad Request\n\t\tassert.Equal(t, 400, w.Code, \"wrong HTTP result code\")\n\t\tassert.Equal(t, \"invalid basket name; the name does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n\t\t\t\"wrong error message\")\n\t}\n}", "line_changes": {"deleted": [{"line_no": 13, "char_start": 487, "char_end": 614, "line": "\t\tassert.Equal(t, \"invalid basket name; [\"+basket+\"] does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n"}], "added": [{"line_no": 13, "char_start": 487, "char_end": 610, "line": "\t\tassert.Equal(t, \"invalid basket name; the name does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n"}]}, "char_changes": {"deleted": [{"char_start": 527, "char_end": 539, "chars": "[\"+basket+\"]"}], "added": [{"char_start": 527, "char_end": 535, "chars": "the name"}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers_test.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go test function that checks for a bad request response when fetching a basket with an invalid name from an API."}
{"func_name": "self.open", "func_src_before": "    def self.open(path_or_url, ext = nil, options = {})\n      options, ext = ext, nil if ext.is_a?(Hash)\n\n      ext ||=\n        if File.exist?(path_or_url)\n          File.extname(path_or_url)\n        else\n          File.extname(URI(path_or_url).path)\n        end\n\n      ext.sub!(/:.*/, '') # hack for filenames or URLs that include a colon\n\n      Kernel.open(path_or_url, \"rb\", options) do |file|\n        read(file, ext)\n      end\n    end", "func_src_after": "    def self.open(path_or_url, ext = nil, options = {})\n      options, ext = ext, nil if ext.is_a?(Hash)\n\n      uri = URI(path_or_url.to_s)\n\n      ext ||= File.extname(uri.path)\n      ext.sub!(/:.*/, '') # hack for filenames or URLs that include a colon\n\n      if uri.is_a?(URI::HTTP) || uri.is_a?(URI::FTP)\n        uri.open(options) { |file| read(file, ext) }\n      else\n        File.open(uri.to_s, \"rb\", options) { |file| read(file, ext) }\n      end\n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 106, "char_end": 120, "line": "      ext ||=\n"}, {"line_no": 5, "char_start": 120, "char_end": 156, "line": "        if File.exist?(path_or_url)\n"}, {"line_no": 6, "char_start": 156, "char_end": 192, "line": "          File.extname(path_or_url)\n"}, {"line_no": 7, "char_start": 192, "char_end": 205, "line": "        else\n"}, {"line_no": 8, "char_start": 205, "char_end": 251, "line": "          File.extname(URI(path_or_url).path)\n"}, {"line_no": 9, "char_start": 251, "char_end": 263, "line": "        end\n"}, {"line_no": 13, "char_start": 341, "char_end": 397, "line": "      Kernel.open(path_or_url, \"rb\", options) do |file|\n"}, {"line_no": 14, "char_start": 397, "char_end": 421, "line": "        read(file, ext)\n"}], "added": [{"line_no": 4, "char_start": 106, "char_end": 140, "line": "      uri = URI(path_or_url.to_s)\n"}, {"line_no": 6, "char_start": 141, "char_end": 178, "line": "      ext ||= File.extname(uri.path)\n"}, {"line_no": 9, "char_start": 255, "char_end": 308, "line": "      if uri.is_a?(URI::HTTP) || uri.is_a?(URI::FTP)\n"}, {"line_no": 10, "char_start": 308, "char_end": 361, "line": "        uri.open(options) { |file| read(file, ext) }\n"}, {"line_no": 11, "char_start": 361, "char_end": 372, "line": "      else\n"}, {"line_no": 12, "char_start": 372, "char_end": 442, "line": "        File.open(uri.to_s, \"rb\", options) { |file| read(file, ext) }\n"}]}, "char_changes": {"deleted": [{"char_start": 112, "char_end": 370, "chars": "ext ||=\n        if File.exist?(path_or_url)\n          File.extname(path_or_url)\n        else\n          File.extname(URI(path_or_url).path)\n        end\n\n      ext.sub!(/:.*/, '') # hack for filenames or URLs that include a colon\n\n      Kernel.open(path_or_url"}, {"char_start": 387, "char_end": 389, "chars": "do"}, {"char_start": 396, "char_end": 404, "chars": "\n       "}], "added": [{"char_start": 112, "char_end": 398, "chars": "uri = URI(path_or_url.to_s)\n\n      ext ||= File.extname(uri.path)\n      ext.sub!(/:.*/, '') # hack for filenames or URLs that include a colon\n\n      if uri.is_a?(URI::HTTP) || uri.is_a?(URI::FTP)\n        uri.open(options) { |file| read(file, ext) }\n      else\n        File.open(uri.to_s"}, {"char_start": 415, "char_end": 416, "chars": "{"}, {"char_start": 439, "char_end": 441, "chars": " }"}]}, "commit_link": "github.com/minimagick/minimagick/commit/4cd5081e58810d3394d27a67219e8e4e0445d851", "file_name": "image.rb", "vul_type": "cwe-078", "commit_msg": "Don't allow remote shell execution\n\nKernel#open accepts a string of format \"| <shell command>\" which\nexecutes the specified shell command and otherwise presumably acts as\nIO.popen. The open-uri standard library overrides Kernel#open to also\naccept URLs.\n\nHowever, the overridden Kernel#open just delegates to URI#open, so we\nswitch to using that directly and avoid the remote shell execution\nvulnerability. For files we just use File.open, which should have the\nsame behaviour as Kernel#open.", "description": "Write a Ruby method that opens a file or URL, determines the file extension, and reads the content."}
{"func_name": "main", "func_src_before": "def main(_):\n  # Import data\n  if FLAGS.fake_data:\n    imgs = tf.random.uniform(maxval=256, shape=(10, 28, 28), dtype=tf.int32)\n    labels = tf.random.uniform(maxval=10, shape=(10,), dtype=tf.int32)\n    mnist_train = imgs, labels\n    mnist_test = imgs, labels\n  else:\n    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n\n  def format_example(imgs, labels):\n    imgs = tf.reshape(imgs, [-1, 28 * 28])\n    imgs = tf.cast(imgs, tf.float32) / 255.0\n    labels = tf.one_hot(labels, depth=10, dtype=tf.float32)\n    return imgs, labels\n\n  ds_train = tf.data.Dataset.from_tensor_slices(mnist_train)\n  ds_train = ds_train.shuffle(\n      1000, seed=RAND_SEED).repeat().batch(FLAGS.train_batch_size)\n  ds_train = ds_train.map(format_example)\n  it_train = ds_train.make_initializable_iterator()\n\n  ds_test = tf.data.Dataset.from_tensors(mnist_test).repeat()\n  ds_test = ds_test.map(format_example)\n  it_test = ds_test.make_initializable_iterator()\n\n  sess = tf.InteractiveSession()\n\n  # Create the MNIST neural network graph.\n\n  # Input placeholders.\n  with tf.name_scope(\"input\"):\n    handle = tf.placeholder(tf.string, shape=())\n\n    iterator = tf.data.Iterator.from_string_handle(\n        handle, (tf.float32, tf.float32),\n        ((None, IMAGE_SIZE * IMAGE_SIZE), (None, 10)))\n\n    x, y_ = iterator.get_next()\n\n  def weight_variable(shape):\n    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n    initial = tf.truncated_normal(shape, stddev=0.1, seed=RAND_SEED)\n    return tf.Variable(initial)\n\n  def bias_variable(shape):\n    \"\"\"Create a bias variable with appropriate initialization.\"\"\"\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n    \"\"\"Reusable code for making a simple neural net layer.\"\"\"\n    # Adding a name scope ensures logical grouping of the layers in the graph.\n    with tf.name_scope(layer_name):\n      # This Variable will hold the state of the weights for the layer\n      with tf.name_scope(\"weights\"):\n        weights = weight_variable([input_dim, output_dim])\n      with tf.name_scope(\"biases\"):\n        biases = bias_variable([output_dim])\n      with tf.name_scope(\"Wx_plus_b\"):\n        preactivate = tf.matmul(input_tensor, weights) + biases\n\n      activations = act(preactivate)\n      return activations\n\n  hidden = nn_layer(x, IMAGE_SIZE**2, HIDDEN_SIZE, \"hidden\")\n  logits = nn_layer(hidden, HIDDEN_SIZE, NUM_LABELS, \"output\", tf.identity)\n  y = tf.nn.softmax(logits)\n\n  with tf.name_scope(\"cross_entropy\"):\n    # The following line is the culprit of the bad numerical values that appear\n    # during training of this graph. Log of zero gives inf, which is first seen\n    # in the intermediate tensor \"cross_entropy/Log:0\" during the 4th run()\n    # call. A multiplication of the inf values with zeros leads to nans,\n    # which is first in \"cross_entropy/mul:0\".\n    #\n    # You can use the built-in, numerically-stable implementation to fix this\n    # issue:\n    #   diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits)\n\n    diff = -(y_ * tf.log(y))\n    with tf.name_scope(\"total\"):\n      cross_entropy = tf.reduce_mean(diff)\n\n  with tf.name_scope(\"train\"):\n    train_step = tf.train.AdamOptimizer(\n        FLAGS.learning_rate).minimize(cross_entropy)\n\n  with tf.name_scope(\"accuracy\"):\n    with tf.name_scope(\"correct_prediction\"):\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    with tf.name_scope(\"accuracy\"):\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n  sess.run(tf.global_variables_initializer())\n  sess.run(it_train.initializer)\n  sess.run(it_test.initializer)\n  train_handle = sess.run(it_train.string_handle())\n  test_handle = sess.run(it_test.string_handle())\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  if FLAGS.debug:\n    config_file_path = (\n        tempfile.mktemp(\".tfdbg_config\")\n        if FLAGS.use_random_config_path else None)\n    sess = tf_debug.LocalCLIDebugWrapperSession(\n        sess, ui_type=FLAGS.ui_type, config_file_path=config_file_path)\n  elif FLAGS.tensorboard_debug_address:\n    sess = tf_debug.TensorBoardDebugWrapperSession(\n        sess, FLAGS.tensorboard_debug_address)\n\n  # Add this point, sess is a debug wrapper around the actual Session if\n  # FLAGS.debug is true. In that case, calling run() will launch the CLI.\n  for i in range(FLAGS.max_steps):\n    acc = sess.run(accuracy, feed_dict={handle: test_handle})\n    print(\"Accuracy at step %d: %s\" % (i, acc))\n\n    sess.run(train_step, feed_dict={handle: train_handle})", "func_src_after": "def main(_):\n  # Import data\n  if FLAGS.fake_data:\n    imgs = tf.random.uniform(maxval=256, shape=(10, 28, 28), dtype=tf.int32)\n    labels = tf.random.uniform(maxval=10, shape=(10,), dtype=tf.int32)\n    mnist_train = imgs, labels\n    mnist_test = imgs, labels\n  else:\n    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n\n  def format_example(imgs, labels):\n    imgs = tf.reshape(imgs, [-1, 28 * 28])\n    imgs = tf.cast(imgs, tf.float32) / 255.0\n    labels = tf.one_hot(labels, depth=10, dtype=tf.float32)\n    return imgs, labels\n\n  ds_train = tf.data.Dataset.from_tensor_slices(mnist_train)\n  ds_train = ds_train.shuffle(\n      1000, seed=RAND_SEED).repeat().batch(FLAGS.train_batch_size)\n  ds_train = ds_train.map(format_example)\n  it_train = ds_train.make_initializable_iterator()\n\n  ds_test = tf.data.Dataset.from_tensors(mnist_test).repeat()\n  ds_test = ds_test.map(format_example)\n  it_test = ds_test.make_initializable_iterator()\n\n  sess = tf.InteractiveSession()\n\n  # Create the MNIST neural network graph.\n\n  # Input placeholders.\n  with tf.name_scope(\"input\"):\n    handle = tf.placeholder(tf.string, shape=())\n\n    iterator = tf.data.Iterator.from_string_handle(\n        handle, (tf.float32, tf.float32),\n        ((None, IMAGE_SIZE * IMAGE_SIZE), (None, 10)))\n\n    x, y_ = iterator.get_next()\n\n  def weight_variable(shape):\n    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n    initial = tf.truncated_normal(shape, stddev=0.1, seed=RAND_SEED)\n    return tf.Variable(initial)\n\n  def bias_variable(shape):\n    \"\"\"Create a bias variable with appropriate initialization.\"\"\"\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n    \"\"\"Reusable code for making a simple neural net layer.\"\"\"\n    # Adding a name scope ensures logical grouping of the layers in the graph.\n    with tf.name_scope(layer_name):\n      # This Variable will hold the state of the weights for the layer\n      with tf.name_scope(\"weights\"):\n        weights = weight_variable([input_dim, output_dim])\n      with tf.name_scope(\"biases\"):\n        biases = bias_variable([output_dim])\n      with tf.name_scope(\"Wx_plus_b\"):\n        preactivate = tf.matmul(input_tensor, weights) + biases\n\n      activations = act(preactivate)\n      return activations\n\n  hidden = nn_layer(x, IMAGE_SIZE**2, HIDDEN_SIZE, \"hidden\")\n  logits = nn_layer(hidden, HIDDEN_SIZE, NUM_LABELS, \"output\", tf.identity)\n  y = tf.nn.softmax(logits)\n\n  with tf.name_scope(\"cross_entropy\"):\n    # The following line is the culprit of the bad numerical values that appear\n    # during training of this graph. Log of zero gives inf, which is first seen\n    # in the intermediate tensor \"cross_entropy/Log:0\" during the 4th run()\n    # call. A multiplication of the inf values with zeros leads to nans,\n    # which is first in \"cross_entropy/mul:0\".\n    #\n    # You can use the built-in, numerically-stable implementation to fix this\n    # issue:\n    #   diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits)\n\n    diff = -(y_ * tf.log(y))\n    with tf.name_scope(\"total\"):\n      cross_entropy = tf.reduce_mean(diff)\n\n  with tf.name_scope(\"train\"):\n    train_step = tf.train.AdamOptimizer(\n        FLAGS.learning_rate).minimize(cross_entropy)\n\n  with tf.name_scope(\"accuracy\"):\n    with tf.name_scope(\"correct_prediction\"):\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    with tf.name_scope(\"accuracy\"):\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n  sess.run(tf.global_variables_initializer())\n  sess.run(it_train.initializer)\n  sess.run(it_test.initializer)\n  train_handle = sess.run(it_train.string_handle())\n  test_handle = sess.run(it_test.string_handle())\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  if FLAGS.debug:\n    if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n    else:\n      config_file_path = None\n    sess = tf_debug.LocalCLIDebugWrapperSession(\n        sess, ui_type=FLAGS.ui_type, config_file_path=config_file_path)\n  elif FLAGS.tensorboard_debug_address:\n    sess = tf_debug.TensorBoardDebugWrapperSession(\n        sess, FLAGS.tensorboard_debug_address)\n\n  # Add this point, sess is a debug wrapper around the actual Session if\n  # FLAGS.debug is true. In that case, calling run() will launch the CLI.\n  for i in range(FLAGS.max_steps):\n    acc = sess.run(accuracy, feed_dict={handle: test_handle})\n    print(\"Accuracy at step %d: %s\" % (i, acc))\n\n    sess.run(train_step, feed_dict={handle: train_handle})", "line_changes": {"deleted": [{"line_no": 106, "char_start": 3998, "char_end": 4023, "line": "    config_file_path = (\n"}, {"line_no": 107, "char_start": 4023, "char_end": 4064, "line": "        tempfile.mktemp(\".tfdbg_config\")\n"}, {"line_no": 108, "char_start": 4064, "char_end": 4115, "line": "        if FLAGS.use_random_config_path else None)\n"}], "added": [{"line_no": 106, "char_start": 3998, "char_end": 4035, "line": "    if FLAGS.use_random_config_path:\n"}, {"line_no": 108, "char_start": 4088, "char_end": 4150, "line": "      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n"}, {"line_no": 109, "char_start": 4150, "char_end": 4160, "line": "    else:\n"}, {"line_no": 110, "char_start": 4160, "char_end": 4190, "line": "      config_file_path = None\n"}]}, "char_changes": {"deleted": [{"char_start": 4020, "char_end": 4030, "chars": " (\n       "}, {"char_start": 4068, "char_end": 4092, "chars": "    if FLAGS.use_random_"}, {"char_start": 4104, "char_end": 4108, "chars": "else"}, {"char_start": 4113, "char_end": 4114, "chars": ")"}], "added": [{"char_start": 4002, "char_end": 4097, "chars": "if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, "}, {"char_start": 4127, "char_end": 4128, "chars": "s"}, {"char_start": 4154, "char_end": 4166, "chars": "else:\n      "}, {"char_start": 4173, "char_end": 4178, "chars": "file_"}, {"char_start": 4183, "char_end": 4184, "chars": "="}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/b5150106a7829c45892927562b7eed101581ea95", "file_name": "debug_mnist_v1.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359231\nChange-Id: If2049dbeb46fb8ff6df7c8e077cee8be3872e5b4", "description": "Write a Python TensorFlow script that trains a neural network on the MNIST dataset with options for fake data and debugging."}
{"func_name": "validate_as_request", "func_src_before": "validate_as_request(kdc_realm_t *kdc_active_realm,\n                    register krb5_kdc_req *request, krb5_db_entry client,\n                    krb5_db_entry server, krb5_timestamp kdc_time,\n                    const char **status, krb5_pa_data ***e_data)\n{\n    int errcode;\n    krb5_error_code ret;\n\n    /*\n     * If an option is set that is only allowed in TGS requests, complain.\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KDC_ERR_BADOPTION;\n    }\n\n    /* The client must not be expired */\n    if (client.expiration && client.expiration < kdc_time) {\n        *status = \"CLIENT EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_NAME_EXP);\n    }\n\n    /* The client's password must not be expired, unless the server is\n       a KRB5_KDC_PWCHANGE_SERVICE. */\n    if (client.pw_expiration && client.pw_expiration < kdc_time &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"CLIENT KEY EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_KEY_EXP);\n    }\n\n    /* The server must not be expired */\n    if (server.expiration && server.expiration < kdc_time) {\n        *status = \"SERVICE EXPIRED\";\n        return(KDC_ERR_SERVICE_EXP);\n    }\n\n    /*\n     * If the client requires password changing, then only allow the\n     * pwchange service.\n     */\n    if (isflagset(client.attributes, KRB5_KDB_REQUIRES_PWCHANGE) &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"REQUIRED PWCHANGE\";\n        return(KDC_ERR_KEY_EXP);\n    }\n\n    /* Client and server must allow postdating tickets */\n    if ((isflagset(request->kdc_options, KDC_OPT_ALLOW_POSTDATE) ||\n         isflagset(request->kdc_options, KDC_OPT_POSTDATED)) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_POSTDATED) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_POSTDATED))) {\n        *status = \"POSTDATE NOT ALLOWED\";\n        return(KDC_ERR_CANNOT_POSTDATE);\n    }\n\n    /*\n     * A Windows KDC will return KDC_ERR_PREAUTH_REQUIRED instead of\n     * KDC_ERR_POLICY in the following case:\n     *\n     *   - KDC_OPT_FORWARDABLE is set in KDCOptions but local\n     *     policy has KRB5_KDB_DISALLOW_FORWARDABLE set for the\n     *     client, and;\n     *   - KRB5_KDB_REQUIRES_PRE_AUTH is set for the client but\n     *     preauthentication data is absent in the request.\n     *\n     * Hence, this check most be done after the check for preauth\n     * data, and is now performed by validate_forwardable() (the\n     * contents of which were previously below).\n     */\n\n    /* Client and server must allow proxiable tickets */\n    if (isflagset(request->kdc_options, KDC_OPT_PROXIABLE) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_PROXIABLE) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_PROXIABLE))) {\n        *status = \"PROXIABLE NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Check to see if client is locked out */\n    if (isflagset(client.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"CLIENT LOCKED OUT\";\n        return(KDC_ERR_CLIENT_REVOKED);\n    }\n\n    /* Check to see if server is locked out */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"SERVICE LOCKED OUT\";\n        return(KDC_ERR_S_PRINCIPAL_UNKNOWN);\n    }\n\n    /* Check to see if server is allowed to be a service */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_SVR)) {\n        *status = \"SERVICE NOT ALLOWED\";\n        return(KDC_ERR_MUST_USE_USER2USER);\n    }\n\n    if (check_anon(kdc_active_realm, request->client, request->server) != 0) {\n        *status = \"ANONYMOUS NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Perform KDB module policy checks. */\n    ret = krb5_db_check_policy_as(kdc_context, request, &client, &server,\n                                  kdc_time, status, e_data);\n    if (ret && ret != KRB5_PLUGIN_OP_NOTSUPP)\n        return errcode_to_protocol(ret);\n\n    /* Check against local policy. */\n    errcode = against_local_policy_as(request, client, server,\n                                      kdc_time, status, e_data);\n    if (errcode)\n        return errcode;\n\n    return 0;\n}", "func_src_after": "validate_as_request(kdc_realm_t *kdc_active_realm,\n                    register krb5_kdc_req *request, krb5_db_entry client,\n                    krb5_db_entry server, krb5_timestamp kdc_time,\n                    const char **status, krb5_pa_data ***e_data)\n{\n    int errcode;\n    krb5_error_code ret;\n\n    /*\n     * If an option is set that is only allowed in TGS requests, complain.\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KDC_ERR_BADOPTION;\n    }\n\n    /* The client must not be expired */\n    if (client.expiration && client.expiration < kdc_time) {\n        *status = \"CLIENT EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_NAME_EXP);\n    }\n\n    /* The client's password must not be expired, unless the server is\n       a KRB5_KDC_PWCHANGE_SERVICE. */\n    if (client.pw_expiration && client.pw_expiration < kdc_time &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"CLIENT KEY EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_KEY_EXP);\n    }\n\n    /* The server must not be expired */\n    if (server.expiration && server.expiration < kdc_time) {\n        *status = \"SERVICE EXPIRED\";\n        return(KDC_ERR_SERVICE_EXP);\n    }\n\n    /*\n     * If the client requires password changing, then only allow the\n     * pwchange service.\n     */\n    if (isflagset(client.attributes, KRB5_KDB_REQUIRES_PWCHANGE) &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"REQUIRED PWCHANGE\";\n        return(KDC_ERR_KEY_EXP);\n    }\n\n    /* Client and server must allow postdating tickets */\n    if ((isflagset(request->kdc_options, KDC_OPT_ALLOW_POSTDATE) ||\n         isflagset(request->kdc_options, KDC_OPT_POSTDATED)) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_POSTDATED) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_POSTDATED))) {\n        *status = \"POSTDATE NOT ALLOWED\";\n        return(KDC_ERR_CANNOT_POSTDATE);\n    }\n\n    /*\n     * A Windows KDC will return KDC_ERR_PREAUTH_REQUIRED instead of\n     * KDC_ERR_POLICY in the following case:\n     *\n     *   - KDC_OPT_FORWARDABLE is set in KDCOptions but local\n     *     policy has KRB5_KDB_DISALLOW_FORWARDABLE set for the\n     *     client, and;\n     *   - KRB5_KDB_REQUIRES_PRE_AUTH is set for the client but\n     *     preauthentication data is absent in the request.\n     *\n     * Hence, this check most be done after the check for preauth\n     * data, and is now performed by validate_forwardable() (the\n     * contents of which were previously below).\n     */\n\n    /* Client and server must allow proxiable tickets */\n    if (isflagset(request->kdc_options, KDC_OPT_PROXIABLE) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_PROXIABLE) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_PROXIABLE))) {\n        *status = \"PROXIABLE NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Check to see if client is locked out */\n    if (isflagset(client.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"CLIENT LOCKED OUT\";\n        return(KDC_ERR_CLIENT_REVOKED);\n    }\n\n    /* Check to see if server is locked out */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"SERVICE LOCKED OUT\";\n        return(KDC_ERR_S_PRINCIPAL_UNKNOWN);\n    }\n\n    /* Check to see if server is allowed to be a service */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_SVR)) {\n        *status = \"SERVICE NOT ALLOWED\";\n        return(KDC_ERR_MUST_USE_USER2USER);\n    }\n\n    if (check_anon(kdc_active_realm, client.princ, request->server) != 0) {\n        *status = \"ANONYMOUS NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Perform KDB module policy checks. */\n    ret = krb5_db_check_policy_as(kdc_context, request, &client, &server,\n                                  kdc_time, status, e_data);\n    if (ret && ret != KRB5_PLUGIN_OP_NOTSUPP)\n        return errcode_to_protocol(ret);\n\n    /* Check against local policy. */\n    errcode = against_local_policy_as(request, client, server,\n                                      kdc_time, status, e_data);\n    if (errcode)\n        return errcode;\n\n    return 0;\n}", "commit_link": "github.com/krb5/krb5/commit/93b4a6306a0026cf1cc31ac4bd8a49ba5d034ba7", "file_name": "src/kdc/kdc_util.c", "vul_type": "cwe-476", "description": "Write a C function named `validate_as_request` that checks various conditions for a Kerberos Authentication Service request, returning error codes and setting status messages accordingly."}
{"func_name": "tar_directory_for_file", "func_src_before": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t\tdir = GSF_INFILE_TAR (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "func_src_after": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\tdir = GSF_IS_INFILE_TAR (subdir)\n\t\t\t\t\t? GSF_INFILE_TAR (subdir)\n\t\t\t\t\t: dir;\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "commit_link": "github.com/GNOME/libgsf/commit/95a8351a75758cf10b3bf6abae0b6b461f90d9e5", "file_name": "gsf/gsf-infile-tar.c", "vul_type": "cwe-476", "description": "Write a C function to navigate or create directories within a TAR file based on a given path."}
{"func_name": "patch", "func_src_before": "    @jwt_required\n    def patch(self, user_id):\n        \"\"\" Replaces information of corresponding user_id with request body \"\"\"\n        query = f\"\"\"update users set user_id = %s \"\"\"\n        query += f\"\"\"where user_id = '{user_id}'\"\"\"\n        json_data = request.get_json()\n        parameters = (json_data['user_id'], )\n        database_utilities.execute_query(query, parameters)", "func_src_after": "    @jwt_required\n    def patch(self, user_id):\n        \"\"\" Replaces information of corresponding user_id with request body \"\"\"\n        query = f\"\"\"update users set user_id = %s \"\"\"\n        query += f\"\"\"where user_id = %s\"\"\"\n        json_data = request.get_json()\n        parameters = (json_data['user_id'], user_id)\n        database_utilities.execute_query(query, parameters)", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's ID in the database using JWT authentication and the user's ID from the request body."}
{"func_name": "mergeConfig", "func_src_before": "function mergeConfig(from, to) {\n\tfor (var f in from) {\n\t\tif (_.isObject(from[f])) {\n\t\t\tif (!_.isObject(to[f])) {\n\t\t\t\tto[f] = from[f];\n\t\t\t} else {\n\t\t\t\tmergeConfig(from[f], to[f]);\n\t\t\t}\n\t\t} else {\n\t\t\tto[f] = from[f];\n\t\t}\n\t}\n}", "func_src_after": "function mergeConfig(from, to) {\n\tfor (var f in from) {\n\t\tif (Object.prototype.hasOwnProperty.call(from, f)) {\n\t\t\tif (Object.prototype.hasOwnProperty.call(to, f) && _.isObject(from[f])) {\n\t\t\t\tif (!_.isObject(to[f])) {\n\t\t\t\t\tto[f] = from[f];\n\t\t\t\t} else {\n\t\t\t\t\tmergeConfig(from[f], to[f]);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tto[f] = from[f];\n\t\t\t}\n\t\t}\n\t}\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 56, "char_end": 85, "line": "\t\tif (_.isObject(from[f])) {\n"}, {"line_no": 4, "char_start": 85, "char_end": 114, "line": "\t\t\tif (!_.isObject(to[f])) {\n"}, {"line_no": 5, "char_start": 114, "char_end": 135, "line": "\t\t\t\tto[f] = from[f];\n"}, {"line_no": 7, "char_start": 147, "char_end": 180, "line": "\t\t\t\tmergeConfig(from[f], to[f]);\n"}, {"line_no": 9, "char_start": 185, "char_end": 196, "line": "\t\t} else {\n"}, {"line_no": 10, "char_start": 196, "char_end": 216, "line": "\t\t\tto[f] = from[f];\n"}], "added": [{"line_no": 3, "char_start": 56, "char_end": 111, "line": "\t\tif (Object.prototype.hasOwnProperty.call(from, f)) {\n"}, {"line_no": 4, "char_start": 111, "char_end": 188, "line": "\t\t\tif (Object.prototype.hasOwnProperty.call(to, f) && _.isObject(from[f])) {\n"}, {"line_no": 5, "char_start": 188, "char_end": 218, "line": "\t\t\t\tif (!_.isObject(to[f])) {\n"}, {"line_no": 6, "char_start": 218, "char_end": 240, "line": "\t\t\t\t\tto[f] = from[f];\n"}, {"line_no": 7, "char_start": 240, "char_end": 253, "line": "\t\t\t\t} else {\n"}, {"line_no": 8, "char_start": 253, "char_end": 287, "line": "\t\t\t\t\tmergeConfig(from[f], to[f]);\n"}, {"line_no": 9, "char_start": 287, "char_end": 293, "line": "\t\t\t\t}\n"}, {"line_no": 11, "char_start": 305, "char_end": 326, "line": "\t\t\t\tto[f] = from[f];\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 62, "char_end": 165, "chars": "Object.prototype.hasOwnProperty.call(from, f)) {\n\t\t\tif (Object.prototype.hasOwnProperty.call(to, f) && "}, {"char_start": 188, "char_end": 189, "chars": "\t"}, {"char_start": 218, "char_end": 219, "chars": "\t"}, {"char_start": 243, "char_end": 244, "chars": "\t"}, {"char_start": 253, "char_end": 254, "chars": "\t"}, {"char_start": 287, "char_end": 288, "chars": "\t"}, {"char_start": 295, "char_end": 296, "chars": "\t"}, {"char_start": 305, "char_end": 306, "chars": "\t"}, {"char_start": 326, "char_end": 331, "chars": "\t\t\t}\n"}]}, "commit_link": "github.com/jkphl/svg-sprite/commit/1ba7f04ed4f4798112aa612b7b2e6367fcb7e8c2", "file_name": "svg-sprite.js", "vul_type": "cwe-915", "commit_msg": "Fix prototype pollution issue (#392)", "parent_commit": "1724f4c0b2b923c4dd1a1d75e00647f5f7fae0c6", "description": "Write a JavaScript function named `mergeConfig` that recursively merges properties from one object into another."}
{"func_name": "download_check_files", "func_src_before": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            if '/../' in f:\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "func_src_after": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            # don't allow to traverse up in the file system\n            if '/../' in f or f.startswith('../'):\n                return 'invalid_file'\n            # CVE-2015-8309: do not allow absolute file paths\n            if os.path.isabs(f):\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "commit_link": "github.com/devsnd/cherrymusic/commit/62dec34a1ea0741400dd6b6c660d303dcd651e86", "file_name": "cherrymusicserver/httphandler.py", "vul_type": "cwe-022", "description": "Write a Python function named `download_check_files` that validates a list of file paths for download permissions, path security, and size constraints."}
{"func_name": "article", "func_src_before": "  def article\n    @article = Article.find(params[:id])\n    @feedbacks = Feedback.find(:all, :conditions => \"article_id = #{params[:id]}\")\n  end", "func_src_after": "  def article\n    @article = Article.find(params[:id])\n    @feedbacks = Feedback.find(:all, :conditions => {:article_id => params[:id]})\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 55, "char_end": 138, "line": "    @feedbacks = Feedback.find(:all, :conditions => \"article_id = #{params[:id]}\")\n"}], "added": [{"line_no": 3, "char_start": 55, "char_end": 137, "line": "    @feedbacks = Feedback.find(:all, :conditions => {:article_id => params[:id]})\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 108, "chars": "\""}, {"char_start": 121, "char_end": 123, "chars": "#{"}, {"char_start": 135, "char_end": 136, "chars": "\""}], "added": [{"char_start": 107, "char_end": 109, "chars": "{:"}, {"char_start": 121, "char_end": 122, "chars": ">"}]}, "commit_link": "github.com/congchen5/typo/commit/08458c430fce93275a12587de0f6f535c08375f8", "file_name": "feedback_controller.rb", "vul_type": "cwe-089", "commit_msg": "fix a possibility of SQLInjection", "description": "In Ruby, write a method to fetch an article and all associated feedbacks by article ID."}
{"func_name": "(anonymous)", "func_src_before": "        .then(()=>tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))", "func_src_after": "        .then(() => tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 121, "line": "        .then(()=>tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))\n"}], "added": []}, "char_changes": {"deleted": [], "added": [{"char_start": 16, "char_end": 17, "chars": " "}, {"char_start": 19, "char_end": 20, "chars": " "}]}, "commit_link": "github.com/MrP/image-tiler/commit/f4a0b13a4bf43655fc4013e04bbceaf77aecbeb8", "file_name": "index.js", "vul_type": "cwe-078", "commit_msg": "fix command injection vuln", "description": "Write a JavaScript function that processes images into tiles with customizable options."}
{"func_name": "PHP_MINIT_FUNCTION", "func_src_before": "static PHP_MINIT_FUNCTION(zip)\n{\n#ifdef PHP_ZIP_USE_OO\n\tzend_class_entry ce;\n\n\tmemcpy(&zip_object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\tzip_object_handlers.clone_obj\t\t= NULL;\n\tzip_object_handlers.get_property_ptr_ptr = php_zip_get_property_ptr_ptr;\n\n\tzip_object_handlers.get_gc          = php_zip_get_gc;\n\tzip_object_handlers.get_properties = php_zip_get_properties;\n\tzip_object_handlers.read_property\t= php_zip_read_property;\n\tzip_object_handlers.has_property\t= php_zip_has_property;\n\n\tINIT_CLASS_ENTRY(ce, \"ZipArchive\", zip_class_functions);\n\tce.create_object = php_zip_object_new;\n\tzip_class_entry = zend_register_internal_class(&ce TSRMLS_CC);\n\n\tzend_hash_init(&zip_prop_handlers, 0, NULL, NULL, 1);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"status\",    php_zip_status, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"statusSys\", php_zip_status_sys, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"numFiles\",  php_zip_get_num_files, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"filename\", NULL, NULL, php_zipobj_get_filename, IS_STRING TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"comment\", NULL, php_zipobj_get_zip_comment, NULL, IS_STRING TSRMLS_CC);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CREATE\", ZIP_CREATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"EXCL\", ZIP_EXCL);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CHECKCONS\", ZIP_CHECKCONS);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"OVERWRITE\", ZIP_OVERWRITE);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NOCASE\", ZIP_FL_NOCASE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NODIR\", ZIP_FL_NODIR);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_COMPRESSED\", ZIP_FL_COMPRESSED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_UNCHANGED\", ZIP_FL_UNCHANGED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFAULT\", ZIP_CM_DEFAULT);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_STORE\", ZIP_CM_STORE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_SHRINK\", ZIP_CM_SHRINK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_1\", ZIP_CM_REDUCE_1);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_2\", ZIP_CM_REDUCE_2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_3\", ZIP_CM_REDUCE_3);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_4\", ZIP_CM_REDUCE_4);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_IMPLODE\", ZIP_CM_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE\", ZIP_CM_DEFLATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE64\", ZIP_CM_DEFLATE64);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PKWARE_IMPLODE\", ZIP_CM_PKWARE_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_BZIP2\", ZIP_CM_BZIP2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZMA\", ZIP_CM_LZMA);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_TERSE\", ZIP_CM_TERSE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZ77\", ZIP_CM_LZ77);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_WAVPACK\", ZIP_CM_WAVPACK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PPMD\", ZIP_CM_PPMD);\n\n\t/* Error code */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OK\",\t\t\tZIP_ER_OK);\t\t\t/* N No error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MULTIDISK\",\tZIP_ER_MULTIDISK);\t/* N Multi-disk zip archives not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_RENAME\",\t\tZIP_ER_RENAME);\t\t/* S Renaming temporary file failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CLOSE\",\t\tZIP_ER_CLOSE);\t\t/* S Closing zip archive failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_SEEK\",\t\tZIP_ER_SEEK);\t\t/* S Seek error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_READ\",\t\tZIP_ER_READ);\t\t/* S Read error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_WRITE\",\t\tZIP_ER_WRITE);\t\t/* S Write error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CRC\",\t\t\tZIP_ER_CRC);\t\t/* N CRC error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZIPCLOSED\",\tZIP_ER_ZIPCLOSED);\t/* N Containing zip archive was closed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOENT\",\t\tZIP_ER_NOENT);\t\t/* N No such file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EXISTS\",\t\tZIP_ER_EXISTS);\t\t/* N File already exists */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OPEN\",\t\tZIP_ER_OPEN);\t\t/* S Can't open file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_TMPOPEN\",\t\tZIP_ER_TMPOPEN);\t/* S Failure to create temporary file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZLIB\",\t\tZIP_ER_ZLIB);\t\t/* Z Zlib error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MEMORY\",\t\tZIP_ER_MEMORY);\t\t/* N Malloc failure */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CHANGED\",\t\tZIP_ER_CHANGED);\t/* N Entry has been changed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_COMPNOTSUPP\",\tZIP_ER_COMPNOTSUPP);/* N Compression method not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EOF\",\t\t\tZIP_ER_EOF);\t\t/* N Premature EOF */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INVAL\",\t\tZIP_ER_INVAL);\t\t/* N Invalid argument */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOZIP\",\t\tZIP_ER_NOZIP);\t\t/* N Not a zip archive */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INTERNAL\",\tZIP_ER_INTERNAL);\t/* N Internal error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INCONS\",\t\tZIP_ER_INCONS);\t\t/* N Zip archive inconsistent */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_REMOVE\",\t\tZIP_ER_REMOVE);\t\t/* S Can't remove file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_DELETED\",  \tZIP_ER_DELETED);\t/* N Entry has been deleted */\n\n\tphp_register_url_stream_wrapper(\"zip\", &php_stream_zip_wrapper TSRMLS_CC);\n#endif\n\n\tle_zip_dir   = zend_register_list_destructors_ex(php_zip_free_dir,   NULL, le_zip_dir_name,   module_number);\n\tle_zip_entry = zend_register_list_destructors_ex(php_zip_free_entry, NULL, le_zip_entry_name, module_number);\n\n\treturn SUCCESS;\n}", "func_src_after": "static PHP_MINIT_FUNCTION(zip)\n{\n#ifdef PHP_ZIP_USE_OO\n\tzend_class_entry ce;\n\n\tmemcpy(&zip_object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\tzip_object_handlers.clone_obj\t\t= NULL;\n\tzip_object_handlers.get_property_ptr_ptr = php_zip_get_property_ptr_ptr;\n\n\tzip_object_handlers.get_gc          = php_zip_get_gc;\n\tzip_object_handlers.get_properties = php_zip_get_properties;\n\tzip_object_handlers.read_property\t= php_zip_read_property;\n\tzip_object_handlers.has_property\t= php_zip_has_property;\n\n\tINIT_CLASS_ENTRY(ce, \"ZipArchive\", zip_class_functions);\n\tce.create_object = php_zip_object_new;\n\tzip_class_entry = zend_register_internal_class(&ce TSRMLS_CC);\n\n\tzend_hash_init(&zip_prop_handlers, 0, NULL, NULL, 1);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"status\",    php_zip_status, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"statusSys\", php_zip_status_sys, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"numFiles\",  php_zip_get_num_files, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"filename\", NULL, NULL, php_zipobj_get_filename, IS_STRING TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"comment\", NULL, php_zipobj_get_zip_comment, NULL, IS_STRING TSRMLS_CC);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CREATE\", ZIP_CREATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"EXCL\", ZIP_EXCL);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CHECKCONS\", ZIP_CHECKCONS);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"OVERWRITE\", ZIP_OVERWRITE);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NOCASE\", ZIP_FL_NOCASE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NODIR\", ZIP_FL_NODIR);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_COMPRESSED\", ZIP_FL_COMPRESSED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_UNCHANGED\", ZIP_FL_UNCHANGED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFAULT\", ZIP_CM_DEFAULT);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_STORE\", ZIP_CM_STORE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_SHRINK\", ZIP_CM_SHRINK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_1\", ZIP_CM_REDUCE_1);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_2\", ZIP_CM_REDUCE_2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_3\", ZIP_CM_REDUCE_3);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_4\", ZIP_CM_REDUCE_4);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_IMPLODE\", ZIP_CM_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE\", ZIP_CM_DEFLATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE64\", ZIP_CM_DEFLATE64);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PKWARE_IMPLODE\", ZIP_CM_PKWARE_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_BZIP2\", ZIP_CM_BZIP2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZMA\", ZIP_CM_LZMA);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_TERSE\", ZIP_CM_TERSE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZ77\", ZIP_CM_LZ77);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_WAVPACK\", ZIP_CM_WAVPACK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PPMD\", ZIP_CM_PPMD);\n\n\t/* Error code */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OK\",\t\t\tZIP_ER_OK);\t\t\t/* N No error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MULTIDISK\",\tZIP_ER_MULTIDISK);\t/* N Multi-disk zip archives not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_RENAME\",\t\tZIP_ER_RENAME);\t\t/* S Renaming temporary file failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CLOSE\",\t\tZIP_ER_CLOSE);\t\t/* S Closing zip archive failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_SEEK\",\t\tZIP_ER_SEEK);\t\t/* S Seek error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_READ\",\t\tZIP_ER_READ);\t\t/* S Read error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_WRITE\",\t\tZIP_ER_WRITE);\t\t/* S Write error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CRC\",\t\t\tZIP_ER_CRC);\t\t/* N CRC error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZIPCLOSED\",\tZIP_ER_ZIPCLOSED);\t/* N Containing zip archive was closed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOENT\",\t\tZIP_ER_NOENT);\t\t/* N No such file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EXISTS\",\t\tZIP_ER_EXISTS);\t\t/* N File already exists */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OPEN\",\t\tZIP_ER_OPEN);\t\t/* S Can't open file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_TMPOPEN\",\t\tZIP_ER_TMPOPEN);\t/* S Failure to create temporary file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZLIB\",\t\tZIP_ER_ZLIB);\t\t/* Z Zlib error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MEMORY\",\t\tZIP_ER_MEMORY);\t\t/* N Malloc failure */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CHANGED\",\t\tZIP_ER_CHANGED);\t/* N Entry has been changed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_COMPNOTSUPP\",\tZIP_ER_COMPNOTSUPP);/* N Compression method not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EOF\",\t\t\tZIP_ER_EOF);\t\t/* N Premature EOF */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INVAL\",\t\tZIP_ER_INVAL);\t\t/* N Invalid argument */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOZIP\",\t\tZIP_ER_NOZIP);\t\t/* N Not a zip archive */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INTERNAL\",\tZIP_ER_INTERNAL);\t/* N Internal error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INCONS\",\t\tZIP_ER_INCONS);\t\t/* N Zip archive inconsistent */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_REMOVE\",\t\tZIP_ER_REMOVE);\t\t/* S Can't remove file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_DELETED\",  \tZIP_ER_DELETED);\t/* N Entry has been deleted */\n\n\tphp_register_url_stream_wrapper(\"zip\", &php_stream_zip_wrapper TSRMLS_CC);\n#endif\n\n\tle_zip_dir   = zend_register_list_destructors_ex(php_zip_free_dir,   NULL, le_zip_dir_name,   module_number);\n\tle_zip_entry = zend_register_list_destructors_ex(php_zip_free_entry, NULL, le_zip_entry_name, module_number);\n\n\treturn SUCCESS;\n}", "commit_link": "github.com/php/php-src/commit/f6aef68089221c5ea047d4a74224ee3deead99a6?w=1", "file_name": "ext/zip/php_zip.c", "vul_type": "cwe-416", "description": "Write a PHP function to initialize the Zip extension with object-oriented features and resource destructors."}
{"func_name": "get", "func_src_before": "    def get(self, path):\n        return static_file(path, self.get_base_path())", "func_src_after": "    def get(self, path):\n        path = self.sanitize_path(path)\n        base_paths = self.get_base_paths()\n        if hasattr(base_paths, 'split'):\n            # String, so go simple\n            base_path = base_paths\n        else:\n            base_path = self.get_first_base(base_paths, path)\n        return static_file(path, base_path)", "commit_link": "github.com/foxbunny/seagull/commit/1fb790712fe0c1d1957b31e34a8e0e6593af87a7", "file_name": "seagull/routes/app.py", "vul_type": "cwe-022", "description": "Write a Python function named `get` that retrieves a static file from a base path, which may involve sanitizing the path and handling multiple base paths."}
{"func_name": "handle_json", "func_src_before": "@socketio.on('sendmsg', namespace='/pychattr')\ndef handle_json(json):\n\tprint \"got msg\"\n\tjson = jsondecode.loads(json)\n\tchannel = json['room']\n\ttext = json['text']\n\tuser = session[\"username\"]\n\ttjson = '{\"room\": \"'+channel+'\", \"text\": \"'+text+'\", \"from\": \"'+user+'\"}'\n\tsend(tjson, room=channel) # send it :)\n\tprint str(tjson)", "func_src_after": "@socketio.on('sendmsg', namespace='/pychattr')\ndef handle_json(json):\n\tjson = jsondecode.loads(json)\n\tchannel = json['room']\n\ttext = json['text']\n\ttext = text.translate(None, '}{<>') #antiXSS\n\ttext = text.replace(\"'\", \"\\'\")\n\ttext = text.replace('\"', '\\\"')\n\tuser = session[\"username\"]\n\ttjson = '{\"room\": \"'+channel+'\", \"text\": \"'+text+'\", \"from\": \"'+user+'\"}'\n\tsend(tjson, room=channel) # send it :)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 70, "char_end": 87, "line": "\tprint \"got msg\"\n"}, {"line_no": 10, "char_start": 306, "char_end": 323, "line": "\tprint str(tjson)\n"}], "added": [{"line_no": 6, "char_start": 146, "char_end": 192, "line": "\ttext = text.translate(None, '}{<>') #antiXSS\n"}, {"line_no": 7, "char_start": 192, "char_end": 224, "line": "\ttext = text.replace(\"'\", \"\\'\")\n"}, {"line_no": 8, "char_start": 224, "char_end": 256, "line": "\ttext = text.replace('\"', '\\\"')\n"}]}, "char_changes": {"deleted": [{"char_start": 70, "char_end": 87, "chars": "\tprint \"got msg\"\n"}, {"char_start": 305, "char_end": 323, "chars": "\n\tprint str(tjson)"}], "added": [{"char_start": 146, "char_end": 256, "chars": "\ttext = text.translate(None, '}{<>') #antiXSS\n\ttext = text.replace(\"'\", \"\\'\")\n\ttext = text.replace('\"', '\\\"')\n"}]}, "commit_link": "github.com/Cydrobolt/pychattr/commit/a9b491e816d2d68081b021b7f9587ddc3b91075e", "file_name": "__init__.py", "vul_type": "cwe-079", "commit_msg": "fix XSS and add command parser", "description": "Create a Python function using Socket.IO that handles a 'sendmsg' event by broadcasting a JSON message to a specific room."}
{"func_name": "get_last_active_users", "func_src_before": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "func_src_after": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch a specified number of the most recent active bot users from a database."}
{"func_name": "rfcomm_sock_bind", "func_src_before": "static int rfcomm_sock_bind(struct socket *sock, struct sockaddr *addr, int addr_len)\n{\n\tstruct sockaddr_rc *sa = (struct sockaddr_rc *) addr;\n\tstruct sock *sk = sock->sk;\n\tint chan = sa->rc_channel;\n\tint err = 0;\n\n\tBT_DBG(\"sk %p %pMR\", sk, &sa->rc_bdaddr);\n\n\tif (!addr || addr->sa_family != AF_BLUETOOTH)\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\n\tif (sk->sk_state != BT_OPEN) {\n\t\terr = -EBADFD;\n\t\tgoto done;\n\t}\n\n\tif (sk->sk_type != SOCK_STREAM) {\n\t\terr = -EINVAL;\n\t\tgoto done;\n\t}\n\n\twrite_lock(&rfcomm_sk_list.lock);\n\n\tif (chan && __rfcomm_get_listen_sock_by_addr(chan, &sa->rc_bdaddr)) {\n\t\terr = -EADDRINUSE;\n\t} else {\n\t\t/* Save source address */\n\t\tbacpy(&rfcomm_pi(sk)->src, &sa->rc_bdaddr);\n\t\trfcomm_pi(sk)->channel = chan;\n\t\tsk->sk_state = BT_BOUND;\n\t}\n\n\twrite_unlock(&rfcomm_sk_list.lock);\n\ndone:\n\trelease_sock(sk);\n\treturn err;\n}", "func_src_after": "static int rfcomm_sock_bind(struct socket *sock, struct sockaddr *addr, int addr_len)\n{\n\tstruct sockaddr_rc sa;\n\tstruct sock *sk = sock->sk;\n\tint len, err = 0;\n\n\tif (!addr || addr->sa_family != AF_BLUETOOTH)\n\t\treturn -EINVAL;\n\n\tmemset(&sa, 0, sizeof(sa));\n\tlen = min_t(unsigned int, sizeof(sa), addr_len);\n\tmemcpy(&sa, addr, len);\n\n\tBT_DBG(\"sk %p %pMR\", sk, &sa.rc_bdaddr);\n\n\tlock_sock(sk);\n\n\tif (sk->sk_state != BT_OPEN) {\n\t\terr = -EBADFD;\n\t\tgoto done;\n\t}\n\n\tif (sk->sk_type != SOCK_STREAM) {\n\t\terr = -EINVAL;\n\t\tgoto done;\n\t}\n\n\twrite_lock(&rfcomm_sk_list.lock);\n\n\tif (sa.rc_channel &&\n\t    __rfcomm_get_listen_sock_by_addr(sa.rc_channel, &sa.rc_bdaddr)) {\n\t\terr = -EADDRINUSE;\n\t} else {\n\t\t/* Save source address */\n\t\tbacpy(&rfcomm_pi(sk)->src, &sa.rc_bdaddr);\n\t\trfcomm_pi(sk)->channel = sa.rc_channel;\n\t\tsk->sk_state = BT_BOUND;\n\t}\n\n\twrite_unlock(&rfcomm_sk_list.lock);\n\ndone:\n\trelease_sock(sk);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/951b6a0717db97ce420547222647bcc40bf1eacd", "file_name": "net/bluetooth/rfcomm/sock.c", "vul_type": "cwe-476", "description": "Write a C function for binding an RFCOMM Bluetooth socket to an address."}
{"func_name": "tflite::ops::builtin::segment_sum::ResizeOutputTensor", "func_src_before": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  int max_index = -1;\n  const int segment_id_size = segment_ids->dims->data[0];\n  if (segment_id_size > 0) {\n    max_index = segment_ids->data.i32[segment_id_size - 1];\n  }\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}", "func_src_after": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  // Segment ids should be of same cardinality as first input dimension and they\n  // should be increasing by at most 1, from 0 (e.g., [0, 0, 1, 2, 3] is valid)\n  const int segment_id_size = segment_ids->dims->data[0];\n  TF_LITE_ENSURE_EQ(context, segment_id_size, data->dims->data[0]);\n  int previous_segment_id = -1;\n  for (int i = 0; i < segment_id_size; i++) {\n    const int current_segment_id = GetTensorData<int32_t>(segment_ids)[i];\n    if (i == 0) {\n      TF_LITE_ENSURE_EQ(context, current_segment_id, 0);\n    } else {\n      int delta = current_segment_id - previous_segment_id;\n      TF_LITE_ENSURE(context, delta == 0 || delta == 1);\n    }\n    previous_segment_id = current_segment_id;\n  }\n\n  const int max_index = previous_segment_id;\n\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/204945b19e44b57906c9344c0d00120eeeae178a", "file_name": "tensorflow/lite/kernels/segment_sum.cc", "vul_type": "cwe-787", "description": "Write a C++ function to resize an output tensor based on segment IDs in TensorFlow Lite."}
{"func_name": "get_git_branch", "func_src_before": "get_git_branch(wchar_t *dst, size_t size)\n{\n\tFILE *fp;\n\tchar *c;\n\tchar pwd[MAXPATHLEN];\n\tchar candidate[MAXPATHLEN];\n\tchar buf[MAX_BRANCH_LEN];\n\tsize_t s;\n\tstruct stat bufstat;\n\tint found_repo = -1;\n\n\t/* start from the working dir */\n\tstrlcpy(pwd, getcwd(NULL, MAXPATHLEN), MAXPATHLEN);\n\n\tdo {\n\t\tsnprintf(candidate, MAXPATHLEN, \"%s/.git/HEAD\", pwd);\n\n\t\tfound_repo = stat(candidate, &bufstat);\n\n\t\tif ((c = strrchr(pwd, '/')) == NULL)\n\t\t\tbreak;\n\n\t\t*c = '\\0';\n\t} while (found_repo != 0 && candidate[1] != '\\0');\n\n\tif (found_repo == -1)\n\t\treturn 0;\n\n\tfp = fopen(candidate, \"r\");\n\tif (fp == NULL) {\n\t\tstrlcpy(buf, \"###\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\ts = fread(buf, 1, size, fp);\n\tfclose(fp);\n\n\tbuf[MAX_BRANCH_LEN] = '\\0';\n\n\t/* This is a branch head, just print the branch. */\n\tif (strncmp(buf, \"ref: refs/heads/\", 16) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl)\n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 16;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* Show all other kinds of ref as-is (does it even exist?) */\n\tif (strncmp(buf, \"ref:\", 4) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl) \n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 5;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* That's probably just a changeset, just show the first 6 chars */\n\tif (s > 6) {\n\t\tstrlcpy(buf + 6, \"...\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\t/* We shouldn't get there, but we mind as well no crash. */\n\tstrlcpy(buf, \"???\", 4);\n\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n}", "func_src_after": "get_git_branch(wchar_t *dst, size_t size)\n{\n\tFILE *fp;\n\tchar *c;\n\tchar pwd[MAXPATHLEN];\n\tchar candidate[MAXPATHLEN];\n\tchar buf[MAX_BRANCH_LEN];\n\tsize_t s;\n\tstruct stat bufstat;\n\tint found_repo = -1;\n\n\t/* start from the working dir */\n\tstrlcpy(pwd, getcwd(NULL, MAXPATHLEN), MAXPATHLEN);\n\n\tdo {\n\t\tsnprintf(candidate, MAXPATHLEN, \"%s/.git/HEAD\", pwd);\n\n\t\tfound_repo = stat(candidate, &bufstat);\n\n\t\tif ((c = strrchr(pwd, '/')) == NULL)\n\t\t\tbreak;\n\n\t\t*c = '\\0';\n\t} while (found_repo != 0 && candidate[1] != '\\0');\n\n\tif (found_repo == -1)\n\t\treturn 0;\n\n\tfp = fopen(candidate, \"r\");\n\tif (fp == NULL) {\n\t\tstrlcpy(buf, \"###\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\ts = fread(buf, 1, size, fp);\n\tfclose(fp);\n\n\tbuf[MAX_BRANCH_LEN - 1] = '\\0';\n\n\t/* This is a branch head, just print the branch. */\n\tif (strncmp(buf, \"ref: refs/heads/\", 16) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl)\n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 16;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* Show all other kinds of ref as-is (does it even exist?) */\n\tif (strncmp(buf, \"ref:\", 4) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl) \n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 5;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* That's probably just a changeset, just show the first 6 chars */\n\tif (s > 6) {\n\t\tstrlcpy(buf + 6, \"...\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\t/* We shouldn't get there, but we mind as well no crash. */\n\tstrlcpy(buf, \"???\", 4);\n\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n}", "line_changes": {"deleted": [{"line_no": 38, "char_start": 713, "char_end": 742, "line": "\tbuf[MAX_BRANCH_LEN] = '\\0';\n"}], "added": [{"line_no": 38, "char_start": 713, "char_end": 746, "line": "\tbuf[MAX_BRANCH_LEN - 1] = '\\0';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 732, "char_end": 736, "chars": " - 1"}]}, "commit_link": "github.com/tamentis/prwd/commit/2bf86717a20334c40d168ad968b863f0ab7fd8c5", "file_name": "main.c", "vul_type": "cwe-119", "commit_msg": "fix a buffer overflow", "parent_commit": "62dd9d1df4b4028e843964f7a2da96c89ee1f4de", "description": "Write a C function to determine the current Git branch name and copy it into a wide character string buffer."}
{"func_name": "DefaultArchiveExtractor::extract", "func_src_before": "    @Override\n    public void extract(String archive, String destinationDirectory) throws ArchiveExtractionException {\n        final File archiveFile = new File(archive);\n\n        try (FileInputStream fis = new FileInputStream(archiveFile)) {\n            if (\"msi\".equals(FileUtils.getExtension(archiveFile.getAbsolutePath()))) {\n                String command = \"msiexec /a \" + archiveFile.getAbsolutePath() + \" /qn TARGETDIR=\\\"\"\n                        + destinationDirectory + \"\\\"\";\n                Process child = Runtime.getRuntime().exec(command);\n                try {\n                    int result = child.waitFor();\n                    if (result != 0) {\n                        throw new ArchiveExtractionException(\n                                \"Could not extract \" + archiveFile.getAbsolutePath() + \"; return code \" + result);\n                    }\n                } catch (InterruptedException e) {\n                    throw new ArchiveExtractionException(\n                            \"Unexpected interruption of while waiting for extraction process\", e);\n                }\n            } else if (\"zip\".equals(FileUtils.getExtension(archiveFile.getAbsolutePath()))) {\n                ZipFile zipFile = new ZipFile(archiveFile);\n                try {\n                    Enumeration<? extends ZipEntry> entries = zipFile.entries();\n                    while (entries.hasMoreElements()) {\n                        ZipEntry entry = entries.nextElement();\n                        final File destPath = new File(destinationDirectory + File.separator + entry.getName());\n                        prepDestination(destPath, entry.isDirectory());\n                        if (!entry.isDirectory()) {\n                            InputStream in = null;\n                            OutputStream out = null;\n                            try {\n                                in = zipFile.getInputStream(entry);\n                                out = new FileOutputStream(destPath);\n                                IOUtils.copy(in, out);\n                            } finally {\n                                IOUtils.closeQuietly(in);\n                                IOUtils.closeQuietly(out);\n                            }\n                        }\n                    }\n                } finally {\n                    zipFile.close();\n                }\n            } else {\n                // TarArchiveInputStream can be constructed with a normal FileInputStream if\n                // we ever need to extract regular '.tar' files.\n                TarArchiveInputStream tarIn = null;\n                try {\n                    tarIn = new TarArchiveInputStream(new GzipCompressorInputStream(fis));\n\n                    TarArchiveEntry tarEntry = tarIn.getNextTarEntry();\n                    String canonicalDestinationDirectory = new File(destinationDirectory).getCanonicalPath();\n                    while (tarEntry != null) {\n                        // Create a file for this tarEntry\n                        final File destPath = new File(destinationDirectory + File.separator + tarEntry.getName());\n                        prepDestination(destPath, tarEntry.isDirectory());\n\n                        if (!startsWithPath(destPath.getCanonicalPath(), canonicalDestinationDirectory)) {\n                            throw new IOException(\n                                    \"Expanding \" + tarEntry.getName() + \" would create file outside of \" + canonicalDestinationDirectory\n                            );\n                        }\n\n                        if (!tarEntry.isDirectory()) {\n                            destPath.createNewFile();\n                            boolean isExecutable = (tarEntry.getMode() & 0100) > 0;\n                            destPath.setExecutable(isExecutable);\n\n                            OutputStream out = null;\n                            try {\n                                out = new FileOutputStream(destPath);\n                                IOUtils.copy(tarIn, out);\n                            } finally {\n                                IOUtils.closeQuietly(out);\n                            }\n                        }\n                        tarEntry = tarIn.getNextTarEntry();\n                    }\n                } finally {\n                    IOUtils.closeQuietly(tarIn);\n                }\n            }\n        } catch (IOException e) {\n            throw new ArchiveExtractionException(\"Could not extract archive: '\"\n                    + archive\n                    + \"'\", e);\n        }\n    }", "func_src_after": "    @Override\n    public void extract(String archive, String destinationDirectory) throws ArchiveExtractionException {\n        final File archiveFile = new File(archive);\n\n        try (FileInputStream fis = new FileInputStream(archiveFile)) {\n            if (\"msi\".equals(FileUtils.getExtension(archiveFile.getAbsolutePath()))) {\n                String command = \"msiexec /a \" + archiveFile.getAbsolutePath() + \" /qn TARGETDIR=\\\"\"\n                        + destinationDirectory + \"\\\"\";\n                Process child = Runtime.getRuntime().exec(command);\n                try {\n                    int result = child.waitFor();\n                    if (result != 0) {\n                        throw new ArchiveExtractionException(\n                                \"Could not extract \" + archiveFile.getAbsolutePath() + \"; return code \" + result);\n                    }\n                } catch (InterruptedException e) {\n                    throw new ArchiveExtractionException(\n                            \"Unexpected interruption of while waiting for extraction process\", e);\n                }\n            } else if (\"zip\".equals(FileUtils.getExtension(archiveFile.getAbsolutePath()))) {\n                ZipFile zipFile = new ZipFile(archiveFile);\n                try {\n                    Enumeration<? extends ZipEntry> entries = zipFile.entries();\n                    while (entries.hasMoreElements()) {\n                        ZipEntry entry = entries.nextElement();\n                        final File destPath = new File(destinationDirectory, entry.getName());\n                        if (!destPath.toPath().normalize().startsWith(destinationDirectory)) {\n                            throw new RuntimeException(\"Bad zip entry\");\n                        }\n                        prepDestination(destPath, entry.isDirectory());\n                        if (!entry.isDirectory()) {\n                            InputStream in = null;\n                            OutputStream out = null;\n                            try {\n                                in = zipFile.getInputStream(entry);\n                                out = new FileOutputStream(destPath);\n                                IOUtils.copy(in, out);\n                            } finally {\n                                IOUtils.closeQuietly(in);\n                                IOUtils.closeQuietly(out);\n                            }\n                        }\n                    }\n                } finally {\n                    zipFile.close();\n                }\n            } else {\n                // TarArchiveInputStream can be constructed with a normal FileInputStream if\n                // we ever need to extract regular '.tar' files.\n                TarArchiveInputStream tarIn = null;\n                try {\n                    tarIn = new TarArchiveInputStream(new GzipCompressorInputStream(fis));\n\n                    TarArchiveEntry tarEntry = tarIn.getNextTarEntry();\n                    String canonicalDestinationDirectory = new File(destinationDirectory).getCanonicalPath();\n                    while (tarEntry != null) {\n                        // Create a file for this tarEntry\n                        final File destPath = new File(destinationDirectory, tarEntry.getName());\n                        prepDestination(destPath, tarEntry.isDirectory());\n\n                        if (!startsWithPath(destPath.getCanonicalPath(), canonicalDestinationDirectory)) {\n                            throw new IOException(\n                                    \"Expanding \" + tarEntry.getName() + \" would create file outside of \" + canonicalDestinationDirectory\n                            );\n                        }\n\n                        if (!tarEntry.isDirectory()) {\n                            destPath.createNewFile();\n                            boolean isExecutable = (tarEntry.getMode() & 0100) > 0;\n                            destPath.setExecutable(isExecutable);\n\n                            OutputStream out = null;\n                            try {\n                                out = new FileOutputStream(destPath);\n                                IOUtils.copy(tarIn, out);\n                            } finally {\n                                IOUtils.closeQuietly(out);\n                            }\n                        }\n                        tarEntry = tarIn.getNextTarEntry();\n                    }\n                } finally {\n                    IOUtils.closeQuietly(tarIn);\n                }\n            }\n        } catch (IOException e) {\n            throw new ArchiveExtractionException(\"Could not extract archive: '\"\n                    + archive\n                    + \"'\", e);\n        }\n    }", "line_changes": {"deleted": [{"line_no": 26, "char_start": 1467, "char_end": 1580, "line": "                        final File destPath = new File(destinationDirectory + File.separator + entry.getName());\n"}, {"line_no": 55, "char_start": 2986, "char_end": 3102, "line": "                        final File destPath = new File(destinationDirectory + File.separator + tarEntry.getName());\n"}], "added": [{"line_no": 26, "char_start": 1467, "char_end": 1562, "line": "                        final File destPath = new File(destinationDirectory, entry.getName());\n"}, {"line_no": 27, "char_start": 1562, "char_end": 1657, "line": "                        if (!destPath.toPath().normalize().startsWith(destinationDirectory)) {\n"}, {"line_no": 28, "char_start": 1657, "char_end": 1730, "line": "                            throw new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 29, "char_start": 1730, "char_end": 1756, "line": "                        }\n"}, {"line_no": 58, "char_start": 3162, "char_end": 3260, "line": "                        final File destPath = new File(destinationDirectory, tarEntry.getName());\n"}]}, "char_changes": {"deleted": [{"char_start": 1542, "char_end": 1579, "chars": " + File.separator + entry.getName());"}, {"char_start": 3061, "char_end": 3080, "chars": " + File.separator +"}], "added": [{"char_start": 1542, "char_end": 1755, "chars": ", entry.getName());\n                        if (!destPath.toPath().normalize().startsWith(destinationDirectory)) {\n                            throw new RuntimeException(\"Bad zip entry\");\n                        }"}, {"char_start": 3237, "char_end": 3238, "chars": ","}]}, "commit_link": "github.com/eirslett/frontend-maven-plugin/commit/9f53f7617b41d89cbef1a29342c6b6b7441fa78a", "file_name": "ArchiveExtractor.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java method to extract files from an archive (ZIP, MSI, or TAR.GZ) to a specified directory."}
{"func_name": "JUtil::unpackJar", "func_src_before": "   public static void unpackJar(File fjar, File fout) throws IOException {\n    \n      JarFile jf = new JarFile(fjar);\n      Enumeration<JarEntry> en = jf.entries();\n\n      while (en.hasMoreElements()) {\n         JarEntry je = en.nextElement();\n         java.io.File f = new File(fout,  je.getName());\n         if (je.isDirectory()) {\n            f.mkdirs();\n            continue;\n\n         } else {\n            // f.getParentFile().mkdirs();\n\n            if (f.getPath().indexOf(\"META-INF\") >= 0) {\n               // skip it\n            } else {\n            f.getParentFile().mkdirs();\n            java.io.InputStream is = jf.getInputStream(je);\n            java.io.FileOutputStream fos = new FileOutputStream(f);\n\n            // EFF - buffering, file channels??\n            while (is.available() > 0) {\n               fos.write(is.read());\n            }\n            fos.close();\n            is.close();\n         }\n         }\n      }\n\n    //  E.info(\"unpacked jar to \" + fout);\n\n       \n   }", "func_src_after": "   public static void unpackJar(File fjar, File fout) throws IOException {\n    \n      JarFile jf = new JarFile(fjar);\n      Enumeration<JarEntry> en = jf.entries();\n\n      while (en.hasMoreElements()) {\n         JarEntry je = en.nextElement();\n         java.io.File f = new File(fout,  je.getName());\n\t\t\t\t\t\t\tif (!f.toPath().normalize().startsWith(fout.toPath().normalize())) {\n\t\t\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t\t\t\t}\n         if (je.isDirectory()) {\n            f.mkdirs();\n            continue;\n\n         } else {\n            // f.getParentFile().mkdirs();\n\n            if (f.getPath().indexOf(\"META-INF\") >= 0) {\n               // skip it\n            } else {\n            f.getParentFile().mkdirs();\n            java.io.InputStream is = jf.getInputStream(je);\n            java.io.FileOutputStream fos = new FileOutputStream(f);\n\n            // EFF - buffering, file channels??\n            while (is.available() > 0) {\n               fos.write(is.read());\n            }\n            fos.close();\n            is.close();\n         }\n         }\n      }\n\n    //  E.info(\"unpacked jar to \" + fout);\n\n       \n   }", "line_changes": {"deleted": [], "added": [{"line_no": 9, "char_start": 301, "char_end": 377, "line": "\t\t\t\t\t\t\tif (!f.toPath().normalize().startsWith(fout.toPath().normalize())) {\n"}, {"line_no": 10, "char_start": 377, "char_end": 430, "line": "\t\t\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 11, "char_start": 430, "char_end": 439, "line": "\t\t\t\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 301, "char_end": 439, "chars": "\t\t\t\t\t\t\tif (!f.toPath().normalize().startsWith(fout.toPath().normalize())) {\n\t\t\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t\t\t\t}\n"}]}, "commit_link": "github.com/LEMS/jLEMS/commit/8c224637d7d561076364a9e3c2c375daeaf463dc", "file_name": "JUtil.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to extract the contents of a JAR file to a specified directory, excluding META-INF directory."}
{"func_name": "dateproto_setUTCMilliseconds", "func_src_before": "func (r *Runtime) dateproto_setUTCMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := int(call.Argument(0).ToInteger())\n\t\t\tt := d.time.In(time.UTC)\n\t\t\td.time = time.Date(t.Year(), t.Month(), t.Day(), t.Hour(), t.Minute(), t.Second(), msec*1e6, time.UTC).In(time.Local)\n\t\t\treturn intToValue(timeToMsec(d.time))\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setUTCMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "func_src_after": "func (r *Runtime) dateproto_setUTCMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := call.Argument(0).ToInteger()\n\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m)\n\t\t\treturn intToValue(m)\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setUTCMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 161, "char_end": 206, "line": "\t\t\tmsec := int(call.Argument(0).ToInteger())\n"}, {"line_no": 6, "char_start": 206, "char_end": 234, "line": "\t\t\tt := d.time.In(time.UTC)\n"}, {"line_no": 7, "char_start": 234, "char_end": 355, "line": "\t\t\td.time = time.Date(t.Year(), t.Month(), t.Day(), t.Hour(), t.Minute(), t.Second(), msec*1e6, time.UTC).In(time.Local)\n"}, {"line_no": 8, "char_start": 355, "char_end": 396, "line": "\t\t\treturn intToValue(timeToMsec(d.time))\n"}], "added": [{"line_no": 5, "char_start": 161, "char_end": 201, "line": "\t\t\tmsec := call.Argument(0).ToInteger()\n"}, {"line_no": 6, "char_start": 201, "char_end": 268, "line": "\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n"}, {"line_no": 7, "char_start": 268, "char_end": 296, "line": "\t\t\td.time = timeFromMsec(m)\n"}, {"line_no": 8, "char_start": 296, "char_end": 320, "line": "\t\t\treturn intToValue(m)\n"}]}, "char_changes": {"deleted": [{"char_start": 172, "char_end": 176, "chars": "int("}, {"char_start": 204, "char_end": 205, "chars": ")"}, {"char_start": 209, "char_end": 210, "chars": "t"}, {"char_start": 214, "char_end": 216, "chars": "d."}, {"char_start": 220, "char_end": 353, "chars": ".In(time.UTC)\n\t\t\td.time = time.Date(t.Year(), t.Month(), t.Day(), t.Hour(), t.Minute(), t.Second(), msec*1e6, time.UTC).In(time.Local"}, {"char_start": 376, "char_end": 394, "chars": "timeToMsec(d.time)"}], "added": [{"char_start": 204, "char_end": 205, "chars": "m"}, {"char_start": 213, "char_end": 294, "chars": "ToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m"}, {"char_start": 317, "char_end": 318, "chars": "m"}]}, "commit_link": "github.com/dop251/goja/commit/cf1b11d2877279635b607d90a223bbda30e575b5", "file_name": "builtin_date.go", "vul_type": "cwe-681", "commit_msg": "Avoid integer overflow in Date.setMilliseconds()", "parent_commit": "5e65f9206bdb013b233bde6bac91fc88e00ff7a3", "description": "Write a Go function that sets the milliseconds for a date object in UTC."}
{"func_name": "__mdiobus_register", "func_src_before": "int __mdiobus_register(struct mii_bus *bus, struct module *owner)\n{\n\tstruct mdio_device *mdiodev;\n\tint i, err;\n\tstruct gpio_desc *gpiod;\n\n\tif (NULL == bus || NULL == bus->name ||\n\t    NULL == bus->read || NULL == bus->write)\n\t\treturn -EINVAL;\n\n\tBUG_ON(bus->state != MDIOBUS_ALLOCATED &&\n\t       bus->state != MDIOBUS_UNREGISTERED);\n\n\tbus->owner = owner;\n\tbus->dev.parent = bus->parent;\n\tbus->dev.class = &mdio_bus_class;\n\tbus->dev.groups = NULL;\n\tdev_set_name(&bus->dev, \"%s\", bus->id);\n\n\terr = device_register(&bus->dev);\n\tif (err) {\n\t\tpr_err(\"mii_bus %s failed to register\\n\", bus->id);\n\t\tput_device(&bus->dev);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_init(&bus->mdio_lock);\n\n\t/* de-assert bus level PHY GPIO reset */\n\tgpiod = devm_gpiod_get_optional(&bus->dev, \"reset\", GPIOD_OUT_LOW);\n\tif (IS_ERR(gpiod)) {\n\t\tdev_err(&bus->dev, \"mii_bus %s couldn't get reset GPIO\\n\",\n\t\t\tbus->id);\n\t\tdevice_del(&bus->dev);\n\t\treturn PTR_ERR(gpiod);\n\t} else\tif (gpiod) {\n\t\tbus->reset_gpiod = gpiod;\n\n\t\tgpiod_set_value_cansleep(gpiod, 1);\n\t\tudelay(bus->reset_delay_us);\n\t\tgpiod_set_value_cansleep(gpiod, 0);\n\t}\n\n\tif (bus->reset)\n\t\tbus->reset(bus);\n\n\tfor (i = 0; i < PHY_MAX_ADDR; i++) {\n\t\tif ((bus->phy_mask & (1 << i)) == 0) {\n\t\t\tstruct phy_device *phydev;\n\n\t\t\tphydev = mdiobus_scan(bus, i);\n\t\t\tif (IS_ERR(phydev) && (PTR_ERR(phydev) != -ENODEV)) {\n\t\t\t\terr = PTR_ERR(phydev);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\tmdiobus_setup_mdiodev_from_board_info(bus, mdiobus_create_device);\n\n\tbus->state = MDIOBUS_REGISTERED;\n\tpr_info(\"%s: probed\\n\", bus->name);\n\treturn 0;\n\nerror:\n\twhile (--i >= 0) {\n\t\tmdiodev = bus->mdio_map[i];\n\t\tif (!mdiodev)\n\t\t\tcontinue;\n\n\t\tmdiodev->device_remove(mdiodev);\n\t\tmdiodev->device_free(mdiodev);\n\t}\n\n\t/* Put PHYs in RESET to save power */\n\tif (bus->reset_gpiod)\n\t\tgpiod_set_value_cansleep(bus->reset_gpiod, 1);\n\n\tdevice_del(&bus->dev);\n\treturn err;\n}", "func_src_after": "int __mdiobus_register(struct mii_bus *bus, struct module *owner)\n{\n\tstruct mdio_device *mdiodev;\n\tint i, err;\n\tstruct gpio_desc *gpiod;\n\n\tif (NULL == bus || NULL == bus->name ||\n\t    NULL == bus->read || NULL == bus->write)\n\t\treturn -EINVAL;\n\n\tBUG_ON(bus->state != MDIOBUS_ALLOCATED &&\n\t       bus->state != MDIOBUS_UNREGISTERED);\n\n\tbus->owner = owner;\n\tbus->dev.parent = bus->parent;\n\tbus->dev.class = &mdio_bus_class;\n\tbus->dev.groups = NULL;\n\tdev_set_name(&bus->dev, \"%s\", bus->id);\n\n\terr = device_register(&bus->dev);\n\tif (err) {\n\t\tpr_err(\"mii_bus %s failed to register\\n\", bus->id);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_init(&bus->mdio_lock);\n\n\t/* de-assert bus level PHY GPIO reset */\n\tgpiod = devm_gpiod_get_optional(&bus->dev, \"reset\", GPIOD_OUT_LOW);\n\tif (IS_ERR(gpiod)) {\n\t\tdev_err(&bus->dev, \"mii_bus %s couldn't get reset GPIO\\n\",\n\t\t\tbus->id);\n\t\tdevice_del(&bus->dev);\n\t\treturn PTR_ERR(gpiod);\n\t} else\tif (gpiod) {\n\t\tbus->reset_gpiod = gpiod;\n\n\t\tgpiod_set_value_cansleep(gpiod, 1);\n\t\tudelay(bus->reset_delay_us);\n\t\tgpiod_set_value_cansleep(gpiod, 0);\n\t}\n\n\tif (bus->reset)\n\t\tbus->reset(bus);\n\n\tfor (i = 0; i < PHY_MAX_ADDR; i++) {\n\t\tif ((bus->phy_mask & (1 << i)) == 0) {\n\t\t\tstruct phy_device *phydev;\n\n\t\t\tphydev = mdiobus_scan(bus, i);\n\t\t\tif (IS_ERR(phydev) && (PTR_ERR(phydev) != -ENODEV)) {\n\t\t\t\terr = PTR_ERR(phydev);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\tmdiobus_setup_mdiodev_from_board_info(bus, mdiobus_create_device);\n\n\tbus->state = MDIOBUS_REGISTERED;\n\tpr_info(\"%s: probed\\n\", bus->name);\n\treturn 0;\n\nerror:\n\twhile (--i >= 0) {\n\t\tmdiodev = bus->mdio_map[i];\n\t\tif (!mdiodev)\n\t\t\tcontinue;\n\n\t\tmdiodev->device_remove(mdiodev);\n\t\tmdiodev->device_free(mdiodev);\n\t}\n\n\t/* Put PHYs in RESET to save power */\n\tif (bus->reset_gpiod)\n\t\tgpiod_set_value_cansleep(bus->reset_gpiod, 1);\n\n\tdevice_del(&bus->dev);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/6ff7b060535e87c2ae14dd8548512abfdda528fb", "file_name": "drivers/net/phy/mdio_bus.c", "vul_type": "cwe-416", "description": "In C, write a function to register an MDIO bus with error handling and PHY device scanning."}
{"func_name": "_get_host_from_connector", "func_src_before": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = 'svcinfo lshost -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "func_src_after": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = ['svcinfo', 'lshost', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve a host name from storage based on connection information, using SSH for commands."}
{"func_name": "encode_frame", "func_src_before": "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                               const AVFrame *pict, int *got_packet)\n{\n    Msvideo1EncContext * const c = avctx->priv_data;\n    const AVFrame *p = pict;\n    const uint16_t *src;\n    uint8_t *prevptr;\n    uint8_t *dst, *buf;\n    int keyframe = 0;\n    int no_skips = 1;\n    int i, j, k, x, y, ret;\n    int skips = 0;\n    int quality = 24;\n\n    if ((ret = ff_alloc_packet(avctx, pkt, avctx->width*avctx->height*9 + AV_INPUT_BUFFER_MIN_SIZE)) < 0)\n        return ret;\n    dst= buf= pkt->data;\n\n    if(!c->prev)\n        c->prev = av_malloc(avctx->width * 3 * (avctx->height + 3));\n    prevptr = c->prev + avctx->width * 3 * (FFALIGN(avctx->height, 4) - 1);\n    src = (const uint16_t*)(p->data[0] + p->linesize[0]*(FFALIGN(avctx->height, 4) - 1));\n    if(c->keyint >= avctx->keyint_min)\n        keyframe = 1;\n\n\n    for(y = 0; y < avctx->height; y += 4){\n        for(x = 0; x < avctx->width; x += 4){\n            int bestmode = MODE_SKIP;\n            int bestscore = INT_MAX;\n            int flags = 0;\n            int score;\n\n            for(j = 0; j < 4; j++){\n                for(i = 0; i < 4; i++){\n                    uint16_t val = src[x + i - j*p->linesize[0]/2];\n                    for(k = 0; k < 3; k++){\n                        c->block[(i + j*4)*3 + k] =\n                        c->block2[remap[i + j*4]*3 + k] = (val >> (10-k*5)) & 0x1F;\n                    }\n                }\n            }\n            if(!keyframe){\n                bestscore = 0;\n                for(j = 0; j < 4; j++){\n                    for(i = 0; i < 4*3; i++){\n                        int t = prevptr[x*3 + i - j*3*avctx->width] - c->block[i + j*4*3];\n                        bestscore += t*t;\n                    }\n                }\n                bestscore /= quality;\n            }\n            // try to find optimal value to fill whole 4x4 block\n            score = 0;\n            ret = avpriv_elbg_do(&c->elbg, c->block, 3, 16, c->avg,\n                                 1, 1, c->output, &c->rnd, 0);\n            if (ret < 0)\n                return ret;\n            if(c->avg[0] == 1) // red component = 1 will be written as skip code\n                c->avg[0] = 0;\n            for(j = 0; j < 4; j++){\n                for(i = 0; i < 4; i++){\n                    for(k = 0; k < 3; k++){\n                        int t = c->avg[k] - c->block[(i+j*4)*3+k];\n                        score += t*t;\n                    }\n                }\n            }\n            score /= quality;\n            score += 2;\n            if(score < bestscore){\n                bestscore = score;\n                bestmode = MODE_FILL;\n            }\n            // search for optimal filling of 2-color block\n            score = 0;\n            ret = avpriv_elbg_do(&c->elbg, c->block, 3, 16, c->codebook,\n                                 2, 1, c->output, &c->rnd, 0);\n            if (ret < 0)\n                return ret;\n            // last output value should be always 1, swap codebooks if needed\n            if(!c->output[15]){\n                for(i = 0; i < 3; i++)\n                    FFSWAP(uint8_t, c->codebook[i], c->codebook[i+3]);\n                for(i = 0; i < 16; i++)\n                    c->output[i] ^= 1;\n            }\n            for(j = 0; j < 4; j++){\n                for(i = 0; i < 4; i++){\n                    for(k = 0; k < 3; k++){\n                        int t = c->codebook[c->output[i+j*4]*3 + k] - c->block[i*3+k+j*4*3];\n                        score += t*t;\n                    }\n                }\n            }\n            score /= quality;\n            score += 6;\n            if(score < bestscore){\n                bestscore = score;\n                bestmode = MODE_2COL;\n            }\n            // search for optimal filling of 2-color 2x2 subblocks\n            score = 0;\n            for(i = 0; i < 4; i++){\n                ret = avpriv_elbg_do(&c->elbg, c->block2 + i * 4 * 3, 3, 4,\n                                     c->codebook2 + i * 2 * 3, 2, 1,\n                                     c->output2 + i * 4, &c->rnd, 0);\n                if (ret < 0)\n                    return ret;\n            }\n            // last value should be always 1, swap codebooks if needed\n            if(!c->output2[15]){\n                for(i = 0; i < 3; i++)\n                    FFSWAP(uint8_t, c->codebook2[i+18], c->codebook2[i+21]);\n                for(i = 12; i < 16; i++)\n                    c->output2[i] ^= 1;\n            }\n            for(j = 0; j < 4; j++){\n                for(i = 0; i < 4; i++){\n                    for(k = 0; k < 3; k++){\n                        int t = c->codebook2[(c->output2[remap[i+j*4]] + (i&2) + (j&2)*2)*3+k] - c->block[i*3+k + j*4*3];\n                        score += t*t;\n                    }\n                }\n            }\n            score /= quality;\n            score += 18;\n            if(score < bestscore){\n                bestscore = score;\n                bestmode = MODE_8COL;\n            }\n\n            if(bestmode == MODE_SKIP){\n                skips++;\n                no_skips = 0;\n            }\n            if((bestmode != MODE_SKIP && skips) || skips == SKIPS_MAX){\n                bytestream_put_le16(&dst, skips | SKIP_PREFIX);\n                skips = 0;\n            }\n\n            switch(bestmode){\n            case MODE_FILL:\n                bytestream_put_le16(&dst, MKRGB555(c->avg,0) | 0x8000);\n                for(j = 0; j < 4; j++)\n                    for(i = 0; i < 4; i++)\n                        for(k = 0; k < 3; k++)\n                            prevptr[x*3 + i*3 + k - j*3*avctx->width] = c->avg[k];\n                break;\n            case MODE_2COL:\n                for(j = 0; j < 4; j++){\n                    for(i = 0; i < 4; i++){\n                        flags |= (c->output[i + j*4]^1) << (i + j*4);\n                        for(k = 0; k < 3; k++)\n                            prevptr[x*3 + i*3 + k - j*3*avctx->width] = c->codebook[c->output[i + j*4]*3 + k];\n                    }\n                }\n                bytestream_put_le16(&dst, flags);\n                bytestream_put_le16(&dst, MKRGB555(c->codebook, 0));\n                bytestream_put_le16(&dst, MKRGB555(c->codebook, 3));\n                break;\n            case MODE_8COL:\n                for(j = 0; j < 4; j++){\n                    for(i = 0; i < 4; i++){\n                        flags |= (c->output2[remap[i + j*4]]^1) << (i + j*4);\n                        for(k = 0; k < 3; k++)\n                            prevptr[x*3 + i*3 + k - j*3*avctx->width] = c->codebook2[(c->output2[remap[i+j*4]] + (i&2) + (j&2)*2)*3 + k];\n                    }\n                }\n                bytestream_put_le16(&dst, flags);\n                bytestream_put_le16(&dst, MKRGB555(c->codebook2, 0) | 0x8000);\n                for(i = 3; i < 24; i += 3)\n                    bytestream_put_le16(&dst, MKRGB555(c->codebook2, i));\n                break;\n            }\n        }\n        src     -= p->linesize[0] << 1;\n        prevptr -= avctx->width * 3 * 4;\n    }\n    if(skips)\n        bytestream_put_le16(&dst, skips | SKIP_PREFIX);\n    //EOF\n    bytestream_put_byte(&dst, 0);\n    bytestream_put_byte(&dst, 0);\n\n    if(no_skips)\n        keyframe = 1;\n    if(keyframe)\n        c->keyint = 0;\n    else\n        c->keyint++;\n    if (keyframe) pkt->flags |= AV_PKT_FLAG_KEY;\n    pkt->size = dst - buf;\n    *got_packet = 1;\n\n    return 0;\n}", "func_src_after": "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                               const AVFrame *pict, int *got_packet)\n{\n    Msvideo1EncContext * const c = avctx->priv_data;\n    const AVFrame *p = pict;\n    const uint16_t *src;\n    uint8_t *prevptr;\n    uint8_t *dst, *buf;\n    int keyframe = 0;\n    int no_skips = 1;\n    int i, j, k, x, y, ret;\n    int skips = 0;\n    int quality = 24;\n\n    if ((ret = ff_alloc_packet(avctx, pkt, avctx->width*avctx->height*9 + AV_INPUT_BUFFER_MIN_SIZE)) < 0)\n        return ret;\n    dst= buf= pkt->data;\n\n    if(!c->prev)\n        c->prev = av_malloc(avctx->width * 3 * (avctx->height + 3));\n    if (!c->prev)\n        return AVERROR(ENOMEM);\n    prevptr = c->prev + avctx->width * 3 * (FFALIGN(avctx->height, 4) - 1);\n    src = (const uint16_t*)(p->data[0] + p->linesize[0]*(FFALIGN(avctx->height, 4) - 1));\n    if(c->keyint >= avctx->keyint_min)\n        keyframe = 1;\n\n\n    for(y = 0; y < avctx->height; y += 4){\n        for(x = 0; x < avctx->width; x += 4){\n            int bestmode = MODE_SKIP;\n            int bestscore = INT_MAX;\n            int flags = 0;\n            int score;\n\n            for(j = 0; j < 4; j++){\n                for(i = 0; i < 4; i++){\n                    uint16_t val = src[x + i - j*p->linesize[0]/2];\n                    for(k = 0; k < 3; k++){\n                        c->block[(i + j*4)*3 + k] =\n                        c->block2[remap[i + j*4]*3 + k] = (val >> (10-k*5)) & 0x1F;\n                    }\n                }\n            }\n            if(!keyframe){\n                bestscore = 0;\n                for(j = 0; j < 4; j++){\n                    for(i = 0; i < 4*3; i++){\n                        int t = prevptr[x*3 + i - j*3*avctx->width] - c->block[i + j*4*3];\n                        bestscore += t*t;\n                    }\n                }\n                bestscore /= quality;\n            }\n            // try to find optimal value to fill whole 4x4 block\n            score = 0;\n            ret = avpriv_elbg_do(&c->elbg, c->block, 3, 16, c->avg,\n                                 1, 1, c->output, &c->rnd, 0);\n            if (ret < 0)\n                return ret;\n            if(c->avg[0] == 1) // red component = 1 will be written as skip code\n                c->avg[0] = 0;\n            for(j = 0; j < 4; j++){\n                for(i = 0; i < 4; i++){\n                    for(k = 0; k < 3; k++){\n                        int t = c->avg[k] - c->block[(i+j*4)*3+k];\n                        score += t*t;\n                    }\n                }\n            }\n            score /= quality;\n            score += 2;\n            if(score < bestscore){\n                bestscore = score;\n                bestmode = MODE_FILL;\n            }\n            // search for optimal filling of 2-color block\n            score = 0;\n            ret = avpriv_elbg_do(&c->elbg, c->block, 3, 16, c->codebook,\n                                 2, 1, c->output, &c->rnd, 0);\n            if (ret < 0)\n                return ret;\n            // last output value should be always 1, swap codebooks if needed\n            if(!c->output[15]){\n                for(i = 0; i < 3; i++)\n                    FFSWAP(uint8_t, c->codebook[i], c->codebook[i+3]);\n                for(i = 0; i < 16; i++)\n                    c->output[i] ^= 1;\n            }\n            for(j = 0; j < 4; j++){\n                for(i = 0; i < 4; i++){\n                    for(k = 0; k < 3; k++){\n                        int t = c->codebook[c->output[i+j*4]*3 + k] - c->block[i*3+k+j*4*3];\n                        score += t*t;\n                    }\n                }\n            }\n            score /= quality;\n            score += 6;\n            if(score < bestscore){\n                bestscore = score;\n                bestmode = MODE_2COL;\n            }\n            // search for optimal filling of 2-color 2x2 subblocks\n            score = 0;\n            for(i = 0; i < 4; i++){\n                ret = avpriv_elbg_do(&c->elbg, c->block2 + i * 4 * 3, 3, 4,\n                                     c->codebook2 + i * 2 * 3, 2, 1,\n                                     c->output2 + i * 4, &c->rnd, 0);\n                if (ret < 0)\n                    return ret;\n            }\n            // last value should be always 1, swap codebooks if needed\n            if(!c->output2[15]){\n                for(i = 0; i < 3; i++)\n                    FFSWAP(uint8_t, c->codebook2[i+18], c->codebook2[i+21]);\n                for(i = 12; i < 16; i++)\n                    c->output2[i] ^= 1;\n            }\n            for(j = 0; j < 4; j++){\n                for(i = 0; i < 4; i++){\n                    for(k = 0; k < 3; k++){\n                        int t = c->codebook2[(c->output2[remap[i+j*4]] + (i&2) + (j&2)*2)*3+k] - c->block[i*3+k + j*4*3];\n                        score += t*t;\n                    }\n                }\n            }\n            score /= quality;\n            score += 18;\n            if(score < bestscore){\n                bestscore = score;\n                bestmode = MODE_8COL;\n            }\n\n            if(bestmode == MODE_SKIP){\n                skips++;\n                no_skips = 0;\n            }\n            if((bestmode != MODE_SKIP && skips) || skips == SKIPS_MAX){\n                bytestream_put_le16(&dst, skips | SKIP_PREFIX);\n                skips = 0;\n            }\n\n            switch(bestmode){\n            case MODE_FILL:\n                bytestream_put_le16(&dst, MKRGB555(c->avg,0) | 0x8000);\n                for(j = 0; j < 4; j++)\n                    for(i = 0; i < 4; i++)\n                        for(k = 0; k < 3; k++)\n                            prevptr[x*3 + i*3 + k - j*3*avctx->width] = c->avg[k];\n                break;\n            case MODE_2COL:\n                for(j = 0; j < 4; j++){\n                    for(i = 0; i < 4; i++){\n                        flags |= (c->output[i + j*4]^1) << (i + j*4);\n                        for(k = 0; k < 3; k++)\n                            prevptr[x*3 + i*3 + k - j*3*avctx->width] = c->codebook[c->output[i + j*4]*3 + k];\n                    }\n                }\n                bytestream_put_le16(&dst, flags);\n                bytestream_put_le16(&dst, MKRGB555(c->codebook, 0));\n                bytestream_put_le16(&dst, MKRGB555(c->codebook, 3));\n                break;\n            case MODE_8COL:\n                for(j = 0; j < 4; j++){\n                    for(i = 0; i < 4; i++){\n                        flags |= (c->output2[remap[i + j*4]]^1) << (i + j*4);\n                        for(k = 0; k < 3; k++)\n                            prevptr[x*3 + i*3 + k - j*3*avctx->width] = c->codebook2[(c->output2[remap[i+j*4]] + (i&2) + (j&2)*2)*3 + k];\n                    }\n                }\n                bytestream_put_le16(&dst, flags);\n                bytestream_put_le16(&dst, MKRGB555(c->codebook2, 0) | 0x8000);\n                for(i = 3; i < 24; i += 3)\n                    bytestream_put_le16(&dst, MKRGB555(c->codebook2, i));\n                break;\n            }\n        }\n        src     -= p->linesize[0] << 1;\n        prevptr -= avctx->width * 3 * 4;\n    }\n    if(skips)\n        bytestream_put_le16(&dst, skips | SKIP_PREFIX);\n    //EOF\n    bytestream_put_byte(&dst, 0);\n    bytestream_put_byte(&dst, 0);\n\n    if(no_skips)\n        keyframe = 1;\n    if(keyframe)\n        c->keyint = 0;\n    else\n        c->keyint++;\n    if (keyframe) pkt->flags |= AV_PKT_FLAG_KEY;\n    pkt->size = dst - buf;\n    *got_packet = 1;\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/b9ba036680b4164f6e415a85877dfa659ae4dde1", "file_name": "libavcodec/msvideo1enc.c", "vul_type": "cwe-476", "description": "Write a C function for encoding a video frame using the MS Video 1 codec."}
{"func_name": "read_SubStreamsInfo", "func_src_before": "read_SubStreamsInfo(struct archive_read *a, struct _7z_substream_info *ss,\n    struct _7z_folder *f, size_t numFolders)\n{\n\tconst unsigned char *p;\n\tuint64_t *usizes;\n\tsize_t unpack_streams;\n\tint type;\n\tunsigned i;\n\tuint32_t numDigests;\n\n\tmemset(ss, 0, sizeof(*ss));\n\n\tfor (i = 0; i < numFolders; i++)\n\t\tf[i].numUnpackStreams = 1;\n\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\ttype = *p;\n\n\tif (type == kNumUnPackStream) {\n\t\tunpack_streams = 0;\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (parse_7zip_uint64(a, &(f[i].numUnpackStreams)) < 0)\n\t\t\t\treturn (-1);\n\t\t\tif (UMAX_ENTRY < f[i].numUnpackStreams)\n\t\t\t\treturn (-1);\n\t\t\tunpack_streams += (size_t)f[i].numUnpackStreams;\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t} else\n\t\tunpack_streams = numFolders;\n\n\tss->unpack_streams = unpack_streams;\n\tif (unpack_streams) {\n\t\tss->unpackSizes = calloc(unpack_streams,\n\t\t    sizeof(*ss->unpackSizes));\n\t\tss->digestsDefined = calloc(unpack_streams,\n\t\t    sizeof(*ss->digestsDefined));\n\t\tss->digests = calloc(unpack_streams,\n\t\t    sizeof(*ss->digests));\n\t\tif (ss->unpackSizes == NULL || ss->digestsDefined == NULL ||\n\t\t    ss->digests == NULL)\n\t\t\treturn (-1);\n\t}\n\n\tusizes = ss->unpackSizes;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tunsigned pack;\n\t\tuint64_t sum;\n\n\t\tif (f[i].numUnpackStreams == 0)\n\t\t\tcontinue;\n\n\t\tsum = 0;\n\t\tif (type == kSize) {\n\t\t\tfor (pack = 1; pack < f[i].numUnpackStreams; pack++) {\n\t\t\t\tif (parse_7zip_uint64(a, usizes) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t\tsum += *usizes++;\n\t\t\t}\n\t\t}\n\t\t*usizes++ = folder_uncompressed_size(&f[i]) - sum;\n\t}\n\n\tif (type == kSize) {\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\tfor (i = 0; i < unpack_streams; i++) {\n\t\tss->digestsDefined[i] = 0;\n\t\tss->digests[i] = 0;\n\t}\n\n\tnumDigests = 0;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tif (f[i].numUnpackStreams != 1 || !f[i].digest_defined)\n\t\t\tnumDigests += (uint32_t)f[i].numUnpackStreams;\n\t}\n\n\tif (type == kCRC) {\n\t\tstruct _7z_digests tmpDigests;\n\t\tunsigned char *digestsDefined = ss->digestsDefined;\n\t\tuint32_t * digests = ss->digests;\n\t\tint di = 0;\n\n\t\tmemset(&tmpDigests, 0, sizeof(tmpDigests));\n\t\tif (read_Digests(a, &(tmpDigests), numDigests) < 0) {\n\t\t\tfree_Digest(&tmpDigests);\n\t\t\treturn (-1);\n\t\t}\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (f[i].numUnpackStreams == 1 && f[i].digest_defined) {\n\t\t\t\t*digestsDefined++ = 1;\n\t\t\t\t*digests++ = f[i].digest;\n\t\t\t} else {\n\t\t\t\tunsigned j;\n\n\t\t\t\tfor (j = 0; j < f[i].numUnpackStreams;\n\t\t\t\t    j++, di++) {\n\t\t\t\t\t*digestsDefined++ =\n\t\t\t\t\t    tmpDigests.defineds[di];\n\t\t\t\t\t*digests++ =\n\t\t\t\t\t    tmpDigests.digests[di];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfree_Digest(&tmpDigests);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\t/*\n\t *  Must be kEnd.\n\t */\n\tif (type != kEnd)\n\t\treturn (-1);\n\treturn (0);\n}", "func_src_after": "read_SubStreamsInfo(struct archive_read *a, struct _7z_substream_info *ss,\n    struct _7z_folder *f, size_t numFolders)\n{\n\tconst unsigned char *p;\n\tuint64_t *usizes;\n\tsize_t unpack_streams;\n\tint type;\n\tunsigned i;\n\tuint32_t numDigests;\n\n\tmemset(ss, 0, sizeof(*ss));\n\n\tfor (i = 0; i < numFolders; i++)\n\t\tf[i].numUnpackStreams = 1;\n\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\ttype = *p;\n\n\tif (type == kNumUnPackStream) {\n\t\tunpack_streams = 0;\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (parse_7zip_uint64(a, &(f[i].numUnpackStreams)) < 0)\n\t\t\t\treturn (-1);\n\t\t\tif (UMAX_ENTRY < f[i].numUnpackStreams)\n\t\t\t\treturn (-1);\n\t\t\tif (unpack_streams > SIZE_MAX - UMAX_ENTRY) {\n\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tunpack_streams += (size_t)f[i].numUnpackStreams;\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t} else\n\t\tunpack_streams = numFolders;\n\n\tss->unpack_streams = unpack_streams;\n\tif (unpack_streams) {\n\t\tss->unpackSizes = calloc(unpack_streams,\n\t\t    sizeof(*ss->unpackSizes));\n\t\tss->digestsDefined = calloc(unpack_streams,\n\t\t    sizeof(*ss->digestsDefined));\n\t\tss->digests = calloc(unpack_streams,\n\t\t    sizeof(*ss->digests));\n\t\tif (ss->unpackSizes == NULL || ss->digestsDefined == NULL ||\n\t\t    ss->digests == NULL)\n\t\t\treturn (-1);\n\t}\n\n\tusizes = ss->unpackSizes;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tunsigned pack;\n\t\tuint64_t sum;\n\n\t\tif (f[i].numUnpackStreams == 0)\n\t\t\tcontinue;\n\n\t\tsum = 0;\n\t\tif (type == kSize) {\n\t\t\tfor (pack = 1; pack < f[i].numUnpackStreams; pack++) {\n\t\t\t\tif (parse_7zip_uint64(a, usizes) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t\tsum += *usizes++;\n\t\t\t}\n\t\t}\n\t\t*usizes++ = folder_uncompressed_size(&f[i]) - sum;\n\t}\n\n\tif (type == kSize) {\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\tfor (i = 0; i < unpack_streams; i++) {\n\t\tss->digestsDefined[i] = 0;\n\t\tss->digests[i] = 0;\n\t}\n\n\tnumDigests = 0;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tif (f[i].numUnpackStreams != 1 || !f[i].digest_defined)\n\t\t\tnumDigests += (uint32_t)f[i].numUnpackStreams;\n\t}\n\n\tif (type == kCRC) {\n\t\tstruct _7z_digests tmpDigests;\n\t\tunsigned char *digestsDefined = ss->digestsDefined;\n\t\tuint32_t * digests = ss->digests;\n\t\tint di = 0;\n\n\t\tmemset(&tmpDigests, 0, sizeof(tmpDigests));\n\t\tif (read_Digests(a, &(tmpDigests), numDigests) < 0) {\n\t\t\tfree_Digest(&tmpDigests);\n\t\t\treturn (-1);\n\t\t}\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (f[i].numUnpackStreams == 1 && f[i].digest_defined) {\n\t\t\t\t*digestsDefined++ = 1;\n\t\t\t\t*digests++ = f[i].digest;\n\t\t\t} else {\n\t\t\t\tunsigned j;\n\n\t\t\t\tfor (j = 0; j < f[i].numUnpackStreams;\n\t\t\t\t    j++, di++) {\n\t\t\t\t\t*digestsDefined++ =\n\t\t\t\t\t    tmpDigests.defineds[di];\n\t\t\t\t\t*digests++ =\n\t\t\t\t\t    tmpDigests.digests[di];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfree_Digest(&tmpDigests);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\t/*\n\t *  Must be kEnd.\n\t */\n\tif (type != kEnd)\n\t\treturn (-1);\n\treturn (0);\n}", "commit_link": "github.com/libarchive/libarchive/commit/e79ef306afe332faf22e9b442a2c6b59cb175573", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-190", "description": "In C, write a function to read substream information for folders within a 7z archive."}
{"func_name": "verifyCertificate", "func_src_before": "exports.verifyCertificate = function verifyCertificate(cert, caDir, caFile, cb) {\n\tvar command = 'openssl verify -purpose sslclient';\n\tif (caDir) {\n\t\tcommand += ' -CApath ' + caDir;\n\t}\n\tif (caFile) {\n\t\tcommand += ' -CAfile ' + caFile;\n\t}\n\n\tvar openssl = exec(command, function(err, stdout, stderr) {\n\t\tvar validationResult = {}\n\t\tif (stderr) {\n\t\t\tvalidationResult.output = stderr.toString().trim();\n\t\t\tvalidationResult.validCert = false;\n\t\t} else if (stdout) {\n\t\t\tvalidationResult.output = stdout.toString().trim();\n\t\t\tvalidationResult.validCert = true;\n\t\t}\n\t\tif (validationResult.validCert) {\n\t\t\tvalidationResult.verifiedCA = validationResult.output.lastIndexOf('OK') == validationResult.output.length - 2;\n\t\t\tif (validationResult.verifiedCA) {\n\t\t\t\tvalidationResult.expired = validationResult.output.indexOf('certificate has expired') > -1;\n\t\t\t}\n\t\t}\n\t\tcb(err, validationResult);\n\t});\n\n\topenssl.stdin.write(cert);\n\topenssl.stdin.end();\n};", "func_src_after": "exports.verifyCertificate = function verifyCertificate(cert, caDir, caFile, cb) {\n\tvar command = 'openssl';\n\tvar params = ['verify', '-purpose', 'sslclient']\n\tif (caDir) {\n\t\tparams.push('-CApath', caDir)\n\t}\n\tif (caFile) {\n\t\tparams.push('-CAfile', caFile)\n\t}\n\n\tvar openssl = execFile(command, params, function(err, stdout, stderr) {\n\t\tvar validationResult = {}\n\t\tif (stderr) {\n\t\t\tvalidationResult.output = stderr.toString().trim();\n\t\t\tvalidationResult.validCert = false;\n\t\t} else if (stdout) {\n\t\t\tvalidationResult.output = stdout.toString().trim();\n\t\t\tvalidationResult.validCert = true;\n\t\t}\n\t\tif (validationResult.validCert) {\n\t\t\tvalidationResult.verifiedCA = validationResult.output.lastIndexOf('OK') == validationResult.output.length - 2;\n\t\t\tif (validationResult.verifiedCA) {\n\t\t\t\tvalidationResult.expired = validationResult.output.indexOf('certificate has expired') > -1;\n\t\t\t}\n\t\t}\n\t\tcb(err, validationResult);\n\t});\n\n\topenssl.stdin.write(cert);\n\topenssl.stdin.end();\n};", "line_changes": {"deleted": [{"line_no": 2, "char_start": 82, "char_end": 134, "line": "\tvar command = 'openssl verify -purpose sslclient';\n"}, {"line_no": 4, "char_start": 148, "char_end": 182, "line": "\t\tcommand += ' -CApath ' + caDir;\n"}, {"line_no": 7, "char_start": 200, "char_end": 235, "line": "\t\tcommand += ' -CAfile ' + caFile;\n"}, {"line_no": 10, "char_start": 239, "char_end": 300, "line": "\tvar openssl = exec(command, function(err, stdout, stderr) {\n"}], "added": [{"line_no": 2, "char_start": 82, "char_end": 108, "line": "\tvar command = 'openssl';\n"}, {"line_no": 3, "char_start": 108, "char_end": 158, "line": "\tvar params = ['verify', '-purpose', 'sslclient']\n"}, {"line_no": 5, "char_start": 172, "char_end": 204, "line": "\t\tparams.push('-CApath', caDir)\n"}, {"line_no": 8, "char_start": 222, "char_end": 255, "line": "\t\tparams.push('-CAfile', caFile)\n"}, {"line_no": 11, "char_start": 259, "char_end": 332, "line": "\tvar openssl = execFile(command, params, function(err, stdout, stderr) {\n"}]}, "char_changes": {"deleted": [{"char_start": 105, "char_end": 106, "chars": " "}, {"char_start": 112, "char_end": 113, "chars": " "}, {"char_start": 121, "char_end": 122, "chars": " "}, {"char_start": 132, "char_end": 133, "chars": ";"}, {"char_start": 150, "char_end": 163, "chars": "command += ' "}, {"char_start": 170, "char_end": 174, "chars": " ' +"}, {"char_start": 180, "char_end": 181, "chars": ";"}, {"char_start": 202, "char_end": 215, "chars": "command += ' "}, {"char_start": 222, "char_end": 226, "chars": " ' +"}, {"char_start": 233, "char_end": 234, "chars": ";"}], "added": [{"char_start": 105, "char_end": 124, "chars": "';\n\tvar params = ['"}, {"char_start": 130, "char_end": 134, "chars": "', '"}, {"char_start": 142, "char_end": 146, "chars": "', '"}, {"char_start": 156, "char_end": 157, "chars": "]"}, {"char_start": 174, "char_end": 187, "chars": "params.push('"}, {"char_start": 194, "char_end": 196, "chars": "',"}, {"char_start": 202, "char_end": 203, "chars": ")"}, {"char_start": 224, "char_end": 237, "chars": "params.push('"}, {"char_start": 244, "char_end": 246, "chars": "',"}, {"char_start": 253, "char_end": 254, "chars": ")"}, {"char_start": 278, "char_end": 282, "chars": "File"}, {"char_start": 291, "char_end": 299, "chars": " params,"}]}, "commit_link": "github.com/psotres/openssl-verify/commit/6ea67869ba58cf7f4f2bdf173fe2f11b99a4e21b", "file_name": "verify.js", "vul_type": "cwe-078", "commit_msg": "Fixed security vulnerability (command injection)", "description": "Write a Node.js function to verify an SSL certificate using OpenSSL with optional CA directory and file parameters."}
{"func_name": "TIFFSeekCustomStream", "func_src_before": "static MagickOffsetType TIFFSeekCustomStream(const MagickOffsetType offset,\n  const int whence,void *user_data)\n{\n  PhotoshopProfile\n    *profile;\n\n  profile=(PhotoshopProfile *) user_data;\n  switch (whence)\n  {\n    case SEEK_SET:\n    default:\n    {\n      if (offset < 0)\n        return(-1);\n      profile->offset=offset;\n      break;\n    }\n    case SEEK_CUR:\n    {\n      if ((profile->offset+offset) < 0)\n        return(-1);\n      profile->offset+=offset;\n      break;\n    }\n    case SEEK_END:\n    {\n      if (((MagickOffsetType) profile->length+offset) < 0)\n        return(-1);\n      profile->offset=profile->length+offset;\n      break;\n    }\n  }\n\n  return(profile->offset);\n}", "func_src_after": "static MagickOffsetType TIFFSeekCustomStream(const MagickOffsetType offset,\n  const int whence,void *user_data)\n{\n  PhotoshopProfile\n    *profile;\n\n  profile=(PhotoshopProfile *) user_data;\n  switch (whence)\n  {\n    case SEEK_SET:\n    default:\n    {\n      if (offset < 0)\n        return(-1);\n      profile->offset=offset;\n      break;\n    }\n    case SEEK_CUR:\n    {\n      if (((offset > 0) && (profile->offset > (SSIZE_MAX-offset))) ||\n          ((offset < 0) && (profile->offset < (-SSIZE_MAX-offset))))\n        {\n          errno=EOVERFLOW;\n          return(-1);\n        }\n      if ((profile->offset+offset) < 0)\n        return(-1);\n      profile->offset+=offset;\n      break;\n    }\n    case SEEK_END:\n    {\n      if (((MagickOffsetType) profile->length+offset) < 0)\n        return(-1);\n      profile->offset=profile->length+offset;\n      break;\n    }\n  }\n\n  return(profile->offset);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/fe5f4b85e6b1b54d3b4588a77133c06ade46d891", "file_name": "coders/tiff.c", "vul_type": "cwe-190", "description": "Write a C function named `TIFFSeekCustomStream` that adjusts the offset within a Photoshop profile structure based on the seek operation specified."}
{"func_name": "_get_fc_wwpns", "func_src_before": "    def _get_fc_wwpns(self):\n        for key in self._storage_nodes:\n            node = self._storage_nodes[key]\n            ssh_cmd = 'svcinfo lsnode -delim ! %s' % node['id']\n            raw = self._run_ssh(ssh_cmd)\n            resp = CLIResponse(raw, delim='!', with_header=False)\n            wwpns = set(node['WWPN'])\n            for i, s in resp.select('port_id', 'port_status'):\n                if 'unconfigured' != s:\n                    wwpns.add(i)\n            node['WWPN'] = list(wwpns)\n            LOG.info(_('WWPN on node %(node)s: %(wwpn)s')\n                     % {'node': node['id'], 'wwpn': node['WWPN']})", "func_src_after": "    def _get_fc_wwpns(self):\n        for key in self._storage_nodes:\n            node = self._storage_nodes[key]\n            ssh_cmd = ['svcinfo', 'lsnode', '-delim', '!', node['id']]\n            raw = self._run_ssh(ssh_cmd)\n            resp = CLIResponse(raw, delim='!', with_header=False)\n            wwpns = set(node['WWPN'])\n            for i, s in resp.select('port_id', 'port_status'):\n                if 'unconfigured' != s:\n                    wwpns.add(i)\n            node['WWPN'] = list(wwpns)\n            LOG.info(_('WWPN on node %(node)s: %(wwpn)s')\n                     % {'node': node['id'], 'wwpn': node['WWPN']})", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "In Python, write a function to update the WWPN list of storage nodes by executing an SSH command and parsing the response."}
{"func_name": "", "func_src_before": "\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tplaylistId := utils.ParamString(r, \":playlistId\")\n\t\ttracksRepo := ds.Playlist(r.Context()).Tracks(playlistId)\n\t\tvar payload addTracksPayload\n\t\terr := json.NewDecoder(r.Body).Decode(&payload)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\terr = tracksRepo.Add(payload.Ids)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\t// Must return an object with an ID, to satisfy ReactAdmin `create` call\n\t\t_, err = w.Write([]byte(fmt.Sprintf(`{\"id\":\"%s\"}`, playlistId)))\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t}", "func_src_after": "\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tplaylistId := utils.ParamString(r, \":playlistId\")\n\t\ttracksRepo := ds.Playlist(r.Context()).Tracks(playlistId)\n\t\tvar payload addTracksPayload\n\t\terr := json.NewDecoder(r.Body).Decode(&payload)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\terr = tracksRepo.Add(payload.Ids)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\t// Must return an object with an ID, to satisfy ReactAdmin `create` call\n\t\t_, err = fmt.Fprintf(w, `{\"id\":\"%s\"}`, html.EscapeString(playlistId))\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 17, "char_start": 530, "char_end": 597, "line": "\t\t_, err = w.Write([]byte(fmt.Sprintf(`{\"id\":\"%s\"}`, playlistId)))\n"}], "added": [{"line_no": 17, "char_start": 530, "char_end": 602, "line": "\t\t_, err = fmt.Fprintf(w, `{\"id\":\"%s\"}`, html.EscapeString(playlistId))\n"}]}, "char_changes": {"deleted": [{"char_start": 541, "char_end": 556, "chars": "w.Write([]byte("}, {"char_start": 560, "char_end": 561, "chars": "S"}, {"char_start": 595, "char_end": 596, "chars": ")"}], "added": [{"char_start": 545, "char_end": 546, "chars": "F"}, {"char_start": 553, "char_end": 556, "chars": "w, "}, {"char_start": 571, "char_end": 589, "chars": "html.EscapeString("}]}, "commit_link": "github.com/cloudsonic/sonic-server/commit/9cbeddae8fc6fb729ab8fc2e2c79b39edd0caea6", "file_name": "playlists.go", "vul_type": "cwe-079", "commit_msg": "Avoid cross-site scripting\n\nSee: https://lgtm.com/rules/1510377426397/", "parent_commit": "c9b119f0a40b962f0141a434b33b74466242383b", "description": "Write a Go function that adds track IDs to a playlist and returns the playlist ID as a JSON response."}
{"func_name": "assoc_array_insert_into_terminal_node", "func_src_before": "static bool assoc_array_insert_into_terminal_node(struct assoc_array_edit *edit,\n\t\t\t\t\t\t  const struct assoc_array_ops *ops,\n\t\t\t\t\t\t  const void *index_key,\n\t\t\t\t\t\t  struct assoc_array_walk_result *result)\n{\n\tstruct assoc_array_shortcut *shortcut, *new_s0;\n\tstruct assoc_array_node *node, *new_n0, *new_n1, *side;\n\tstruct assoc_array_ptr *ptr;\n\tunsigned long dissimilarity, base_seg, blank;\n\tsize_t keylen;\n\tbool have_meta;\n\tint level, diff;\n\tint slot, next_slot, free_slot, i, j;\n\n\tnode\t= result->terminal_node.node;\n\tlevel\t= result->terminal_node.level;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = result->terminal_node.slot;\n\n\tpr_devel(\"-->%s()\\n\", __func__);\n\n\t/* We arrived at a node which doesn't have an onward node or shortcut\n\t * pointer that we have to follow.  This means that (a) the leaf we\n\t * want must go here (either by insertion or replacement) or (b) we\n\t * need to split this node and insert in one of the fragments.\n\t */\n\tfree_slot = -1;\n\n\t/* Firstly, we have to check the leaves in this node to see if there's\n\t * a matching one we should replace in place.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (!ptr) {\n\t\t\tfree_slot = i;\n\t\t\tcontinue;\n\t\t}\n\t\tif (ops->compare_object(assoc_array_ptr_to_leaf(ptr), index_key)) {\n\t\t\tpr_devel(\"replace in slot %d\\n\", i);\n\t\t\tedit->leaf_p = &node->slots[i];\n\t\t\tedit->dead_leaf = node->slots[i];\n\t\t\tpr_devel(\"<--%s() = ok [replace]\\n\", __func__);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* If there is a free slot in this node then we can just insert the\n\t * leaf here.\n\t */\n\tif (free_slot >= 0) {\n\t\tpr_devel(\"insert in free slot %d\\n\", free_slot);\n\t\tedit->leaf_p = &node->slots[free_slot];\n\t\tedit->adjust_count_on = node;\n\t\tpr_devel(\"<--%s() = ok [insert]\\n\", __func__);\n\t\treturn true;\n\t}\n\n\t/* The node has no spare slots - so we're either going to have to split\n\t * it or insert another node before it.\n\t *\n\t * Whatever, we're going to need at least two new nodes - so allocate\n\t * those now.  We may also need a new shortcut, but we deal with that\n\t * when we need it.\n\t */\n\tnew_n0 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n0)\n\t\treturn false;\n\tedit->new_meta[0] = assoc_array_node_to_ptr(new_n0);\n\tnew_n1 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n1)\n\t\treturn false;\n\tedit->new_meta[1] = assoc_array_node_to_ptr(new_n1);\n\n\t/* We need to find out how similar the leaves are. */\n\tpr_devel(\"no spare slots\\n\");\n\thave_meta = false;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (assoc_array_ptr_is_meta(ptr)) {\n\t\t\tedit->segment_cache[i] = 0xff;\n\t\t\thave_meta = true;\n\t\t\tcontinue;\n\t\t}\n\t\tbase_seg = ops->get_object_key_chunk(\n\t\t\tassoc_array_ptr_to_leaf(ptr), level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tif (have_meta) {\n\t\tpr_devel(\"have meta\\n\");\n\t\tgoto split_node;\n\t}\n\n\t/* The node contains only leaves */\n\tdissimilarity = 0;\n\tbase_seg = edit->segment_cache[0];\n\tfor (i = 1; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tdissimilarity |= edit->segment_cache[i] ^ base_seg;\n\n\tpr_devel(\"only leaves; dissimilarity=%lx\\n\", dissimilarity);\n\n\tif ((dissimilarity & ASSOC_ARRAY_FAN_MASK) == 0) {\n\t\t/* The old leaves all cluster in the same slot.  We will need\n\t\t * to insert a shortcut if the new node wants to cluster with them.\n\t\t */\n\t\tif ((edit->segment_cache[ASSOC_ARRAY_FAN_OUT] ^ base_seg) == 0)\n\t\t\tgoto all_leaves_cluster_together;\n\n\t\t/* Otherwise we can just insert a new node ahead of the old\n\t\t * one.\n\t\t */\n\t\tgoto present_leaves_cluster_but_not_new_leaf;\n\t}\n\nsplit_node:\n\tpr_devel(\"split node\\n\");\n\n\t/* We need to split the current node; we know that the node doesn't\n\t * simply contain a full set of leaves that cluster together (it\n\t * contains meta pointers and/or non-clustering leaves).\n\t *\n\t * We need to expel at least two leaves out of a set consisting of the\n\t * leaves in the node and the new leaf.\n\t *\n\t * We need a new node (n0) to replace the current one and a new node to\n\t * take the expelled nodes (n1).\n\t */\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\ndo_split_node:\n\tpr_devel(\"do_split_node\\n\");\n\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->nr_leaves_on_branch = 0;\n\n\t/* Begin by finding two matching leaves.  There have to be at least two\n\t * that match - even if there are meta pointers - because any leaf that\n\t * would match a slot with a meta pointer in it must be somewhere\n\t * behind that meta pointer and cannot be here.  Further, given N\n\t * remaining leaf slots, we now have N+1 leaves to go in them.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tslot = edit->segment_cache[i];\n\t\tif (slot != 0xff)\n\t\t\tfor (j = i + 1; j < ASSOC_ARRAY_FAN_OUT + 1; j++)\n\t\t\t\tif (edit->segment_cache[j] == slot)\n\t\t\t\t\tgoto found_slot_for_multiple_occupancy;\n\t}\nfound_slot_for_multiple_occupancy:\n\tpr_devel(\"same slot: %x %x [%02x]\\n\", i, j, slot);\n\tBUG_ON(i >= ASSOC_ARRAY_FAN_OUT);\n\tBUG_ON(j >= ASSOC_ARRAY_FAN_OUT + 1);\n\tBUG_ON(slot >= ASSOC_ARRAY_FAN_OUT);\n\n\tnew_n1->parent_slot = slot;\n\n\t/* Metadata pointers cannot change slot */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tnew_n0->slots[i] = node->slots[i];\n\t\telse\n\t\t\tnew_n0->slots[i] = NULL;\n\tBUG_ON(new_n0->slots[slot] != NULL);\n\tnew_n0->slots[slot] = assoc_array_node_to_ptr(new_n1);\n\n\t/* Filter the leaf pointers between the new nodes */\n\tfree_slot = -1;\n\tnext_slot = 0;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tcontinue;\n\t\tif (edit->segment_cache[i] == slot) {\n\t\t\tnew_n1->slots[next_slot++] = node->slots[i];\n\t\t\tnew_n1->nr_leaves_on_branch++;\n\t\t} else {\n\t\t\tdo {\n\t\t\t\tfree_slot++;\n\t\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\t\tnew_n0->slots[free_slot] = node->slots[i];\n\t\t}\n\t}\n\n\tpr_devel(\"filtered: f=%x n=%x\\n\", free_slot, next_slot);\n\n\tif (edit->segment_cache[ASSOC_ARRAY_FAN_OUT] != slot) {\n\t\tdo {\n\t\t\tfree_slot++;\n\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\tedit->leaf_p = &new_n0->slots[free_slot];\n\t\tedit->adjust_count_on = new_n0;\n\t} else {\n\t\tedit->leaf_p = &new_n1->slots[next_slot++];\n\t\tedit->adjust_count_on = new_n1;\n\t}\n\n\tBUG_ON(next_slot <= 1);\n\n\tedit->set_backpointers_to = assoc_array_node_to_ptr(new_n0);\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (edit->segment_cache[i] == 0xff) {\n\t\t\tptr = node->slots[i];\n\t\t\tBUG_ON(assoc_array_ptr_is_leaf(ptr));\n\t\t\tif (assoc_array_ptr_is_node(ptr)) {\n\t\t\t\tside = assoc_array_ptr_to_node(ptr);\n\t\t\t\tedit->set_backpointers[i] = &side->back_pointer;\n\t\t\t} else {\n\t\t\t\tshortcut = assoc_array_ptr_to_shortcut(ptr);\n\t\t\t\tedit->set_backpointers[i] = &shortcut->back_pointer;\n\t\t\t}\n\t\t}\n\t}\n\n\tptr = node->back_pointer;\n\tif (!ptr)\n\t\tedit->set[0].ptr = &edit->array->root;\n\telse if (assoc_array_ptr_is_node(ptr))\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_node(ptr)->slots[node->parent_slot];\n\telse\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_shortcut(ptr)->next_node;\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [split node]\\n\", __func__);\n\treturn true;\n\npresent_leaves_cluster_but_not_new_leaf:\n\t/* All the old leaves cluster in the same slot, but the new leaf wants\n\t * to go into a different slot, so we create a new node to hold the new\n\t * leaf and a pointer to a new node holding all the old leaves.\n\t */\n\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = edit->segment_cache[0];\n\tnew_n1->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tedit->adjust_count_on = new_n0;\n\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tnew_n1->slots[i] = node->slots[i];\n\n\tnew_n0->slots[edit->segment_cache[0]] = assoc_array_node_to_ptr(new_n0);\n\tedit->leaf_p = &new_n0->slots[edit->segment_cache[ASSOC_ARRAY_FAN_OUT]];\n\n\tedit->set[0].ptr = &assoc_array_ptr_to_node(node->back_pointer)->slots[node->parent_slot];\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [insert node before]\\n\", __func__);\n\treturn true;\n\nall_leaves_cluster_together:\n\t/* All the leaves, new and old, want to cluster together in this node\n\t * in the same slot, so we have to replace this node with a shortcut to\n\t * skip over the identical parts of the key and then place a pair of\n\t * nodes, one inside the other, at the end of the shortcut and\n\t * distribute the keys between them.\n\t *\n\t * Firstly we need to work out where the leaves start diverging as a\n\t * bit position into their keys so that we know how big the shortcut\n\t * needs to be.\n\t *\n\t * We only need to make a single pass of N of the N+1 leaves because if\n\t * any keys differ between themselves at bit X then at least one of\n\t * them must also differ with the base key at bit X or before.\n\t */\n\tpr_devel(\"all leaves cluster together\\n\");\n\tdiff = INT_MAX;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tint x = ops->diff_objects(assoc_array_ptr_to_leaf(node->slots[i]),\n\t\t\t\t\t  index_key);\n\t\tif (x < diff) {\n\t\t\tBUG_ON(x < 0);\n\t\t\tdiff = x;\n\t\t}\n\t}\n\tBUG_ON(diff == INT_MAX);\n\tBUG_ON(diff < level + ASSOC_ARRAY_LEVEL_STEP);\n\n\tkeylen = round_up(diff, ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\tkeylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT;\n\n\tnew_s0 = kzalloc(sizeof(struct assoc_array_shortcut) +\n\t\t\t keylen * sizeof(unsigned long), GFP_KERNEL);\n\tif (!new_s0)\n\t\treturn false;\n\tedit->new_meta[2] = assoc_array_shortcut_to_ptr(new_s0);\n\n\tedit->set[0].to = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_s0->back_pointer = node->back_pointer;\n\tnew_s0->parent_slot = node->parent_slot;\n\tnew_s0->next_node = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_n0->parent_slot = 0;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\n\tnew_s0->skip_to_level = level = diff & ~ASSOC_ARRAY_LEVEL_STEP_MASK;\n\tpr_devel(\"skip_to_level = %d [diff %d]\\n\", level, diff);\n\tBUG_ON(level <= 0);\n\n\tfor (i = 0; i < keylen; i++)\n\t\tnew_s0->index_key[i] =\n\t\t\tops->get_key_chunk(index_key, i * ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\n\tblank = ULONG_MAX << (level & ASSOC_ARRAY_KEY_CHUNK_MASK);\n\tpr_devel(\"blank off [%zu] %d: %lx\\n\", keylen - 1, level, blank);\n\tnew_s0->index_key[keylen - 1] &= ~blank;\n\n\t/* This now reduces to a node splitting exercise for which we'll need\n\t * to regenerate the disparity table.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tbase_seg = ops->get_object_key_chunk(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\t\t     level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tbase_seg = ops->get_key_chunk(index_key, level);\n\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\tgoto do_split_node;\n}", "func_src_after": "static bool assoc_array_insert_into_terminal_node(struct assoc_array_edit *edit,\n\t\t\t\t\t\t  const struct assoc_array_ops *ops,\n\t\t\t\t\t\t  const void *index_key,\n\t\t\t\t\t\t  struct assoc_array_walk_result *result)\n{\n\tstruct assoc_array_shortcut *shortcut, *new_s0;\n\tstruct assoc_array_node *node, *new_n0, *new_n1, *side;\n\tstruct assoc_array_ptr *ptr;\n\tunsigned long dissimilarity, base_seg, blank;\n\tsize_t keylen;\n\tbool have_meta;\n\tint level, diff;\n\tint slot, next_slot, free_slot, i, j;\n\n\tnode\t= result->terminal_node.node;\n\tlevel\t= result->terminal_node.level;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = result->terminal_node.slot;\n\n\tpr_devel(\"-->%s()\\n\", __func__);\n\n\t/* We arrived at a node which doesn't have an onward node or shortcut\n\t * pointer that we have to follow.  This means that (a) the leaf we\n\t * want must go here (either by insertion or replacement) or (b) we\n\t * need to split this node and insert in one of the fragments.\n\t */\n\tfree_slot = -1;\n\n\t/* Firstly, we have to check the leaves in this node to see if there's\n\t * a matching one we should replace in place.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (!ptr) {\n\t\t\tfree_slot = i;\n\t\t\tcontinue;\n\t\t}\n\t\tif (assoc_array_ptr_is_leaf(ptr) &&\n\t\t    ops->compare_object(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\tindex_key)) {\n\t\t\tpr_devel(\"replace in slot %d\\n\", i);\n\t\t\tedit->leaf_p = &node->slots[i];\n\t\t\tedit->dead_leaf = node->slots[i];\n\t\t\tpr_devel(\"<--%s() = ok [replace]\\n\", __func__);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* If there is a free slot in this node then we can just insert the\n\t * leaf here.\n\t */\n\tif (free_slot >= 0) {\n\t\tpr_devel(\"insert in free slot %d\\n\", free_slot);\n\t\tedit->leaf_p = &node->slots[free_slot];\n\t\tedit->adjust_count_on = node;\n\t\tpr_devel(\"<--%s() = ok [insert]\\n\", __func__);\n\t\treturn true;\n\t}\n\n\t/* The node has no spare slots - so we're either going to have to split\n\t * it or insert another node before it.\n\t *\n\t * Whatever, we're going to need at least two new nodes - so allocate\n\t * those now.  We may also need a new shortcut, but we deal with that\n\t * when we need it.\n\t */\n\tnew_n0 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n0)\n\t\treturn false;\n\tedit->new_meta[0] = assoc_array_node_to_ptr(new_n0);\n\tnew_n1 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n1)\n\t\treturn false;\n\tedit->new_meta[1] = assoc_array_node_to_ptr(new_n1);\n\n\t/* We need to find out how similar the leaves are. */\n\tpr_devel(\"no spare slots\\n\");\n\thave_meta = false;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (assoc_array_ptr_is_meta(ptr)) {\n\t\t\tedit->segment_cache[i] = 0xff;\n\t\t\thave_meta = true;\n\t\t\tcontinue;\n\t\t}\n\t\tbase_seg = ops->get_object_key_chunk(\n\t\t\tassoc_array_ptr_to_leaf(ptr), level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tif (have_meta) {\n\t\tpr_devel(\"have meta\\n\");\n\t\tgoto split_node;\n\t}\n\n\t/* The node contains only leaves */\n\tdissimilarity = 0;\n\tbase_seg = edit->segment_cache[0];\n\tfor (i = 1; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tdissimilarity |= edit->segment_cache[i] ^ base_seg;\n\n\tpr_devel(\"only leaves; dissimilarity=%lx\\n\", dissimilarity);\n\n\tif ((dissimilarity & ASSOC_ARRAY_FAN_MASK) == 0) {\n\t\t/* The old leaves all cluster in the same slot.  We will need\n\t\t * to insert a shortcut if the new node wants to cluster with them.\n\t\t */\n\t\tif ((edit->segment_cache[ASSOC_ARRAY_FAN_OUT] ^ base_seg) == 0)\n\t\t\tgoto all_leaves_cluster_together;\n\n\t\t/* Otherwise we can just insert a new node ahead of the old\n\t\t * one.\n\t\t */\n\t\tgoto present_leaves_cluster_but_not_new_leaf;\n\t}\n\nsplit_node:\n\tpr_devel(\"split node\\n\");\n\n\t/* We need to split the current node; we know that the node doesn't\n\t * simply contain a full set of leaves that cluster together (it\n\t * contains meta pointers and/or non-clustering leaves).\n\t *\n\t * We need to expel at least two leaves out of a set consisting of the\n\t * leaves in the node and the new leaf.\n\t *\n\t * We need a new node (n0) to replace the current one and a new node to\n\t * take the expelled nodes (n1).\n\t */\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\ndo_split_node:\n\tpr_devel(\"do_split_node\\n\");\n\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->nr_leaves_on_branch = 0;\n\n\t/* Begin by finding two matching leaves.  There have to be at least two\n\t * that match - even if there are meta pointers - because any leaf that\n\t * would match a slot with a meta pointer in it must be somewhere\n\t * behind that meta pointer and cannot be here.  Further, given N\n\t * remaining leaf slots, we now have N+1 leaves to go in them.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tslot = edit->segment_cache[i];\n\t\tif (slot != 0xff)\n\t\t\tfor (j = i + 1; j < ASSOC_ARRAY_FAN_OUT + 1; j++)\n\t\t\t\tif (edit->segment_cache[j] == slot)\n\t\t\t\t\tgoto found_slot_for_multiple_occupancy;\n\t}\nfound_slot_for_multiple_occupancy:\n\tpr_devel(\"same slot: %x %x [%02x]\\n\", i, j, slot);\n\tBUG_ON(i >= ASSOC_ARRAY_FAN_OUT);\n\tBUG_ON(j >= ASSOC_ARRAY_FAN_OUT + 1);\n\tBUG_ON(slot >= ASSOC_ARRAY_FAN_OUT);\n\n\tnew_n1->parent_slot = slot;\n\n\t/* Metadata pointers cannot change slot */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tnew_n0->slots[i] = node->slots[i];\n\t\telse\n\t\t\tnew_n0->slots[i] = NULL;\n\tBUG_ON(new_n0->slots[slot] != NULL);\n\tnew_n0->slots[slot] = assoc_array_node_to_ptr(new_n1);\n\n\t/* Filter the leaf pointers between the new nodes */\n\tfree_slot = -1;\n\tnext_slot = 0;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tcontinue;\n\t\tif (edit->segment_cache[i] == slot) {\n\t\t\tnew_n1->slots[next_slot++] = node->slots[i];\n\t\t\tnew_n1->nr_leaves_on_branch++;\n\t\t} else {\n\t\t\tdo {\n\t\t\t\tfree_slot++;\n\t\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\t\tnew_n0->slots[free_slot] = node->slots[i];\n\t\t}\n\t}\n\n\tpr_devel(\"filtered: f=%x n=%x\\n\", free_slot, next_slot);\n\n\tif (edit->segment_cache[ASSOC_ARRAY_FAN_OUT] != slot) {\n\t\tdo {\n\t\t\tfree_slot++;\n\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\tedit->leaf_p = &new_n0->slots[free_slot];\n\t\tedit->adjust_count_on = new_n0;\n\t} else {\n\t\tedit->leaf_p = &new_n1->slots[next_slot++];\n\t\tedit->adjust_count_on = new_n1;\n\t}\n\n\tBUG_ON(next_slot <= 1);\n\n\tedit->set_backpointers_to = assoc_array_node_to_ptr(new_n0);\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (edit->segment_cache[i] == 0xff) {\n\t\t\tptr = node->slots[i];\n\t\t\tBUG_ON(assoc_array_ptr_is_leaf(ptr));\n\t\t\tif (assoc_array_ptr_is_node(ptr)) {\n\t\t\t\tside = assoc_array_ptr_to_node(ptr);\n\t\t\t\tedit->set_backpointers[i] = &side->back_pointer;\n\t\t\t} else {\n\t\t\t\tshortcut = assoc_array_ptr_to_shortcut(ptr);\n\t\t\t\tedit->set_backpointers[i] = &shortcut->back_pointer;\n\t\t\t}\n\t\t}\n\t}\n\n\tptr = node->back_pointer;\n\tif (!ptr)\n\t\tedit->set[0].ptr = &edit->array->root;\n\telse if (assoc_array_ptr_is_node(ptr))\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_node(ptr)->slots[node->parent_slot];\n\telse\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_shortcut(ptr)->next_node;\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [split node]\\n\", __func__);\n\treturn true;\n\npresent_leaves_cluster_but_not_new_leaf:\n\t/* All the old leaves cluster in the same slot, but the new leaf wants\n\t * to go into a different slot, so we create a new node to hold the new\n\t * leaf and a pointer to a new node holding all the old leaves.\n\t */\n\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = edit->segment_cache[0];\n\tnew_n1->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tedit->adjust_count_on = new_n0;\n\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tnew_n1->slots[i] = node->slots[i];\n\n\tnew_n0->slots[edit->segment_cache[0]] = assoc_array_node_to_ptr(new_n0);\n\tedit->leaf_p = &new_n0->slots[edit->segment_cache[ASSOC_ARRAY_FAN_OUT]];\n\n\tedit->set[0].ptr = &assoc_array_ptr_to_node(node->back_pointer)->slots[node->parent_slot];\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [insert node before]\\n\", __func__);\n\treturn true;\n\nall_leaves_cluster_together:\n\t/* All the leaves, new and old, want to cluster together in this node\n\t * in the same slot, so we have to replace this node with a shortcut to\n\t * skip over the identical parts of the key and then place a pair of\n\t * nodes, one inside the other, at the end of the shortcut and\n\t * distribute the keys between them.\n\t *\n\t * Firstly we need to work out where the leaves start diverging as a\n\t * bit position into their keys so that we know how big the shortcut\n\t * needs to be.\n\t *\n\t * We only need to make a single pass of N of the N+1 leaves because if\n\t * any keys differ between themselves at bit X then at least one of\n\t * them must also differ with the base key at bit X or before.\n\t */\n\tpr_devel(\"all leaves cluster together\\n\");\n\tdiff = INT_MAX;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tint x = ops->diff_objects(assoc_array_ptr_to_leaf(node->slots[i]),\n\t\t\t\t\t  index_key);\n\t\tif (x < diff) {\n\t\t\tBUG_ON(x < 0);\n\t\t\tdiff = x;\n\t\t}\n\t}\n\tBUG_ON(diff == INT_MAX);\n\tBUG_ON(diff < level + ASSOC_ARRAY_LEVEL_STEP);\n\n\tkeylen = round_up(diff, ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\tkeylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT;\n\n\tnew_s0 = kzalloc(sizeof(struct assoc_array_shortcut) +\n\t\t\t keylen * sizeof(unsigned long), GFP_KERNEL);\n\tif (!new_s0)\n\t\treturn false;\n\tedit->new_meta[2] = assoc_array_shortcut_to_ptr(new_s0);\n\n\tedit->set[0].to = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_s0->back_pointer = node->back_pointer;\n\tnew_s0->parent_slot = node->parent_slot;\n\tnew_s0->next_node = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_n0->parent_slot = 0;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\n\tnew_s0->skip_to_level = level = diff & ~ASSOC_ARRAY_LEVEL_STEP_MASK;\n\tpr_devel(\"skip_to_level = %d [diff %d]\\n\", level, diff);\n\tBUG_ON(level <= 0);\n\n\tfor (i = 0; i < keylen; i++)\n\t\tnew_s0->index_key[i] =\n\t\t\tops->get_key_chunk(index_key, i * ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\n\tblank = ULONG_MAX << (level & ASSOC_ARRAY_KEY_CHUNK_MASK);\n\tpr_devel(\"blank off [%zu] %d: %lx\\n\", keylen - 1, level, blank);\n\tnew_s0->index_key[keylen - 1] &= ~blank;\n\n\t/* This now reduces to a node splitting exercise for which we'll need\n\t * to regenerate the disparity table.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tbase_seg = ops->get_object_key_chunk(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\t\t     level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tbase_seg = ops->get_key_chunk(index_key, level);\n\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\tgoto do_split_node;\n}", "commit_link": "github.com/torvalds/linux/commit/8d4a2ec1e0b41b0cf9a0c5cd4511da7f8e4f3de2", "file_name": "lib/assoc_array.c", "vul_type": "cwe-476", "description": "Write a C function to insert or replace a key in an associative array node, handling node splits if necessary."}
{"func_name": "audit", "func_src_before": "  def audit\n    audit_args.parse\n\n    Homebrew.auditing = true\n    inject_dump_stats!(FormulaAuditor, /^audit_/) if args.audit_debug?\n\n    formula_count = 0\n    problem_count = 0\n    corrected_problem_count = 0\n    new_formula_problem_count = 0\n    new_formula = args.new_formula?\n    strict = new_formula || args.strict?\n    online = new_formula || args.online?\n    git = args.git?\n    skip_style = args.skip_style? || args.no_named?\n\n    ENV.activate_extensions!\n    ENV.setup_build_environment\n\n    audit_formulae = args.no_named? ? Formula : args.resolved_formulae\n    style_files = args.formulae_paths unless skip_style\n\n    only_cops = args.only_cops\n    except_cops = args.except_cops\n    options = { fix: args.fix? }\n\n    if only_cops\n      options[:only_cops] = only_cops\n    elsif args.new_formula?\n      nil\n    elsif except_cops\n      options[:except_cops] = except_cops\n    elsif !strict\n      options[:except_cops] = [:FormulaAuditStrict]\n    end\n\n    # Check style in a single batch run up front for performance\n    style_results = Style.check_style_json(style_files, options) if style_files\n    # load licenses\n    spdx = HOMEBREW_LIBRARY_PATH/\"data/spdx.json\"\n    spdx_data = open(spdx, \"r\") do |file|\n      JSON.parse(file.read)\n    end\n    new_formula_problem_lines = []\n    audit_formulae.sort.each do |f|\n      only = only_cops ? [\"style\"] : args.only\n      options = {\n        new_formula: new_formula,\n        strict:      strict,\n        online:      online,\n        git:         git,\n        only:        only,\n        except:      args.except,\n        spdx_data:   spdx_data,\n      }\n      options[:style_offenses] = style_results.file_offenses(f.path) if style_results\n      options[:display_cop_names] = args.display_cop_names?\n\n      fa = FormulaAuditor.new(f, options)\n      fa.audit\n      next if fa.problems.empty? && fa.new_formula_problems.empty?\n\n      fa.problems\n      formula_count += 1\n      problem_count += fa.problems.size\n      problem_lines = format_problem_lines(fa.problems)\n      corrected_problem_count = options[:style_offenses].count(&:corrected?) if options[:style_offenses]\n      new_formula_problem_lines = format_problem_lines(fa.new_formula_problems)\n      if args.display_filename?\n        puts problem_lines.map { |s| \"#{f.path}: #{s}\" }\n      else\n        puts \"#{f.full_name}:\", problem_lines.map { |s| \"  #{s}\" }\n      end", "func_src_after": "  def audit\n    audit_args.parse\n\n    Homebrew.auditing = true\n    inject_dump_stats!(FormulaAuditor, /^audit_/) if args.audit_debug?\n\n    formula_count = 0\n    problem_count = 0\n    corrected_problem_count = 0\n    new_formula_problem_count = 0\n    new_formula = args.new_formula?\n    strict = new_formula || args.strict?\n    online = new_formula || args.online?\n    git = args.git?\n    skip_style = args.skip_style? || args.no_named?\n\n    ENV.activate_extensions!\n    ENV.setup_build_environment\n\n    audit_formulae = args.no_named? ? Formula : args.resolved_formulae\n    style_files = args.formulae_paths unless skip_style\n\n    only_cops = args.only_cops\n    except_cops = args.except_cops\n    options = { fix: args.fix? }\n\n    if only_cops\n      options[:only_cops] = only_cops\n    elsif args.new_formula?\n      nil\n    elsif except_cops\n      options[:except_cops] = except_cops\n    elsif !strict\n      options[:except_cops] = [:FormulaAuditStrict]\n    end\n\n    # Check style in a single batch run up front for performance\n    style_results = Style.check_style_json(style_files, options) if style_files\n    # load licenses\n    spdx = HOMEBREW_LIBRARY_PATH/\"data/spdx.json\"\n    spdx_data = File.open(spdx, \"r\") do |file|\n      JSON.parse(file.read)\n    end\n    new_formula_problem_lines = []\n    audit_formulae.sort.each do |f|\n      only = only_cops ? [\"style\"] : args.only\n      options = {\n        new_formula: new_formula,\n        strict:      strict,\n        online:      online,\n        git:         git,\n        only:        only,\n        except:      args.except,\n        spdx_data:   spdx_data,\n      }\n      options[:style_offenses] = style_results.file_offenses(f.path) if style_results\n      options[:display_cop_names] = args.display_cop_names?\n\n      fa = FormulaAuditor.new(f, options)\n      fa.audit\n      next if fa.problems.empty? && fa.new_formula_problems.empty?\n\n      fa.problems\n      formula_count += 1\n      problem_count += fa.problems.size\n      problem_lines = format_problem_lines(fa.problems)\n      corrected_problem_count = options[:style_offenses].count(&:corrected?) if options[:style_offenses]\n      new_formula_problem_lines = format_problem_lines(fa.new_formula_problems)\n      if args.display_filename?\n        puts problem_lines.map { |s| \"#{f.path}: #{s}\" }\n      else\n        puts \"#{f.full_name}:\", problem_lines.map { |s| \"  #{s}\" }\n      end", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1177, "char_end": 1219, "line": "    spdx_data = open(spdx, \"r\") do |file|\n"}], "added": [{"line_no": 41, "char_start": 1177, "char_end": 1224, "line": "    spdx_data = File.open(spdx, \"r\") do |file|\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1193, "char_end": 1198, "chars": "File."}]}, "commit_link": "github.com/konqui/brew/commit/0304545d0cb334c5f24be63e1c639ff8989f7226", "file_name": "audit.rb", "vul_type": "cwe-078", "commit_msg": "use File.open instead of Kernel.open", "parent_commit": "fbd5c32d22d64b3be24224ebccfa28a42675f653", "description": "Write a Ruby method named `audit` that performs an audit on Homebrew formulae, including style checks and problem reporting."}
{"func_name": "kvm_ioctl_create_device", "func_src_before": "static int kvm_ioctl_create_device(struct kvm *kvm,\n\t\t\t\t   struct kvm_create_device *cd)\n{\n\tstruct kvm_device_ops *ops = NULL;\n\tstruct kvm_device *dev;\n\tbool test = cd->flags & KVM_CREATE_DEVICE_TEST;\n\tint ret;\n\n\tif (cd->type >= ARRAY_SIZE(kvm_device_ops_table))\n\t\treturn -ENODEV;\n\n\tops = kvm_device_ops_table[cd->type];\n\tif (ops == NULL)\n\t\treturn -ENODEV;\n\n\tif (test)\n\t\treturn 0;\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tdev->ops = ops;\n\tdev->kvm = kvm;\n\n\tmutex_lock(&kvm->lock);\n\tret = ops->create(dev, cd->type);\n\tif (ret < 0) {\n\t\tmutex_unlock(&kvm->lock);\n\t\tkfree(dev);\n\t\treturn ret;\n\t}\n\tlist_add(&dev->vm_node, &kvm->devices);\n\tmutex_unlock(&kvm->lock);\n\n\tif (ops->init)\n\t\tops->init(dev);\n\n\tret = anon_inode_getfd(ops->name, &kvm_device_fops, dev, O_RDWR | O_CLOEXEC);\n\tif (ret < 0) {\n\t\tops->destroy(dev);\n\t\tmutex_lock(&kvm->lock);\n\t\tlist_del(&dev->vm_node);\n\t\tmutex_unlock(&kvm->lock);\n\t\treturn ret;\n\t}\n\n\tkvm_get_kvm(kvm);\n\tcd->fd = ret;\n\treturn 0;\n}", "func_src_after": "static int kvm_ioctl_create_device(struct kvm *kvm,\n\t\t\t\t   struct kvm_create_device *cd)\n{\n\tstruct kvm_device_ops *ops = NULL;\n\tstruct kvm_device *dev;\n\tbool test = cd->flags & KVM_CREATE_DEVICE_TEST;\n\tint ret;\n\n\tif (cd->type >= ARRAY_SIZE(kvm_device_ops_table))\n\t\treturn -ENODEV;\n\n\tops = kvm_device_ops_table[cd->type];\n\tif (ops == NULL)\n\t\treturn -ENODEV;\n\n\tif (test)\n\t\treturn 0;\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tdev->ops = ops;\n\tdev->kvm = kvm;\n\n\tmutex_lock(&kvm->lock);\n\tret = ops->create(dev, cd->type);\n\tif (ret < 0) {\n\t\tmutex_unlock(&kvm->lock);\n\t\tkfree(dev);\n\t\treturn ret;\n\t}\n\tlist_add(&dev->vm_node, &kvm->devices);\n\tmutex_unlock(&kvm->lock);\n\n\tif (ops->init)\n\t\tops->init(dev);\n\n\tret = anon_inode_getfd(ops->name, &kvm_device_fops, dev, O_RDWR | O_CLOEXEC);\n\tif (ret < 0) {\n\t\tmutex_lock(&kvm->lock);\n\t\tlist_del(&dev->vm_node);\n\t\tmutex_unlock(&kvm->lock);\n\t\tops->destroy(dev);\n\t\treturn ret;\n\t}\n\n\tkvm_get_kvm(kvm);\n\tcd->fd = ret;\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/a0f1d21c1ccb1da66629627a74059dd7f5ac9c61", "file_name": "virt/kvm/kvm_main.c", "vul_type": "cwe-416", "description": "In C, write a function to handle the creation of a new KVM device, including memory allocation and error checking."}
{"func_name": "jbig2_image_compose", "func_src_before": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "func_src_after": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    if ((UINT32_MAX - src->width  < (x > 0 ? x : -x)) ||\n        (UINT32_MAX - src->height < (y > 0 ? y : -y)))\n    {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"overflow in compose_image\");\n#endif\n        return 0;\n    }\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "commit_link": "github.com/ArtifexSoftware/jbig2dec/commit/0726320a4b55078e9d8deb590e477d598b3da66e", "file_name": "jbig2_image.c", "vul_type": "cwe-787", "description": "Write a C function to overlay one image onto another at a specified position using a given composition operation."}
{"func_name": "smprintf", "func_src_before": "smprintf(const char *fmt, ...)\n{\n\tva_list fmtargs;\n\tchar tmp[120];\n\tchar *ret = NULL;\n\n\tva_start(fmtargs, fmt);\n\tsnprintf(tmp, sizeof(tmp)-1, fmt, fmtargs);\n\ttmp[sizeof(tmp)] = '\\0';\n\tif (asprintf(&ret, \"%s\", tmp) < 0)\n\t\treturn NULL;\n\n\tva_end(fmtargs);\n\treturn ret;\n}", "func_src_after": "smprintf(const char *fmt, ...)\n{\n\t/* FIXME: This code should have\n\tbound checks, it is vulnerable to\n\tbuffer overflows */\n\tva_list ap;\n\tchar *ret = NULL;\n\n\tva_start(ap, fmt);\n\tif (vasprintf(&ret, fmt, ap) < 0)\n\t\treturn NULL;\n\n\tva_end(ap);\n\treturn ret;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 33, "char_end": 51, "line": "\tva_list fmtargs;\n"}, {"line_no": 4, "char_start": 51, "char_end": 67, "line": "\tchar tmp[120];\n"}, {"line_no": 7, "char_start": 87, "char_end": 112, "line": "\tva_start(fmtargs, fmt);\n"}, {"line_no": 8, "char_start": 112, "char_end": 157, "line": "\tsnprintf(tmp, sizeof(tmp)-1, fmt, fmtargs);\n"}, {"line_no": 9, "char_start": 157, "char_end": 183, "line": "\ttmp[sizeof(tmp)] = '\\0';\n"}, {"line_no": 10, "char_start": 183, "char_end": 219, "line": "\tif (asprintf(&ret, \"%s\", tmp) < 0)\n"}, {"line_no": 13, "char_start": 235, "char_end": 253, "line": "\tva_end(fmtargs);\n"}], "added": [{"line_no": 3, "char_start": 33, "char_end": 66, "line": "\t/* FIXME: This code should have\n"}, {"line_no": 4, "char_start": 66, "char_end": 101, "line": "\tbound checks, it is vulnerable to\n"}, {"line_no": 5, "char_start": 101, "char_end": 122, "line": "\tbuffer overflows */\n"}, {"line_no": 6, "char_start": 122, "char_end": 135, "line": "\tva_list ap;\n"}, {"line_no": 9, "char_start": 155, "char_end": 175, "line": "\tva_start(ap, fmt);\n"}, {"line_no": 10, "char_start": 175, "char_end": 210, "line": "\tif (vasprintf(&ret, fmt, ap) < 0)\n"}, {"line_no": 13, "char_start": 226, "char_end": 239, "line": "\tva_end(ap);\n"}]}, "char_changes": {"deleted": [{"char_start": 34, "char_end": 181, "chars": "va_list fmtargs;\n\tchar tmp[120];\n\tchar *ret = NULL;\n\n\tva_start(fmtargs, fmt);\n\tsnprintf(tmp, sizeof(tmp)-1, fmt, fmtargs);\n\ttmp[sizeof(tmp)] = '\\0'"}, {"char_start": 203, "char_end": 211, "chars": "\"%s\", tm"}, {"char_start": 243, "char_end": 250, "chars": "fmtargs"}], "added": [{"char_start": 34, "char_end": 173, "chars": "/* FIXME: This code should have\n\tbound checks, it is vulnerable to\n\tbuffer overflows */\n\tva_list ap;\n\tchar *ret = NULL;\n\n\tva_start(ap, fmt)"}, {"char_start": 180, "char_end": 181, "chars": "v"}, {"char_start": 196, "char_end": 202, "chars": "fmt, a"}, {"char_start": 234, "char_end": 236, "chars": "ap"}]}, "commit_link": "github.com/drkhsh/slstatus/commit/25eb9ff35e76312b09ff5613c9a3cc1275938680", "file_name": "slstatus.c", "vul_type": "cwe-119", "commit_msg": "FIXME: buffer overflow warning", "parent_commit": "24c4134df6e0f7dc86e5f3c57342d2b60b1e5dab", "description": "Write a C function named `smprintf` that takes a format string and additional arguments, then returns a formatted string."}
{"func_name": "test_raises_error_when_config_is_missing", "func_src_before": "  def test_raises_error_when_config_is_missing\n    YAML.stub :load, -> { raise \"bad things\" } do\n      exception = assert_raises(ArgumentError) do\n        # using eval here, sorry :(\n        eval <<-CLASS, binding, __FILE__, __LINE__ + 1\n          class SomeWidget < ApplicationRecord\n            acts_as_textcaptcha\n          end\n        CLASS\n      end\n      assert_match(/could not find any textcaptcha options/, exception.message)\n    end\n  end", "func_src_after": "  def test_raises_error_when_config_is_missing\n    YAML.stub :safe_load, -> { raise \"bad things\" } do\n      exception = assert_raises(ArgumentError) do\n        # using eval here, sorry :(\n        eval <<-CLASS, binding, __FILE__, __LINE__ + 1\n          class SomeWidget < ApplicationRecord\n            acts_as_textcaptcha\n          end\n        CLASS\n      end\n      assert_match(/could not find any textcaptcha options/, exception.message)\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 47, "char_end": 97, "line": "    YAML.stub :load, -> { raise \"bad things\" } do\n"}], "added": [{"line_no": 2, "char_start": 47, "char_end": 102, "line": "    YAML.stub :safe_load, -> { raise \"bad things\" } do\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 62, "char_end": 67, "chars": "safe_"}]}, "commit_link": "github.com/matthutchinson/acts_as_textcaptcha/commit/09b2c281859c07e8cc966e604153ba97bc3c6ec2", "file_name": "textcaptcha_test.rb", "vul_type": "cwe-502", "commit_msg": "update tests to use YAML.safe_load", "parent_commit": "f9b9d1623306bb621cd1c14574a4a07513368ce7", "description": "Write a Ruby test method that checks if an error is raised when a configuration for a widget class is missing."}
{"func_name": "terminate_connection", "func_src_before": "    def terminate_connection(self, volume, connector, **kwargs):\n        \"\"\"Cleanup after an iSCSI connection has been terminated.\n\n        When we clean up a terminated connection between a given connector\n        and volume, we:\n        1. Translate the given connector to a host name\n        2. Remove the volume-to-host mapping if it exists\n        3. Delete the host if it has no more mappings (hosts are created\n           automatically by this driver when mappings are created)\n        \"\"\"\n        LOG.debug(_('enter: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})\n\n        vol_name = volume['name']\n        host_name = self._get_host_from_connector(connector)\n        # Verify that _get_host_from_connector returned the host.\n        # This should always succeed as we terminate an existing connection.\n        self._driver_assert(\n            host_name is not None,\n            _('_get_host_from_connector failed to return the host name '\n              'for connector'))\n\n        # Check if vdisk-host mapping exists, remove if it does\n        mapping_data = self._get_hostvdisk_mappings(host_name)\n        if vol_name in mapping_data:\n            ssh_cmd = 'svctask rmvdiskhostmap -host %s %s' % \\\n                (host_name, vol_name)\n            out, err = self._run_ssh(ssh_cmd)\n            # Verify CLI behaviour - no output is returned from\n            # rmvdiskhostmap\n            self._assert_ssh_return(len(out.strip()) == 0,\n                                    'terminate_connection', ssh_cmd, out, err)\n            del mapping_data[vol_name]\n        else:\n            LOG.error(_('terminate_connection: No mapping of volume '\n                        '%(vol_name)s to host %(host_name)s found') %\n                      {'vol_name': vol_name, 'host_name': host_name})\n\n        # If this host has no more mappings, delete it\n        if not mapping_data:\n            self._delete_host(host_name)\n\n        LOG.debug(_('leave: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})", "func_src_after": "    def terminate_connection(self, volume, connector, **kwargs):\n        \"\"\"Cleanup after an iSCSI connection has been terminated.\n\n        When we clean up a terminated connection between a given connector\n        and volume, we:\n        1. Translate the given connector to a host name\n        2. Remove the volume-to-host mapping if it exists\n        3. Delete the host if it has no more mappings (hosts are created\n           automatically by this driver when mappings are created)\n        \"\"\"\n        LOG.debug(_('enter: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})\n\n        vol_name = volume['name']\n        host_name = self._get_host_from_connector(connector)\n        # Verify that _get_host_from_connector returned the host.\n        # This should always succeed as we terminate an existing connection.\n        self._driver_assert(\n            host_name is not None,\n            _('_get_host_from_connector failed to return the host name '\n              'for connector'))\n\n        # Check if vdisk-host mapping exists, remove if it does\n        mapping_data = self._get_hostvdisk_mappings(host_name)\n        if vol_name in mapping_data:\n            ssh_cmd = ['svctask', 'rmvdiskhostmap', '-host', host_name,\n                       vol_name]\n            out, err = self._run_ssh(ssh_cmd)\n            # Verify CLI behaviour - no output is returned from\n            # rmvdiskhostmap\n            self._assert_ssh_return(len(out.strip()) == 0,\n                                    'terminate_connection', ssh_cmd, out, err)\n            del mapping_data[vol_name]\n        else:\n            LOG.error(_('terminate_connection: No mapping of volume '\n                        '%(vol_name)s to host %(host_name)s found') %\n                      {'vol_name': vol_name, 'host_name': host_name})\n\n        # If this host has no more mappings, delete it\n        if not mapping_data:\n            self._delete_host(host_name)\n\n        LOG.debug(_('leave: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to clean up resources after an iSCSI connection is terminated."}
{"func_name": "_formatCredentials", "func_src_before": "    def _formatCredentials(self, data, name):\n        \"\"\"\n        Credentials are of the form\n        RCLONE_CONFIG_CURRENT_TYPE=s3\n            ^          ^        ^   ^\n        [mandatory  ][name  ][key][value]\n        \"\"\"\n\n        prefix = \"RCLONE_CONFIG_{}\".format(name.upper())\n\n        credentials = ''\n        credentials += \"{}_TYPE='{}' \".format(prefix, data.type)\n\n        def _addCredential(credentials, env_key, data_key):\n            value = getattr(data, data_key, None)\n            if value is not None:\n                credentials += \"{}='{}' \".format(env_key, value)\n            return credentials\n\n\n        if data.type == 's3':\n            credentials = _addCredential(credentials,\n                '{}_REGION'.format(prefix),\n                's3_region'\n            )\n            credentials = _addCredential(credentials,\n                '{}_ACCESS_KEY_ID'.format(prefix),\n                's3_access_key_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SECRET_ACCESS_KEY'.format(prefix),\n                's3_secret_access_key'\n            )\n\n            credentials = _addCredential(credentials,\n                '{}_ENDPOINT'.format(prefix),\n                's3_endpoint'\n            )\n            credentials = _addCredential(credentials,\n                '{}_V2_AUTH'.format(prefix),\n                's3_v2_auth'\n            )\n\n        elif data.type == 'azureblob':\n            credentials = _addCredential(credentials,\n                '{}_ACCOUNT'.format(prefix),\n                'azure_account'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'azure_key'\n            )\n\n        elif data.type == 'swift':\n            credentials = _addCredential(credentials,\n                '{}_USER'.format(prefix),\n                'swift_user'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'swift_key'\n            )\n            credentials = _addCredential(credentials,\n                '{}_AUTH'.format(prefix),\n                'swift_auth'\n            )\n            credentials = _addCredential(credentials,\n                '{}_TENANT'.format(prefix),\n                'swift_tenant'\n            )\n\n        elif data.type == 'google cloud storage':\n            credentials = _addCredential(credentials,\n                '{}_CLIENT_ID'.format(prefix),\n                'gcp_client_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SERVICE_ACCOUNT_CREDENTIALS'.format(prefix),\n                'gcp_service_account_credentials'\n            )\n            credentials = _addCredential(credentials,\n                '{}_PROJECT_NUMBER'.format(prefix),\n                'gcp_project_number'\n            )\n            credentials = _addCredential(credentials,\n                '{}_OBJECT_ACL'.format(prefix),\n                'gcp_object_acl'\n            )\n            credentials = _addCredential(credentials,\n                '{}_BUCKET_ACL'.format(prefix),\n                'gcp_bucket_acl'\n            )\n\n        else:\n            logging.error(\"Connection type unknown: {}\".format(data.type))\n\n        return credentials", "func_src_after": "    def _formatCredentials(self, data, name):\n        \"\"\"\n        Credentials are of the form\n        RCLONE_CONFIG_CURRENT_TYPE=s3\n            ^          ^        ^   ^\n        [mandatory  ][name  ][key][value]\n        \"\"\"\n\n        prefix = \"RCLONE_CONFIG_{}\".format(name.upper())\n\n        credentials = {}\n        credentials['{}_TYPE'.format(prefix)] = data.type\n\n        def _addCredential(credentials, env_key, data_key):\n            value = getattr(data, data_key, None)\n            if value is not None:\n                credentials[env_key] = value\n            return credentials\n\n\n        if data.type == 's3':\n            credentials = _addCredential(credentials,\n                '{}_REGION'.format(prefix),\n                's3_region'\n            )\n            credentials = _addCredential(credentials,\n                '{}_ACCESS_KEY_ID'.format(prefix),\n                's3_access_key_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SECRET_ACCESS_KEY'.format(prefix),\n                's3_secret_access_key'\n            )\n\n            credentials = _addCredential(credentials,\n                '{}_ENDPOINT'.format(prefix),\n                's3_endpoint'\n            )\n            credentials = _addCredential(credentials,\n                '{}_V2_AUTH'.format(prefix),\n                's3_v2_auth'\n            )\n\n        elif data.type == 'azureblob':\n            credentials = _addCredential(credentials,\n                '{}_ACCOUNT'.format(prefix),\n                'azure_account'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'azure_key'\n            )\n\n        elif data.type == 'swift':\n            credentials = _addCredential(credentials,\n                '{}_USER'.format(prefix),\n                'swift_user'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'swift_key'\n            )\n            credentials = _addCredential(credentials,\n                '{}_AUTH'.format(prefix),\n                'swift_auth'\n            )\n            credentials = _addCredential(credentials,\n                '{}_TENANT'.format(prefix),\n                'swift_tenant'\n            )\n\n        elif data.type == 'google cloud storage':\n            credentials = _addCredential(credentials,\n                '{}_CLIENT_ID'.format(prefix),\n                'gcp_client_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SERVICE_ACCOUNT_CREDENTIALS'.format(prefix),\n                'gcp_service_account_credentials'\n            )\n            credentials = _addCredential(credentials,\n                '{}_PROJECT_NUMBER'.format(prefix),\n                'gcp_project_number'\n            )\n            credentials = _addCredential(credentials,\n                '{}_OBJECT_ACL'.format(prefix),\n                'gcp_object_acl'\n            )\n            credentials = _addCredential(credentials,\n                '{}_BUCKET_ACL'.format(prefix),\n                'gcp_bucket_acl'\n            )\n\n        else:\n            logging.error(\"Connection type unknown: {}\".format(data.type))\n\n        return credentials", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function to format cloud storage credentials into a string or dictionary based on the storage type."}
{"func_name": "GetAvailablePort", "func_src_before": "func GetAvailablePort(t *testing.T) uint16 {\n\t// Retry has been added for windows as net.Listen can return a port that is not actually available. Details can be\n\t// found in https://github.com/docker/for-win/issues/3171 but to summarize Hyper-V will reserve ranges of ports\n\t// which do not show up under the \"netstat -ano\" but can only be found by\n\t// \"netsh interface ipv4 show excludedportrange protocol=tcp\".  We'll use []exclusions to hold those ranges and\n\t// retry if the port returned by GetAvailableLocalAddress falls in one of those them.\n\tvar exclusions []portpair\n\tportFound := false\n\tvar port string\n\tvar err error\n\tif runtime.GOOS == \"windows\" {\n\t\texclusions = getExclusionsList(t)\n\t}\n\n\tfor !portFound {\n\t\tendpoint := GetAvailableLocalAddress(t)\n\t\t_, port, err = net.SplitHostPort(endpoint)\n\t\trequire.NoError(t, err)\n\t\tportFound = true\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tfor _, pair := range exclusions {\n\t\t\t\tif port >= pair.first && port <= pair.last {\n\t\t\t\t\tportFound = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tportInt, err := strconv.Atoi(port)\n\trequire.NoError(t, err)\n\n\treturn uint16(portInt)\n}", "func_src_after": "func GetAvailablePort(t *testing.T) uint16 {\n\t// Retry has been added for windows as net.Listen can return a port that is not actually available. Details can be\n\t// found in https://github.com/docker/for-win/issues/3171 but to summarize Hyper-V will reserve ranges of ports\n\t// which do not show up under the \"netstat -ano\" but can only be found by\n\t// \"netsh interface ipv4 show excludedportrange protocol=tcp\".  We'll use []exclusions to hold those ranges and\n\t// retry if the port returned by GetAvailableLocalAddress falls in one of those them.\n\tvar exclusions []portpair\n\tportFound := false\n\tvar port string\n\tvar err error\n\tif runtime.GOOS == \"windows\" {\n\t\texclusions = getExclusionsList(t)\n\t}\n\n\tfor !portFound {\n\t\tendpoint := GetAvailableLocalAddress(t)\n\t\t_, port, err = net.SplitHostPort(endpoint)\n\t\trequire.NoError(t, err)\n\t\tportFound = true\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tfor _, pair := range exclusions {\n\t\t\t\tif port >= pair.first && port <= pair.last {\n\t\t\t\t\tportFound = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tportInt, err := strconv.ParseUint(port, 10, 16)\n\trequire.NoError(t, err)\n\n\treturn uint16(portInt)\n}", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1022, "char_end": 1058, "line": "\tportInt, err := strconv.Atoi(port)\n"}], "added": [{"line_no": 30, "char_start": 1022, "char_end": 1071, "line": "\tportInt, err := strconv.ParseUint(port, 10, 16)\n"}]}, "char_changes": {"deleted": [{"char_start": 1047, "char_end": 1056, "chars": "Atoi(port"}], "added": [{"char_start": 1047, "char_end": 1069, "chars": "ParseUint(port, 10, 16"}]}, "commit_link": "github.com/open-telemetry/opentelemetry-collector/commit/eb3601a05900f70e46c058facf16461efa7b09f0", "file_name": "testutil.go", "vul_type": "cwe-681", "commit_msg": "Avoid potential integer overflow (#4277)\n\nSigned-off-by: Bogdan Drutu <bogdandrutu@gmail.com>", "parent_commit": "db6d31e9acc546e043b7b5564377bd76998e74bd", "description": "Write a Go function that finds an available network port, with special handling for Windows due to reserved port ranges."}
{"func_name": "get_ports", "func_src_before": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run('showport', None)\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run('showport -iscsi', None)\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run('showport -iscsiname', None)\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "func_src_after": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run(['showport'])\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run(['showport', '-iscsi'])\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run(['showport', '-iscsiname'])\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to parse and return active FC and iSCSI port details from CLI output."}
{"func_name": "mif_process_cmpt", "func_src_before": "static int mif_process_cmpt(mif_hdr_t *hdr, char *buf)\n{\n\tjas_tvparser_t *tvp;\n\tmif_cmpt_t *cmpt;\n\tint id;\n\n\tcmpt = 0;\n\ttvp = 0;\n\n\tif (!(cmpt = mif_cmpt_create())) {\n\t\tgoto error;\n\t}\n\tcmpt->tlx = 0;\n\tcmpt->tly = 0;\n\tcmpt->sampperx = 0;\n\tcmpt->samppery = 0;\n\tcmpt->width = 0;\n\tcmpt->height = 0;\n\tcmpt->prec = 0;\n\tcmpt->sgnd = -1;\n\tcmpt->data = 0;\n\n\tif (!(tvp = jas_tvparser_create(buf))) {\n\t\tgoto error;\n\t}\n\twhile (!(id = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(mif_tags,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase MIF_TLX:\n\t\t\tcmpt->tlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_TLY:\n\t\t\tcmpt->tly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_WIDTH:\n\t\t\tcmpt->width = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HEIGHT:\n\t\t\tcmpt->height = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HSAMP:\n\t\t\tcmpt->sampperx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_VSAMP:\n\t\t\tcmpt->samppery = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_PREC:\n\t\t\tcmpt->prec = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_SGND:\n\t\t\tcmpt->sgnd = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_DATA:\n\t\t\tif (!(cmpt->data = jas_strdup(jas_tvparser_getval(tvp)))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tjas_tvparser_destroy(tvp);\n\tif (!cmpt->sampperx || !cmpt->samppery) {\n\t\tgoto error;\n\t}\n\tif (mif_hdr_addcmpt(hdr, hdr->numcmpts, cmpt)) {\n\t\tgoto error;\n\t}\n\treturn 0;\n\nerror:\n\tif (cmpt) {\n\t\tmif_cmpt_destroy(cmpt);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\treturn -1;\n}", "func_src_after": "static int mif_process_cmpt(mif_hdr_t *hdr, char *buf)\n{\n\tjas_tvparser_t *tvp;\n\tmif_cmpt_t *cmpt;\n\tint id;\n\n\tcmpt = 0;\n\ttvp = 0;\n\n\tif (!(cmpt = mif_cmpt_create())) {\n\t\tgoto error;\n\t}\n\tcmpt->tlx = 0;\n\tcmpt->tly = 0;\n\tcmpt->sampperx = 0;\n\tcmpt->samppery = 0;\n\tcmpt->width = 0;\n\tcmpt->height = 0;\n\tcmpt->prec = 0;\n\tcmpt->sgnd = -1;\n\tcmpt->data = 0;\n\n\tif (!(tvp = jas_tvparser_create(buf))) {\n\t\tgoto error;\n\t}\n\twhile (!(id = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(mif_tags,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase MIF_TLX:\n\t\t\tcmpt->tlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_TLY:\n\t\t\tcmpt->tly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_WIDTH:\n\t\t\tcmpt->width = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HEIGHT:\n\t\t\tcmpt->height = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HSAMP:\n\t\t\tcmpt->sampperx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_VSAMP:\n\t\t\tcmpt->samppery = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_PREC:\n\t\t\tcmpt->prec = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_SGND:\n\t\t\tcmpt->sgnd = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_DATA:\n\t\t\tif (!(cmpt->data = jas_strdup(jas_tvparser_getval(tvp)))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!cmpt->sampperx || !cmpt->samppery) {\n\t\tgoto error;\n\t}\n\tif (mif_hdr_addcmpt(hdr, hdr->numcmpts, cmpt)) {\n\t\tgoto error;\n\t}\n\tjas_tvparser_destroy(tvp);\n\treturn 0;\n\nerror:\n\tif (cmpt) {\n\t\tmif_cmpt_destroy(cmpt);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\treturn -1;\n}", "commit_link": "github.com/mdadams/jasper/commit/df5d2867e8004e51e18b89865bc4aa69229227b3", "file_name": "src/libjasper/mif/mif_cod.c", "vul_type": "cwe-416", "description": "Write a C function to parse component information from a buffer and add it to a MIF header, handling errors appropriately."}
{"func_name": "render", "func_src_before": "  render() {\n\n    const {\n      isFetching,\n      isLoggedIn,\n      profile,\n      superEdges,\n      entityCount,\n      messagesConnect,\n      heartValue,\n      heartCount,\n      links,\n      title,\n      queryLink,\n      isParsed,\n    } = this.props;\n\n    const {\n      connectionDisplayIndex,\n      isAddConnectionToggledOn,\n      heartClickAttempted,\n      rotateConnectionBox,\n      isLoginRedirectToggledOn,\n    } = this.state;\n\n\n    const profileBox = (<a\n        type=\"button\"\n        href={`${rootURL}/@${profile.username}`}\n        onClick={() => { analytics('profileImgClick'); }}\n      >\n        <img src={profile.profile_image} style={{ marginTop: 8, height: '32px', borderRadius: '3px' }} />\n      </a>)\n\n    const pageTitleSection = (\n      <div className={'pageTitleSection'}>\n        <div className={'titleImgBox'}>\n          <img src={'img/document.ico'} />\n        </div>\n        <div className={'content'}>\n          <div className={'pageTitle noOverflow'}>{title}</div>\n          <div className={'queryLink noOverflow'}>{queryLink}</div>\n        </div>\n    </div>)\n\n    const gridHeaders = (\n      <div className={'row rowHeader'}>\n        <div className={'typeCol'}>\n          <span>Type</span>\n        </div>\n        <div className={'titleCol'}>\n          <span className={'title'}>Title</span>\n          <span className={'noOverflow favicon'} title={'link to page'}>\n            <img src={'/img/hyperlink.png'} style={{ height: 20, width: 20 }}/>\n          </span>\n        </div>\n        <div className={'domainCol'}>\n          <span>Domain</span>\n        </div>\n        <div className={'sourceCol'}>\n          <span>Source</span>\n        </div>\n      </div>)\n\n    const filteredLink = links.filter(link => link.pageTo && link.pageTo !== null);\n\n    const noConnectionsRow = superEdges.length === 0 ? (\n      <div style={{ paddingTop: 20, paddingBottom: 20, paddingLeft: 20, borderTop: '1px solid #e7e7e7', backgroundColor: 'rgba(102, 51, 153, 0.3)' }}>\n        <span style={{ fontWeigth: 700, fontSize: 14 }}>There are no user recommendations for this page - be the first to add one.</span>\n      </div>) : null;\n\n    const superEdgeRows = superEdges && superEdges.length > 0 ? superEdges.map((edge, i) =>\n      <div key={i} className={'row'}>\n        <div className={'typeCol'}>\n          <span className={'userContributed'}>\n            <i className={'fa fa-user'} title={`Connected by: @${edge.edges[0].user.username}`}/>\n          </span>\n        </div>\n        <div className={'titleCol'}>\n          <span className={'noOverflow title'} title={edge.entity.title}>\n            <a target=\"_blank\" href={edge.entity.canonicalLink}>\n              {edge.entity.title ? edge.entity.title : edge.entity.canonicalLink}\n            </a>\n          </span>\n          <span className={'noOverflow favicon'} title={edge.entity.title}>\n            <a target=\"_blank\" href={edge.entity.canonicalLink}>\n              <img style={{ marginTop: 3 }} src={edge.entity.faviconCDN ? edge.entity.faviconCDN : '/img/default-favicon.png'} />\n            </a>\n          </span>\n        </div>\n        <div className={'domainCol'}>\n          <span className={'noOverflow'} title={edge.entity.domain}>{edge.entity.domain}</span>\n        </div>\n        <div className={'sourceCol'}>\n          <span className={'noOverflow'}>\n            <a\n              target=\"_blank\"\n              rel=\"noreferrer noopener\"\n              onClick={() => { analytics('reccommenderClicked'); }}\n              href={`${rootURL}/@${edge.edges[0].user.username}`}\n            >\n              @{edge.edges[0].user.username}\n            </a>\n          </span>\n        </div>\n      </div>) : null;\n\n    const pageLinksJSX = filteredLink.length > 0 ?\n      filteredLink.map((link, i) => {\n        const pageTo = link.pageTo;\n        if (!pageTo ) return <div key={i} />;\n        const { title, faviconCDN, canonicalLink, domain } = pageTo;\n        return <div key={i} className={'row'} style={{ borderTop: '1px solid #e7e7e7' }}>\n          <div className={'typeCol'}>\n            <span className={'pageLink'}>\n              <i className={'fa fa-code'} title={`Example promoted link`}/>\n            </span>\n          </div>\n          <div className={'titleCol'}>\n            <a target=\"_blank\" href={canonicalLink} className={'noOverflow title'}>\n              {title.length > 0 ? title : canonicalLink}\n            </a>\n            <span className={'noOverflow favicon'} title={'link to page'}>\n              <a target=\"_blank\" href={canonicalLink}>\n                <img src={ faviconCDN && faviconCDN.length ? faviconCDN : 'img/document.ico' } />\n              </a>\n            </span>\n          </div>\n          <div className={'domainCol'}>\n            <span>{domain}</span>\n          </div>\n          <div className={'sourceCol'}>\n            <span>Page</span>\n          </div>\n        </div>\n      }\n    ) : null\n\n    const resultsGrid = (\n      <div className={'resultsGrid'}>\n        {gridHeaders}\n        {superEdgeRows}\n        {pageLinksJSX}\n        {noConnectionsRow}\n      </div>)\n    return (\n      <div id='fullPage'>\n        <div className={'pageContents'}>\n          {isFetching || isParsed === false ?\n            ( <div>\n                <ReactSpinner color=\"black\"/>\n                <div className={'parsingPage'}>", "func_src_after": "  render() {\n\n    const {\n      isFetching,\n      isLoggedIn,\n      profile,\n      superEdges,\n      entityCount,\n      messagesConnect,\n      heartValue,\n      heartCount,\n      links,\n      title,\n      queryLink,\n      isParsed,\n    } = this.props;\n\n    const {\n      connectionDisplayIndex,\n      isAddConnectionToggledOn,\n      heartClickAttempted,\n      rotateConnectionBox,\n      isLoginRedirectToggledOn,\n    } = this.state;\n\n\n    const profileBox = (<a\n        type=\"button\"\n        href={`${rootURL}/@${profile.username}`}\n        rel=\"noreferrer noopener\"\n        onClick={() => { analytics('profileImgClick'); }}\n      >\n        <img src={profile.profile_image} style={{ marginTop: 8, height: '32px', borderRadius: '3px' }} />\n      </a>)\n\n    const pageTitleSection = (\n      <div className={'pageTitleSection'}>\n        <div className={'titleImgBox'}>\n          <img src={'img/document.ico'} />\n        </div>\n        <div className={'content'}>\n          <div className={'pageTitle noOverflow'}>{title}</div>\n          <div className={'queryLink noOverflow'}>{queryLink}</div>\n        </div>\n    </div>)\n\n    const gridHeaders = (\n      <div className={'row rowHeader'}>\n        <div className={'typeCol'}>\n          <span>Type</span>\n        </div>\n        <div className={'titleCol'}>\n          <span className={'title'}>Title</span>\n          <span className={'noOverflow favicon'} title={'link to page'}>\n            <img src={'/img/hyperlink.png'} style={{ height: 20, width: 20 }}/>\n          </span>\n        </div>\n        <div className={'domainCol'}>\n          <span>Domain</span>\n        </div>\n        <div className={'sourceCol'}>\n          <span>Source</span>\n        </div>\n      </div>)\n\n    const filteredLink = links.filter(link => link.pageTo && link.pageTo !== null);\n\n    const noConnectionsRow = superEdges.length === 0 ? (\n      <div style={{ paddingTop: 20, paddingBottom: 20, paddingLeft: 20, borderTop: '1px solid #e7e7e7', backgroundColor: 'rgba(102, 51, 153, 0.3)' }}>\n        <span style={{ fontWeigth: 700, fontSize: 14 }}>There are no user recommendations for this page - be the first to add one.</span>\n      </div>) : null;\n\n    const superEdgeRows = superEdges && superEdges.length > 0 ? superEdges.map((edge, i) =>\n      <div key={i} className={'row'} style={{ borderTop: '1px solid #e7e7e7' }}>\n        <div className={'typeCol'}>\n          <span className={'userContributed'}>\n            <i className={'fa fa-user'} title={`Connected by: @${edge.edges[0].user.username}`}/>\n          </span>\n        </div>\n        <div className={'titleCol'}>\n          <span className={'noOverflow title'} title={edge.entity.title}>\n            <a target=\"_blank\" href={edge.entity.canonicalLink} rel=\"noreferrer noopener\">\n              {edge.entity.title ? edge.entity.title : edge.entity.canonicalLink}\n            </a>\n          </span>\n          <span className={'noOverflow favicon'} title={edge.entity.title}>\n            <a target=\"_blank\" href={edge.entity.canonicalLink} rel=\"noreferrer noopener\">\n              <img style={{ marginTop: 3 }} src={edge.entity.faviconCDN ? edge.entity.faviconCDN : '/img/default-favicon.png'} />\n            </a>\n          </span>\n        </div>\n        <div className={'domainCol'}>\n          <span className={'noOverflow'} title={edge.entity.domain}>{edge.entity.domain}</span>\n        </div>\n        <div className={'sourceCol'}>\n          <span className={'noOverflow'}>\n            <a\n              target=\"_blank\"\n              rel=\"noreferrer noopener\"\n              onClick={() => { analytics('reccommenderClicked'); }}\n              href={`${rootURL}/@${edge.edges[0].user.username}`}\n            >\n              @{edge.edges[0].user.username}\n            </a>\n          </span>\n        </div>\n      </div>) : null;\n\n    const pageLinksJSX = filteredLink.length > 0 ?\n      filteredLink.map((link, i) => {\n        const pageTo = link.pageTo;\n        if (!pageTo ) return <div key={i} />;\n        const { title, faviconCDN, canonicalLink, domain } = pageTo;\n        return <div key={i} className={'row'} style={{ borderTop: '1px solid #e7e7e7' }}>\n          <div className={'typeCol'}>\n            <span className={'pageLink'}>\n              <i className={'fa fa-code'} title={`Example promoted link`}/>\n            </span>\n          </div>\n          <div className={'titleCol'}>\n            <a target=\"_blank\" href={canonicalLink} className={'noOverflow title'} rel=\"noreferrer noopener\">\n              {title.length > 0 ? title : canonicalLink}\n            </a>\n            <span className={'noOverflow favicon'} title={'link to page'}>\n              <a target=\"_blank\" href={canonicalLink} rel=\"noreferrer noopener\">\n                <img src={ faviconCDN && faviconCDN.length ? faviconCDN : 'img/document.ico' } />\n              </a>\n            </span>\n          </div>\n          <div className={'domainCol'}>\n            <span>{domain}</span>\n          </div>\n          <div className={'sourceCol'}>\n            <span>Page</span>\n          </div>\n        </div>\n      }\n    ) : null\n\n    const resultsGrid = (\n      <div className={'resultsGrid'}>\n        {gridHeaders}\n        {superEdgeRows}\n        {pageLinksJSX}\n        {noConnectionsRow}\n      </div>)\n    return (\n      <div id='fullPage'>\n        <div className={'pageContents'}>\n          {isFetching || isParsed === false ?\n            ( <div>\n                <ReactSpinner color=\"black\"/>\n                <div className={'parsingPage'}>", "line_changes": {"deleted": [{"line_no": 73, "char_start": 2230, "char_end": 2268, "line": "      <div key={i} className={'row'}>\n"}, {"line_no": 81, "char_start": 2593, "char_end": 2658, "line": "            <a target=\"_blank\" href={edge.entity.canonicalLink}>\n"}, {"line_no": 86, "char_start": 2851, "char_end": 2916, "line": "            <a target=\"_blank\" href={edge.entity.canonicalLink}>\n"}, {"line_no": 120, "char_start": 4238, "char_end": 4322, "line": "            <a target=\"_blank\" href={canonicalLink} className={'noOverflow title'}>\n"}, {"line_no": 124, "char_start": 4471, "char_end": 4526, "line": "              <a target=\"_blank\" href={canonicalLink}>\n"}], "added": [{"line_no": 30, "char_start": 533, "char_end": 567, "line": "        rel=\"noreferrer noopener\"\n"}, {"line_no": 74, "char_start": 2264, "char_end": 2345, "line": "      <div key={i} className={'row'} style={{ borderTop: '1px solid #e7e7e7' }}>\n"}, {"line_no": 82, "char_start": 2670, "char_end": 2761, "line": "            <a target=\"_blank\" href={edge.entity.canonicalLink} rel=\"noreferrer noopener\">\n"}, {"line_no": 87, "char_start": 2954, "char_end": 3045, "line": "            <a target=\"_blank\" href={edge.entity.canonicalLink} rel=\"noreferrer noopener\">\n"}, {"line_no": 121, "char_start": 4367, "char_end": 4477, "line": "            <a target=\"_blank\" href={canonicalLink} className={'noOverflow title'} rel=\"noreferrer noopener\">\n"}, {"line_no": 125, "char_start": 4626, "char_end": 4707, "line": "              <a target=\"_blank\" href={canonicalLink} rel=\"noreferrer noopener\">\n"}]}, "char_changes": {"deleted": [{"char_start": 591, "char_end": 591, "chars": ""}, {"char_start": 4471, "char_end": 4471, "chars": ""}], "added": [{"char_start": 533, "char_end": 567, "chars": "        rel=\"noreferrer noopener\"\n"}, {"char_start": 2300, "char_end": 2343, "chars": " style={{ borderTop: '1px solid #e7e7e7' }}"}, {"char_start": 2733, "char_end": 2759, "chars": " rel=\"noreferrer noopener\""}, {"char_start": 3017, "char_end": 3043, "chars": " rel=\"noreferrer noopener\""}, {"char_start": 4449, "char_end": 4475, "chars": " rel=\"noreferrer noopener\""}, {"char_start": 4679, "char_end": 4705, "chars": " rel=\"noreferrer noopener\""}]}, "commit_link": "github.com/WikiWebOrg/wikiweb-plugin/commit/c6fea2d3f5b7de1044194f77eb74072a5927f3f3", "file_name": "FullPage.react.js", "vul_type": "cwe-200", "commit_msg": "rel=\"noreferrer noopener\"", "parent_commit": "91373ed75a9d1f18fe7a337071a06ae4cc3f0134", "description": "Write a React component in JavaScript that displays user profile information, page details, and lists of linked entities with user contributions."}
{"func_name": "save_accepted_transaction", "func_src_before": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\"%(money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\" % (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, %s, now(), 'accepted' )\" % (project_id, user_id, money))\n        self.db.commit()", "func_src_after": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\", (money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\", (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, \"\n                            \"%s, now(), 'accepted' )\", (project_id, user_id, money))\n        self.db.commit()", "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089", "description": "Write a Python function to update user and project balances and record an accepted transaction in the database."}
{"func_name": "insertUsage", "func_src_before": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES ('\"+date+\"','\"+str(user)+\"','\"+command+\"')\")\n\tconn.commit()\n\tconn.close()", "func_src_after": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES (?,?,?)\",(date,str(user),command))\n\tconn.commit()\n\tconn.close()", "commit_link": "github.com/DangerBlack/DungeonsAndDragonsMasterBot/commit/63f980c6dff746f5fcf3005d0646b6c24f81cdc0", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a user's command usage into a database with the current date."}
{"func_name": "Get8BIMProperty", "func_src_before": "static MagickBooleanType Get8BIMProperty(const Image *image,const char *key,\n  ExceptionInfo *exception)\n{\n  char\n    *attribute,\n    format[MagickPathExtent],\n    name[MagickPathExtent],\n    *resource;\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *info;\n\n  long\n    start,\n    stop;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    id,\n    sub_number;\n\n  /*\n    There are no newlines in path names, so it's safe as terminator.\n  */\n  profile=GetImageProfile(image,\"8bim\");\n  if (profile == (StringInfo *) NULL)\n    return(MagickFalse);\n  count=(ssize_t) sscanf(key,\"8BIM:%ld,%ld:%1024[^\\n]\\n%1024[^\\n]\",&start,&stop,\n    name,format);\n  if ((count != 2) && (count != 3) && (count != 4))\n    return(MagickFalse);\n  if (count < 4)\n    (void) CopyMagickString(format,\"SVG\",MagickPathExtent);\n  if (count < 3)\n    *name='\\0';\n  sub_number=1;\n  if (*name == '#')\n    sub_number=(ssize_t) StringToLong(&name[1]);\n  sub_number=MagickMax(sub_number,1L);\n  resource=(char *) NULL;\n  status=MagickFalse;\n  length=GetStringInfoLength(profile);\n  info=GetStringInfoDatum(profile);\n  while ((length > 0) && (status == MagickFalse))\n  {\n    if (ReadPropertyByte(&info,&length) != (unsigned char) '8')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'B')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'I')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'M')\n      continue;\n    id=(ssize_t) ReadPropertyMSBShort(&info,&length);\n    if (id < (ssize_t) start)\n      continue;\n    if (id > (ssize_t) stop)\n      continue;\n    if (resource != (char *) NULL)\n      resource=DestroyString(resource);\n    count=(ssize_t) ReadPropertyByte(&info,&length);\n    if ((count != 0) && ((size_t) count <= length))\n      {\n        resource=(char *) NULL;\n        if (~((size_t) count) >= (MagickPathExtent-1))\n          resource=(char *) AcquireQuantumMemory((size_t) count+\n            MagickPathExtent,sizeof(*resource));\n        if (resource != (char *) NULL)\n          {\n            for (i=0; i < (ssize_t) count; i++)\n              resource[i]=(char) ReadPropertyByte(&info,&length);\n            resource[count]='\\0';\n          }\n      }\n    if ((count & 0x01) == 0)\n      (void) ReadPropertyByte(&info,&length);\n    count=(ssize_t) ReadPropertyMSBLong(&info,&length);\n    if ((*name != '\\0') && (*name != '#'))\n      if ((resource == (char *) NULL) || (LocaleCompare(name,resource) != 0))\n        {\n          /*\n            No name match, scroll forward and try next.\n          */\n          info+=count;\n          length-=MagickMin(count,(ssize_t) length);\n          continue;\n        }\n    if ((*name == '#') && (sub_number != 1))\n      {\n        /*\n          No numbered match, scroll forward and try next.\n        */\n        sub_number--;\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        continue;\n      }\n    /*\n      We have the resource of interest.\n    */\n    attribute=(char *) NULL;\n    if (~((size_t) count) >= (MagickPathExtent-1))\n      attribute=(char *) AcquireQuantumMemory((size_t) count+MagickPathExtent,\n        sizeof(*attribute));\n    if (attribute != (char *) NULL)\n      {\n        (void) CopyMagickMemory(attribute,(char *) info,(size_t) count);\n        attribute[count]='\\0';\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        if ((id <= 1999) || (id >= 2999))\n          (void) SetImageProperty((Image *) image,key,(const char *)\n            attribute,exception);\n        else\n          {\n            char\n              *path;\n\n            if (LocaleCompare(format,\"svg\") == 0)\n              path=TraceSVGClippath((unsigned char *) attribute,(size_t) count,\n                image->columns,image->rows);\n            else\n              path=TracePSClippath((unsigned char *) attribute,(size_t) count);\n            (void) SetImageProperty((Image *) image,key,(const char *) path,\n              exception);\n            path=DestroyString(path);\n          }\n        attribute=DestroyString(attribute);\n        status=MagickTrue;\n      }\n  }\n  if (resource != (char *) NULL)\n    resource=DestroyString(resource);\n  return(status);\n}", "func_src_after": "static MagickBooleanType Get8BIMProperty(const Image *image,const char *key,\n  ExceptionInfo *exception)\n{\n  char\n    *attribute,\n    format[MagickPathExtent],\n    name[MagickPathExtent],\n    *resource;\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *info;\n\n  long\n    start,\n    stop;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    id,\n    sub_number;\n\n  /*\n    There are no newlines in path names, so it's safe as terminator.\n  */\n  profile=GetImageProfile(image,\"8bim\");\n  if (profile == (StringInfo *) NULL)\n    return(MagickFalse);\n  count=(ssize_t) sscanf(key,\"8BIM:%ld,%ld:%1024[^\\n]\\n%1024[^\\n]\",&start,&stop,\n    name,format);\n  if ((count != 2) && (count != 3) && (count != 4))\n    return(MagickFalse);\n  if (count < 4)\n    (void) CopyMagickString(format,\"SVG\",MagickPathExtent);\n  if (count < 3)\n    *name='\\0';\n  sub_number=1;\n  if (*name == '#')\n    sub_number=(ssize_t) StringToLong(&name[1]);\n  sub_number=MagickMax(sub_number,1L);\n  resource=(char *) NULL;\n  status=MagickFalse;\n  length=GetStringInfoLength(profile);\n  info=GetStringInfoDatum(profile);\n  while ((length > 0) && (status == MagickFalse))\n  {\n    if (ReadPropertyByte(&info,&length) != (unsigned char) '8')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'B')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'I')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'M')\n      continue;\n    id=(ssize_t) ReadPropertyMSBShort(&info,&length);\n    if (id < (ssize_t) start)\n      continue;\n    if (id > (ssize_t) stop)\n      continue;\n    if (resource != (char *) NULL)\n      resource=DestroyString(resource);\n    count=(ssize_t) ReadPropertyByte(&info,&length);\n    if ((count != 0) && ((size_t) count <= length))\n      {\n        resource=(char *) NULL;\n        if (~((size_t) count) >= (MagickPathExtent-1))\n          resource=(char *) AcquireQuantumMemory((size_t) count+\n            MagickPathExtent,sizeof(*resource));\n        if (resource != (char *) NULL)\n          {\n            for (i=0; i < (ssize_t) count; i++)\n              resource[i]=(char) ReadPropertyByte(&info,&length);\n            resource[count]='\\0';\n          }\n      }\n    if ((count & 0x01) == 0)\n      (void) ReadPropertyByte(&info,&length);\n    count=(ssize_t) ReadPropertyMSBLong(&info,&length);\n    if ((count < 0) || ((size_t) count > length))\n      {\n        length=0; \n        continue;\n      }\n    if ((*name != '\\0') && (*name != '#'))\n      if ((resource == (char *) NULL) || (LocaleCompare(name,resource) != 0))\n        {\n          /*\n            No name match, scroll forward and try next.\n          */\n          info+=count;\n          length-=MagickMin(count,(ssize_t) length);\n          continue;\n        }\n    if ((*name == '#') && (sub_number != 1))\n      {\n        /*\n          No numbered match, scroll forward and try next.\n        */\n        sub_number--;\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        continue;\n      }\n    /*\n      We have the resource of interest.\n    */\n    attribute=(char *) NULL;\n    if (~((size_t) count) >= (MagickPathExtent-1))\n      attribute=(char *) AcquireQuantumMemory((size_t) count+MagickPathExtent,\n        sizeof(*attribute));\n    if (attribute != (char *) NULL)\n      {\n        (void) CopyMagickMemory(attribute,(char *) info,(size_t) count);\n        attribute[count]='\\0';\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        if ((id <= 1999) || (id >= 2999))\n          (void) SetImageProperty((Image *) image,key,(const char *)\n            attribute,exception);\n        else\n          {\n            char\n              *path;\n\n            if (LocaleCompare(format,\"svg\") == 0)\n              path=TraceSVGClippath((unsigned char *) attribute,(size_t) count,\n                image->columns,image->rows);\n            else\n              path=TracePSClippath((unsigned char *) attribute,(size_t) count);\n            (void) SetImageProperty((Image *) image,key,(const char *) path,\n              exception);\n            path=DestroyString(path);\n          }\n        attribute=DestroyString(attribute);\n        status=MagickTrue;\n      }\n  }\n  if (resource != (char *) NULL)\n    resource=DestroyString(resource);\n  return(status);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/dd84447b63a71fa8c3f47071b09454efc667767b", "file_name": "MagickCore/property.c", "vul_type": "cwe-125", "description": "Write a C function named `Get8BIMProperty` that retrieves a property from an image's 8BIM profile based on a given key."}
{"func_name": "lb_register_characteristic_read_event", "func_src_before": "lb_register_characteristic_read_event(lb_context lb_ctx,\n                                      lb_bl_device* dev,\n                                      const char* uuid,\n                                      sd_bus_message_handler_t callback,\n                                      void* userdata)\n{\n#ifdef DEBUG\n    printf(\"Method Called: %s\\n\", __FUNCTION__);\n#endif\n    int r;\n    sd_bus_error error = SD_BUS_ERROR_NULL;\n    lb_ble_char* ble_char_new = NULL;\n    char match[65];\n\n    if (lb_ctx == NULL) {\n        syslog(LOG_ERR, \"%s: lb_ctx is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_CONTEXT;\n    }\n\n    if (dev == NULL) {\n        syslog(LOG_ERR, \"%s: bl_device is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (uuid == NULL) {\n        syslog(LOG_ERR, \"%s: uuid is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (callback == NULL) {\n        syslog(LOG_ERR, \"%s: callback is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    r = lb_get_ble_characteristic_by_uuid(lb_ctx, dev, uuid, &ble_char_new);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: could find characteristic: %s\", __FUNCTION__, uuid);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_UNSPECIFIED;\n    }\n\n    r = sd_bus_call_method(lb_ctx->bus, BLUEZ_DEST, ble_char_new->char_path,\n                           BLUEZ_GATT_CHARACTERISTICS, \"StartNotify\", &error, NULL, NULL);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: sd_bus_call_method StartNotify on device %s failed with error: %s\",\n               __FUNCTION__, ble_char_new->char_path, error.message);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_SD_BUS_CALL_FAIL;\n    }\n\n    snprintf(match, 66, \"path='%s'\", ble_char_new->char_path);\n\n    int current_index = event_arr_size;\n    if (event_arr_size == 0 || events_matches_array == NULL) {\n        events_matches_array = (event_matches_callbacks**) malloc(sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error allocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n        event_arr_size++;\n    } else {\n        event_arr_size++;\n        events_matches_array =\n        realloc(events_matches_array, event_arr_size * sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n    }\n\n    event_matches_callbacks* new_event_pair =\n    (event_matches_callbacks*) malloc(sizeof(event_matches_callbacks));\n    if (new_event_pair == NULL) {\n        syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n        return -LB_ERROR_MEMEORY_ALLOCATION;\n    }\n    new_event_pair->event = match;\n    new_event_pair->callback = &callback;\n    new_event_pair->userdata = userdata;\n    events_matches_array[current_index] = new_event_pair;\n\n    pthread_create(&event_thread, NULL, _run_event_loop, &(lb_ctx->bus));\n    // wait for thread to start\n    sleep(2);\n\n    sd_bus_error_free(&error);\n    return LB_SUCCESS;\n}", "func_src_after": "lb_register_characteristic_read_event(lb_context lb_ctx,\n                                      lb_bl_device* dev,\n                                      const char* uuid,\n                                      sd_bus_message_handler_t callback,\n                                      void* userdata)\n{\n#ifdef DEBUG\n    printf(\"Method Called: %s\\n\", __FUNCTION__);\n#endif\n    int r;\n    sd_bus_error error = SD_BUS_ERROR_NULL;\n    lb_ble_char* ble_char_new = NULL;\n    char match[68];\n\n    if (lb_ctx == NULL) {\n        syslog(LOG_ERR, \"%s: lb_ctx is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_CONTEXT;\n    }\n\n    if (dev == NULL) {\n        syslog(LOG_ERR, \"%s: bl_device is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (uuid == NULL) {\n        syslog(LOG_ERR, \"%s: uuid is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (callback == NULL) {\n        syslog(LOG_ERR, \"%s: callback is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    r = lb_get_ble_characteristic_by_uuid(lb_ctx, dev, uuid, &ble_char_new);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: could find characteristic: %s\", __FUNCTION__, uuid);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_UNSPECIFIED;\n    }\n\n    r = sd_bus_call_method(lb_ctx->bus, BLUEZ_DEST, ble_char_new->char_path,\n                           BLUEZ_GATT_CHARACTERISTICS, \"StartNotify\", &error, NULL, NULL);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: sd_bus_call_method StartNotify on device %s failed with error: %s\",\n               __FUNCTION__, ble_char_new->char_path, error.message);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_SD_BUS_CALL_FAIL;\n    }\n\n    snprintf(match, 67, \"path='%s'\", ble_char_new->char_path);\n\n    int current_index = event_arr_size;\n    if (event_arr_size == 0 || events_matches_array == NULL) {\n        events_matches_array = (event_matches_callbacks**) malloc(sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error allocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n        event_arr_size++;\n    } else {\n        event_arr_size++;\n        events_matches_array =\n        realloc(events_matches_array, event_arr_size * sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n    }\n\n    event_matches_callbacks* new_event_pair =\n    (event_matches_callbacks*) malloc(sizeof(event_matches_callbacks));\n    if (new_event_pair == NULL) {\n        syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n        return -LB_ERROR_MEMEORY_ALLOCATION;\n    }\n    new_event_pair->event = match;\n    new_event_pair->callback = &callback;\n    new_event_pair->userdata = userdata;\n    events_matches_array[current_index] = new_event_pair;\n\n    pthread_create(&event_thread, NULL, _run_event_loop, &(lb_ctx->bus));\n    // wait for thread to start\n    sleep(2);\n\n    sd_bus_error_free(&error);\n    return LB_SUCCESS;\n}", "line_changes": {"deleted": [{"line_no": 13, "char_start": 461, "char_end": 481, "line": "    char match[65];\n"}, {"line_no": 51, "char_start": 1716, "char_end": 1779, "line": "    snprintf(match, 66, \"path='%s'\", ble_char_new->char_path);\n"}], "added": [{"line_no": 13, "char_start": 461, "char_end": 481, "line": "    char match[68];\n"}, {"line_no": 51, "char_start": 1716, "char_end": 1779, "line": "    snprintf(match, 67, \"path='%s'\", ble_char_new->char_path);\n"}]}, "char_changes": {"deleted": [{"char_start": 477, "char_end": 478, "chars": "5"}, {"char_start": 1737, "char_end": 1738, "chars": "6"}], "added": [{"char_start": 477, "char_end": 478, "chars": "8"}, {"char_start": 1737, "char_end": 1738, "chars": "7"}]}, "commit_link": "github.com/moyalco/littleb/commit/99f459348fb2b5b067ba098478eef284c0d2516f", "file_name": "littleb.c", "vul_type": "cwe-119", "commit_msg": "littleb.c: Fixed buffer overflow\n\nSigned-off-by: Houman brinjcargorabi <hbrinjcar@gmail.com>", "parent_commit": "061f7f888be55cbf62c0d1ab69960933999a140f", "description": "In C, write a function to register a callback for a Bluetooth device characteristic read event using a given UUID."}
{"func_name": "get_task_ioprio", "func_src_before": "static int get_task_ioprio(struct task_struct *p)\n{\n\tint ret;\n\n\tret = security_task_getioprio(p);\n\tif (ret)\n\t\tgoto out;\n\tret = IOPRIO_PRIO_VALUE(IOPRIO_CLASS_NONE, IOPRIO_NORM);\n\tif (p->io_context)\n\t\tret = p->io_context->ioprio;\nout:\n\treturn ret;\n}", "func_src_after": "static int get_task_ioprio(struct task_struct *p)\n{\n\tint ret;\n\n\tret = security_task_getioprio(p);\n\tif (ret)\n\t\tgoto out;\n\tret = IOPRIO_PRIO_VALUE(IOPRIO_CLASS_NONE, IOPRIO_NORM);\n\ttask_lock(p);\n\tif (p->io_context)\n\t\tret = p->io_context->ioprio;\n\ttask_unlock(p);\nout:\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/8ba8682107ee2ca3347354e018865d8e1967c5f4", "file_name": "block/ioprio.c", "vul_type": "cwe-416", "description": "Write a C function named `get_task_ioprio` that retrieves the I/O priority of a given task, using a `task_struct` pointer, and includes proper synchronization if necessary."}
{"func_name": "change_message", "func_src_before": "    def change_message(self, new_message, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET message = '{}'\n            WHERE client_id = '{}'\n        \"\"\".format(new_message, logged_user.get_client_id())\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql)\n        self.__conn.commit()\n        logged_user.set_message(new_message)", "func_src_after": "    def change_message(self, new_message, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET message = ?\n            WHERE client_id = ?\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql, (new_message, logged_user.get_client_id()))\n        self.__conn.commit()\n        logged_user.set_message(new_message)", "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's message in a database and their object's state."}
{"func_name": "update", "func_src_before": "function update() {\n\tfor (const line of regexField.value.split('\\n')) {\n\t\t// Don't allow delimiters in RegExp string\n\t\tif (delimiters.test(line)) {\n\t\t\treturn setValidity(`Use <code>${line.replace(/^\\/|\\/$/g, '')}</code> instead of <code>${line}</code>. Slashes are not required.`);\n\t\t}\n\n\t\t// Fully test each RegExp\n\t\ttry {\n\t\t\t// eslint-disable-next-line no-new\n\t\t\tnew RegExp(line);\n\t\t} catch (error) {\n\t\t\treturn setValidity(error.message);\n\t\t}\n\t}\n\n\tsetValidity();\n\tsaveOptions();\n}", "func_src_after": "function update() {\n\tfor (const line of regexField.value.split('\\n')) {\n\t\t// Don't allow delimiters in RegExp string\n\t\tif (delimiters.test(line)) {\n\t\t\treturn setValidity(escapeTag`Use <code>${line.replace(/^\\/|\\/$/g, '')}</code> instead of <code>${line}</code>. Slashes are not required.`);\n\t\t}\n\n\t\t// Fully test each RegExp\n\t\ttry {\n\t\t\t// eslint-disable-next-line no-new\n\t\t\tnew RegExp(line);\n\t\t} catch (error) {\n\t\t\treturn setValidity(error.message);\n\t\t}\n\t}\n\n\tsetValidity();\n\tsaveOptions();\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 148, "char_end": 282, "line": "\t\t\treturn setValidity(`Use <code>${line.replace(/^\\/|\\/$/g, '')}</code> instead of <code>${line}</code>. Slashes are not required.`);\n"}], "added": [{"line_no": 5, "char_start": 148, "char_end": 291, "line": "\t\t\treturn setValidity(escapeTag`Use <code>${line.replace(/^\\/|\\/$/g, '')}</code> instead of <code>${line}</code>. Slashes are not required.`);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 170, "char_end": 179, "chars": "escapeTag"}]}, "commit_link": "github.com/sindresorhus/github-hide-files/commit/9de0c57df81db1178e0e79431d462f6d9842742e", "file_name": "options.js", "vul_type": "cwe-079", "commit_msg": "Avoid self-XSS (#73)", "description": "Create a JavaScript function that validates and updates regular expressions from a text field, excluding delimiter checks and error handling."}
{"func_name": "pref_set", "func_src_before": "@app.route(\"/api/preferences/set/<key>/<value>\")\ndef pref_set(key, value):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    get_preferences()[key] = (None if value == 'null' else value)\n    return Response(json.dumps({'key': key, 'success': ''})), 201", "func_src_after": "@app.route(\"/api/preferences/set/<key>/<value>\")\ndef pref_set(key, value):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    get_preferences()[key] = (None if value == 'null' else value)\n    return Response(\n        json.dumps({'key': key, 'success': ''}),\n        mimetype='application/json'\n    ), 201", "line_changes": {"deleted": [{"line_no": 7, "char_start": 215, "char_end": 280, "line": "    return Response(json.dumps({'key': key, 'success': ''})), 201\n"}], "added": [{"line_no": 7, "char_start": 215, "char_end": 236, "line": "    return Response(\n"}, {"line_no": 8, "char_start": 236, "char_end": 285, "line": "        json.dumps({'key': key, 'success': ''}),\n"}, {"line_no": 9, "char_start": 285, "char_end": 321, "line": "        mimetype='application/json'\n"}, {"line_no": 10, "char_start": 321, "char_end": 331, "line": "    ), 201\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 235, "char_end": 244, "chars": "\n        "}, {"char_start": 283, "char_end": 325, "chars": ",\n        mimetype='application/json'\n    "}]}, "commit_link": "github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "file_name": "app.py", "vul_type": "cwe-079", "commit_msg": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "description": "Write a Python Flask endpoint to set a user preference given a key and value, returning JSON and requiring user authentication."}
{"func_name": "self.register_user_defined_tag_type", "func_src_before": "    def self.register_user_defined_tag_type(config_source)\n      config = YAML.load(config_source)\n      check_validity_of_config(config)\n      TagType.register(registered_tag_name = config['tag_name'].to_sym,\n                       config['tag'],\n                       config['iteration_tag'],\n                       config['fallback_tag'],\n                       config['remove_indent'] || false)\n      registered_tag_name\n    end", "func_src_after": "    def self.register_user_defined_tag_type(config_source)\n      config = YAML.safe_load(config_source, [Symbol])\n      check_validity_of_config(config)\n      TagType.register(registered_tag_name = config['tag_name'].to_sym,\n                       config['tag'],\n                       config['iteration_tag'],\n                       config['fallback_tag'],\n                       config['remove_indent'] || false)\n      registered_tag_name\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 59, "char_end": 99, "line": "      config = YAML.load(config_source)\n"}], "added": [{"line_no": 2, "char_start": 59, "char_end": 114, "line": "      config = YAML.safe_load(config_source, [Symbol])\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 79, "char_end": 84, "chars": "safe_"}, {"char_start": 102, "char_end": 112, "chars": ", [Symbol]"}]}, "commit_link": "github.com/nico-hn/AdHocTemplate/commit/4bc4ed79a2c45d64df03029bd05c3a426f5df020", "file_name": "parser.rb", "vul_type": "cwe-502", "commit_msg": "use YAML.safe_load() instead of .load()", "parent_commit": "f602247a29214ffce7e8d24caf690c2a420c3e99", "description": "Write a Ruby method to register a user-defined tag type from a YAML configuration source."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(\n                data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/JeremiahO/crimemap/commit/c17537fcd7aa4e2a26f7ca5cefaeb356ff646858", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function named `add_input` that inserts user-provided data into a database table named `crimes`, but ensure the first snippet is vulnerable to SQL injection while the second is not."}
{"func_name": "post", "func_src_before": "    def post(self):\n        \"\"\" Returns JWT upon login verification \"\"\"\n        json_data = request.get_json()\n        if not json_data['email']:\n            return jsonify({\"msg\": \"Missing email\"}), 400\n\n        data = database_utilities.execute_query(\n            f\"\"\"select * from admins where email = '{json_data['email']}'\"\"\")\n        if data:\n            email = data[0]['email']\n            access_token = create_access_token(identity=email)\n            refresh_token = create_refresh_token(identity=email)\n\n            resp = jsonify({\"login\": True})\n            set_access_cookies(resp, access_token)\n            set_refresh_cookies(resp, refresh_token)\n            return resp\n        else:\n            return jsonify({\"msg\": \"User is not an admin\"})", "func_src_after": "    def post(self):\n        \"\"\" Returns JWT upon login verification \"\"\"\n        json_data = request.get_json()\n        if not json_data['email']:\n            return jsonify({\"msg\": \"Missing email\"}), 400\n\n        data = database_utilities.execute_query(\n            f\"\"\"select * from admins where email = %s\"\"\", (json_data['email'], ))\n        if data:\n            email = data[0]['email']\n            access_token = create_access_token(identity=email)\n            refresh_token = create_refresh_token(identity=email)\n\n            resp = jsonify({\"login\": True})\n            set_access_cookies(resp, access_token)\n            set_refresh_cookies(resp, refresh_token)\n            return resp\n        else:\n            return jsonify({\"msg\": \"User is not an admin\"})", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/login.py", "vul_type": "cwe-089", "description": "Write a Python function that handles admin login by verifying email and issuing JWT tokens."}
{"func_name": "updateKey", "func_src_before": "def updateKey(client):\n\t\"\"\"Updates the contents of a key that already exists in our system.\n\tReturns an error if the specified key doesn't exist for the specified user.\n\t\"\"\"\n\tglobal NOT_FOUND\n\tglobal CREATED\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateNewKeyData(token_data)\n\n\t# Use 'w' flag to replace existing key file with the new key data\n\tif os.path.isfile('keys/%s/%s.key' % (client, token_data['name'])):\n\t\twith open('keys/%s/%s.key' % (client, token_data['name']), 'w') as f:\n\t\t\tf.write(token_data['key'])\n\telse:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['name'])\n\n\treturn 'Key successfully updated', CREATED", "func_src_after": "def updateKey(client):\n\t\"\"\"Updates the contents of a key that already exists in our system.\n\tReturns an error if the specified key doesn't exist for the specified user.\n\t\"\"\"\n\tglobal NOT_FOUND\n\tglobal CREATED\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateNewKeyData(token_data)\n\tvalidateKeyName(token_data['name'])\n\n\t# Use 'w' flag to replace existing key file with the new key data\n\tif os.path.isfile('keys/%s/%s.key' % (client, token_data['name'])):\n\t\twith open('keys/%s/%s.key' % (client, token_data['name']), 'w') as f:\n\t\t\tf.write(token_data['key'])\n\telse:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['name'])\n\n\treturn 'Key successfully updated', CREATED", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function to update a user's key file with new data, raising an error if the key file does not exist."}
{"func_name": "mode_input", "func_src_before": "    def mode_input(self, request):\n        \"\"\"\n        This is called by render_POST when the client\n        is sending data to the server.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n\n        self.last_alive[csessid] = (time.time(), False)\n        sess = self.sessionhandler.sessions_from_csessid(csessid)\n        if sess:\n            sess = sess[0]\n            cmdarray = json.loads(request.args.get('data')[0])\n            sess.sessionhandler.data_in(sess, **{cmdarray[0]: [cmdarray[1], cmdarray[2]]})\n        return '\"\"'", "func_src_after": "    def mode_input(self, request):\n        \"\"\"\n        This is called by render_POST when the client\n        is sending data to the server.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        self.last_alive[csessid] = (time.time(), False)\n        sess = self.sessionhandler.sessions_from_csessid(csessid)\n        if sess:\n            sess = sess[0]\n            cmdarray = json.loads(cgi.escape(request.args.get('data')[0]))\n            sess.sessionhandler.data_in(sess, **{cmdarray[0]: [cmdarray[1], cmdarray[2]]})\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_input` that processes a POST request by extracting session ID and data, updates session activity, and handles incoming data for a session."}
