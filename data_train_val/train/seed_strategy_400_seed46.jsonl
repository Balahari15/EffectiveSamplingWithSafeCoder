{"func_name": "get_all_referrers", "func_src_before": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer='\"+account_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n\n    return jsonify(results)", "func_src_after": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer=%s\"\n    cur.execute(query, (account_id,))\n    results = cur.fetchall()\n\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint to fetch and return all referrer entries for a given account ID from a PostgreSQL database, handling account ID lookup if necessary."}
{"func_name": "keyctl_read_key", "func_src_before": "long keyctl_read_key(key_serial_t keyid, char __user *buffer, size_t buflen)\n{\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tlong ret;\n\n\t/* find the key first */\n\tkey_ref = lookup_user_key(keyid, 0, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = -ENOKEY;\n\t\tgoto error;\n\t}\n\n\tkey = key_ref_to_ptr(key_ref);\n\n\t/* see if we can read it directly */\n\tret = key_permission(key_ref, KEY_NEED_READ);\n\tif (ret == 0)\n\t\tgoto can_read_key;\n\tif (ret != -EACCES)\n\t\tgoto error2;\n\n\t/* we can't; see if it's searchable from this process's keyrings\n\t * - we automatically take account of the fact that it may be\n\t *   dangling off an instantiation key\n\t */\n\tif (!is_key_possessed(key_ref)) {\n\t\tret = -EACCES;\n\t\tgoto error2;\n\t}\n\n\t/* the key is probably readable - now try to read it */\ncan_read_key:\n\tret = -EOPNOTSUPP;\n\tif (key->type->read) {\n\t\t/* Read the data with the semaphore held (since we might sleep)\n\t\t * to protect against the key being updated or revoked.\n\t\t */\n\t\tdown_read(&key->sem);\n\t\tret = key_validate(key);\n\t\tif (ret == 0)\n\t\t\tret = key->type->read(key, buffer, buflen);\n\t\tup_read(&key->sem);\n\t}\n\nerror2:\n\tkey_put(key);\nerror:\n\treturn ret;\n}", "func_src_after": "long keyctl_read_key(key_serial_t keyid, char __user *buffer, size_t buflen)\n{\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tlong ret;\n\n\t/* find the key first */\n\tkey_ref = lookup_user_key(keyid, 0, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = -ENOKEY;\n\t\tgoto error;\n\t}\n\n\tkey = key_ref_to_ptr(key_ref);\n\n\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags)) {\n\t\tret = -ENOKEY;\n\t\tgoto error2;\n\t}\n\n\t/* see if we can read it directly */\n\tret = key_permission(key_ref, KEY_NEED_READ);\n\tif (ret == 0)\n\t\tgoto can_read_key;\n\tif (ret != -EACCES)\n\t\tgoto error2;\n\n\t/* we can't; see if it's searchable from this process's keyrings\n\t * - we automatically take account of the fact that it may be\n\t *   dangling off an instantiation key\n\t */\n\tif (!is_key_possessed(key_ref)) {\n\t\tret = -EACCES;\n\t\tgoto error2;\n\t}\n\n\t/* the key is probably readable - now try to read it */\ncan_read_key:\n\tret = -EOPNOTSUPP;\n\tif (key->type->read) {\n\t\t/* Read the data with the semaphore held (since we might sleep)\n\t\t * to protect against the key being updated or revoked.\n\t\t */\n\t\tdown_read(&key->sem);\n\t\tret = key_validate(key);\n\t\tif (ret == 0)\n\t\t\tret = key->type->read(key, buffer, buflen);\n\t\tup_read(&key->sem);\n\t}\n\nerror2:\n\tkey_put(key);\nerror:\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/37863c43b2c6464f252862bf2e9768264e961678", "file_name": "security/keys/keyctl.c", "vul_type": "cwe-476", "description": "Write a C function named `keyctl_read_key` that reads data from a specified key into a buffer, handling permissions and errors."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 56, "char_start": 2347, "char_end": 2420, "line": "                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 56, "char_start": 2347, "char_end": 2402, "line": "                                  XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 2380, "char_end": 2398, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/87ade081f1f3a26ab74d6c1ad3942eb4666c5cab", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "ca66d344a3894691ed96e95a186f28c8eab75d93", "description": "Write a C function to read a GraphML file into an igraph graph structure, handling different graph indices."}
{"func_name": "users_to_notify_popup", "func_src_before": "  def users_to_notify_popup\n    # anyone already attached to the task should be removed\n    excluded_ids = params[:watcher_ids].blank? ? 0 : params[:watcher_ids]\n    @users = current_user.customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    @task = AbstractTask.accessed_by(current_user).find_by(:id => params[:id])\n\n    @task && @task.customers.each do |customer|\n      @users = @users + customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    end\n    @users = @users.uniq.sort_by{|user| user.name}.first(50)\n\n    if @task && current_user.customer != @task.project.customer\n      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (#{excluded_ids})\")\n      @users = @users.uniq.sort_by{|user| user.name}.first(50)\n    end\n    render :layout =>false\n  end", "func_src_after": "  def users_to_notify_popup\n    # anyone already attached to the task should be removed\n    excluded_ids = params[:watcher_ids].blank? ? 0 : params[:watcher_ids]\n    @users = current_user.customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    @task = AbstractTask.accessed_by(current_user).find_by(:id => params[:id])\n\n    @task && @task.customers.each do |customer|\n      @users = @users + customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    end\n    @users = @users.uniq.sort_by{|user| user.name}.first(50)\n\n    if @task && current_user.customer != @task.project.customer\n      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (?)\", excluded_ids)\n      @users = @users.uniq.sort_by{|user| user.name}.first(50)\n    end\n    render :layout =>false\n  end", "line_changes": {"deleted": [{"line_no": 13, "char_start": 640, "char_end": 737, "line": "      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (#{excluded_ids})\")\n"}], "added": [{"line_no": 13, "char_start": 640, "char_end": 737, "line": "      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (?)\", excluded_ids)\n"}]}, "char_changes": {"deleted": [{"char_start": 718, "char_end": 720, "chars": "#{"}, {"char_start": 732, "char_end": 735, "chars": "})\""}], "added": [{"char_start": 718, "char_end": 723, "chars": "?)\", "}]}, "commit_link": "github.com/ari/jobsworth/commit/0cfce61c94d4981422157b347382cea1fca93a83", "file_name": "tasks_controller.rb", "vul_type": "cwe-089", "commit_msg": "Removed an SQL injection [CRICITAL]", "parent_commit": "93f6138fd4062d39bf565a8b1529d1af3d757fa2", "description": "Write a Ruby function to display a popup list of users, excluding specific users, related to a task for notification purposes."}
{"func_name": "(anonymous)", "func_src_before": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n    });", "func_src_after": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n    });", "line_changes": {"deleted": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n"}], "added": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n"}]}, "char_changes": {"deleted": [{"char_start": 821, "char_end": 825, "chars": "html"}], "added": [{"char_start": 821, "char_end": 825, "chars": "text"}]}, "commit_link": "github.com/edmundoa/graylog2-server/commit/a88cae99955cd0ccdd5d99a1c6d506029eb15c60", "file_name": "streamrules.js", "vul_type": "cwe-079", "commit_msg": "use .text() not .html() in stream rule editor to prevent DOM XSS\n\nfixes #543", "description": "In JavaScript, write a jQuery event handler that updates text in a modal based on user input and selection changes, with special handling for an \"inverted\" checkbox state."}
{"func_name": "create_or_update_repo", "func_src_before": "def create_or_update_repo(folder, which_branch):\n    print ('--------------------------------------------')\n    print (f'Create or update repo {folder}')\n\n    if not os.path.isdir(folder):\n        # if the repo doesn't already exist, create it\n        create_new_repo(folder,which_branch)\n\n    else:\n        os.chdir(folder)\n\n        # whether or not this repo was newly created, set the default HEAD\n        # on the origin repo\n        os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n\n        # if this repo has no branches with valid commits, add an\n        # empty commit to the specified branch so that the repository\n        # is not empty\n        add_empty_commit(folder,which_branch)\n        \n        \n    # set/correct the permissions of all files\n    os.chdir(folder)\n    for root, dirs, files in os.walk(folder):\n        for entry in files + dirs:\n            shutil.chown(os.path.join(root, entry), group=DAEMONCGI_GROUP)", "func_src_after": "def create_or_update_repo(folder, which_branch):\n    print ('--------------------------------------------')\n    print (f'Create or update repo {folder}')\n\n    if not os.path.isdir(folder):\n        # if the repo doesn't already exist, create it\n        create_new_repo(folder,which_branch)\n\n    else:\n        os.chdir(folder)\n\n        # whether or not this repo was newly created, set the default HEAD\n        # on the origin repo\n        subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n\n        # if this repo has no branches with valid commits, add an\n        # empty commit to the specified branch so that the repository\n        # is not empty\n        add_empty_commit(folder,which_branch)\n        \n        \n    # set/correct the permissions of all files\n    os.chdir(folder)\n    for root, dirs, files in os.walk(folder):\n        for entry in files + dirs:\n            shutil.chown(os.path.join(root, entry), group=DAEMONCGI_GROUP)", "line_changes": {"deleted": [{"line_no": 14, "char_start": 430, "char_end": 500, "line": "        os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n"}], "added": [{"line_no": 14, "char_start": 430, "char_end": 516, "line": "        subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n"}]}, "char_changes": {"deleted": [{"char_start": 438, "char_end": 472, "chars": "os.system(f'git symbolic-ref HEAD "}], "added": [{"char_start": 438, "char_end": 487, "chars": "subprocess.run(['git', 'symbolic-ref', 'HEAD', f'"}, {"char_start": 513, "char_end": 514, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to manage a git repository by creating or updating it and setting file permissions."}
{"func_name": "HPHP::SimpleParser::handleBackslash", "func_src_before": "  bool handleBackslash(signed char& out) {\n    char ch = *p++;\n    switch (ch) {\n      case 0: return false;\n      case '\"': out = ch; return true;\n      case '\\\\': out = ch; return true;\n      case '/': out = ch; return true;\n      case 'b': out = '\\b'; return true;\n      case 'f': out = '\\f'; return true;\n      case 'n': out = '\\n'; return true;\n      case 'r': out = '\\r'; return true;\n      case 't': out = '\\t'; return true;\n      case 'u': {\n        if (UNLIKELY(is_tsimplejson)) {\n          auto const ch1 = *p++;\n          auto const ch2 = *p++;\n          auto const dch3 = dehexchar(*p++);\n          auto const dch4 = dehexchar(*p++);\n          if (UNLIKELY(ch1 != '0' || ch2 != '0' || dch3 < 0 || dch4 < 0)) {\n            return false;\n          }\n          out = (dch3 << 4) | dch4;\n          return true;\n        } else {\n          uint16_t u16cp = 0;\n          for (int i = 0; i < 4; i++) {\n            auto const hexv = dehexchar(*p++);\n            if (hexv < 0) return false; // includes check for end of string\n            u16cp <<= 4;\n            u16cp |= hexv;\n          }\n          if (u16cp > 0x7f) {\n            return false;\n          } else {\n            out = u16cp;\n            return true;\n          }\n        }\n      }\n      default: return false;\n    }\n  }", "func_src_after": "  bool handleBackslash(signed char& out) {\n    char ch = *p++;\n    switch (ch) {\n      case 0: return false;\n      case '\"': out = ch; return true;\n      case '\\\\': out = ch; return true;\n      case '/': out = ch; return true;\n      case 'b': out = '\\b'; return true;\n      case 'f': out = '\\f'; return true;\n      case 'n': out = '\\n'; return true;\n      case 'r': out = '\\r'; return true;\n      case 't': out = '\\t'; return true;\n      case 'u': {\n        if (UNLIKELY(is_tsimplejson)) {\n          auto const ch1 = *p++;\n          if (UNLIKELY(ch1 != '0')) return false;\n          auto const ch2 = *p++;\n          if (UNLIKELY(ch2 != '0')) return false;\n          auto const dch3 = dehexchar(*p++);\n          if (UNLIKELY(dch3 < 0)) return false;\n          auto const dch4 = dehexchar(*p++);\n          if (UNLIKELY(dch4 < 0)) return false;\n          out = (dch3 << 4) | dch4;\n          return true;\n        } else {\n          uint16_t u16cp = 0;\n          for (int i = 0; i < 4; i++) {\n            auto const hexv = dehexchar(*p++);\n            if (hexv < 0) return false; // includes check for end of string\n            u16cp <<= 4;\n            u16cp |= hexv;\n          }\n          if (u16cp > 0x7f) {\n            return false;\n          } else {\n            out = u16cp;\n            return true;\n          }\n        }\n      }\n      default: return false;\n    }\n  }", "commit_link": "github.com/facebook/hhvm/commit/b3679121bb3c7017ff04b4c08402ffff5cf59b13", "file_name": "hphp/runtime/ext/json/JSON_parser.cpp", "vul_type": "cwe-125", "description": "Write a C++ function to process escape sequences in a JSON string and convert them to their corresponding characters."}
{"func_name": "editInPlace", "func_src_before": "function editInPlace(element) {\n  closeEditInPlaceForms();\n\n  // create edit form\n  var tag_id = $(this).attr('id').substr(5);\n  var tag_name = $(this).text();\n  var tag_width = $(this).width();\n  $(this).parent().data(\"revert\", $(this).parent().html());\n  var form = '<form id=\"gRenameTagForm\" method=\"post\" class=\"ui-helper-clearfix\" ';\n  form += 'action=\"' + TAG_RENAME_URL.replace('__ID__', tag_id) + '\">';\n  form += '<input name=\"csrf\" type=\"hidden\" value=\"' + csrf_token + '\" />';\n  form += '<input id=\"name\" name=\"name\" type=\"text\" class=\"textbox\" value=\"' + tag_name + '\" />';\n  form += '<input type=\"submit\" class=\"submit ui-state-default ui-corner-all\" value=\"' + save_i18n + '\" i/>';\n  form += '<a href=\"#\">' + cancel_i18n + '</a>';\n  form += '</form>';\n\n  // add edit form\n  $(this).parent().html(form);\n  $(\"#gRenameTagForm #name\")\n    .width(tag_width+30)\n    .focus();\n  //$(\"#gRenameTagForm\").parent().height( $(\"#gRenameTagForm\").height() );\n  $(\"#gRenameTagForm a\").bind(\"click\", closeEditInPlaceForms);\n\n  ajaxify_editInPlaceForm = function() {\n    $(\"#gRenameTagForm\").ajaxForm({\n      dataType: \"json\",\n      success: function(data) {\n        if (data.result == \"success\") {\n          closeEditInPlaceForms(); // close form\n          $(\"#gTag-\" + data.tag_id).text(data.new_tagname); // update tagname\n          console.log(data);\n          window.location.reload();\n        }\n      }\n    });\n  };\n  ajaxify_editInPlaceForm();\n}", "func_src_after": "function editInPlace(element) {\n  closeEditInPlaceForms();\n\n  // create edit form\n  var tag_id = $(this).attr('id').substr(5);\n  var tag_name = $(this).html();\n  var tag_width = $(this).width();\n  $(this).parent().data(\"revert\", $(this).parent().html());\n  var form = '<form id=\"gRenameTagForm\" method=\"post\" class=\"ui-helper-clearfix\" ';\n  form += 'action=\"' + TAG_RENAME_URL.replace('__ID__', tag_id) + '\">';\n  form += '<input name=\"csrf\" type=\"hidden\" value=\"' + csrf_token + '\" />';\n  form += '<input id=\"name\" name=\"name\" type=\"text\" class=\"textbox\" value=\"' +\n          str_replace('\"', \"&quot;\", tag_name) + '\" />';\n  form += '<input type=\"submit\" class=\"submit ui-state-default ui-corner-all\" value=\"' + save_i18n + '\" i/>';\n  form += '<a href=\"#\">' + cancel_i18n + '</a>';\n  form += '</form>';\n\n  // add edit form\n  $(this).parent().html(form);\n  $(\"#gRenameTagForm #name\")\n    .width(tag_width+30)\n    .focus();\n  //$(\"#gRenameTagForm\").parent().height( $(\"#gRenameTagForm\").height() );\n  $(\"#gRenameTagForm a\").bind(\"click\", closeEditInPlaceForms);\n\n  ajaxify_editInPlaceForm = function() {\n    $(\"#gRenameTagForm\").ajaxForm({\n      dataType: \"json\",\n      success: function(data) {\n        if (data.result == \"success\") {\n          closeEditInPlaceForms(); // close form\n          $(\"#gTag-\" + data.tag_id).text(data.new_tagname); // update tagname\n          console.log(data);\n          window.location.reload();\n        }\n      }\n    });\n  };\n  ajaxify_editInPlaceForm();\n}", "line_changes": {"deleted": [{"line_no": 6, "char_start": 127, "char_end": 160, "line": "  var tag_name = $(this).text();\n"}, {"line_no": 12, "char_start": 487, "char_end": 585, "line": "  form += '<input id=\"name\" name=\"name\" type=\"text\" class=\"textbox\" value=\"' + tag_name + '\" />';\n"}], "added": [{"line_no": 6, "char_start": 127, "char_end": 160, "line": "  var tag_name = $(this).html();\n"}, {"line_no": 12, "char_start": 487, "char_end": 566, "line": "  form += '<input id=\"name\" name=\"name\" type=\"text\" class=\"textbox\" value=\"' +\n"}, {"line_no": 13, "char_start": 566, "char_end": 623, "line": "          str_replace('\"', \"&quot;\", tag_name) + '\" />';\n"}]}, "char_changes": {"deleted": [{"char_start": 152, "char_end": 156, "chars": "text"}], "added": [{"char_start": 152, "char_end": 156, "chars": "html"}, {"char_start": 565, "char_end": 602, "chars": "\n          str_replace('\"', \"&quot;\","}, {"char_start": 611, "char_end": 612, "chars": ")"}]}, "commit_link": "github.com/gallery/gallery3/commit/ff1979e12e0b012374e2ab3712b19f87e1a92e64", "file_name": "tag.js", "vul_type": "cwe-079", "commit_msg": "Fix XSS in tags JS", "description": "Write a JavaScript function to replace an HTML element with an editable form and handle the form submission asynchronously."}
{"func_name": "TestDateSetters", "func_src_before": "func TestDateSetters(t *testing.T) {\n\tconst SCRIPT = `\n\tassert.sameValue((new Date(0)).setMilliseconds(2345), 2345, \"setMilliseconds()\");\n\tassert.sameValue((new Date(0)).setUTCMilliseconds(2345), 2345, \"setUTCMilliseconds()\");\n\tassert.sameValue((new Date(0)).setSeconds(12), 12000, \"setSeconds()\");\n\tassert.sameValue((new Date(0)).setUTCSeconds(12), 12000, \"setUTCSeconds()\");\n\tassert.sameValue((new Date(0)).setMinutes(12), 12 * 60 * 1000, \"setMinutes()\");\n\tassert.sameValue((new Date(0)).setUTCMinutes(12), 12 * 60 * 1000, \"setUTCMinutes()\");\n\tassert.sameValue((new Date(\"2016-06-01\")).setHours(1), 1464739200000, \"setHours()\");\n\tassert.sameValue((new Date(\"2016-06-01\")).setUTCHours(1), 1464742800000, \"setUTCHours()\");\n\tassert.sameValue((new Date(0)).setDate(2), 86400000, \"setDate()\");\n\tassert.sameValue((new Date(0)).setUTCDate(2), 86400000, \"setUTCDate()\");\n\tassert.sameValue((new Date(0)).setMonth(2), 5097600000, \"setMonth()\");\n\tassert.sameValue((new Date(0)).setUTCMonth(2), 5097600000, \"setUTCMonth()\");\n\tassert.sameValue((new Date(0)).setFullYear(1971), 31536000000, \"setFullYear()\");\n\tassert.sameValue((new Date(0)).setFullYear(1971, 2, 3), 36806400000, \"setFullYear(Y,M,D)\");\n\tassert.sameValue((new Date(0)).setUTCFullYear(1971), 31536000000, \"setUTCFullYear()\");\n\tassert.sameValue((new Date(0)).setUTCFullYear(1971, 2, 3), 36806400000, \"setUTCFullYear(Y,M,D)\");\n\n\t`\n\n\tl := time.Local\n\tdefer func() {\n\t\ttime.Local = l\n\t}()\n\tvar err error\n\ttime.Local, err = time.LoadLocation(\"Europe/London\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\ttestScript1(TESTLIB+SCRIPT, _undefined, t)\n}", "func_src_after": "func TestDateSetters(t *testing.T) {\n\tconst SCRIPT = `\n\tassert.sameValue((new Date(0)).setMilliseconds(2345), 2345, \"setMilliseconds(2345)\");\n\tassert.sameValue(new Date(1000).setMilliseconds(23450000000000), 23450000001000, \"setMilliseconds(23450000000000)\");\n\tassert.sameValue((new Date(0)).setUTCMilliseconds(2345), 2345, \"setUTCMilliseconds()\");\n\tassert.sameValue((new Date(0)).setSeconds(12), 12000, \"setSeconds()\");\n\tassert.sameValue((new Date(0)).setUTCSeconds(12), 12000, \"setUTCSeconds()\");\n\tassert.sameValue((new Date(0)).setMinutes(12), 12 * 60 * 1000, \"setMinutes()\");\n\tassert.sameValue((new Date(0)).setUTCMinutes(12), 12 * 60 * 1000, \"setUTCMinutes()\");\n\tassert.sameValue((new Date(\"2016-06-01\")).setHours(1), 1464739200000, \"setHours()\");\n\tassert.sameValue((new Date(\"2016-06-01\")).setUTCHours(1), 1464742800000, \"setUTCHours()\");\n\tassert.sameValue((new Date(0)).setDate(2), 86400000, \"setDate()\");\n\tassert.sameValue((new Date(0)).setUTCDate(2), 86400000, \"setUTCDate()\");\n\tassert.sameValue((new Date(0)).setMonth(2), 5097600000, \"setMonth()\");\n\tassert.sameValue((new Date(0)).setUTCMonth(2), 5097600000, \"setUTCMonth()\");\n\tassert.sameValue((new Date(0)).setFullYear(1971), 31536000000, \"setFullYear()\");\n\tassert.sameValue((new Date(0)).setFullYear(1971, 2, 3), 36806400000, \"setFullYear(Y,M,D)\");\n\tassert.sameValue((new Date(0)).setUTCFullYear(1971), 31536000000, \"setUTCFullYear()\");\n\tassert.sameValue((new Date(0)).setUTCFullYear(1971, 2, 3), 36806400000, \"setUTCFullYear(Y,M,D)\");\n\n\tvar d = new Date();\n\td.setTime(1151877845000);\n\tassert.sameValue(d.getHours(), 23, \"d.getHours()\");\n\t`\n\n\tl := time.Local\n\tdefer func() {\n\t\ttime.Local = l\n\t}()\n\tvar err error\n\ttime.Local, err = time.LoadLocation(\"Europe/London\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\ttestScript1(TESTLIB+SCRIPT, _undefined, t)\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 55, "char_end": 138, "line": "\tassert.sameValue((new Date(0)).setMilliseconds(2345), 2345, \"setMilliseconds()\");\n"}], "added": [{"line_no": 3, "char_start": 55, "char_end": 142, "line": "\tassert.sameValue((new Date(0)).setMilliseconds(2345), 2345, \"setMilliseconds(2345)\");\n"}, {"line_no": 4, "char_start": 142, "char_end": 260, "line": "\tassert.sameValue(new Date(1000).setMilliseconds(23450000000000), 23450000001000, \"setMilliseconds(23450000000000)\");\n"}, {"line_no": 21, "char_start": 1500, "char_end": 1521, "line": "\tvar d = new Date();\n"}, {"line_no": 22, "char_start": 1521, "char_end": 1548, "line": "\td.setTime(1151877845000);\n"}, {"line_no": 23, "char_start": 1548, "char_end": 1601, "line": "\tassert.sameValue(d.getHours(), 23, \"d.getHours()\");\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 133, "char_end": 255, "chars": "2345)\");\n\tassert.sameValue(new Date(1000).setMilliseconds(23450000000000), 23450000001000, \"setMilliseconds(23450000000000"}, {"char_start": 1500, "char_end": 1601, "chars": "\tvar d = new Date();\n\td.setTime(1151877845000);\n\tassert.sameValue(d.getHours(), 23, \"d.getHours()\");\n"}]}, "commit_link": "github.com/dop251/goja/commit/cf1b11d2877279635b607d90a223bbda30e575b5", "file_name": "date_test.go", "vul_type": "cwe-681", "commit_msg": "Avoid integer overflow in Date.setMilliseconds()", "parent_commit": "5e65f9206bdb013b233bde6bac91fc88e00ff7a3", "description": "Write a Go test function to check various date setter methods in JavaScript."}
{"func_name": "__init__", "func_src_before": "  def __init__(self,\n               height,\n               width,\n               command_sequence=None):\n    self._height = height\n    self._width = width\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    # The mock class has no actual textbox. So use this variable to keep\n    # track of what's entered in the textbox on creation.\n    self._curr_existing_command = \"\"\n\n    # Observers for test.\n    # Observers of screen output.\n    self.unwrapped_outputs = []\n    self.wrapped_outputs = []\n    self.scroll_messages = []\n    self.output_array_pointer_indices = []\n\n    self.output_pad_rows = []\n\n    # Observers of command textbox.\n    self.existing_commands = []\n\n    # Observer for tab-completion candidates.\n    self.candidates_lists = []\n\n    # Observer for the main menu.\n    self.main_menu_list = []\n\n    # Observer for toast messages.\n    self.toasts = []\n\n    curses_ui.CursesUI.__init__(\n        self,\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n\n    # Override the default path to the command history file to avoid test\n    # concurrency issues.\n    self._command_history_store = debugger_cli_common.CommandHistory(\n        history_file_path=tempfile.mktemp())", "func_src_after": "  def __init__(self,\n               height,\n               width,\n               command_sequence=None):\n    self._height = height\n    self._width = width\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    # The mock class has no actual textbox. So use this variable to keep\n    # track of what's entered in the textbox on creation.\n    self._curr_existing_command = \"\"\n\n    # Observers for test.\n    # Observers of screen output.\n    self.unwrapped_outputs = []\n    self.wrapped_outputs = []\n    self.scroll_messages = []\n    self.output_array_pointer_indices = []\n\n    self.output_pad_rows = []\n\n    # Observers of command textbox.\n    self.existing_commands = []\n\n    # Observer for tab-completion candidates.\n    self.candidates_lists = []\n\n    # Observer for the main menu.\n    self.main_menu_list = []\n\n    # Observer for toast messages.\n    self.toasts = []\n\n    curses_ui.CursesUI.__init__(\n        self,\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n\n    # Override the default path to the command history file to avoid test\n    # concurrency issues.\n    _, history_file_path = tempfile.mkstemp()  # safe to ignore fd\n    self._command_history_store = debugger_cli_common.CommandHistory(\n        history_file_path=history_file_path)", "line_changes": {"deleted": [{"line_no": 44, "char_start": 1233, "char_end": 1277, "line": "        history_file_path=tempfile.mktemp())\n"}], "added": [{"line_no": 43, "char_start": 1163, "char_end": 1230, "line": "    _, history_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"line_no": 45, "char_start": 1300, "char_end": 1344, "line": "        history_file_path=history_file_path)\n"}]}, "char_changes": {"deleted": [{"char_start": 1259, "char_end": 1276, "chars": "tempfile.mktemp()"}], "added": [{"char_start": 1163, "char_end": 1230, "chars": "    _, history_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"char_start": 1326, "char_end": 1343, "chars": "history_file_path"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/578f7eec19544d0223d145b56d88dfe043114538", "file_name": "curses_ui_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359212\nChange-Id: I172811749d2e7b901399f63df4fd1523447c6682", "description": "In Python, write an initializer for a mock UI class that sets up dimensions, command handling, and various observers for testing, without using actual UI components."}
{"func_name": "ndpi_search_oracle", "func_src_before": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "func_src_after": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload_packet_len >= 3 && packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "commit_link": "github.com/ntop/nDPI/commit/b69177be2fbe01c2442239a61832c44e40136c05", "file_name": "src/lib/protocols/oracle.c", "vul_type": "cwe-125", "description": "In C, write a function to detect Oracle database traffic by examining TCP packets and their payload."}
{"func_name": "self.read_record", "func_src_before": "      def self.read_record(yaml_data)\n        RecordReader.convert_values_to_string(YAML.load(yaml_data))\n      end", "func_src_after": "      def self.read_record(yaml_data)\n        RecordReader.convert_values_to_string(YAML.safe_load(yaml_data,\n                                                             [Symbol]))\n      end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 38, "char_end": 106, "line": "        RecordReader.convert_values_to_string(YAML.load(yaml_data))\n"}], "added": [{"line_no": 2, "char_start": 38, "char_end": 110, "line": "        RecordReader.convert_values_to_string(YAML.safe_load(yaml_data,\n"}, {"line_no": 3, "char_start": 110, "char_end": 182, "line": "                                                             [Symbol]))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 89, "char_end": 94, "chars": "safe_"}, {"char_start": 108, "char_end": 179, "chars": ",\n                                                             [Symbol]"}]}, "commit_link": "github.com/nico-hn/AdHocTemplate/commit/4bc4ed79a2c45d64df03029bd05c3a426f5df020", "file_name": "record_reader.rb", "vul_type": "cwe-502", "commit_msg": "use YAML.safe_load() instead of .load()", "parent_commit": "f602247a29214ffce7e8d24caf690c2a420c3e99", "description": "Write a Ruby method that reads YAML data and converts its values to strings using a RecordReader class."}
{"func_name": "initialize", "func_src_before": "    def initialize(*configs)\n      @config = configs.each_with_object(default_config) do |path, obj|\n        new = YAML.load(File.read(path))\n        next unless new\n        obj.deep_merge! Cymbal.symbolize(new)\n      end\n      @paths = @config[:paths]\n    end", "func_src_after": "    def initialize(*configs)\n      @config = configs.each_with_object(default_config) do |path, obj|\n        new = YAML.safe_load(File.read(path))\n        next unless new\n        obj.deep_merge! Cymbal.symbolize(new)\n      end\n      @paths = @config[:paths]\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 101, "char_end": 142, "line": "        new = YAML.load(File.read(path))\n"}], "added": [{"line_no": 3, "char_start": 101, "char_end": 147, "line": "        new = YAML.safe_load(File.read(path))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 120, "char_end": 125, "chars": "safe_"}]}, "commit_link": "github.com/dock0/dock0/commit/c4800a6be1e62b124b401214b416b7adedca341a", "file_name": "dock0.rb", "vul_type": "cwe-502", "commit_msg": "use safe_load", "parent_commit": "243b9d713e05eebb5ef8e17bc568dfefcd2a32a2", "description": "Write a Ruby method named `initialize` that merges multiple YAML configuration files into a default configuration object and stores specific paths from the configuration."}
{"func_name": "disk_seqf_stop", "func_src_before": "static void disk_seqf_stop(struct seq_file *seqf, void *v)\n{\n\tstruct class_dev_iter *iter = seqf->private;\n\n\t/* stop is called even after start failed :-( */\n\tif (iter) {\n\t\tclass_dev_iter_exit(iter);\n\t\tkfree(iter);\n\t}\n}", "func_src_after": "static void disk_seqf_stop(struct seq_file *seqf, void *v)\n{\n\tstruct class_dev_iter *iter = seqf->private;\n\n\t/* stop is called even after start failed :-( */\n\tif (iter) {\n\t\tclass_dev_iter_exit(iter);\n\t\tkfree(iter);\n\t\tseqf->private = NULL;\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/77da160530dd1dc94f6ae15a981f24e5f0021e84", "file_name": "block/genhd.c", "vul_type": "cwe-416", "description": "Write a C function named `disk_seqf_stop` that cleans up an iterator for a sequence file, ensuring memory is freed and the iterator is reset if necessary."}
{"func_name": "create_list", "func_src_before": "list_t *create_list(void)\n{\n    list_t *list = malloc(sizeof(list_t));\n\n    list->size = 0;\n    list->head = NULL;\n    list->tail = NULL;\n\n    return list;\n}", "func_src_after": "list_t *create_list(void)\n{\n    list_t *list = malloc(sizeof(list_t));\n\n    if (list == NULL)\n        return NULL;\n\n    list->size = 0;\n    list->head = NULL;\n    list->tail = NULL;\n\n    return list;\n}", "commit_link": "github.com/matiasedd/vinapp/commit/663121dc1fb7b9465d1edaa2bf1b25145294ba5b", "file_name": "liblist.c", "vul_type": "cwe-476", "description": "Write a C function named `create_list` that initializes an empty linked list and handles memory allocation failure."}
{"func_name": "copy", "func_src_before": "    def copy(self, src_data, src_path, dst_data, dst_path, job_id=None):\n        credentials = ''\n\n        if src_data is None: # Local\n            src = src_path\n        else:\n            credentials += self._formatCredentials(src_data, name='src')\n            src = 'src:{}'.format(src_path)\n\n        if dst_data is None: # Local\n            dst = dst_path\n        else:\n            credentials += self._formatCredentials(dst_data, name='dst')\n            dst = 'dst:{}'.format(dst_path)\n\n\n        command = (\n            '{credentials} '\n            'rclone copy {src} {dst} '\n            '--progress '\n            '--stats 2s '\n        ).format(\n            credentials=credentials,\n            src=src,\n            dst=dst,\n        )\n\n        logging.info(sanitize(command))\n\n        if job_id is None:\n            job_id = self._get_next_job_id()\n        else:\n            if self._job_id_exists(job_id):\n                raise ValueError('rclone copy job with ID {} already exists'.fromat(job_id))\n\n        self._stop_events[job_id] = threading.Event()\n\n        try:\n            self._execute_interactive(command, job_id)\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))\n\n        return job_id", "func_src_after": "    def copy(self, src_data, src_path, dst_data, dst_path, job_id=None):\n        credentials = {}\n\n        if src_data is None: # Local\n            src = src_path\n        else:\n            credentials.update(self._formatCredentials(src_data, name='src'))\n            src = 'src:{}'.format(src_path)\n\n        if dst_data is None: # Local\n            dst = dst_path\n        else:\n            credentials.update(self._formatCredentials(dst_data, name='dst'))\n            dst = 'dst:{}'.format(dst_path)\n\n        command = [\n            'rclone',\n            'copy',\n            src,\n            dst,\n            '--progress',\n            '--stats', '2s',\n        ]\n\n        bash_command = \"{} {}\".format(\n            ' '.join(\"{}='{}'\".format(key, value) for key, value in credentials.items()),\n            ' '.join(command),\n        )\n\n        logging.info(sanitize(bash_command))\n\n        if job_id is None:\n            job_id = self._get_next_job_id()\n        else:\n            if self._job_id_exists(job_id):\n                raise ValueError('rclone copy job with ID {} already exists'.fromat(job_id))\n\n        self._stop_events[job_id] = threading.Event()\n\n        try:\n            self._execute_interactive(command, credentials, job_id)\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))\n\n        return job_id", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function named `copy` that handles file copying with rclone, including local and remote sources and destinations, and manages job IDs."}
{"func_name": "uas_switch_interface", "func_src_before": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tint alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (alt < 0)\n\t\treturn alt;\n\n\treturn usb_set_interface(udev,\n\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);\n}", "func_src_after": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tstruct usb_host_interface *alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (!alt)\n\t\treturn -ENODEV;\n\n\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,\n\t\t\talt->desc.bAlternateSetting);\n}", "commit_link": "github.com/torvalds/linux/commit/786de92b3cb26012d3d0f00ee37adf14527f35c4", "file_name": "drivers/usb/storage/uas.c", "vul_type": "cwe-125", "description": "Write a C function named `uas_switch_interface` that switches the USB interface to an alternate setting for a given USB device and interface."}
{"func_name": "mode_input", "func_src_before": "    def mode_input(self, request):\n        \"\"\"\n        This is called by render_POST when the client\n        is sending data to the server.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n\n        self.last_alive[csessid] = (time.time(), False)\n        sess = self.sessionhandler.sessions_from_csessid(csessid)\n        if sess:\n            sess = sess[0]\n            cmdarray = json.loads(request.args.get('data')[0])\n            sess.sessionhandler.data_in(sess, **{cmdarray[0]: [cmdarray[1], cmdarray[2]]})\n        return '\"\"'", "func_src_after": "    def mode_input(self, request):\n        \"\"\"\n        This is called by render_POST when the client\n        is sending data to the server.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        self.last_alive[csessid] = (time.time(), False)\n        sess = self.sessionhandler.sessions_from_csessid(csessid)\n        if sess:\n            sess = sess[0]\n            cmdarray = json.loads(cgi.escape(request.args.get('data')[0]))\n            sess.sessionhandler.data_in(sess, **{cmdarray[0]: [cmdarray[1], cmdarray[2]]})\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_input` that processes a POST request by extracting session ID and data, updates session activity, and handles incoming data for a session."}
{"func_name": "blk_rq_map_user_iov", "func_src_before": "int blk_rq_map_user_iov(struct request_queue *q, struct request *rq,\n\t\t\tstruct rq_map_data *map_data,\n\t\t\tconst struct iov_iter *iter, gfp_t gfp_mask)\n{\n\tbool copy = false;\n\tunsigned long align = q->dma_pad_mask | queue_dma_alignment(q);\n\tstruct bio *bio = NULL;\n\tstruct iov_iter i;\n\tint ret;\n\n\tif (map_data)\n\t\tcopy = true;\n\telse if (iov_iter_alignment(iter) & align)\n\t\tcopy = true;\n\telse if (queue_virt_boundary(q))\n\t\tcopy = queue_virt_boundary(q) & iov_iter_gap_alignment(iter);\n\n\ti = *iter;\n\tdo {\n\t\tret =__blk_rq_map_user_iov(rq, map_data, &i, gfp_mask, copy);\n\t\tif (ret)\n\t\t\tgoto unmap_rq;\n\t\tif (!bio)\n\t\t\tbio = rq->bio;\n\t} while (iov_iter_count(&i));\n\n\tif (!bio_flagged(bio, BIO_USER_MAPPED))\n\t\trq->cmd_flags |= REQ_COPY_USER;\n\treturn 0;\n\nunmap_rq:\n\t__blk_rq_unmap_user(bio);\n\trq->bio = NULL;\n\treturn -EINVAL;\n}", "func_src_after": "int blk_rq_map_user_iov(struct request_queue *q, struct request *rq,\n\t\t\tstruct rq_map_data *map_data,\n\t\t\tconst struct iov_iter *iter, gfp_t gfp_mask)\n{\n\tbool copy = false;\n\tunsigned long align = q->dma_pad_mask | queue_dma_alignment(q);\n\tstruct bio *bio = NULL;\n\tstruct iov_iter i;\n\tint ret;\n\n\tif (!iter_is_iovec(iter))\n\t\tgoto fail;\n\n\tif (map_data)\n\t\tcopy = true;\n\telse if (iov_iter_alignment(iter) & align)\n\t\tcopy = true;\n\telse if (queue_virt_boundary(q))\n\t\tcopy = queue_virt_boundary(q) & iov_iter_gap_alignment(iter);\n\n\ti = *iter;\n\tdo {\n\t\tret =__blk_rq_map_user_iov(rq, map_data, &i, gfp_mask, copy);\n\t\tif (ret)\n\t\t\tgoto unmap_rq;\n\t\tif (!bio)\n\t\t\tbio = rq->bio;\n\t} while (iov_iter_count(&i));\n\n\tif (!bio_flagged(bio, BIO_USER_MAPPED))\n\t\trq->cmd_flags |= REQ_COPY_USER;\n\treturn 0;\n\nunmap_rq:\n\t__blk_rq_unmap_user(bio);\nfail:\n\trq->bio = NULL;\n\treturn -EINVAL;\n}", "commit_link": "github.com/torvalds/linux/commit/a0ac402cfcdc904f9772e1762b3fda112dcc56a0", "file_name": "block/blk-map.c", "vul_type": "cwe-416", "description": "Write a C function named `blk_rq_map_user_iov` that maps a user I/O vector to a request queue and handles errors."}
{"func_name": "ExprResolveLhs", "func_src_before": "ExprResolveLhs(struct xkb_context *ctx, const ExprDef *expr,\n               const char **elem_rtrn, const char **field_rtrn,\n               ExprDef **index_rtrn)\n{\n    switch (expr->expr.op) {\n    case EXPR_IDENT:\n        *elem_rtrn = NULL;\n        *field_rtrn = xkb_atom_text(ctx, expr->ident.ident);\n        *index_rtrn = NULL;\n        return (*field_rtrn != NULL);\n    case EXPR_FIELD_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->field_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->field_ref.field);\n        *index_rtrn = NULL;\n        return true;\n    case EXPR_ARRAY_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->array_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->array_ref.field);\n        *index_rtrn = expr->array_ref.entry;\n        return true;\n    default:\n        break;\n    }\n    log_wsgo(ctx, \"Unexpected operator %d in ResolveLhs\\n\", expr->expr.op);\n    return false;\n}", "func_src_after": "ExprResolveLhs(struct xkb_context *ctx, const ExprDef *expr,\n               const char **elem_rtrn, const char **field_rtrn,\n               ExprDef **index_rtrn)\n{\n    switch (expr->expr.op) {\n    case EXPR_IDENT:\n        *elem_rtrn = NULL;\n        *field_rtrn = xkb_atom_text(ctx, expr->ident.ident);\n        *index_rtrn = NULL;\n        return (*field_rtrn != NULL);\n    case EXPR_FIELD_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->field_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->field_ref.field);\n        *index_rtrn = NULL;\n        return (*elem_rtrn != NULL && *field_rtrn != NULL);\n    case EXPR_ARRAY_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->array_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->array_ref.field);\n        *index_rtrn = expr->array_ref.entry;\n\tif (expr->array_ref.element != XKB_ATOM_NONE && *elem_rtrn == NULL)\n\t\treturn false;\n\tif (*field_rtrn == NULL)\n\t\treturn false;\n        return true;\n    default:\n        break;\n    }\n    log_wsgo(ctx, \"Unexpected operator %d in ResolveLhs\\n\", expr->expr.op);\n    return false;\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/bb4909d2d8fa6b08155e449986a478101e2b2634", "file_name": "src/xkbcomp/expr.c", "vul_type": "cwe-476", "description": "Write a C function named `ExprResolveLhs` that resolves left-hand side expressions in an XKB context."}
{"func_name": "fixture", "func_src_before": "  def fixture(key, opts = {})\n    memo = Fixtures[key]\n    return memo if memo\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n\n    yaml = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    json = Pathname.new(File.join(dir, \"fixture_#{key}.json\"))\n    txt = Pathname.new(File.join(dir, \"fixture_#{key}.txt\"))\n\n    Fixtures[key] = if yaml.exist?; then YAML.load(File.read(yaml))\n                    elsif json.exist?; then JSON.parse(File.read(json))\n                    elsif txt.exist?; then File.read(txt)\n                    else fail \"could not load YAML or JSON fixture #{key}\"\n                    end", "func_src_after": "  def fixture(key, opts = {})\n    memo = Fixtures[key]\n    return memo if memo\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n\n    yaml = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    json = Pathname.new(File.join(dir, \"fixture_#{key}.json\"))\n    txt = Pathname.new(File.join(dir, \"fixture_#{key}.txt\"))\n\n    Fixtures[key] = if yaml.exist?; then YAML.safe_load(File.read(yaml))\n                    elsif json.exist?; then JSON.parse(File.read(json))\n                    elsif txt.exist?; then File.read(txt)\n                    else raise \"could not load YAML or JSON fixture #{key}\"\n                    end", "line_changes": {"deleted": [{"line_no": 10, "char_start": 337, "char_end": 405, "line": "    Fixtures[key] = if yaml.exist?; then YAML.load(File.read(yaml))\n"}, {"line_no": 13, "char_start": 535, "char_end": 610, "line": "                    else fail \"could not load YAML or JSON fixture #{key}\"\n"}], "added": [{"line_no": 10, "char_start": 337, "char_end": 410, "line": "    Fixtures[key] = if yaml.exist?; then YAML.safe_load(File.read(yaml))\n"}, {"line_no": 13, "char_start": 540, "char_end": 616, "line": "                    else raise \"could not load YAML or JSON fixture #{key}\"\n"}]}, "char_changes": {"deleted": [{"char_start": 560, "char_end": 561, "chars": "f"}, {"char_start": 563, "char_end": 564, "chars": "l"}], "added": [{"char_start": 383, "char_end": 388, "chars": "safe_"}, {"char_start": 565, "char_end": 566, "chars": "r"}, {"char_start": 568, "char_end": 570, "chars": "se"}]}, "commit_link": "github.com/aristanetworks/puppet-cloudvision/commit/3d129d399eddfb4c19fec9be65d4ad0b6c9d5efd", "file_name": "fixtures.rb", "vul_type": "cwe-502", "commit_msg": "Replace YAML.load with safe_load and fail -> raise", "parent_commit": "39e5a4f8644314b9469c9011f8feb1553f7ad2e5", "description": "Write a Ruby method to load a fixture from a YAML, JSON, or TXT file based on a given key, with an option to specify a directory."}
{"func_name": "parse_playlist", "func_src_before": "static int parse_playlist(HLSContext *c, const char *url,\n                          struct playlist *pls, AVIOContext *in)\n{\n    int ret = 0, is_segment = 0, is_variant = 0;\n    int64_t duration = 0;\n    enum KeyType key_type = KEY_NONE;\n    uint8_t iv[16] = \"\";\n    int has_iv = 0;\n    char key[MAX_URL_SIZE] = \"\";\n    char line[MAX_URL_SIZE];\n    const char *ptr;\n    int close_in = 0;\n    int64_t seg_offset = 0;\n    int64_t seg_size = -1;\n    uint8_t *new_url = NULL;\n    struct variant_info variant_info;\n    char tmp_str[MAX_URL_SIZE];\n    struct segment *cur_init_section = NULL;\n\n    if (!in) {\n#if 1\n        AVDictionary *opts = NULL;\n        close_in = 1;\n        /* Some HLS servers don't like being sent the range header */\n        av_dict_set(&opts, \"seekable\", \"0\", 0);\n\n        // broker prior HTTP options that should be consistent across requests\n        av_dict_set(&opts, \"user-agent\", c->user_agent, 0);\n        av_dict_set(&opts, \"cookies\", c->cookies, 0);\n        av_dict_set(&opts, \"headers\", c->headers, 0);\n\n        ret = avio_open2(&in, url, AVIO_FLAG_READ,\n                         c->interrupt_callback, &opts);\n        av_dict_free(&opts);\n        if (ret < 0)\n            return ret;\n#else\n        ret = open_in(c, &in, url);\n        if (ret < 0)\n            return ret;\n        close_in = 1;\n#endif\n    }\n\n    if (av_opt_get(in, \"location\", AV_OPT_SEARCH_CHILDREN, &new_url) >= 0)\n        url = new_url;\n\n    read_chomp_line(in, line, sizeof(line));\n    if (strcmp(line, \"#EXTM3U\")) {\n        ret = AVERROR_INVALIDDATA;\n        goto fail;\n    }\n\n    if (pls) {\n        free_segment_list(pls);\n        pls->finished = 0;\n        pls->type = PLS_TYPE_UNSPECIFIED;\n    }\n    while (!avio_feof(in)) {\n        read_chomp_line(in, line, sizeof(line));\n        if (av_strstart(line, \"#EXT-X-STREAM-INF:\", &ptr)) {\n            is_variant = 1;\n            memset(&variant_info, 0, sizeof(variant_info));\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_variant_args,\n                               &variant_info);\n        } else if (av_strstart(line, \"#EXT-X-KEY:\", &ptr)) {\n            struct key_info info = {{0}};\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_key_args,\n                               &info);\n            key_type = KEY_NONE;\n            has_iv = 0;\n            if (!strcmp(info.method, \"AES-128\"))\n                key_type = KEY_AES_128;\n            if (!strcmp(info.method, \"SAMPLE-AES\"))\n                key_type = KEY_SAMPLE_AES;\n            if (!strncmp(info.iv, \"0x\", 2) || !strncmp(info.iv, \"0X\", 2)) {\n                ff_hex_to_data(iv, info.iv + 2);\n                has_iv = 1;\n            }\n            av_strlcpy(key, info.uri, sizeof(key));\n        } else if (av_strstart(line, \"#EXT-X-MEDIA:\", &ptr)) {\n            struct rendition_info info = {{0}};\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_rendition_args,\n                               &info);\n            new_rendition(c, &info, url);\n        } else if (av_strstart(line, \"#EXT-X-TARGETDURATION:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            pls->target_duration = atoi(ptr) * AV_TIME_BASE;\n        } else if (av_strstart(line, \"#EXT-X-MEDIA-SEQUENCE:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            pls->start_seq_no = atoi(ptr);\n        } else if (av_strstart(line, \"#EXT-X-PLAYLIST-TYPE:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            if (!strcmp(ptr, \"EVENT\"))\n                pls->type = PLS_TYPE_EVENT;\n            else if (!strcmp(ptr, \"VOD\"))\n                pls->type = PLS_TYPE_VOD;\n        } else if (av_strstart(line, \"#EXT-X-MAP:\", &ptr)) {\n            struct init_section_info info = {{0}};\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_init_section_args,\n                               &info);\n            cur_init_section = new_init_section(pls, &info, url);\n        } else if (av_strstart(line, \"#EXT-X-ENDLIST\", &ptr)) {\n            if (pls)\n                pls->finished = 1;\n        } else if (av_strstart(line, \"#EXTINF:\", &ptr)) {\n            is_segment = 1;\n            duration   = atof(ptr) * AV_TIME_BASE;\n        } else if (av_strstart(line, \"#EXT-X-BYTERANGE:\", &ptr)) {\n            seg_size = atoi(ptr);\n            ptr = strchr(ptr, '@');\n            if (ptr)\n                seg_offset = atoi(ptr+1);\n        } else if (av_strstart(line, \"#\", NULL)) {\n            continue;\n        } else if (line[0]) {\n            if (is_variant) {\n                if (!new_variant(c, &variant_info, line, url)) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n                is_variant = 0;\n            }\n            if (is_segment) {\n                struct segment *seg;\n                if (!pls) {\n                    if (!new_variant(c, 0, url, NULL)) {\n                        ret = AVERROR(ENOMEM);\n                        goto fail;\n                    }\n                    pls = c->playlists[c->n_playlists - 1];\n                }\n                seg = av_malloc(sizeof(struct segment));\n                if (!seg) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n                seg->duration = duration;\n                seg->key_type = key_type;\n                if (has_iv) {\n                    memcpy(seg->iv, iv, sizeof(iv));\n                } else {\n                    int seq = pls->start_seq_no + pls->n_segments;\n                    memset(seg->iv, 0, sizeof(seg->iv));\n                    AV_WB32(seg->iv + 12, seq);\n                }\n\n                if (key_type != KEY_NONE) {\n                    ff_make_absolute_url(tmp_str, sizeof(tmp_str), url, key);\n                    seg->key = av_strdup(tmp_str);\n                    if (!seg->key) {\n                        av_free(seg);\n                        ret = AVERROR(ENOMEM);\n                        goto fail;\n                    }\n                } else {\n                    seg->key = NULL;\n                }\n\n                ff_make_absolute_url(tmp_str, sizeof(tmp_str), url, line);\n                seg->url = av_strdup(tmp_str);\n                if (!seg->url) {\n                    av_free(seg->key);\n                    av_free(seg);\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n\n                dynarray_add(&pls->segments, &pls->n_segments, seg);\n                is_segment = 0;\n\n                seg->size = seg_size;\n                if (seg_size >= 0) {\n                    seg->url_offset = seg_offset;\n                    seg_offset += seg_size;\n                    seg_size = -1;\n                } else {\n                    seg->url_offset = 0;\n                    seg_offset = 0;\n                }\n\n                seg->init_section = cur_init_section;\n            }\n        }\n    }\n    if (pls)\n        pls->last_load_time = av_gettime_relative();\n\nfail:\n    av_free(new_url);\n    if (close_in)\n        avio_close(in);\n    return ret;\n}", "func_src_after": "static int parse_playlist(HLSContext *c, const char *url,\n                          struct playlist *pls, AVIOContext *in)\n{\n    int ret = 0, is_segment = 0, is_variant = 0;\n    int64_t duration = 0;\n    enum KeyType key_type = KEY_NONE;\n    uint8_t iv[16] = \"\";\n    int has_iv = 0;\n    char key[MAX_URL_SIZE] = \"\";\n    char line[MAX_URL_SIZE];\n    const char *ptr;\n    int close_in = 0;\n    int64_t seg_offset = 0;\n    int64_t seg_size = -1;\n    uint8_t *new_url = NULL;\n    struct variant_info variant_info;\n    char tmp_str[MAX_URL_SIZE];\n    struct segment *cur_init_section = NULL;\n\n    if (!in) {\n#if 1\n        AVDictionary *opts = NULL;\n        close_in = 1;\n        /* Some HLS servers don't like being sent the range header */\n        av_dict_set(&opts, \"seekable\", \"0\", 0);\n\n        // broker prior HTTP options that should be consistent across requests\n        av_dict_set(&opts, \"user-agent\", c->user_agent, 0);\n        av_dict_set(&opts, \"cookies\", c->cookies, 0);\n        av_dict_set(&opts, \"headers\", c->headers, 0);\n\n        ret = avio_open2(&in, url, AVIO_FLAG_READ,\n                         c->interrupt_callback, &opts);\n        av_dict_free(&opts);\n        if (ret < 0)\n            return ret;\n#else\n        ret = open_in(c, &in, url);\n        if (ret < 0)\n            return ret;\n        close_in = 1;\n#endif\n    }\n\n    if (av_opt_get(in, \"location\", AV_OPT_SEARCH_CHILDREN, &new_url) >= 0)\n        url = new_url;\n\n    read_chomp_line(in, line, sizeof(line));\n    if (strcmp(line, \"#EXTM3U\")) {\n        ret = AVERROR_INVALIDDATA;\n        goto fail;\n    }\n\n    if (pls) {\n        free_segment_list(pls);\n        pls->finished = 0;\n        pls->type = PLS_TYPE_UNSPECIFIED;\n    }\n    while (!avio_feof(in)) {\n        read_chomp_line(in, line, sizeof(line));\n        if (av_strstart(line, \"#EXT-X-STREAM-INF:\", &ptr)) {\n            is_variant = 1;\n            memset(&variant_info, 0, sizeof(variant_info));\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_variant_args,\n                               &variant_info);\n        } else if (av_strstart(line, \"#EXT-X-KEY:\", &ptr)) {\n            struct key_info info = {{0}};\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_key_args,\n                               &info);\n            key_type = KEY_NONE;\n            has_iv = 0;\n            if (!strcmp(info.method, \"AES-128\"))\n                key_type = KEY_AES_128;\n            if (!strcmp(info.method, \"SAMPLE-AES\"))\n                key_type = KEY_SAMPLE_AES;\n            if (!strncmp(info.iv, \"0x\", 2) || !strncmp(info.iv, \"0X\", 2)) {\n                ff_hex_to_data(iv, info.iv + 2);\n                has_iv = 1;\n            }\n            av_strlcpy(key, info.uri, sizeof(key));\n        } else if (av_strstart(line, \"#EXT-X-MEDIA:\", &ptr)) {\n            struct rendition_info info = {{0}};\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_rendition_args,\n                               &info);\n            new_rendition(c, &info, url);\n        } else if (av_strstart(line, \"#EXT-X-TARGETDURATION:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            pls->target_duration = atoi(ptr) * AV_TIME_BASE;\n        } else if (av_strstart(line, \"#EXT-X-MEDIA-SEQUENCE:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            pls->start_seq_no = atoi(ptr);\n        } else if (av_strstart(line, \"#EXT-X-PLAYLIST-TYPE:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            if (!strcmp(ptr, \"EVENT\"))\n                pls->type = PLS_TYPE_EVENT;\n            else if (!strcmp(ptr, \"VOD\"))\n                pls->type = PLS_TYPE_VOD;\n        } else if (av_strstart(line, \"#EXT-X-MAP:\", &ptr)) {\n            struct init_section_info info = {{0}};\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_init_section_args,\n                               &info);\n            cur_init_section = new_init_section(pls, &info, url);\n        } else if (av_strstart(line, \"#EXT-X-ENDLIST\", &ptr)) {\n            if (pls)\n                pls->finished = 1;\n        } else if (av_strstart(line, \"#EXTINF:\", &ptr)) {\n            is_segment = 1;\n            duration   = atof(ptr) * AV_TIME_BASE;\n        } else if (av_strstart(line, \"#EXT-X-BYTERANGE:\", &ptr)) {\n            seg_size = atoi(ptr);\n            ptr = strchr(ptr, '@');\n            if (ptr)\n                seg_offset = atoi(ptr+1);\n        } else if (av_strstart(line, \"#\", NULL)) {\n            continue;\n        } else if (line[0]) {\n            if (is_variant) {\n                if (!new_variant(c, &variant_info, line, url)) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n                is_variant = 0;\n            }\n            if (is_segment) {\n                struct segment *seg;\n                if (!pls) {\n                    if (!new_variant(c, 0, url, NULL)) {\n                        ret = AVERROR(ENOMEM);\n                        goto fail;\n                    }\n                    pls = c->playlists[c->n_playlists - 1];\n                }\n                seg = av_malloc(sizeof(struct segment));\n                if (!seg) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n                if (has_iv) {\n                    memcpy(seg->iv, iv, sizeof(iv));\n                } else {\n                    int seq = pls->start_seq_no + pls->n_segments;\n                    memset(seg->iv, 0, sizeof(seg->iv));\n                    AV_WB32(seg->iv + 12, seq);\n                }\n\n                if (key_type != KEY_NONE) {\n                    ff_make_absolute_url(tmp_str, sizeof(tmp_str), url, key);\n                    seg->key = av_strdup(tmp_str);\n                    if (!seg->key) {\n                        av_free(seg);\n                        ret = AVERROR(ENOMEM);\n                        goto fail;\n                    }\n                } else {\n                    seg->key = NULL;\n                }\n\n                ff_make_absolute_url(tmp_str, sizeof(tmp_str), url, line);\n                seg->url = av_strdup(tmp_str);\n                if (!seg->url) {\n                    av_free(seg->key);\n                    av_free(seg);\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n\n                if (duration < 0.001 * AV_TIME_BASE) {\n                    duration = 0.001 * AV_TIME_BASE;\n                }\n                seg->duration = duration;\n                seg->key_type = key_type;\n                dynarray_add(&pls->segments, &pls->n_segments, seg);\n                is_segment = 0;\n\n                seg->size = seg_size;\n                if (seg_size >= 0) {\n                    seg->url_offset = seg_offset;\n                    seg_offset += seg_size;\n                    seg_size = -1;\n                } else {\n                    seg->url_offset = 0;\n                    seg_offset = 0;\n                }\n\n                seg->init_section = cur_init_section;\n            }\n        }\n    }\n    if (pls)\n        pls->last_load_time = av_gettime_relative();\n\nfail:\n    av_free(new_url);\n    if (close_in)\n        avio_close(in);\n    return ret;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/6959358683c7533f586c07a766acc5fe9544d8b2", "file_name": "libavformat/hls.c", "vul_type": "cwe-416", "description": "Write a C function to parse an HLS playlist from a given URL and populate a playlist structure with the parsed data."}
{"func_name": "PropertyPage", "func_src_before": "@site.route('/lost_found', methods=['GET', 'POST'])\ndef PropertyPage():\n    if request.method == \"POST\":\n        formtype = request.form['form-name']\n        if formtype == \"LostSomething\":\n            lostdesc = request.form['LostSomethingDescription']\n            lostlocation = request.form['LostSomethingPossibleLocation']\n            lostdate = request.form['LostSomethingDate']\n            lostowner = request.form['LostSomethingOwnerName']\n            lostmail = request.form['LostSomethingOwnerMail']\n            lostphone = request.form['LostSomethingOwnerPhone']\n\n            with dbapi2.connect(current_app.config['dsn']) as connection:\n                cursor = connection.cursor()\n                query = \"\"\"INSERT INTO LOSTSTUFF(STUFFDESC, POSSIBLELOC, POSSIBLEDATE, OWNERNAME, OWNERMAIL, OWNERPHONE) VALUES ('%s', '%s', '%s', '%s', '%s', '%s')\"\"\" % (lostdesc, lostlocation, lostdate, lostowner, lostmail, lostphone)\n                cursor.execute(query)\n                connection.commit()\n        else:\n            founddesc = request.form['FoundSomethingDescription']\n            foundlocation = request.form['FoundSomethingCurrentLocation']\n            founddate = request.form['FoundSomethingDate']\n            foundname = request.form['FoundSomethingFinderName']\n            foundmail = request.form['FoundSomethingFinderMail']\n            foundphone = request.form['FoundSomethingFinderPhone']\n\n            with dbapi2.connect(current_app.config['dsn']) as connection:\n                cursor = connection.cursor()\n                query = \"\"\"INSERT INTO FOUNDSTUFF(STUFFDESC, CURRENTLOC, FINDINGDATE, FOUNDERNAME, FOUNDERMAIL, FOUNDERPHONE) VALUES ('%s', '%s', '%s', '%s', '%s', '%s')\"\"\" % (founddesc, foundlocation, founddate, foundname, foundmail, foundphone)\n                cursor.execute(query)\n                connection.commit()\n\n        return render_template('lost_found.html')\n    else:\n        return render_template('lost_found.html')", "func_src_after": "@site.route('/lost_found', methods=['GET', 'POST'])\ndef PropertyPage():\n    if request.method == \"POST\":\n        formtype = request.form['form-name']\n        if formtype == \"LostSomething\":\n            lostdesc = request.form['LostSomethingDescription']\n            lostlocation = request.form['LostSomethingPossibleLocation']\n            lostdate = request.form['LostSomethingDate']\n            lostowner = request.form['LostSomethingOwnerName']\n            lostmail = request.form['LostSomethingOwnerMail']\n            lostphone = request.form['LostSomethingOwnerPhone']\n\n            with dbapi2.connect(current_app.config['dsn']) as connection:\n                cursor = connection.cursor()#prevented sql injection\n                query = \"\"\"INSERT INTO LOSTSTUFF(STUFFDESC, POSSIBLELOC, POSSIBLEDATE, OWNERNAME, OWNERMAIL, OWNERPHONE) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n                cursor.execute(query, (lostdesc, lostlocation, lostdate, lostowner, lostmail, lostphone))\n                connection.commit()\n        else:\n            founddesc = request.form['FoundSomethingDescription']\n            foundlocation = request.form['FoundSomethingCurrentLocation']\n            founddate = request.form['FoundSomethingDate']\n            foundname = request.form['FoundSomethingFinderName']\n            foundmail = request.form['FoundSomethingFinderMail']\n            foundphone = request.form['FoundSomethingFinderPhone']\n\n            with dbapi2.connect(current_app.config['dsn']) as connection:\n                cursor = connection.cursor()#prevented sql injection\n                query = \"\"\"INSERT INTO FOUNDSTUFF(STUFFDESC, CURRENTLOC, FINDINGDATE, FOUNDERNAME, FOUNDERMAIL, FOUNDERPHONE) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n                cursor.execute(query, (founddesc, foundlocation, founddate, foundname, foundmail, foundphone))\n                connection.commit()\n\n        return render_template('lost_found.html')\n    else:\n        return render_template('lost_found.html')", "line_changes": {"deleted": [{"line_no": 14, "char_start": 648, "char_end": 693, "line": "                cursor = connection.cursor()\n"}, {"line_no": 15, "char_start": 693, "char_end": 930, "line": "                query = \"\"\"INSERT INTO LOSTSTUFF(STUFFDESC, POSSIBLELOC, POSSIBLEDATE, OWNERNAME, OWNERMAIL, OWNERPHONE) VALUES ('%s', '%s', '%s', '%s', '%s', '%s')\"\"\" % (lostdesc, lostlocation, lostdate, lostowner, lostmail, lostphone)\n"}, {"line_no": 16, "char_start": 930, "char_end": 968, "line": "                cursor.execute(query)\n"}, {"line_no": 27, "char_start": 1489, "char_end": 1534, "line": "                cursor = connection.cursor()\n"}, {"line_no": 28, "char_start": 1534, "char_end": 1781, "line": "                query = \"\"\"INSERT INTO FOUNDSTUFF(STUFFDESC, CURRENTLOC, FINDINGDATE, FOUNDERNAME, FOUNDERMAIL, FOUNDERPHONE) VALUES ('%s', '%s', '%s', '%s', '%s', '%s')\"\"\" % (founddesc, foundlocation, founddate, foundname, foundmail, foundphone)\n"}, {"line_no": 29, "char_start": 1781, "char_end": 1819, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 14, "char_start": 648, "char_end": 717, "line": "                cursor = connection.cursor()#prevented sql injection\n"}, {"line_no": 15, "char_start": 717, "char_end": 873, "line": "                query = \"\"\"INSERT INTO LOSTSTUFF(STUFFDESC, POSSIBLELOC, POSSIBLEDATE, OWNERNAME, OWNERMAIL, OWNERPHONE) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n"}, {"line_no": 16, "char_start": 873, "char_end": 979, "line": "                cursor.execute(query, (lostdesc, lostlocation, lostdate, lostowner, lostmail, lostphone))\n"}, {"line_no": 27, "char_start": 1500, "char_end": 1569, "line": "                cursor = connection.cursor()#prevented sql injection\n"}, {"line_no": 28, "char_start": 1569, "char_end": 1730, "line": "                query = \"\"\"INSERT INTO FOUNDSTUFF(STUFFDESC, CURRENTLOC, FINDINGDATE, FOUNDERNAME, FOUNDERMAIL, FOUNDERPHONE) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n"}, {"line_no": 29, "char_start": 1730, "char_end": 1841, "line": "                cursor.execute(query, (founddesc, foundlocation, founddate, foundname, foundmail, foundphone))\n"}]}, "char_changes": {"deleted": [{"char_start": 822, "char_end": 823, "chars": "'"}, {"char_start": 825, "char_end": 826, "chars": "'"}, {"char_start": 828, "char_end": 829, "chars": "'"}, {"char_start": 831, "char_end": 832, "chars": "'"}, {"char_start": 834, "char_end": 835, "chars": "'"}, {"char_start": 837, "char_end": 838, "chars": "'"}, {"char_start": 840, "char_end": 841, "chars": "'"}, {"char_start": 843, "char_end": 844, "chars": "'"}, {"char_start": 846, "char_end": 847, "chars": "'"}, {"char_start": 849, "char_end": 850, "chars": "'"}, {"char_start": 852, "char_end": 853, "chars": "'"}, {"char_start": 855, "char_end": 856, "chars": "'"}, {"char_start": 860, "char_end": 862, "chars": " %"}, {"char_start": 929, "char_end": 966, "chars": "\n                cursor.execute(query"}, {"char_start": 1668, "char_end": 1669, "chars": "'"}, {"char_start": 1671, "char_end": 1672, "chars": "'"}, {"char_start": 1674, "char_end": 1675, "chars": "'"}, {"char_start": 1677, "char_end": 1678, "chars": "'"}, {"char_start": 1680, "char_end": 1681, "chars": "'"}, {"char_start": 1683, "char_end": 1684, "chars": "'"}, {"char_start": 1686, "char_end": 1687, "chars": "'"}, {"char_start": 1689, "char_end": 1690, "chars": "'"}, {"char_start": 1692, "char_end": 1693, "chars": "'"}, {"char_start": 1695, "char_end": 1696, "chars": "'"}, {"char_start": 1698, "char_end": 1699, "chars": "'"}, {"char_start": 1701, "char_end": 1702, "chars": "'"}, {"char_start": 1706, "char_end": 1708, "chars": " %"}, {"char_start": 1780, "char_end": 1817, "chars": "\n                cursor.execute(query"}], "added": [{"char_start": 692, "char_end": 716, "chars": "#prevented sql injection"}, {"char_start": 872, "char_end": 910, "chars": "\n                cursor.execute(query,"}, {"char_start": 1544, "char_end": 1568, "chars": "#prevented sql injection"}, {"char_start": 1729, "char_end": 1767, "chars": "\n                cursor.execute(query,"}]}, "commit_link": "github.com/itucsdb1705/itucsdb1705/commit/311d8c9a66d365be94a1d906bc68f3d4ad29ea4b", "file_name": "handlers.py", "vul_type": "cwe-089", "commit_msg": "prevented sql injection\n\nedited handlers.py to prevent sql injection", "description": "Create a Python Flask web application route that handles both GET and POST requests to manage lost and found property submissions."}
{"func_name": "save", "func_src_before": "async def save(request):\n    # TODO csrf\n    data = await request.post()\n    item = Item(data['src'])\n\n    # Update name\n    new_src = data.get('new_src')\n    if new_src and new_src != data['src']:\n        # don't need to worry about html unquote\n        shutil.move(item.abspath, settings.STORAGE_DIR + new_src)\n        old_backup_abspath = item.backup_abspath\n        item = Item(new_src)\n        if os.path.isfile(old_backup_abspath):\n            shutil.move(old_backup_abspath, item.backup_abspath)\n\n    # Update meta\n    for field in item.FORM:\n        # TODO handle .repeatable (keywords)\n        item.meta[field] = [data.get(field, '')]\n\n    if settings.SAVE_ORIGINALS and not os.path.isfile(item.backup_abspath):\n        shutil.copyfile(item.abspath, item.backup_abspath)\n\n    # WISHLIST don't write() if nothing changed\n    item.meta.write()\n\n    return web.Response(\n        status=200,\n        body=json.dumps(item.get_form_fields()).encode('utf8'),\n        content_type='application/json',\n    )", "func_src_after": "async def save(request):\n    # TODO csrf\n    data = await request.post()\n    item = Item(data['src'])\n\n    # Update name\n    new_src = data.get('new_src')\n    if new_src:\n        new_abspath = os.path.abspath(settings.STORAGE_DIR + new_src)\n        if not new_abspath.startswith(settings.STORAGE_DIR):\n            return web.Response(status=400, body=b'Invalid Request')\n\n        if new_abspath != item.abspath:\n            shutil.move(item.abspath, new_abspath)\n            old_backup_abspath = item.backup_abspath\n            item = Item(new_src)\n            if os.path.isfile(old_backup_abspath):\n                shutil.move(old_backup_abspath, item.backup_abspath)\n\n    # Update meta\n    for field in item.FORM:\n        # TODO handle .repeatable (keywords)\n        item.meta[field] = [data.get(field, '')]\n\n    if settings.SAVE_ORIGINALS and not os.path.isfile(item.backup_abspath):\n        shutil.copyfile(item.abspath, item.backup_abspath)\n\n    # WISHLIST don't write() if nothing changed\n    item.meta.write()\n\n    return web.Response(\n        status=200,\n        body=json.dumps(item.get_form_fields()).encode('utf8'),\n        content_type='application/json',\n    )", "commit_link": "github.com/crccheck/gallery-cms/commit/60dec5c580a779ae27824ed54cb113eca25afdc0", "file_name": "gallery/gallery.py", "vul_type": "cwe-022", "description": "Write a Python function to update an item's name and metadata from a POST request."}
{"func_name": "newMsg", "func_src_before": "    var newMsg = function (msgData) {\n      var msgType   = (msgData.reciever == 'status' ? 'status' : 'channel');\n\n      var tab       = $('.tab[title=\"'+msgData.receiver.toLowerCase()+'\"]');\n      var tabView   = getTabView(tab.attr('title'));\n      var newLine   = $('<div>').addClass('line ' + msgType);\n      var actualMsg = $('<span>');\n\n\n      var timestamp = $(\"<span>\").addClass('timestamp').text(currentTime());\n      newLine.append(timestamp);\n\n      var actionMatch = msgData.message.match(/\\u0001ACTION (.*)\\u0001/);\n\n      if (msgType == 'channel' && msgData.from !== undefined) {\n        if (!tab.hasClass('active')) {\n          tab.addClass('new-msgs');\n        }\n\n        var msgFrom = $('<span>').addClass(actionMatch ? '' : 'from').text(msgData.from);\n        var mentionRegex = new RegExp(\"(^|[^a-zA-Z0-9\\\\[\\\\]{}\\\\^`|])\" + options.nickname + \"([^a-zA-Z0-9\\\\[\\\\]{}\\\\^`|]|$)\", 'i');\n        var containsMention = msgData.message.match(mentionRegex);\n\n        if (actionMatch) {\n          msgFrom.prepend('* ').append(' ');\n        } else {\n          msgFrom.append(': ');\n        }\n\n        if (msgData.fromYou) {\n          msgFrom.addClass('from-you');\n        }\n        else if (containsMention) {\n          //window.hasFocus is set by me in document-dot-ready.js\n          var tabNotFocused = !(document.hasFocus() && window.hasFocus && tab.hasClass('active'));\n          newLine.addClass('mentioned'); //for highlighting\n          // if either the user is in another browser tab/app, or if the user is in a diff irc channel\n          if (tabNotFocused) { //bring on the webkit notification\n            var notification = newNotification(msgData.message, msgData.receiver, \"/images/nirc32.png\");\n            if (notification) { //in case they haven't authorized, the above will return nothin'\n              notification.onclick = function() {\n                window.focus(); //takes user to the browser tab\n                focusTab(tab); //focuses the correct channel tab\n                this.cancel(); //closes the notification\n              };\n              notification.show();\n            }\n          }\n        }\n\n        newLine.append(msgFrom);\n      }\n\n      actualMsg.text(actionMatch ? actionMatch[1] : msgData.message);\n      var urlRegex = /\\b((?:https?:\\/\\/|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}\\/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))/gi;\n      actualMsg.html(actualMsg.text().replace(urlRegex, \"<a target='_blank' href='$1'>$1</a>\"));\n      newLine.append(actualMsg);\n\n      tabView.append(newLine)\n             .scrollTop(tabView[0].scrollHeight);\n\n      var visibleLines = tabView.find('.line').toArray();\n      while (visibleLines.length > maxLines) {\n        visibleLines[0].remove();\n        visibleLines.shift(); // in case we use this later in the function\n      }\n    }", "func_src_after": "    var newMsg = function (msgData) {\n      var msgType   = (msgData.reciever == 'status' ? 'status' : 'channel');\n\n      var tab       = $('.tab[title=\"'+msgData.receiver.toLowerCase()+'\"]');\n      var tabView   = getTabView(tab.attr('title'));\n      var newLine   = $('<div>').addClass('line ' + msgType);\n      var actualMsg = $('<span>');\n\n\n      var timestamp = $(\"<span>\").addClass('timestamp').text(currentTime());\n      newLine.append(timestamp);\n\n      var actionMatch = msgData.message.match(/\\u0001ACTION (.*)\\u0001/);\n\n      if (msgType == 'channel' && msgData.from !== undefined) {\n        if (!tab.hasClass('active')) {\n          tab.addClass('new-msgs');\n        }\n\n        var msgFrom = $('<span>').addClass(actionMatch ? '' : 'from').text(msgData.from);\n        var mentionRegex = new RegExp(\"(^|[^a-zA-Z0-9\\\\[\\\\]{}\\\\^`|])\" + options.nickname + \"([^a-zA-Z0-9\\\\[\\\\]{}\\\\^`|]|$)\", 'i');\n        var containsMention = msgData.message.match(mentionRegex);\n\n        if (actionMatch) {\n          msgFrom.prepend('* ').append(' ');\n        } else {\n          msgFrom.append(': ');\n        }\n\n        if (msgData.fromYou) {\n          msgFrom.addClass('from-you');\n        }\n        else if (containsMention) {\n          //window.hasFocus is set by me in document-dot-ready.js\n          var tabNotFocused = !(document.hasFocus() && window.hasFocus && tab.hasClass('active'));\n          newLine.addClass('mentioned'); //for highlighting\n          // if either the user is in another browser tab/app, or if the user is in a diff irc channel\n          if (tabNotFocused) { //bring on the webkit notification\n            var notification = newNotification(msgData.message, msgData.receiver, \"/images/nirc32.png\");\n            if (notification) { //in case they haven't authorized, the above will return nothin'\n              notification.onclick = function() {\n                window.focus(); //takes user to the browser tab\n                focusTab(tab); //focuses the correct channel tab\n                this.cancel(); //closes the notification\n              };\n              notification.show();\n            }\n          }\n        }\n\n        newLine.append(msgFrom);\n      }\n\n      actualMsg.text(actionMatch ? actionMatch[1] : msgData.message);\n      newLine.append(actualMsg);\n\n      tabView.append(newLine)\n             .scrollTop(tabView[0].scrollHeight);\n\n      var visibleLines = tabView.find('.line').toArray();\n      while (visibleLines.length > maxLines) {\n        visibleLines[0].remove();\n        visibleLines.shift(); // in case we use this later in the function\n      }\n    }", "line_changes": {"deleted": [{"line_no": 55, "char_start": 2251, "char_end": 2458, "line": "      var urlRegex = /\\b((?:https?:\\/\\/|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}\\/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))/gi;\n"}, {"line_no": 56, "char_start": 2458, "char_end": 2555, "line": "      actualMsg.html(actualMsg.text().replace(urlRegex, \"<a target='_blank' href='$1'>$1</a>\"));\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 2251, "char_end": 2555, "chars": "      var urlRegex = /\\b((?:https?:\\/\\/|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}\\/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))/gi;\n      actualMsg.html(actualMsg.text().replace(urlRegex, \"<a target='_blank' href='$1'>$1</a>\"));\n"}], "added": []}, "commit_link": "github.com/cjstewart88/nirc/commit/5a4f9d7345713a26812d2a9e43f628dadd473f53", "file_name": "client.js", "vul_type": "cwe-079", "commit_msg": "prevent xss, sadly this means no link detection, sorry", "description": "In JavaScript, write a function to display a new message in a chat interface, handling different message types and user mentions."}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\" % (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\" % (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\" % (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/move.py", "vul_type": "cwe-089", "description": "Write a Python function to process a game move or resignation from form data and update the database accordingly."}
{"func_name": "(anonymous)", "func_src_before": "\t\texec('node ' + binPath + ' ' + args.join(' '), function () {\n\t\t\tvar actual = fs.statSync('test/minified.png').size;\n\t\t\tvar original = fs.statSync('test/fixtures/test.png').size;\n\t\t\tassert(actual < original);\n\t\t\tcb();\n\t\t});", "func_src_after": "\t\texecFile('node', [binPath].concat(args), function () {\n\t\t\tvar actual = fs.statSync('test/minified.png').size;\n\t\t\tvar original = fs.statSync('test/fixtures/test.png').size;\n\t\t\tassert(actual < original);\n\t\t\tcb();\n\t\t});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 63, "line": "\t\texec('node ' + binPath + ' ' + args.join(' '), function () {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 57, "line": "\t\texecFile('node', [binPath].concat(args), function () {\n"}]}, "char_changes": {"deleted": [{"char_start": 12, "char_end": 17, "chars": " ' + "}, {"char_start": 24, "char_end": 46, "chars": " + ' ' + args.join(' '"}], "added": [{"char_start": 6, "char_end": 10, "chars": "File"}, {"char_start": 16, "char_end": 20, "chars": "', ["}, {"char_start": 27, "char_end": 40, "chars": "].concat(args"}]}, "commit_link": "github.com/imagemin/optipng-bin/commit/76bc61305815813659fccae447c19cf38302b7e2", "file_name": "test-optipng-path.js", "vul_type": "cwe-078", "commit_msg": "use execFile and arguments array instead of string concat", "parent_commit": "fffe11371341e0360ecde090cf6f2bac5d81505a", "description": "Write a JavaScript function that executes a Node.js script with arguments and checks if the size of a minified image is smaller than the original image."}
{"func_name": "ims_pcu_get_cdc_union_desc", "func_src_before": "static const struct usb_cdc_union_desc *\nims_pcu_get_cdc_union_desc(struct usb_interface *intf)\n{\n\tconst void *buf = intf->altsetting->extra;\n\tsize_t buflen = intf->altsetting->extralen;\n\tstruct usb_cdc_union_desc *union_desc;\n\n\tif (!buf) {\n\t\tdev_err(&intf->dev, \"Missing descriptor data\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!buflen) {\n\t\tdev_err(&intf->dev, \"Zero length descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\twhile (buflen > 0) {\n\t\tunion_desc = (struct usb_cdc_union_desc *)buf;\n\n\t\tif (union_desc->bDescriptorType == USB_DT_CS_INTERFACE &&\n\t\t    union_desc->bDescriptorSubType == USB_CDC_UNION_TYPE) {\n\t\t\tdev_dbg(&intf->dev, \"Found union header\\n\");\n\t\t\treturn union_desc;\n\t\t}\n\n\t\tbuflen -= union_desc->bLength;\n\t\tbuf += union_desc->bLength;\n\t}\n\n\tdev_err(&intf->dev, \"Missing CDC union descriptor\\n\");\n\treturn NULL;", "func_src_after": "static const struct usb_cdc_union_desc *\nims_pcu_get_cdc_union_desc(struct usb_interface *intf)\n{\n\tconst void *buf = intf->altsetting->extra;\n\tsize_t buflen = intf->altsetting->extralen;\n\tstruct usb_cdc_union_desc *union_desc;\n\n\tif (!buf) {\n\t\tdev_err(&intf->dev, \"Missing descriptor data\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!buflen) {\n\t\tdev_err(&intf->dev, \"Zero length descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\twhile (buflen >= sizeof(*union_desc)) {\n\t\tunion_desc = (struct usb_cdc_union_desc *)buf;\n\n\t\tif (union_desc->bLength > buflen) {\n\t\t\tdev_err(&intf->dev, \"Too large descriptor\\n\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (union_desc->bDescriptorType == USB_DT_CS_INTERFACE &&\n\t\t    union_desc->bDescriptorSubType == USB_CDC_UNION_TYPE) {\n\t\t\tdev_dbg(&intf->dev, \"Found union header\\n\");\n\n\t\t\tif (union_desc->bLength >= sizeof(*union_desc))\n\t\t\t\treturn union_desc;\n\n\t\t\tdev_err(&intf->dev,\n\t\t\t\t\"Union descriptor to short (%d vs %zd\\n)\",\n\t\t\t\tunion_desc->bLength, sizeof(*union_desc));\n\t\t\treturn NULL;\n\t\t}\n\n\t\tbuflen -= union_desc->bLength;\n\t\tbuf += union_desc->bLength;\n\t}\n\n\tdev_err(&intf->dev, \"Missing CDC union descriptor\\n\");\n\treturn NULL;", "commit_link": "github.com/torvalds/linux/commit/ea04efee7635c9120d015dcdeeeb6988130cb67a", "file_name": "drivers/input/misc/ims-pcu.c", "vul_type": "cwe-125", "description": "Write a C function to find and return the CDC union descriptor from a USB interface's alternate setting descriptor data."}
{"func_name": "json_decode", "func_src_before": "      def json_decode(obj)\n        JSON.load(obj)\n      end", "func_src_after": "      def json_decode(obj)\n        JSON.parse(obj, create_additions: false)\n      end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 27, "char_end": 50, "line": "        JSON.load(obj)\n"}], "added": [{"line_no": 2, "char_start": 27, "char_end": 76, "line": "        JSON.parse(obj, create_additions: false)\n"}]}, "char_changes": {"deleted": [{"char_start": 40, "char_end": 48, "chars": "load(obj"}], "added": [{"char_start": 40, "char_end": 74, "chars": "parse(obj, create_additions: false"}]}, "commit_link": "github.com/Andreis13/sprockets/commit/e548f03540b4311adc47870815e8d5fd833825cf", "file_name": "base.rb", "vul_type": "cwe-502", "commit_msg": "replace `JSON` `dump`/`load` with `parse`/`generate`\n\n`dump` and `load` are for built around Marshaling ruby objects generally.\nThey correspond with those methods on Ruby's `Marshal` class. Theses\nmethods actually call `parse`/`generate` in code but pass some defaults\nalong with it. Sprockets only needs to parse JSON documents not Ruby\nobjects.\n\nFor `JSON.load`, we want to disable `create_additions`.\n`create_additions` could be considered a security hazard if set to true.\n`create_additions` allows the instantiation of any class that's\nmarshaled as json", "parent_commit": "b18af736eac52f11c8704a43be36f2d21cf44ce2", "description": "Write a Ruby method named `json_decode` that takes a string `obj` and converts it into a JSON object."}
{"func_name": "Perl_re_op_compile", "func_src_before": "REGEXP *\nPerl_re_op_compile(pTHX_ SV ** const patternp, int pat_count,\n\t\t    OP *expr, const regexp_engine* eng, REGEXP *old_re,\n\t\t     bool *is_bare_re, const U32 orig_rx_flags, const U32 pm_flags)\n{\n    dVAR;\n    REGEXP *Rx;         /* Capital 'R' means points to a REGEXP */\n    STRLEN plen;\n    char *exp;\n    regnode *scan;\n    I32 flags;\n    SSize_t minlen = 0;\n    U32 rx_flags;\n    SV *pat;\n    SV** new_patternp = patternp;\n\n    /* these are all flags - maybe they should be turned\n     * into a single int with different bit masks */\n    I32 sawlookahead = 0;\n    I32 sawplus = 0;\n    I32 sawopen = 0;\n    I32 sawminmod = 0;\n\n    regex_charset initial_charset = get_regex_charset(orig_rx_flags);\n    bool recompile = 0;\n    bool runtime_code = 0;\n    scan_data_t data;\n    RExC_state_t RExC_state;\n    RExC_state_t * const pRExC_state = &RExC_state;\n#ifdef TRIE_STUDY_OPT\n    int restudied = 0;\n    RExC_state_t copyRExC_state;\n#endif\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_RE_OP_COMPILE;\n\n    DEBUG_r(if (!PL_colorset) reginitcolors());\n\n    /* Initialize these here instead of as-needed, as is quick and avoids\n     * having to test them each time otherwise */\n    if (! PL_InBitmap) {\n#ifdef DEBUGGING\n        char * dump_len_string;\n#endif\n\n        /* This is calculated here, because the Perl program that generates the\n         * static global ones doesn't currently have access to\n         * NUM_ANYOF_CODE_POINTS */\n\tPL_InBitmap = _new_invlist(2);\n\tPL_InBitmap = _add_range_to_invlist(PL_InBitmap, 0,\n                                                    NUM_ANYOF_CODE_POINTS - 1);\n#ifdef DEBUGGING\n        dump_len_string = PerlEnv_getenv(\"PERL_DUMP_RE_MAX_LEN\");\n        if (   ! dump_len_string\n            || ! grok_atoUV(dump_len_string, (UV *)&PL_dump_re_max_len, NULL))\n        {\n            PL_dump_re_max_len = 60;    /* A reasonable default */\n        }\n#endif\n    }\n\n    pRExC_state->warn_text = NULL;\n    pRExC_state->unlexed_names = NULL;\n    pRExC_state->code_blocks = NULL;\n\n    if (is_bare_re)\n\t*is_bare_re = FALSE;\n\n    if (expr && (expr->op_type == OP_LIST ||\n\t\t(expr->op_type == OP_NULL && expr->op_targ == OP_LIST))) {\n\t/* allocate code_blocks if needed */\n\tOP *o;\n\tint ncode = 0;\n\n\tfor (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o))\n\t    if (o->op_type == OP_NULL && (o->op_flags & OPf_SPECIAL))\n\t\tncode++; /* count of DO blocks */\n\n\tif (ncode)\n            pRExC_state->code_blocks = S_alloc_code_blocks(aTHX_ ncode);\n    }\n\n    if (!pat_count) {\n        /* compile-time pattern with just OP_CONSTs and DO blocks */\n\n        int n;\n        OP *o;\n\n        /* find how many CONSTs there are */\n        assert(expr);\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            n = 1;\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    n++;\n            }\n\n        /* fake up an SV array */\n\n        assert(!new_patternp);\n        Newx(new_patternp, n, SV*);\n        SAVEFREEPV(new_patternp);\n        pat_count = n;\n\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            new_patternp[n] = cSVOPx_sv(expr);\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    new_patternp[n++] = cSVOPo_sv;\n            }\n\n    }\n\n    DEBUG_PARSE_r(Perl_re_printf( aTHX_\n        \"Assembling pattern from %d elements%s\\n\", pat_count,\n            orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n    /* set expr to the first arg op */\n\n    if (pRExC_state->code_blocks && pRExC_state->code_blocks->count\n         && expr->op_type != OP_CONST)\n    {\n            expr = cLISTOPx(expr)->op_first;\n            assert(   expr->op_type == OP_PUSHMARK\n                   || (expr->op_type == OP_NULL && expr->op_targ == OP_PUSHMARK)\n                   || expr->op_type == OP_PADRANGE);\n            expr = OpSIBLING(expr);\n    }\n\n    pat = S_concat_pat(aTHX_ pRExC_state, NULL, new_patternp, pat_count,\n                        expr, &recompile, NULL);\n\n    /* handle bare (possibly after overloading) regex: foo =~ $re */\n    {\n        SV *re = pat;\n        if (SvROK(re))\n            re = SvRV(re);\n        if (SvTYPE(re) == SVt_REGEXP) {\n            if (is_bare_re)\n                *is_bare_re = TRUE;\n            SvREFCNT_inc(re);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_\n                \"Precompiled pattern%s\\n\",\n                    orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n            return (REGEXP*)re;\n        }\n    }\n\n    exp = SvPV_nomg(pat, plen);\n\n    if (!eng->op_comp) {\n\tif ((SvUTF8(pat) && IN_BYTES)\n\t\t|| SvGMAGICAL(pat) || SvAMAGIC(pat))\n\t{\n\t    /* make a temporary copy; either to convert to bytes,\n\t     * or to avoid repeating get-magic / overloaded stringify */\n\t    pat = newSVpvn_flags(exp, plen, SVs_TEMP |\n\t\t\t\t\t(IN_BYTES ? 0 : SvUTF8(pat)));\n\t}\n\treturn CALLREGCOMP_ENG(eng, pat, orig_rx_flags);\n    }\n\n    /* ignore the utf8ness if the pattern is 0 length */\n    RExC_utf8 = RExC_orig_utf8 = (plen == 0 || IN_BYTES) ? 0 : SvUTF8(pat);\n    RExC_uni_semantics = 0;\n    RExC_contains_locale = 0;\n    RExC_strict = cBOOL(pm_flags & RXf_PMf_STRICT);\n    RExC_in_script_run = 0;\n    RExC_study_started = 0;\n    pRExC_state->runtime_code_qr = NULL;\n    RExC_frame_head= NULL;\n    RExC_frame_last= NULL;\n    RExC_frame_count= 0;\n    RExC_latest_warn_offset = 0;\n    RExC_use_BRANCHJ = 0;\n    RExC_total_parens = 0;\n    RExC_open_parens = NULL;\n    RExC_close_parens = NULL;\n    RExC_paren_names = NULL;\n    RExC_size = 0;\n    RExC_seen_d_op = FALSE;\n#ifdef DEBUGGING\n    RExC_paren_name_list = NULL;\n#endif\n\n    DEBUG_r({\n        RExC_mysv1= sv_newmortal();\n        RExC_mysv2= sv_newmortal();\n    });\n\n    DEBUG_COMPILE_r({\n            SV *dsv= sv_newmortal();\n            RE_PV_QUOTED_DECL(s, RExC_utf8, dsv, exp, plen, PL_dump_re_max_len);\n            Perl_re_printf( aTHX_  \"%sCompiling REx%s %s\\n\",\n                          PL_colors[4], PL_colors[5], s);\n        });\n\n    /* we jump here if we have to recompile, e.g., from upgrading the pattern\n     * to utf8 */\n\n    if ((pm_flags & PMf_USE_RE_EVAL)\n\t\t/* this second condition covers the non-regex literal case,\n\t\t * i.e.  $foo =~ '(?{})'. */\n\t\t|| (IN_PERL_COMPILETIME && (PL_hints & HINT_RE_EVAL))\n    )\n\truntime_code = S_has_runtime_code(aTHX_ pRExC_state, exp, plen);\n\n  redo_parse:\n    /* return old regex if pattern hasn't changed */\n    /* XXX: note in the below we have to check the flags as well as the\n     * pattern.\n     *\n     * Things get a touch tricky as we have to compare the utf8 flag\n     * independently from the compile flags.  */\n\n    if (   old_re\n        && !recompile\n        && !!RX_UTF8(old_re) == !!RExC_utf8\n        && ( RX_COMPFLAGS(old_re) == ( orig_rx_flags & RXf_PMf_FLAGCOPYMASK ) )\n\t&& RX_PRECOMP(old_re)\n\t&& RX_PRELEN(old_re) == plen\n        && memEQ(RX_PRECOMP(old_re), exp, plen)\n\t&& !runtime_code /* with runtime code, always recompile */ )\n    {\n        return old_re;\n    }\n\n    /* Allocate the pattern's SV */\n    RExC_rx_sv = Rx = (REGEXP*) newSV_type(SVt_REGEXP);\n    RExC_rx = ReANY(Rx);\n    if ( RExC_rx == NULL )\n        FAIL(\"Regexp out of space\");\n\n    rx_flags = orig_rx_flags;\n\n    if (   (UTF || RExC_uni_semantics)\n        && initial_charset == REGEX_DEPENDS_CHARSET)\n    {\n\n\t/* Set to use unicode semantics if the pattern is in utf8 and has the\n\t * 'depends' charset specified, as it means unicode when utf8  */\n\tset_regex_charset(&rx_flags, REGEX_UNICODE_CHARSET);\n        RExC_uni_semantics = 1;\n    }\n\n    RExC_pm_flags = pm_flags;\n\n    if (runtime_code) {\n        assert(TAINTING_get || !TAINT_get);\n\tif (TAINT_get)\n\t    Perl_croak(aTHX_ \"Eval-group in insecure regular expression\");\n\n\tif (!S_compile_runtime_code(aTHX_ pRExC_state, exp, plen)) {\n\t    /* whoops, we have a non-utf8 pattern, whilst run-time code\n\t     * got compiled as utf8. Try again with a utf8 pattern */\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n                pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            goto redo_parse;\n\t}\n    }\n    assert(!pRExC_state->runtime_code_qr);\n\n    RExC_sawback = 0;\n\n    RExC_seen = 0;\n    RExC_maxlen = 0;\n    RExC_in_lookbehind = 0;\n    RExC_seen_zerolen = *exp == '^' ? -1 : 0;\n#ifdef EBCDIC\n    RExC_recode_x_to_native = 0;\n#endif\n    RExC_in_multi_char_class = 0;\n\n    RExC_start = RExC_copy_start_in_constructed = RExC_copy_start_in_input = RExC_precomp = exp;\n    RExC_precomp_end = RExC_end = exp + plen;\n    RExC_nestroot = 0;\n    RExC_whilem_seen = 0;\n    RExC_end_op = NULL;\n    RExC_recurse = NULL;\n    RExC_study_chunk_recursed = NULL;\n    RExC_study_chunk_recursed_bytes= 0;\n    RExC_recurse_count = 0;\n    pRExC_state->code_index = 0;\n\n    /* Initialize the string in the compiled pattern.  This is so that there is\n     * something to output if necessary */\n    set_regex_pv(pRExC_state, Rx);\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Starting parse and generation\\n\");\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n    /* Allocate space and zero-initialize. Note, the two step process\n       of zeroing when in debug mode, thus anything assigned has to\n       happen after that */\n    if (!  RExC_size) {\n\n        /* On the first pass of the parse, we guess how big this will be.  Then\n         * we grow in one operation to that amount and then give it back.  As\n         * we go along, we re-allocate what we need.\n         *\n         * XXX Currently the guess is essentially that the pattern will be an\n         * EXACT node with one byte input, one byte output.  This is crude, and\n         * better heuristics are welcome.\n         *\n         * On any subsequent passes, we guess what we actually computed in the\n         * latest earlier pass.  Such a pass probably didn't complete so is\n         * missing stuff.  We could improve those guesses by knowing where the\n         * parse stopped, and use the length so far plus apply the above\n         * assumption to what's left. */\n        RExC_size = STR_SZ(RExC_end - RExC_start);\n    }\n\n    Newxc(RExC_rxi, sizeof(regexp_internal) + RExC_size, char, regexp_internal);\n    if ( RExC_rxi == NULL )\n        FAIL(\"Regexp out of space\");\n\n    Zero(RExC_rxi, sizeof(regexp_internal) + RExC_size, char);\n    RXi_SET( RExC_rx, RExC_rxi );\n\n    /* We start from 0 (over from 0 in the case this is a reparse.  The first\n     * node parsed will give back any excess memory we have allocated so far).\n     * */\n    RExC_size = 0;\n\n    /* non-zero initialization begins here */\n    RExC_rx->engine= eng;\n    RExC_rx->extflags = rx_flags;\n    RXp_COMPFLAGS(RExC_rx) = orig_rx_flags & RXf_PMf_FLAGCOPYMASK;\n\n    if (pm_flags & PMf_IS_QR) {\n\tRExC_rxi->code_blocks = pRExC_state->code_blocks;\n        if (RExC_rxi->code_blocks) {\n            RExC_rxi->code_blocks->refcnt++;\n        }\n    }\n\n    RExC_rx->intflags = 0;\n\n    RExC_flags = rx_flags;\t/* don't let top level (?i) bleed */\n    RExC_parse = exp;\n\n    /* This NUL is guaranteed because the pattern comes from an SV*, and the sv\n     * code makes sure the final byte is an uncounted NUL.  But should this\n     * ever not be the case, lots of things could read beyond the end of the\n     * buffer: loops like\n     *      while(isFOO(*RExC_parse)) RExC_parse++;\n     *      strchr(RExC_parse, \"foo\");\n     * etc.  So it is worth noting. */\n    assert(*RExC_end == '\\0');\n\n    RExC_naughty = 0;\n    RExC_npar = 1;\n    RExC_parens_buf_size = 0;\n    RExC_emit_start = RExC_rxi->program;\n    pRExC_state->code_index = 0;\n\n    *((char*) RExC_emit_start) = (char) REG_MAGIC;\n    RExC_emit = 1;\n\n    /* Do the parse */\n    if (reg(pRExC_state, 0, &flags, 1)) {\n\n        /* Success!, But we may need to redo the parse knowing how many parens\n         * there actually are */\n        if (IN_PARENS_PASS) {\n            flags |= RESTART_PARSE;\n        }\n\n        /* We have that number in RExC_npar */\n        RExC_total_parens = RExC_npar;\n    }\n    else if (! MUST_RESTART(flags)) {\n\tReREFCNT_dec(Rx);\n        Perl_croak(aTHX_ \"panic: reg returned failure to re_op_compile, flags=%#\" UVxf, (UV) flags);\n    }\n\n    /* Here, we either have success, or we have to redo the parse for some reason */\n    if (MUST_RESTART(flags)) {\n\n        /* It's possible to write a regexp in ascii that represents Unicode\n        codepoints outside of the byte range, such as via \\x{100}. If we\n        detect such a sequence we have to convert the entire pattern to utf8\n        and then recompile, as our sizing calculation will have been based\n        on 1 byte == 1 character, but we will need to use utf8 to encode\n        at least some part of the pattern, and therefore must convert the whole\n        thing.\n        -- dmq */\n        if (flags & NEED_UTF8) {\n\n            /* We have stored the offset of the final warning output so far.\n             * That must be adjusted.  Any variant characters between the start\n             * of the pattern and this warning count for 2 bytes in the final,\n             * so just add them again */\n            if (UNLIKELY(RExC_latest_warn_offset > 0)) {\n                RExC_latest_warn_offset +=\n                            variant_under_utf8_count((U8 *) exp, (U8 *) exp\n                                                + RExC_latest_warn_offset);\n            }\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n            pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse after upgrade\\n\"));\n        }\n        else {\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse\\n\"));\n        }\n\n        if (ALL_PARENS_COUNTED) {\n            /* Make enough room for all the known parens, and zero it */\n            Renew(RExC_open_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_open_parens, RExC_total_parens, regnode_offset);\n            RExC_open_parens[0] = 1;    /* +1 for REG_MAGIC */\n\n            Renew(RExC_close_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_close_parens, RExC_total_parens, regnode_offset);\n        }\n        else { /* Parse did not complete.  Reinitialize the parentheses\n                  structures */\n            RExC_total_parens = 0;\n            if (RExC_open_parens) {\n                Safefree(RExC_open_parens);\n                RExC_open_parens = NULL;\n            }\n            if (RExC_close_parens) {\n                Safefree(RExC_close_parens);\n                RExC_close_parens = NULL;\n            }\n        }\n\n        /* Clean up what we did in this parse */\n        SvREFCNT_dec_NN(RExC_rx_sv);\n\n        goto redo_parse;\n    }\n\n    /* Here, we have successfully parsed and generated the pattern's program\n     * for the regex engine.  We are ready to finish things up and look for\n     * optimizations. */\n\n    /* Update the string to compile, with correct modifiers, etc */\n    set_regex_pv(pRExC_state, Rx);\n\n    RExC_rx->nparens = RExC_total_parens - 1;\n\n    /* Uses the upper 4 bits of the FLAGS field, so keep within that size */\n    if (RExC_whilem_seen > 15)\n        RExC_whilem_seen = 15;\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Required size %\" IVdf \" nodes\\n\", (IV)RExC_size);\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n#ifdef RE_TRACK_PATTERN_OFFSETS\n    DEBUG_OFFSETS_r(Perl_re_printf( aTHX_\n                          \"%s %\" UVuf \" bytes for offset annotations.\\n\",\n                          RExC_offsets ? \"Got\" : \"Couldn't get\",\n                          (UV)((RExC_offsets[0] * 2 + 1))));\n    DEBUG_OFFSETS_r(if (RExC_offsets) {\n        const STRLEN len = RExC_offsets[0];\n        STRLEN i;\n        GET_RE_DEBUG_FLAGS_DECL;\n        Perl_re_printf( aTHX_\n                      \"Offsets: [%\" UVuf \"]\\n\\t\", (UV)RExC_offsets[0]);\n        for (i = 1; i <= len; i++) {\n            if (RExC_offsets[i*2-1] || RExC_offsets[i*2])\n                Perl_re_printf( aTHX_  \"%\" UVuf \":%\" UVuf \"[%\" UVuf \"] \",\n                (UV)i, (UV)RExC_offsets[i*2-1], (UV)RExC_offsets[i*2]);\n        }\n        Perl_re_printf( aTHX_  \"\\n\");\n    });\n\n#else\n    SetProgLen(RExC_rxi,RExC_size);\n#endif\n\n    DEBUG_OPTIMISE_r(\n        Perl_re_printf( aTHX_  \"Starting post parse optimization\\n\");\n    );\n\n    /* XXXX To minimize changes to RE engine we always allocate\n       3-units-long substrs field. */\n    Newx(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_recurse_count) {\n        Newx(RExC_recurse, RExC_recurse_count, regnode *);\n        SAVEFREEPV(RExC_recurse);\n    }\n\n    if (RExC_seen & REG_RECURSE_SEEN) {\n        /* Note, RExC_total_parens is 1 + the number of parens in a pattern.\n         * So its 1 if there are no parens. */\n        RExC_study_chunk_recursed_bytes= (RExC_total_parens >> 3) +\n                                         ((RExC_total_parens & 0x07) != 0);\n        Newx(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n        SAVEFREEPV(RExC_study_chunk_recursed);\n    }\n\n  reStudy:\n    RExC_rx->minlen = minlen = sawlookahead = sawplus = sawopen = sawminmod = 0;\n    DEBUG_r(\n        RExC_study_chunk_recursed_count= 0;\n    );\n    Zero(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_study_chunk_recursed) {\n        Zero(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n    }\n\n\n#ifdef TRIE_STUDY_OPT\n    if (!restudied) {\n        StructCopy(&zero_scan_data, &data, scan_data_t);\n        copyRExC_state = RExC_state;\n    } else {\n        U32 seen=RExC_seen;\n        DEBUG_OPTIMISE_r(Perl_re_printf( aTHX_ \"Restudying\\n\"));\n\n        RExC_state = copyRExC_state;\n        if (seen & REG_TOP_LEVEL_BRANCHES_SEEN)\n            RExC_seen |= REG_TOP_LEVEL_BRANCHES_SEEN;\n        else\n            RExC_seen &= ~REG_TOP_LEVEL_BRANCHES_SEEN;\n\tStructCopy(&zero_scan_data, &data, scan_data_t);\n    }\n#else\n    StructCopy(&zero_scan_data, &data, scan_data_t);\n#endif\n\n    /* Dig out information for optimizations. */\n    RExC_rx->extflags = RExC_flags; /* was pm_op */\n    /*dmq: removed as part of de-PMOP: pm->op_pmflags = RExC_flags; */\n\n    if (UTF)\n\tSvUTF8_on(Rx);\t/* Unicode in it? */\n    RExC_rxi->regstclass = NULL;\n    if (RExC_naughty >= TOO_NAUGHTY)\t/* Probably an expensive pattern. */\n\tRExC_rx->intflags |= PREGf_NAUGHTY;\n    scan = RExC_rxi->program + 1;\t\t/* First BRANCH. */\n\n    /* testing for BRANCH here tells us whether there is \"must appear\"\n       data in the pattern. If there is then we can use it for optimisations */\n    if (!(RExC_seen & REG_TOP_LEVEL_BRANCHES_SEEN)) { /*  Only one top-level choice.\n                                                  */\n\tSSize_t fake;\n\tSTRLEN longest_length[2];\n\tregnode_ssc ch_class; /* pointed to by data */\n\tint stclass_flag;\n\tSSize_t last_close = 0; /* pointed to by data */\n        regnode *first= scan;\n        regnode *first_next= regnext(first);\n        int i;\n\n\t/*\n\t * Skip introductions and multiplicators >= 1\n\t * so that we can extract the 'meat' of the pattern that must\n\t * match in the large if() sequence following.\n\t * NOTE that EXACT is NOT covered here, as it is normally\n\t * picked up by the optimiser separately.\n\t *\n\t * This is unfortunate as the optimiser isnt handling lookahead\n\t * properly currently.\n\t *\n\t */\n\twhile ((OP(first) == OPEN && (sawopen = 1)) ||\n\t       /* An OR of *one* alternative - should not happen now. */\n\t    (OP(first) == BRANCH && OP(first_next) != BRANCH) ||\n\t    /* for now we can't handle lookbehind IFMATCH*/\n\t    (OP(first) == IFMATCH && !first->flags && (sawlookahead = 1)) ||\n\t    (OP(first) == PLUS) ||\n\t    (OP(first) == MINMOD) ||\n\t       /* An {n,m} with n>0 */\n\t    (PL_regkind[OP(first)] == CURLY && ARG1(first) > 0) ||\n\t    (OP(first) == NOTHING && PL_regkind[OP(first_next)] != END ))\n\t{\n\t\t/*\n\t\t * the only op that could be a regnode is PLUS, all the rest\n\t\t * will be regnode_1 or regnode_2.\n\t\t *\n                 * (yves doesn't think this is true)\n\t\t */\n\t\tif (OP(first) == PLUS)\n\t\t    sawplus = 1;\n                else {\n                    if (OP(first) == MINMOD)\n                        sawminmod = 1;\n\t\t    first += regarglen[OP(first)];\n                }\n\t\tfirst = NEXTOPER(first);\n\t\tfirst_next= regnext(first);\n\t}\n\n\t/* Starting-point info. */\n      again:\n        DEBUG_PEEP(\"first:\", first, 0, 0);\n        /* Ignore EXACT as we deal with it later. */\n\tif (PL_regkind[OP(first)] == EXACT) {\n\t    if (   OP(first) == EXACT\n                || OP(first) == EXACT_ONLY8\n                || OP(first) == EXACTL)\n            {\n\t\tNOOP;\t/* Empty, get anchored substr later. */\n            }\n\t    else\n\t\tRExC_rxi->regstclass = first;\n\t}\n#ifdef TRIE_STCLASS\n\telse if (PL_regkind[OP(first)] == TRIE &&\n\t        ((reg_trie_data *)RExC_rxi->data->data[ ARG(first) ])->minlen>0)\n\t{\n            /* this can happen only on restudy */\n            RExC_rxi->regstclass = construct_ahocorasick_from_trie(pRExC_state, (regnode *)first, 0);\n\t}\n#endif\n\telse if (REGNODE_SIMPLE(OP(first)))\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOUND ||\n\t\t PL_regkind[OP(first)] == NBOUND)\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOL) {\n            RExC_rx->intflags |= (OP(first) == MBOL\n                           ? PREGf_ANCH_MBOL\n                           : PREGf_ANCH_SBOL);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if (OP(first) == GPOS) {\n            RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if ((!sawopen || !RExC_sawback) &&\n            !sawlookahead &&\n\t    (OP(first) == STAR &&\n\t    PL_regkind[OP(NEXTOPER(first))] == REG_ANY) &&\n            !(RExC_rx->intflags & PREGf_ANCH) && !pRExC_state->code_blocks)\n\t{\n\t    /* turn .* into ^.* with an implied $*=1 */\n\t    const int type =\n\t\t(OP(NEXTOPER(first)) == REG_ANY)\n                    ? PREGf_ANCH_MBOL\n                    : PREGf_ANCH_SBOL;\n            RExC_rx->intflags |= (type | PREGf_IMPLICIT);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n        if (sawplus && !sawminmod && !sawlookahead\n            && (!sawopen || !RExC_sawback)\n\t    && !pRExC_state->code_blocks) /* May examine pos and $& */\n\t    /* x+ must match at the 1st pos of run of x's */\n\t    RExC_rx->intflags |= PREGf_SKIP;\n\n\t/* Scan is after the zeroth branch, first is atomic matcher. */\n#ifdef TRIE_STUDY_OPT\n\tDEBUG_PARSE_r(\n\t    if (!restudied)\n                Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t\t\t      (IV)(first - scan + 1))\n        );\n#else\n\tDEBUG_PARSE_r(\n            Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t        (IV)(first - scan + 1))\n        );\n#endif\n\n\n\t/*\n\t* If there's something expensive in the r.e., find the\n\t* longest literal string that must appear and make it the\n\t* regmust.  Resolve ties in favor of later strings, since\n\t* the regstart check works with the beginning of the r.e.\n\t* and avoiding duplication strengthens checking.  Not a\n\t* strong reason, but sufficient in the absence of others.\n\t* [Now we resolve ties in favor of the earlier string if\n\t* it happens that c_offset_min has been invalidated, since the\n\t* earlier string may buy us something the later one won't.]\n\t*/\n\n\tdata.substrs[0].str = newSVpvs(\"\");\n\tdata.substrs[1].str = newSVpvs(\"\");\n\tdata.last_found = newSVpvs(\"\");\n\tdata.cur_is_floating = 0; /* initially any found substring is fixed */\n\tENTER_with_name(\"study_chunk\");\n\tSAVEFREESV(data.substrs[0].str);\n\tSAVEFREESV(data.substrs[1].str);\n\tSAVEFREESV(data.last_found);\n\tfirst = scan;\n\tif (!RExC_rxi->regstclass) {\n\t    ssc_init(pRExC_state, &ch_class);\n\t    data.start_class = &ch_class;\n\t    stclass_flag = SCF_DO_STCLASS_AND;\n\t} else\t\t\t\t/* XXXX Check for BOUND? */\n\t    stclass_flag = 0;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/PATTERN/\n         * (NO top level branches)\n         */\n\tminlen = study_chunk(pRExC_state, &first, &minlen, &fake,\n                             scan + RExC_size, /* Up to end */\n            &data, -1, 0, NULL,\n            SCF_DO_SUBSTR | SCF_WHILEM_VISITED_POS | stclass_flag\n                          | (restudied ? SCF_TRIE_DOING_RESTUDY : 0),\n            0);\n\n\n        CHECK_RESTUDY_GOTO_butfirst(LEAVE_with_name(\"study_chunk\"));\n\n\n\tif ( RExC_total_parens == 1 && !data.cur_is_floating\n\t     && data.last_start_min == 0 && data.last_end > 0\n\t     && !RExC_seen_zerolen\n             && !(RExC_seen & REG_VERBARG_SEEN)\n             && !(RExC_seen & REG_GPOS_SEEN)\n        ){\n\t    RExC_rx->extflags |= RXf_CHECK_ALL;\n        }\n\tscan_commit(pRExC_state, &data,&minlen, 0);\n\n\n        /* XXX this is done in reverse order because that's the way the\n         * code was before it was parameterised. Don't know whether it\n         * actually needs doing in reverse order. DAPM */\n        for (i = 1; i >= 0; i--) {\n            longest_length[i] = CHR_SVLEN(data.substrs[i].str);\n\n            if (   !(   i\n                     && SvCUR(data.substrs[0].str)  /* ok to leave SvCUR */\n                     &&    data.substrs[0].min_offset\n                        == data.substrs[1].min_offset\n                     &&    SvCUR(data.substrs[0].str)\n                        == SvCUR(data.substrs[1].str)\n                    )\n                && S_setup_longest (aTHX_ pRExC_state,\n                                        &(RExC_rx->substrs->data[i]),\n                                        &(data.substrs[i]),\n                                        longest_length[i]))\n            {\n                RExC_rx->substrs->data[i].min_offset =\n                        data.substrs[i].min_offset - data.substrs[i].lookbehind;\n\n                RExC_rx->substrs->data[i].max_offset = data.substrs[i].max_offset;\n                /* Don't offset infinity */\n                if (data.substrs[i].max_offset < SSize_t_MAX)\n                    RExC_rx->substrs->data[i].max_offset -= data.substrs[i].lookbehind;\n                SvREFCNT_inc_simple_void_NN(data.substrs[i].str);\n            }\n            else {\n                RExC_rx->substrs->data[i].substr      = NULL;\n                RExC_rx->substrs->data[i].utf8_substr = NULL;\n                longest_length[i] = 0;\n            }\n        }\n\n\tLEAVE_with_name(\"study_chunk\");\n\n\tif (RExC_rxi->regstclass\n\t    && (OP(RExC_rxi->regstclass) == REG_ANY || OP(RExC_rxi->regstclass) == SANY))\n\t    RExC_rxi->regstclass = NULL;\n\n\tif ((!(RExC_rx->substrs->data[0].substr || RExC_rx->substrs->data[0].utf8_substr)\n              || RExC_rx->substrs->data[0].min_offset)\n\t    && stclass_flag\n            && ! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n\t{\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV *sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n\n        /* A temporary algorithm prefers floated substr to fixed one of\n         * same length to dig more info. */\n\ti = (longest_length[0] <= longest_length[1]);\n        RExC_rx->substrs->check_ix = i;\n        RExC_rx->check_end_shift  = RExC_rx->substrs->data[i].end_shift;\n        RExC_rx->check_substr     = RExC_rx->substrs->data[i].substr;\n        RExC_rx->check_utf8       = RExC_rx->substrs->data[i].utf8_substr;\n        RExC_rx->check_offset_min = RExC_rx->substrs->data[i].min_offset;\n        RExC_rx->check_offset_max = RExC_rx->substrs->data[i].max_offset;\n        if (!i && (RExC_rx->intflags & (PREGf_ANCH_SBOL|PREGf_ANCH_GPOS)))\n            RExC_rx->intflags |= PREGf_NOSCAN;\n\n\tif ((RExC_rx->check_substr || RExC_rx->check_utf8) ) {\n\t    RExC_rx->extflags |= RXf_USE_INTUIT;\n\t    if (SvTAIL(RExC_rx->check_substr ? RExC_rx->check_substr : RExC_rx->check_utf8))\n\t\tRExC_rx->extflags |= RXf_INTUIT_TAIL;\n\t}\n\n\t/* XXX Unneeded? dmq (shouldn't as this is handled elsewhere)\n\tif ( (STRLEN)minlen < longest_length[1] )\n            minlen= longest_length[1];\n        if ( (STRLEN)minlen < longest_length[0] )\n            minlen= longest_length[0];\n        */\n    }\n    else {\n\t/* Several toplevels. Best we can is to set minlen. */\n\tSSize_t fake;\n\tregnode_ssc ch_class;\n\tSSize_t last_close = 0;\n\n        DEBUG_PARSE_r(Perl_re_printf( aTHX_  \"\\nMulti Top Level\\n\"));\n\n\tscan = RExC_rxi->program + 1;\n\tssc_init(pRExC_state, &ch_class);\n\tdata.start_class = &ch_class;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/P1|P2|.../\n         * (patterns WITH top level branches)\n         */\n\tminlen = study_chunk(pRExC_state,\n            &scan, &minlen, &fake, scan + RExC_size, &data, -1, 0, NULL,\n            SCF_DO_STCLASS_AND|SCF_WHILEM_VISITED_POS|(restudied\n                                                      ? SCF_TRIE_DOING_RESTUDY\n                                                      : 0),\n            0);\n\n        CHECK_RESTUDY_GOTO_butfirst(NOOP);\n\n\tRExC_rx->check_substr = NULL;\n        RExC_rx->check_utf8 = NULL;\n        RExC_rx->substrs->data[0].substr      = NULL;\n        RExC_rx->substrs->data[0].utf8_substr = NULL;\n        RExC_rx->substrs->data[1].substr      = NULL;\n        RExC_rx->substrs->data[1].utf8_substr = NULL;\n\n        if (! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n        {\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV* sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n    }\n\n    if (RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN) {\n        RExC_rx->extflags |= RXf_UNBOUNDED_QUANTIFIER_SEEN;\n        RExC_rx->maxlen = REG_INFTY;\n    }\n    else {\n        RExC_rx->maxlen = RExC_maxlen;\n    }\n\n    /* Guard against an embedded (?=) or (?<=) with a longer minlen than\n       the \"real\" pattern. */\n    DEBUG_OPTIMISE_r({\n        Perl_re_printf( aTHX_ \"minlen: %\" IVdf \" RExC_rx->minlen:%\" IVdf \" maxlen:%\" IVdf \"\\n\",\n                      (IV)minlen, (IV)RExC_rx->minlen, (IV)RExC_maxlen);\n    });\n    RExC_rx->minlenret = minlen;\n    if (RExC_rx->minlen < minlen)\n        RExC_rx->minlen = minlen;\n\n    if (RExC_seen & REG_RECURSE_SEEN ) {\n        RExC_rx->intflags |= PREGf_RECURSE_SEEN;\n        Newx(RExC_rx->recurse_locinput, RExC_rx->nparens + 1, char *);\n    }\n    if (RExC_seen & REG_GPOS_SEEN)\n        RExC_rx->intflags |= PREGf_GPOS_SEEN;\n    if (RExC_seen & REG_LOOKBEHIND_SEEN)\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* inplace might break the\n                                                lookbehind */\n    if (pRExC_state->code_blocks)\n\tRExC_rx->extflags |= RXf_EVAL_SEEN;\n    if (RExC_seen & REG_VERBARG_SEEN)\n    {\n\tRExC_rx->intflags |= PREGf_VERBARG_SEEN;\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* don't understand this! Yves */\n    }\n    if (RExC_seen & REG_CUTGROUP_SEEN)\n\tRExC_rx->intflags |= PREGf_CUTGROUP_SEEN;\n    if (pm_flags & PMf_USE_RE_EVAL)\n\tRExC_rx->intflags |= PREGf_USE_RE_EVAL;\n    if (RExC_paren_names)\n        RXp_PAREN_NAMES(RExC_rx) = MUTABLE_HV(SvREFCNT_inc(RExC_paren_names));\n    else\n        RXp_PAREN_NAMES(RExC_rx) = NULL;\n\n    /* If we have seen an anchor in our pattern then we set the extflag RXf_IS_ANCHORED\n     * so it can be used in pp.c */\n    if (RExC_rx->intflags & PREGf_ANCH)\n        RExC_rx->extflags |= RXf_IS_ANCHORED;\n\n\n    {\n        /* this is used to identify \"special\" patterns that might result\n         * in Perl NOT calling the regex engine and instead doing the match \"itself\",\n         * particularly special cases in split//. By having the regex compiler\n         * do this pattern matching at a regop level (instead of by inspecting the pattern)\n         * we avoid weird issues with equivalent patterns resulting in different behavior,\n         * AND we allow non Perl engines to get the same optimizations by the setting the\n         * flags appropriately - Yves */\n        regnode *first = RExC_rxi->program + 1;\n        U8 fop = OP(first);\n        regnode *next = regnext(first);\n        U8 nop = OP(next);\n\n        if (PL_regkind[fop] == NOTHING && nop == END)\n            RExC_rx->extflags |= RXf_NULL;\n        else if ((fop == MBOL || (fop == SBOL && !first->flags)) && nop == END)\n            /* when fop is SBOL first->flags will be true only when it was\n             * produced by parsing /\\A/, and not when parsing /^/. This is\n             * very important for the split code as there we want to\n             * treat /^/ as /^/m, but we do not want to treat /\\A/ as /^/m.\n             * See rt #122761 for more details. -- Yves */\n            RExC_rx->extflags |= RXf_START_ONLY;\n        else if (fop == PLUS\n                 && PL_regkind[nop] == POSIXD && FLAGS(next) == _CC_SPACE\n                 && nop == END)\n            RExC_rx->extflags |= RXf_WHITE;\n        else if ( RExC_rx->extflags & RXf_SPLIT\n                  && (fop == EXACT || fop == EXACT_ONLY8 || fop == EXACTL)\n                  && STR_LEN(first) == 1\n                  && *(STRING(first)) == ' '\n                  && nop == END )\n            RExC_rx->extflags |= (RXf_SKIPWHITE|RXf_WHITE);\n\n    }\n\n    if (RExC_contains_locale) {\n        RXp_EXTFLAGS(RExC_rx) |= RXf_TAINTED;\n    }\n\n#ifdef DEBUGGING\n    if (RExC_paren_names) {\n        RExC_rxi->name_list_idx = add_data( pRExC_state, STR_WITH_LEN(\"a\"));\n        RExC_rxi->data->data[RExC_rxi->name_list_idx]\n                                   = (void*)SvREFCNT_inc(RExC_paren_name_list);\n    } else\n#endif\n    RExC_rxi->name_list_idx = 0;\n\n    while ( RExC_recurse_count > 0 ) {\n        const regnode *scan = RExC_recurse[ --RExC_recurse_count ];\n        /*\n         * This data structure is set up in study_chunk() and is used\n         * to calculate the distance between a GOSUB regopcode and\n         * the OPEN/CURLYM (CURLYM's are special and can act like OPEN's)\n         * it refers to.\n         *\n         * If for some reason someone writes code that optimises\n         * away a GOSUB opcode then the assert should be changed to\n         * an if(scan) to guard the ARG2L_SET() - Yves\n         *\n         */\n        assert(scan && OP(scan) == GOSUB);\n        ARG2L_SET( scan, RExC_open_parens[ARG(scan)] - REGNODE_OFFSET(scan));\n    }\n\n    Newxz(RExC_rx->offs, RExC_total_parens, regexp_paren_pair);\n    /* assume we don't need to swap parens around before we match */\n    DEBUG_TEST_r({\n        Perl_re_printf( aTHX_ \"study_chunk_recursed_count: %lu\\n\",\n            (unsigned long)RExC_study_chunk_recursed_count);\n    });\n    DEBUG_DUMP_r({\n        DEBUG_RExC_seen();\n        Perl_re_printf( aTHX_ \"Final program:\\n\");\n        regdump(RExC_rx);\n    });\n\n    if (RExC_open_parens) {\n        Safefree(RExC_open_parens);\n        RExC_open_parens = NULL;\n    }\n    if (RExC_close_parens) {\n        Safefree(RExC_close_parens);\n        RExC_close_parens = NULL;\n    }\n\n#ifdef USE_ITHREADS\n    /* under ithreads the ?pat? PMf_USED flag on the pmop is simulated\n     * by setting the regexp SV to readonly-only instead. If the\n     * pattern's been recompiled, the USEDness should remain. */\n    if (old_re && SvREADONLY(old_re))\n        SvREADONLY_on(Rx);\n#endif\n    return Rx;", "func_src_after": "REGEXP *\nPerl_re_op_compile(pTHX_ SV ** const patternp, int pat_count,\n\t\t    OP *expr, const regexp_engine* eng, REGEXP *old_re,\n\t\t     bool *is_bare_re, const U32 orig_rx_flags, const U32 pm_flags)\n{\n    dVAR;\n    REGEXP *Rx;         /* Capital 'R' means points to a REGEXP */\n    STRLEN plen;\n    char *exp;\n    regnode *scan;\n    I32 flags;\n    SSize_t minlen = 0;\n    U32 rx_flags;\n    SV *pat;\n    SV** new_patternp = patternp;\n\n    /* these are all flags - maybe they should be turned\n     * into a single int with different bit masks */\n    I32 sawlookahead = 0;\n    I32 sawplus = 0;\n    I32 sawopen = 0;\n    I32 sawminmod = 0;\n\n    regex_charset initial_charset = get_regex_charset(orig_rx_flags);\n    bool recompile = 0;\n    bool runtime_code = 0;\n    scan_data_t data;\n    RExC_state_t RExC_state;\n    RExC_state_t * const pRExC_state = &RExC_state;\n#ifdef TRIE_STUDY_OPT\n    int restudied = 0;\n    RExC_state_t copyRExC_state;\n#endif\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_RE_OP_COMPILE;\n\n    DEBUG_r(if (!PL_colorset) reginitcolors());\n\n    /* Initialize these here instead of as-needed, as is quick and avoids\n     * having to test them each time otherwise */\n    if (! PL_InBitmap) {\n#ifdef DEBUGGING\n        char * dump_len_string;\n#endif\n\n        /* This is calculated here, because the Perl program that generates the\n         * static global ones doesn't currently have access to\n         * NUM_ANYOF_CODE_POINTS */\n\tPL_InBitmap = _new_invlist(2);\n\tPL_InBitmap = _add_range_to_invlist(PL_InBitmap, 0,\n                                                    NUM_ANYOF_CODE_POINTS - 1);\n#ifdef DEBUGGING\n        dump_len_string = PerlEnv_getenv(\"PERL_DUMP_RE_MAX_LEN\");\n        if (   ! dump_len_string\n            || ! grok_atoUV(dump_len_string, (UV *)&PL_dump_re_max_len, NULL))\n        {\n            PL_dump_re_max_len = 60;    /* A reasonable default */\n        }\n#endif\n    }\n\n    pRExC_state->warn_text = NULL;\n    pRExC_state->unlexed_names = NULL;\n    pRExC_state->code_blocks = NULL;\n\n    if (is_bare_re)\n\t*is_bare_re = FALSE;\n\n    if (expr && (expr->op_type == OP_LIST ||\n\t\t(expr->op_type == OP_NULL && expr->op_targ == OP_LIST))) {\n\t/* allocate code_blocks if needed */\n\tOP *o;\n\tint ncode = 0;\n\n\tfor (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o))\n\t    if (o->op_type == OP_NULL && (o->op_flags & OPf_SPECIAL))\n\t\tncode++; /* count of DO blocks */\n\n\tif (ncode)\n            pRExC_state->code_blocks = S_alloc_code_blocks(aTHX_ ncode);\n    }\n\n    if (!pat_count) {\n        /* compile-time pattern with just OP_CONSTs and DO blocks */\n\n        int n;\n        OP *o;\n\n        /* find how many CONSTs there are */\n        assert(expr);\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            n = 1;\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    n++;\n            }\n\n        /* fake up an SV array */\n\n        assert(!new_patternp);\n        Newx(new_patternp, n, SV*);\n        SAVEFREEPV(new_patternp);\n        pat_count = n;\n\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            new_patternp[n] = cSVOPx_sv(expr);\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    new_patternp[n++] = cSVOPo_sv;\n            }\n\n    }\n\n    DEBUG_PARSE_r(Perl_re_printf( aTHX_\n        \"Assembling pattern from %d elements%s\\n\", pat_count,\n            orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n    /* set expr to the first arg op */\n\n    if (pRExC_state->code_blocks && pRExC_state->code_blocks->count\n         && expr->op_type != OP_CONST)\n    {\n            expr = cLISTOPx(expr)->op_first;\n            assert(   expr->op_type == OP_PUSHMARK\n                   || (expr->op_type == OP_NULL && expr->op_targ == OP_PUSHMARK)\n                   || expr->op_type == OP_PADRANGE);\n            expr = OpSIBLING(expr);\n    }\n\n    pat = S_concat_pat(aTHX_ pRExC_state, NULL, new_patternp, pat_count,\n                        expr, &recompile, NULL);\n\n    /* handle bare (possibly after overloading) regex: foo =~ $re */\n    {\n        SV *re = pat;\n        if (SvROK(re))\n            re = SvRV(re);\n        if (SvTYPE(re) == SVt_REGEXP) {\n            if (is_bare_re)\n                *is_bare_re = TRUE;\n            SvREFCNT_inc(re);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_\n                \"Precompiled pattern%s\\n\",\n                    orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n            return (REGEXP*)re;\n        }\n    }\n\n    exp = SvPV_nomg(pat, plen);\n\n    if (!eng->op_comp) {\n\tif ((SvUTF8(pat) && IN_BYTES)\n\t\t|| SvGMAGICAL(pat) || SvAMAGIC(pat))\n\t{\n\t    /* make a temporary copy; either to convert to bytes,\n\t     * or to avoid repeating get-magic / overloaded stringify */\n\t    pat = newSVpvn_flags(exp, plen, SVs_TEMP |\n\t\t\t\t\t(IN_BYTES ? 0 : SvUTF8(pat)));\n\t}\n\treturn CALLREGCOMP_ENG(eng, pat, orig_rx_flags);\n    }\n\n    /* ignore the utf8ness if the pattern is 0 length */\n    RExC_utf8 = RExC_orig_utf8 = (plen == 0 || IN_BYTES) ? 0 : SvUTF8(pat);\n    RExC_uni_semantics = 0;\n    RExC_contains_locale = 0;\n    RExC_strict = cBOOL(pm_flags & RXf_PMf_STRICT);\n    RExC_in_script_run = 0;\n    RExC_study_started = 0;\n    pRExC_state->runtime_code_qr = NULL;\n    RExC_frame_head= NULL;\n    RExC_frame_last= NULL;\n    RExC_frame_count= 0;\n    RExC_latest_warn_offset = 0;\n    RExC_use_BRANCHJ = 0;\n    RExC_total_parens = 0;\n    RExC_open_parens = NULL;\n    RExC_close_parens = NULL;\n    RExC_paren_names = NULL;\n    RExC_size = 0;\n    RExC_seen_d_op = FALSE;\n#ifdef DEBUGGING\n    RExC_paren_name_list = NULL;\n#endif\n\n    DEBUG_r({\n        RExC_mysv1= sv_newmortal();\n        RExC_mysv2= sv_newmortal();\n    });\n\n    DEBUG_COMPILE_r({\n            SV *dsv= sv_newmortal();\n            RE_PV_QUOTED_DECL(s, RExC_utf8, dsv, exp, plen, PL_dump_re_max_len);\n            Perl_re_printf( aTHX_  \"%sCompiling REx%s %s\\n\",\n                          PL_colors[4], PL_colors[5], s);\n        });\n\n    /* we jump here if we have to recompile, e.g., from upgrading the pattern\n     * to utf8 */\n\n    if ((pm_flags & PMf_USE_RE_EVAL)\n\t\t/* this second condition covers the non-regex literal case,\n\t\t * i.e.  $foo =~ '(?{})'. */\n\t\t|| (IN_PERL_COMPILETIME && (PL_hints & HINT_RE_EVAL))\n    )\n\truntime_code = S_has_runtime_code(aTHX_ pRExC_state, exp, plen);\n\n  redo_parse:\n    /* return old regex if pattern hasn't changed */\n    /* XXX: note in the below we have to check the flags as well as the\n     * pattern.\n     *\n     * Things get a touch tricky as we have to compare the utf8 flag\n     * independently from the compile flags.  */\n\n    if (   old_re\n        && !recompile\n        && !!RX_UTF8(old_re) == !!RExC_utf8\n        && ( RX_COMPFLAGS(old_re) == ( orig_rx_flags & RXf_PMf_FLAGCOPYMASK ) )\n\t&& RX_PRECOMP(old_re)\n\t&& RX_PRELEN(old_re) == plen\n        && memEQ(RX_PRECOMP(old_re), exp, plen)\n\t&& !runtime_code /* with runtime code, always recompile */ )\n    {\n        return old_re;\n    }\n\n    /* Allocate the pattern's SV */\n    RExC_rx_sv = Rx = (REGEXP*) newSV_type(SVt_REGEXP);\n    RExC_rx = ReANY(Rx);\n    if ( RExC_rx == NULL )\n        FAIL(\"Regexp out of space\");\n\n    rx_flags = orig_rx_flags;\n\n    if (   (UTF || RExC_uni_semantics)\n        && initial_charset == REGEX_DEPENDS_CHARSET)\n    {\n\n\t/* Set to use unicode semantics if the pattern is in utf8 and has the\n\t * 'depends' charset specified, as it means unicode when utf8  */\n\tset_regex_charset(&rx_flags, REGEX_UNICODE_CHARSET);\n        RExC_uni_semantics = 1;\n    }\n\n    RExC_pm_flags = pm_flags;\n\n    if (runtime_code) {\n        assert(TAINTING_get || !TAINT_get);\n\tif (TAINT_get)\n\t    Perl_croak(aTHX_ \"Eval-group in insecure regular expression\");\n\n\tif (!S_compile_runtime_code(aTHX_ pRExC_state, exp, plen)) {\n\t    /* whoops, we have a non-utf8 pattern, whilst run-time code\n\t     * got compiled as utf8. Try again with a utf8 pattern */\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n                pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            goto redo_parse;\n\t}\n    }\n    assert(!pRExC_state->runtime_code_qr);\n\n    RExC_sawback = 0;\n\n    RExC_seen = 0;\n    RExC_maxlen = 0;\n    RExC_in_lookbehind = 0;\n    RExC_seen_zerolen = *exp == '^' ? -1 : 0;\n#ifdef EBCDIC\n    RExC_recode_x_to_native = 0;\n#endif\n    RExC_in_multi_char_class = 0;\n\n    RExC_start = RExC_copy_start_in_constructed = RExC_copy_start_in_input = RExC_precomp = exp;\n    RExC_precomp_end = RExC_end = exp + plen;\n    RExC_nestroot = 0;\n    RExC_whilem_seen = 0;\n    RExC_end_op = NULL;\n    RExC_recurse = NULL;\n    RExC_study_chunk_recursed = NULL;\n    RExC_study_chunk_recursed_bytes= 0;\n    RExC_recurse_count = 0;\n    pRExC_state->code_index = 0;\n\n    /* Initialize the string in the compiled pattern.  This is so that there is\n     * something to output if necessary */\n    set_regex_pv(pRExC_state, Rx);\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Starting parse and generation\\n\");\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n    /* Allocate space and zero-initialize. Note, the two step process\n       of zeroing when in debug mode, thus anything assigned has to\n       happen after that */\n    if (!  RExC_size) {\n\n        /* On the first pass of the parse, we guess how big this will be.  Then\n         * we grow in one operation to that amount and then give it back.  As\n         * we go along, we re-allocate what we need.\n         *\n         * XXX Currently the guess is essentially that the pattern will be an\n         * EXACT node with one byte input, one byte output.  This is crude, and\n         * better heuristics are welcome.\n         *\n         * On any subsequent passes, we guess what we actually computed in the\n         * latest earlier pass.  Such a pass probably didn't complete so is\n         * missing stuff.  We could improve those guesses by knowing where the\n         * parse stopped, and use the length so far plus apply the above\n         * assumption to what's left. */\n        RExC_size = STR_SZ(RExC_end - RExC_start);\n    }\n\n    Newxc(RExC_rxi, sizeof(regexp_internal) + RExC_size, char, regexp_internal);\n    if ( RExC_rxi == NULL )\n        FAIL(\"Regexp out of space\");\n\n    Zero(RExC_rxi, sizeof(regexp_internal) + RExC_size, char);\n    RXi_SET( RExC_rx, RExC_rxi );\n\n    /* We start from 0 (over from 0 in the case this is a reparse.  The first\n     * node parsed will give back any excess memory we have allocated so far).\n     * */\n    RExC_size = 0;\n\n    /* non-zero initialization begins here */\n    RExC_rx->engine= eng;\n    RExC_rx->extflags = rx_flags;\n    RXp_COMPFLAGS(RExC_rx) = orig_rx_flags & RXf_PMf_FLAGCOPYMASK;\n\n    if (pm_flags & PMf_IS_QR) {\n\tRExC_rxi->code_blocks = pRExC_state->code_blocks;\n        if (RExC_rxi->code_blocks) {\n            RExC_rxi->code_blocks->refcnt++;\n        }\n    }\n\n    RExC_rx->intflags = 0;\n\n    RExC_flags = rx_flags;\t/* don't let top level (?i) bleed */\n    RExC_parse = exp;\n\n    /* This NUL is guaranteed because the pattern comes from an SV*, and the sv\n     * code makes sure the final byte is an uncounted NUL.  But should this\n     * ever not be the case, lots of things could read beyond the end of the\n     * buffer: loops like\n     *      while(isFOO(*RExC_parse)) RExC_parse++;\n     *      strchr(RExC_parse, \"foo\");\n     * etc.  So it is worth noting. */\n    assert(*RExC_end == '\\0');\n\n    RExC_naughty = 0;\n    RExC_npar = 1;\n    RExC_parens_buf_size = 0;\n    RExC_emit_start = RExC_rxi->program;\n    pRExC_state->code_index = 0;\n\n    *((char*) RExC_emit_start) = (char) REG_MAGIC;\n    RExC_emit = 1;\n\n    /* Do the parse */\n    if (reg(pRExC_state, 0, &flags, 1)) {\n\n        /* Success!, But we may need to redo the parse knowing how many parens\n         * there actually are */\n        if (IN_PARENS_PASS) {\n            flags |= RESTART_PARSE;\n        }\n\n        /* We have that number in RExC_npar */\n        RExC_total_parens = RExC_npar;\n\n        /* XXX For backporting, use long jumps if there is any possibility of\n         * overflow */\n        if (RExC_size > U16_MAX && ! RExC_use_BRANCHJ) {\n            RExC_use_BRANCHJ = TRUE;\n            flags |= RESTART_PARSE;\n        }\n    }\n    else if (! MUST_RESTART(flags)) {\n\tReREFCNT_dec(Rx);\n        Perl_croak(aTHX_ \"panic: reg returned failure to re_op_compile, flags=%#\" UVxf, (UV) flags);\n    }\n\n    /* Here, we either have success, or we have to redo the parse for some reason */\n    if (MUST_RESTART(flags)) {\n\n        /* It's possible to write a regexp in ascii that represents Unicode\n        codepoints outside of the byte range, such as via \\x{100}. If we\n        detect such a sequence we have to convert the entire pattern to utf8\n        and then recompile, as our sizing calculation will have been based\n        on 1 byte == 1 character, but we will need to use utf8 to encode\n        at least some part of the pattern, and therefore must convert the whole\n        thing.\n        -- dmq */\n        if (flags & NEED_UTF8) {\n\n            /* We have stored the offset of the final warning output so far.\n             * That must be adjusted.  Any variant characters between the start\n             * of the pattern and this warning count for 2 bytes in the final,\n             * so just add them again */\n            if (UNLIKELY(RExC_latest_warn_offset > 0)) {\n                RExC_latest_warn_offset +=\n                            variant_under_utf8_count((U8 *) exp, (U8 *) exp\n                                                + RExC_latest_warn_offset);\n            }\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n            pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse after upgrade\\n\"));\n        }\n        else {\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse\\n\"));\n        }\n\n        if (ALL_PARENS_COUNTED) {\n            /* Make enough room for all the known parens, and zero it */\n            Renew(RExC_open_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_open_parens, RExC_total_parens, regnode_offset);\n            RExC_open_parens[0] = 1;    /* +1 for REG_MAGIC */\n\n            Renew(RExC_close_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_close_parens, RExC_total_parens, regnode_offset);\n        }\n        else { /* Parse did not complete.  Reinitialize the parentheses\n                  structures */\n            RExC_total_parens = 0;\n            if (RExC_open_parens) {\n                Safefree(RExC_open_parens);\n                RExC_open_parens = NULL;\n            }\n            if (RExC_close_parens) {\n                Safefree(RExC_close_parens);\n                RExC_close_parens = NULL;\n            }\n        }\n\n        /* Clean up what we did in this parse */\n        SvREFCNT_dec_NN(RExC_rx_sv);\n\n        goto redo_parse;\n    }\n\n    /* Here, we have successfully parsed and generated the pattern's program\n     * for the regex engine.  We are ready to finish things up and look for\n     * optimizations. */\n\n    /* Update the string to compile, with correct modifiers, etc */\n    set_regex_pv(pRExC_state, Rx);\n\n    RExC_rx->nparens = RExC_total_parens - 1;\n\n    /* Uses the upper 4 bits of the FLAGS field, so keep within that size */\n    if (RExC_whilem_seen > 15)\n        RExC_whilem_seen = 15;\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Required size %\" IVdf \" nodes\\n\", (IV)RExC_size);\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n#ifdef RE_TRACK_PATTERN_OFFSETS\n    DEBUG_OFFSETS_r(Perl_re_printf( aTHX_\n                          \"%s %\" UVuf \" bytes for offset annotations.\\n\",\n                          RExC_offsets ? \"Got\" : \"Couldn't get\",\n                          (UV)((RExC_offsets[0] * 2 + 1))));\n    DEBUG_OFFSETS_r(if (RExC_offsets) {\n        const STRLEN len = RExC_offsets[0];\n        STRLEN i;\n        GET_RE_DEBUG_FLAGS_DECL;\n        Perl_re_printf( aTHX_\n                      \"Offsets: [%\" UVuf \"]\\n\\t\", (UV)RExC_offsets[0]);\n        for (i = 1; i <= len; i++) {\n            if (RExC_offsets[i*2-1] || RExC_offsets[i*2])\n                Perl_re_printf( aTHX_  \"%\" UVuf \":%\" UVuf \"[%\" UVuf \"] \",\n                (UV)i, (UV)RExC_offsets[i*2-1], (UV)RExC_offsets[i*2]);\n        }\n        Perl_re_printf( aTHX_  \"\\n\");\n    });\n\n#else\n    SetProgLen(RExC_rxi,RExC_size);\n#endif\n\n    DEBUG_OPTIMISE_r(\n        Perl_re_printf( aTHX_  \"Starting post parse optimization\\n\");\n    );\n\n    /* XXXX To minimize changes to RE engine we always allocate\n       3-units-long substrs field. */\n    Newx(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_recurse_count) {\n        Newx(RExC_recurse, RExC_recurse_count, regnode *);\n        SAVEFREEPV(RExC_recurse);\n    }\n\n    if (RExC_seen & REG_RECURSE_SEEN) {\n        /* Note, RExC_total_parens is 1 + the number of parens in a pattern.\n         * So its 1 if there are no parens. */\n        RExC_study_chunk_recursed_bytes= (RExC_total_parens >> 3) +\n                                         ((RExC_total_parens & 0x07) != 0);\n        Newx(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n        SAVEFREEPV(RExC_study_chunk_recursed);\n    }\n\n  reStudy:\n    RExC_rx->minlen = minlen = sawlookahead = sawplus = sawopen = sawminmod = 0;\n    DEBUG_r(\n        RExC_study_chunk_recursed_count= 0;\n    );\n    Zero(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_study_chunk_recursed) {\n        Zero(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n    }\n\n\n#ifdef TRIE_STUDY_OPT\n    if (!restudied) {\n        StructCopy(&zero_scan_data, &data, scan_data_t);\n        copyRExC_state = RExC_state;\n    } else {\n        U32 seen=RExC_seen;\n        DEBUG_OPTIMISE_r(Perl_re_printf( aTHX_ \"Restudying\\n\"));\n\n        RExC_state = copyRExC_state;\n        if (seen & REG_TOP_LEVEL_BRANCHES_SEEN)\n            RExC_seen |= REG_TOP_LEVEL_BRANCHES_SEEN;\n        else\n            RExC_seen &= ~REG_TOP_LEVEL_BRANCHES_SEEN;\n\tStructCopy(&zero_scan_data, &data, scan_data_t);\n    }\n#else\n    StructCopy(&zero_scan_data, &data, scan_data_t);\n#endif\n\n    /* Dig out information for optimizations. */\n    RExC_rx->extflags = RExC_flags; /* was pm_op */\n    /*dmq: removed as part of de-PMOP: pm->op_pmflags = RExC_flags; */\n\n    if (UTF)\n\tSvUTF8_on(Rx);\t/* Unicode in it? */\n    RExC_rxi->regstclass = NULL;\n    if (RExC_naughty >= TOO_NAUGHTY)\t/* Probably an expensive pattern. */\n\tRExC_rx->intflags |= PREGf_NAUGHTY;\n    scan = RExC_rxi->program + 1;\t\t/* First BRANCH. */\n\n    /* testing for BRANCH here tells us whether there is \"must appear\"\n       data in the pattern. If there is then we can use it for optimisations */\n    if (!(RExC_seen & REG_TOP_LEVEL_BRANCHES_SEEN)) { /*  Only one top-level choice.\n                                                  */\n\tSSize_t fake;\n\tSTRLEN longest_length[2];\n\tregnode_ssc ch_class; /* pointed to by data */\n\tint stclass_flag;\n\tSSize_t last_close = 0; /* pointed to by data */\n        regnode *first= scan;\n        regnode *first_next= regnext(first);\n        int i;\n\n\t/*\n\t * Skip introductions and multiplicators >= 1\n\t * so that we can extract the 'meat' of the pattern that must\n\t * match in the large if() sequence following.\n\t * NOTE that EXACT is NOT covered here, as it is normally\n\t * picked up by the optimiser separately.\n\t *\n\t * This is unfortunate as the optimiser isnt handling lookahead\n\t * properly currently.\n\t *\n\t */\n\twhile ((OP(first) == OPEN && (sawopen = 1)) ||\n\t       /* An OR of *one* alternative - should not happen now. */\n\t    (OP(first) == BRANCH && OP(first_next) != BRANCH) ||\n\t    /* for now we can't handle lookbehind IFMATCH*/\n\t    (OP(first) == IFMATCH && !first->flags && (sawlookahead = 1)) ||\n\t    (OP(first) == PLUS) ||\n\t    (OP(first) == MINMOD) ||\n\t       /* An {n,m} with n>0 */\n\t    (PL_regkind[OP(first)] == CURLY && ARG1(first) > 0) ||\n\t    (OP(first) == NOTHING && PL_regkind[OP(first_next)] != END ))\n\t{\n\t\t/*\n\t\t * the only op that could be a regnode is PLUS, all the rest\n\t\t * will be regnode_1 or regnode_2.\n\t\t *\n                 * (yves doesn't think this is true)\n\t\t */\n\t\tif (OP(first) == PLUS)\n\t\t    sawplus = 1;\n                else {\n                    if (OP(first) == MINMOD)\n                        sawminmod = 1;\n\t\t    first += regarglen[OP(first)];\n                }\n\t\tfirst = NEXTOPER(first);\n\t\tfirst_next= regnext(first);\n\t}\n\n\t/* Starting-point info. */\n      again:\n        DEBUG_PEEP(\"first:\", first, 0, 0);\n        /* Ignore EXACT as we deal with it later. */\n\tif (PL_regkind[OP(first)] == EXACT) {\n\t    if (   OP(first) == EXACT\n                || OP(first) == EXACT_ONLY8\n                || OP(first) == EXACTL)\n            {\n\t\tNOOP;\t/* Empty, get anchored substr later. */\n            }\n\t    else\n\t\tRExC_rxi->regstclass = first;\n\t}\n#ifdef TRIE_STCLASS\n\telse if (PL_regkind[OP(first)] == TRIE &&\n\t        ((reg_trie_data *)RExC_rxi->data->data[ ARG(first) ])->minlen>0)\n\t{\n            /* this can happen only on restudy */\n            RExC_rxi->regstclass = construct_ahocorasick_from_trie(pRExC_state, (regnode *)first, 0);\n\t}\n#endif\n\telse if (REGNODE_SIMPLE(OP(first)))\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOUND ||\n\t\t PL_regkind[OP(first)] == NBOUND)\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOL) {\n            RExC_rx->intflags |= (OP(first) == MBOL\n                           ? PREGf_ANCH_MBOL\n                           : PREGf_ANCH_SBOL);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if (OP(first) == GPOS) {\n            RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if ((!sawopen || !RExC_sawback) &&\n            !sawlookahead &&\n\t    (OP(first) == STAR &&\n\t    PL_regkind[OP(NEXTOPER(first))] == REG_ANY) &&\n            !(RExC_rx->intflags & PREGf_ANCH) && !pRExC_state->code_blocks)\n\t{\n\t    /* turn .* into ^.* with an implied $*=1 */\n\t    const int type =\n\t\t(OP(NEXTOPER(first)) == REG_ANY)\n                    ? PREGf_ANCH_MBOL\n                    : PREGf_ANCH_SBOL;\n            RExC_rx->intflags |= (type | PREGf_IMPLICIT);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n        if (sawplus && !sawminmod && !sawlookahead\n            && (!sawopen || !RExC_sawback)\n\t    && !pRExC_state->code_blocks) /* May examine pos and $& */\n\t    /* x+ must match at the 1st pos of run of x's */\n\t    RExC_rx->intflags |= PREGf_SKIP;\n\n\t/* Scan is after the zeroth branch, first is atomic matcher. */\n#ifdef TRIE_STUDY_OPT\n\tDEBUG_PARSE_r(\n\t    if (!restudied)\n                Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t\t\t      (IV)(first - scan + 1))\n        );\n#else\n\tDEBUG_PARSE_r(\n            Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t        (IV)(first - scan + 1))\n        );\n#endif\n\n\n\t/*\n\t* If there's something expensive in the r.e., find the\n\t* longest literal string that must appear and make it the\n\t* regmust.  Resolve ties in favor of later strings, since\n\t* the regstart check works with the beginning of the r.e.\n\t* and avoiding duplication strengthens checking.  Not a\n\t* strong reason, but sufficient in the absence of others.\n\t* [Now we resolve ties in favor of the earlier string if\n\t* it happens that c_offset_min has been invalidated, since the\n\t* earlier string may buy us something the later one won't.]\n\t*/\n\n\tdata.substrs[0].str = newSVpvs(\"\");\n\tdata.substrs[1].str = newSVpvs(\"\");\n\tdata.last_found = newSVpvs(\"\");\n\tdata.cur_is_floating = 0; /* initially any found substring is fixed */\n\tENTER_with_name(\"study_chunk\");\n\tSAVEFREESV(data.substrs[0].str);\n\tSAVEFREESV(data.substrs[1].str);\n\tSAVEFREESV(data.last_found);\n\tfirst = scan;\n\tif (!RExC_rxi->regstclass) {\n\t    ssc_init(pRExC_state, &ch_class);\n\t    data.start_class = &ch_class;\n\t    stclass_flag = SCF_DO_STCLASS_AND;\n\t} else\t\t\t\t/* XXXX Check for BOUND? */\n\t    stclass_flag = 0;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/PATTERN/\n         * (NO top level branches)\n         */\n\tminlen = study_chunk(pRExC_state, &first, &minlen, &fake,\n                             scan + RExC_size, /* Up to end */\n            &data, -1, 0, NULL,\n            SCF_DO_SUBSTR | SCF_WHILEM_VISITED_POS | stclass_flag\n                          | (restudied ? SCF_TRIE_DOING_RESTUDY : 0),\n            0);\n\n\n        CHECK_RESTUDY_GOTO_butfirst(LEAVE_with_name(\"study_chunk\"));\n\n\n\tif ( RExC_total_parens == 1 && !data.cur_is_floating\n\t     && data.last_start_min == 0 && data.last_end > 0\n\t     && !RExC_seen_zerolen\n             && !(RExC_seen & REG_VERBARG_SEEN)\n             && !(RExC_seen & REG_GPOS_SEEN)\n        ){\n\t    RExC_rx->extflags |= RXf_CHECK_ALL;\n        }\n\tscan_commit(pRExC_state, &data,&minlen, 0);\n\n\n        /* XXX this is done in reverse order because that's the way the\n         * code was before it was parameterised. Don't know whether it\n         * actually needs doing in reverse order. DAPM */\n        for (i = 1; i >= 0; i--) {\n            longest_length[i] = CHR_SVLEN(data.substrs[i].str);\n\n            if (   !(   i\n                     && SvCUR(data.substrs[0].str)  /* ok to leave SvCUR */\n                     &&    data.substrs[0].min_offset\n                        == data.substrs[1].min_offset\n                     &&    SvCUR(data.substrs[0].str)\n                        == SvCUR(data.substrs[1].str)\n                    )\n                && S_setup_longest (aTHX_ pRExC_state,\n                                        &(RExC_rx->substrs->data[i]),\n                                        &(data.substrs[i]),\n                                        longest_length[i]))\n            {\n                RExC_rx->substrs->data[i].min_offset =\n                        data.substrs[i].min_offset - data.substrs[i].lookbehind;\n\n                RExC_rx->substrs->data[i].max_offset = data.substrs[i].max_offset;\n                /* Don't offset infinity */\n                if (data.substrs[i].max_offset < SSize_t_MAX)\n                    RExC_rx->substrs->data[i].max_offset -= data.substrs[i].lookbehind;\n                SvREFCNT_inc_simple_void_NN(data.substrs[i].str);\n            }\n            else {\n                RExC_rx->substrs->data[i].substr      = NULL;\n                RExC_rx->substrs->data[i].utf8_substr = NULL;\n                longest_length[i] = 0;\n            }\n        }\n\n\tLEAVE_with_name(\"study_chunk\");\n\n\tif (RExC_rxi->regstclass\n\t    && (OP(RExC_rxi->regstclass) == REG_ANY || OP(RExC_rxi->regstclass) == SANY))\n\t    RExC_rxi->regstclass = NULL;\n\n\tif ((!(RExC_rx->substrs->data[0].substr || RExC_rx->substrs->data[0].utf8_substr)\n              || RExC_rx->substrs->data[0].min_offset)\n\t    && stclass_flag\n            && ! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n\t{\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV *sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n\n        /* A temporary algorithm prefers floated substr to fixed one of\n         * same length to dig more info. */\n\ti = (longest_length[0] <= longest_length[1]);\n        RExC_rx->substrs->check_ix = i;\n        RExC_rx->check_end_shift  = RExC_rx->substrs->data[i].end_shift;\n        RExC_rx->check_substr     = RExC_rx->substrs->data[i].substr;\n        RExC_rx->check_utf8       = RExC_rx->substrs->data[i].utf8_substr;\n        RExC_rx->check_offset_min = RExC_rx->substrs->data[i].min_offset;\n        RExC_rx->check_offset_max = RExC_rx->substrs->data[i].max_offset;\n        if (!i && (RExC_rx->intflags & (PREGf_ANCH_SBOL|PREGf_ANCH_GPOS)))\n            RExC_rx->intflags |= PREGf_NOSCAN;\n\n\tif ((RExC_rx->check_substr || RExC_rx->check_utf8) ) {\n\t    RExC_rx->extflags |= RXf_USE_INTUIT;\n\t    if (SvTAIL(RExC_rx->check_substr ? RExC_rx->check_substr : RExC_rx->check_utf8))\n\t\tRExC_rx->extflags |= RXf_INTUIT_TAIL;\n\t}\n\n\t/* XXX Unneeded? dmq (shouldn't as this is handled elsewhere)\n\tif ( (STRLEN)minlen < longest_length[1] )\n            minlen= longest_length[1];\n        if ( (STRLEN)minlen < longest_length[0] )\n            minlen= longest_length[0];\n        */\n    }\n    else {\n\t/* Several toplevels. Best we can is to set minlen. */\n\tSSize_t fake;\n\tregnode_ssc ch_class;\n\tSSize_t last_close = 0;\n\n        DEBUG_PARSE_r(Perl_re_printf( aTHX_  \"\\nMulti Top Level\\n\"));\n\n\tscan = RExC_rxi->program + 1;\n\tssc_init(pRExC_state, &ch_class);\n\tdata.start_class = &ch_class;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/P1|P2|.../\n         * (patterns WITH top level branches)\n         */\n\tminlen = study_chunk(pRExC_state,\n            &scan, &minlen, &fake, scan + RExC_size, &data, -1, 0, NULL,\n            SCF_DO_STCLASS_AND|SCF_WHILEM_VISITED_POS|(restudied\n                                                      ? SCF_TRIE_DOING_RESTUDY\n                                                      : 0),\n            0);\n\n        CHECK_RESTUDY_GOTO_butfirst(NOOP);\n\n\tRExC_rx->check_substr = NULL;\n        RExC_rx->check_utf8 = NULL;\n        RExC_rx->substrs->data[0].substr      = NULL;\n        RExC_rx->substrs->data[0].utf8_substr = NULL;\n        RExC_rx->substrs->data[1].substr      = NULL;\n        RExC_rx->substrs->data[1].utf8_substr = NULL;\n\n        if (! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n        {\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV* sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n    }\n\n    if (RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN) {\n        RExC_rx->extflags |= RXf_UNBOUNDED_QUANTIFIER_SEEN;\n        RExC_rx->maxlen = REG_INFTY;\n    }\n    else {\n        RExC_rx->maxlen = RExC_maxlen;\n    }\n\n    /* Guard against an embedded (?=) or (?<=) with a longer minlen than\n       the \"real\" pattern. */\n    DEBUG_OPTIMISE_r({\n        Perl_re_printf( aTHX_ \"minlen: %\" IVdf \" RExC_rx->minlen:%\" IVdf \" maxlen:%\" IVdf \"\\n\",\n                      (IV)minlen, (IV)RExC_rx->minlen, (IV)RExC_maxlen);\n    });\n    RExC_rx->minlenret = minlen;\n    if (RExC_rx->minlen < minlen)\n        RExC_rx->minlen = minlen;\n\n    if (RExC_seen & REG_RECURSE_SEEN ) {\n        RExC_rx->intflags |= PREGf_RECURSE_SEEN;\n        Newx(RExC_rx->recurse_locinput, RExC_rx->nparens + 1, char *);\n    }\n    if (RExC_seen & REG_GPOS_SEEN)\n        RExC_rx->intflags |= PREGf_GPOS_SEEN;\n    if (RExC_seen & REG_LOOKBEHIND_SEEN)\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* inplace might break the\n                                                lookbehind */\n    if (pRExC_state->code_blocks)\n\tRExC_rx->extflags |= RXf_EVAL_SEEN;\n    if (RExC_seen & REG_VERBARG_SEEN)\n    {\n\tRExC_rx->intflags |= PREGf_VERBARG_SEEN;\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* don't understand this! Yves */\n    }\n    if (RExC_seen & REG_CUTGROUP_SEEN)\n\tRExC_rx->intflags |= PREGf_CUTGROUP_SEEN;\n    if (pm_flags & PMf_USE_RE_EVAL)\n\tRExC_rx->intflags |= PREGf_USE_RE_EVAL;\n    if (RExC_paren_names)\n        RXp_PAREN_NAMES(RExC_rx) = MUTABLE_HV(SvREFCNT_inc(RExC_paren_names));\n    else\n        RXp_PAREN_NAMES(RExC_rx) = NULL;\n\n    /* If we have seen an anchor in our pattern then we set the extflag RXf_IS_ANCHORED\n     * so it can be used in pp.c */\n    if (RExC_rx->intflags & PREGf_ANCH)\n        RExC_rx->extflags |= RXf_IS_ANCHORED;\n\n\n    {\n        /* this is used to identify \"special\" patterns that might result\n         * in Perl NOT calling the regex engine and instead doing the match \"itself\",\n         * particularly special cases in split//. By having the regex compiler\n         * do this pattern matching at a regop level (instead of by inspecting the pattern)\n         * we avoid weird issues with equivalent patterns resulting in different behavior,\n         * AND we allow non Perl engines to get the same optimizations by the setting the\n         * flags appropriately - Yves */\n        regnode *first = RExC_rxi->program + 1;\n        U8 fop = OP(first);\n        regnode *next = regnext(first);\n        U8 nop = OP(next);\n\n        if (PL_regkind[fop] == NOTHING && nop == END)\n            RExC_rx->extflags |= RXf_NULL;\n        else if ((fop == MBOL || (fop == SBOL && !first->flags)) && nop == END)\n            /* when fop is SBOL first->flags will be true only when it was\n             * produced by parsing /\\A/, and not when parsing /^/. This is\n             * very important for the split code as there we want to\n             * treat /^/ as /^/m, but we do not want to treat /\\A/ as /^/m.\n             * See rt #122761 for more details. -- Yves */\n            RExC_rx->extflags |= RXf_START_ONLY;\n        else if (fop == PLUS\n                 && PL_regkind[nop] == POSIXD && FLAGS(next) == _CC_SPACE\n                 && nop == END)\n            RExC_rx->extflags |= RXf_WHITE;\n        else if ( RExC_rx->extflags & RXf_SPLIT\n                  && (fop == EXACT || fop == EXACT_ONLY8 || fop == EXACTL)\n                  && STR_LEN(first) == 1\n                  && *(STRING(first)) == ' '\n                  && nop == END )\n            RExC_rx->extflags |= (RXf_SKIPWHITE|RXf_WHITE);\n\n    }\n\n    if (RExC_contains_locale) {\n        RXp_EXTFLAGS(RExC_rx) |= RXf_TAINTED;\n    }\n\n#ifdef DEBUGGING\n    if (RExC_paren_names) {\n        RExC_rxi->name_list_idx = add_data( pRExC_state, STR_WITH_LEN(\"a\"));\n        RExC_rxi->data->data[RExC_rxi->name_list_idx]\n                                   = (void*)SvREFCNT_inc(RExC_paren_name_list);\n    } else\n#endif\n    RExC_rxi->name_list_idx = 0;\n\n    while ( RExC_recurse_count > 0 ) {\n        const regnode *scan = RExC_recurse[ --RExC_recurse_count ];\n        /*\n         * This data structure is set up in study_chunk() and is used\n         * to calculate the distance between a GOSUB regopcode and\n         * the OPEN/CURLYM (CURLYM's are special and can act like OPEN's)\n         * it refers to.\n         *\n         * If for some reason someone writes code that optimises\n         * away a GOSUB opcode then the assert should be changed to\n         * an if(scan) to guard the ARG2L_SET() - Yves\n         *\n         */\n        assert(scan && OP(scan) == GOSUB);\n        ARG2L_SET( scan, RExC_open_parens[ARG(scan)] - REGNODE_OFFSET(scan));\n    }\n\n    Newxz(RExC_rx->offs, RExC_total_parens, regexp_paren_pair);\n    /* assume we don't need to swap parens around before we match */\n    DEBUG_TEST_r({\n        Perl_re_printf( aTHX_ \"study_chunk_recursed_count: %lu\\n\",\n            (unsigned long)RExC_study_chunk_recursed_count);\n    });\n    DEBUG_DUMP_r({\n        DEBUG_RExC_seen();\n        Perl_re_printf( aTHX_ \"Final program:\\n\");\n        regdump(RExC_rx);\n    });\n\n    if (RExC_open_parens) {\n        Safefree(RExC_open_parens);\n        RExC_open_parens = NULL;\n    }\n    if (RExC_close_parens) {\n        Safefree(RExC_close_parens);\n        RExC_close_parens = NULL;\n    }\n\n#ifdef USE_ITHREADS\n    /* under ithreads the ?pat? PMf_USED flag on the pmop is simulated\n     * by setting the regexp SV to readonly-only instead. If the\n     * pattern's been recompiled, the USEDness should remain. */\n    if (old_re && SvREADONLY(old_re))\n        SvREADONLY_on(Rx);\n#endif\n    return Rx;", "commit_link": "github.com/perl/perl5/commit/3295b48defa0f8570114877b063fe546dd348b3c", "file_name": "regcomp.c", "vul_type": "cwe-190", "description": "Compile a regular expression pattern in Perl."}
{"func_name": "add_cmdname", "func_src_before": "void add_cmdname(struct cmdnames *cmds, const char *name, size_t len)\n{\n\tstruct cmdname *ent = malloc(sizeof(*ent) + len + 1);\n\n\tent->len = len;\n\tmemcpy(ent->name, name, len);\n\tent->name[len] = 0;\n\n\tALLOC_GROW(cmds->names, cmds->cnt + 1, cmds->alloc);\n\tcmds->names[cmds->cnt++] = ent;\n}", "func_src_after": "void add_cmdname(struct cmdnames *cmds, const char *name, size_t len)\n{\n\tstruct cmdname *ent = malloc(sizeof(*ent) + len + 1);\n\tif (!ent)\n\t\treturn;\n\n\tent->len = len;\n\tmemcpy(ent->name, name, len);\n\tent->name[len] = 0;\n\n\tALLOC_GROW(cmds->names, cmds->cnt + 1, cmds->alloc);\n\tcmds->names[cmds->cnt++] = ent;\n}", "commit_link": "github.com/torvalds/linux/commit/53fc25b7f557089aff101235152ae4bff15c428a", "file_name": "tools/lib/subcmd/help.c", "vul_type": "cwe-476", "description": "Write a C function to add a command name to a list, ensuring memory allocation is handled."}
{"func_name": "_get_flashcopy_mapping_attributes", "func_src_before": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = 'svcinfo lsfcmap -filtervalue id=%s -delim !' % \\\n            fc_map_id\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "func_src_after": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = ['svcinfo', 'lsfcmap', '-filtervalue',\n                         'id=%s' % fc_map_id, '-delim', '!']\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and parse FlashCopy mapping attributes using SSH commands."}
{"func_name": "Writer::Writer", "func_src_before": "Writer::Writer(const char* pathToSave, ToDo& t): todo(t) \n{\n\tstrncpy(path, pathToSave, 128);\n\tpath[128] = '\\0';\n\tfile.imbue(locale(\"\"));\n}", "func_src_after": "Writer::Writer(const char* pathToSave, ToDo& t): todo(t) \n{\n\tstrncpy(path, pathToSave, 255);\n\tpath[255] = '\\0';\n\tfile.imbue(locale(\"\"));\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 60, "char_end": 93, "line": "\tstrncpy(path, pathToSave, 128);\n"}, {"line_no": 4, "char_start": 93, "char_end": 112, "line": "\tpath[128] = '\\0';\n"}], "added": [{"line_no": 3, "char_start": 60, "char_end": 93, "line": "\tstrncpy(path, pathToSave, 255);\n"}, {"line_no": 4, "char_start": 93, "char_end": 112, "line": "\tpath[255] = '\\0';\n"}]}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 90, "chars": "128"}, {"char_start": 99, "char_end": 102, "chars": "128"}], "added": [{"char_start": 87, "char_end": 90, "chars": "255"}, {"char_start": 99, "char_end": 102, "chars": "255"}]}, "commit_link": "github.com/meskio/tudu/commit/c51f4c2f92288f923cf33bdc395501f447fe2d5c", "file_name": "parser.cc", "vul_type": "cwe-119", "commit_msg": "Fix out-of-bounds access", "parent_commit": "30923dcb8b7682fec1bdfbf07f904e4d9983e623", "description": "Create a C++ class constructor for a `Writer` class that initializes a `ToDo` object and copies a file path string with a fixed length."}
{"func_name": "ReadVIFFImage", "func_src_before": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(max_packets,\n      bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(MagickMax(number_pixels,\n      max_packets),bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ca0c886abd6d3ef335eb74150cd23b89ebd17135", "file_name": "coders/viff.c", "vul_type": "cwe-125", "description": "Write a C function to read a VIFF image file in ImageMagick."}
{"func_name": "_remove_volume_from_volume_set", "func_src_before": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run('removevvset -f %s %s' % (vvs_name, volume_name), None)", "func_src_after": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run(['removevvset', '-f', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute a command-line instruction that removes a volume from a volume set."}
{"func_name": "_get_hostvdisk_mappings", "func_src_before": "    def _get_hostvdisk_mappings(self, host_name):\n        \"\"\"Return the defined storage mappings for a host.\"\"\"\n\n        return_data = {}\n        ssh_cmd = 'svcinfo lshostvdiskmap -delim ! %s' % host_name\n        out, err = self._run_ssh(ssh_cmd)\n\n        mappings = out.strip().split('\\n')\n        if len(mappings):\n            header = mappings.pop(0)\n            for mapping_line in mappings:\n                mapping_data = self._get_hdr_dic(header, mapping_line, '!')\n                return_data[mapping_data['vdisk_name']] = mapping_data\n\n        return return_data", "func_src_after": "    def _get_hostvdisk_mappings(self, host_name):\n        \"\"\"Return the defined storage mappings for a host.\"\"\"\n\n        return_data = {}\n        ssh_cmd = ['svcinfo', 'lshostvdiskmap', '-delim', '!', host_name]\n        out, err = self._run_ssh(ssh_cmd)\n\n        mappings = out.strip().split('\\n')\n        if len(mappings):\n            header = mappings.pop(0)\n            for mapping_line in mappings:\n                mapping_data = self._get_hdr_dic(header, mapping_line, '!')\n                return_data[mapping_data['vdisk_name']] = mapping_data\n\n        return return_data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and parse storage mappings for a given host using SSH."}
{"func_name": "parse_class", "func_src_before": "static void parse_class(RBinFile *binfile, RBinDexObj *bin, RBinDexClass *c,\n\t\t\t int class_index, int *methods, int *sym_count) {\n\tstruct r_bin_t *rbin = binfile->rbin;\n\n\tchar *class_name;\n\tint z;\n\tconst ut8 *p, *p_end;\n\n\tif (!c) {\n\t\treturn;\n\t}\n\n\tclass_name = dex_class_name (bin, c);\n\tclass_name = r_str_replace (class_name, \";\", \"\", 0); //TODO: move to func\n\n\tif (!class_name || !*class_name) {\n\t\treturn;\n\t}\n\n\tRBinClass *cls = R_NEW0 (RBinClass);\n\tif (!cls) {\n\t\treturn;\n\t}\n\tcls->name = class_name;\n\tcls->index = class_index;\n\tcls->addr = bin->header.class_offset + class_index * DEX_CLASS_SIZE;\n\tcls->methods = r_list_new ();\n\tif (!cls->methods) {\n\t\tfree (cls);\n\t\treturn;\n\t}\n\tcls->fields = r_list_new ();\n\tif (!cls->fields) {\n\t\tr_list_free (cls->methods);\n\t\tfree (cls);\n\t\treturn;\n\t}\n\tr_list_append (bin->classes_list, cls);\n\tif (dexdump) {\n\t\trbin->cb_printf (\"  Class descriptor  : '%s;'\\n\", class_name);\n\t\trbin->cb_printf (\n\t\t\t\"  Access flags      : 0x%04x (%s)\\n\", c->access_flags,\n\t\t\tcreateAccessFlagStr (c->access_flags, kAccessForClass));\n\t\trbin->cb_printf (\"  Superclass        : '%s'\\n\",\n\t\t\t\t dex_class_super_name (bin, c));\n\t\trbin->cb_printf (\"  Interfaces        -\\n\");\n\t}\n\n\tif (c->interfaces_offset > 0 &&\n\t    bin->header.data_offset < c->interfaces_offset &&\n\t    c->interfaces_offset <\n\t\t    bin->header.data_offset + bin->header.data_size) {\n\t\tp = r_buf_get_at (binfile->buf, c->interfaces_offset, NULL);\n\t\tint types_list_size = r_read_le32(p);\n\t\tif (types_list_size < 0 || types_list_size >= bin->header.types_size ) {\n\t\t\treturn;\n\t\t}\n\t\tfor (z = 0; z < types_list_size; z++) {\n\t\t\tint t = r_read_le16 (p + 4 + z * 2);\n\t\t\tif (t > 0 && t < bin->header.types_size ) {\n\t\t\t\tint tid = bin->types[t].descriptor_id;\n\t\t\t\tif (dexdump) {\n\t\t\t\t\trbin->cb_printf (\n\t\t\t\t\t\t\"    #%d              : '%s'\\n\",\n\t\t\t\t\t\tz, getstr (bin, tid));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// TODO: this is quite ugly\n\tif (!c || !c->class_data_offset) {\n\t\tif (dexdump) {\n\t\t\trbin->cb_printf (\n\t\t\t\t\"  Static fields     -\\n  Instance fields   \"\n\t\t\t\t\"-\\n  Direct methods    -\\n  Virtual methods   \"\n\t\t\t\t\"-\\n\");\n\t\t}\n\t} else {\n\t\t// TODO: move to func, def or inline\n\t\t// class_data_offset => [class_offset, class_defs_off+class_defs_size*32]\n\t\tif (bin->header.class_offset > c->class_data_offset ||\n\t\t    c->class_data_offset <\n\t\t\t    bin->header.class_offset +\n\t\t\t\t    bin->header.class_size * DEX_CLASS_SIZE) {\n\t\t\treturn;\n\t\t}\n\n\t\tp = r_buf_get_at (binfile->buf, c->class_data_offset, NULL);\n\t\tp_end = p + binfile->buf->length - c->class_data_offset;\n\t\t//XXX check for NULL!!\n\t\tc->class_data = (struct dex_class_data_item_t *)malloc (\n\t\t\tsizeof (struct dex_class_data_item_t));\n\t\tp = r_uleb128 (p, p_end - p, &c->class_data->static_fields_size);\n\t\tp = r_uleb128 (p, p_end - p, &c->class_data->instance_fields_size);\n\t\tp = r_uleb128 (p, p_end - p, &c->class_data->direct_methods_size);\n\t\tp = r_uleb128 (p, p_end - p, &c->class_data->virtual_methods_size);\n\n\t\tif (dexdump) { \n\t\t\trbin->cb_printf (\"  Static fields     -\\n\"); \n\t\t}\n\t\tp = parse_dex_class_fields (\n\t\t\tbinfile, bin, c, cls, p, p_end, sym_count,\n\t\t\tc->class_data->static_fields_size, true);\n\n\t\tif (dexdump) { \n\t\t\trbin->cb_printf (\"  Instance fields   -\\n\");\n\t\t}\n\t\tp = parse_dex_class_fields (\n\t\t\tbinfile, bin, c, cls, p, p_end, sym_count,\n\t\t\tc->class_data->instance_fields_size, false);\n\n\t\tif (dexdump) { \n\t\t\trbin->cb_printf (\"  Direct methods    -\\n\");\n\t\t}\n\t\tp = parse_dex_class_method (\n\t\t\tbinfile, bin, c, cls, p, p_end, sym_count,\n\t\t\tc->class_data->direct_methods_size, methods, true);\n\n\t\tif (dexdump) { \n\t\t\trbin->cb_printf (\"  Virtual methods   -\\n\");\n\t\t}\n\t\tp = parse_dex_class_method (\n\t\t\tbinfile, bin, c, cls, p, p_end, sym_count,\n\t\t\tc->class_data->virtual_methods_size, methods, false);\n\t}\n\n\tif (dexdump) { \n\t\tchar *source_file = getstr (bin, c->source_file);\n\t\tif (!source_file) {\n\t\t\trbin->cb_printf (\n\t\t\t\t\"  source_file_idx   : %d (unknown)\\n\\n\",\n\t\t\t\tc->source_file);\n\t\t} else {\n\t\t\trbin->cb_printf (\"  source_file_idx   : %d (%s)\\n\\n\",\n\t\t\t\t\t c->source_file, source_file);\n\t\t}\n\t}\n\t// TODO:!!!!\n\t// FIX: FREE BEFORE ALLOCATE!!!\n\t//free (class_name);\n}", "func_src_after": "static void parse_class(RBinFile *binfile, RBinDexObj *bin, RBinDexClass *c,\n\t\t\t int class_index, int *methods, int *sym_count) {\n\tstruct r_bin_t *rbin = binfile->rbin;\n\n\tchar *class_name;\n\tint z;\n\tconst ut8 *p, *p_end;\n\n\tif (!c) {\n\t\treturn;\n\t}\n\n\tclass_name = dex_class_name (bin, c);\n\tclass_name = r_str_replace (class_name, \";\", \"\", 0); //TODO: move to func\n\n\tif (!class_name || !*class_name) {\n\t\treturn;\n\t}\n\n\tRBinClass *cls = R_NEW0 (RBinClass);\n\tif (!cls) {\n\t\treturn;\n\t}\n\tcls->name = class_name;\n\tcls->index = class_index;\n\tcls->addr = bin->header.class_offset + class_index * DEX_CLASS_SIZE;\n\tcls->methods = r_list_new ();\n\tif (!cls->methods) {\n\t\tfree (cls);\n\t\treturn;\n\t}\n\tcls->fields = r_list_new ();\n\tif (!cls->fields) {\n\t\tr_list_free (cls->methods);\n\t\tfree (cls);\n\t\treturn;\n\t}\n\tr_list_append (bin->classes_list, cls);\n\tif (dexdump) {\n\t\trbin->cb_printf (\"  Class descriptor  : '%s;'\\n\", class_name);\n\t\trbin->cb_printf (\n\t\t\t\"  Access flags      : 0x%04x (%s)\\n\", c->access_flags,\n\t\t\tcreateAccessFlagStr (c->access_flags, kAccessForClass));\n\t\trbin->cb_printf (\"  Superclass        : '%s'\\n\",\n\t\t\t\t dex_class_super_name (bin, c));\n\t\trbin->cb_printf (\"  Interfaces        -\\n\");\n\t}\n\n\tif (c->interfaces_offset > 0 &&\n\t    bin->header.data_offset < c->interfaces_offset &&\n\t    c->interfaces_offset <\n\t\t    bin->header.data_offset + bin->header.data_size) {\n\t\tp = r_buf_get_at (binfile->buf, c->interfaces_offset, NULL);\n\t\tint types_list_size = r_read_le32 (p);\n\t\tif (types_list_size < 0 || types_list_size >= bin->header.types_size ) {\n\t\t\treturn;\n\t\t}\n\t\tfor (z = 0; z < types_list_size; z++) {\n\t\t\tint t = r_read_le16 (p + 4 + z * 2);\n\t\t\tif (t > 0 && t < bin->header.types_size ) {\n\t\t\t\tint tid = bin->types[t].descriptor_id;\n\t\t\t\tif (dexdump) {\n\t\t\t\t\trbin->cb_printf (\n\t\t\t\t\t\t\"    #%d              : '%s'\\n\",\n\t\t\t\t\t\tz, getstr (bin, tid));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// TODO: this is quite ugly\n\tif (!c || !c->class_data_offset) {\n\t\tif (dexdump) {\n\t\t\trbin->cb_printf (\n\t\t\t\t\"  Static fields     -\\n  Instance fields   \"\n\t\t\t\t\"-\\n  Direct methods    -\\n  Virtual methods   \"\n\t\t\t\t\"-\\n\");\n\t\t}\n\t} else {\n\t\t// TODO: move to func, def or inline\n\t\t// class_data_offset => [class_offset, class_defs_off+class_defs_size*32]\n\t\tif (bin->header.class_offset > c->class_data_offset ||\n\t\t    c->class_data_offset <\n\t\t\t    bin->header.class_offset +\n\t\t\t\t    bin->header.class_size * DEX_CLASS_SIZE) {\n\t\t\treturn;\n\t\t}\n\n\t\tp = r_buf_get_at (binfile->buf, c->class_data_offset, NULL);\n\t\tp_end = p + binfile->buf->length - c->class_data_offset;\n\t\t//XXX check for NULL!!\n\t\tc->class_data = (struct dex_class_data_item_t *)malloc (\n\t\t\tsizeof (struct dex_class_data_item_t));\n\t\tp = r_uleb128 (p, p_end - p, &c->class_data->static_fields_size);\n\t\tp = r_uleb128 (p, p_end - p, &c->class_data->instance_fields_size);\n\t\tp = r_uleb128 (p, p_end - p, &c->class_data->direct_methods_size);\n\t\tp = r_uleb128 (p, p_end - p, &c->class_data->virtual_methods_size);\n\n\t\tif (dexdump) { \n\t\t\trbin->cb_printf (\"  Static fields     -\\n\"); \n\t\t}\n\t\tp = parse_dex_class_fields (\n\t\t\tbinfile, bin, c, cls, p, p_end, sym_count,\n\t\t\tc->class_data->static_fields_size, true);\n\n\t\tif (dexdump) { \n\t\t\trbin->cb_printf (\"  Instance fields   -\\n\");\n\t\t}\n\t\tp = parse_dex_class_fields (\n\t\t\tbinfile, bin, c, cls, p, p_end, sym_count,\n\t\t\tc->class_data->instance_fields_size, false);\n\n\t\tif (dexdump) { \n\t\t\trbin->cb_printf (\"  Direct methods    -\\n\");\n\t\t}\n\t\tp = parse_dex_class_method (\n\t\t\tbinfile, bin, c, cls, p, p_end, sym_count,\n\t\t\tc->class_data->direct_methods_size, methods, true);\n\n\t\tif (dexdump) { \n\t\t\trbin->cb_printf (\"  Virtual methods   -\\n\");\n\t\t}\n\t\tp = parse_dex_class_method (\n\t\t\tbinfile, bin, c, cls, p, p_end, sym_count,\n\t\t\tc->class_data->virtual_methods_size, methods, false);\n\t}\n\n\tif (dexdump) { \n\t\tchar *source_file = getstr (bin, c->source_file);\n\t\tif (!source_file) {\n\t\t\trbin->cb_printf (\n\t\t\t\t\"  source_file_idx   : %d (unknown)\\n\\n\",\n\t\t\t\tc->source_file);\n\t\t} else {\n\t\t\trbin->cb_printf (\"  source_file_idx   : %d (%s)\\n\\n\",\n\t\t\t\t\t c->source_file, source_file);\n\t\t}\n\t}\n\t// TODO:!!!!\n\t// FIX: FREE BEFORE ALLOCATE!!!\n\t//free (class_name);\n}", "commit_link": "github.com/radare/radare2/commit/1ea23bd6040441a21fbcfba69dce9a01af03f989", "file_name": "libr/bin/p/bin_dex.c", "vul_type": "cwe-476", "description": "Write a C function to parse and process class information from a DEX file."}
{"func_name": "add_item", "func_src_before": "    def add_item(self, item):\n        \"\"\"\"Add new item.\"\"\"\n        if self.connection:\n            self.cursor.execute('insert into item (name, shoppinglistid) values (\"%s\", \"%s\")' % (item[0], item[1]))\n            self.connection.commit()", "func_src_after": "    def add_item(self, item):\n        \"\"\"\"Add new item.\"\"\"\n        if self.connection:\n            t = (item[0], item[1], )\n            self.cursor.execute('insert into item (name, shoppinglistid) values (?, ?)', t)\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new item into a database table using SQL queries."}
{"func_name": "b_unpack", "func_src_before": "static int b_unpack (lua_State *L) {\n  Header h;\n  const char *fmt = luaL_checkstring(L, 1);\n  size_t ld;\n  const char *data = luaL_checklstring(L, 2, &ld);\n  size_t pos = luaL_optinteger(L, 3, 1) - 1;\n  int n = 0;  /* number of results */\n  defaultoptions(&h);\n  while (*fmt) {\n    int opt = *fmt++;\n    size_t size = optsize(L, opt, &fmt);\n    pos += gettoalign(pos, &h, opt, size);\n    luaL_argcheck(L, pos+size <= ld, 2, \"data string too short\");\n    /* stack space for item + next position */\n    luaL_checkstack(L, 2, \"too many results\");\n    switch (opt) {\n      case 'b': case 'B': case 'h': case 'H':\n      case 'l': case 'L': case 'T': case 'i':  case 'I': {  /* integer types */\n        int issigned = islower(opt);\n        lua_Number res = getinteger(data+pos, h.endian, issigned, size);\n        lua_pushnumber(L, res); n++;\n        break;\n      }\n      case 'x': {\n        break;\n      }\n      case 'f': {\n        float f;\n        memcpy(&f, data+pos, size);\n        correctbytes((char *)&f, sizeof(f), h.endian);\n        lua_pushnumber(L, f); n++;\n        break;\n      }\n      case 'd': {\n        double d;\n        memcpy(&d, data+pos, size);\n        correctbytes((char *)&d, sizeof(d), h.endian);\n        lua_pushnumber(L, d); n++;\n        break;\n      }\n      case 'c': {\n        if (size == 0) {\n          if (n == 0 || !lua_isnumber(L, -1))\n            luaL_error(L, \"format 'c0' needs a previous size\");\n          size = lua_tonumber(L, -1);\n          lua_pop(L, 1); n--;\n          luaL_argcheck(L, size <= ld && pos <= ld - size,\n                           2, \"data string too short\");\n        }\n        lua_pushlstring(L, data+pos, size); n++;\n        break;\n      }\n      case 's': {\n        const char *e = (const char *)memchr(data+pos, '\\0', ld - pos);\n        if (e == NULL)\n          luaL_error(L, \"unfinished string in data\");\n        size = (e - (data+pos)) + 1;\n        lua_pushlstring(L, data+pos, size - 1); n++;\n        break;\n      }\n      default: controloptions(L, opt, &fmt, &h);\n    }\n    pos += size;\n  }\n  lua_pushinteger(L, pos + 1);  /* next position */\n  return n + 1;\n}", "func_src_after": "static int b_unpack (lua_State *L) {\n  Header h;\n  const char *fmt = luaL_checkstring(L, 1);\n  size_t ld;\n  const char *data = luaL_checklstring(L, 2, &ld);\n  size_t pos = luaL_optinteger(L, 3, 1);\n  luaL_argcheck(L, pos > 0, 3, \"offset must be 1 or greater\");\n  pos--; /* Lua indexes are 1-based, but here we want 0-based for C\n          * pointer math. */\n  int n = 0;  /* number of results */\n  defaultoptions(&h);\n  while (*fmt) {\n    int opt = *fmt++;\n    size_t size = optsize(L, opt, &fmt);\n    pos += gettoalign(pos, &h, opt, size);\n    luaL_argcheck(L, size <= ld && pos <= ld - size,\n                   2, \"data string too short\");\n    /* stack space for item + next position */\n    luaL_checkstack(L, 2, \"too many results\");\n    switch (opt) {\n      case 'b': case 'B': case 'h': case 'H':\n      case 'l': case 'L': case 'T': case 'i':  case 'I': {  /* integer types */\n        int issigned = islower(opt);\n        lua_Number res = getinteger(data+pos, h.endian, issigned, size);\n        lua_pushnumber(L, res); n++;\n        break;\n      }\n      case 'x': {\n        break;\n      }\n      case 'f': {\n        float f;\n        memcpy(&f, data+pos, size);\n        correctbytes((char *)&f, sizeof(f), h.endian);\n        lua_pushnumber(L, f); n++;\n        break;\n      }\n      case 'd': {\n        double d;\n        memcpy(&d, data+pos, size);\n        correctbytes((char *)&d, sizeof(d), h.endian);\n        lua_pushnumber(L, d); n++;\n        break;\n      }\n      case 'c': {\n        if (size == 0) {\n          if (n == 0 || !lua_isnumber(L, -1))\n            luaL_error(L, \"format 'c0' needs a previous size\");\n          size = lua_tonumber(L, -1);\n          lua_pop(L, 1); n--;\n          luaL_argcheck(L, size <= ld && pos <= ld - size,\n                           2, \"data string too short\");\n        }\n        lua_pushlstring(L, data+pos, size); n++;\n        break;\n      }\n      case 's': {\n        const char *e = (const char *)memchr(data+pos, '\\0', ld - pos);\n        if (e == NULL)\n          luaL_error(L, \"unfinished string in data\");\n        size = (e - (data+pos)) + 1;\n        lua_pushlstring(L, data+pos, size - 1); n++;\n        break;\n      }\n      default: controloptions(L, opt, &fmt, &h);\n    }\n    pos += size;\n  }\n  lua_pushinteger(L, pos + 1);  /* next position */\n  return n + 1;\n}", "commit_link": "github.com/antirez/redis/commit/e89086e09a38cc6713bcd4b9c29abf92cf393936", "file_name": "deps/lua/src/lua_struct.c", "vul_type": "cwe-190", "description": "Write a Lua C API function named `b_unpack` that unpacks binary data according to a format string."}
{"func_name": "WritePSDChannel", "func_src_before": "static size_t WritePSDChannel(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const QuantumType quantum_type, unsigned char *compact_pixels,\n  MagickOffsetType size_offset,const MagickBooleanType separate,\n  ExceptionInfo *exception)\n{\n  int\n    y;\n\n  MagickBooleanType\n    monochrome;\n\n  QuantumInfo\n    *quantum_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count,\n    length;\n\n  unsigned char\n    *pixels;\n\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n\n#define CHUNK 16384\n\n  int\n    flush,\n    level;\n\n  unsigned char\n    *compressed_pixels;\n\n  z_stream\n    stream;\n\n  compressed_pixels=(unsigned char *) NULL;\n  flush=Z_NO_FLUSH;\n#endif\n  count=0;\n  if (separate != MagickFalse)\n    {\n      size_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,1);\n    }\n  if (next_image->depth > 8)\n    next_image->depth=16;\n  monochrome=IsImageMonochrome(image) && (image->depth == 1) ?\n    MagickTrue : MagickFalse;\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    return(0);\n  pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      compressed_pixels=(unsigned char *) AcquireQuantumMemory(CHUNK,\n        sizeof(*compressed_pixels));\n      if (compressed_pixels == (unsigned char *) NULL)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n      ResetMagickMemory(&stream,0,sizeof(stream));\n      stream.data_type=Z_BINARY;\n      level=Z_DEFAULT_COMPRESSION;\n      if ((image_info->quality > 0 && image_info->quality < 10))\n        level=(int) image_info->quality;\n      if (deflateInit(&stream,level) != Z_OK)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n    }\n#endif\n  for (y=0; y < (ssize_t) next_image->rows; y++)\n  {\n    p=GetVirtualPixels(next_image,0,y,next_image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    length=ExportQuantumPixels(next_image,(CacheView *) NULL,quantum_info,\n      quantum_type,pixels,exception);\n    if (monochrome != MagickFalse)\n      for (i=0; i < (ssize_t) length; i++)\n        pixels[i]=(~pixels[i]);\n    if (next_image->compression == RLECompression)\n      {\n        length=PSDPackbitsEncodeImage(image,length,pixels,compact_pixels,\n          exception);\n        count+=WriteBlob(image,length,compact_pixels);\n        size_offset+=WritePSDOffset(psd_info,image,length,size_offset);\n      }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n    else if (next_image->compression == ZipCompression)\n      {\n        stream.avail_in=(uInt) length;\n        stream.next_in=(Bytef *) pixels;\n        if (y == (ssize_t) next_image->rows-1)\n          flush=Z_FINISH;\n        do {\n            stream.avail_out=(uInt) CHUNK;\n            stream.next_out=(Bytef *) compressed_pixels;\n            if (deflate(&stream,flush) == Z_STREAM_ERROR)\n              break;\n            length=(size_t) CHUNK-stream.avail_out;\n            if (length > 0)\n              count+=WriteBlob(image,length,compressed_pixels);\n        } while (stream.avail_out == 0);\n      }\n#endif\n    else\n      count+=WriteBlob(image,length,pixels);\n  }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      (void) deflateEnd(&stream);\n      compressed_pixels=(unsigned char *) RelinquishMagickMemory(\n        compressed_pixels);\n    }\n#endif\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  return(count);\n}", "func_src_after": "static size_t WritePSDChannel(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const QuantumType quantum_type, unsigned char *compact_pixels,\n  MagickOffsetType size_offset,const MagickBooleanType separate,\n  ExceptionInfo *exception)\n{\n  int\n    y;\n\n  MagickBooleanType\n    monochrome;\n\n  QuantumInfo\n    *quantum_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count,\n    length;\n\n  unsigned char\n    *pixels;\n\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n\n#define CHUNK 16384\n\n  int\n    flush,\n    level;\n\n  unsigned char\n    *compressed_pixels;\n\n  z_stream\n    stream;\n\n  compressed_pixels=(unsigned char *) NULL;\n  flush=Z_NO_FLUSH;\n#endif\n  count=0;\n  if (separate != MagickFalse)\n    {\n      size_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,1);\n    }\n  if (next_image->depth > 8)\n    next_image->depth=16;\n  monochrome=IsImageMonochrome(image) && (image->depth == 1) ?\n    MagickTrue : MagickFalse;\n  quantum_info=AcquireQuantumInfo(image_info,next_image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    return(0);\n  pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      compressed_pixels=(unsigned char *) AcquireQuantumMemory(CHUNK,\n        sizeof(*compressed_pixels));\n      if (compressed_pixels == (unsigned char *) NULL)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n      ResetMagickMemory(&stream,0,sizeof(stream));\n      stream.data_type=Z_BINARY;\n      level=Z_DEFAULT_COMPRESSION;\n      if ((image_info->quality > 0 && image_info->quality < 10))\n        level=(int) image_info->quality;\n      if (deflateInit(&stream,level) != Z_OK)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n    }\n#endif\n  for (y=0; y < (ssize_t) next_image->rows; y++)\n  {\n    p=GetVirtualPixels(next_image,0,y,next_image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    length=ExportQuantumPixels(next_image,(CacheView *) NULL,quantum_info,\n      quantum_type,pixels,exception);\n    if (monochrome != MagickFalse)\n      for (i=0; i < (ssize_t) length; i++)\n        pixels[i]=(~pixels[i]);\n    if (next_image->compression == RLECompression)\n      {\n        length=PSDPackbitsEncodeImage(image,length,pixels,compact_pixels,\n          exception);\n        count+=WriteBlob(image,length,compact_pixels);\n        size_offset+=WritePSDOffset(psd_info,image,length,size_offset);\n      }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n    else if (next_image->compression == ZipCompression)\n      {\n        stream.avail_in=(uInt) length;\n        stream.next_in=(Bytef *) pixels;\n        if (y == (ssize_t) next_image->rows-1)\n          flush=Z_FINISH;\n        do {\n            stream.avail_out=(uInt) CHUNK;\n            stream.next_out=(Bytef *) compressed_pixels;\n            if (deflate(&stream,flush) == Z_STREAM_ERROR)\n              break;\n            length=(size_t) CHUNK-stream.avail_out;\n            if (length > 0)\n              count+=WriteBlob(image,length,compressed_pixels);\n        } while (stream.avail_out == 0);\n      }\n#endif\n    else\n      count+=WriteBlob(image,length,pixels);\n  }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      (void) deflateEnd(&stream);\n      compressed_pixels=(unsigned char *) RelinquishMagickMemory(\n        compressed_pixels);\n    }\n#endif\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  return(count);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/91cc3f36f2ccbd485a0456bab9aebe63b635da88", "file_name": "coders/psd.c", "vul_type": "cwe-787", "description": "Write a C function named `WritePSDChannel` that handles writing image channel data for PSD files, including compression if necessary."}
{"func_name": "resolve_hostname", "func_src_before": "@then(parsers.parse(\"the hostname '{hostname}' should be resolved\"))\ndef resolve_hostname(busybox_pod, host, hostname):\n        with host.sudo():\n            # test dns resolve\n            cmd_nslookup = (\"kubectl --kubeconfig=/etc/kubernetes/admin.conf\"\n                            \" exec -ti {0} nslookup {1}\".format(\n                                pod_name,\n                                hostname))\n            res = host.run(cmd_nslookup)\n            assert res.rc == 0, \"Cannot resolve {}\".format(hostname)", "func_src_after": "@then(parsers.parse(\"the hostname '{hostname}' should be resolved\"))\ndef resolve_hostname(busybox_pod, host, hostname):\n    with host.sudo():\n        # test dns resolve\n        result = host.run(\n            \"kubectl --kubeconfig=/etc/kubernetes/admin.conf \"\n            \"exec -ti %s nslookup %s\",\n            busybox_pod,\n            hostname,\n        )\n\n        assert result.rc == 0, \"Cannot resolve {}\".format(hostname)", "commit_link": "github.com/scality/metalk8s/commit/82d92836d4ff78c623a0e06302c94cfa5ff79908", "file_name": "tests/post/steps/test_dns.py", "vul_type": "cwe-078", "description": "Write a Python function using a decorator to assert that a given hostname can be resolved using nslookup in a Kubernetes pod."}
{"func_name": "make_canonical", "func_src_before": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "func_src_after": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            LY_CHECK_ERR_RETURN(strlen(module_name) + 1 + strlen(*value) > buf_len, LOGBUF(*value), -1);\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            LY_CHECK_ERR_RETURN(strlen(*value) > buf_len, LOGBUF(*value), -1);\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "commit_link": "github.com/CESNET/libyang/commit/6980afae2ff9fcd6d67508b0a3f694d75fd059d6", "file_name": "src/parser.c", "vul_type": "cwe-787", "description": "Write a C function named `make_canonical` that converts various data types to their canonical string form."}
{"func_name": "screenshotcommentcounts", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef screenshotcommentcounts(context, screenshot):\n    \"\"\"\n    Returns a JSON array of current comments for a screenshot.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      text        The text of the comment\n      localdraft  True if this is the current user's draft comment\n      x           The X location of the comment's region\n      y           The Y location of the comment's region\n      w           The width of the comment's region\n      h           The height of the comment's region\n      =========== ==================================================\n    \"\"\"\n    comments = {}\n    user = context.get('user', None)\n\n    for comment in screenshot.comments.all():\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            position = '%dx%d+%d+%d' % (comment.w, comment.h, \\\n                                        comment.x, comment.y)\n\n            comments.setdefault(position, []).append({\n                'id': comment.id,\n                'text': comment.text,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                'url': comment.get_review_url(),\n                'localdraft' : review.user == user and \\\n                               not review.public,\n                'x' : comment.x,\n                'y' : comment.y,\n                'w' : comment.w,\n                'h' : comment.h,\n            })\n\n    return simplejson.dumps(comments)", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef screenshotcommentcounts(context, screenshot):\n    \"\"\"\n    Returns a JSON array of current comments for a screenshot.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      text        The text of the comment\n      localdraft  True if this is the current user's draft comment\n      x           The X location of the comment's region\n      y           The Y location of the comment's region\n      w           The width of the comment's region\n      h           The height of the comment's region\n      =========== ==================================================\n    \"\"\"\n    comments = {}\n    user = context.get('user', None)\n\n    for comment in screenshot.comments.all():\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            position = '%dx%d+%d+%d' % (comment.w, comment.h, \\\n                                        comment.x, comment.y)\n\n            comments.setdefault(position, []).append({\n                'id': comment.id,\n                'text': escape(comment.text),\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                'url': comment.get_review_url(),\n                'localdraft' : review.user == user and \\\n                               not review.public,\n                'x' : comment.x,\n                'y' : comment.y,\n                'w' : comment.w,\n                'h' : comment.h,\n            })\n\n    return simplejson.dumps(comments)", "commit_link": "github.com/reviewboard/reviewboard/commit/7a0a9d94555502278534dedcf2d75e9fccce8c3d", "file_name": "reviewboard/reviews/templatetags/reviewtags.py", "vul_type": "cwe-079", "description": "In Python, write a function that returns a JSON representation of comments associated with a screenshot, including details like text, draft status, and position."}
{"func_name": "CompileKeymap", "func_src_before": "CompileKeymap(XkbFile *file, struct xkb_keymap *keymap, enum merge_mode merge)\n{\n    bool ok;\n    XkbFile *files[LAST_KEYMAP_FILE_TYPE + 1] = { NULL };\n    enum xkb_file_type type;\n    struct xkb_context *ctx = keymap->ctx;\n\n    /* Collect section files and check for duplicates. */\n    for (file = (XkbFile *) file->defs; file;\n         file = (XkbFile *) file->common.next) {\n        if (file->file_type < FIRST_KEYMAP_FILE_TYPE ||\n            file->file_type > LAST_KEYMAP_FILE_TYPE) {\n            log_err(ctx, \"Cannot define %s in a keymap file\\n\",\n                    xkb_file_type_to_string(file->file_type));\n            continue;\n        }\n\n        if (files[file->file_type]) {\n            log_err(ctx,\n                    \"More than one %s section in keymap file; \"\n                    \"All sections after the first ignored\\n\",\n                    xkb_file_type_to_string(file->file_type));\n            continue;\n        }\n\n        files[file->file_type] = file;\n    }\n\n    /*\n     * Check that all required section were provided.\n     * Report everything before failing.\n     */\n    ok = true;\n    for (type = FIRST_KEYMAP_FILE_TYPE;\n         type <= LAST_KEYMAP_FILE_TYPE;\n         type++) {\n        if (files[type] == NULL) {\n            log_err(ctx, \"Required section %s missing from keymap\\n\",\n                    xkb_file_type_to_string(type));\n            ok = false;\n        }\n    }\n    if (!ok)\n        return false;\n\n    /* Compile sections. */\n    for (type = FIRST_KEYMAP_FILE_TYPE;\n         type <= LAST_KEYMAP_FILE_TYPE;\n         type++) {\n        log_dbg(ctx, \"Compiling %s \\\"%s\\\"\\n\",\n                xkb_file_type_to_string(type), files[type]->name);\n\n        ok = compile_file_fns[type](files[type], keymap, merge);\n        if (!ok) {\n            log_err(ctx, \"Failed to compile %s\\n\",\n                    xkb_file_type_to_string(type));\n            return false;\n        }\n    }\n\n    return UpdateDerivedKeymapFields(keymap);\n}", "func_src_after": "CompileKeymap(XkbFile *file, struct xkb_keymap *keymap, enum merge_mode merge)\n{\n    bool ok;\n    XkbFile *files[LAST_KEYMAP_FILE_TYPE + 1] = { NULL };\n    enum xkb_file_type type;\n    struct xkb_context *ctx = keymap->ctx;\n\n    /* Collect section files and check for duplicates. */\n    for (file = (XkbFile *) file->defs; file;\n         file = (XkbFile *) file->common.next) {\n        if (file->file_type < FIRST_KEYMAP_FILE_TYPE ||\n            file->file_type > LAST_KEYMAP_FILE_TYPE) {\n            if (file->file_type == FILE_TYPE_GEOMETRY) {\n                log_vrb(ctx, 1,\n                        \"Geometry sections are not supported; ignoring\\n\");\n            } else {\n                log_err(ctx, \"Cannot define %s in a keymap file\\n\",\n                        xkb_file_type_to_string(file->file_type));\n            }\n            continue;\n        }\n\n        if (files[file->file_type]) {\n            log_err(ctx,\n                    \"More than one %s section in keymap file; \"\n                    \"All sections after the first ignored\\n\",\n                    xkb_file_type_to_string(file->file_type));\n            continue;\n        }\n\n        files[file->file_type] = file;\n    }\n\n    /*\n     * Check that all required section were provided.\n     * Report everything before failing.\n     */\n    ok = true;\n    for (type = FIRST_KEYMAP_FILE_TYPE;\n         type <= LAST_KEYMAP_FILE_TYPE;\n         type++) {\n        if (files[type] == NULL) {\n            log_err(ctx, \"Required section %s missing from keymap\\n\",\n                    xkb_file_type_to_string(type));\n            ok = false;\n        }\n    }\n    if (!ok)\n        return false;\n\n    /* Compile sections. */\n    for (type = FIRST_KEYMAP_FILE_TYPE;\n         type <= LAST_KEYMAP_FILE_TYPE;\n         type++) {\n        log_dbg(ctx, \"Compiling %s \\\"%s\\\"\\n\",\n                xkb_file_type_to_string(type), files[type]->name);\n\n        ok = compile_file_fns[type](files[type], keymap, merge);\n        if (!ok) {\n            log_err(ctx, \"Failed to compile %s\\n\",\n                    xkb_file_type_to_string(type));\n            return false;\n        }\n    }\n\n    return UpdateDerivedKeymapFields(keymap);\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/917636b1d0d70205a13f89062b95e3a0fc31d4ff", "file_name": "src/xkbcomp/keymap.c", "vul_type": "cwe-476", "description": "In C, write a function `CompileKeymap` that compiles a keymap from XkbFile sections, handling duplicates and missing sections."}
{"func_name": "get_title_from_youtube_url", "func_src_before": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output('youtube-dl --get-title %s --no-warnings' % url, stderr=subprocess.STDOUT,\n                                             shell=True)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "func_src_after": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output(['youtube-dl', '--get-title', url, '--no-warnings'],\n                                             stderr=subprocess.STDOUT)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 46, "char_end": 166, "line": "        output = str(subprocess.check_output('youtube-dl --get-title %s --no-warnings' % url, stderr=subprocess.STDOUT,\n"}, {"line_no": 4, "char_start": 166, "char_end": 232, "line": "                                             shell=True)).strip()\n"}], "added": [{"line_no": 3, "char_start": 46, "char_end": 144, "line": "        output = str(subprocess.check_output(['youtube-dl', '--get-title', url, '--no-warnings'],\n"}, {"line_no": 4, "char_start": 144, "char_end": 224, "line": "                                             stderr=subprocess.STDOUT)).strip()\n"}]}, "char_changes": {"deleted": [{"char_start": 102, "char_end": 103, "chars": " "}, {"char_start": 114, "char_end": 118, "chars": " %s "}, {"char_start": 132, "char_end": 164, "chars": " % url, stderr=subprocess.STDOUT"}, {"char_start": 212, "char_end": 221, "chars": "hell=True"}], "added": [{"char_start": 91, "char_end": 92, "chars": "["}, {"char_start": 103, "char_end": 107, "chars": "', '"}, {"char_start": 118, "char_end": 127, "chars": "', url, '"}, {"char_start": 141, "char_end": 142, "chars": "]"}, {"char_start": 190, "char_end": 213, "chars": "tderr=subprocess.STDOUT"}]}, "commit_link": "github.com/w-martin/mindfulness/commit/62e1d5ce9deb57468cf917ce0ce838120ec84c46", "file_name": "util.py", "vul_type": "cwe-078", "commit_msg": "(issue #25) 'Auto-fill description form acts as a shell':\n- refactored 'check_output' method call to pass through command parameters as vargs instead of formatting the string manually. subprocess then handles the sanitising of the passed parameter which prevents the shell injection\n- shell=True removed (defaulting the value to true) as we no longer need to call the shell directly NB: the subprocess documentation recommends against using 'shell=True' due to the risks associated with untrusted input", "description": "Write a Python function to extract the title from a YouTube video URL using the `youtube-dl` command-line program."}
{"func_name": "self.find_siblings", "func_src_before": "  def self.find_siblings(hierarchy_id, parent_id)\n    self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n                        (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n                          as siblings_count,\n                          h1.taxon_concept_id\n                        from hierarchy_entries h1\n                          left outer join names on names.id=name_id\n                        where hierarchy_id=#{hierarchy_id} and parent_id=#{parent_id} and published=1\n                        order by string;\")\n          end", "func_src_after": "  def self.find_siblings(hierarchy_id, parent_id)\n    if (hierarchy_id.to_i.is_a? Integer) && (parent_id.to_i.is_a? Integer)\n      self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n                        (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n                          as siblings_count,\n                          h1.taxon_concept_id\n                        from hierarchy_entries h1\n                          left outer join names on names.id=name_id\n                        where hierarchy_id=#{hierarchy_id.to_i} and parent_id=#{parent_id.to_i} and published=1\n                        order by string;\")\n\n    else\n      return []\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 50, "char_end": 125, "line": "    self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n"}, {"line_no": 8, "char_start": 430, "char_end": 532, "line": "                        where hierarchy_id=#{hierarchy_id} and parent_id=#{parent_id} and published=1\n"}, {"line_no": 10, "char_start": 575, "char_end": 588, "line": "          end\n"}], "added": [{"line_no": 2, "char_start": 50, "char_end": 125, "line": "    if (hierarchy_id.to_i.is_a? Integer) && (parent_id.to_i.is_a? Integer)\n"}, {"line_no": 3, "char_start": 125, "char_end": 202, "line": "      self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n"}, {"line_no": 9, "char_start": 507, "char_end": 619, "line": "                        where hierarchy_id=#{hierarchy_id.to_i} and parent_id=#{parent_id.to_i} and published=1\n"}, {"line_no": 11, "char_start": 662, "char_end": 663, "line": "\n"}, {"line_no": 12, "char_start": 663, "char_end": 672, "line": "    else\n"}, {"line_no": 13, "char_start": 672, "char_end": 688, "line": "      return []\n"}, {"line_no": 14, "char_start": 688, "char_end": 696, "line": "    end\n"}, {"line_no": 15, "char_start": 696, "char_end": 701, "line": "  end\n"}]}, "char_changes": {"deleted": [{"char_start": 579, "char_end": 583, "chars": "    "}], "added": [{"char_start": 50, "char_end": 127, "chars": "    if (hierarchy_id.to_i.is_a? Integer) && (parent_id.to_i.is_a? Integer)\n  "}, {"char_start": 564, "char_end": 569, "chars": ".to_i"}, {"char_start": 596, "char_end": 601, "chars": ".to_i"}, {"char_start": 662, "char_end": 663, "chars": "\n"}, {"char_start": 667, "char_end": 696, "chars": "else\n      return []\n    end\n"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Write a Ruby method to query a database for sibling entries based on a hierarchy ID and a parent ID."}
{"func_name": "ParseMPLSLabelStack", "func_src_before": "func ParseMPLSLabelStack(buf string) (*MPLSLabelStack, error) {\n\telems := strings.Split(buf, \"/\")\n\tlabels := make([]uint32, 0, len(elems))\n\tif len(elems) == 0 {\n\t\tgoto ERR\n\t}\n\tfor _, elem := range elems {\n\t\ti, err := strconv.Atoi(elem)\n\t\tif err != nil {\n\t\t\tgoto ERR\n\t\t}\n\t\tif i < 0 || i > ((1<<20)-1) {\n\t\t\tgoto ERR\n\t\t}\n\t\tlabels = append(labels, uint32(i))\n\t}\n\treturn NewMPLSLabelStack(labels...), nil\nERR:\n\treturn nil, NewMessageError(BGP_ERROR_UPDATE_MESSAGE_ERROR, BGP_ERROR_SUB_MALFORMED_ATTRIBUTE_LIST, nil, \"invalid mpls label stack format\")\n}", "func_src_after": "func ParseMPLSLabelStack(buf string) (*MPLSLabelStack, error) {\n\telems := strings.Split(buf, \"/\")\n\tlabels := make([]uint32, 0, len(elems))\n\tif len(elems) == 0 {\n\t\tgoto ERR\n\t}\n\tfor _, elem := range elems {\n\t\ti, err := strconv.ParseUint(elem, 10, 32)\n\t\tif err != nil {\n\t\t\tgoto ERR\n\t\t}\n\t\tif i > ((1 << 20) - 1) {\n\t\t\tgoto ERR\n\t\t}\n\t\tlabels = append(labels, uint32(i))\n\t}\n\treturn NewMPLSLabelStack(labels...), nil\nERR:\n\treturn nil, NewMessageError(BGP_ERROR_UPDATE_MESSAGE_ERROR, BGP_ERROR_SUB_MALFORMED_ATTRIBUTE_LIST, nil, \"invalid mpls label stack format\")\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 205, "char_end": 236, "line": "\t\ti, err := strconv.Atoi(elem)\n"}, {"line_no": 12, "char_start": 270, "char_end": 302, "line": "\t\tif i < 0 || i > ((1<<20)-1) {\n"}], "added": [{"line_no": 8, "char_start": 205, "char_end": 249, "line": "\t\ti, err := strconv.ParseUint(elem, 10, 32)\n"}, {"line_no": 12, "char_start": 283, "char_end": 310, "line": "\t\tif i > ((1 << 20) - 1) {\n"}]}, "char_changes": {"deleted": [{"char_start": 225, "char_end": 234, "chars": "Atoi(elem"}, {"char_start": 274, "char_end": 283, "chars": " i < 0 ||"}, {"char_start": 296, "char_end": 297, "chars": "-"}], "added": [{"char_start": 225, "char_end": 247, "chars": "ParseUint(elem, 10, 32"}, {"char_start": 295, "char_end": 296, "chars": " "}, {"char_start": 298, "char_end": 299, "chars": " "}, {"char_start": 302, "char_end": 305, "chars": " - "}]}, "commit_link": "github.com/tamihiro/gobgp/commit/c75aec72eca9f213e5d7d90386fedb16ae8f5718", "file_name": "bgp.go", "vul_type": "cwe-681", "commit_msg": "packet/bgp: use strconv.ParseUint instead of strconv.Atoi()\n\nAtoi() returns a signed int. On a 32-bit platform, this is not big\nenough to fit an unsigned 32-bit int. Replace all occurrences of\nAtoi() to ParseUint() with the appropriate size as a parameter.\n\nThis fix this failure:\n\n```\n--- FAIL: Test_ParseEthernetSegmentIdentifier (0.00s)\n        Error Trace:    bgp_test.go:1181\n        Error:          Expected nil, but got: &errors.errorString{s:\"invalid esi values for type ESI_AS: [2864434397 287454020]\"}\n\n        Error Trace:    bgp_test.go:1182\n        Error:          Not equal: bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0xaa, 0xbb, 0xcc, 0xdd, 0x11, 0x22, 0x33, 0x44, 0x0}} (expected)\n                                != bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0}} (actual)\n\n                        Diff:\n                        --- Expected\n                        +++ Actual\n                        @@ -1,2 +1,2 @@\n                        -(bgp.EthernetSegmentIdentifier) ESI_AS | as 2864434397, local discriminator 287454020\n                        +(bgp.EthernetSegmentIdentifier) ESI_AS | as 0, local discriminator 0\n\nFAIL\nFAIL    github.com/osrg/gobgp/packet/bgp        0.003s\n```", "parent_commit": "51f69fe247b260fb6cb3b7f3308aa28fa430def0", "description": "Write a Go function to parse a string of MPLS labels separated by slashes into a label stack, returning an error for invalid formats."}
{"func_name": "HPHP::JSON_parser", "func_src_before": "bool JSON_parser(Variant &z, const char *p, int length, bool const assoc,\n                 int depth, int64_t options) {\n  // No GC safepoints during JSON parsing, please. Code is not re-entrant.\n  NoHandleSurpriseScope no_surprise(SafepointFlags);\n\n  json_parser *json = s_json_parser.get(); /* the parser state */\n  // Clear and reuse the thread-local string buffers. They are only freed if\n  // they exceed kMaxPersistentStringBufferCapacity at exit or if the thread\n  // is explicitly flushed (e.g., due to being idle).\n  json->initSb(length);\n  SCOPE_EXIT {\n    constexpr int kMaxPersistentStringBufferCapacity = 256 * 1024;\n    if (json->sb_cap > kMaxPersistentStringBufferCapacity) json->flushSb();\n  };\n  // SimpleParser only handles the most common set of options. Also, only use it\n  // if its array nesting depth check is *more* restrictive than what the user\n  // asks for, to ensure that the precise semantics of the general case is\n  // applied for all nesting overflows.\n  if (assoc &&\n      options == (options & (k_JSON_FB_LOOSE |\n                             k_JSON_FB_DARRAYS |\n                             k_JSON_FB_DARRAYS_AND_VARRAYS |\n                             k_JSON_FB_HACK_ARRAYS |\n                             k_JSON_FB_THRIFT_SIMPLE_JSON |\n                             k_JSON_FB_LEGACY_HACK_ARRAYS)) &&\n      depth >= SimpleParser::kMaxArrayDepth &&\n      length <= RuntimeOption::EvalSimpleJsonMaxLength &&\n      SimpleParser::TryParse(p, length, json->tl_buffer.tv, z,\n                             get_container_type_from_options(options),\n                             options & k_JSON_FB_THRIFT_SIMPLE_JSON)) {\n    return true;\n  }\n\n  int b;  /* the next character */\n  int c;  /* the next character class */\n  int s;  /* the next state */\n  int state = 0;\n\n  /*<fb>*/\n  bool const loose = options & k_JSON_FB_LOOSE;\n  JSONContainerType const container_type =\n    get_container_type_from_options(options);\n  int qchr = 0;\n  int8_t const *byte_class;\n  int8_t const (*next_state_table)[32];\n  if (loose) {\n    byte_class = loose_ascii_class;\n    next_state_table = loose_state_transition_table;\n  } else {\n    byte_class = ascii_class;\n    next_state_table = state_transition_table;\n  }\n  /*</fb>*/\n\n  UncheckedBuffer *buf = &json->sb_buf;\n  UncheckedBuffer *key = &json->sb_key;\n\n  DataType type = kInvalidDataType;\n  unsigned short escaped_bytes = 0;\n\n  auto reset_type = [&] { type = kInvalidDataType; };\n\n  json->depth = depth;\n  // Since the stack is maintainined on a per request basis, for performance\n  // reasons, it only makes sense to expand if necessary and cycles are wasted\n  // contracting. Calls with a depth other than default should be rare.\n  if (depth > json->stack.size()) {\n    json->stack.resize(depth);\n  }\n  SCOPE_EXIT {\n    if (json->stack.empty()) return;\n    for (int i = 0; i <= json->mark; i++) {\n      json->stack[i].key.reset();\n      json->stack[i].val.unset();\n    }\n    json->mark = -1;\n  };\n\n  json->mark = json->top = -1;\n  push(json, Mode::DONE);\n\n  UTF8To16Decoder decoder(p, length, loose);\n  for (;;) {\n    b = decoder.decode();\n    // Fast-case most common transition: append a simple string character.\n    if (state == 3 && type == KindOfString) {\n      while (b != '\\\"' &&  b != '\\\\' && b != '\\'' && b <= 127 && b >= ' ') {\n        buf->append((char)b);\n        b = decoder.decode();\n      }\n    }\n    if (b == UTF8_END) break; // UTF-8 decoding finishes successfully.\n    if (b == UTF8_ERROR) {\n      s_json_parser->error_code = JSON_ERROR_UTF8;\n      return false;\n    }\n    assertx(b >= 0);\n\n    if ((b & 127) == b) {\n      /*<fb>*/\n      c = byte_class[b];\n      /*</fb>*/\n      if (c <= S_ERR) {\n        s_json_parser->error_code = JSON_ERROR_CTRL_CHAR;\n        return false;\n      }\n    } else {\n      c = S_ETC;\n    }\n    /*\n      Get the next state from the transition table.\n    */\n\n    /*<fb>*/\n    s = next_state_table[state][c];\n\n    if (s == -4) {\n      if (b != qchr) {\n        s = 3;\n      } else {\n        qchr = 0;\n      }\n    }\n    /*</fb>*/\n\n    if (s < 0) {\n      /*\n        Perform one of the predefined actions.\n      */\n      switch (s) {\n        /*\n          empty }\n        */\n      case -9:\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key, assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::KEY)) {\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          {\n        */\n      case -8:\n        if (!push(json, Mode::KEY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n\n        state = 1;\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            // stable_maps is meaningless\n            top = req::make<c_Map>();\n          } else {\n          /*</fb>*/\n            if (!assoc) {\n              top = SystemLib::AllocStdClassObject();\n            /* <fb> */\n            } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n              top = Array::CreateDict();\n            } else if (container_type == JSONContainerType::DARRAYS ||\n                       container_type == JSONContainerType::DARRAYS_AND_VARRAYS)\n            {\n              top = Array::CreateDArray();\n            /* </fb> */\n            } else if (\n              container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n              auto arr = staticEmptyDictArray()->copy();\n              arr->setLegacyArray(true);\n              top = arr;\n            } else {\n              top = Array::CreateDArray();\n            }\n          /*<fb>*/\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          }\n        */\n      case -7:\n        /*** BEGIN Facebook: json_utf8_loose ***/\n        /*\n          If this is a trailing comma in an object definition,\n          we're in Mode::KEY. In that case, throw that off the\n          stack and restore Mode::OBJECT so that we pretend the\n          trailing comma just didn't happen.\n        */\n        if (loose) {\n          if (pop(json, Mode::KEY)) {\n            push(json, Mode::OBJECT);\n          }\n        }\n        /*** END Facebook: json_utf8_loose ***/\n\n        if (type != kInvalidDataType &&\n            json->stack[json->top].mode == Mode::OBJECT) {\n          Variant mval;\n          json_create_zval(mval, *buf, type, options);\n          Variant &top = json->stack[json->top].val;\n          object_set(json, top, copy_and_clear(*key),\n                     mval, assoc, container_type);\n          buf->clear();\n          reset_type();\n        }\n\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key,\n            assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::OBJECT)) {\n          s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          [\n        */\n      case -6:\n        if (!push(json, Mode::ARRAY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n        state = 2;\n\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            top = req::make<c_Vector>();\n          } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n            top = Array::CreateVec();\n          } else if (container_type == JSONContainerType::DARRAYS_AND_VARRAYS) {\n            top = Array::CreateVArray();\n          } else if (container_type == JSONContainerType::DARRAYS) {\n            top = Array::CreateDArray();\n          } else if (container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n            auto arr = staticEmptyVecArray()->copy();\n            arr->setLegacyArray(true);\n            top = arr;\n          } else {\n            top = Array::CreateDArray();\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          ]\n        */\n      case -5:\n        {\n          if (type != kInvalidDataType &&\n               json->stack[json->top].mode == Mode::ARRAY) {\n            Variant mval;\n            json_create_zval(mval, *buf, type, options);\n            auto& top = json->stack[json->top].val;\n            if (container_type == JSONContainerType::COLLECTIONS) {\n              collections::append(top.getObjectData(), mval.asTypedValue());\n            } else {\n              top.asArrRef().append(mval);\n            }\n            buf->clear();\n            reset_type();\n          }\n\n          /*<fb>*/\n          if (json->top == 1) z = json->stack[json->top].val;\n          else {\n          /*</fb>*/\n            attach_zval(json, json->stack[json->top].key, assoc,\n              container_type);\n          /*<fb>*/\n          }\n          /*</fb>*/\n          if (!pop(json, Mode::ARRAY)) {\n            s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n            return false;\n          }\n          state = 9;\n        }\n        break;\n        /*\n          \"\n        */\n      case -4:\n        switch (json->stack[json->top].mode) {\n        case Mode::KEY:\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          break;\n        case Mode::ARRAY:\n        case Mode::OBJECT:\n          state = 9;\n          break;\n        case Mode::DONE:\n          if (type == KindOfString) {\n            z = copy_and_clear(*buf);\n            state = 9;\n            break;\n          }\n          /* fall through if not KindOfString */\n        default:\n          s_json_parser->error_code = JSON_ERROR_SYNTAX;\n          return false;\n        }\n        break;\n        /*\n          ,\n        */\n      case -3:\n        {\n          Variant mval;\n          if (type != kInvalidDataType &&\n              (json->stack[json->top].mode == Mode::OBJECT ||\n               json->stack[json->top].mode == Mode::ARRAY)) {\n            json_create_zval(mval, *buf, type, options);\n          }\n\n          switch (json->stack[json->top].mode) {\n          case Mode::OBJECT:\n            if (pop(json, Mode::OBJECT) &&\n                push(json, Mode::KEY)) {\n              if (type != kInvalidDataType) {\n                Variant &top = json->stack[json->top].val;\n                object_set(\n                  json,\n                  top,\n                  copy_and_clear(*key),\n                  mval,\n                  assoc,\n                  container_type\n                );\n              }\n              state = 29;\n            }\n            break;\n          case Mode::ARRAY:\n            if (type != kInvalidDataType) {\n              auto& top = json->stack[json->top].val;\n              if (container_type == JSONContainerType::COLLECTIONS) {\n                collections::append(top.getObjectData(), mval.asTypedValue());\n              } else {\n                top.asArrRef().append(mval);\n              }\n            }\n            state = 28;\n            break;\n          default:\n            s_json_parser->error_code = JSON_ERROR_SYNTAX;\n            return false;\n          }\n          buf->clear();\n          reset_type();\n          check_non_safepoint_surprise();\n        }\n        break;\n\n        /*<fb>*/\n        /*\n          : (after unquoted string)\n        */\n      case -10:\n        if (json->stack[json->top].mode == Mode::KEY) {\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          s = -2;\n        } else {\n          s = 3;\n          break;\n        }\n        /*</fb>*/\n\n        /*\n          :\n        */\n      case -2:\n        if (pop(json, Mode::KEY) && push(json, Mode::OBJECT)) {\n          state = 28;\n          break;\n        }\n        /*\n          syntax error\n        */\n      case -1:\n        s_json_parser->error_code = JSON_ERROR_SYNTAX;\n        return false;\n      }\n    } else {\n      /*\n        Change the state and iterate.\n      */\n      bool is_tsimplejson = options & k_JSON_FB_THRIFT_SIMPLE_JSON;\n      if (type == KindOfString) {\n        if (/*<fb>*/(/*</fb>*/s == 3/*<fb>*/ || s == 30)/*</fb>*/ &&\n            state != 8) {\n          if (state != 4) {\n            utf16_to_utf8(*buf, b);\n          } else {\n            switch (b) {\n            case 'b': buf->append('\\b'); break;\n            case 't': buf->append('\\t'); break;\n            case 'n': buf->append('\\n'); break;\n            case 'f': buf->append('\\f'); break;\n            case 'r': buf->append('\\r'); break;\n            default:\n              utf16_to_utf8(*buf, b);\n              break;\n            }\n          }\n        } else if (s == 6) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n            escaped_bytes = 0;\n          } else {\n            escaped_bytes = dehexchar(b) << 12;\n          }\n        } else if (s == 7) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n          } else {\n            escaped_bytes += dehexchar(b) << 8;\n          }\n        } else if (s == 8) {\n          escaped_bytes += dehexchar(b) << 4;\n        } else if (s == 3 && state == 8) {\n          escaped_bytes += dehexchar(b);\n          if (UNLIKELY(is_tsimplejson)) {\n            buf->append((char)escaped_bytes);\n          } else {\n            utf16_to_utf8(*buf, escaped_bytes);\n          }\n        }\n      } else if ((type == kInvalidDataType || type == KindOfNull) &&\n                 (c == S_DIG || c == S_ZER)) {\n        type = KindOfInt64;\n        buf->append((char)b);\n      } else if (type == KindOfInt64 && s == 24) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64) &&\n                 c == S_DOT) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if (type != KindOfString && c == S_QUO) {\n        type = KindOfString;\n        /*<fb>*/qchr = b;/*</fb>*/\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64 || type == KindOfDouble) &&\n                 ((state == 12 && s == 9) ||\n                  (state == 16 && s == 9))) {\n        type = KindOfBoolean;\n      } else if (type == kInvalidDataType && state == 19 && s == 9) {\n        type = KindOfNull;\n      } else if (type != KindOfString && c > S_WSP) {\n        utf16_to_utf8(*buf, b);\n      }\n\n      state = s;\n    }\n  }\n\n  if (state == 9 && pop(json, Mode::DONE)) {\n    s_json_parser->error_code = JSON_ERROR_NONE;\n    return true;\n  }\n\n  s_json_parser->error_code = JSON_ERROR_SYNTAX;\n  return false;\n}", "func_src_after": "bool JSON_parser(Variant &z, const char *p, int length, bool const assoc,\n                 int depth, int64_t options) {\n  // No GC safepoints during JSON parsing, please. Code is not re-entrant.\n  NoHandleSurpriseScope no_surprise(SafepointFlags);\n\n  json_parser *json = s_json_parser.get(); /* the parser state */\n  // Clear and reuse the thread-local string buffers. They are only freed if\n  // they exceed kMaxPersistentStringBufferCapacity at exit or if the thread\n  // is explicitly flushed (e.g., due to being idle).\n  json->initSb(length);\n  if (depth <= 0) {\n    json->error_code = json_error_codes::JSON_ERROR_DEPTH;\n    return false;\n  }\n  SCOPE_EXIT {\n    constexpr int kMaxPersistentStringBufferCapacity = 256 * 1024;\n    if (json->sb_cap > kMaxPersistentStringBufferCapacity) json->flushSb();\n  };\n  // SimpleParser only handles the most common set of options. Also, only use it\n  // if its array nesting depth check is *more* restrictive than what the user\n  // asks for, to ensure that the precise semantics of the general case is\n  // applied for all nesting overflows.\n  if (assoc &&\n      options == (options & (k_JSON_FB_LOOSE |\n                             k_JSON_FB_DARRAYS |\n                             k_JSON_FB_DARRAYS_AND_VARRAYS |\n                             k_JSON_FB_HACK_ARRAYS |\n                             k_JSON_FB_THRIFT_SIMPLE_JSON |\n                             k_JSON_FB_LEGACY_HACK_ARRAYS)) &&\n      depth >= SimpleParser::kMaxArrayDepth &&\n      length <= RuntimeOption::EvalSimpleJsonMaxLength &&\n      SimpleParser::TryParse(p, length, json->tl_buffer.tv, z,\n                             get_container_type_from_options(options),\n                             options & k_JSON_FB_THRIFT_SIMPLE_JSON)) {\n    return true;\n  }\n\n  int b;  /* the next character */\n  int c;  /* the next character class */\n  int s;  /* the next state */\n  int state = 0;\n\n  /*<fb>*/\n  bool const loose = options & k_JSON_FB_LOOSE;\n  JSONContainerType const container_type =\n    get_container_type_from_options(options);\n  int qchr = 0;\n  int8_t const *byte_class;\n  int8_t const (*next_state_table)[32];\n  if (loose) {\n    byte_class = loose_ascii_class;\n    next_state_table = loose_state_transition_table;\n  } else {\n    byte_class = ascii_class;\n    next_state_table = state_transition_table;\n  }\n  /*</fb>*/\n\n  UncheckedBuffer *buf = &json->sb_buf;\n  UncheckedBuffer *key = &json->sb_key;\n\n  DataType type = kInvalidDataType;\n  unsigned short escaped_bytes = 0;\n\n  auto reset_type = [&] { type = kInvalidDataType; };\n\n  json->depth = depth;\n  // Since the stack is maintainined on a per request basis, for performance\n  // reasons, it only makes sense to expand if necessary and cycles are wasted\n  // contracting. Calls with a depth other than default should be rare.\n  if (depth > json->stack.size()) {\n    json->stack.resize(depth);\n  }\n  SCOPE_EXIT {\n    if (json->stack.empty()) return;\n    for (int i = 0; i <= json->mark; i++) {\n      json->stack[i].key.reset();\n      json->stack[i].val.unset();\n    }\n    json->mark = -1;\n  };\n\n  json->mark = json->top = -1;\n  push(json, Mode::DONE);\n\n  UTF8To16Decoder decoder(p, length, loose);\n  for (;;) {\n    b = decoder.decode();\n    // Fast-case most common transition: append a simple string character.\n    if (state == 3 && type == KindOfString) {\n      while (b != '\\\"' &&  b != '\\\\' && b != '\\'' && b <= 127 && b >= ' ') {\n        buf->append((char)b);\n        b = decoder.decode();\n      }\n    }\n    if (b == UTF8_END) break; // UTF-8 decoding finishes successfully.\n    if (b == UTF8_ERROR) {\n      s_json_parser->error_code = JSON_ERROR_UTF8;\n      return false;\n    }\n    assertx(b >= 0);\n\n    if ((b & 127) == b) {\n      /*<fb>*/\n      c = byte_class[b];\n      /*</fb>*/\n      if (c <= S_ERR) {\n        s_json_parser->error_code = JSON_ERROR_CTRL_CHAR;\n        return false;\n      }\n    } else {\n      c = S_ETC;\n    }\n    /*\n      Get the next state from the transition table.\n    */\n\n    /*<fb>*/\n    s = next_state_table[state][c];\n\n    if (s == -4) {\n      if (b != qchr) {\n        s = 3;\n      } else {\n        qchr = 0;\n      }\n    }\n    /*</fb>*/\n\n    if (s < 0) {\n      /*\n        Perform one of the predefined actions.\n      */\n      switch (s) {\n        /*\n          empty }\n        */\n      case -9:\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key, assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::KEY)) {\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          {\n        */\n      case -8:\n        if (!push(json, Mode::KEY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n\n        state = 1;\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            // stable_maps is meaningless\n            top = req::make<c_Map>();\n          } else {\n          /*</fb>*/\n            if (!assoc) {\n              top = SystemLib::AllocStdClassObject();\n            /* <fb> */\n            } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n              top = Array::CreateDict();\n            } else if (container_type == JSONContainerType::DARRAYS ||\n                       container_type == JSONContainerType::DARRAYS_AND_VARRAYS)\n            {\n              top = Array::CreateDArray();\n            /* </fb> */\n            } else if (\n              container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n              auto arr = staticEmptyDictArray()->copy();\n              arr->setLegacyArray(true);\n              top = arr;\n            } else {\n              top = Array::CreateDArray();\n            }\n          /*<fb>*/\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          }\n        */\n      case -7:\n        /*** BEGIN Facebook: json_utf8_loose ***/\n        /*\n          If this is a trailing comma in an object definition,\n          we're in Mode::KEY. In that case, throw that off the\n          stack and restore Mode::OBJECT so that we pretend the\n          trailing comma just didn't happen.\n        */\n        if (loose) {\n          if (pop(json, Mode::KEY)) {\n            push(json, Mode::OBJECT);\n          }\n        }\n        /*** END Facebook: json_utf8_loose ***/\n\n        if (type != kInvalidDataType &&\n            json->stack[json->top].mode == Mode::OBJECT) {\n          Variant mval;\n          json_create_zval(mval, *buf, type, options);\n          Variant &top = json->stack[json->top].val;\n          object_set(json, top, copy_and_clear(*key),\n                     mval, assoc, container_type);\n          buf->clear();\n          reset_type();\n        }\n\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key,\n            assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::OBJECT)) {\n          s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          [\n        */\n      case -6:\n        if (!push(json, Mode::ARRAY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n        state = 2;\n\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            top = req::make<c_Vector>();\n          } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n            top = Array::CreateVec();\n          } else if (container_type == JSONContainerType::DARRAYS_AND_VARRAYS) {\n            top = Array::CreateVArray();\n          } else if (container_type == JSONContainerType::DARRAYS) {\n            top = Array::CreateDArray();\n          } else if (container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n            auto arr = staticEmptyVecArray()->copy();\n            arr->setLegacyArray(true);\n            top = arr;\n          } else {\n            top = Array::CreateDArray();\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          ]\n        */\n      case -5:\n        {\n          if (type != kInvalidDataType &&\n               json->stack[json->top].mode == Mode::ARRAY) {\n            Variant mval;\n            json_create_zval(mval, *buf, type, options);\n            auto& top = json->stack[json->top].val;\n            if (container_type == JSONContainerType::COLLECTIONS) {\n              collections::append(top.getObjectData(), mval.asTypedValue());\n            } else {\n              top.asArrRef().append(mval);\n            }\n            buf->clear();\n            reset_type();\n          }\n\n          /*<fb>*/\n          if (json->top == 1) z = json->stack[json->top].val;\n          else {\n          /*</fb>*/\n            attach_zval(json, json->stack[json->top].key, assoc,\n              container_type);\n          /*<fb>*/\n          }\n          /*</fb>*/\n          if (!pop(json, Mode::ARRAY)) {\n            s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n            return false;\n          }\n          state = 9;\n        }\n        break;\n        /*\n          \"\n        */\n      case -4:\n        switch (json->stack[json->top].mode) {\n        case Mode::KEY:\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          break;\n        case Mode::ARRAY:\n        case Mode::OBJECT:\n          state = 9;\n          break;\n        case Mode::DONE:\n          if (type == KindOfString) {\n            z = copy_and_clear(*buf);\n            state = 9;\n            break;\n          }\n          /* fall through if not KindOfString */\n        default:\n          s_json_parser->error_code = JSON_ERROR_SYNTAX;\n          return false;\n        }\n        break;\n        /*\n          ,\n        */\n      case -3:\n        {\n          Variant mval;\n          if (type != kInvalidDataType &&\n              (json->stack[json->top].mode == Mode::OBJECT ||\n               json->stack[json->top].mode == Mode::ARRAY)) {\n            json_create_zval(mval, *buf, type, options);\n          }\n\n          switch (json->stack[json->top].mode) {\n          case Mode::OBJECT:\n            if (pop(json, Mode::OBJECT) &&\n                push(json, Mode::KEY)) {\n              if (type != kInvalidDataType) {\n                Variant &top = json->stack[json->top].val;\n                object_set(\n                  json,\n                  top,\n                  copy_and_clear(*key),\n                  mval,\n                  assoc,\n                  container_type\n                );\n              }\n              state = 29;\n            }\n            break;\n          case Mode::ARRAY:\n            if (type != kInvalidDataType) {\n              auto& top = json->stack[json->top].val;\n              if (container_type == JSONContainerType::COLLECTIONS) {\n                collections::append(top.getObjectData(), mval.asTypedValue());\n              } else {\n                top.asArrRef().append(mval);\n              }\n            }\n            state = 28;\n            break;\n          default:\n            s_json_parser->error_code = JSON_ERROR_SYNTAX;\n            return false;\n          }\n          buf->clear();\n          reset_type();\n          check_non_safepoint_surprise();\n        }\n        break;\n\n        /*<fb>*/\n        /*\n          : (after unquoted string)\n        */\n      case -10:\n        if (json->stack[json->top].mode == Mode::KEY) {\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          s = -2;\n        } else {\n          s = 3;\n          break;\n        }\n        /*</fb>*/\n\n        /*\n          :\n        */\n      case -2:\n        if (pop(json, Mode::KEY) && push(json, Mode::OBJECT)) {\n          state = 28;\n          break;\n        }\n        /*\n          syntax error\n        */\n      case -1:\n        s_json_parser->error_code = JSON_ERROR_SYNTAX;\n        return false;\n      }\n    } else {\n      /*\n        Change the state and iterate.\n      */\n      bool is_tsimplejson = options & k_JSON_FB_THRIFT_SIMPLE_JSON;\n      if (type == KindOfString) {\n        if (/*<fb>*/(/*</fb>*/s == 3/*<fb>*/ || s == 30)/*</fb>*/ &&\n            state != 8) {\n          if (state != 4) {\n            utf16_to_utf8(*buf, b);\n          } else {\n            switch (b) {\n            case 'b': buf->append('\\b'); break;\n            case 't': buf->append('\\t'); break;\n            case 'n': buf->append('\\n'); break;\n            case 'f': buf->append('\\f'); break;\n            case 'r': buf->append('\\r'); break;\n            default:\n              utf16_to_utf8(*buf, b);\n              break;\n            }\n          }\n        } else if (s == 6) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n            escaped_bytes = 0;\n          } else {\n            escaped_bytes = dehexchar(b) << 12;\n          }\n        } else if (s == 7) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n          } else {\n            escaped_bytes += dehexchar(b) << 8;\n          }\n        } else if (s == 8) {\n          escaped_bytes += dehexchar(b) << 4;\n        } else if (s == 3 && state == 8) {\n          escaped_bytes += dehexchar(b);\n          if (UNLIKELY(is_tsimplejson)) {\n            buf->append((char)escaped_bytes);\n          } else {\n            utf16_to_utf8(*buf, escaped_bytes);\n          }\n        }\n      } else if ((type == kInvalidDataType || type == KindOfNull) &&\n                 (c == S_DIG || c == S_ZER)) {\n        type = KindOfInt64;\n        buf->append((char)b);\n      } else if (type == KindOfInt64 && s == 24) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64) &&\n                 c == S_DOT) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if (type != KindOfString && c == S_QUO) {\n        type = KindOfString;\n        /*<fb>*/qchr = b;/*</fb>*/\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64 || type == KindOfDouble) &&\n                 ((state == 12 && s == 9) ||\n                  (state == 16 && s == 9))) {\n        type = KindOfBoolean;\n      } else if (type == kInvalidDataType && state == 19 && s == 9) {\n        type = KindOfNull;\n      } else if (type != KindOfString && c > S_WSP) {\n        utf16_to_utf8(*buf, b);\n      }\n\n      state = s;\n    }\n  }\n\n  if (state == 9 && pop(json, Mode::DONE)) {\n    s_json_parser->error_code = JSON_ERROR_NONE;\n    return true;\n  }\n\n  s_json_parser->error_code = JSON_ERROR_SYNTAX;\n  return false;\n}", "commit_link": "github.com/facebook/hhvm/commit/dabd48caf74995e605f1700344f1ff4a5d83441d", "file_name": "hphp/runtime/ext/json/JSON_parser.cpp", "vul_type": "cwe-125", "description": "Write a JSON parsing function in C++."}
{"func_name": "copyIPv6IfDifferent", "func_src_before": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "func_src_after": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src && src != NULL) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/cb8a02af7a5677cf608e86d57ab04241cf34e24f", "file_name": "miniupnpd/pcpserver.c", "vul_type": "cwe-476", "description": "Write a C function named `copyIPv6IfDifferent` that copies an IPv6 address from source to destination if they are different, with the second version also checking if the source is not NULL."}
{"func_name": "authDigestNonceLink", "func_src_before": "authDigestNonceLink(digest_nonce_h * nonce)\n{\n    assert(nonce != NULL);\n    ++nonce->references;\n    debugs(29, 9, \"nonce '\" << nonce << \"' now at '\" << nonce->references << \"'.\");\n}", "func_src_after": "authDigestNonceLink(digest_nonce_h * nonce)\n{\n    assert(nonce != NULL);\n    ++nonce->references;\n    assert(nonce->references != 0); // no overflows\n    debugs(29, 9, \"nonce '\" << nonce << \"' now at '\" << nonce->references << \"'.\");\n}", "commit_link": "github.com/squid-cache/squid/commit/eeebf0f37a72a2de08348e85ae34b02c34e9a811", "file_name": "src/auth/digest/Config.cc", "vul_type": "cwe-190", "description": "Write a C++ function named `authDigestNonceLink` that increments a reference counter for a given nonce object and logs the new reference count, ensuring the nonce is not null and, for the second snippet, that the reference count does not overflow."}
{"func_name": "reset_passwd", "func_src_before": "@app.route('/reset-password', methods=['GET', 'POST'])\ndef reset_passwd():\n  if request.method == 'POST':\n    if 'username' not in session:\n      flash('You did something naughty')\n      return redirect(url_for('forgot_passwd'))\n    new_password = request.form['password']\n    new_password2 = request.form['password2']\n\n    # Get the user's email\n    query = text(\"SELECT email FROM members WHERE user_id=:id\")\n    result = connection.execute(query, id=str(session['user_id']))\n    email = result.first()[0]\n\n    if new_password != new_password2:\n      flash('Passwords do not match. Please try again!')\n      return render_template('reset_password.html')\n    elif auth.passwd_reset(session['username'], new_password, connection, \\\n                           email=email):\n      session.pop('username')\n      flash('Password successfully changed.')\n      return redirect(url_for('home'))\n    else:\n      flash('An unknown problem has occured. Please contact an admin!')\n      return render_template('reset_password.html')\n  else:\n    user_id = request.args.get('u', None)\n    reset_key = request.args.get('r', None)\n    if user_id == None or reset_key == None:\n      flash(\"Missing parameter. Try generating the link again?\")\n      return redirect(url_for('forgot_passwd'))\n    query = text(\"SELECT * FROM users NATURAL JOIN members WHERE user_id=:u\")\n    result = connection.execute(query, u=str(user_id))\n    if result.returns_rows and result.rowcount != 0:\n      result_cols = result.keys()\n      row = result.first()\n      q_dict = dict(zip(result_cols, row))\n      if int(reset_key) == auth.reset_key(q_dict['passwd'], q_dict['salt'],\n                                          q_dict['username']):\n        session['username'] = q_dict['username']\n        return render_template('reset_password.html')\n      flash(\"Incorrect reset_key. Try generating the link again?\")\n    return redirect(url_for('forgot_passwd'))", "func_src_after": "@app.route('/reset-password', methods=['GET', 'POST'])\ndef reset_passwd():\n  if request.method == 'POST':\n    if 'username' not in session:\n      flash('You did something naughty')\n      return redirect(url_for('forgot_passwd'))\n    new_password = request.form['password']\n    new_password2 = request.form['password2']\n\n    # Get the user's email\n    query = text(\"SELECT email FROM members WHERE user_id=:id\")\n    result = connection.execute(query, id=str(session['user_id']))\n    email = result.first()[0]\n\n    if new_password != new_password2:\n      flash('Passwords do not match. Please try again!')\n      return render_template('reset_password.html')\n    elif auth.passwd_reset(session['username'], new_password, connection, \\\n                           email=email):\n      session.pop('username')\n      flash('Password successfully changed.')\n      return redirect(url_for('home'))\n    else:\n      flash('An unknown problem has occured. Please contact an admin!')\n      return render_template('reset_password.html')\n  else:\n    user_id = request.args.get('u', None)\n    reset_key = request.args.get('r', None)\n    if user_id == None or reset_key == None:\n      flash(\"Missing parameter. Try generating the link again?\")\n      return redirect(url_for('forgot_passwd'))\n    query = text(\"SELECT * FROM users WHERE user_id=:u\")\n    result = connection.execute(query, u=str(user_id))\n    if result.returns_rows and result.rowcount != 0:\n      result_cols = result.keys()\n      row = result.first()\n      q_dict = dict(zip(result_cols, row))\n      if int(reset_key) == auth.reset_key(q_dict['passwd'], q_dict['salt'],\n                                          q_dict['username']):\n        session['username'] = q_dict['username']\n        return render_template('reset_password.html')\n      flash(\"Incorrect reset_key. Try generating the link again?\")\n    return redirect(url_for('forgot_passwd'))", "line_changes": {"deleted": [{"line_no": 32, "char_start": 1274, "char_end": 1352, "line": "    query = text(\"SELECT * FROM users NATURAL JOIN members WHERE user_id=:u\")\n"}], "added": [{"line_no": 32, "char_start": 1274, "char_end": 1331, "line": "    query = text(\"SELECT * FROM users WHERE user_id=:u\")\n"}]}, "char_changes": {"deleted": [{"char_start": 1312, "char_end": 1333, "chars": "NATURAL JOIN members "}], "added": []}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "RuddockWebsite.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python Flask route to handle password reset functionality with form submission and user verification."}
{"func_name": "usb_get_bos_descriptor", "func_src_before": "int usb_get_bos_descriptor(struct usb_device *dev)\n{\n\tstruct device *ddev = &dev->dev;\n\tstruct usb_bos_descriptor *bos;\n\tstruct usb_dev_cap_header *cap;\n\tunsigned char *buffer;\n\tint length, total_len, num, i;\n\tint ret;\n\n\tbos = kzalloc(sizeof(struct usb_bos_descriptor), GFP_KERNEL);\n\tif (!bos)\n\t\treturn -ENOMEM;\n\n\t/* Get BOS descriptor */\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, bos, USB_DT_BOS_SIZE);\n\tif (ret < USB_DT_BOS_SIZE) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tkfree(bos);\n\t\treturn ret;\n\t}\n\n\tlength = bos->bLength;\n\ttotal_len = le16_to_cpu(bos->wTotalLength);\n\tnum = bos->bNumDeviceCaps;\n\tkfree(bos);\n\tif (total_len < length)\n\t\treturn -EINVAL;\n\n\tdev->bos = kzalloc(sizeof(struct usb_host_bos), GFP_KERNEL);\n\tif (!dev->bos)\n\t\treturn -ENOMEM;\n\n\t/* Now let's get the whole BOS descriptor set */\n\tbuffer = kzalloc(total_len, GFP_KERNEL);\n\tif (!buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tdev->bos->desc = (struct usb_bos_descriptor *)buffer;\n\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, buffer, total_len);\n\tif (ret < total_len) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor set\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tgoto err;\n\t}\n\ttotal_len -= length;\n\n\tfor (i = 0; i < num; i++) {\n\t\tbuffer += length;\n\t\tcap = (struct usb_dev_cap_header *)buffer;\n\t\tlength = cap->bLength;\n\n\t\tif (total_len < length)\n\t\t\tbreak;\n\t\ttotal_len -= length;\n\n\t\tif (cap->bDescriptorType != USB_DT_DEVICE_CAPABILITY) {\n\t\t\tdev_warn(ddev, \"descriptor type invalid, skip\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch (cap->bDevCapabilityType) {\n\t\tcase USB_CAP_TYPE_WIRELESS_USB:\n\t\t\t/* Wireless USB cap descriptor is handled by wusb */\n\t\t\tbreak;\n\t\tcase USB_CAP_TYPE_EXT:\n\t\t\tdev->bos->ext_cap =\n\t\t\t\t(struct usb_ext_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SS_CAP_TYPE:\n\t\t\tdev->bos->ss_cap =\n\t\t\t\t(struct usb_ss_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SSP_CAP_TYPE:\n\t\t\tdev->bos->ssp_cap =\n\t\t\t\t(struct usb_ssp_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase CONTAINER_ID_TYPE:\n\t\t\tdev->bos->ss_id =\n\t\t\t\t(struct usb_ss_container_id_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_PTM_CAP_TYPE:\n\t\t\tdev->bos->ptm_cap =\n\t\t\t\t(struct usb_ptm_cap_descriptor *)buffer;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr:\n\tusb_release_bos_descriptor(dev);\n\treturn ret;\n}", "func_src_after": "int usb_get_bos_descriptor(struct usb_device *dev)\n{\n\tstruct device *ddev = &dev->dev;\n\tstruct usb_bos_descriptor *bos;\n\tstruct usb_dev_cap_header *cap;\n\tunsigned char *buffer;\n\tint length, total_len, num, i;\n\tint ret;\n\n\tbos = kzalloc(sizeof(struct usb_bos_descriptor), GFP_KERNEL);\n\tif (!bos)\n\t\treturn -ENOMEM;\n\n\t/* Get BOS descriptor */\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, bos, USB_DT_BOS_SIZE);\n\tif (ret < USB_DT_BOS_SIZE) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tkfree(bos);\n\t\treturn ret;\n\t}\n\n\tlength = bos->bLength;\n\ttotal_len = le16_to_cpu(bos->wTotalLength);\n\tnum = bos->bNumDeviceCaps;\n\tkfree(bos);\n\tif (total_len < length)\n\t\treturn -EINVAL;\n\n\tdev->bos = kzalloc(sizeof(struct usb_host_bos), GFP_KERNEL);\n\tif (!dev->bos)\n\t\treturn -ENOMEM;\n\n\t/* Now let's get the whole BOS descriptor set */\n\tbuffer = kzalloc(total_len, GFP_KERNEL);\n\tif (!buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tdev->bos->desc = (struct usb_bos_descriptor *)buffer;\n\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, buffer, total_len);\n\tif (ret < total_len) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor set\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tgoto err;\n\t}\n\ttotal_len -= length;\n\n\tfor (i = 0; i < num; i++) {\n\t\tbuffer += length;\n\t\tcap = (struct usb_dev_cap_header *)buffer;\n\n\t\tif (total_len < sizeof(*cap) || total_len < cap->bLength) {\n\t\t\tdev->bos->desc->bNumDeviceCaps = i;\n\t\t\tbreak;\n\t\t}\n\t\tlength = cap->bLength;\n\t\ttotal_len -= length;\n\n\t\tif (cap->bDescriptorType != USB_DT_DEVICE_CAPABILITY) {\n\t\t\tdev_warn(ddev, \"descriptor type invalid, skip\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch (cap->bDevCapabilityType) {\n\t\tcase USB_CAP_TYPE_WIRELESS_USB:\n\t\t\t/* Wireless USB cap descriptor is handled by wusb */\n\t\t\tbreak;\n\t\tcase USB_CAP_TYPE_EXT:\n\t\t\tdev->bos->ext_cap =\n\t\t\t\t(struct usb_ext_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SS_CAP_TYPE:\n\t\t\tdev->bos->ss_cap =\n\t\t\t\t(struct usb_ss_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SSP_CAP_TYPE:\n\t\t\tdev->bos->ssp_cap =\n\t\t\t\t(struct usb_ssp_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase CONTAINER_ID_TYPE:\n\t\t\tdev->bos->ss_id =\n\t\t\t\t(struct usb_ss_container_id_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_PTM_CAP_TYPE:\n\t\t\tdev->bos->ptm_cap =\n\t\t\t\t(struct usb_ptm_cap_descriptor *)buffer;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr:\n\tusb_release_bos_descriptor(dev);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/1c0edc3633b56000e18d82fc241e3995ca18a69e", "file_name": "drivers/usb/core/config.c", "vul_type": "cwe-125", "description": "Write a C function named `usb_get_bos_descriptor` that retrieves the Binary Object Store (BOS) descriptor for a USB device."}
{"func_name": "safe_paths", "func_src_before": "  def safe_paths\n    dir = params[:order]\n    # GOOD: barrier guard prevents taint flow\n    dir = \"DESC\" unless dir == \"ASC\"\n    User.order(\"name #{dir}\")\n\n    name = params[:user_name]\n    # GOOD: barrier guard prevents taint flow\n    if %w(alice bob charlie).include? name\n      User.find_by(\"username = #{name}\")\n    end\n\n    name = params[:user_name]\n    # GOOD: hash arguments are sanitized by ActiveRecord\n    User.find_by(user_name: name)\n\n    # OK: `find` method is overridden in `User`\n    User.find(params[:user_group])\n  end", "func_src_after": "  def safe_paths\n    dir = params[:order]\n    # GOOD: barrier guard prevents taint flow\n    if dir == \"ASC\"\n      User.order(\"name #{dir}\")\n    else\n      dir = \"DESC\"\n      User.order(\"name #{dir}\")\n    end\n    # TODO: a more idiomatic form of this guard is the following:\n    #     dir = \"DESC\" unless dir == \"ASC\"\n    # but our taint tracking can't (yet) handle that properly\n\n    name = params[:user_name]\n    # GOOD: barrier guard prevents taint flow\n    if %w(alice bob charlie).include? name\n      User.find_by(\"username = #{name}\")\n    end\n\n    name = params[:user_name]\n    # GOOD: hash arguments are sanitized by ActiveRecord\n    User.find_by(user_name: name)\n\n    # OK: `find` method is overridden in `User`\n    User.find(params[:user_group])\n  end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 88, "char_end": 125, "line": "    dir = \"DESC\" unless dir == \"ASC\"\n"}, {"line_no": 5, "char_start": 125, "char_end": 155, "line": "    User.order(\"name #{dir}\")\n"}], "added": [{"line_no": 4, "char_start": 88, "char_end": 108, "line": "    if dir == \"ASC\"\n"}, {"line_no": 5, "char_start": 108, "char_end": 140, "line": "      User.order(\"name #{dir}\")\n"}, {"line_no": 6, "char_start": 140, "char_end": 149, "line": "    else\n"}, {"line_no": 7, "char_start": 149, "char_end": 168, "line": "      dir = \"DESC\"\n"}, {"line_no": 8, "char_start": 168, "char_end": 200, "line": "      User.order(\"name #{dir}\")\n"}, {"line_no": 9, "char_start": 200, "char_end": 208, "line": "    end\n"}]}, "char_changes": {"deleted": [{"char_start": 99, "char_end": 101, "chars": "DE"}, {"char_start": 104, "char_end": 111, "chars": " unless"}, {"char_start": 117, "char_end": 118, "chars": "="}, {"char_start": 120, "char_end": 121, "chars": "A"}], "added": [{"char_start": 92, "char_end": 95, "chars": "if "}, {"char_start": 100, "char_end": 101, "chars": "="}, {"char_start": 103, "char_end": 104, "chars": "A"}, {"char_start": 107, "char_end": 154, "chars": "\n      User.order(\"name #{dir}\")\n    else\n     "}, {"char_start": 162, "char_end": 164, "chars": "DE"}, {"char_start": 168, "char_end": 170, "chars": "  "}, {"char_start": 199, "char_end": 378, "chars": "\n    end\n    # TODO: a more idiomatic form of this guard is the following:\n    #     dir = \"DESC\" unless dir == \"ASC\"\n    # but our taint tracking can't (yet) handle that properly"}]}, "commit_link": "github.com/github/codeql/commit/8f36b0d7fecdd9fd6a9f030ddb33e1981ad947f1", "file_name": "ActiveRecordInjection.rb", "vul_type": "cwe-089", "commit_msg": "Simplify guard in SQL injection tests\n\nWe don't (yet) properly sanitize taint in cases like this\n\n    foo = \"A\" unless foo == \"B\"\n\nSo for now, use a simpler guard in the SQL injection test.\nWe can resurrect the old, more idiomatic guard when we can support it.", "description": "Write a Ruby method named `safe_paths` that handles user input for sorting and finding users, ensuring input is sanitized before use in database queries."}
{"func_name": "errorf", "func_src_before": "func (v *VM) errorf(format string, args ...interface{}) {\n\ti := v.prog[v.t.pc-1]\n\tprogRuntimeErrors.Add(v.name, 1)\n\tv.runtimeErrorMu.Lock()\n\tv.runtimeError = fmt.Sprintf(format+\"\\n\", args...)\n\tv.runtimeError += fmt.Sprintf(\n\t\t\"Error occurred at instruction %d {%s, %v}, originating in %s at line %d\\n\",\n\t\tv.t.pc-1, i.Opcode, i.Operand, v.name, i.SourceLine+1)\n\tv.runtimeError += fmt.Sprintf(\"Full input text from %q was %q\", v.input.Filename, v.input.Line)\n\tif *runtimeLogError || bool(glog.V(1)) {\n\t\tglog.Info(v.name + \": Runtime error: \" + v.runtimeError)\n\n\t\tglog.Infof(\"Set logging verbosity higher (-v1 or more) to see full VM state dump.\")\n\t}\n\tif glog.V(1) {\n\t\tglog.Infof(\"VM stack:\\n%s\", debug.Stack())\n\t\tglog.Infof(\"Dumping vm state\")\n\t\tglog.Infof(\"Name: %s\", v.name)\n\t\tglog.Infof(\"Input: %#v\", v.input)\n\t\tglog.Infof(\"Thread:\")\n\t\tglog.Infof(\" PC %v\", v.t.pc-1)\n\t\tglog.Infof(\" Matched %v\", v.t.matched)\n\t\tglog.Infof(\" Matches %v\", v.t.matches)\n\t\tglog.Infof(\" Timestamp %v\", v.t.time)\n\t\tglog.Infof(\" Stack %v\", v.t.stack)\n\t\tglog.Infof(v.DumpByteCode(v.name))\n\t}\n\tv.runtimeErrorMu.Unlock()\n\tv.terminate = true\n}", "func_src_after": "func (v *VM) errorf(format string, args ...interface{}) {\n\ti := v.prog[v.t.pc-1]\n\tprogRuntimeErrors.Add(v.name, 1)\n\tv.runtimeErrorMu.Lock()\n\tv.runtimeError = fmt.Sprintf(format+\"\\n\", args...)\n\tv.runtimeError += fmt.Sprintf(\n\t\t\"Error occurred at instruction %d {%s, %v}, originating in %s at line %d\\n\",\n\t\tv.t.pc-1, i.Opcode, i.Operand, v.name, i.SourceLine+1)\n\tv.runtimeError += fmt.Sprintf(\"Full input text from %q was %q\", v.input.Filename, v.input.Line)\n\tif *runtimeLogError || bool(glog.V(1)) {\n\t\tglog.Info(v.name + \": Runtime error: \" + v.runtimeError)\n\n\t\tglog.Infof(\"Set logging verbosity higher (-v1 or more) to see full VM state dump.\")\n\t}\n\tif glog.V(1) {\n\t\tglog.Infof(\"VM stack:\\n%s\", debug.Stack())\n\t\tglog.Infof(\"Dumping vm state\")\n\t\tglog.Infof(\"Name: %s\", v.name)\n\t\tglog.Infof(\"Input: %#v\", v.input)\n\t\tglog.Infof(\"Thread:\")\n\t\tglog.Infof(\" PC %v\", v.t.pc-1)\n\t\tglog.Infof(\" Matched %v\", v.t.matched)\n\t\tglog.Infof(\" Matches %v\", v.t.matches)\n\t\tglog.Infof(\" Timestamp %v\", v.t.time)\n\t\tglog.Infof(\" Stack %v\", v.t.stack)\n\t\tglog.Infof(v.DumpByteCode())\n\t}\n\tv.runtimeErrorMu.Unlock()\n\tv.terminate = true\n}", "line_changes": {"deleted": [{"line_no": 26, "char_start": 1027, "char_end": 1064, "line": "\t\tglog.Infof(v.DumpByteCode(v.name))\n"}], "added": [{"line_no": 26, "char_start": 1027, "char_end": 1058, "line": "\t\tglog.Infof(v.DumpByteCode())\n"}]}, "char_changes": {"deleted": [{"char_start": 1055, "char_end": 1061, "chars": "v.name"}], "added": []}, "commit_link": "github.com/SuperQ/mtail/commit/a90de206158775716feb1f0a1b36636301cd14fa", "file_name": "vm.go", "vul_type": "cwe-079", "commit_msg": "Don't need to pass the name of the prog to the prog dumper.\n\nIt already knows what the name is, and CodeQL thinks this is an XSS.", "parent_commit": "28a3000450fa7a2a34df95ff656db845139606be", "description": "Write a Go function that logs a formatted runtime error and VM state for a virtual machine object."}
{"func_name": "(anonymous)", "func_src_before": "        $('#frm_endpoint').on('submit', (e) => {\n            e.preventDefault();\n            const server_url = $server_url.val().trim().toLowerCase();\n            const app_id     = $app_id.val().trim();\n            if (server_url) localStorage.setItem('config.server_url', server_url);\n            if (app_id && !isNaN(app_id)) localStorage.setItem('config.app_id', parseInt(app_id));\n            window.location.reload();\n        });", "func_src_after": "        $('#frm_endpoint').on('submit', (e) => {\n            e.preventDefault();\n            const server_url = $server_url.val().trim().toLowerCase().replace(/[><()\\/\\\"\\']/g, '');\n            const app_id     = $app_id.val().trim();\n            if (server_url) localStorage.setItem('config.server_url', server_url);\n            if (app_id && !isNaN(app_id)) localStorage.setItem('config.app_id', parseInt(app_id));\n            window.location.reload();\n        });", "line_changes": {"deleted": [{"line_no": 3, "char_start": 81, "char_end": 152, "line": "            const server_url = $server_url.val().trim().toLowerCase();\n"}], "added": [{"line_no": 3, "char_start": 81, "char_end": 181, "line": "            const server_url = $server_url.val().trim().toLowerCase().replace(/[><()\\/\\\"\\']/g, '');\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 150, "char_end": 179, "chars": ".replace(/[><()\\/\\\"\\']/g, '')"}]}, "commit_link": "github.com/kellybinary/binary-static/commit/5f633fa51eefb648798daaa4d4950e24c5d86909", "file_name": "endpoint.js", "vul_type": "cwe-079", "commit_msg": "Shashank/XSS Fix\n\nThe endpoint accepts user input value directly. This resulted in an XSS vulnerability.", "description": "Write a JavaScript function that handles a form submission by storing trimmed input values in local storage and then reloads the page."}
{"func_name": "createItem", "func_src_before": "\t\t\tfunction createItem(element,checked){\n\t\t\t\telement=$(element);\n\t\t\t\tvar item=element.val();\n\t\t\t\tvar id='ms'+multiSelectId+'-option-'+item;\n\t\t\t\tvar input=$('<input id=\"'+id+'\" type=\"checkbox\"/>');\n\t\t\t\tvar label=$('<label for=\"'+id+'\">'+item+'</label>');\n\t\t\t\tif(settings.checked.indexOf(item)!=-1 || checked){\n\t\t\t\t\tinput.attr('checked',true);\n\t\t\t\t}\n\t\t\t\tif(checked){\n\t\t\t\t\tsettings.checked.push(item);\n\t\t\t\t}\n\t\t\t\tinput.change(function(){\n\t\t\t\t\tvar groupname=$(this).next().text();\n\t\t\t\t\tif($(this).is(':checked')){\n\t\t\t\t\t\telement.attr('selected','selected');\n\t\t\t\t\t\tif(settings.oncheck){\n\t\t\t\t\t\t\tif(settings.oncheck(groupname)===false){\n\t\t\t\t\t\t\t\t$(this).attr('checked', false);\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsettings.checked.push(groupname);\n\t\t\t\t\t}else{\n\t\t\t\t\t\tvar index=settings.checked.indexOf(groupname);\n\t\t\t\t\t\telement.attr('selected',null);\n\t\t\t\t\t\tif(settings.onuncheck){\n\t\t\t\t\t\t\tif(settings.onuncheck(groupname)===false){\n\t\t\t\t\t\t\t\t$(this).attr('checked',true);\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsettings.checked.splice(index,1);\n\t\t\t\t\t}\n\t\t\t\t\tvar oldWidth=button.width();\n\t\t\t\t\tif(settings.checked.length>0){\n\t\t\t\t\t\tbutton.children('span').first().text(settings.checked.join(', '));\n\t\t\t\t\t}else{\n\t\t\t\t\t\tbutton.children('span').first().text(settings.title);\n\t\t\t\t\t}\n\t\t\t\t\tvar newOuterWidth=Math.max((button.outerWidth()-2),settings.minOuterWidth)+'px';\n\t\t\t\t\tvar newWidth=Math.max(button.width(),settings.minWidth);\n\t\t\t\t\tvar pos=button.position();\n\t\t\t\t\tbutton.css('height',button.height());\n\t\t\t\t\tbutton.css('white-space','nowrap');\n\t\t\t\t\tbutton.css('width',oldWidth);\n\t\t\t\t\tbutton.animate({'width':newWidth},undefined,undefined,function(){\n\t\t\t\t\t\tbutton.css('width','');\n\t\t\t\t\t});\n\t\t\t\t\tlist.animate({'width':newOuterWidth,'left':pos.left+3});\n\t\t\t\t});\n\t\t\t\tvar li=$('<li></li>');\n\t\t\t\tli.append(input).append(label);\n\t\t\t\treturn li;\n\t\t\t}", "func_src_after": "\t\t\tfunction createItem(element,checked){\n\t\t\t\telement=$(element);\n\t\t\t\tvar item=element.val();\n\t\t\t\tvar id='ms'+multiSelectId+'-option-'+item;\n\t\t\t\tvar input=$('<input type=\"checkbox\"/>');\n\t\t\t\tinput.attr('id',id);\n\t\t\t\tvar label=$('<label/>');\n\t\t\t\tlabel.attr('for',id);\n\t\t\t\tlabel.text(item);\n\t\t\t\tif(settings.checked.indexOf(item)!=-1 || checked){\n\t\t\t\t\tinput.attr('checked',true);\n\t\t\t\t}\n\t\t\t\tif(checked){\n\t\t\t\t\tsettings.checked.push(item);\n\t\t\t\t}\n\t\t\t\tinput.change(function(){\n\t\t\t\t\tvar groupname=$(this).next().text();\n\t\t\t\t\tif($(this).is(':checked')){\n\t\t\t\t\t\telement.attr('selected','selected');\n\t\t\t\t\t\tif(settings.oncheck){\n\t\t\t\t\t\t\tif(settings.oncheck(groupname)===false){\n\t\t\t\t\t\t\t\t$(this).attr('checked', false);\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsettings.checked.push(groupname);\n\t\t\t\t\t}else{\n\t\t\t\t\t\tvar index=settings.checked.indexOf(groupname);\n\t\t\t\t\t\telement.attr('selected',null);\n\t\t\t\t\t\tif(settings.onuncheck){\n\t\t\t\t\t\t\tif(settings.onuncheck(groupname)===false){\n\t\t\t\t\t\t\t\t$(this).attr('checked',true);\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsettings.checked.splice(index,1);\n\t\t\t\t\t}\n\t\t\t\t\tvar oldWidth=button.width();\n\t\t\t\t\tif(settings.checked.length>0){\n\t\t\t\t\t\tbutton.children('span').first().text(settings.checked.join(', '));\n\t\t\t\t\t}else{\n\t\t\t\t\t\tbutton.children('span').first().text(settings.title);\n\t\t\t\t\t}\n\t\t\t\t\tvar newOuterWidth=Math.max((button.outerWidth()-2),settings.minOuterWidth)+'px';\n\t\t\t\t\tvar newWidth=Math.max(button.width(),settings.minWidth);\n\t\t\t\t\tvar pos=button.position();\n\t\t\t\t\tbutton.css('height',button.height());\n\t\t\t\t\tbutton.css('white-space','nowrap');\n\t\t\t\t\tbutton.css('width',oldWidth);\n\t\t\t\t\tbutton.animate({'width':newWidth},undefined,undefined,function(){\n\t\t\t\t\t\tbutton.css('width','');\n\t\t\t\t\t});\n\t\t\t\t\tlist.animate({'width':newOuterWidth,'left':pos.left+3});\n\t\t\t\t});\n\t\t\t\tvar li=$('<li></li>');\n\t\t\t\tli.append(input).append(label);\n\t\t\t\treturn li;\n\t\t\t}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 140, "char_end": 197, "line": "\t\t\t\tvar input=$('<input id=\"'+id+'\" type=\"checkbox\"/>');\n"}, {"line_no": 6, "char_start": 197, "char_end": 254, "line": "\t\t\t\tvar label=$('<label for=\"'+id+'\">'+item+'</label>');\n"}], "added": [{"line_no": 5, "char_start": 140, "char_end": 185, "line": "\t\t\t\tvar input=$('<input type=\"checkbox\"/>');\n"}, {"line_no": 6, "char_start": 185, "char_end": 210, "line": "\t\t\t\tinput.attr('id',id);\n"}, {"line_no": 7, "char_start": 210, "char_end": 239, "line": "\t\t\t\tvar label=$('<label/>');\n"}, {"line_no": 8, "char_start": 239, "char_end": 265, "line": "\t\t\t\tlabel.attr('for',id);\n"}, {"line_no": 9, "char_start": 265, "char_end": 287, "line": "\t\t\t\tlabel.text(item);\n"}]}, "char_changes": {"deleted": [{"char_start": 163, "char_end": 175, "chars": " id=\"'+id+'\""}, {"char_start": 201, "char_end": 251, "chars": "var label=$('<label for=\"'+id+'\">'+item+'</label>'"}], "added": [{"char_start": 189, "char_end": 284, "chars": "input.attr('id',id);\n\t\t\t\tvar label=$('<label/>');\n\t\t\t\tlabel.attr('for',id);\n\t\t\t\tlabel.text(item"}]}, "commit_link": "github.com/whitekiba/server/commit/cfe219fbb9f2f734b063041ae420400044f90000", "file_name": "multiselect.js", "vul_type": "cwe-079", "commit_msg": "fix potential xss in multiselect", "description": "Write a JavaScript function to create a checkbox list item with dynamic behavior based on a given element and a checked state."}
{"func_name": "test_list_kube_config_contexts", "func_src_before": "    def test_list_kube_config_contexts(self):\n        config_file = self._create_temp_file(yaml.dump(self.TEST_KUBE_CONFIG))\n        contexts, active_context = list_kube_config_contexts(\n            config_file=config_file)\n        self.assertDictEqual(self.TEST_KUBE_CONFIG['contexts'][0],\n                             active_context)\n        if PY3:\n            self.assertCountEqual(self.TEST_KUBE_CONFIG['contexts'],\n                                  contexts)\n        else:\n            self.assertItemsEqual(self.TEST_KUBE_CONFIG['contexts'],\n                                  contexts)", "func_src_after": "    def test_list_kube_config_contexts(self):\n        config_file = self._create_temp_file(yaml.safe_dump(self.TEST_KUBE_CONFIG))\n        contexts, active_context = list_kube_config_contexts(\n            config_file=config_file)\n        self.assertDictEqual(self.TEST_KUBE_CONFIG['contexts'][0],\n                             active_context)\n        if PY3:\n            self.assertCountEqual(self.TEST_KUBE_CONFIG['contexts'],\n                                  contexts)\n        else:\n            self.assertItemsEqual(self.TEST_KUBE_CONFIG['contexts'],\n                                  contexts)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 46, "char_end": 125, "line": "        config_file = self._create_temp_file(yaml.dump(self.TEST_KUBE_CONFIG))\n"}], "added": [{"line_no": 2, "char_start": 46, "char_end": 130, "line": "        config_file = self._create_temp_file(yaml.safe_dump(self.TEST_KUBE_CONFIG))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 96, "char_end": 101, "chars": "safe_"}]}, "commit_link": "github.com/kubernetes-client/python/commit/ebb49d02ed90256cd002d1d75cb8a92125c4392e", "file_name": "kube_config_test.py", "vul_type": "cwe-502", "commit_msg": "Use safe_load and safe_dump for all yaml calls", "parent_commit": "5c242ead602797ae870798882654f7a2a4edfe39", "description": "Write a Python function to test listing Kubernetes config contexts and checking the active context."}
{"func_name": "(anonymous)", "func_src_before": "  fs.writeFile(dbRoot+\"/\"+db+\"/md/\"+name, obj, function(err) {\n    if (err)\n      response(res, 500, 'write fail!');\n    else\n      response(res, 200, 'write success!');\n  })", "func_src_after": "app.post(\"/db/:db/:name\", function(req, res) {\n  var db = req.params.db;\n  var name = req.params.name;\n  var obj = req.body.obj;\n  var msg = \"db:\"+db+\" name:\"+name+\"\\n\"+obj;\n  c.log(msg);\n  var filename = path.join(dbRoot, db, 'md', name);\n  if (filename.indexOf(dbRoot) !== 0) { // \u6aa2\u67e5\u662f\u5426\u7a7f\u8d8adbRoot \u53c3\u8003\uff1ahttps://en.wikipedia.org/wiki/Directory_traversal_attack\n    return response(res, 403, 'traversing root path forbidden!');\n  }\n\n  fs.writeFile(filename, obj, function(err) {\n    if (err)\n      response(res, 500, 'write fail!');\n    else\n      response(res, 200, 'write success!');\n  })\n});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 63, "line": "  fs.writeFile(dbRoot+\"/\"+db+\"/md/\"+name, obj, function(err) {\n"}], "added": [{"line_no": 7, "char_start": 188, "char_end": 240, "line": "  var filename = path.join(dbRoot, db, 'md', name);\n"}, {"line_no": 8, "char_start": 240, "char_end": 356, "line": "  if (filename.indexOf(dbRoot) !== 0) { // \u6aa2\u67e5\u662f\u5426\u7a7f\u8d8adbRoot \u53c3\u8003\uff1ahttps://en.wikipedia.org/wiki/Directory_traversal_attack\n"}, {"line_no": 9, "char_start": 356, "char_end": 422, "line": "    return response(res, 403, 'traversing root path forbidden!');\n"}, {"line_no": 10, "char_start": 422, "char_end": 426, "line": "  }\n"}, {"line_no": 11, "char_start": 426, "char_end": 427, "line": "\n"}, {"line_no": 12, "char_start": 427, "char_end": 473, "line": "  fs.writeFile(filename, obj, function(err) {\n"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 36, "chars": "  fs.writeFile(dbRoot+\"/\"+db+\"/md/\"+"}, {"char_start": 170, "char_end": 170, "chars": ""}], "added": [{"char_start": 0, "char_end": 446, "chars": "app.post(\"/db/:db/:name\", function(req, res) {\n  var db = req.params.db;\n  var name = req.params.name;\n  var obj = req.body.obj;\n  var msg = \"db:\"+db+\" name:\"+name+\"\\n\"+obj;\n  c.log(msg);\n  var filename = path.join(dbRoot, db, 'md', name);\n  if (filename.indexOf(dbRoot) !== 0) { // \u6aa2\u67e5\u662f\u5426\u7a7f\u8d8adbRoot \u53c3\u8003\uff1ahttps://en.wikipedia.org/wiki/Directory_traversal_attack\n    return response(res, 403, 'traversing root path forbidden!');\n  }\n\n  fs.writeFile(file"}, {"char_start": 584, "char_end": 588, "chars": "\n});"}]}, "commit_link": "github.com/ccckmit/wikidown.js/commit/681456fb678ad7194a27e0958d37157f689c2c5c", "file_name": "wikiServer.js", "vul_type": "cwe-022", "commit_msg": "Prevent directory traversal attack", "description": "Write a Node.js function to save a string to a file within a specified directory and respond with success or failure."}
{"func_name": "set_eeprom_serial_number", "func_src_before": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 16);\n  _dirty = 1;\n\n  return 0;\n}", "func_src_after": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 12);\n  _dirty = 1;\n\n  return 0;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 16);\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 12);\n"}]}, "char_changes": {"deleted": [{"char_start": 80, "char_end": 81, "chars": "6"}], "added": [{"char_start": 80, "char_end": 81, "chars": "2"}]}, "commit_link": "github.com/picoflamingo/BBCape_EEPROM/commit/0b2d0afdd72e6ca35e9312bd43e29d488ae8c2e5", "file_name": "bbcape_eeprom.c", "vul_type": "cwe-119", "commit_msg": "Buffer Overflow fixed (https://github.com/picoflamingo/BBCape_EEPROM/issues/1)", "parent_commit": "21b1310205d6b2d9073efc51c6a32edbd9a08b89", "description": "Write a C function named `set_eeprom_serial_number` that copies a serial number string into an EEPROM structure and sets a dirty flag."}
{"func_name": "mode_keepalive", "func_src_before": "    def mode_keepalive(self, request):\n        \"\"\"\n        This is called by render_POST when the\n        client is replying to the keepalive.\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        self.last_alive[csessid] = (time.time(), False)\n        return '\"\"'", "func_src_after": "    def mode_keepalive(self, request):\n        \"\"\"\n        This is called by render_POST when the\n        client is replying to the keepalive.\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        self.last_alive[csessid] = (time.time(), False)\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_keepalive` that updates a timestamp for a client session ID from a POST request and returns an empty string."}
{"func_name": "futex_requeue", "func_src_before": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "func_src_after": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "commit_link": "github.com/torvalds/linux/commit/fbe0e839d1e22d88810f3ee3e2f1479be4c0aa4a", "file_name": "kernel/futex.c", "vul_type": "cwe-190", "description": "Write a C function named `futex_requeue` that manages the requeueing of futexes, potentially involving priority inheritance logic."}
{"func_name": "ImagingFliDecode", "func_src_before": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer (on the other hand, the Python part of the driver\n       makes sure this is always the case) */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}", "func_src_after": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (bytes < 8) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}", "commit_link": "github.com/python-pillow/Pillow/commit/a09acd0decd8a87ccce939d5ff65dab59e7d365b", "file_name": "src/libImaging/FliDecode.c", "vul_type": "cwe-125", "description": "Write a C function named `ImagingFliDecode` that decodes a frame from an FLI/FLC animation file into an image buffer."}
{"func_name": "verify_email", "func_src_before": "    def verify_email(self, member):\n        query = \"SELECT COUNT(email) FROM members WHERE email = '{email}'\".format(email = member)\n        self.cursor.execute(query)\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "func_src_after": "    def verify_email(self, member):\n        self.cursor.execute(\"SELECT COUNT(email) FROM members WHERE email = ':email'\", {'email':member})\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "commit_link": "github.com/kenboo98/291-Mini-Project-I/commit/3080ccb687c79c83954ce703faee8fcceec8c9eb", "file_name": "book_rides/book_rides.py", "vul_type": "cwe-089", "description": "Write a Python function to check if an email exists in a database using SQL queries."}
{"func_name": "ffs_user_copy_worker", "func_src_before": "static void ffs_user_copy_worker(struct work_struct *work)\n{\n\tstruct ffs_io_data *io_data = container_of(work, struct ffs_io_data,\n\t\t\t\t\t\t   work);\n\tint ret = io_data->req->status ? io_data->req->status :\n\t\t\t\t\t io_data->req->actual;\n\n\tif (io_data->read && ret > 0) {\n\t\tuse_mm(io_data->mm);\n\t\tret = copy_to_iter(io_data->buf, ret, &io_data->data);\n\t\tif (iov_iter_count(&io_data->data))\n\t\t\tret = -EFAULT;\n\t\tunuse_mm(io_data->mm);\n\t}\n\n\tio_data->kiocb->ki_complete(io_data->kiocb, ret, ret);\n\n\tif (io_data->ffs->ffs_eventfd &&\n\t    !(io_data->kiocb->ki_flags & IOCB_EVENTFD))\n\t\teventfd_signal(io_data->ffs->ffs_eventfd, 1);\n\n\tusb_ep_free_request(io_data->ep, io_data->req);\n\n\tio_data->kiocb->private = NULL;\n\tif (io_data->read)\n\t\tkfree(io_data->to_free);\n\tkfree(io_data->buf);\n\tkfree(io_data);\n}", "func_src_after": "static void ffs_user_copy_worker(struct work_struct *work)\n{\n\tstruct ffs_io_data *io_data = container_of(work, struct ffs_io_data,\n\t\t\t\t\t\t   work);\n\tint ret = io_data->req->status ? io_data->req->status :\n\t\t\t\t\t io_data->req->actual;\n\tbool kiocb_has_eventfd = io_data->kiocb->ki_flags & IOCB_EVENTFD;\n\n\tif (io_data->read && ret > 0) {\n\t\tuse_mm(io_data->mm);\n\t\tret = copy_to_iter(io_data->buf, ret, &io_data->data);\n\t\tif (iov_iter_count(&io_data->data))\n\t\t\tret = -EFAULT;\n\t\tunuse_mm(io_data->mm);\n\t}\n\n\tio_data->kiocb->ki_complete(io_data->kiocb, ret, ret);\n\n\tif (io_data->ffs->ffs_eventfd && !kiocb_has_eventfd)\n\t\teventfd_signal(io_data->ffs->ffs_eventfd, 1);\n\n\tusb_ep_free_request(io_data->ep, io_data->req);\n\n\tif (io_data->read)\n\t\tkfree(io_data->to_free);\n\tkfree(io_data->buf);\n\tkfree(io_data);\n}", "commit_link": "github.com/torvalds/linux/commit/38740a5b87d53ceb89eb2c970150f6e94e00373a", "file_name": "drivers/usb/gadget/function/f_fs.c", "vul_type": "cwe-416", "description": "Write a C function named `ffs_user_copy_worker` that processes I/O data for a USB function filesystem."}
{"func_name": "on_save", "func_src_before": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            f\"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values ('{self.ip_address}', '{self.user_agent}', '{self.referrer}', '{self.full_path}', '{self.visit_time}');\")\n        connection.commit()\n        connection.close()\n        return 0", "func_src_after": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            \"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values (%s, %s, %s, %s, %s);\",\n            (str(self.ip_address), str(self.user_agent), str(self.referrer), str(self.full_path), self.visit_time))\n        connection.commit()\n        connection.close()\n        return 0", "commit_link": "github.com/onewyoming/onewyoming/commit/54fc7b076fda2de74eeb55e6b75b28e09ef231c2", "file_name": "experimental/python/buford/model/visitor.py", "vul_type": "cwe-089", "description": "Write a Python function to save a visitor's details to a database using SQL insert query."}
{"func_name": "set_interface_var", "func_src_before": "set_interface_var(const char *iface,\n\t\t  const char *var, const char *name,\n\t\t  uint32_t val)\n{\n\tFILE *fp;\n\tchar spath[64+IFNAMSIZ];\t/* XXX: magic constant */\n\tif (snprintf(spath, sizeof(spath), var, iface) >= sizeof(spath))\n\t\treturn -1;\n\n\tif (access(spath, F_OK) != 0)\n\t\treturn -1;\n\n\tfp = fopen(spath, \"w\");\n\tif (!fp) {\n\t\tif (name)\n\t\t\tflog(LOG_ERR, \"failed to set %s (%u) for %s: %s\",\n\t\t\t     name, val, iface, strerror(errno));\n\t\treturn -1;\n\t}\n\tfprintf(fp, \"%u\", val);\n\tfclose(fp);\n\n\treturn 0;\n}", "func_src_after": "set_interface_var(const char *iface,\n\t\t  const char *var, const char *name,\n\t\t  uint32_t val)\n{\n\tFILE *fp;\n\tchar spath[64+IFNAMSIZ];\t/* XXX: magic constant */\n\tif (snprintf(spath, sizeof(spath), var, iface) >= sizeof(spath))\n\t\treturn -1;\n\n\t/* No path traversal */\n\tif (strstr(name, \"..\") || strchr(name, '/'))\n\t\treturn -1;\n\n\tif (access(spath, F_OK) != 0)\n\t\treturn -1;\n\n\tfp = fopen(spath, \"w\");\n\tif (!fp) {\n\t\tif (name)\n\t\t\tflog(LOG_ERR, \"failed to set %s (%u) for %s: %s\",\n\t\t\t     name, val, iface, strerror(errno));\n\t\treturn -1;\n\t}\n\tfprintf(fp, \"%u\", val);\n\tfclose(fp);\n\n\treturn 0;\n}", "commit_link": "github.com/reubenhwk/radvd/commit/92e22ca23e52066da2258df8c76a2dca8a428bcc", "file_name": "device-linux.c", "vul_type": "cwe-022", "description": "Write a C function to update a network interface variable in a file, handling file paths and potential errors."}
{"func_name": "ZipUtil::checkDestinationFileForTraversal", "func_src_before": "  private static File checkDestinationFileForTraversal(File outputDir, String name, File destFile) throws IOException {\n    /* If we see the relative traversal string of \"..\" we need to make sure\n     * that the outputdir + name doesn't leave the outputdir. See\n     * DirectoryTraversalMaliciousTest for details.\n     */\n    if (name.indexOf(\"..\") != -1 && !destFile.getCanonicalPath().startsWith(outputDir.getCanonicalPath())) {\n      throw new MaliciousZipException(outputDir, name);\n    }\n    return destFile;\n  }", "func_src_after": "  private static File checkDestinationFileForTraversal(File outputDir, String name, File destFile) throws IOException {\n    /* If we see the relative traversal string of \"..\" we need to make sure\n     * that the outputdir + name doesn't leave the outputdir. See\n     * DirectoryTraversalMaliciousTest for details.\n     */\n    if (name.indexOf(\"..\") != -1 && !destFile.getCanonicalFile().toPath().startsWith(outputDir.getCanonicalFile().toPath())) {\n      throw new MaliciousZipException(outputDir, name);\n    }\n    return destFile;\n  }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 322, "char_end": 431, "line": "    if (name.indexOf(\"..\") != -1 && !destFile.getCanonicalPath().startsWith(outputDir.getCanonicalPath())) {\n"}], "added": [{"line_no": 6, "char_start": 322, "char_end": 449, "line": "    if (name.indexOf(\"..\") != -1 && !destFile.getCanonicalFile().toPath().startsWith(outputDir.getCanonicalFile().toPath())) {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 380, "char_end": 389, "chars": "File().to"}, {"char_start": 429, "char_end": 438, "chars": "File().to"}]}, "commit_link": "github.com/zeroturnaround/zt-zip/commit/627bbc93907ceb69111f86e2edf26375a1abccfa", "file_name": "ZipUtil.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "9b0818802c8fc804d75ef731da538423a7e020fa", "description": "Write a Java function to prevent directory traversal by validating a file's destination path against an intended output directory."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHP_FUNCTION(imagegammacorrect)\n{\n\tzval *IM;\n\tgdImagePtr im;\n\tint i;\n\tdouble input, output;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rdd\", &IM, &input, &output) == FAILURE) {\n\t\treturn;\n\t}\n\n\tZEND_FETCH_RESOURCE(im, gdImagePtr, &IM, -1, \"Image\", le_gd);\n\n\tif (gdImageTrueColor(im))\t{\n\t\tint x, y, c;\n\n\t\tfor (y = 0; y < gdImageSY(im); y++)\t{\n\t\t\tfor (x = 0; x < gdImageSX(im); x++)\t{\n\t\t\t\tc = gdImageGetPixel(im, x, y);\n\t\t\t\tgdImageSetPixel(im, x, y,\n\t\t\t\t\tgdTrueColorAlpha(\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetRed(c)   / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetGreen(c) / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetBlue(c)  / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\tgdTrueColorGetAlpha(c)\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t\tRETURN_TRUE;\n\t}\n\n\tfor (i = 0; i < gdImageColorsTotal(im); i++) {\n\t\tim->red[i]   = (int)((pow((pow((im->red[i]   / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->green[i] = (int)((pow((pow((im->green[i] / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->blue[i]  = (int)((pow((pow((im->blue[i]  / 255.0), input)), 1.0 / output) * 255) + .5);\n\t}\n\n\tRETURN_TRUE;\n}", "func_src_after": "PHP_FUNCTION(imagegammacorrect)\n{\n\tzval *IM;\n\tgdImagePtr im;\n\tint i;\n\tdouble input, output;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rdd\", &IM, &input, &output) == FAILURE) {\n\t\treturn;\n\t}\n\n\tif ( input <= 0.0 || output <= 0.0 ) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Gamma values should be positive\");\n\t\tRETURN_FALSE;\n\t}\n\n\tZEND_FETCH_RESOURCE(im, gdImagePtr, &IM, -1, \"Image\", le_gd);\n\n\tif (gdImageTrueColor(im))\t{\n\t\tint x, y, c;\n\n\t\tfor (y = 0; y < gdImageSY(im); y++)\t{\n\t\t\tfor (x = 0; x < gdImageSX(im); x++)\t{\n\t\t\t\tc = gdImageGetPixel(im, x, y);\n\t\t\t\tgdImageSetPixel(im, x, y,\n\t\t\t\t\tgdTrueColorAlpha(\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetRed(c)   / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetGreen(c) / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetBlue(c)  / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\tgdTrueColorGetAlpha(c)\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t\tRETURN_TRUE;\n\t}\n\n\tfor (i = 0; i < gdImageColorsTotal(im); i++) {\n\t\tim->red[i]   = (int)((pow((pow((im->red[i]   / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->green[i] = (int)((pow((pow((im->green[i] / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->blue[i]  = (int)((pow((pow((im->blue[i]  / 255.0), input)), 1.0 / output) * 255) + .5);\n\t}\n\n\tRETURN_TRUE;\n}", "commit_link": "github.com/php/php-src/commit/1bd103df00f49cf4d4ade2cfe3f456ac058a4eae", "file_name": "ext/gd/gd.c", "vul_type": "cwe-787", "description": "Write a PHP function to apply gamma correction to an image resource with given input and output gamma values."}
{"func_name": "nntp_hcache_namer", "func_src_before": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  return snprintf(dest, destlen, \"%s.hcache\", path);\n}", "func_src_after": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  int count = snprintf(dest, destlen, \"%s.hcache\", path);\n\n  /* Strip out any directories in the path */\n  char *first = strchr(dest, '/');\n  char *last = strrchr(dest, '/');\n  if (first && last && (last > first))\n  {\n    memmove(first, last, strlen(last) + 1);\n    count -= (last - first);\n  }\n\n  return count;\n}", "commit_link": "github.com/neomutt/neomutt/commit/9bfab35522301794483f8f9ed60820bdec9be59e", "file_name": "newsrc.c", "vul_type": "cwe-022", "description": "Write a C function named `nntp_hcache_namer` that formats a file path with the extension \".hcache\", optionally removing directory components."}
{"func_name": "taxon_search", "func_src_before": "  def taxon_search(prefix, tax_levels = TaxonCount::NAME_2_LEVEL.keys, filters = {})\n    return {} if Rails.env == \"test\"\n    prefix = sanitize(prefix)\n\n    matching_taxa = []\n    taxon_ids = []\n    tax_levels.each do |level|\n      search_params = {\n        size: ElasticsearchHelper::MAX_SEARCH_RESULTS,\n        query: {\n          query_string: {\n            query: \"#{prefix}*\",\n            fields: [\"#{level}_name\"]\n          }\n        },\n        aggs: {\n          distinct_taxa: {\n            terms: {\n              field: \"#{level}_taxid\"\n            }\n          }\n        }\n      }\n      search_response = TaxonLineage.search(search_params)\n      search_taxon_ids = search_response.aggregations.distinct_taxa.buckets.pluck(:key)\n\n      taxon_data = TaxonLineage\n                   .where(\"#{level}_taxid\" => search_taxon_ids)\n                   .order(id: :desc)\n                   .distinct(\"#{level}_taxid\")\n                   .pluck(\"#{level}_name\", \"#{level}_taxid\")\n                   .map do |name, taxid|\n                     {\n                       \"title\" => name,\n                       \"description\" => \"Taxonomy ID: #{taxid}\",\n                       \"taxid\" => taxid,\n                       \"level\" => level\n                     }\n                   end\n\n      matching_taxa += taxon_data\n      taxon_ids += search_taxon_ids\n    end\n\n    taxon_ids = filter_by_samples(taxon_ids, filters[:samples]) if filters[:samples]\n    taxon_ids = filter_by_project(taxon_ids, filters[:project_id]) if filters[:project_id]\n    taxon_ids = Set.new(taxon_ids)\n\n    return matching_taxa.select { |taxon| taxon_ids.include? taxon[\"taxid\"] }\n  end", "func_src_after": "  def taxon_search(query, tax_levels = TaxonCount::NAME_2_LEVEL.keys, filters = {})\n    return {} if Rails.env == \"test\"\n    query = sanitize(query)\n\n    # sanitize tax_levels\n    tax_levels = tax_levels.select { |l| TaxonCount::NAME_2_LEVEL[l] }\n\n    matching_taxa = []\n    taxon_ids = []\n    tax_levels.each do |level|\n      search_params = {\n        size: ElasticsearchHelper::MAX_SEARCH_RESULTS,\n        query: {\n          query_string: {\n            query: \"*#{query}*\",\n            fields: [\"#{level}_name\"]\n          }\n        },\n        aggs: {\n          distinct_taxa: {\n            terms: {\n              field: \"#{level}_taxid\"\n            }\n          }\n        }\n      }\n      search_response = TaxonLineage.search(search_params)\n      search_taxon_ids = search_response.aggregations.distinct_taxa.buckets.pluck(:key)\n\n      taxon_data = TaxonLineage\n                   .where(\"#{level}_taxid\" => search_taxon_ids)\n                   .order(id: :desc)\n                   .distinct(\"#{level}_taxid\")\n                   .pluck(\"#{level}_name\", \"#{level}_taxid\")\n                   .map do |name, taxid|\n                     {\n                       \"title\" => name,\n                       \"description\" => \"Taxonomy ID: #{taxid}\",\n                       \"taxid\" => taxid,\n                       \"level\" => level\n                     }\n                   end\n\n      matching_taxa += taxon_data\n      taxon_ids += search_taxon_ids\n    end\n\n    taxon_ids = filter_by_samples(taxon_ids, filters[:samples]) if filters[:samples]\n    taxon_ids = filter_by_project(taxon_ids, filters[:project_id]) if filters[:project_id]\n    taxon_ids = Set.new(taxon_ids)\n\n    return matching_taxa.select { |taxon| taxon_ids.include? taxon[\"taxid\"] }\n  end", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 85, "line": "  def taxon_search(prefix, tax_levels = TaxonCount::NAME_2_LEVEL.keys, filters = {})\n"}, {"line_no": 3, "char_start": 122, "char_end": 152, "line": "    prefix = sanitize(prefix)\n"}, {"line_no": 12, "char_start": 348, "char_end": 381, "line": "            query: \"#{prefix}*\",\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 84, "line": "  def taxon_search(query, tax_levels = TaxonCount::NAME_2_LEVEL.keys, filters = {})\n"}, {"line_no": 3, "char_start": 121, "char_end": 149, "line": "    query = sanitize(query)\n"}, {"line_no": 4, "char_start": 149, "char_end": 150, "line": "\n"}, {"line_no": 6, "char_start": 176, "char_end": 247, "line": "    tax_levels = tax_levels.select { |l| TaxonCount::NAME_2_LEVEL[l] }\n"}, {"line_no": 15, "char_start": 443, "char_end": 476, "line": "            query: \"*#{query}*\",\n"}]}, "char_changes": {"deleted": [{"char_start": 19, "char_end": 25, "chars": "prefix"}, {"char_start": 126, "char_end": 132, "chars": "prefix"}, {"char_start": 144, "char_end": 151, "chars": "prefix)"}, {"char_start": 370, "char_end": 376, "chars": "prefix"}], "added": [{"char_start": 19, "char_end": 24, "chars": "query"}, {"char_start": 125, "char_end": 130, "chars": "query"}, {"char_start": 142, "char_end": 246, "chars": "query)\n\n    # sanitize tax_levels\n    tax_levels = tax_levels.select { |l| TaxonCount::NAME_2_LEVEL[l] }"}, {"char_start": 463, "char_end": 464, "chars": "*"}, {"char_start": 466, "char_end": 471, "chars": "query"}]}, "commit_link": "github.com/chanzuckerberg/idseq-web/commit/5e0901a9bd161312cf8bb57004830ac32921f976", "file_name": "elasticsearch_helper.rb", "vul_type": "cwe-089", "commit_msg": "[Taxon Search] Search text on any part of the word and avoid SQL injection. (#2372)\n\n* Search text on any part of the word.\r\nSanitize tax_levels to avoid SQL injection.\r\n\r\n* Rubocop", "parent_commit": "22e2cdb38444f81519346b4b0ce35c8e66c3de2d", "description": "Write a Ruby method for searching taxonomic data using Elasticsearch, filtering results by optional parameters."}
{"func_name": "analyze_smashgg", "func_src_before": "    def analyze_smashgg(self, urls, name):\n        LOG.info('we are about to analyze scene {} with {} brackets'.format(name, len(urls)))\n        for url in urls:\n            # Before we process this URL, check to see if we already have\n            sql = \"SELECT * FROM analyzed where base_url='{}'\".format(url)\n            res = self.db.exec(sql)\n            if len(res) == 0:\n\n                display_name = bracket_utils.get_display_base(url)\n\n                # We don't care about doubles tournaments\n                if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                    LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                    continue\n\n                LOG.info('About to process pro bracket {}'.format(url))\n                self.data_processor.process(url, name, display_name)\n            else:\n                LOG.info(\"Skpping pro bracket because it has already been analyzed: {}\".format(url))", "func_src_after": "    def analyze_smashgg(self, urls, name):\n        LOG.info('we are about to analyze scene {} with {} brackets'.format(name, len(urls)))\n        for url in urls:\n            # Before we process this URL, check to see if we already have\n            sql = \"SELECT * FROM analyzed where base_url='{url}'\"\n            args = {'url':url}\n            res = self.db.exec(sql, args)\n            if len(res) == 0:\n\n                display_name = bracket_utils.get_display_base(url)\n\n                # We don't care about doubles tournaments\n                if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                    LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                    continue\n\n                LOG.info('About to process pro bracket {}'.format(url))\n                self.data_processor.process(url, name, display_name)\n            else:\n                LOG.info(\"Skpping pro bracket because it has already been analyzed: {}\".format(url))", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089", "description": "Write a Python function that logs the analysis process of Smash.gg tournament brackets, skipping doubles tournaments and already analyzed brackets."}
{"func_name": "wddx_stack_destroy", "func_src_before": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "func_src_after": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "commit_link": "github.com/php/php-src/commit/b88393f08a558eec14964a55d3c680fe67407712?w=1", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-416", "description": "Write a function in C to destroy a stack, deallocating any dynamic memory used by its elements."}
{"func_name": "_create_host", "func_src_before": "    def _create_host(self, connector):\n        \"\"\"Create a new host on the storage system.\n\n        We create a host name and associate it with the given connection\n        information.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _create_host: host %s') % connector['host'])\n\n        rand_id = str(random.randint(0, 99999999)).zfill(8)\n        host_name = '%s-%s' % (self._connector_to_hostname_prefix(connector),\n                               rand_id)\n\n        # Get all port information from the connector\n        ports = []\n        if 'initiator' in connector:\n            ports.append('-iscsiname %s' % connector['initiator'])\n        if 'wwpns' in connector:\n            for wwpn in connector['wwpns']:\n                ports.append('-hbawwpn %s' % wwpn)\n\n        # When creating a host, we need one port\n        self._driver_assert(len(ports), _('_create_host: No connector ports'))\n        port1 = ports.pop(0)\n        ssh_cmd = ('svctask mkhost -force %(port1)s -name \"%(host_name)s\"' %\n                   {'port1': port1, 'host_name': host_name})\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return('successfully created' in out,\n                                '_create_host', ssh_cmd, out, err)\n\n        # Add any additional ports to the host\n        for port in ports:\n            ssh_cmd = ('svctask addhostport -force %s %s' % (port, host_name))\n            out, err = self._run_ssh(ssh_cmd)\n\n        LOG.debug(_('leave: _create_host: host %(host)s - %(host_name)s') %\n                  {'host': connector['host'], 'host_name': host_name})\n        return host_name", "func_src_after": "    def _create_host(self, connector):\n        \"\"\"Create a new host on the storage system.\n\n        We create a host name and associate it with the given connection\n        information.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _create_host: host %s') % connector['host'])\n\n        rand_id = str(random.randint(0, 99999999)).zfill(8)\n        host_name = '%s-%s' % (self._connector_to_hostname_prefix(connector),\n                               rand_id)\n\n        # Get all port information from the connector\n        ports = []\n        if 'initiator' in connector:\n            ports.append('-iscsiname %s' % connector['initiator'])\n        if 'wwpns' in connector:\n            for wwpn in connector['wwpns']:\n                ports.append('-hbawwpn %s' % wwpn)\n\n        # When creating a host, we need one port\n        self._driver_assert(len(ports), _('_create_host: No connector ports'))\n        port1 = ports.pop(0)\n        arg_name, arg_val = port1.split()\n        ssh_cmd = ['svctask', 'mkhost', '-force', arg_name, arg_val, '-name',\n                   '\"%s\"' % host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return('successfully created' in out,\n                                '_create_host', ssh_cmd, out, err)\n\n        # Add any additional ports to the host\n        for port in ports:\n            arg_name, arg_val = port.split()\n            ssh_cmd = ['svctask', 'addhostport', '-force', arg_name, arg_val,\n                       host_name]\n            out, err = self._run_ssh(ssh_cmd)\n\n        LOG.debug(_('leave: _create_host: host %(host)s - %(host_name)s') %\n                  {'host': connector['host'], 'host_name': host_name})\n        return host_name", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a storage system host with a unique name and associated connection ports."}
{"func_name": "cleanup_pathname", "func_src_before": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/')\n\t\tseparator = *src++;\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "func_src_after": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/') {\n\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NOABSOLUTEPATHS) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t                  \"Path is absolute\");\n\t\t\treturn (ARCHIVE_FAILED);\n\t\t}\n\n\t\tseparator = *src++;\n\t}\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "commit_link": "github.com/libarchive/libarchive/commit/59357157706d47c365b2227739e17daba3607526", "file_name": "libarchive/archive_write_disk_posix.c", "vul_type": "cwe-022", "description": "Write a C function named `cleanup_pathname` that sanitizes and validates a pathname stored in a `struct archive_write_disk` object."}
{"func_name": "ld86r", "func_src_before": "ld86r(argc, argv)\n   int argc; char ** argv;\n#endif\n{\nchar buf[128];\n   FILE * fd, * ifd;\n   struct stat st;\n   int ar, libarg=0, need_o = 0, got_o = 0;\n\n   for(ar=1; ar<argc; ar++) if( argv[ar][0] == '-' )\n   {\n      if( argv[ar][1] == 'r' ) need_o = 1;\n      if( argv[ar][1] == 'o' ) { got_o++; libarg = 0; }\n   }\n   else\n   {\n      if( libarg == 0 ) libarg = ar;\n   }\n\n   if( libarg == 0 || got_o > 1 || need_o > got_o )\n      fatalerror(\"-o option required for -r\");\n\n   if( (fd =fopen(argv[libarg], \"wb\")) == 0 ) fatalerror(\"Cannot open archive\");\n   if( fwrite(ARMAG, 1, SARMAG, fd) != SARMAG)  fatalerror(\"Cannot write magic\");\n\n   for(ar=1; ar<argc; ar++) if( ar != libarg && argv[ar][0] != '-' )\n   {\n      char * ptr;\n      if( stat(argv[ar], &st) < 0 ) fatalerror(\"Cannot stat object\");\n      if((ptr=strchr(argv[ar], '/'))) ptr++; else ptr=argv[ar];\n      memset(&arbuf, ' ', sizeof(arbuf));\n      strcpy(buf, ptr); strcat(buf, \"/                 \");\n      strncpy(arbuf.ar_name, buf, sizeof(arbuf.ar_name));\n      \n      sprintf(arbuf.ar_date, \"%-12ld\", (long)st.st_mtime);\n      sprintf(arbuf.ar_uid, \"%-6d\",    (int)(st.st_uid%1000000L));\n      sprintf(arbuf.ar_gid, \"%-6d\",    (int)(st.st_gid%1000000L));\n      sprintf(arbuf.ar_mode, \"%-8lo\",  (long)st.st_mode);\n      sprintf(arbuf.ar_size, \"%-10ld\", (long)st.st_size);\n      memcpy(arbuf.ar_fmag, ARFMAG, sizeof(arbuf.ar_fmag));\n\n      if( fwrite(&arbuf, 1, sizeof(arbuf), fd) != sizeof(arbuf) )\n         fatalerror(\"Cannot write header\");\n\n      ptr = malloc(st.st_size+2);\n      if( ptr == 0 ) fatalerror(\"Out of memory\");\n      ptr[st.st_size] = ' ';\n      if( (ifd = fopen(argv[ar], \"rb\")) == 0 ) fatalerror(\"Cannot open input\");\n      if( fread(ptr, 1, st.st_size, ifd) != st.st_size )\n         fatalerror(\"Cannot read input file\");\n      fclose(ifd);\n\n      if( st.st_size&1 ) st.st_size++;\n      if( fwrite(ptr, 1, st.st_size, fd) != st.st_size )\n         fatalerror(\"Cannot write output file\");\n   }\n   fclose(fd);\n   exit(0);\n}", "func_src_after": "ld86r(argc, argv)\n   int argc; char ** argv;\n#endif\n{\nchar buf[128];\n   FILE * fd, * ifd;\n   struct stat st;\n   int ar, libarg=0, need_o = 0, got_o = 0;\n\n   for(ar=1; ar<argc; ar++) if( argv[ar][0] == '-' )\n   {\n      if( argv[ar][1] == 'r' ) need_o = 1;\n      if( argv[ar][1] == 'o' ) { got_o++; libarg = 0; }\n   }\n   else\n   {\n      if( libarg == 0 ) libarg = ar;\n   }\n\n   if( libarg == 0 || got_o > 1 || need_o > got_o )\n      fatalerror(\"-o option required for -r\");\n\n   if( (fd =fopen(argv[libarg], \"wb\")) == 0 ) fatalerror(\"Cannot open archive\");\n   if( fwrite(ARMAG, 1, SARMAG, fd) != SARMAG)  fatalerror(\"Cannot write magic\");\n\n   for(ar=1; ar<argc; ar++) if( ar != libarg && argv[ar][0] != '-' )\n   {\n      char * ptr;\n      if( stat(argv[ar], &st) < 0 ) fatalerror(\"Cannot stat object\");\n      if((ptr=strchr(argv[ar], '/'))) ptr++; else ptr=argv[ar];\n      memset(&arbuf, ' ', sizeof(arbuf));\n      strcpy(buf, ptr); strcat(buf, \"/                 \");\n      strncpy(arbuf.ar_name, buf, sizeof(arbuf.ar_name));\n     \n      snprintf(arbuf.ar_date, 12, \"%-12ld\", (long)st.st_mtime);\n      snprintf(arbuf.ar_uid, 6, \"%-6d\", (int)(st.st_uid%1000000L));\n      snprintf(arbuf.ar_gid, 6, \"%-6d\", (int)(st.st_gid%1000000L));\n      snprintf(arbuf.ar_mode, 8, \"%-8lo\", (long)st.st_mode);\n      snprintf(arbuf.ar_size, 10, \"%-10ld\", (long)st.st_size);\n      memcpy(arbuf.ar_fmag, ARFMAG, sizeof(arbuf.ar_fmag));\n\n      if( fwrite(&arbuf, 1, sizeof(arbuf), fd) != sizeof(arbuf) )\n         fatalerror(\"Cannot write header\");\n\n      ptr = malloc(st.st_size+2);\n      if( ptr == 0 ) fatalerror(\"Out of memory\");\n      ptr[st.st_size] = ' ';\n      if( (ifd = fopen(argv[ar], \"rb\")) == 0 ) fatalerror(\"Cannot open input\");\n      if( fread(ptr, 1, st.st_size, ifd) != st.st_size )\n         fatalerror(\"Cannot read input file\");\n      fclose(ifd);\n\n      if( st.st_size&1 ) st.st_size++;\n      if( fwrite(ptr, 1, st.st_size, fd) != st.st_size )\n         fatalerror(\"Cannot write output file\");\n   }\n   fclose(fd);\n   exit(0);\n}", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1021, "char_end": 1028, "line": "      \n"}, {"line_no": 35, "char_start": 1028, "char_end": 1087, "line": "      sprintf(arbuf.ar_date, \"%-12ld\", (long)st.st_mtime);\n"}, {"line_no": 36, "char_start": 1087, "char_end": 1154, "line": "      sprintf(arbuf.ar_uid, \"%-6d\",    (int)(st.st_uid%1000000L));\n"}, {"line_no": 37, "char_start": 1154, "char_end": 1221, "line": "      sprintf(arbuf.ar_gid, \"%-6d\",    (int)(st.st_gid%1000000L));\n"}, {"line_no": 38, "char_start": 1221, "char_end": 1279, "line": "      sprintf(arbuf.ar_mode, \"%-8lo\",  (long)st.st_mode);\n"}, {"line_no": 39, "char_start": 1279, "char_end": 1337, "line": "      sprintf(arbuf.ar_size, \"%-10ld\", (long)st.st_size);\n"}], "added": [{"line_no": 34, "char_start": 1021, "char_end": 1027, "line": "     \n"}, {"line_no": 35, "char_start": 1027, "char_end": 1091, "line": "      snprintf(arbuf.ar_date, 12, \"%-12ld\", (long)st.st_mtime);\n"}, {"line_no": 36, "char_start": 1091, "char_end": 1159, "line": "      snprintf(arbuf.ar_uid, 6, \"%-6d\", (int)(st.st_uid%1000000L));\n"}, {"line_no": 37, "char_start": 1159, "char_end": 1227, "line": "      snprintf(arbuf.ar_gid, 6, \"%-6d\", (int)(st.st_gid%1000000L));\n"}, {"line_no": 38, "char_start": 1227, "char_end": 1288, "line": "      snprintf(arbuf.ar_mode, 8, \"%-8lo\", (long)st.st_mode);\n"}, {"line_no": 39, "char_start": 1288, "char_end": 1351, "line": "      snprintf(arbuf.ar_size, 10, \"%-10ld\", (long)st.st_size);\n"}]}, "char_changes": {"deleted": [{"char_start": 1026, "char_end": 1027, "chars": " "}, {"char_start": 1122, "char_end": 1125, "chars": "   "}, {"char_start": 1189, "char_end": 1192, "chars": "   "}, {"char_start": 1258, "char_end": 1259, "chars": " "}], "added": [{"char_start": 1034, "char_end": 1035, "chars": "n"}, {"char_start": 1056, "char_end": 1060, "chars": " 12,"}, {"char_start": 1098, "char_end": 1099, "chars": "n"}, {"char_start": 1119, "char_end": 1122, "chars": " 6,"}, {"char_start": 1166, "char_end": 1167, "chars": "n"}, {"char_start": 1187, "char_end": 1190, "chars": " 6,"}, {"char_start": 1234, "char_end": 1235, "chars": "n"}, {"char_start": 1256, "char_end": 1259, "chars": " 8,"}, {"char_start": 1295, "char_end": 1296, "chars": "n"}, {"char_start": 1317, "char_end": 1321, "chars": " 10,"}]}, "commit_link": "github.com/jbruchon/dev86/commit/6632a39575ae931f0532c84d78245c012fbb8773", "file_name": "mkar.c", "vul_type": "cwe-787", "commit_msg": "mkar: Fix off-by-one errors\n\nThere are off-by-one errors when filling the ar headers, the trailing nul\nwould overflow the target buffer.", "parent_commit": "cea8e7abbab7ea77de6090dc6dc43ac6a3eaca65", "description": "Write a C program that processes command-line arguments to handle archive creation with specific options."}
{"func_name": "dd_save_text", "func_src_before": "void dd_save_text(struct dump_dir *dd, const char *name, const char *data)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, strlen(data), dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "func_src_after": "void dd_save_text(struct dump_dir *dd, const char *name, const char *data)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot save text. '%s' is not a valid file name\", name);\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, strlen(data), dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function `dd_save_text` to save text data to a file within a directory structure, handling errors for directory access and file naming."}
{"func_name": "main", "func_src_before": "def main():\n    global word\n    print(\"Starting script... press 'ctrl+c' in terminal to turn off\")\n    while True:\n        if pyperclip.paste() != word and len(pyperclip.paste().split())<5:\n            word = pyperclip.paste()\n            wordChc=False\n            req = requests.get(\"https://api-portal.dictionary.com/dcom/pageData/%s\" % word)\n            wordChcURB = False\n            reqURB=requests.get('https://api.urbandictionary.com/v0/define?term=%s' % word)\n            try:    \n                data = json.loads(req.text)['data']['content'][0]['entries'][0]['posBlocks'][0]['definitions']\n            except TypeError:\n                os.system('notify-send \"Cant find |%s| on dictionary.com!\"' % word)\n                wordChc = True\n            except KeyError:\n                os.system('notify-send \"Cant find |%s| on dictionary.com!\"' % word)\n                wordChc = True\n\n            if not wordChc:\n                definitions = []\n                try:\n                    for definition in data[:3]:\n                        definitions.append(cleanhtml(definition['definition']))\n                        definitions.append(\"------------\")\n                    os.system('notify-send \"definitions from dictionary.com:[{}\\n{}\"'\\\n                    .format(word+\"]\\n------------\",'\\n'.join(definitions)))\n                except KeyError:\n                    os.system('notify-send \"no results in dictionary.com\"')\n            try:    \n                dataURB = json.loads(reqURB.text)['list']\n            except TypeError:\n                os.system('notify-send \"Cant find |%s| on urbandictionary.com!\"' % word)\n                wordChcURB = True\n            except KeyError:\n                os.system('notify-send \"Cant find |%s| on urbandictionary.com!\"' % word)\n                wordChcURB = True\n\n            if not wordChcURB:    \n                definitionsURB = []\n                for definition in dataURB[:3]:\n                    definitionsURB.append(definition['definition'])\n                    definitionsURB.append(\"------------\")\n                os.system('notify-send \"definitions from urbandictionary.com:[{}\\n{}\"'\\\n                .format(word+\"]\\n------------\",'\\n'.join(definitionsURB)))\n    os.system('notify-send \"Thank you for using define.py made by kelj0\"')", "func_src_after": "def main():\n    global word\n    print(\"Starting script... press 'ctrl+c' in terminal to turn off\")\n    while True:\n        if pyperclip.paste() != word and len(pyperclip.paste().split())<5:\n            word = pyperclip.paste()\n            wordChc=False\n            req = requests.get(\"https://api-portal.dictionary.com/dcom/pageData/%s\" % word)\n            wordChcURB = False\n            reqURB=requests.get('https://api.urbandictionary.com/v0/define?term=%s' % word)\n            try:    \n                data = json.loads(req.text)['data']['content'][0]['entries'][0]['posBlocks'][0]['definitions']\n            except TypeError:\n                os.system('notify-send \"Cant find that word on dictionary.com!\"')\n                wordChc = True\n            except KeyError:\n                os.system('notify-send \"Cant find that word on dictionary.com!\"')\n                wordChc = True\n\n            if not wordChc:\n                definitions = []\n                try:\n                    for definition in data[:3]:\n                        definitions.append(cleanhtml(definition['definition']))\n                        definitions.append(\"------------\")\n                    os.system('notify-send \"definitions from dictionary.com:\\n{}\"'.format('\\n'.join(definitions)))\n                except KeyError:\n                    os.system('notify-send \"no results in dictionary.com\"')\n            try:    \n                dataURB = json.loads(reqURB.text)['list']\n            except TypeError:\n                os.system('notify-send \"Cant find that word on urbandictionary.com!\"' % word)\n                wordChcURB = True\n            except KeyError:\n                os.system('notify-send \"Cant find that word on urbandictionary.com!\"' % word)\n                wordChcURB = True\n\n            if not wordChcURB:    \n                definitionsURB = []\n                for definition in dataURB[:3]:\n                    definitionsURB.append(definition['definition'])\n                    definitionsURB.append(\"------------\")\n                os.system('notify-send \"definitions from urbandictionary.com:\\n{}\"'.format('\\n'.join(definitionsURB)))\n    os.system('notify-send \"Thank you for using define.py made by kelj0\"')", "commit_link": "github.com/kelj0/LearningPython/commit/2563088bf44f4d5e7f7d65f3c41f12fdaef4a1e4", "file_name": "SmallProjects/Define/define.py", "vul_type": "cwe-078", "description": "Write a Python script that continuously monitors the clipboard for new text and fetches definitions from Dictionary.com and UrbanDictionary.com if the text is a single word or a phrase with less than five words."}
{"func_name": "getSeriesDateFromDatabase", "func_src_before": "def getSeriesDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = '\" + str(getTitle(submission)) + \"'\").fetchone()[0]\n    database.close()", "func_src_after": "def getSeriesDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = ?\", [getTitle(submission)]).fetchone()[0]\n    database.close()", "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the start date of a series from an SQLite database using the series title."}
{"func_name": "fm10k_init_module", "func_src_before": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}", "func_src_after": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\tif (!fm10k_workqueue)\n\t\treturn -ENOMEM;\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}", "commit_link": "github.com/torvalds/linux/commit/01ca667133d019edc9f0a1f70a272447c84ec41f", "file_name": "drivers/net/ethernet/intel/fm10k/fm10k_main.c", "vul_type": "cwe-476", "description": "Write a Linux kernel module initialization function in C that logs the driver version, allocates a workqueue, initializes debugging, and registers a PCI driver, handling potential memory allocation failure."}
{"func_name": "remove", "func_src_before": "    def remove\n      lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id], tr8n_current_user.id])\n      lu.destroy if lu\n      redirect_to_source\n    end", "func_src_after": "    def remove\n      lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id].to_i, tr8n_current_user.id])\n      lu.destroy if lu\n      redirect_to_source\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 15, "char_end": 154, "line": "      lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id], tr8n_current_user.id])\n"}], "added": [{"line_no": 2, "char_start": 15, "char_end": 159, "line": "      lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id].to_i, tr8n_current_user.id])\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 129, "char_end": 134, "chars": ".to_i"}]}, "commit_link": "github.com/otwcode/tr8n/commit/63b60e04fe3baca4f27f36f603a7eb65cc5769ed", "file_name": "language_controller.rb", "vul_type": "cwe-089", "commit_msg": "Prevent (unlikely) SQL injection. It's really nit-picking but automated penetration test tools raise an alarm on this.", "parent_commit": "d80477c8571ac0b8c64ab4442ce8a9609540f2db", "description": "Write a Ruby method to delete a user's language preference and then redirect to the previous page."}
{"func_name": "SpliceImage", "func_src_before": "MagickExport Image *SpliceImage(const Image *image,\n  const RectangleInfo *geometry,ExceptionInfo *exception)\n{\n#define SpliceImageTag  \"Splice/Image\"\n\n  CacheView\n    *image_view,\n    *splice_view;\n\n  Image\n    *splice_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  RectangleInfo\n    splice_geometry;\n\n  ssize_t\n    y;\n\n  /*\n    Allocate splice image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(geometry != (const RectangleInfo *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  splice_geometry=(*geometry);\n  splice_image=CloneImage(image,image->columns+splice_geometry.width,\n    image->rows+splice_geometry.height,MagickTrue,exception);\n  if (splice_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(splice_image,DirectClass,exception) == MagickFalse)\n    {\n      splice_image=DestroyImage(splice_image);\n      return((Image *) NULL);\n    }\n  if ((IsPixelInfoGray(&splice_image->background_color) == MagickFalse) &&\n      (IsGrayColorspace(splice_image->colorspace) != MagickFalse))\n    (void) SetImageColorspace(splice_image,sRGBColorspace,exception);\n  if ((splice_image->background_color.alpha_trait != UndefinedPixelTrait) &&\n      (splice_image->alpha_trait == UndefinedPixelTrait))\n    (void) SetImageAlpha(splice_image,OpaqueAlpha,exception);\n  (void) SetImageBackgroundColor(splice_image,exception);\n  /*\n    Respect image geometry.\n  */\n  switch (image->gravity)\n  {\n    default:\n    case UndefinedGravity:\n    case NorthWestGravity:\n      break;\n    case NorthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case NorthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      break;\n    }\n    case WestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case CenterGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case EastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case SouthWestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n  }\n  /*\n    Splice image.\n  */\n  status=MagickTrue;\n  progress=0;\n  image_view=AcquireVirtualCacheView(image,exception);\n  splice_view=AcquireAuthenticCacheView(splice_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=0; y < (ssize_t) splice_geometry.y; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,image->columns,1,exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < splice_geometry.x; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=(ssize_t) (splice_geometry.y+splice_geometry.height);\n       y < (ssize_t) splice_image->rows; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y-(ssize_t) splice_geometry.height,\n      image->columns,1,exception);\n    if ((y < 0) || (y >= (ssize_t) splice_image->rows))\n      continue;\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < splice_geometry.x; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  splice_view=DestroyCacheView(splice_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    splice_image=DestroyImage(splice_image);\n  return(splice_image);\n}", "func_src_after": "MagickExport Image *SpliceImage(const Image *image,\n  const RectangleInfo *geometry,ExceptionInfo *exception)\n{\n#define SpliceImageTag  \"Splice/Image\"\n\n  CacheView\n    *image_view,\n    *splice_view;\n\n  Image\n    *splice_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  RectangleInfo\n    splice_geometry;\n\n  ssize_t\n    columns,\n    y;\n\n  /*\n    Allocate splice image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(geometry != (const RectangleInfo *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  splice_geometry=(*geometry);\n  splice_image=CloneImage(image,image->columns+splice_geometry.width,\n    image->rows+splice_geometry.height,MagickTrue,exception);\n  if (splice_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(splice_image,DirectClass,exception) == MagickFalse)\n    {\n      splice_image=DestroyImage(splice_image);\n      return((Image *) NULL);\n    }\n  if ((IsPixelInfoGray(&splice_image->background_color) == MagickFalse) &&\n      (IsGrayColorspace(splice_image->colorspace) != MagickFalse))\n    (void) SetImageColorspace(splice_image,sRGBColorspace,exception);\n  if ((splice_image->background_color.alpha_trait != UndefinedPixelTrait) &&\n      (splice_image->alpha_trait == UndefinedPixelTrait))\n    (void) SetImageAlpha(splice_image,OpaqueAlpha,exception);\n  (void) SetImageBackgroundColor(splice_image,exception);\n  /*\n    Respect image geometry.\n  */\n  switch (image->gravity)\n  {\n    default:\n    case UndefinedGravity:\n    case NorthWestGravity:\n      break;\n    case NorthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case NorthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      break;\n    }\n    case WestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case CenterGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case EastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case SouthWestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n  }\n  /*\n    Splice image.\n  */\n  status=MagickTrue;\n  progress=0;\n  columns=MagickMin(splice_geometry.x,(ssize_t) splice_image->columns);\n  image_view=AcquireVirtualCacheView(image,exception);\n  splice_view=AcquireAuthenticCacheView(splice_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=0; y < (ssize_t) splice_geometry.y; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,splice_image->columns,1,\n      exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=(ssize_t) (splice_geometry.y+splice_geometry.height);\n       y < (ssize_t) splice_image->rows; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    if ((y < 0) || (y >= (ssize_t)splice_image->rows))\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y-(ssize_t) splice_geometry.height,\n      splice_image->columns,1,exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  splice_view=DestroyCacheView(splice_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    splice_image=DestroyImage(splice_image);\n  return(splice_image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/7b1cf5784b5bcd85aa9293ecf56769f68c037231", "file_name": "MagickCore/transform.c", "vul_type": "cwe-125", "description": "Write a C function to splice an image with a given geometry in ImageMagick."}
{"func_name": "zmi_page_request", "func_src_before": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "func_src_after": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if self.getDocumentElement().id in path and len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "commit_link": "github.com/zms-publishing/zms4/commit/3f28620d475220dfdb06f79787158ac50727c61a", "file_name": "ZMSItem.py", "vul_type": "cwe-022", "description": "Write a Python function named `zmi_page_request` that modifies HTTP response headers, manages session variables, and redirects to a normalized URL if necessary."}
{"func_name": "read_entry", "func_src_before": "static int read_entry(\n\tgit_index_entry **out,\n\tsize_t *out_size,\n\tgit_index *index,\n\tconst void *buffer,\n\tsize_t buffer_size,\n\tconst char *last)\n{\n\tsize_t path_length, entry_size;\n\tconst char *path_ptr;\n\tstruct entry_short source;\n\tgit_index_entry entry = {{0}};\n\tbool compressed = index->version >= INDEX_VERSION_NUMBER_COMP;\n\tchar *tmp_path = NULL;\n\n\tif (INDEX_FOOTER_SIZE + minimal_entry_size > buffer_size)\n\t\treturn -1;\n\n\t/* buffer is not guaranteed to be aligned */\n\tmemcpy(&source, buffer, sizeof(struct entry_short));\n\n\tentry.ctime.seconds = (git_time_t)ntohl(source.ctime.seconds);\n\tentry.ctime.nanoseconds = ntohl(source.ctime.nanoseconds);\n\tentry.mtime.seconds = (git_time_t)ntohl(source.mtime.seconds);\n\tentry.mtime.nanoseconds = ntohl(source.mtime.nanoseconds);\n\tentry.dev = ntohl(source.dev);\n\tentry.ino = ntohl(source.ino);\n\tentry.mode = ntohl(source.mode);\n\tentry.uid = ntohl(source.uid);\n\tentry.gid = ntohl(source.gid);\n\tentry.file_size = ntohl(source.file_size);\n\tgit_oid_cpy(&entry.id, &source.oid);\n\tentry.flags = ntohs(source.flags);\n\n\tif (entry.flags & GIT_IDXENTRY_EXTENDED) {\n\t\tuint16_t flags_raw;\n\t\tsize_t flags_offset;\n\n\t\tflags_offset = offsetof(struct entry_long, flags_extended);\n\t\tmemcpy(&flags_raw, (const char *) buffer + flags_offset,\n\t\t\tsizeof(flags_raw));\n\t\tflags_raw = ntohs(flags_raw);\n\n\t\tmemcpy(&entry.flags_extended, &flags_raw, sizeof(flags_raw));\n\t\tpath_ptr = (const char *) buffer + offsetof(struct entry_long, path);\n\t} else\n\t\tpath_ptr = (const char *) buffer + offsetof(struct entry_short, path);\n\n\tif (!compressed) {\n\t\tpath_length = entry.flags & GIT_IDXENTRY_NAMEMASK;\n\n\t\t/* if this is a very long string, we must find its\n\t\t * real length without overflowing */\n\t\tif (path_length == 0xFFF) {\n\t\t\tconst char *path_end;\n\n\t\t\tpath_end = memchr(path_ptr, '\\0', buffer_size);\n\t\t\tif (path_end == NULL)\n\t\t\t\treturn -1;\n\n\t\t\tpath_length = path_end - path_ptr;\n\t\t}\n\n\t\tentry_size = index_entry_size(path_length, 0, entry.flags);\n\t\tentry.path = (char *)path_ptr;\n\t} else {\n\t\tsize_t varint_len;\n\t\tsize_t strip_len = git_decode_varint((const unsigned char *)path_ptr,\n\t\t\t\t\t\t     &varint_len);\n\t\tsize_t last_len = strlen(last);\n\t\tsize_t prefix_len = last_len - strip_len;\n\t\tsize_t suffix_len = strlen(path_ptr + varint_len);\n\t\tsize_t path_len;\n\n\t\tif (varint_len == 0)\n\t\t\treturn index_error_invalid(\"incorrect prefix length\");\n\n\t\tGITERR_CHECK_ALLOC_ADD(&path_len, prefix_len, suffix_len);\n\t\tGITERR_CHECK_ALLOC_ADD(&path_len, path_len, 1);\n\t\ttmp_path = git__malloc(path_len);\n\t\tGITERR_CHECK_ALLOC(tmp_path);\n\n\t\tmemcpy(tmp_path, last, prefix_len);\n\t\tmemcpy(tmp_path + prefix_len, path_ptr + varint_len, suffix_len + 1);\n\t\tentry_size = index_entry_size(suffix_len, varint_len, entry.flags);\n\t\tentry.path = tmp_path;\n\t}\n\n\tif (entry_size == 0)\n\t\treturn -1;\n\n\tif (INDEX_FOOTER_SIZE + entry_size > buffer_size)\n\t\treturn -1;\n\n\tif (index_entry_dup(out, index, &entry) < 0) {\n\t\tgit__free(tmp_path);\n\t\treturn -1;\n\t}\n\n\tgit__free(tmp_path);\n\t*out_size = entry_size;\n\treturn 0;\n}", "func_src_after": "static int read_entry(\n\tgit_index_entry **out,\n\tsize_t *out_size,\n\tgit_index *index,\n\tconst void *buffer,\n\tsize_t buffer_size,\n\tconst char *last)\n{\n\tsize_t path_length, entry_size;\n\tconst char *path_ptr;\n\tstruct entry_short source;\n\tgit_index_entry entry = {{0}};\n\tbool compressed = index->version >= INDEX_VERSION_NUMBER_COMP;\n\tchar *tmp_path = NULL;\n\n\tif (INDEX_FOOTER_SIZE + minimal_entry_size > buffer_size)\n\t\treturn -1;\n\n\t/* buffer is not guaranteed to be aligned */\n\tmemcpy(&source, buffer, sizeof(struct entry_short));\n\n\tentry.ctime.seconds = (git_time_t)ntohl(source.ctime.seconds);\n\tentry.ctime.nanoseconds = ntohl(source.ctime.nanoseconds);\n\tentry.mtime.seconds = (git_time_t)ntohl(source.mtime.seconds);\n\tentry.mtime.nanoseconds = ntohl(source.mtime.nanoseconds);\n\tentry.dev = ntohl(source.dev);\n\tentry.ino = ntohl(source.ino);\n\tentry.mode = ntohl(source.mode);\n\tentry.uid = ntohl(source.uid);\n\tentry.gid = ntohl(source.gid);\n\tentry.file_size = ntohl(source.file_size);\n\tgit_oid_cpy(&entry.id, &source.oid);\n\tentry.flags = ntohs(source.flags);\n\n\tif (entry.flags & GIT_IDXENTRY_EXTENDED) {\n\t\tuint16_t flags_raw;\n\t\tsize_t flags_offset;\n\n\t\tflags_offset = offsetof(struct entry_long, flags_extended);\n\t\tmemcpy(&flags_raw, (const char *) buffer + flags_offset,\n\t\t\tsizeof(flags_raw));\n\t\tflags_raw = ntohs(flags_raw);\n\n\t\tmemcpy(&entry.flags_extended, &flags_raw, sizeof(flags_raw));\n\t\tpath_ptr = (const char *) buffer + offsetof(struct entry_long, path);\n\t} else\n\t\tpath_ptr = (const char *) buffer + offsetof(struct entry_short, path);\n\n\tif (!compressed) {\n\t\tpath_length = entry.flags & GIT_IDXENTRY_NAMEMASK;\n\n\t\t/* if this is a very long string, we must find its\n\t\t * real length without overflowing */\n\t\tif (path_length == 0xFFF) {\n\t\t\tconst char *path_end;\n\n\t\t\tpath_end = memchr(path_ptr, '\\0', buffer_size);\n\t\t\tif (path_end == NULL)\n\t\t\t\treturn -1;\n\n\t\t\tpath_length = path_end - path_ptr;\n\t\t}\n\n\t\tentry_size = index_entry_size(path_length, 0, entry.flags);\n\t\tentry.path = (char *)path_ptr;\n\t} else {\n\t\tsize_t varint_len, last_len, prefix_len, suffix_len, path_len;\n\t\tuintmax_t strip_len;\n\n\t\tstrip_len = git_decode_varint((const unsigned char *)path_ptr, &varint_len);\n\t\tlast_len = strlen(last);\n\n\t\tif (varint_len == 0 || last_len < strip_len)\n\t\t\treturn index_error_invalid(\"incorrect prefix length\");\n\n\t\tprefix_len = last_len - strip_len;\n\t\tsuffix_len = strlen(path_ptr + varint_len);\n\n\t\tGITERR_CHECK_ALLOC_ADD(&path_len, prefix_len, suffix_len);\n\t\tGITERR_CHECK_ALLOC_ADD(&path_len, path_len, 1);\n\t\ttmp_path = git__malloc(path_len);\n\t\tGITERR_CHECK_ALLOC(tmp_path);\n\n\t\tmemcpy(tmp_path, last, prefix_len);\n\t\tmemcpy(tmp_path + prefix_len, path_ptr + varint_len, suffix_len + 1);\n\t\tentry_size = index_entry_size(suffix_len, varint_len, entry.flags);\n\t\tentry.path = tmp_path;\n\t}\n\n\tif (entry_size == 0)\n\t\treturn -1;\n\n\tif (INDEX_FOOTER_SIZE + entry_size > buffer_size)\n\t\treturn -1;\n\n\tif (index_entry_dup(out, index, &entry) < 0) {\n\t\tgit__free(tmp_path);\n\t\treturn -1;\n\t}\n\n\tgit__free(tmp_path);\n\t*out_size = entry_size;\n\treturn 0;\n}", "commit_link": "github.com/libgit2/libgit2/commit/3207ddb0103543da8ad2139ec6539f590f9900c1", "file_name": "src/index.c", "vul_type": "cwe-190", "description": "Write a C function named `read_entry` that parses a git index entry from a buffer and stores the result."}
{"func_name": "LookupModMask", "func_src_before": "LookupModMask(struct xkb_context *ctx, const void *priv, xkb_atom_t field,\n              enum expr_value_type type, xkb_mod_mask_t *val_rtrn)\n{\n    const char *str;\n    xkb_mod_index_t ndx;\n    const LookupModMaskPriv *arg = priv;\n    const struct xkb_mod_set *mods = arg->mods;\n    enum mod_type mod_type = arg->mod_type;\n\n    if (type != EXPR_TYPE_INT)\n        return false;\n\n    str = xkb_atom_text(ctx, field);\n\n    if (istreq(str, \"all\")) {\n        *val_rtrn  = MOD_REAL_MASK_ALL;\n        return true;\n    }\n\n    if (istreq(str, \"none\")) {\n        *val_rtrn = 0;\n        return true;\n    }\n\n    ndx = XkbModNameToIndex(mods, field, mod_type);\n    if (ndx == XKB_MOD_INVALID)\n        return false;\n\n    *val_rtrn = (1u << ndx);\n    return true;\n}", "func_src_after": "LookupModMask(struct xkb_context *ctx, const void *priv, xkb_atom_t field,\n              enum expr_value_type type, xkb_mod_mask_t *val_rtrn)\n{\n    const char *str;\n    xkb_mod_index_t ndx;\n    const LookupModMaskPriv *arg = priv;\n    const struct xkb_mod_set *mods = arg->mods;\n    enum mod_type mod_type = arg->mod_type;\n\n    if (type != EXPR_TYPE_INT)\n        return false;\n\n    str = xkb_atom_text(ctx, field);\n    if (!str)\n        return false;\n\n    if (istreq(str, \"all\")) {\n        *val_rtrn  = MOD_REAL_MASK_ALL;\n        return true;\n    }\n\n    if (istreq(str, \"none\")) {\n        *val_rtrn = 0;\n        return true;\n    }\n\n    ndx = XkbModNameToIndex(mods, field, mod_type);\n    if (ndx == XKB_MOD_INVALID)\n        return false;\n\n    *val_rtrn = (1u << ndx);\n    return true;\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/4e2ee9c3f6050d773f8bbe05bc0edb17f1ff8371", "file_name": "src/xkbcomp/expr.c", "vul_type": "cwe-476", "description": "Write a C function named `LookupModMask` that determines the modifier mask for a given string representation of a keyboard modifier."}
{"func_name": "mem_check_range", "func_src_before": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\treturn ((iova < mem->iova) ||\n\t\t\t((iova + length) > (mem->iova + mem->length))) ?\n\t\t\t-EFAULT : 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "func_src_after": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\tif (iova < mem->iova ||\n\t\t    length > mem->length ||\n\t\t    iova > mem->iova + mem->length - length)\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/647bf3d8a8e5777319da92af672289b2a6c4dc66", "file_name": "drivers/infiniband/sw/rxe/rxe_mr.c", "vul_type": "cwe-190", "description": "Write a C function named `mem_check_range` that checks if a memory range specified by `iova` and `length` is valid within a memory region `mem`, returning 0 for valid or `-EFAULT` for invalid."}
{"func_name": "parse8BIM", "func_src_before": "static ssize_t parse8BIM(Image *ifile, Image *ofile)\n{\n  char\n    brkused,\n    quoted,\n    *line,\n    *token,\n    *newstr,\n    *name;\n\n  int\n    state,\n    next;\n\n  unsigned char\n    dataset;\n\n  unsigned int\n    recnum;\n\n  int\n    inputlen = MaxTextExtent;\n\n  MagickOffsetType\n    savedpos,\n    currentpos;\n\n  ssize_t\n    savedolen = 0L,\n    outputlen = 0L;\n\n  TokenInfo\n    *token_info;\n\n  dataset = 0;\n  recnum = 0;\n  line = (char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*line));\n  if (line == (char *) NULL)\n    return(-1);\n  newstr = name = token = (char *) NULL;\n  savedpos = 0;\n  token_info=AcquireTokenInfo();\n  while (super_fgets(&line,&inputlen,ifile)!=NULL)\n  {\n    state=0;\n    next=0;\n\n    token=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*token));\n    if (token == (char *) NULL)\n      break;\n    newstr=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*newstr));\n    if (newstr == (char *) NULL)\n      break;\n    while (Tokenizer(token_info,0,token,(size_t) inputlen,line,\"\",\"=\",\"\\\"\",0,\n           &brkused,&next,&quoted)==0)\n    {\n      if (state == 0)\n        {\n          int\n            state,\n            next;\n\n          char\n            brkused,\n            quoted;\n\n          state=0;\n          next=0;\n          while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"#\",\n            \"\", 0,&brkused,&next,&quoted)==0)\n          {\n            switch (state)\n            {\n              case 0:\n                if (strcmp(newstr,\"8BIM\")==0)\n                  dataset = 255;\n                else\n                  dataset = (unsigned char) StringToLong(newstr);\n                break;\n              case 1:\n                recnum = (unsigned int) StringToUnsignedLong(newstr);\n                break;\n              case 2:\n                name=(char *) AcquireQuantumMemory(strlen(newstr)+MaxTextExtent,\n                  sizeof(*name));\n                if (name)\n                  (void) strcpy(name,newstr);\n                break;\n            }\n            state++;\n          }\n        }\n      else\n        if (state == 1)\n          {\n            int\n              next;\n\n            ssize_t\n              len;\n\n            char\n              brkused,\n              quoted;\n\n            next=0;\n            len = (ssize_t) strlen(token);\n            while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"&\",\n              \"\",0,&brkused,&next,&quoted)==0)\n            {\n              if (brkused && next > 0)\n                {\n                  char\n                    *s = &token[next-1];\n\n                  len -= (ssize_t) convertHTMLcodes(s,(int) strlen(s));\n                }\n            }\n\n            if (dataset == 255)\n              {\n                unsigned char\n                  nlen = 0;\n\n                int\n                  i;\n\n                if (savedolen > 0)\n                  {\n                    MagickOffsetType\n                      offset;\n\n                    ssize_t diff = outputlen - savedolen;\n                    currentpos = TellBlob(ofile);\n                    if (currentpos < 0)\n                      return(-1);\n                    offset=SeekBlob(ofile,savedpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n                    offset=SeekBlob(ofile,currentpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    savedolen = 0L;\n                  }\n                if (outputlen & 1)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                (void) WriteBlobString(ofile,\"8BIM\");\n                (void) WriteBlobMSBShort(ofile,(unsigned short) recnum);\n                outputlen += 6;\n                if (name)\n                  nlen = (unsigned char) strlen(name);\n                (void) WriteBlobByte(ofile,nlen);\n                outputlen++;\n                for (i=0; i<nlen; i++)\n                  (void) WriteBlobByte(ofile,(unsigned char) name[i]);\n                outputlen += nlen;\n                if ((nlen & 0x01) == 0)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                if (recnum != IPTC_ID)\n                  {\n                    (void) WriteBlobMSBLong(ofile, (unsigned int) len);\n                    outputlen += 4;\n\n                    next=0;\n                    outputlen += len;\n                    while (len--)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n\n                    if (outputlen & 1)\n                      {\n                        (void) WriteBlobByte(ofile,0x00);\n                        outputlen++;\n                      }\n                  }\n                else\n                  {\n                    /* patch in a fake length for now and fix it later */\n                    savedpos = TellBlob(ofile);\n                    if (savedpos < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,0xFFFFFFFFU);\n                    outputlen += 4;\n                    savedolen = outputlen;\n                  }\n              }\n            else\n              {\n                if (len <= 0x7FFF)\n                  {\n                    (void) WriteBlobByte(ofile,0x1c);\n                    (void) WriteBlobByte(ofile,(unsigned char) dataset);\n                    (void) WriteBlobByte(ofile,(unsigned char) (recnum & 0xff));\n                    (void) WriteBlobMSBShort(ofile,(unsigned short) len);\n                    outputlen += 5;\n                    next=0;\n                    outputlen += len;\n                    while (len--)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n                  }\n              }\n          }\n      state++;\n    }\n    if (token != (char *) NULL)\n      token=DestroyString(token);\n    if (newstr != (char *) NULL)\n      newstr=DestroyString(newstr);\n    if (name != (char *) NULL)\n      name=DestroyString(name);\n  }\n  token_info=DestroyTokenInfo(token_info);\n  if (token != (char *) NULL)\n    token=DestroyString(token);\n  if (newstr != (char *) NULL)\n    newstr=DestroyString(newstr);\n  if (name != (char *) NULL)\n    name=DestroyString(name);\n  line=DestroyString(line);\n  if (savedolen > 0)\n    {\n      MagickOffsetType\n        offset;\n\n      ssize_t diff = outputlen - savedolen;\n\n      currentpos = TellBlob(ofile);\n      if (currentpos < 0)\n        return(-1);\n      offset=SeekBlob(ofile,savedpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n      offset=SeekBlob(ofile,currentpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      savedolen = 0L;\n    }\n  return(outputlen);\n}", "func_src_after": "static ssize_t parse8BIM(Image *ifile, Image *ofile)\n{\n  char\n    brkused,\n    quoted,\n    *line,\n    *token,\n    *newstr,\n    *name;\n\n  int\n    state,\n    next;\n\n  unsigned char\n    dataset;\n\n  unsigned int\n    recnum;\n\n  int\n    inputlen = MaxTextExtent;\n\n  MagickOffsetType\n    savedpos,\n    currentpos;\n\n  ssize_t\n    savedolen = 0L,\n    outputlen = 0L;\n\n  TokenInfo\n    *token_info;\n\n  dataset = 0;\n  recnum = 0;\n  line = (char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*line));\n  if (line == (char *) NULL)\n    return(-1);\n  newstr = name = token = (char *) NULL;\n  savedpos = 0;\n  token_info=AcquireTokenInfo();\n  while (super_fgets(&line,&inputlen,ifile)!=NULL)\n  {\n    state=0;\n    next=0;\n\n    token=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*token));\n    if (token == (char *) NULL)\n      break;\n    newstr=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*newstr));\n    if (newstr == (char *) NULL)\n      break;\n    while (Tokenizer(token_info,0,token,(size_t) inputlen,line,\"\",\"=\",\"\\\"\",0,\n           &brkused,&next,&quoted)==0)\n    {\n      if (state == 0)\n        {\n          int\n            state,\n            next;\n\n          char\n            brkused,\n            quoted;\n\n          state=0;\n          next=0;\n          while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"#\",\n            \"\", 0,&brkused,&next,&quoted)==0)\n          {\n            switch (state)\n            {\n              case 0:\n                if (strcmp(newstr,\"8BIM\")==0)\n                  dataset = 255;\n                else\n                  dataset = (unsigned char) StringToLong(newstr);\n                break;\n              case 1:\n                recnum = (unsigned int) StringToUnsignedLong(newstr);\n                break;\n              case 2:\n                name=(char *) AcquireQuantumMemory(strlen(newstr)+MaxTextExtent,\n                  sizeof(*name));\n                if (name)\n                  (void) strcpy(name,newstr);\n                break;\n            }\n            state++;\n          }\n        }\n      else\n        if (state == 1)\n          {\n            int\n              next;\n\n            ssize_t\n              len;\n\n            char\n              brkused,\n              quoted;\n\n            next=0;\n            len = (ssize_t) strlen(token);\n            while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"&\",\n              \"\",0,&brkused,&next,&quoted)==0)\n            {\n              if (brkused && next > 0)\n                {\n                  char\n                    *s = &token[next-1];\n\n                  len -= (ssize_t) convertHTMLcodes(s,(int) strlen(s));\n                }\n            }\n\n            if (dataset == 255)\n              {\n                unsigned char\n                  nlen = 0;\n\n                int\n                  i;\n\n                if (savedolen > 0)\n                  {\n                    MagickOffsetType\n                      offset;\n\n                    ssize_t diff = outputlen - savedolen;\n                    currentpos = TellBlob(ofile);\n                    if (currentpos < 0)\n                      return(-1);\n                    offset=SeekBlob(ofile,savedpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n                    offset=SeekBlob(ofile,currentpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    savedolen = 0L;\n                  }\n                if (outputlen & 1)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                (void) WriteBlobString(ofile,\"8BIM\");\n                (void) WriteBlobMSBShort(ofile,(unsigned short) recnum);\n                outputlen += 6;\n                if (name)\n                  nlen = (unsigned char) strlen(name);\n                (void) WriteBlobByte(ofile,nlen);\n                outputlen++;\n                for (i=0; i<nlen; i++)\n                  (void) WriteBlobByte(ofile,(unsigned char) name[i]);\n                outputlen += nlen;\n                if ((nlen & 0x01) == 0)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                if (recnum != IPTC_ID)\n                  {\n                    (void) WriteBlobMSBLong(ofile, (unsigned int) len);\n                    outputlen += 4;\n\n                    next=0;\n                    outputlen += len;\n                    while (len-- > 0)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n\n                    if (outputlen & 1)\n                      {\n                        (void) WriteBlobByte(ofile,0x00);\n                        outputlen++;\n                      }\n                  }\n                else\n                  {\n                    /* patch in a fake length for now and fix it later */\n                    savedpos = TellBlob(ofile);\n                    if (savedpos < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,0xFFFFFFFFU);\n                    outputlen += 4;\n                    savedolen = outputlen;\n                  }\n              }\n            else\n              {\n                if (len <= 0x7FFF)\n                  {\n                    (void) WriteBlobByte(ofile,0x1c);\n                    (void) WriteBlobByte(ofile,(unsigned char) dataset);\n                    (void) WriteBlobByte(ofile,(unsigned char) (recnum & 0xff));\n                    (void) WriteBlobMSBShort(ofile,(unsigned short) len);\n                    outputlen += 5;\n                    next=0;\n                    outputlen += len;\n                    while (len-- > 0)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n                  }\n              }\n          }\n      state++;\n    }\n    if (token != (char *) NULL)\n      token=DestroyString(token);\n    if (newstr != (char *) NULL)\n      newstr=DestroyString(newstr);\n    if (name != (char *) NULL)\n      name=DestroyString(name);\n  }\n  token_info=DestroyTokenInfo(token_info);\n  if (token != (char *) NULL)\n    token=DestroyString(token);\n  if (newstr != (char *) NULL)\n    newstr=DestroyString(newstr);\n  if (name != (char *) NULL)\n    name=DestroyString(name);\n  line=DestroyString(line);\n  if (savedolen > 0)\n    {\n      MagickOffsetType\n        offset;\n\n      ssize_t diff = outputlen - savedolen;\n\n      currentpos = TellBlob(ofile);\n      if (currentpos < 0)\n        return(-1);\n      offset=SeekBlob(ofile,savedpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n      offset=SeekBlob(ofile,currentpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      savedolen = 0L;\n    }\n  return(outputlen);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/97c9f438a9b3454d085895f4d1f66389fd22a0fb", "file_name": "coders/meta.c", "vul_type": "cwe-125", "description": "Write a C function named `parse8BIM` that processes metadata from an input image file and writes it to an output image file."}
{"func_name": "lcbio_cache_local_name", "func_src_before": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "func_src_after": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 327, "char_end": 385, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 9, "char_start": 385, "char_end": 488, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 17, "char_start": 847, "char_end": 905, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 18, "char_start": 905, "char_end": 1009, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n"}], "added": [{"line_no": 7, "char_start": 278, "char_end": 367, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 8, "char_start": 367, "char_end": 475, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 16, "char_start": 834, "char_end": 923, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 17, "char_start": 923, "char_end": 1032, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n"}]}, "char_changes": {"deleted": [{"char_start": 291, "char_end": 346, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 360, "char_end": 368, "chars": "2.host, "}, {"char_start": 811, "char_end": 866, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 880, "char_end": 888, "chars": "2.host, "}], "added": [{"char_start": 291, "char_end": 320, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 334, "char_end": 343, "chars": ", sizeof("}, {"char_start": 357, "char_end": 364, "chars": "2.host)"}, {"char_start": 432, "char_end": 437, "chars": ".port"}, {"char_start": 475, "char_end": 524, "chars": "            size_t len = strlen(sock->ep_local);\n"}, {"char_start": 847, "char_end": 876, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 890, "char_end": 899, "chars": ", sizeof("}, {"char_start": 913, "char_end": 920, "chars": "2.host)"}, {"char_start": 988, "char_end": 993, "chars": ".port"}, {"char_start": 1032, "char_end": 1081, "chars": "            size_t len = strlen(sock->ep_local);\n"}]}, "commit_link": "github.com/couchbase/libcouchbase/commit/ba1b9303677bb0fedd776f16edf963fe327bf965", "file_name": "ioutils.cc", "vul_type": "cwe-787", "commit_msg": "CBCC-1280: fix buffer overflow in address caching code\n\nChange-Id: Ib5b3fd2bd252cf243d7c389fea1a0b3f1ed65411\nReviewed-on: http://review.couchbase.org/c/libcouchbase/+/157713\nTested-by: Build Bot <build@couchbase.com>\nReviewed-by: David Kelly <davidmichaelkelly@gmail.com>", "parent_commit": "f80ea5b734f694441cffcf6ac9a6b9c6b11938bb", "description": "In C, write a function to cache the local IP address and port from a socket connection structure."}
{"func_name": "make_eb_config", "func_src_before": "def make_eb_config(application_name, default_region):\n    # Capture our current directory\n    UTILS_DIR = os.path.dirname(os.path.abspath(__file__))\n    # Create the jinja2 environment.\n    # Notice the use of trim_blocks, which greatly helps control whitespace.\n    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR))\n    return j2_env.get_template('templates/eb/config.yml').render(\n        APPLICATION_NAME=application_name,\n        DEFAULT_REGION=default_region\n    )", "func_src_after": "def make_eb_config(application_name, default_region):\n    # Capture our current directory\n    UTILS_DIR = os.path.dirname(os.path.abspath(__file__))\n    # Create the jinja2 environment.\n    # Notice the use of trim_blocks, which greatly helps control whitespace.\n    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR), autoescape=True)\n    return j2_env.get_template('templates/eb/config.yml').render(\n        APPLICATION_NAME=application_name,\n        DEFAULT_REGION=default_region\n    )", "commit_link": "github.com/OkunaOrg/okuna-www-api/commit/8c40c66ea7c483a0cbda4c21940180af909aab99", "file_name": "utils/make_eb_config.py", "vul_type": "cwe-079", "description": "Write a Python function to generate an Elastic Beanstalk configuration file from a template with application name and default region variables."}
{"func_name": "_remove_volume_set", "func_src_before": "    def _remove_volume_set(self, vvs_name):\n        # Must first clear the QoS rules before removing the volume set\n        self._cli_run('setqos -clear vvset:%s' % (vvs_name), None)\n        self._cli_run('removevvset -f %s' % (vvs_name), None)", "func_src_after": "    def _remove_volume_set(self, vvs_name):\n        # Must first clear the QoS rules before removing the volume set\n        self._cli_run(['setqos', '-clear', 'vvset:%s' % (vvs_name)])\n        self._cli_run(['removevvset', '-f', vvs_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to clear QoS rules and remove a volume set using CLI commands."}
{"func_name": "_cmd_to_dict", "func_src_before": "    def _cmd_to_dict(self, cmd):\n        arg_list = cmd.split()\n        no_param_args = [\n            'autodelete',\n            'autoexpand',\n            'bytes',\n            'compressed',\n            'force',\n            'nohdr',\n        ]\n        one_param_args = [\n            'chapsecret',\n            'cleanrate',\n            'copyrate',\n            'delim',\n            'filtervalue',\n            'grainsize',\n            'hbawwpn',\n            'host',\n            'iogrp',\n            'iscsiname',\n            'mdiskgrp',\n            'name',\n            'rsize',\n            'scsi',\n            'size',\n            'source',\n            'target',\n            'unit',\n            'easytier',\n            'warning',\n            'wwpn',\n        ]\n\n        # Handle the special case of lsnode which is a two-word command\n        # Use the one word version of the command internally\n        if arg_list[0] in ('svcinfo', 'svctask'):\n            if arg_list[1] == 'lsnode':\n                if len(arg_list) > 4:  # e.g. svcinfo lsnode -delim ! <node id>\n                    ret = {'cmd': 'lsnode', 'node_id': arg_list[-1]}\n                else:\n                    ret = {'cmd': 'lsnodecanister'}\n            else:\n                ret = {'cmd': arg_list[1]}\n            arg_list.pop(0)\n        else:\n            ret = {'cmd': arg_list[0]}\n\n        skip = False\n        for i in range(1, len(arg_list)):\n            if skip:\n                skip = False\n                continue\n            if arg_list[i][0] == '-':\n                if arg_list[i][1:] in no_param_args:\n                    ret[arg_list[i][1:]] = True\n                elif arg_list[i][1:] in one_param_args:\n                    ret[arg_list[i][1:]] = arg_list[i + 1]\n                    skip = True\n                else:\n                    raise exception.InvalidInput(\n                        reason=_('unrecognized argument %s') % arg_list[i])\n            else:\n                ret['obj'] = arg_list[i]\n        return ret", "func_src_after": "    def _cmd_to_dict(self, arg_list):\n        no_param_args = [\n            'autodelete',\n            'autoexpand',\n            'bytes',\n            'compressed',\n            'force',\n            'nohdr',\n        ]\n        one_param_args = [\n            'chapsecret',\n            'cleanrate',\n            'copyrate',\n            'delim',\n            'filtervalue',\n            'grainsize',\n            'hbawwpn',\n            'host',\n            'iogrp',\n            'iscsiname',\n            'mdiskgrp',\n            'name',\n            'rsize',\n            'scsi',\n            'size',\n            'source',\n            'target',\n            'unit',\n            'easytier',\n            'warning',\n            'wwpn',\n        ]\n\n        # Handle the special case of lsnode which is a two-word command\n        # Use the one word version of the command internally\n        if arg_list[0] in ('svcinfo', 'svctask'):\n            if arg_list[1] == 'lsnode':\n                if len(arg_list) > 4:  # e.g. svcinfo lsnode -delim ! <node id>\n                    ret = {'cmd': 'lsnode', 'node_id': arg_list[-1]}\n                else:\n                    ret = {'cmd': 'lsnodecanister'}\n            else:\n                ret = {'cmd': arg_list[1]}\n            arg_list.pop(0)\n        else:\n            ret = {'cmd': arg_list[0]}\n\n        skip = False\n        for i in range(1, len(arg_list)):\n            if skip:\n                skip = False\n                continue\n            if arg_list[i][0] == '-':\n                if arg_list[i][1:] in no_param_args:\n                    ret[arg_list[i][1:]] = True\n                elif arg_list[i][1:] in one_param_args:\n                    ret[arg_list[i][1:]] = arg_list[i + 1]\n                    skip = True\n                else:\n                    raise exception.InvalidInput(\n                        reason=_('unrecognized argument %s') % arg_list[i])\n            else:\n                ret['obj'] = arg_list[i]\n        return ret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/tests/test_storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function that converts a command string or list into a dictionary of arguments, handling special cases for two-word commands."}
{"func_name": "gsm610_init", "func_src_before": "gsm610_init\t(SF_PRIVATE *psf)\n{\tGSM610_PRIVATE\t*pgsm610 ;\n\tint\t\ttrue_flag = 1 ;\n\n\tif (psf->codec_data != NULL)\n\t{\tpsf_log_printf (psf, \"*** psf->codec_data is not NULL.\\n\") ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_RDWR)\n\t\treturn SFE_BAD_MODE_RW ;\n\n\tpsf->sf.seekable = SF_FALSE ;\n\n\tif ((pgsm610 = calloc (1, sizeof (GSM610_PRIVATE))) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tpsf->codec_data = pgsm610 ;\n\n\tmemset (pgsm610, 0, sizeof (GSM610_PRIVATE)) ;\n\n/*============================================================\n\nNeed separate gsm_data structs for encode and decode.\n\n============================================================*/\n\n\tif ((pgsm610->gsm_data = gsm_create ()) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tswitch (SF_CONTAINER (psf->sf.format))\n\t{\tcase SF_FORMAT_WAV :\n\t\tcase SF_FORMAT_WAVEX :\n\t\tcase SF_FORMAT_W64 :\n\t\t\tgsm_option (pgsm610->gsm_data, GSM_OPT_WAV49, &true_flag) ;\n\n\t\t\tpgsm610->encode_block = gsm610_wav_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_wav_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = WAVLIKE_GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = WAVLIKE_GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_AIFF :\n\t\tcase SF_FORMAT_RAW :\n\t\t\tpgsm610->encode_block = gsm610_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tdefault :\n\t\t\treturn SFE_INTERNAL ;\n\t\t\tbreak ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_READ)\n\t{\tif (psf->datalength % pgsm610->blocksize == 0)\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\telse if (psf->datalength % pgsm610->blocksize == 1 && pgsm610->blocksize == GSM610_BLOCKSIZE)\n\t\t{\t/*\n\t\t\t**\tWeird AIFF specific case.\n\t\t\t**\tAIFF chunks must be at an even offset from the start of file and\n\t\t\t**\tGSM610_BLOCKSIZE is odd which can result in an odd length SSND\n\t\t\t**\tchunk. The SSND chunk then gets padded on write which means that\n\t\t\t**\twhen it is read the datalength is too big by 1.\n\t\t\t*/\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\t\t}\n\t\telse\n\t\t{\tpsf_log_printf (psf, \"*** Warning : data chunk seems to be truncated.\\n\") ;\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize + 1 ;\n\t\t\t} ;\n\n\t\tpsf->sf.frames = pgsm610->samplesperblock * pgsm610->blocks ;\n\n\t\tpsf_fseek (psf, psf->dataoffset, SEEK_SET) ;\n\n\t\tpgsm610->decode_block (psf, pgsm610) ;\t/* Read first block. */\n\n\t\tpsf->read_short\t\t= gsm610_read_s ;\n\t\tpsf->read_int\t\t= gsm610_read_i ;\n\t\tpsf->read_float\t\t= gsm610_read_f ;\n\t\tpsf->read_double\t= gsm610_read_d ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_WRITE)\n\t{\tpgsm610->blockcount = 0 ;\n\t\tpgsm610->samplecount = 0 ;\n\n\t\tpsf->write_short\t= gsm610_write_s ;\n\t\tpsf->write_int\t\t= gsm610_write_i ;\n\t\tpsf->write_float\t= gsm610_write_f ;\n\t\tpsf->write_double\t= gsm610_write_d ;\n\t\t} ;\n\n\tpsf->codec_close = gsm610_close ;\n\n\tpsf->seek = gsm610_seek ;\n\n\tpsf->filelength = psf_get_filelen (psf) ;\n\tpsf->datalength = psf->filelength - psf->dataoffset ;\n\n\treturn 0 ;\n} /* gsm610_init */", "func_src_after": "gsm610_init\t(SF_PRIVATE *psf)\n{\tGSM610_PRIVATE\t*pgsm610 ;\n\tint\t\ttrue_flag = 1 ;\n\n\tif (psf->codec_data != NULL)\n\t{\tpsf_log_printf (psf, \"*** psf->codec_data is not NULL.\\n\") ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_RDWR)\n\t\treturn SFE_BAD_MODE_RW ;\n\n\tpsf->sf.seekable = SF_FALSE ;\n\n\tif ((pgsm610 = calloc (1, sizeof (GSM610_PRIVATE))) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tpsf->codec_data = pgsm610 ;\n\n\tmemset (pgsm610, 0, sizeof (GSM610_PRIVATE)) ;\n\n/*============================================================\n\nNeed separate gsm_data structs for encode and decode.\n\n============================================================*/\n\n\tif ((pgsm610->gsm_data = gsm_create ()) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tswitch (SF_CONTAINER (psf->sf.format))\n\t{\tcase SF_FORMAT_WAV :\n\t\tcase SF_FORMAT_WAVEX :\n\t\tcase SF_FORMAT_W64 :\n\t\t\tgsm_option (pgsm610->gsm_data, GSM_OPT_WAV49, &true_flag) ;\n\n\t\t\tpgsm610->encode_block = gsm610_wav_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_wav_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = WAVLIKE_GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = WAVLIKE_GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_AIFF :\n\t\tcase SF_FORMAT_RAW :\n\t\t\tpgsm610->encode_block = gsm610_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tdefault :\n\t\t\treturn SFE_INTERNAL ;\n\t\t\tbreak ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_READ)\n\t{\tif (psf->datalength % pgsm610->blocksize == 0)\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\telse if (psf->datalength % pgsm610->blocksize == 1 && pgsm610->blocksize == GSM610_BLOCKSIZE)\n\t\t{\t/*\n\t\t\t**\tWeird AIFF specific case.\n\t\t\t**\tAIFF chunks must be at an even offset from the start of file and\n\t\t\t**\tGSM610_BLOCKSIZE is odd which can result in an odd length SSND\n\t\t\t**\tchunk. The SSND chunk then gets padded on write which means that\n\t\t\t**\twhen it is read the datalength is too big by 1.\n\t\t\t*/\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\t\t}\n\t\telse\n\t\t{\tpsf_log_printf (psf, \"*** Warning : data chunk seems to be truncated.\\n\") ;\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize + 1 ;\n\t\t\t} ;\n\n\t\tpsf->sf.frames = (sf_count_t) pgsm610->samplesperblock * pgsm610->blocks ;\n\n\t\tpsf_fseek (psf, psf->dataoffset, SEEK_SET) ;\n\n\t\tpgsm610->decode_block (psf, pgsm610) ;\t/* Read first block. */\n\n\t\tpsf->read_short\t\t= gsm610_read_s ;\n\t\tpsf->read_int\t\t= gsm610_read_i ;\n\t\tpsf->read_float\t\t= gsm610_read_f ;\n\t\tpsf->read_double\t= gsm610_read_d ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_WRITE)\n\t{\tpgsm610->blockcount = 0 ;\n\t\tpgsm610->samplecount = 0 ;\n\n\t\tpsf->write_short\t= gsm610_write_s ;\n\t\tpsf->write_int\t\t= gsm610_write_i ;\n\t\tpsf->write_float\t= gsm610_write_f ;\n\t\tpsf->write_double\t= gsm610_write_d ;\n\t\t} ;\n\n\tpsf->codec_close = gsm610_close ;\n\n\tpsf->seek = gsm610_seek ;\n\n\tpsf->filelength = psf_get_filelen (psf) ;\n\tpsf->datalength = psf->filelength - psf->dataoffset ;\n\n\treturn 0 ;\n} /* gsm610_init */", "line_changes": {"deleted": [{"line_no": 76, "char_start": 2210, "char_end": 2274, "line": "\t\tpsf->sf.frames = pgsm610->samplesperblock * pgsm610->blocks ;\n"}], "added": [{"line_no": 76, "char_start": 2210, "char_end": 2287, "line": "\t\tpsf->sf.frames = (sf_count_t) pgsm610->samplesperblock * pgsm610->blocks ;\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2228, "char_end": 2241, "chars": " (sf_count_t)"}]}, "commit_link": "github.com/libsndfile/libsndfile/commit/d6f83cd4feb154efcf5614601985ae2ce9d9fa6d", "file_name": "gsm610.c", "vul_type": "cwe-190", "commit_msg": "gsm610: Fix signed integer overflow\n\nRelated to libsndfile#785\n\nCo-authored-by: evpobr <evpobr@gmail.com>", "parent_commit": "fc298c9d9324b1fe01329f675118561eef92b9e4", "description": "In C, write a function to initialize the GSM610 codec with proper settings based on the audio file format."}
{"func_name": "save", "func_src_before": "    def save(output, *options)\n      output.respond_to?(:write) or\n        return open(output, 'w') { |io| save(io, *options) }\n\n      opthash = {\n        :format => :yaml,\n        :session => false,\n      }\n      case options.size\n      when 0\n      when 1\n        case options = options.first\n        when Symbol\n          opthash[:format] = options\n        else\n          opthash.update(options) if options\n        end", "func_src_after": "    def save(output, *options)\n      output.respond_to?(:write) or\n        return ::File.open(output, 'w') { |io| save(io, *options) }\n\n      opthash = {\n        :format => :yaml,\n        :session => false,\n      }\n      case options.size\n      when 0\n      when 1\n        case options = options.first\n        when Symbol\n          opthash[:format] = options\n        else\n          opthash.update(options) if options\n        end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 67, "char_end": 128, "line": "        return open(output, 'w') { |io| save(io, *options) }\n"}], "added": [{"line_no": 3, "char_start": 67, "char_end": 135, "line": "        return ::File.open(output, 'w') { |io| save(io, *options) }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 82, "char_end": 89, "chars": "::File."}]}, "commit_link": "github.com/sparklemotion/mechanize/commit/aae0b13514a1a0caf93b1cf233733c50e679069a", "file_name": "cookie_jar.rb", "vul_type": "cwe-078", "commit_msg": "fix(security): prevent command injection in CookieJar\n\nRelated to https://github.com/sparklemotion/mechanize/security/advisories/GHSA-qrqm-fpv6-6r8g", "description": "Write a Ruby method named `save` that takes an output destination and an optional set of parameters to configure the save process."}
{"func_name": "get_realm_activity", "func_src_before": "@require_server_admin\ndef get_realm_activity(request: HttpRequest, realm_str: str) -> HttpResponse:\n    data: List[Tuple[str, str]] = []\n    all_user_records: Dict[str, Any] = {}\n\n    try:\n        admins = Realm.objects.get(string_id=realm_str).get_human_admin_users()\n    except Realm.DoesNotExist:\n        return HttpResponseNotFound(f\"Realm {realm_str} does not exist\")\n\n    admin_emails = {admin.delivery_email for admin in admins}\n\n    for is_bot, page_title in [(False, \"Humans\"), (True, \"Bots\")]:\n        all_records = list(get_user_activity_records_for_realm(realm_str, is_bot))\n\n        user_records, content = realm_user_summary_table(all_records, admin_emails)\n        all_user_records.update(user_records)\n\n        data += [(page_title, content)]\n\n    page_title = \"Clients\"\n    content = realm_client_table(all_user_records)\n    data += [(page_title, content)]\n\n    page_title = \"History\"\n    content = sent_messages_report(realm_str)\n    data += [(page_title, content)]\n\n    title = realm_str\n    return render(\n        request,\n        \"analytics/activity.html\",\n        context=dict(data=data, realm_link=None, title=title),\n    )", "func_src_after": "@require_server_admin\ndef get_realm_activity(request: HttpRequest, realm_str: str) -> HttpResponse:\n    data: List[Tuple[str, str]] = []\n    all_user_records: Dict[str, Any] = {}\n\n    try:\n        admins = Realm.objects.get(string_id=realm_str).get_human_admin_users()\n    except Realm.DoesNotExist:\n        return HttpResponseNotFound()\n\n    admin_emails = {admin.delivery_email for admin in admins}\n\n    for is_bot, page_title in [(False, \"Humans\"), (True, \"Bots\")]:\n        all_records = list(get_user_activity_records_for_realm(realm_str, is_bot))\n\n        user_records, content = realm_user_summary_table(all_records, admin_emails)\n        all_user_records.update(user_records)\n\n        data += [(page_title, content)]\n\n    page_title = \"Clients\"\n    content = realm_client_table(all_user_records)\n    data += [(page_title, content)]\n\n    page_title = \"History\"\n    content = sent_messages_report(realm_str)\n    data += [(page_title, content)]\n\n    title = realm_str\n    return render(\n        request,\n        \"analytics/activity.html\",\n        context=dict(data=data, realm_link=None, title=title),\n    )", "line_changes": {"deleted": [{"line_no": 9, "char_start": 300, "char_end": 373, "line": "        return HttpResponseNotFound(f\"Realm {realm_str} does not exist\")\n"}], "added": [{"line_no": 9, "char_start": 300, "char_end": 338, "line": "        return HttpResponseNotFound()\n"}]}, "char_changes": {"deleted": [{"char_start": 336, "char_end": 371, "chars": "f\"Realm {realm_str} does not exist\""}], "added": []}, "commit_link": "github.com/rht/zulip/commit/0da1bd43e95f78bee0bf3f78f1bcb594e7db66fd", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "analytics: Remove buggy HttpResponseNotFound text.\n\nHad this been in normal route, this would have been an XSS bug, as we\nwere passing what the developer clearly believed to be plain text into\nan HTML 404 page.\n\nThe affected routes have @require_server_admin, a permission that we\ndo not expect any self-hosted users to have ever enabled (as it is\nundocumented and doing so is only possible manually via a `manage.py\nshell`, and we believe to only be useful for running a SaaS service\nlike zulip.com).  So the security impact is limited to a handful of\nstaff of zulip.com and this isn't a candidate for a CVE.\n\nThanks to GitHub's CodeQL for finding this.", "description": "Write a Python function that retrieves and displays activity data for a specified realm, requiring server admin privileges."}
{"func_name": "cancelFollow", "func_src_before": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%d;\"%(userid,friendid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%s;\"\n        params=[userid,friendid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `cancelFollow` that removes a friend connection from a database using SQL."}
{"func_name": "h2h", "func_src_before": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '\"+str(player1)+\"' OR \"\\\n            +\"player2 = '\"+str(player1)+\"') AND (player1 = '\"+str(player2)+\"' OR \"\\\n            +\"player2 = '\"+str(player2)+\"') ORDER BY date DESC;\"\n    result = db.exec(sql)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '{player1}' OR \"\\\n            +\"player2 = '{player1}') AND (player1 = '{player2}' OR \"\\\n            +\"player2 = '{player2}') ORDER BY date DESC;\"\n    args = {'player1': player1, 'player2': player2}\n    result = db.exec(sql, args)\n    return json.dumps(result)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint function named 'h2h' that retrieves head-to-head match records between two players from a database and returns the result as JSON, with default player names as 'christmasmike'."}
{"func_name": "initialize", "func_src_before": "    def initialize(json)\n      @params = YAML.load(json || '')\n    end", "func_src_after": "    def initialize(json)\n      @params = YAML.safe_load(json || '')\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 25, "char_end": 63, "line": "      @params = YAML.load(json || '')\n"}], "added": [{"line_no": 2, "char_start": 25, "char_end": 68, "line": "      @params = YAML.safe_load(json || '')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 46, "char_end": 51, "chars": "safe_"}]}, "commit_link": "github.com/TravisCannon/panamax-api/commit/5f0bd8a0a60751bfd8ff51db83627b0477863b55", "file_name": "from_json.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load when parsing user templates", "parent_commit": "0f311d932ddb665f5ebdde98cca040ec858f1010", "description": "Create a Ruby method named `initialize` that loads a JSON string into a `@params` variable using YAML, with an optional use of a safer loading method."}
{"func_name": "autocomplete_phrases", "func_src_before": "def autocomplete_phrases(query):\n    query_string = ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, '({query}\\w*?\\M)', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{1}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{2}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{3}}|)\\M', 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\".format(query=query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases", "func_src_after": "def autocomplete_phrases(query):\n    query_statement = sql.text(ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\").bindparams(\n            p0='%{}%'.format(query),\n            p1=ur'({}\\w*?\\M)'.format(query),\n            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n        )\n\n    rows = db.engine.execute(query_statement).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases", "line_changes": {"deleted": [{"line_no": 2, "char_start": 33, "char_end": 58, "line": "    query_string = ur\"\"\"\n"}, {"line_no": 3, "char_start": 58, "char_end": 161, "line": "        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')\n"}, {"line_no": 5, "char_start": 208, "char_end": 295, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?\\M)', 'g') as match FROM s\n"}, {"line_no": 7, "char_start": 317, "char_end": 419, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{1}})\\M', 'g') as match FROM s\n"}, {"line_no": 9, "char_start": 441, "char_end": 543, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{2}})\\M', 'g') as match FROM s\n"}, {"line_no": 11, "char_start": 565, "char_end": 668, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{3}}|)\\M', 'g') as match FROM s\n"}, {"line_no": 15, "char_start": 760, "char_end": 801, "line": "        LIMIT 50;\"\"\".format(query=query)\n"}, {"line_no": 17, "char_start": 802, "char_end": 866, "line": "    rows = db.engine.execute(sql.text(query_string)).fetchall()\n"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 70, "line": "    query_statement = sql.text(ur\"\"\"\n"}, {"line_no": 3, "char_start": 70, "char_end": 165, "line": "        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)\n"}, {"line_no": 5, "char_start": 212, "char_end": 285, "line": "            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s\n"}, {"line_no": 7, "char_start": 307, "char_end": 380, "line": "            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s\n"}, {"line_no": 9, "char_start": 402, "char_end": 475, "line": "            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s\n"}, {"line_no": 11, "char_start": 497, "char_end": 570, "line": "            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s\n"}, {"line_no": 15, "char_start": 662, "char_end": 696, "line": "        LIMIT 50;\"\"\").bindparams(\n"}, {"line_no": 16, "char_start": 696, "char_end": 733, "line": "            p0='%{}%'.format(query),\n"}, {"line_no": 17, "char_start": 733, "char_end": 778, "line": "            p1=ur'({}\\w*?\\M)'.format(query),\n"}, {"line_no": 18, "char_start": 778, "char_end": 838, "line": "            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n"}, {"line_no": 19, "char_start": 838, "char_end": 898, "line": "            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n"}, {"line_no": 20, "char_start": 898, "char_end": 958, "line": "            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n"}, {"line_no": 21, "char_start": 958, "char_end": 968, "line": "        )\n"}, {"line_no": 23, "char_start": 969, "char_end": 1026, "line": "    rows = db.engine.execute(query_statement).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 45, "char_end": 52, "chars": "ring = "}, {"char_start": 148, "char_end": 159, "chars": "'%{query}%'"}, {"char_start": 255, "char_end": 272, "chars": "'({query}\\w*?\\M)'"}, {"char_start": 364, "char_end": 396, "chars": "'({query}\\w*?(?:\\s+\\w+){{1}})\\M'"}, {"char_start": 488, "char_end": 520, "chars": "'({query}\\w*?(?:\\s+\\w+){{2}})\\M'"}, {"char_start": 612, "char_end": 645, "chars": "'({query}\\w*?(?:\\s+\\w+){{3}}|)\\M'"}, {"char_start": 780, "char_end": 799, "chars": ".format(query=query"}, {"char_start": 831, "char_end": 840, "chars": "sql.text("}, {"char_start": 848, "char_end": 853, "chars": "ring)"}], "added": [{"char_start": 45, "char_end": 64, "chars": "atement = sql.text("}, {"char_start": 160, "char_end": 163, "chars": ":p0"}, {"char_start": 259, "char_end": 262, "chars": ":p1"}, {"char_start": 354, "char_end": 357, "chars": ":p2"}, {"char_start": 449, "char_end": 452, "chars": ":p3"}, {"char_start": 544, "char_end": 547, "chars": ":p4"}, {"char_start": 682, "char_end": 966, "chars": ").bindparams(\n            p0='%{}%'.format(query),\n            p1=ur'({}\\w*?\\M)'.format(query),\n            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n        "}, {"char_start": 1006, "char_end": 1013, "chars": "atement"}]}, "commit_link": "github.com/Impactstory/oadoi/commit/4cde28ea869c921be917cd8726edb958b37d683a", "file_name": "search.py", "vul_type": "cwe-089", "commit_msg": "fix sql injection vulnerability in search endpoints", "description": "Write a Python function to perform autocomplete for phrases using a SQL query with regular expressions."}
{"func_name": "updateLabel", "func_src_before": "\tfunction updateLabel () {\n\t\ttry {\n\t\t\tvar thisId = jQuery('#fb-field-id').val();\n\t\t\tvar thisLabel = jQuery('#fb-new-label').val();\n\t\t\t// Update preview\n\t\t\tif (thisLabel.length === 0) {\n\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').html(\"New field\");\n\t\t\t} else {\n\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').html(thisLabel);\n\t\t\t}\n\t\t\t// Update fbForm object\n\t\t\tfbForm.fields[thisId].label = thisLabel;\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"updateLabel(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tfunction updateLabel () {\n\t\ttry {\n\t\t\tvar thisId = jQuery('#fb-field-id').val();\n\t\t\tvar thisLabel = jQuery('#fb-new-label').val();\n\t\t\t// Update preview\n\t\t\tif (thisLabel.length === 0) {\n\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').text( GrunionFB_i18n.newLabel );\n\t\t\t} else {\n\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').text( thisLabel );\n\t\t\t}\n\t\t\t// Update fbForm object\n\t\t\tfbForm.fields[thisId].label = thisLabel;\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"updateLabel(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 7, "char_start": 185, "char_end": 264, "line": "\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').html(\"New field\");\n"}, {"line_no": 9, "char_start": 276, "char_end": 353, "line": "\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').html(thisLabel);\n"}], "added": [{"line_no": 7, "char_start": 185, "char_end": 278, "line": "\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').text( GrunionFB_i18n.newLabel );\n"}, {"line_no": 9, "char_start": 290, "char_end": 369, "line": "\t\t\t\tjQuery('#fb-new-field' + thisId + ' label .label-text').text( thisLabel );\n"}]}, "char_changes": {"deleted": [{"char_start": 245, "char_end": 261, "chars": "html(\"New field\""}, {"char_start": 336, "char_end": 341, "chars": "html("}], "added": [{"char_start": 245, "char_end": 275, "chars": "text( GrunionFB_i18n.newLabel "}, {"char_start": 350, "char_end": 356, "chars": "text( "}, {"char_start": 365, "char_end": 366, "chars": " "}]}, "commit_link": "github.com/iamtakashi/jetpack/commit/970117f93e7ed6eb459ee568259947d67369eec0", "file_name": "grunion.js", "vul_type": "cwe-079", "commit_msg": "Grunion: Fix 2 XSS vulnerabilities.\nPreview of field labels.\nPreview of radio option labels.\nAlso:\nPrevent future potential XSS in feedback message.\nFix i18n\nFix encoding of field labels bug (every preview would add another level of HTML encoding to the label)\nprops @mdawaffe", "description": "Write a JavaScript function using jQuery to update a form label with user input or a default value."}
{"func_name": "__ext4_journal_stop", "func_src_before": "int __ext4_journal_stop(const char *where, unsigned int line, handle_t *handle)\n{\n\tstruct super_block *sb;\n\tint err;\n\tint rc;\n\n\tif (!ext4_handle_valid(handle)) {\n\t\text4_put_nojournal(handle);\n\t\treturn 0;\n\t}\n\n\tif (!handle->h_transaction) {\n\t\terr = jbd2_journal_stop(handle);\n\t\treturn handle->h_err ? handle->h_err : err;\n\t}\n\n\tsb = handle->h_transaction->t_journal->j_private;\n\terr = handle->h_err;\n\trc = jbd2_journal_stop(handle);\n\n\tif (!err)\n\t\terr = rc;\n\tif (err)\n\t\t__ext4_std_error(sb, where, line, err);\n\treturn err;\n}", "func_src_after": "int __ext4_journal_stop(const char *where, unsigned int line, handle_t *handle)\n{\n\tstruct super_block *sb;\n\tint err;\n\tint rc;\n\n\tif (!ext4_handle_valid(handle)) {\n\t\text4_put_nojournal(handle);\n\t\treturn 0;\n\t}\n\n\terr = handle->h_err;\n\tif (!handle->h_transaction) {\n\t\trc = jbd2_journal_stop(handle);\n\t\treturn err ? err : rc;\n\t}\n\n\tsb = handle->h_transaction->t_journal->j_private;\n\trc = jbd2_journal_stop(handle);\n\n\tif (!err)\n\t\terr = rc;\n\tif (err)\n\t\t__ext4_std_error(sb, where, line, err);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/6934da9238da947628be83635e365df41064b09b", "file_name": "fs/ext4/ext4_jbd2.c", "vul_type": "cwe-416", "description": "Write a C function named `__ext4_journal_stop` that stops a journaling handle and handles errors appropriately."}
{"func_name": "check", "func_src_before": "def check(current_num):\n    try:\n        cursor.execute('SELECT * FROM comics WHERE num=\"%s\"' % current_num)\n    except sqlite3.OperationalError:\n        cursor.execute('CREATE TABLE comics (num text)')\n        return False\n    else:\n        return False if cursor.fetchone() is None else True", "func_src_after": "def check(current_num):\n    try:\n        cursor.execute('SELECT * FROM comics WHERE num=?', (current_num,))\n    except sqlite3.OperationalError:\n        cursor.execute('CREATE TABLE comics (num text)')\n        return False\n    else:\n        return False if cursor.fetchone() is None else True", "commit_link": "github.com/lord63/a_bunch_of_code/commit/c0d67a1312306fd1257c354bfb5d6cac7643aa29", "file_name": "comics/check_comics.py", "vul_type": "cwe-089", "description": "Write a Python function named `check` that queries a SQLite database for a specific record and creates a table if it doesn't exist."}
{"func_name": "get_list_context", "func_src_before": "def get_list_context(context=None):\n\tlist_context = frappe._dict(\n\t\ttemplate = \"templates/includes/blog/blog.html\",\n\t\tget_list = get_blog_list,\n\t\thide_filters = True,\n\t\tchildren = get_children(),\n\t\t# show_search = True,\n\t\ttitle = _('Blog')\n\t)\n\n\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n\tif category:\n\t\tcategory_title = get_blog_category(category)\n\t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n\t\tlist_context.title = category_title\n\n\telif frappe.local.form_dict.blogger:\n\t\tblogger = frappe.db.get_value(\"Blogger\", {\"name\": frappe.local.form_dict.blogger}, \"full_name\")\n\t\tlist_context.sub_title = _(\"Posts by {0}\").format(blogger)\n\t\tlist_context.title = blogger\n\n\telif frappe.local.form_dict.txt:\n\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n\n\tif list_context.sub_title:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n\t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}]\n\telse:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"}]\n\n\tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True))\n\treturn list_context", "func_src_after": "def get_list_context(context=None):\n\tlist_context = frappe._dict(\n\t\ttemplate = \"templates/includes/blog/blog.html\",\n\t\tget_list = get_blog_list,\n\t\thide_filters = True,\n\t\tchildren = get_children(),\n\t\t# show_search = True,\n\t\ttitle = _('Blog')\n\t)\n\n\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n\tif category:\n\t\tcategory_title = get_blog_category(category)\n\t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n\t\tlist_context.title = category_title\n\n\telif frappe.local.form_dict.blogger:\n\t\tblogger = frappe.db.get_value(\"Blogger\", {\"name\": frappe.local.form_dict.blogger}, \"full_name\")\n\t\tlist_context.sub_title = _(\"Posts by {0}\").format(blogger)\n\t\tlist_context.title = blogger\n\n\telif frappe.local.form_dict.txt:\n\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n\n\tif list_context.sub_title:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n\t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}]\n\telse:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"}]\n\n\tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True))\n\treturn list_context", "commit_link": "github.com/omirajkar/bench_frappe/commit/2fa19c25066ed17478d683666895e3266936aee6", "file_name": "frappe/website/doctype/blog_post/blog_post.py", "vul_type": "cwe-079", "description": "Write a Python function in Frappe to customize the context of a blog list page based on filters like category, blogger, or search text."}
{"func_name": "_read_clouds", "func_src_before": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "func_src_after": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.safe_load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 98, "char_end": 152, "line": "                self._clouds = yaml.load(clouds_file)\n"}], "added": [{"line_no": 4, "char_start": 98, "char_end": 157, "line": "                self._clouds = yaml.safe_load(clouds_file)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 134, "char_end": 139, "chars": "safe_"}]}, "commit_link": "github.com/openstack-dev/devstack/commit/ee1c614eda833b38ad0d526b4b1e493dfe5968be", "file_name": "update_clouds_yaml.py", "vul_type": "cwe-502", "commit_msg": "Fix use of yaml.load()\n\nThe use of this function has been deprecated for a long time[0]. With\nPyYAML==6.0 the call is now failing, so replace it with the safe\nversion.\n\n[0] https://msg.pyyaml.org/load\n\nSigned-off-by: Jens Harbott <frickler@offenerstapel.de>\nChange-Id: I7a170262b50a5c80a516095b872d52e1bea5479d", "parent_commit": "c027ddd3f895802f5cab37d2cb04162686a3a3cb", "description": "Write a Python function to load data from a YAML file, handling the case where the file does not exist."}
{"func_name": "GetOutboundPinholeTimeout", "func_src_before": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "func_src_after": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\tif (!int_port || !ext_port || !protocol)\n\t{\n\t\tClearNameValueList(&data);\n\t\tSoapError(h, 402, \"Invalid Args\");\n\t\treturn;\n\t}\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/13585f15c7f7dc28bbbba1661efb280d530d114c", "file_name": "miniupnpd/upnpsoap.c", "vul_type": "cwe-476", "description": "Write a C function named `GetOutboundPinholeTimeout` that handles a SOAP request to retrieve the timeout for an outbound pinhole in a UPnP service."}
{"func_name": "init", "func_src_before": "\tinit : function(settings) {\n\t\tvar theme, nl, baseHREF = \"\", i, cssPath, entities, h, p, src, elements = [], head;\n\n\t\t// IE 5.0x is no longer supported since 5.5, 6.0 and 7.0 now exists. We can't support old browsers forever, sorry.\n\t\tif (this.isMSIE5_0)\n\t\t\treturn;\n\n\t\tthis.settings = settings;\n\n\t\t// Check if valid browser has execcommand support\n\t\tif (typeof(document.execCommand) == 'undefined')\n\t\t\treturn;\n\n\t\t// Get script base path\n\t\tif (!tinyMCE.baseURL) {\n\t\t\t// Search through head\n\t\t\thead = document.getElementsByTagName('head')[0];\n\n\t\t\tif (head) {\n\t\t\t\tfor (i=0, nl = head.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\t\telements.push(nl[i]);\n\t\t\t}\n\n\t\t\t// Search through rest of document\n\t\t\tfor (i=0, nl = document.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\telements.push(nl[i]);\n\n\t\t\t// If base element found, add that infront of baseURL\n\t\t\tnl = document.getElementsByTagName('base');\n\t\t\tfor (i=0; i<nl.length; i++) {\n\t\t\t\tif (nl[i].href)\n\t\t\t\t\tbaseHREF = nl[i].href;\n\t\t\t}\n\n\t\t\tfor (i=0; i<elements.length; i++) {\n\t\t\t\tif (elements[i].src && (elements[i].src.indexOf(\"tiny_mce.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_dev.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_src.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_gzip\") != -1)) {\n\t\t\t\t\tsrc = elements[i].src;\n\n\t\t\t\t\ttinyMCE.srcMode = (src.indexOf('_src') != -1 || src.indexOf('_dev') != -1) ? '_src' : '';\n\t\t\t\t\ttinyMCE.gzipMode = src.indexOf('_gzip') != -1;\n\t\t\t\t\tsrc = src.substring(0, src.lastIndexOf('/'));\n\n\t\t\t\t\tif (settings.exec_mode == \"src\" || settings.exec_mode == \"normal\")\n\t\t\t\t\t\ttinyMCE.srcMode = settings.exec_mode == \"src\" ? '_src' : '';\n\n\t\t\t\t\t// Force it absolute if page has a base href\n\t\t\t\t\tif (baseHREF !== '' && src.indexOf('://') == -1)\n\t\t\t\t\t\ttinyMCE.baseURL = baseHREF + src;\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.baseURL = src;\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Get document base path\n\t\tthis.documentBasePath = escapePath(document.location.href);\n\t\tif (this.documentBasePath.indexOf('?') != -1)\n\t\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.indexOf('?'));\n\t\tthis.documentURL = this.documentBasePath;\n\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.lastIndexOf('/'));\n\n\t\t// If not HTTP absolute\n\t\tif (tinyMCE.baseURL.indexOf('://') == -1 && tinyMCE.baseURL.charAt(0) != '/') {\n\t\t\t// If site absolute\n\t\t\ttinyMCE.baseURL = this.documentBasePath + \"/\" + tinyMCE.baseURL;\n\t\t}\n\n\t\t// Set default values on settings\n\t\tthis._def(\"mode\", \"none\");\n\t\tthis._def(\"theme\", \"advanced\");\n\t\tthis._def(\"plugins\", \"\", true);\n\t\tthis._def(\"language\", \"en\");\n\t\tthis._def(\"docs_language\", this.settings.language);\n\t\tthis._def(\"elements\", \"\");\n\t\tthis._def(\"textarea_trigger\", \"mce_editable\");\n\t\tthis._def(\"editor_selector\", \"\");\n\t\tthis._def(\"editor_deselector\", \"mceNoEditor\");\n\t\tthis._def(\"valid_elements\", \"+a[id|style|rel|rev|charset|hreflang|dir|lang|tabindex|accesskey|type|name|href|target|title|class|onfocus|onblur|onclick|ondblclick|onmousedown|onmouseup|onmouseover|onmousemove|onmouseout|onkeypress|onkeydown|onkeyup],-strong/-b[class|style],-em/-i[class|style],-strike[class|style],-u[class|style],#p[id|style|dir|class|align],-ol[class|style],-ul[class|style],-li[class|style],br,img[id|dir|lang|longdesc|usemap|style|class|src|onmouseover|onmouseout|border|alt=|title|hspace|vspace|width|height|align],-sub[style|class],-sup[style|class],-blockquote[dir|style],-table[border=0|cellspacing|cellpadding|width|height|class|align|summary|style|dir|id|lang|bgcolor|background|bordercolor],-tr[id|lang|dir|class|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor],tbody[id|class],thead[id|class],tfoot[id|class],#td[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor|scope],-th[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|scope],caption[id|lang|dir|class|style],-div[id|dir|class|align|style],-span[style|class|align],-pre[class|align|style],address[class|align|style],-h1[id|style|dir|class|align],-h2[id|style|dir|class|align],-h3[id|style|dir|class|align],-h4[id|style|dir|class|align],-h5[id|style|dir|class|align],-h6[id|style|dir|class|align],hr[class|style],-font[face|size|style|id|class|dir|color],dd[id|class|title|style|dir|lang],dl[id|class|title|style|dir|lang],dt[id|class|title|style|dir|lang],cite[title|id|class|style|dir|lang],abbr[title|id|class|style|dir|lang],acronym[title|id|class|style|dir|lang],del[title|id|class|style|dir|lang|datetime|cite],ins[title|id|class|style|dir|lang|datetime|cite]\");\n\t\tthis._def(\"extended_valid_elements\", \"\");\n\t\tthis._def(\"invalid_elements\", \"\");\n\t\tthis._def(\"encoding\", \"\");\n\t\tthis._def(\"urlconverter_callback\", tinyMCE.getParam(\"urlconvertor_callback\", \"TinyMCE_Engine.prototype.convertURL\"));\n\t\tthis._def(\"save_callback\", \"\");\n\t\tthis._def(\"force_br_newlines\", false);\n\t\tthis._def(\"force_p_newlines\", true);\n\t\tthis._def(\"add_form_submit_trigger\", true);\n\t\tthis._def(\"relative_urls\", true);\n\t\tthis._def(\"remove_script_host\", true);\n\t\tthis._def(\"focus_alert\", true);\n\t\tthis._def(\"document_base_url\", this.documentURL);\n\t\tthis._def(\"visual\", true);\n\t\tthis._def(\"visual_table_class\", \"mceVisualAid\");\n\t\tthis._def(\"setupcontent_callback\", \"\");\n\t\tthis._def(\"fix_content_duplication\", true);\n\t\tthis._def(\"custom_undo_redo\", true);\n\t\tthis._def(\"custom_undo_redo_levels\", -1);\n\t\tthis._def(\"custom_undo_redo_keyboard_shortcuts\", true);\n\t\tthis._def(\"custom_undo_redo_restore_selection\", true);\n\t\tthis._def(\"custom_undo_redo_global\", false);\n\t\tthis._def(\"verify_html\", true);\n\t\tthis._def(\"apply_source_formatting\", false);\n\t\tthis._def(\"directionality\", \"ltr\");\n\t\tthis._def(\"cleanup_on_startup\", false);\n\t\tthis._def(\"inline_styles\", false);\n\t\tthis._def(\"convert_newlines_to_brs\", false);\n\t\tthis._def(\"auto_reset_designmode\", true);\n\t\tthis._def(\"entities\", \"39,#39,160,nbsp,161,iexcl,162,cent,163,pound,164,curren,165,yen,166,brvbar,167,sect,168,uml,169,copy,170,ordf,171,laquo,172,not,173,shy,174,reg,175,macr,176,deg,177,plusmn,178,sup2,179,sup3,180,acute,181,micro,182,para,183,middot,184,cedil,185,sup1,186,ordm,187,raquo,188,frac14,189,frac12,190,frac34,191,iquest,192,Agrave,193,Aacute,194,Acirc,195,Atilde,196,Auml,197,Aring,198,AElig,199,Ccedil,200,Egrave,201,Eacute,202,Ecirc,203,Euml,204,Igrave,205,Iacute,206,Icirc,207,Iuml,208,ETH,209,Ntilde,210,Ograve,211,Oacute,212,Ocirc,213,Otilde,214,Ouml,215,times,216,Oslash,217,Ugrave,218,Uacute,219,Ucirc,220,Uuml,221,Yacute,222,THORN,223,szlig,224,agrave,225,aacute,226,acirc,227,atilde,228,auml,229,aring,230,aelig,231,ccedil,232,egrave,233,eacute,234,ecirc,235,euml,236,igrave,237,iacute,238,icirc,239,iuml,240,eth,241,ntilde,242,ograve,243,oacute,244,ocirc,245,otilde,246,ouml,247,divide,248,oslash,249,ugrave,250,uacute,251,ucirc,252,uuml,253,yacute,254,thorn,255,yuml,402,fnof,913,Alpha,914,Beta,915,Gamma,916,Delta,917,Epsilon,918,Zeta,919,Eta,920,Theta,921,Iota,922,Kappa,923,Lambda,924,Mu,925,Nu,926,Xi,927,Omicron,928,Pi,929,Rho,931,Sigma,932,Tau,933,Upsilon,934,Phi,935,Chi,936,Psi,937,Omega,945,alpha,946,beta,947,gamma,948,delta,949,epsilon,950,zeta,951,eta,952,theta,953,iota,954,kappa,955,lambda,956,mu,957,nu,958,xi,959,omicron,960,pi,961,rho,962,sigmaf,963,sigma,964,tau,965,upsilon,966,phi,967,chi,968,psi,969,omega,977,thetasym,978,upsih,982,piv,8226,bull,8230,hellip,8242,prime,8243,Prime,8254,oline,8260,frasl,8472,weierp,8465,image,8476,real,8482,trade,8501,alefsym,8592,larr,8593,uarr,8594,rarr,8595,darr,8596,harr,8629,crarr,8656,lArr,8657,uArr,8658,rArr,8659,dArr,8660,hArr,8704,forall,8706,part,8707,exist,8709,empty,8711,nabla,8712,isin,8713,notin,8715,ni,8719,prod,8721,sum,8722,minus,8727,lowast,8730,radic,8733,prop,8734,infin,8736,ang,8743,and,8744,or,8745,cap,8746,cup,8747,int,8756,there4,8764,sim,8773,cong,8776,asymp,8800,ne,8801,equiv,8804,le,8805,ge,8834,sub,8835,sup,8836,nsub,8838,sube,8839,supe,8853,oplus,8855,otimes,8869,perp,8901,sdot,8968,lceil,8969,rceil,8970,lfloor,8971,rfloor,9001,lang,9002,rang,9674,loz,9824,spades,9827,clubs,9829,hearts,9830,diams,34,quot,38,amp,60,lt,62,gt,338,OElig,339,oelig,352,Scaron,353,scaron,376,Yuml,710,circ,732,tilde,8194,ensp,8195,emsp,8201,thinsp,8204,zwnj,8205,zwj,8206,lrm,8207,rlm,8211,ndash,8212,mdash,8216,lsquo,8217,rsquo,8218,sbquo,8220,ldquo,8221,rdquo,8222,bdquo,8224,dagger,8225,Dagger,8240,permil,8249,lsaquo,8250,rsaquo,8364,euro\", true);\n\t\tthis._def(\"entity_encoding\", \"named\");\n\t\tthis._def(\"cleanup_callback\", \"\");\n\t\tthis._def(\"add_unload_trigger\", true);\n\t\tthis._def(\"ask\", false);\n\t\tthis._def(\"nowrap\", false);\n\t\tthis._def(\"auto_resize\", false);\n\t\tthis._def(\"auto_focus\", false);\n\t\tthis._def(\"cleanup\", true);\n\t\tthis._def(\"remove_linebreaks\", true);\n\t\tthis._def(\"button_tile_map\", false);\n\t\tthis._def(\"submit_patch\", true);\n\t\tthis._def(\"browsers\", \"msie,safari,gecko,opera\", true);\n\t\tthis._def(\"dialog_type\", \"window\");\n\t\tthis._def(\"accessibility_warnings\", true);\n\t\tthis._def(\"accessibility_focus\", true);\n\t\tthis._def(\"merge_styles_invalid_parents\", \"\");\n\t\tthis._def(\"force_hex_style_colors\", true);\n\t\tthis._def(\"trim_span_elements\", true);\n\t\tthis._def(\"convert_fonts_to_spans\", false);\n\t\tthis._def(\"doctype\", '<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">');\n\t\tthis._def(\"font_size_classes\", '');\n\t\tthis._def(\"font_size_style_values\", 'xx-small,x-small,small,medium,large,x-large,xx-large', true);\n\t\tthis._def(\"event_elements\", 'a,img', true);\n\t\tthis._def(\"convert_urls\", true);\n\t\tthis._def(\"table_inline_editing\", false);\n\t\tthis._def(\"object_resizing\", true);\n\t\tthis._def(\"custom_shortcuts\", true);\n\t\tthis._def(\"convert_on_click\", false);\n\t\tthis._def(\"content_css\", '');\n\t\tthis._def(\"fix_list_elements\", true);\n\t\tthis._def(\"fix_table_elements\", false);\n\t\tthis._def(\"strict_loading_mode\", document.contentType == 'application/xhtml+xml');\n\t\tthis._def(\"hidden_tab_class\", '');\n\t\tthis._def(\"display_tab_class\", '');\n\t\tthis._def(\"gecko_spellcheck\", false);\n\t\tthis._def(\"hide_selects_on_submit\", true);\n\t\tthis._def(\"forced_root_block\", false);\n\t\tthis._def(\"remove_trailing_nbsp\", false);\n\t\tthis._def(\"save_on_tinymce_forms\", false);\n\n\t\t// Force strict loading mode to false on non Gecko browsers\n\t\tif (this.isMSIE && !this.isOpera)\n\t\t\tthis.settings.strict_loading_mode = false;\n\n\t\t// Browser check IE\n\t\tif (this.isMSIE && this.settings.browsers.indexOf('msie') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Gecko\n\t\tif (this.isGecko && this.settings.browsers.indexOf('gecko') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Safari\n\t\tif (this.isSafari && this.settings.browsers.indexOf('safari') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Opera\n\t\tif (this.isOpera && this.settings.browsers.indexOf('opera') == -1)\n\t\t\treturn;\n\n\t\t// If not super absolute make it so\n\t\tbaseHREF = tinyMCE.settings.document_base_url;\n\t\th = document.location.href;\n\t\tp = h.indexOf('://');\n\t\tif (p > 0 && document.location.protocol != \"file:\") {\n\t\t\tp = h.indexOf('/', p + 3);\n\t\t\th = h.substring(0, p);\n\n\t\t\tif (baseHREF.indexOf('://') == -1)\n\t\t\t\tbaseHREF = h + baseHREF;\n\n\t\t\ttinyMCE.settings.document_base_url = baseHREF;\n\t\t\ttinyMCE.settings.document_base_prefix = h;\n\t\t}\n\n\t\t// Trim away query part\n\t\tif (baseHREF.indexOf('?') != -1)\n\t\t\tbaseHREF = baseHREF.substring(0, baseHREF.indexOf('?'));\n\n\t\tthis.settings.base_href = baseHREF.substring(0, baseHREF.lastIndexOf('/')) + \"/\";\n\n\t\ttheme = this.settings.theme;\n\t\tthis.inlineStrict = 'A|BR|SPAN|BDO|MAP|OBJECT|IMG|TT|I|B|BIG|SMALL|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|#text|#comment';\n\t\tthis.inlineTransitional = 'A|BR|SPAN|BDO|OBJECT|APPLET|IMG|MAP|IFRAME|TT|I|B|U|S|STRIKE|BIG|SMALL|FONT|BASEFONT|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|INPUT|SELECT|TEXTAREA|LABEL|BUTTON|#text|#comment';\n\t\tthis.blockElms = 'H[1-6]|P|DIV|ADDRESS|PRE|FORM|TABLE|LI|OL|UL|TD|CAPTION|BLOCKQUOTE|CENTER|DL|DT|DD|DIR|FIELDSET|FORM|NOSCRIPT|NOFRAMES|MENU|ISINDEX|SAMP';\n\t\tthis.blockRegExp = new RegExp(\"^(\" + this.blockElms + \")$\", \"i\");\n\t\tthis.posKeyCodes = [13,45,36,35,33,34,37,38,39,40];\n\t\tthis.uniqueURL = 'javascript:void(091039730);'; // Make unique URL non real URL\n\t\tthis.uniqueTag = '<div id=\"mceTMPElement\" style=\"display: none\">TMP</div>';\n\t\tthis.callbacks = ['onInit', 'getInfo', 'getEditorTemplate', 'setupContent', 'onChange', 'onPageLoad', 'handleNodeChange', 'initInstance', 'execCommand', 'getControlHTML', 'handleEvent', 'cleanup', 'removeInstance'];\n\n\t\t// Theme url\n\t\tthis.settings.theme_href = tinyMCE.baseURL + \"/themes/\" + theme;\n\n\t\tif (!tinyMCE.isIE || tinyMCE.isOpera)\n\t\t\tthis.settings.force_br_newlines = false;\n\n\t\tif (tinyMCE.getParam(\"popups_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"popups_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.popups_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.popups_css = cssPath;\n\t\t} else\n\t\t\tthis.settings.popups_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_popup.css\";\n\n\t\tif (tinyMCE.getParam(\"editor_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"editor_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.editor_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.editor_css = cssPath;\n\t\t} else {\n\t\t\tif (this.settings.editor_css !== '')\n\t\t\t\tthis.settings.editor_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_ui.css\";\n\t\t}\n\n\t\t// Only do this once\n\t\tif (this.configs.length == 0) {\n\t\t\tif (typeof(TinyMCECompressed) == \"undefined\") {\n\t\t\t\ttinyMCE.addEvent(window, \"DOMContentLoaded\", TinyMCE_Engine.prototype.onLoad);\n\n\t\t\t\tif (tinyMCE.isRealIE) {\n\t\t\t\t\tif (document.body)\n\t\t\t\t\t\ttinyMCE.addEvent(document.body, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.addEvent(document, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t}\n\n\t\t\t\ttinyMCE.addEvent(window, \"load\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\ttinyMCE._addUnloadEvents();\n\t\t\t}\n\t\t}\n\n\t\tthis.loadScript(tinyMCE.baseURL + '/themes/' + this.settings.theme + '/editor_template' + tinyMCE.srcMode + '.js');\n\t\tthis.loadScript(tinyMCE.baseURL + '/langs/' + this.settings.language +  '.js');\n\t\tthis.loadCSS(this.settings.editor_css);\n\n\t\t// Add plugins\n\t\tp = tinyMCE.getParam('plugins', '', true, ',');\n\t\tif (p.length > 0) {\n\t\t\tfor (i=0; i<p.length; i++) {\n\t\t\t\tif (p[i].charAt(0) != '-')\n\t\t\t\t\tthis.loadScript(tinyMCE.baseURL + '/plugins/' + p[i] + '/editor_plugin' + tinyMCE.srcMode + '.js');\n\t\t\t}\n\t\t}\n\n\t\t// Setup entities\n\t\tif (tinyMCE.getParam('entity_encoding') == 'named') {\n\t\t\tsettings.cleanup_entities = [];\n\t\t\tentities = tinyMCE.getParam('entities', '', true, ',');\n\t\t\tfor (i=0; i<entities.length; i+=2)\n\t\t\t\tsettings.cleanup_entities['c' + entities[i]] = entities[i+1];\n\t\t}\n\n\t\t// Save away this config\n\t\tsettings.index = this.configs.length;\n\t\tthis.configs[this.configs.length] = settings;\n\n\t\t// Start loading first one in chain\n\t\tthis.loadNextScript();\n\n\t\t// Force flicker free CSS backgrounds in IE\n\t\tif (this.isIE && !this.isOpera) {\n\t\t\ttry {\n\t\t\t\tdocument.execCommand('BackgroundImageCache', false, true);\n\t\t\t} catch (e) {\n\t\t\t\t// Ignore\n\t\t\t}\n\t\t}\n\n\t\t// Setup XML encoding regexps\n\t\tthis.xmlEncodeRe = new RegExp('[<>&\"]', 'g');\n\t},", "func_src_after": "\tinit : function(settings) {\n\t\tvar theme, nl, baseHREF = \"\", i, cssPath, entities, h, p, src, elements = [], head;\n\n\t\t// IE 5.0x is no longer supported since 5.5, 6.0 and 7.0 now exists. We can't support old browsers forever, sorry.\n\t\tif (this.isMSIE5_0)\n\t\t\treturn;\n\n\t\tthis.settings = settings;\n\n\t\t// Check if valid browser has execcommand support\n\t\tif (typeof(document.execCommand) == 'undefined')\n\t\t\treturn;\n\n\t\t// Get script base path\n\t\tif (!tinyMCE.baseURL) {\n\t\t\t// Search through head\n\t\t\thead = document.getElementsByTagName('head')[0];\n\n\t\t\tif (head) {\n\t\t\t\tfor (i=0, nl = head.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\t\telements.push(nl[i]);\n\t\t\t}\n\n\t\t\t// Search through rest of document\n\t\t\tfor (i=0, nl = document.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\telements.push(nl[i]);\n\n\t\t\t// If base element found, add that infront of baseURL\n\t\t\tnl = document.getElementsByTagName('base');\n\t\t\tfor (i=0; i<nl.length; i++) {\n\t\t\t\tif (nl[i].href)\n\t\t\t\t\tbaseHREF = nl[i].href;\n\t\t\t}\n\n\t\t\tfor (i=0; i<elements.length; i++) {\n\t\t\t\tif (elements[i].src && (elements[i].src.indexOf(\"tiny_mce.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_dev.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_src.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_gzip\") != -1)) {\n\t\t\t\t\tsrc = elements[i].src;\n\n\t\t\t\t\ttinyMCE.srcMode = (src.indexOf('_src') != -1 || src.indexOf('_dev') != -1) ? '_src' : '';\n\t\t\t\t\ttinyMCE.gzipMode = src.indexOf('_gzip') != -1;\n\t\t\t\t\tsrc = src.substring(0, src.lastIndexOf('/'));\n\n\t\t\t\t\tif (settings.exec_mode == \"src\" || settings.exec_mode == \"normal\")\n\t\t\t\t\t\ttinyMCE.srcMode = settings.exec_mode == \"src\" ? '_src' : '';\n\n\t\t\t\t\t// Force it absolute if page has a base href\n\t\t\t\t\tif (baseHREF !== '' && src.indexOf('://') == -1)\n\t\t\t\t\t\ttinyMCE.baseURL = baseHREF + src;\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.baseURL = src;\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Get document base path\n\t\tthis.documentBasePath = escapePath(document.location.href);\n\t\tif (this.documentBasePath.indexOf('?') != -1)\n\t\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.indexOf('?'));\n\t\tthis.documentURL = this.documentBasePath;\n\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.lastIndexOf('/'));\n\n\t\t// If not HTTP absolute\n\t\tif (tinyMCE.baseURL.indexOf('://') == -1 && tinyMCE.baseURL.charAt(0) != '/') {\n\t\t\t// If site absolute\n\t\t\ttinyMCE.baseURL = this.documentBasePath + \"/\" + tinyMCE.baseURL;\n\t\t}\n\n\t\t// Set default values on settings\n\t\tthis._def(\"mode\", \"none\");\n\t\tthis._def(\"theme\", \"advanced\");\n\t\tthis._def(\"plugins\", \"\", true);\n\t\tthis._def(\"language\", \"en\");\n\t\tthis._def(\"docs_language\", this.settings.language);\n\t\tthis._def(\"elements\", \"\");\n\t\tthis._def(\"textarea_trigger\", \"mce_editable\");\n\t\tthis._def(\"editor_selector\", \"\");\n\t\tthis._def(\"editor_deselector\", \"mceNoEditor\");\n\t\tthis._def(\"valid_elements\", \"+a[id|style|rel|rev|charset|hreflang|dir|lang|tabindex|accesskey|type|name|href|target|title|class|onfocus|onblur|onclick|ondblclick|onmousedown|onmouseup|onmouseover|onmousemove|onmouseout|onkeypress|onkeydown|onkeyup],-strong/-b[class|style],-em/-i[class|style],-strike[class|style],-u[class|style],#p[id|style|dir|class|align],-ol[class|style],-ul[class|style],-li[class|style],br,img[id|dir|lang|longdesc|usemap|style|class|src|onmouseover|onmouseout|border|alt=|title|hspace|vspace|width|height|align],-sub[style|class],-sup[style|class],-blockquote[dir|style],-table[border=0|cellspacing|cellpadding|width|height|class|align|summary|style|dir|id|lang|bgcolor|background|bordercolor],-tr[id|lang|dir|class|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor],tbody[id|class],thead[id|class],tfoot[id|class],#td[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor|scope],-th[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|scope],caption[id|lang|dir|class|style],-div[id|dir|class|align|style],-span[style|class|align],-pre[class|align|style],address[class|align|style],-h1[id|style|dir|class|align],-h2[id|style|dir|class|align],-h3[id|style|dir|class|align],-h4[id|style|dir|class|align],-h5[id|style|dir|class|align],-h6[id|style|dir|class|align],hr[class|style],-font[face|size|style|id|class|dir|color],dd[id|class|title|style|dir|lang],dl[id|class|title|style|dir|lang],dt[id|class|title|style|dir|lang],cite[title|id|class|style|dir|lang],abbr[title|id|class|style|dir|lang],acronym[title|id|class|style|dir|lang],del[title|id|class|style|dir|lang|datetime|cite],ins[title|id|class|style|dir|lang|datetime|cite]\");\n\t\tthis._def(\"extended_valid_elements\", \"\");\n\t\tthis._def(\"invalid_elements\", \"\");\n\t\tthis._def(\"encoding\", \"\");\n\t\tthis._def(\"urlconverter_callback\", tinyMCE.getParam(\"urlconvertor_callback\", \"TinyMCE_Engine.prototype.convertURL\"));\n\t\tthis._def(\"save_callback\", \"\");\n\t\tthis._def(\"force_br_newlines\", false);\n\t\tthis._def(\"force_p_newlines\", true);\n\t\tthis._def(\"add_form_submit_trigger\", true);\n\t\tthis._def(\"relative_urls\", true);\n\t\tthis._def(\"remove_script_host\", true);\n\t\tthis._def(\"focus_alert\", true);\n\t\tthis._def(\"document_base_url\", this.documentURL);\n\t\tthis._def(\"visual\", true);\n\t\tthis._def(\"visual_table_class\", \"mceVisualAid\");\n\t\tthis._def(\"setupcontent_callback\", \"\");\n\t\tthis._def(\"fix_content_duplication\", true);\n\t\tthis._def(\"custom_undo_redo\", true);\n\t\tthis._def(\"custom_undo_redo_levels\", -1);\n\t\tthis._def(\"custom_undo_redo_keyboard_shortcuts\", true);\n\t\tthis._def(\"custom_undo_redo_restore_selection\", true);\n\t\tthis._def(\"custom_undo_redo_global\", false);\n\t\tthis._def(\"verify_html\", true);\n\t\tthis._def(\"apply_source_formatting\", false);\n\t\tthis._def(\"directionality\", \"ltr\");\n\t\tthis._def(\"cleanup_on_startup\", false);\n\t\tthis._def(\"inline_styles\", false);\n\t\tthis._def(\"convert_newlines_to_brs\", false);\n\t\tthis._def(\"auto_reset_designmode\", true);\n\t\tthis._def(\"entities\", \"39,#39,160,nbsp,161,iexcl,162,cent,163,pound,164,curren,165,yen,166,brvbar,167,sect,168,uml,169,copy,170,ordf,171,laquo,172,not,173,shy,174,reg,175,macr,176,deg,177,plusmn,178,sup2,179,sup3,180,acute,181,micro,182,para,183,middot,184,cedil,185,sup1,186,ordm,187,raquo,188,frac14,189,frac12,190,frac34,191,iquest,192,Agrave,193,Aacute,194,Acirc,195,Atilde,196,Auml,197,Aring,198,AElig,199,Ccedil,200,Egrave,201,Eacute,202,Ecirc,203,Euml,204,Igrave,205,Iacute,206,Icirc,207,Iuml,208,ETH,209,Ntilde,210,Ograve,211,Oacute,212,Ocirc,213,Otilde,214,Ouml,215,times,216,Oslash,217,Ugrave,218,Uacute,219,Ucirc,220,Uuml,221,Yacute,222,THORN,223,szlig,224,agrave,225,aacute,226,acirc,227,atilde,228,auml,229,aring,230,aelig,231,ccedil,232,egrave,233,eacute,234,ecirc,235,euml,236,igrave,237,iacute,238,icirc,239,iuml,240,eth,241,ntilde,242,ograve,243,oacute,244,ocirc,245,otilde,246,ouml,247,divide,248,oslash,249,ugrave,250,uacute,251,ucirc,252,uuml,253,yacute,254,thorn,255,yuml,402,fnof,913,Alpha,914,Beta,915,Gamma,916,Delta,917,Epsilon,918,Zeta,919,Eta,920,Theta,921,Iota,922,Kappa,923,Lambda,924,Mu,925,Nu,926,Xi,927,Omicron,928,Pi,929,Rho,931,Sigma,932,Tau,933,Upsilon,934,Phi,935,Chi,936,Psi,937,Omega,945,alpha,946,beta,947,gamma,948,delta,949,epsilon,950,zeta,951,eta,952,theta,953,iota,954,kappa,955,lambda,956,mu,957,nu,958,xi,959,omicron,960,pi,961,rho,962,sigmaf,963,sigma,964,tau,965,upsilon,966,phi,967,chi,968,psi,969,omega,977,thetasym,978,upsih,982,piv,8226,bull,8230,hellip,8242,prime,8243,Prime,8254,oline,8260,frasl,8472,weierp,8465,image,8476,real,8482,trade,8501,alefsym,8592,larr,8593,uarr,8594,rarr,8595,darr,8596,harr,8629,crarr,8656,lArr,8657,uArr,8658,rArr,8659,dArr,8660,hArr,8704,forall,8706,part,8707,exist,8709,empty,8711,nabla,8712,isin,8713,notin,8715,ni,8719,prod,8721,sum,8722,minus,8727,lowast,8730,radic,8733,prop,8734,infin,8736,ang,8743,and,8744,or,8745,cap,8746,cup,8747,int,8756,there4,8764,sim,8773,cong,8776,asymp,8800,ne,8801,equiv,8804,le,8805,ge,8834,sub,8835,sup,8836,nsub,8838,sube,8839,supe,8853,oplus,8855,otimes,8869,perp,8901,sdot,8968,lceil,8969,rceil,8970,lfloor,8971,rfloor,9001,lang,9002,rang,9674,loz,9824,spades,9827,clubs,9829,hearts,9830,diams,34,quot,38,amp,60,lt,62,gt,338,OElig,339,oelig,352,Scaron,353,scaron,376,Yuml,710,circ,732,tilde,8194,ensp,8195,emsp,8201,thinsp,8204,zwnj,8205,zwj,8206,lrm,8207,rlm,8211,ndash,8212,mdash,8216,lsquo,8217,rsquo,8218,sbquo,8220,ldquo,8221,rdquo,8222,bdquo,8224,dagger,8225,Dagger,8240,permil,8249,lsaquo,8250,rsaquo,8364,euro\", true);\n\t\tthis._def(\"entity_encoding\", \"named\");\n\t\tthis._def(\"cleanup_callback\", \"\");\n\t\tthis._def(\"add_unload_trigger\", true);\n\t\tthis._def(\"ask\", false);\n\t\tthis._def(\"nowrap\", false);\n\t\tthis._def(\"auto_resize\", false);\n\t\tthis._def(\"auto_focus\", false);\n\t\tthis._def(\"cleanup\", true);\n\t\tthis._def(\"remove_linebreaks\", true);\n\t\tthis._def(\"button_tile_map\", false);\n\t\tthis._def(\"submit_patch\", true);\n\t\tthis._def(\"browsers\", \"msie,safari,gecko,opera\", true);\n\t\tthis._def(\"dialog_type\", \"window\");\n\t\tthis._def(\"accessibility_warnings\", true);\n\t\tthis._def(\"accessibility_focus\", true);\n\t\tthis._def(\"merge_styles_invalid_parents\", \"\");\n\t\tthis._def(\"force_hex_style_colors\", true);\n\t\tthis._def(\"trim_span_elements\", true);\n\t\tthis._def(\"convert_fonts_to_spans\", false);\n\t\tthis._def(\"doctype\", '<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">');\n\t\tthis._def(\"font_size_classes\", '');\n\t\tthis._def(\"font_size_style_values\", 'xx-small,x-small,small,medium,large,x-large,xx-large', true);\n\t\tthis._def(\"event_elements\", 'a,img', true);\n\t\tthis._def(\"convert_urls\", true);\n\t\tthis._def(\"table_inline_editing\", false);\n\t\tthis._def(\"object_resizing\", true);\n\t\tthis._def(\"custom_shortcuts\", true);\n\t\tthis._def(\"convert_on_click\", false);\n\t\tthis._def(\"content_css\", '');\n\t\tthis._def(\"fix_list_elements\", true);\n\t\tthis._def(\"fix_table_elements\", false);\n\t\tthis._def(\"strict_loading_mode\", document.contentType == 'application/xhtml+xml');\n\t\tthis._def(\"hidden_tab_class\", '');\n\t\tthis._def(\"display_tab_class\", '');\n\t\tthis._def(\"gecko_spellcheck\", false);\n\t\tthis._def(\"hide_selects_on_submit\", true);\n\t\tthis._def(\"forced_root_block\", false);\n\t\tthis._def(\"remove_trailing_nbsp\", false);\n\t\tthis._def(\"save_on_tinymce_forms\", false);\n\n\t\t// Force strict loading mode to false on non Gecko browsers\n\t\tif (this.isMSIE && !this.isOpera)\n\t\t\tthis.settings.strict_loading_mode = false;\n\n\t\t// Browser check IE\n\t\tif (this.isMSIE && this.settings.browsers.indexOf('msie') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Gecko\n\t\tif (this.isGecko && this.settings.browsers.indexOf('gecko') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Safari\n\t\tif (this.isSafari && this.settings.browsers.indexOf('safari') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Opera\n\t\tif (this.isOpera && this.settings.browsers.indexOf('opera') == -1)\n\t\t\treturn;\n\n\t\t// If not super absolute make it so\n\t\tbaseHREF = tinyMCE.settings.document_base_url;\n\t\th = escapePath(document.location.href);\n\t\tp = h.indexOf('://');\n\t\tif (p > 0 && document.location.protocol != \"file:\") {\n\t\t\tp = h.indexOf('/', p + 3);\n\t\t\th = h.substring(0, p);\n\n\t\t\tif (baseHREF.indexOf('://') == -1)\n\t\t\t\tbaseHREF = h + baseHREF;\n\n\t\t\ttinyMCE.settings.document_base_url = baseHREF;\n\t\t\ttinyMCE.settings.document_base_prefix = h;\n\t\t}\n\n\t\t// Trim away query part\n\t\tif (baseHREF.indexOf('?') != -1)\n\t\t\tbaseHREF = baseHREF.substring(0, baseHREF.indexOf('?'));\n\n\t\tthis.settings.base_href = baseHREF.substring(0, baseHREF.lastIndexOf('/')) + \"/\";\n\n\t\ttheme = this.settings.theme;\n\t\tthis.inlineStrict = 'A|BR|SPAN|BDO|MAP|OBJECT|IMG|TT|I|B|BIG|SMALL|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|#text|#comment';\n\t\tthis.inlineTransitional = 'A|BR|SPAN|BDO|OBJECT|APPLET|IMG|MAP|IFRAME|TT|I|B|U|S|STRIKE|BIG|SMALL|FONT|BASEFONT|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|INPUT|SELECT|TEXTAREA|LABEL|BUTTON|#text|#comment';\n\t\tthis.blockElms = 'H[1-6]|P|DIV|ADDRESS|PRE|FORM|TABLE|LI|OL|UL|TD|CAPTION|BLOCKQUOTE|CENTER|DL|DT|DD|DIR|FIELDSET|FORM|NOSCRIPT|NOFRAMES|MENU|ISINDEX|SAMP';\n\t\tthis.blockRegExp = new RegExp(\"^(\" + this.blockElms + \")$\", \"i\");\n\t\tthis.posKeyCodes = [13,45,36,35,33,34,37,38,39,40];\n\t\tthis.uniqueURL = 'javascript:void(091039730);'; // Make unique URL non real URL\n\t\tthis.uniqueTag = '<div id=\"mceTMPElement\" style=\"display: none\">TMP</div>';\n\t\tthis.callbacks = ['onInit', 'getInfo', 'getEditorTemplate', 'setupContent', 'onChange', 'onPageLoad', 'handleNodeChange', 'initInstance', 'execCommand', 'getControlHTML', 'handleEvent', 'cleanup', 'removeInstance'];\n\n\t\t// Theme url\n\t\tthis.settings.theme_href = tinyMCE.baseURL + \"/themes/\" + theme;\n\n\t\tif (!tinyMCE.isIE || tinyMCE.isOpera)\n\t\t\tthis.settings.force_br_newlines = false;\n\n\t\tif (tinyMCE.getParam(\"popups_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"popups_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.popups_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.popups_css = cssPath;\n\t\t} else\n\t\t\tthis.settings.popups_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_popup.css\";\n\n\t\tif (tinyMCE.getParam(\"editor_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"editor_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.editor_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.editor_css = cssPath;\n\t\t} else {\n\t\t\tif (this.settings.editor_css !== '')\n\t\t\t\tthis.settings.editor_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_ui.css\";\n\t\t}\n\n\t\t// Only do this once\n\t\tif (this.configs.length == 0) {\n\t\t\tif (typeof(TinyMCECompressed) == \"undefined\") {\n\t\t\t\ttinyMCE.addEvent(window, \"DOMContentLoaded\", TinyMCE_Engine.prototype.onLoad);\n\n\t\t\t\tif (tinyMCE.isRealIE) {\n\t\t\t\t\tif (document.body)\n\t\t\t\t\t\ttinyMCE.addEvent(document.body, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.addEvent(document, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t}\n\n\t\t\t\ttinyMCE.addEvent(window, \"load\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\ttinyMCE._addUnloadEvents();\n\t\t\t}\n\t\t}\n\n\t\tthis.loadScript(tinyMCE.baseURL + '/themes/' + this.settings.theme + '/editor_template' + tinyMCE.srcMode + '.js');\n\t\tthis.loadScript(tinyMCE.baseURL + '/langs/' + this.settings.language +  '.js');\n\t\tthis.loadCSS(this.settings.editor_css);\n\n\t\t// Add plugins\n\t\tp = tinyMCE.getParam('plugins', '', true, ',');\n\t\tif (p.length > 0) {\n\t\t\tfor (i=0; i<p.length; i++) {\n\t\t\t\tif (p[i].charAt(0) != '-')\n\t\t\t\t\tthis.loadScript(tinyMCE.baseURL + '/plugins/' + p[i] + '/editor_plugin' + tinyMCE.srcMode + '.js');\n\t\t\t}\n\t\t}\n\n\t\t// Setup entities\n\t\tif (tinyMCE.getParam('entity_encoding') == 'named') {\n\t\t\tsettings.cleanup_entities = [];\n\t\t\tentities = tinyMCE.getParam('entities', '', true, ',');\n\t\t\tfor (i=0; i<entities.length; i+=2)\n\t\t\t\tsettings.cleanup_entities['c' + entities[i]] = entities[i+1];\n\t\t}\n\n\t\t// Save away this config\n\t\tsettings.index = this.configs.length;\n\t\tthis.configs[this.configs.length] = settings;\n\n\t\t// Start loading first one in chain\n\t\tthis.loadNextScript();\n\n\t\t// Force flicker free CSS backgrounds in IE\n\t\tif (this.isIE && !this.isOpera) {\n\t\t\ttry {\n\t\t\t\tdocument.execCommand('BackgroundImageCache', false, true);\n\t\t\t} catch (e) {\n\t\t\t\t// Ignore\n\t\t\t}\n\t\t}\n\n\t\t// Setup XML encoding regexps\n\t\tthis.xmlEncodeRe = new RegExp('[<>&\"]', 'g');\n\t},", "line_changes": {"deleted": [{"line_no": 172, "char_start": 10731, "char_end": 10761, "line": "\t\th = document.location.href;\n"}], "added": [{"line_no": 172, "char_start": 10731, "char_end": 10773, "line": "\t\th = escapePath(document.location.href);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 10737, "char_end": 10748, "chars": "escapePath("}, {"char_start": 10770, "char_end": 10771, "chars": ")"}]}, "commit_link": "github.com/jaffa-projects/jaffa-framework/commit/f9241bf1b4e4f06fc9778b2314664b58f4fbe309", "file_name": "tiny_mce_src.js", "vul_type": "cwe-079", "commit_msg": "Coverity CWE79 (DOM XSS) new TinyMCE vulnerability fix", "description": "Write a JavaScript function to initialize a WYSIWYG editor with given settings."}
{"func_name": "PlayerGeneric::~PlayerGeneric", "func_src_before": "PlayerGeneric::~PlayerGeneric()\n{\n\tif (mixer)\n\t\tdelete mixer;\n\n\tif (player)\n\t{\n\t\tif (mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "func_src_after": "PlayerGeneric::~PlayerGeneric()\n{\n\n\tif (player)\n\t{\n\t\tif (mixer && mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\t\n\tif (mixer)\n\t\tdelete mixer;\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "commit_link": "github.com/milkytracker/MilkyTracker/commit/7afd55c42ad80d01a339197a2d8b5461d214edaf", "file_name": "src/milkyplay/PlayerGeneric.cpp", "vul_type": "cwe-416", "description": "Write a C++ destructor for a class named `PlayerGeneric` that cleans up memory by deleting member pointers, ensuring that a `mixer` object is properly deactivated and devices are removed before deletion."}
{"func_name": "Curl_close", "func_src_before": "CURLcode Curl_close(struct Curl_easy *data)\n{\n  struct Curl_multi *m;\n\n  if(!data)\n    return CURLE_OK;\n\n  Curl_expire_clear(data); /* shut off timers */\n\n  m = data->multi;\n  if(m)\n    /* This handle is still part of a multi handle, take care of this first\n       and detach this handle from there. */\n    curl_multi_remove_handle(data->multi, data);\n\n  if(data->multi_easy)\n    /* when curl_easy_perform() is used, it creates its own multi handle to\n       use and this is the one */\n    curl_multi_cleanup(data->multi_easy);\n\n  /* Destroy the timeout list that is held in the easy handle. It is\n     /normally/ done by curl_multi_remove_handle() but this is \"just in\n     case\" */\n  Curl_llist_destroy(&data->state.timeoutlist, NULL);\n\n  data->magic = 0; /* force a clear AFTER the possibly enforced removal from\n                      the multi handle, since that function uses the magic\n                      field! */\n\n  if(data->state.rangestringalloc)\n    free(data->state.range);\n\n  /* freed here just in case DONE wasn't called */\n  Curl_free_request_state(data);\n\n  /* Close down all open SSL info and sessions */\n  Curl_ssl_close_all(data);\n  Curl_safefree(data->state.first_host);\n  Curl_safefree(data->state.scratch);\n  Curl_ssl_free_certinfo(data);\n\n  /* Cleanup possible redirect junk */\n  free(data->req.newurl);\n  data->req.newurl = NULL;\n\n  if(data->change.referer_alloc) {\n    Curl_safefree(data->change.referer);\n    data->change.referer_alloc = FALSE;\n  }\n  data->change.referer = NULL;\n\n  Curl_up_free(data);\n  Curl_safefree(data->state.buffer);\n  Curl_safefree(data->state.headerbuff);\n  Curl_safefree(data->state.ulbuf);\n  Curl_flush_cookies(data, 1);\n  Curl_digest_cleanup(data);\n  Curl_safefree(data->info.contenttype);\n  Curl_safefree(data->info.wouldredirect);\n\n  /* this destroys the channel and we cannot use it anymore after this */\n  Curl_resolver_cleanup(data->state.resolver);\n\n  Curl_http2_cleanup_dependencies(data);\n  Curl_convert_close(data);\n\n  /* No longer a dirty share, if it exists */\n  if(data->share) {\n    Curl_share_lock(data, CURL_LOCK_DATA_SHARE, CURL_LOCK_ACCESS_SINGLE);\n    data->share->dirty--;\n    Curl_share_unlock(data, CURL_LOCK_DATA_SHARE);\n  }\n\n  /* destruct wildcard structures if it is needed */\n  Curl_wildcard_dtor(&data->wildcard);\n  Curl_freeset(data);\n  free(data);\n  return CURLE_OK;\n}", "func_src_after": "CURLcode Curl_close(struct Curl_easy *data)\n{\n  struct Curl_multi *m;\n\n  if(!data)\n    return CURLE_OK;\n\n  Curl_expire_clear(data); /* shut off timers */\n\n  m = data->multi;\n  if(m)\n    /* This handle is still part of a multi handle, take care of this first\n       and detach this handle from there. */\n    curl_multi_remove_handle(data->multi, data);\n\n  if(data->multi_easy) {\n    /* when curl_easy_perform() is used, it creates its own multi handle to\n       use and this is the one */\n    curl_multi_cleanup(data->multi_easy);\n    data->multi_easy = NULL;\n  }\n\n  /* Destroy the timeout list that is held in the easy handle. It is\n     /normally/ done by curl_multi_remove_handle() but this is \"just in\n     case\" */\n  Curl_llist_destroy(&data->state.timeoutlist, NULL);\n\n  data->magic = 0; /* force a clear AFTER the possibly enforced removal from\n                      the multi handle, since that function uses the magic\n                      field! */\n\n  if(data->state.rangestringalloc)\n    free(data->state.range);\n\n  /* freed here just in case DONE wasn't called */\n  Curl_free_request_state(data);\n\n  /* Close down all open SSL info and sessions */\n  Curl_ssl_close_all(data);\n  Curl_safefree(data->state.first_host);\n  Curl_safefree(data->state.scratch);\n  Curl_ssl_free_certinfo(data);\n\n  /* Cleanup possible redirect junk */\n  free(data->req.newurl);\n  data->req.newurl = NULL;\n\n  if(data->change.referer_alloc) {\n    Curl_safefree(data->change.referer);\n    data->change.referer_alloc = FALSE;\n  }\n  data->change.referer = NULL;\n\n  Curl_up_free(data);\n  Curl_safefree(data->state.buffer);\n  Curl_safefree(data->state.headerbuff);\n  Curl_safefree(data->state.ulbuf);\n  Curl_flush_cookies(data, 1);\n  Curl_digest_cleanup(data);\n  Curl_safefree(data->info.contenttype);\n  Curl_safefree(data->info.wouldredirect);\n\n  /* this destroys the channel and we cannot use it anymore after this */\n  Curl_resolver_cleanup(data->state.resolver);\n\n  Curl_http2_cleanup_dependencies(data);\n  Curl_convert_close(data);\n\n  /* No longer a dirty share, if it exists */\n  if(data->share) {\n    Curl_share_lock(data, CURL_LOCK_DATA_SHARE, CURL_LOCK_ACCESS_SINGLE);\n    data->share->dirty--;\n    Curl_share_unlock(data, CURL_LOCK_DATA_SHARE);\n  }\n\n  /* destruct wildcard structures if it is needed */\n  Curl_wildcard_dtor(&data->wildcard);\n  Curl_freeset(data);\n  free(data);\n  return CURLE_OK;\n}", "commit_link": "github.com/curl/curl/commit/81d135d67155c5295b1033679c606165d4e28f3f", "file_name": "lib/url.c", "vul_type": "cwe-416", "description": "Write a function in C to clean up and close a libcurl easy handle."}
{"func_name": "load", "func_src_before": "    def load(input, *options)\n      input.respond_to?(:write) or\n        return open(input, 'r') { |io| load(io, *options) }\n\n      opthash = {\n        :format => :yaml,\n        :session => false,\n      }\n      case options.size\n      when 0\n      when 1\n        case options = options.first\n        when Symbol\n          opthash[:format] = options\n        else\n          if hash = Hash.try_convert(options)\n            opthash.update(hash)\n          end\n        end", "func_src_after": "    def load(input, *options)\n      input.respond_to?(:write) or\n        return ::File.open(input, 'r') { |io| load(io, *options) }\n\n      opthash = {\n        :format => :yaml,\n        :session => false,\n      }\n      case options.size\n      when 0\n      when 1\n        case options = options.first\n        when Symbol\n          opthash[:format] = options\n        else\n          if hash = Hash.try_convert(options)\n            opthash.update(hash)\n          end\n        end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 65, "char_end": 125, "line": "        return open(input, 'r') { |io| load(io, *options) }\n"}], "added": [{"line_no": 3, "char_start": 65, "char_end": 132, "line": "        return ::File.open(input, 'r') { |io| load(io, *options) }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 80, "char_end": 87, "chars": "::File."}]}, "commit_link": "github.com/sparklemotion/mechanize/commit/aae0b13514a1a0caf93b1cf233733c50e679069a", "file_name": "cookie_jar.rb", "vul_type": "cwe-078", "commit_msg": "fix(security): prevent command injection in CookieJar\n\nRelated to https://github.com/sparklemotion/mechanize/security/advisories/GHSA-qrqm-fpv6-6r8g", "description": "Write a Ruby method named `load` that takes an input and optional parameters to process file loading with format options."}
{"func_name": "wins", "func_src_before": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '\"+str(player)+\"' ORDER BY date DESC;\"\n    result = db.exec(sql)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '{player}' ORDER BY date DESC;\"\n    args = {'player': player}\n    result = db.exec(sql, args)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that returns a JSON list of match wins for a specified player from a database, with \"christmasmike\" as the default player name."}
{"func_name": "shame_add", "func_src_before": "def shame_add(name):\n    shame = shame_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if shame is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES('{}',0,1)\n                '''.format(name))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 shame for {}'.format(name))\n            db.close()\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n\n    else:\n        shame = shame + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET shame = {0} WHERE name = '{1}'\n                '''.format(shame, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} shame for {}'.format(\n                shame, name))\n            db.close()\n            return shame\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "func_src_after": "def shame_add(name):\n    shame = shame_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if shame is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES(%(name)s,0,1)\n                ''', (name, ))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 shame for {}'.format(name))\n            db.close()\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n\n    else:\n        shame = shame + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET shame = %(karma)s WHERE name = %(name)s\n                ''' (\n                shame,\n                name,\n            ))\n            db.commit()\n            logger.debug('Inserted into karmadb {} shame for {}'.format(\n                shame, name))\n            db.close()\n            return shame\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to increment a user's shame count in a database, inserting a new record if the user doesn't exist."}
{"func_name": "Utility::UnZip", "func_src_before": "bool Utility::UnZip(const QString &zippath, const QString &destpath)\n{\n    int res = 0;\n    QDir dir(destpath);\n    if (!cp437) {\n        cp437 = new QCodePage437Codec();\n    }\n#ifdef Q_OS_WIN32\n    zlib_filefunc64_def ffunc;\n    fill_win32_filefunc64W(&ffunc);\n    unzFile zfile = unzOpen2_64(Utility::QStringToStdWString(QDir::toNativeSeparators(zippath)).c_str(), &ffunc);\n#else\n    unzFile zfile = unzOpen64(QDir::toNativeSeparators(zippath).toUtf8().constData());\n#endif\n\n    if ((zfile == NULL) || (!IsFileReadable(zippath)) || (!dir.exists())) {\n        return false;\n    }\n\n    res = unzGoToFirstFile(zfile);\n\n    if (res == UNZ_OK) {\n        do {\n            // Get the name of the file in the archive.\n            char file_name[MAX_PATH] = {0};\n            unz_file_info64 file_info;\n            unzGetCurrentFileInfo64(zfile, &file_info, file_name, MAX_PATH, NULL, 0, NULL, 0);\n            QString qfile_name;\n            QString cp437_file_name;\n            qfile_name = QString::fromUtf8(file_name);\n            if (!(file_info.flag & (1<<11))) {\n                // General purpose bit 11 says the filename is utf-8 encoded. If not set then\n                // IBM 437 encoding might be used.\n                cp437_file_name = cp437->toUnicode(file_name);\n            }\n\n            // If there is no file name then we can't do anything with it.\n            if (!qfile_name.isEmpty()) {\n                // We use the dir object to create the path in the temporary directory.\n                // Unfortunately, we need a dir ojbect to do this as it's not a static function.\n                // Full file path in the temporary directory.\n                QString file_path = destpath + \"/\" + qfile_name;\n                QFileInfo qfile_info(file_path);\n\n                // Is this entry a directory?\n                if (file_info.uncompressed_size == 0 && qfile_name.endsWith('/')) {\n                    dir.mkpath(qfile_name);\n                    continue;\n                } else {\n                    dir.mkpath(qfile_info.path());\n                }\n\n                // Open the file entry in the archive for reading.\n                if (unzOpenCurrentFile(zfile) != UNZ_OK) {\n                    unzClose(zfile);\n                    return false;\n                }\n\n                // Open the file on disk to write the entry in the archive to.\n                QFile entry(file_path);\n\n                if (!entry.open(QIODevice::WriteOnly | QIODevice::Truncate)) {\n                    unzCloseCurrentFile(zfile);\n                    unzClose(zfile);\n                    return false;\n                }\n\n                // Buffered reading and writing.\n                char buff[BUFF_SIZE] = {0};\n                int read = 0;\n\n                while ((read = unzReadCurrentFile(zfile, buff, BUFF_SIZE)) > 0) {\n                    entry.write(buff, read);\n                }\n\n                entry.close();\n\n                // Read errors are marked by a negative read amount.\n                if (read < 0) {\n                    unzCloseCurrentFile(zfile);\n                    unzClose(zfile);\n                    return false;\n                }\n\n                // The file was read but the CRC did not match.\n                // We don't check the read file size vs the uncompressed file size\n                // because if they're different there should be a CRC error.\n                if (unzCloseCurrentFile(zfile) == UNZ_CRCERROR) {\n                    unzClose(zfile);\n                    return false;\n                }\n\n                if (!cp437_file_name.isEmpty() && cp437_file_name != qfile_name) {\n                    QString cp437_file_path = destpath + \"/\" + cp437_file_name;\n                    QFile::copy(file_path, cp437_file_path);\n                }\n            }\n        } while ((res = unzGoToNextFile(zfile)) == UNZ_OK);\n    }\n\n    if (res != UNZ_END_OF_LIST_OF_FILE) {\n        unzClose(zfile);\n        return false;\n    }\n\n    unzClose(zfile);\n    return true;\n}", "func_src_after": "bool Utility::UnZip(const QString &zippath, const QString &destpath)\n{\n    int res = 0;\n    QDir dir(destpath);\n    if (!cp437) {\n        cp437 = new QCodePage437Codec();\n    }\n#ifdef Q_OS_WIN32\n    zlib_filefunc64_def ffunc;\n    fill_win32_filefunc64W(&ffunc);\n    unzFile zfile = unzOpen2_64(Utility::QStringToStdWString(QDir::toNativeSeparators(zippath)).c_str(), &ffunc);\n#else\n    unzFile zfile = unzOpen64(QDir::toNativeSeparators(zippath).toUtf8().constData());\n#endif\n\n    if ((zfile == NULL) || (!IsFileReadable(zippath)) || (!dir.exists())) {\n        return false;\n    }\n\n    res = unzGoToFirstFile(zfile);\n\n    if (res == UNZ_OK) {\n        do {\n            // Get the name of the file in the archive.\n            char file_name[MAX_PATH] = {0};\n            unz_file_info64 file_info;\n            unzGetCurrentFileInfo64(zfile, &file_info, file_name, MAX_PATH, NULL, 0, NULL, 0);\n            QString qfile_name;\n            QString cp437_file_name;\n            qfile_name = QString::fromUtf8(file_name);\n            if (!(file_info.flag & (1<<11))) {\n                // General purpose bit 11 says the filename is utf-8 encoded. If not set then\n                // IBM 437 encoding might be used.\n                cp437_file_name = cp437->toUnicode(file_name);\n            }\n\n            // If there is no file name then we can't do anything with it.\n            if (!qfile_name.isEmpty()) {\n\n\t        // for security reasons against maliciously crafted zip archives\n\t        // we need the file path to always be inside the target folder \n\t        // and not outside, so we will remove all illegal backslashes\n\t        // and all relative upward paths segments \"/../\" from the zip's local \n\t        // file name/path before prepending the target folder to create \n\t        // the final path\n\n\t        QString original_path = qfile_name;\n\t        bool evil_or_corrupt_epub = false;\n\n\t        if (qfile_name.contains(\"\\\\\")) evil_or_corrupt_epub = true; \n\t        qfile_name = \"/\" + qfile_name.replace(\"\\\\\",\"\");\n\n\t        if (qfile_name.contains(\"/../\")) evil_or_corrupt_epub = true;\n\t        qfile_name = qfile_name.replace(\"/../\",\"/\");\n\n\t        while(qfile_name.startsWith(\"/\")) { \n\t\t  qfile_name = qfile_name.remove(0,1);\n\t        }\n                \n\t        if (cp437_file_name.contains(\"\\\\\")) evil_or_corrupt_epub = true; \n\t        cp437_file_name = \"/\" + cp437_file_name.replace(\"\\\\\",\"\");\n\n\t        if (cp437_file_name.contains(\"/../\")) evil_or_corrupt_epub = true;\n\t        cp437_file_name = cp437_file_name.replace(\"/../\",\"/\");\n\n\t        while(cp437_file_name.startsWith(\"/\")) { \n\t\t  cp437_file_name = cp437_file_name.remove(0,1);\n\t        }\n\n\t        if (evil_or_corrupt_epub) {\n\t\t    unzCloseCurrentFile(zfile);\n\t\t    unzClose(zfile);\n\t\t    // throw (UNZIPLoadParseError(QString(QObject::tr(\"Possible evil or corrupt zip file name: %1\")).arg(original_path).toStdString()));\n                    return false;\n\t        }\n\n                // We use the dir object to create the path in the temporary directory.\n                // Unfortunately, we need a dir ojbect to do this as it's not a static function.\n                // Full file path in the temporary directory.\n                QString file_path = destpath + \"/\" + qfile_name;\n                QFileInfo qfile_info(file_path);\n\n                // Is this entry a directory?\n                if (file_info.uncompressed_size == 0 && qfile_name.endsWith('/')) {\n                    dir.mkpath(qfile_name);\n                    continue;\n                } else {\n                    dir.mkpath(qfile_info.path());\n                }\n\n                // Open the file entry in the archive for reading.\n                if (unzOpenCurrentFile(zfile) != UNZ_OK) {\n                    unzClose(zfile);\n                    return false;\n                }\n\n                // Open the file on disk to write the entry in the archive to.\n                QFile entry(file_path);\n\n                if (!entry.open(QIODevice::WriteOnly | QIODevice::Truncate)) {\n                    unzCloseCurrentFile(zfile);\n                    unzClose(zfile);\n                    return false;\n                }\n\n                // Buffered reading and writing.\n                char buff[BUFF_SIZE] = {0};\n                int read = 0;\n\n                while ((read = unzReadCurrentFile(zfile, buff, BUFF_SIZE)) > 0) {\n                    entry.write(buff, read);\n                }\n\n                entry.close();\n\n                // Read errors are marked by a negative read amount.\n                if (read < 0) {\n                    unzCloseCurrentFile(zfile);\n                    unzClose(zfile);\n                    return false;\n                }\n\n                // The file was read but the CRC did not match.\n                // We don't check the read file size vs the uncompressed file size\n                // because if they're different there should be a CRC error.\n                if (unzCloseCurrentFile(zfile) == UNZ_CRCERROR) {\n                    unzClose(zfile);\n                    return false;\n                }\n\n                if (!cp437_file_name.isEmpty() && cp437_file_name != qfile_name) {\n                    QString cp437_file_path = destpath + \"/\" + cp437_file_name;\n                    QFile::copy(file_path, cp437_file_path);\n                }\n            }\n        } while ((res = unzGoToNextFile(zfile)) == UNZ_OK);\n    }\n\n    if (res != UNZ_END_OF_LIST_OF_FILE) {\n        unzClose(zfile);\n        return false;\n    }\n\n    unzClose(zfile);\n    return true;\n}", "commit_link": "github.com/Sigil-Ebook/Sigil/commit/0979ba8d10c96ebca330715bfd4494ea0e019a8f", "file_name": "src/Misc/Utility.cpp", "vul_type": "cwe-022", "description": "Write a C++ function to unzip a file to a specified directory using the QuaZIP library."}
{"func_name": "getGameID", "func_src_before": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = %i\" % ID)\n\tID = db.fetchone()\n\treturn ID", "func_src_after": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = ?\", ID)\n\tID = db.fetchone()\n\treturn ID", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getGameID` that retrieves a game's record from a database by its ID using parameterized queries."}
{"func_name": "hash_accept", "func_src_before": "static int hash_accept(struct socket *sock, struct socket *newsock, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tstruct hash_ctx *ctx = ask->private;\n\tstruct ahash_request *req = &ctx->req;\n\tchar state[crypto_ahash_statesize(crypto_ahash_reqtfm(req))];\n\tstruct sock *sk2;\n\tstruct alg_sock *ask2;\n\tstruct hash_ctx *ctx2;\n\tint err;\n\n\terr = crypto_ahash_export(req, state);\n\tif (err)\n\t\treturn err;\n\n\terr = af_alg_accept(ask->parent, newsock);\n\tif (err)\n\t\treturn err;\n\n\tsk2 = newsock->sk;\n\task2 = alg_sk(sk2);\n\tctx2 = ask2->private;\n\tctx2->more = 1;\n\n\terr = crypto_ahash_import(&ctx2->req, state);\n\tif (err) {\n\t\tsock_orphan(sk2);\n\t\tsock_put(sk2);\n\t}\n\n\treturn err;\n}", "func_src_after": "static int hash_accept(struct socket *sock, struct socket *newsock, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tstruct hash_ctx *ctx = ask->private;\n\tstruct ahash_request *req = &ctx->req;\n\tchar state[crypto_ahash_statesize(crypto_ahash_reqtfm(req))];\n\tstruct sock *sk2;\n\tstruct alg_sock *ask2;\n\tstruct hash_ctx *ctx2;\n\tbool more;\n\tint err;\n\n\tlock_sock(sk);\n\tmore = ctx->more;\n\terr = more ? crypto_ahash_export(req, state) : 0;\n\trelease_sock(sk);\n\n\tif (err)\n\t\treturn err;\n\n\terr = af_alg_accept(ask->parent, newsock);\n\tif (err)\n\t\treturn err;\n\n\tsk2 = newsock->sk;\n\task2 = alg_sk(sk2);\n\tctx2 = ask2->private;\n\tctx2->more = more;\n\n\tif (!more)\n\t\treturn err;\n\n\terr = crypto_ahash_import(&ctx2->req, state);\n\tif (err) {\n\t\tsock_orphan(sk2);\n\t\tsock_put(sk2);\n\t}\n\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/4afa5f9617927453ac04b24b584f6c718dfb4f45", "file_name": "crypto/algif_hash.c", "vul_type": "cwe-476", "description": "Write a C function named `hash_accept` that handles the acceptance of a new hash algorithm socket connection and the transfer of its state."}
{"func_name": "insertData", "func_src_before": "    def insertData(self,userid,post):\n        sqlText=\"insert into post(userid,date,comment) \\\n                values(%d,current_timestamp(0),'%s');\"%(userid,post);\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def insertData(self,userid,post):\n        sqlText=\"insert into post(userid,date,comment) \\\n                values(%s,current_timestamp(0),%s);\"\n        params=[userid,post];\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a user's post with the current timestamp into a database."}
{"func_name": "dumprecord", "func_src_before": "func dumprecord(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tdatabase := parray[0]\n\ttable := parray[1]\n\trec, err := strconv.Atoi(parray[2])\n\tcheckY(err)\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from \" + table)\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcolumns, err := rows.Columns()\n\tcheckY(err)\n\n\traw := make([]interface{}, len(columns))\n\tval := make([]interface{}, len(columns))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\nrowLoop:\n\tfor rows.Next() {\n\n\t\t// unfortunately we have to iterate up to row of interest\n\t\tif n == rec {\n\t\t\terr = rows.Scan(raw...)\n\t\t\tcheckY(err)\n\n\t\t\tfmt.Fprintln(w, \"<p>\")\n\t\t\tfor i, col := range val {\n\t\t\t\tif col != nil {\n\t\t\t\t\tfmt.Fprintln(w, columns[i], \":\", string(col.([]byte)), \"<br>\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"</p>\")\n\t\t\tbreak rowLoop\n\t\t}\n\t\tn = n + 1\n\t}\n}", "func_src_after": "func dumprecord(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tdatabase := parray[0]\n\ttable := parray[1]\n\trec, err := strconv.Atoi(parray[2])\n\tcheckY(err)\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcolumns, err := rows.Columns()\n\tcheckY(err)\n\n\traw := make([]interface{}, len(columns))\n\tval := make([]interface{}, len(columns))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\nrowLoop:\n\tfor rows.Next() {\n\n\t\t// unfortunately we have to iterate up to row of interest\n\t\tif n == rec {\n\t\t\terr = rows.Scan(raw...)\n\t\t\tcheckY(err)\n\n\t\t\tfmt.Fprintln(w, \"<p>\")\n\t\t\tfor i, col := range val {\n\t\t\t\tif col != nil {\n\t\t\t\t\tfmt.Fprintln(w, columns[i], \":\", string(col.([]byte)), \"<br>\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"</p>\")\n\t\t\tbreak rowLoop\n\t\t}\n\t\tn = n + 1\n\t}\n}", "line_changes": {"deleted": [{"line_no": 13, "char_start": 292, "char_end": 350, "line": "\tstatement, err := conn.Prepare(\"select * from \" + table)\n"}, {"line_no": 16, "char_start": 364, "char_end": 396, "line": "\trows, err := statement.Query()\n"}], "added": [{"line_no": 13, "char_start": 292, "char_end": 343, "line": "\tstatement, err := conn.Prepare(\"select * from ?\")\n"}, {"line_no": 16, "char_start": 357, "char_end": 394, "line": "\trows, err := statement.Query(table)\n"}]}, "char_changes": {"deleted": [{"char_start": 340, "char_end": 348, "chars": " + table"}], "added": [{"char_start": 339, "char_end": 340, "chars": "?"}, {"char_start": 387, "char_end": 392, "chars": "table"}]}, "commit_link": "github.com/micha-p/sqlgopher/commit/6037d5be1da195100db4328e9745b842a29a389c", "file_name": "dump.go", "vul_type": "cwe-089", "commit_msg": "Protection against sql injection via composed queries", "parent_commit": "3b4884a57e465df2433dde79a7e7a31c92a15099", "description": "Write a Go function to fetch and display a specific record from a MySQL database table based on parameters from an HTTP request."}
{"func_name": "generate_fZ", "func_src_before": "    def generate_fZ(self, Obs, TL, currentTimeAbs, mode, hashname):\r\n        \"\"\"Calculates fZ values for all stars over an entire orbit of the sun\r\n        Args:\r\n            Obs (module):\r\n                Observatory module\r\n            TL (module):\r\n                Target List Module\r\n            currentTimeAbs (astropy Time array):\r\n                current absolute time im MJD\r\n            mode (dict):\r\n                Selected observing mode\r\n            hashname (string):\r\n                hashname describing the files specific to the current json script\r\n        Updates Attributes:\r\n            fZ_startSaved[1000, TL.nStars] (astropy Quantity array):\r\n                Surface brightness of zodiacal light in units of 1/arcsec2 for each star over 1 year at discrete points defined by resolution\r\n        \"\"\"\r\n        #Generate cache Name########################################################################\r\n        cachefname = hashname+'starkfZ'\r\n\r\n        #Check if file exists#######################################################################\r\n        if os.path.isfile(cachefname):#check if file exists\r\n            self.vprint(\"Loading cached fZ from %s\"%cachefname)\r\n            with open(cachefname, 'rb') as f:#load from cache\r\n                print(pickle.load(f))\r\n                tmpfZ = pickle.load(f)\r\n                try:\r\n                    f.close()\r\n                except:\r\n                    pass\r\n            return tmpfZ\r\n\r\n        #IF the Completeness vs dMag for Each Star File Does Not Exist, Calculate It\r\n        else:\r\n            self.vprint(\"Calculating fZ\")\r\n            #OS = self.OpticalSystem#Testing to be sure I can remove this\r\n            #WA = OS.WA0#Testing to be sure I can remove this\r\n            sInds= np.arange(TL.nStars)\r\n            startTime = np.zeros(sInds.shape[0])*u.d + currentTimeAbs#Array of current times\r\n            resolution = [j for j in range(1000)]\r\n            fZ = np.zeros([sInds.shape[0], len(resolution)])\r\n            dt = 365.25/len(resolution)*u.d\r\n            for i in xrange(len(resolution)):#iterate through all times of year\r\n                time = startTime + dt*resolution[i]\r\n                fZ[:,i] = self.fZ(Obs, TL, sInds, time, mode)\r\n            \r\n            with open(cachefname, \"wb\") as fo:\r\n                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n                pickle.dump(fZ,fo)\r\n                self.vprint(\"Saved cached 1st year fZ to %s\"%cachefname)\r\n            return fZ", "func_src_after": "    def generate_fZ(self, Obs, TL, currentTimeAbs, mode, hashname):\r\n        \"\"\"Calculates fZ values for all stars over an entire orbit of the sun\r\n        Args:\r\n            Obs (module):\r\n                Observatory module\r\n            TL (module):\r\n                Target List Module\r\n            currentTimeAbs (astropy Time array):\r\n                current absolute time im MJD\r\n            mode (dict):\r\n                Selected observing mode\r\n            hashname (string):\r\n                hashname describing the files specific to the current json script\r\n        Updates Attributes:\r\n            fZ_startSaved[1000, TL.nStars] (astropy Quantity array):\r\n                Surface brightness of zodiacal light in units of 1/arcsec2 for each star over 1 year at discrete points defined by resolution\r\n        \"\"\"\r\n        #Generate cache Name########################################################################\r\n        cachefname = hashname+'starkfZ'\r\n\r\n        #Check if file exists#######################################################################\r\n        if os.path.isfile(cachefname):#check if file exists\r\n            self.vprint(\"Loading cached fZ from %s\"%cachefname)\r\n            with open(cachefname, 'rb') as f:#load from cache\r\n                tmpfZ = pickle.load(f)\r\n            return tmpfZ\r\n\r\n        #IF the Completeness vs dMag for Each Star File Does Not Exist, Calculate It\r\n        else:\r\n            self.vprint(\"Calculating fZ\")\r\n            #OS = self.OpticalSystem#Testing to be sure I can remove this\r\n            #WA = OS.WA0#Testing to be sure I can remove this\r\n            sInds= np.arange(TL.nStars)\r\n            startTime = np.zeros(sInds.shape[0])*u.d + currentTimeAbs#Array of current times\r\n            resolution = [j for j in range(1000)]\r\n            fZ = np.zeros([sInds.shape[0], len(resolution)])\r\n            dt = 365.25/len(resolution)*u.d\r\n            for i in xrange(len(resolution)):#iterate through all times of year\r\n                time = startTime + dt*resolution[i]\r\n                fZ[:,i] = self.fZ(Obs, TL, sInds, time, mode)\r\n            \r\n            with open(cachefname, \"wb\") as fo:\r\n                pickle.dump(fZ,fo)\r\n                self.vprint(\"Saved cached 1st year fZ to %s\"%cachefname)\r\n            return fZ", "line_changes": {"deleted": [{"line_no": 25, "char_start": 1257, "char_end": 1296, "line": "                print(pickle.load(f))\r\n"}, {"line_no": 27, "char_start": 1336, "char_end": 1358, "line": "                try:\r\n"}, {"line_no": 28, "char_start": 1358, "char_end": 1389, "line": "                    f.close()\r\n"}, {"line_no": 29, "char_start": 1389, "char_end": 1414, "line": "                except:\r\n"}, {"line_no": 30, "char_start": 1414, "char_end": 1440, "line": "                    pass\r\n"}, {"line_no": 48, "char_start": 2302, "char_end": 2362, "line": "                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 1273, "char_end": 1438, "chars": "print(pickle.load(f))\r\n                tmpfZ = pickle.load(f)\r\n                try:\r\n                    f.close()\r\n                except:\r\n                    pass"}, {"char_start": 2302, "char_end": 2362, "chars": "                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n"}], "added": [{"char_start": 1273, "char_end": 1295, "chars": "tmpfZ = pickle.load(f)"}]}, "commit_link": "github.com/dsavransky/EXOSIMS/commit/2df12d23c54a140161c24e92b3c03aaf522c61ec", "file_name": "ZodiacalLight.py", "vul_type": "cwe-502", "commit_msg": "fixed pickle load errors", "parent_commit": "c4660a0de665797559fd4d048b4d971661366f50", "description": "In Python, write a function to calculate and cache surface brightness values for stars, loading from cache if available."}
{"func_name": "MultiPartInputFile::Data::chunkOffsetReconstruction", "func_src_before": "MultiPartInputFile::Data::chunkOffsetReconstruction(OPENEXR_IMF_INTERNAL_NAMESPACE::IStream& is, const vector<InputPartData*>& parts)\n{\n    //\n    // Reconstruct broken chunk offset tables. Stop once we received any exception.\n    //\n\n    Int64 position = is.tellg();\n\n    \n    //\n    // check we understand all the parts available: if not, we cannot continue\n    // exceptions thrown here should trickle back up to the constructor\n    //\n    \n    for (size_t i = 0; i < parts.size(); i++)\n    {\n        Header& header=parts[i]->header;\n        \n        //\n        // do we have a valid type entry?\n        // we only need them for true multipart files or single part non-image (deep) files\n        //\n        if(!header.hasType() && (isMultiPart(version) || isNonImage(version)))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with missing type\");\n        }\n        if(!isSupportedType(header.type()))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with unknown type \"+header.type());\n        }\n    }\n    \n    \n    // how many chunks should we read? We should stop when we reach the end\n    size_t total_chunks = 0;\n        \n    // for tiled-based parts, array of (pointers to) tileOffsets objects\n    // to create mapping between tile coordinates and chunk table indices\n    \n    \n    vector<TileOffsets*> tileOffsets(parts.size());\n    \n    // for scanline-based parts, number of scanlines in each chunk\n    vector<int> rowsizes(parts.size());\n        \n    for(size_t i = 0 ; i < parts.size() ; i++)\n    {\n        total_chunks += parts[i]->chunkOffsets.size();\n        if (isTiled(parts[i]->header.type()))\n        {\n            tileOffsets[i] = createTileOffsets(parts[i]->header);\n        }else{\n            tileOffsets[i] = NULL;\n            // (TODO) fix this so that it doesn't need to be revised for future compression types.\n            switch(parts[i]->header.compression())\n            {\n                case DWAB_COMPRESSION :\n                    rowsizes[i] = 256;\n                    break;\n                case PIZ_COMPRESSION :\n                case B44_COMPRESSION :\n                case B44A_COMPRESSION :\n                case DWAA_COMPRESSION :\n                    rowsizes[i]=32;\n                    break;\n                case ZIP_COMPRESSION :\n                case PXR24_COMPRESSION :\n                    rowsizes[i]=16;\n                    break;\n                case ZIPS_COMPRESSION :\n                case RLE_COMPRESSION :\n                case NO_COMPRESSION :\n                    rowsizes[i]=1;\n                    break;\n                default :\n                    throw(IEX_NAMESPACE::ArgExc(\"Unknown compression method in chunk offset reconstruction\"));\n            }\n        }\n     }\n        \n     try\n     {\n            \n        //\n        // \n        //\n        \n        Int64 chunk_start = position;\n        for (size_t i = 0; i < total_chunks ; i++)\n        {\n            //\n            // do we have a part number?\n            //\n            \n            int partNumber = 0;\n            if(isMultiPart(version))\n            {\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, partNumber);\n            }\n            \n            \n            \n            if(partNumber<0 || partNumber> static_cast<int>(parts.size()))\n            {\n                throw IEX_NAMESPACE::IoExc(\"part number out of range\");\n            }\n            \n            Header& header = parts[partNumber]->header;\n\n            // size of chunk NOT including multipart field\n            \n            Int64 size_of_chunk=0;\n\n            if (isTiled(header.type()))\n            {\n                //\n                // \n                //\n                int tilex,tiley,levelx,levely;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tilex);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tiley);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levelx);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levely);\n                \n                //std::cout << \"chunk_start for \" << tilex <<',' << tiley << ',' << levelx << ' ' << levely << ':' << chunk_start << std::endl;\n                    \n                \n                if(!tileOffsets[partNumber])\n                {\n                    // this shouldn't actually happen - we should have allocated a valid\n                    // tileOffsets for any part which isTiled\n                    throw IEX_NAMESPACE::IoExc(\"part not tiled\");\n                    \n                }\n                \n                if(!tileOffsets[partNumber]->isValidTile(tilex,tiley,levelx,levely))\n                {\n                    throw IEX_NAMESPACE::IoExc(\"invalid tile coordinates\");\n                }\n                \n                (*tileOffsets[partNumber])(tilex,tiley,levelx,levely)=chunk_start;\n                \n                // compute chunk sizes - different procedure for deep tiles and regular\n                // ones\n                if(header.type()==DEEPTILE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    //add 40 byte header to packed sizes (tile coordinates, packed sizes, unpacked size)\n                    size_of_chunk=packed_offset+packed_sample+40;\n                }\n                else\n                {\n                    \n                    // regular image has 20 bytes of header, 4 byte chunksize;\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);\n                    size_of_chunk=chunksize+20;\n                }\n            }\n            else\n            {\n                int y_coordinate;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, y_coordinate);\n                \n                \n                if(y_coordinate < header.dataWindow().min.y || y_coordinate > header.dataWindow().max.y)\n                {\n                   throw IEX_NAMESPACE::IoExc(\"y out of range\");\n                }\n                y_coordinate -= header.dataWindow().min.y;\n                y_coordinate /= rowsizes[partNumber];   \n                \n                if(y_coordinate < 0 || y_coordinate >= int(parts[partNumber]->chunkOffsets.size()))\n                {\n                   throw IEX_NAMESPACE::IoExc(\"chunk index out of range\");\n                }\n                \n                parts[partNumber]->chunkOffsets[y_coordinate]=chunk_start;\n                \n                if(header.type()==DEEPSCANLINE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    \n                    size_of_chunk=packed_offset+packed_sample+28;\n                }\n                else\n                {\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);   \n                    size_of_chunk=chunksize+8;\n                }\n                \n            }\n            \n            if(isMultiPart(version))\n            {\n                chunk_start+=4;\n            }\n            \n            chunk_start+=size_of_chunk;\n            \n            is.seekg(chunk_start);\n            \n        }\n        \n    }\n    catch (...)\n    {\n        //\n        // Suppress all exceptions.  This functions is\n        // called only to reconstruct the line offset\n        // table for incomplete files, and exceptions\n        // are likely.\n        //\n    }\n\n    // copy tiled part data back to chunk offsets\n    \n    for(size_t partNumber=0;partNumber<parts.size();partNumber++)\n    {\n        if(tileOffsets[partNumber])\n        {\n            size_t pos=0;\n            vector<vector<vector <Int64> > > offsets = tileOffsets[partNumber]->getOffsets();\n            for (size_t l = 0; l < offsets.size(); l++)\n                for (size_t y = 0; y < offsets[l].size(); y++)\n                    for (size_t x = 0; x < offsets[l][y].size(); x++)\n                    {\n                        parts[ partNumber ]->chunkOffsets[pos] = offsets[l][y][x];\n                        pos++;\n                    }\n           delete tileOffsets[partNumber];\n        }\n    }\n\n    is.clear();\n    is.seekg (position);\n}", "func_src_after": "MultiPartInputFile::Data::chunkOffsetReconstruction(OPENEXR_IMF_INTERNAL_NAMESPACE::IStream& is, const vector<InputPartData*>& parts)\n{\n    //\n    // Reconstruct broken chunk offset tables. Stop once we received any exception.\n    //\n\n    Int64 position = is.tellg();\n\n    \n    //\n    // check we understand all the parts available: if not, we cannot continue\n    // exceptions thrown here should trickle back up to the constructor\n    //\n    \n    for (size_t i = 0; i < parts.size(); i++)\n    {\n        Header& header=parts[i]->header;\n        \n        //\n        // do we have a valid type entry?\n        // we only need them for true multipart files or single part non-image (deep) files\n        //\n        if(!header.hasType() && (isMultiPart(version) || isNonImage(version)))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with missing type\");\n        }\n        if(!isSupportedType(header.type()))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with unknown type \"+header.type());\n        }\n    }\n    \n    \n    // how many chunks should we read? We should stop when we reach the end\n    size_t total_chunks = 0;\n        \n    // for tiled-based parts, array of (pointers to) tileOffsets objects\n    // to create mapping between tile coordinates and chunk table indices\n    \n    \n    vector<TileOffsets*> tileOffsets(parts.size());\n    \n    // for scanline-based parts, number of scanlines in each chunk\n    vector<int> rowsizes(parts.size());\n        \n    for(size_t i = 0 ; i < parts.size() ; i++)\n    {\n        total_chunks += parts[i]->chunkOffsets.size();\n        if (isTiled(parts[i]->header.type()))\n        {\n            tileOffsets[i] = createTileOffsets(parts[i]->header);\n        }else{\n            tileOffsets[i] = NULL;\n            // (TODO) fix this so that it doesn't need to be revised for future compression types.\n            switch(parts[i]->header.compression())\n            {\n                case DWAB_COMPRESSION :\n                    rowsizes[i] = 256;\n                    break;\n                case PIZ_COMPRESSION :\n                case B44_COMPRESSION :\n                case B44A_COMPRESSION :\n                case DWAA_COMPRESSION :\n                    rowsizes[i]=32;\n                    break;\n                case ZIP_COMPRESSION :\n                case PXR24_COMPRESSION :\n                    rowsizes[i]=16;\n                    break;\n                case ZIPS_COMPRESSION :\n                case RLE_COMPRESSION :\n                case NO_COMPRESSION :\n                    rowsizes[i]=1;\n                    break;\n                default :\n                    throw(IEX_NAMESPACE::ArgExc(\"Unknown compression method in chunk offset reconstruction\"));\n            }\n        }\n     }\n        \n     try\n     {\n            \n        //\n        // \n        //\n        \n        Int64 chunk_start = position;\n        for (size_t i = 0; i < total_chunks ; i++)\n        {\n            //\n            // do we have a part number?\n            //\n            \n            int partNumber = 0;\n            if(isMultiPart(version))\n            {\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, partNumber);\n            }\n            \n            \n            \n            if(partNumber<0 || partNumber>= static_cast<int>(parts.size()))\n            {\n                throw IEX_NAMESPACE::IoExc(\"part number out of range\");\n            }\n            \n            Header& header = parts[partNumber]->header;\n\n            // size of chunk NOT including multipart field\n            \n            Int64 size_of_chunk=0;\n\n            if (isTiled(header.type()))\n            {\n                //\n                // \n                //\n                int tilex,tiley,levelx,levely;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tilex);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tiley);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levelx);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levely);\n                \n                //std::cout << \"chunk_start for \" << tilex <<',' << tiley << ',' << levelx << ' ' << levely << ':' << chunk_start << std::endl;\n                    \n                \n                if(!tileOffsets[partNumber])\n                {\n                    // this shouldn't actually happen - we should have allocated a valid\n                    // tileOffsets for any part which isTiled\n                    throw IEX_NAMESPACE::IoExc(\"part not tiled\");\n                    \n                }\n                \n                if(!tileOffsets[partNumber]->isValidTile(tilex,tiley,levelx,levely))\n                {\n                    throw IEX_NAMESPACE::IoExc(\"invalid tile coordinates\");\n                }\n                \n                (*tileOffsets[partNumber])(tilex,tiley,levelx,levely)=chunk_start;\n                \n                // compute chunk sizes - different procedure for deep tiles and regular\n                // ones\n                if(header.type()==DEEPTILE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    //add 40 byte header to packed sizes (tile coordinates, packed sizes, unpacked size)\n                    size_of_chunk=packed_offset+packed_sample+40;\n                }\n                else\n                {\n                    \n                    // regular image has 20 bytes of header, 4 byte chunksize;\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);\n                    size_of_chunk=chunksize+20;\n                }\n            }\n            else\n            {\n                int y_coordinate;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, y_coordinate);\n                \n                \n                if(y_coordinate < header.dataWindow().min.y || y_coordinate > header.dataWindow().max.y)\n                {\n                   throw IEX_NAMESPACE::IoExc(\"y out of range\");\n                }\n                y_coordinate -= header.dataWindow().min.y;\n                y_coordinate /= rowsizes[partNumber];   \n                \n                if(y_coordinate < 0 || y_coordinate >= int(parts[partNumber]->chunkOffsets.size()))\n                {\n                   throw IEX_NAMESPACE::IoExc(\"chunk index out of range\");\n                }\n                \n                parts[partNumber]->chunkOffsets[y_coordinate]=chunk_start;\n                \n                if(header.type()==DEEPSCANLINE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    \n                    size_of_chunk=packed_offset+packed_sample+28;\n                }\n                else\n                {\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);   \n                    size_of_chunk=chunksize+8;\n                }\n                \n            }\n            \n            if(isMultiPart(version))\n            {\n                chunk_start+=4;\n            }\n            \n            chunk_start+=size_of_chunk;\n            \n            is.seekg(chunk_start);\n            \n        }\n        \n    }\n    catch (...)\n    {\n        //\n        // Suppress all exceptions.  This functions is\n        // called only to reconstruct the line offset\n        // table for incomplete files, and exceptions\n        // are likely.\n        //\n    }\n\n    // copy tiled part data back to chunk offsets\n    \n    for(size_t partNumber=0;partNumber<parts.size();partNumber++)\n    {\n        if(tileOffsets[partNumber])\n        {\n            size_t pos=0;\n            vector<vector<vector <Int64> > > offsets = tileOffsets[partNumber]->getOffsets();\n            for (size_t l = 0; l < offsets.size(); l++)\n                for (size_t y = 0; y < offsets[l].size(); y++)\n                    for (size_t x = 0; x < offsets[l][y].size(); x++)\n                    {\n                        parts[ partNumber ]->chunkOffsets[pos] = offsets[l][y][x];\n                        pos++;\n                    }\n           delete tileOffsets[partNumber];\n        }\n    }\n\n    is.clear();\n    is.seekg (position);\n}", "commit_link": "github.com/AcademySoftwareFoundation/openexr/commit/8b5370c688a7362673c3a5256d93695617a4cd9a", "file_name": "OpenEXR/IlmImf/ImfMultiPartInputFile.cpp", "vul_type": "cwe-787", "description": "Write a C++ function to reconstruct chunk offset tables from an OpenEXR file stream, handling exceptions silently."}
{"func_name": "test_fluent_safe", "func_src_before": "def test_fluent_safe():\n    hostname = 'www.python.org'\n    context = SSL.Context(SSL.SSLv23_METHOD)\n    context.set_options(SSL.OP_NO_TLSv1)\n    context.set_options(SSL.OP_NO_TLSv1_1)\n\n    conn = SSL.Connection(context, socket.socket(socket.AF_INET, socket.SOCK_STREAM))\n    r = conn.connect((hostname, 443))\n    print(r, conn.get_protocol_version_name())", "func_src_after": "def test_fluent_safe():\n    hostname = 'www.python.org'\n    context = SSL.Context(SSL.SSLv23_METHOD)\n    context.set_options(SSL.OP_NO_SSLv2)\n    context.set_options(SSL.OP_NO_SSLv3)\n    context.set_options(SSL.OP_NO_TLSv1)\n    context.set_options(SSL.OP_NO_TLSv1_1)\n\n    conn = SSL.Connection(context, socket.socket(socket.AF_INET, socket.SOCK_STREAM))\n    r = conn.connect((hostname, 443))\n    print(r, conn.get_protocol_version_name())", "line_changes": {"deleted": [], "added": [{"line_no": 4, "char_start": 101, "char_end": 142, "line": "    context.set_options(SSL.OP_NO_SSLv2)\n"}, {"line_no": 5, "char_start": 142, "char_end": 183, "line": "    context.set_options(SSL.OP_NO_SSLv3)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 101, "char_end": 183, "chars": "    context.set_options(SSL.OP_NO_SSLv2)\n    context.set_options(SSL.OP_NO_SSLv3)\n"}]}, "commit_link": "github.com/github/codeql/commit/54dad57cf4a22a9d01a434d0633606fa8adf7c8f", "file_name": "pyOpenSSL_fluent.py", "vul_type": "cwe-327", "commit_msg": "Update python/ql/test/query-tests/Security/CWE-327/pyOpenSSL_fluent.py\n\nCo-authored-by: Rasmus Wriedt Larsen <rasmuswriedtlarsen@gmail.com>", "parent_commit": "62a0775cf69c8bda45aeb9b0cdf60f28dafd9c72", "description": "Write a Python function that establishes a secure connection to a specified hostname and prints the connection result and protocol version."}
{"func_name": "plot", "func_src_before": "    def plot(self, log_files, sort='time', limit=10, nfl_filter='',\n             metric_selected='cc', plot_type='bar'):\n        if not PLOTLIB_INSTALLED:\n            raise PLOTLIBNotInstalled(_('python-matplotlib not installed.'))\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            stats_dict = stats.stats\n            __, func_list = stats.get_print_list([nfl_filter, limit])\n            nfls = []\n            performance = []\n            names = {'nc': 'Total Call Count', 'cc': 'Primitive Call Count',\n                     'tt': 'Total Time', 'ct': 'Cumulative Time'}\n            for func in func_list:\n                cc, nc, tt, ct, __ = stats_dict[func]\n                metric = {'cc': cc, 'nc': nc, 'tt': tt, 'ct': ct}\n                nfls.append(func[2])\n                performance.append(metric[metric_selected])\n            y_pos = range(len(nfls))\n            error = [random.random() for __ in y_pos]\n            plt.clf()\n            if plot_type == 'pie':\n                plt.pie(x=performance, explode=None, labels=nfls,\n                        autopct='%1.1f%%')\n            else:\n                plt.barh(y_pos, performance, xerr=error, align='center',\n                         alpha=0.4)\n                plt.yticks(y_pos, nfls)\n                plt.xlabel(names[metric_selected])\n            plt.title('Profile Statistics (by %s)' % names[metric_selected])\n            #plt.gcf().tight_layout(pad=1.2)\n            profile_img = tempfile.mktemp('.png', 'plot')\n            plt.savefig(profile_img, dpi=300)\n            data = open(profile_img).read()\n            os.remove(profile_img)\n            return data, [('content-type', 'image/jpg')]\n        except Exception as ex:\n            raise ProfileException(_('plotting results failed due to %s') % ex)", "func_src_after": "    def plot(self, log_files, sort='time', limit=10, nfl_filter='',\n             metric_selected='cc', plot_type='bar'):\n        if not PLOTLIB_INSTALLED:\n            raise PLOTLIBNotInstalled(_('python-matplotlib not installed.'))\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            stats_dict = stats.stats\n            __, func_list = stats.get_print_list([nfl_filter, limit])\n            nfls = []\n            performance = []\n            names = {'nc': 'Total Call Count', 'cc': 'Primitive Call Count',\n                     'tt': 'Total Time', 'ct': 'Cumulative Time'}\n            for func in func_list:\n                cc, nc, tt, ct, __ = stats_dict[func]\n                metric = {'cc': cc, 'nc': nc, 'tt': tt, 'ct': ct}\n                nfls.append(func[2])\n                performance.append(metric[metric_selected])\n            y_pos = range(len(nfls))\n            error = [random.random() for __ in y_pos]\n            plt.clf()\n            if plot_type == 'pie':\n                plt.pie(x=performance, explode=None, labels=nfls,\n                        autopct='%1.1f%%')\n            else:\n                plt.barh(y_pos, performance, xerr=error, align='center',\n                         alpha=0.4)\n                plt.yticks(y_pos, nfls)\n                plt.xlabel(names[metric_selected])\n            plt.title('Profile Statistics (by %s)' % names[metric_selected])\n            #plt.gcf().tight_layout(pad=1.2)\n            profile_img = tempfile.TemporaryFile()\n            plt.savefig(profile_img, format='png', dpi=300)\n            profile_img.seek(0)\n            data = profile_img.read()\n            os.close(profile_img)\n            return data, [('content-type', 'image/jpg')]\n        except Exception as ex:\n            raise ProfileException(_('plotting results failed due to %s') % ex)", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1561, "char_end": 1619, "line": "            profile_img = tempfile.mktemp('.png', 'plot')\n"}, {"line_no": 35, "char_start": 1619, "char_end": 1665, "line": "            plt.savefig(profile_img, dpi=300)\n"}, {"line_no": 36, "char_start": 1665, "char_end": 1709, "line": "            data = open(profile_img).read()\n"}, {"line_no": 37, "char_start": 1709, "char_end": 1744, "line": "            os.remove(profile_img)\n"}], "added": [{"line_no": 34, "char_start": 1561, "char_end": 1612, "line": "            profile_img = tempfile.TemporaryFile()\n"}, {"line_no": 35, "char_start": 1612, "char_end": 1672, "line": "            plt.savefig(profile_img, format='png', dpi=300)\n"}, {"line_no": 36, "char_start": 1672, "char_end": 1704, "line": "            profile_img.seek(0)\n"}, {"line_no": 37, "char_start": 1704, "char_end": 1742, "line": "            data = profile_img.read()\n"}, {"line_no": 38, "char_start": 1742, "char_end": 1776, "line": "            os.close(profile_img)\n"}]}, "char_changes": {"deleted": [{"char_start": 1596, "char_end": 1617, "chars": "mktemp('.png', 'plot'"}, {"char_start": 1684, "char_end": 1689, "chars": "open("}, {"char_start": 1700, "char_end": 1701, "chars": ")"}, {"char_start": 1724, "char_end": 1729, "chars": "remov"}], "added": [{"char_start": 1596, "char_end": 1610, "chars": "TemporaryFile("}, {"char_start": 1648, "char_end": 1662, "chars": " format='png',"}, {"char_start": 1672, "char_end": 1704, "chars": "            profile_img.seek(0)\n"}, {"char_start": 1757, "char_end": 1761, "chars": "clos"}]}, "commit_link": "github.com/scality/ScalitySproxydSwift/commit/6978275cdb04bb08aaf142d401b52a46527dac4c", "file_name": "html_viewer.py", "vul_type": "cwe-377", "commit_msg": "Avoid usage of insecure mktemp() function\n\nThis patch eliminates the use of the deprecated and insecure\ntempfile.mktemp() function.  It has been replaced with secure\nalternatives where temporary files are actually required.\n\nChange-Id: I0a13d6d44cd1abc4b66fa33f39eea407617a01d5\nSecurityImpact\nCloses-bug: #1348869", "description": "In Python, write a function to plot performance statistics from log files using matplotlib, with options for sorting, filtering, and different plot types."}
{"func_name": "_call_prepare_fc_map", "func_src_before": "    def _call_prepare_fc_map(self, fc_map_id, source, target):\n        try:\n            out, err = self._run_ssh('svctask prestartfcmap %s' % fc_map_id)\n        except exception.ProcessExecutionError as e:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_('_prepare_fc_map: Failed to prepare FlashCopy '\n                            'from %(source)s to %(target)s.\\n'\n                            'stdout: %(out)s\\n stderr: %(err)s')\n                          % {'source': source,\n                             'target': target,\n                             'out': e.stdout,\n                             'err': e.stderr})", "func_src_after": "    def _call_prepare_fc_map(self, fc_map_id, source, target):\n        try:\n            out, err = self._run_ssh(['svctask', 'prestartfcmap', fc_map_id])\n        except exception.ProcessExecutionError as e:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_('_prepare_fc_map: Failed to prepare FlashCopy '\n                            'from %(source)s to %(target)s.\\n'\n                            'stdout: %(out)s\\n stderr: %(err)s')\n                          % {'source': source,\n                             'target': target,\n                             'out': e.stdout,\n                             'err': e.stderr})", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function that attempts to run an SSH command for preparing a FlashCopy map and logs an error if it fails."}
{"func_name": "(anonymous)", "func_src_before": "(function() {\n  'use strict';\n\n  var ready = function(loaded) {\n    if (['interactive', 'complete'].indexOf(document.readyState) !== -1) {\n      loaded();\n    } else {\n      document.addEventListener('DOMContentLoaded', loaded);\n    }\n  };\n\n  ready(function() {\n    var iframes = [];\n\n    window.addEventListener('message', function(e) {\n      var data = e.data || {};\n\n      if (data.type !== 'setHeight' || !iframes[data.id] || window.location.origin !== e.origin || data.id.toString() === '__proto__') {\n        return;\n      }\n\n      iframes[data.id].height = data.height;\n    });\n\n    [].forEach.call(document.querySelectorAll('iframe.mastodon-embed'), function(iframe) {\n      iframe.scrolling      = 'no';\n      iframe.style.overflow = 'hidden';\n\n      iframes.push(iframe);\n\n      var id = iframes.length - 1;\n\n      iframe.onload = function() {\n        iframe.contentWindow.postMessage({\n          type: 'setHeight',\n          id: id,\n        }, '*');\n      };\n\n      iframe.onload();\n    });\n  });\n})();", "func_src_after": "(function() {\n  'use strict';\n\n  /**\n   * @param {() => void} loaded\n   */\n  var ready = function(loaded) {\n    if (['interactive', 'complete'].indexOf(document.readyState) !== -1) {\n      loaded();\n    } else {\n      document.addEventListener('DOMContentLoaded', loaded);\n    }\n  };\n\n  ready(function() {\n    /** @type {Map<number, HTMLIFrameElement>} */\n    var iframes = new Map();\n\n    window.addEventListener('message', function(e) {\n      var data = e.data || {};\n\n      if (typeof data !== 'object' || data.type !== 'setHeight' || !iframes.has(data.id)) {\n        return;\n      }\n\n      var iframe = iframes.get(data.id);\n\n      if ('source' in e && iframe.contentWindow !== e.source) {\n        return;\n      }\n\n      iframe.height = data.height;\n    });\n\n    [].forEach.call(document.querySelectorAll('iframe.mastodon-embed'), function(iframe) {\n      // select unique id for each iframe\n      var id = 0, failCount = 0, idBuffer = new Uint32Array(1);\n      while (id === 0 || iframes.has(id)) {\n        id = crypto.getRandomValues(idBuffer)[0];\n        failCount++;\n        if (failCount > 100) {\n          // give up and assign (easily guessable) unique number if getRandomValues is broken or no luck\n          id = -(iframes.size + 1);\n          break;\n        }\n      }\n\n      iframes.set(id, iframe);\n\n      iframe.scrolling      = 'no';\n      iframe.style.overflow = 'hidden';\n\n      iframe.onload = function() {\n        iframe.contentWindow.postMessage({\n          type: 'setHeight',\n          id: id,\n        }, '*');\n      };\n\n      iframe.onload();\n    });\n  });\n})();", "line_changes": {"deleted": [{"line_no": 13, "char_start": 262, "char_end": 284, "line": "    var iframes = [];\n"}, {"line_no": 18, "char_start": 370, "char_end": 507, "line": "      if (data.type !== 'setHeight' || !iframes[data.id] || window.location.origin !== e.origin || data.id.toString() === '__proto__') {\n"}, {"line_no": 22, "char_start": 532, "char_end": 577, "line": "      iframes[data.id].height = data.height;\n"}, {"line_no": 26, "char_start": 677, "char_end": 713, "line": "      iframe.scrolling      = 'no';\n"}, {"line_no": 27, "char_start": 713, "char_end": 753, "line": "      iframe.style.overflow = 'hidden';\n"}, {"line_no": 29, "char_start": 754, "char_end": 782, "line": "      iframes.push(iframe);\n"}, {"line_no": 31, "char_start": 783, "char_end": 818, "line": "      var id = iframes.length - 1;\n"}], "added": [{"line_no": 4, "char_start": 31, "char_end": 37, "line": "  /**\n"}, {"line_no": 5, "char_start": 37, "char_end": 69, "line": "   * @param {() => void} loaded\n"}, {"line_no": 6, "char_start": 69, "char_end": 75, "line": "   */\n"}, {"line_no": 16, "char_start": 306, "char_end": 356, "line": "    /** @type {Map<number, HTMLIFrameElement>} */\n"}, {"line_no": 17, "char_start": 356, "char_end": 385, "line": "    var iframes = new Map();\n"}, {"line_no": 22, "char_start": 471, "char_end": 563, "line": "      if (typeof data !== 'object' || data.type !== 'setHeight' || !iframes.has(data.id)) {\n"}, {"line_no": 23, "char_start": 563, "char_end": 579, "line": "        return;\n"}, {"line_no": 24, "char_start": 579, "char_end": 587, "line": "      }\n"}, {"line_no": 25, "char_start": 587, "char_end": 588, "line": "\n"}, {"line_no": 26, "char_start": 588, "char_end": 629, "line": "      var iframe = iframes.get(data.id);\n"}, {"line_no": 27, "char_start": 629, "char_end": 630, "line": "\n"}, {"line_no": 28, "char_start": 630, "char_end": 694, "line": "      if ('source' in e && iframe.contentWindow !== e.source) {\n"}, {"line_no": 32, "char_start": 719, "char_end": 754, "line": "      iframe.height = data.height;\n"}, {"line_no": 37, "char_start": 896, "char_end": 960, "line": "      var id = 0, failCount = 0, idBuffer = new Uint32Array(1);\n"}, {"line_no": 38, "char_start": 960, "char_end": 1004, "line": "      while (id === 0 || iframes.has(id)) {\n"}, {"line_no": 39, "char_start": 1004, "char_end": 1054, "line": "        id = crypto.getRandomValues(idBuffer)[0];\n"}, {"line_no": 40, "char_start": 1054, "char_end": 1075, "line": "        failCount++;\n"}, {"line_no": 41, "char_start": 1075, "char_end": 1106, "line": "        if (failCount > 100) {\n"}, {"line_no": 43, "char_start": 1211, "char_end": 1247, "line": "          id = -(iframes.size + 1);\n"}, {"line_no": 44, "char_start": 1247, "char_end": 1264, "line": "          break;\n"}, {"line_no": 45, "char_start": 1264, "char_end": 1274, "line": "        }\n"}, {"line_no": 46, "char_start": 1274, "char_end": 1282, "line": "      }\n"}, {"line_no": 48, "char_start": 1283, "char_end": 1314, "line": "      iframes.set(id, iframe);\n"}, {"line_no": 50, "char_start": 1315, "char_end": 1351, "line": "      iframe.scrolling      = 'no';\n"}, {"line_no": 51, "char_start": 1351, "char_end": 1391, "line": "      iframe.style.overflow = 'hidden';\n"}]}, "char_changes": {"deleted": [{"char_start": 280, "char_end": 282, "chars": "[]"}, {"char_start": 417, "char_end": 418, "chars": "["}, {"char_start": 425, "char_end": 503, "chars": "] || window.location.origin !== e.origin || data.id.toString() === '__proto__'"}, {"char_start": 544, "char_end": 554, "chars": "s[data.id]"}, {"char_start": 683, "char_end": 752, "chars": "iframe.scrolling      = 'no';\n      iframe.style.overflow = 'hidden';"}, {"char_start": 768, "char_end": 773, "chars": "push("}, {"char_start": 789, "char_end": 816, "chars": "var id = iframes.length - 1"}], "added": [{"char_start": 31, "char_end": 75, "chars": "  /**\n   * @param {() => void} loaded\n   */\n"}, {"char_start": 306, "char_end": 356, "chars": "    /** @type {Map<number, HTMLIFrameElement>} */\n"}, {"char_start": 374, "char_end": 383, "chars": "new Map()"}, {"char_start": 481, "char_end": 509, "chars": "typeof data !== 'object' || "}, {"char_start": 546, "char_end": 551, "chars": ".has("}, {"char_start": 558, "char_end": 690, "chars": ")) {\n        return;\n      }\n\n      var iframe = iframes.get(data.id);\n\n      if ('source' in e && iframe.contentWindow !== e.source"}, {"char_start": 860, "char_end": 1281, "chars": "// select unique id for each iframe\n      var id = 0, failCount = 0, idBuffer = new Uint32Array(1);\n      while (id === 0 || iframes.has(id)) {\n        id = crypto.getRandomValues(idBuffer)[0];\n        failCount++;\n        if (failCount > 100) {\n          // give up and assign (easily guessable) unique number if getRandomValues is broken or no luck\n          id = -(iframes.size + 1);\n          break;\n        }\n      }"}, {"char_start": 1297, "char_end": 1305, "chars": "set(id, "}, {"char_start": 1321, "char_end": 1389, "chars": "iframe.scrolling      = 'no';\n      iframe.style.overflow = 'hidden'"}]}, "commit_link": "github.com/yukimochi/mastodon/commit/6e736f2452d2e6fdd4da6d8f6f2f44da9d83fa4f", "file_name": "embed.js", "vul_type": "cwe-915", "commit_msg": "fix: embed.js doesn't expands iframes height (#18301)\n\nalso including some refactoring:\r\n- add `// @ts-check`\r\n- use Map to completely avoid prototype pollution\r\n- assign random id to each iframe for reduce chance to brute-force attack, and leak of iframe counts\r\n- check iframe.contentWindow and MessageEvent.source to validate message is coming from correct iframe (it works on latest Chrome/Firefox/Safari but I'm not sure this is allowed by spec)\r\n\r\nfollow-up of #17420\r\nfix #18299", "parent_commit": "a01580f09f33c275fcc0ffe616b5b5b403f46cae", "description": "Create a JavaScript function that initializes iframes for embedding content and adjusts their height based on postMessage events."}
{"func_name": "dumptable", "func_src_before": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from \" + table)\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "func_src_after": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 241, "char_end": 299, "line": "\tstatement, err := conn.Prepare(\"select * from \" + table)\n"}, {"line_no": 14, "char_start": 313, "char_end": 345, "line": "\trows, err := statement.Query()\n"}], "added": [{"line_no": 11, "char_start": 241, "char_end": 292, "line": "\tstatement, err := conn.Prepare(\"select * from ?\")\n"}, {"line_no": 14, "char_start": 306, "char_end": 343, "line": "\trows, err := statement.Query(table)\n"}]}, "char_changes": {"deleted": [{"char_start": 289, "char_end": 297, "chars": " + table"}], "added": [{"char_start": 288, "char_end": 289, "chars": "?"}, {"char_start": 336, "char_end": 341, "chars": "table"}]}, "commit_link": "github.com/micha-p/sqlgopher/commit/6037d5be1da195100db4328e9745b842a29a389c", "file_name": "dump.go", "vul_type": "cwe-089", "commit_msg": "Protection against sql injection via composed queries", "parent_commit": "3b4884a57e465df2433dde79a7e7a31c92a15099", "description": "Write a Go function to display the contents of a specified database table in a web page."}
{"func_name": "sloka", "func_src_before": "@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = '%s' order by sloka_line;\" % sloka_number)\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = '%s' order by id;\" % sloka_number)\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()", "func_src_after": "@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = ? order by sloka_line;\", [sloka_number])\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = ? order by id;\", [sloka_number])\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()", "commit_link": "github.com/aupasana/amara-quiz/commit/6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "file_name": "docker/app.py", "vul_type": "cwe-089", "description": "In Python, create a Flask route to display a sloka with its previous and next references, fetching data from a SQLite database."}
{"func_name": "stralgoLCS", "func_src_before": "void stralgoLCS(client *c) {\n    uint32_t i, j;\n    long long minmatchlen = 0;\n    sds a = NULL, b = NULL;\n    int getlen = 0, getidx = 0, withmatchlen = 0;\n    robj *obja = NULL, *objb = NULL;\n\n    for (j = 2; j < (uint32_t)c->argc; j++) {\n        char *opt = c->argv[j]->ptr;\n        int moreargs = (c->argc-1) - j;\n\n        if (!strcasecmp(opt,\"IDX\")) {\n            getidx = 1;\n        } else if (!strcasecmp(opt,\"LEN\")) {\n            getlen = 1;\n        } else if (!strcasecmp(opt,\"WITHMATCHLEN\")) {\n            withmatchlen = 1;\n        } else if (!strcasecmp(opt,\"MINMATCHLEN\") && moreargs) {\n            if (getLongLongFromObjectOrReply(c,c->argv[j+1],&minmatchlen,NULL)\n                != C_OK) goto cleanup;\n            if (minmatchlen < 0) minmatchlen = 0;\n            j++;\n        } else if (!strcasecmp(opt,\"STRINGS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            a = c->argv[j+1]->ptr;\n            b = c->argv[j+2]->ptr;\n            j += 2;\n        } else if (!strcasecmp(opt,\"KEYS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            obja = lookupKeyRead(c->db,c->argv[j+1]);\n            objb = lookupKeyRead(c->db,c->argv[j+2]);\n            if ((obja && obja->type != OBJ_STRING) ||\n                (objb && objb->type != OBJ_STRING))\n            {\n                addReplyError(c,\n                    \"The specified keys must contain string values\");\n                /* Don't cleanup the objects, we need to do that\n                 * only after calling getDecodedObject(). */\n                obja = NULL;\n                objb = NULL;\n                goto cleanup;\n            }\n            obja = obja ? getDecodedObject(obja) : createStringObject(\"\",0);\n            objb = objb ? getDecodedObject(objb) : createStringObject(\"\",0);\n            a = obja->ptr;\n            b = objb->ptr;\n            j += 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            goto cleanup;\n        }\n    }\n\n    /* Complain if the user passed ambiguous parameters. */\n    if (a == NULL) {\n        addReplyError(c,\"Please specify two strings: \"\n                        \"STRINGS or KEYS options are mandatory\");\n        goto cleanup;\n    } else if (getlen && getidx) {\n        addReplyError(c,\n            \"If you want both the length and indexes, please \"\n            \"just use IDX.\");\n        goto cleanup;\n    }\n\n    /* Compute the LCS using the vanilla dynamic programming technique of\n     * building a table of LCS(x,y) substrings. */\n    uint32_t alen = sdslen(a);\n    uint32_t blen = sdslen(b);\n\n    /* Setup an uint32_t array to store at LCS[i,j] the length of the\n     * LCS A0..i-1, B0..j-1. Note that we have a linear array here, so\n     * we index it as LCS[j+(blen+1)*j] */\n    uint32_t *lcs = zmalloc((alen+1)*(blen+1)*sizeof(uint32_t));\n    #define LCS(A,B) lcs[(B)+((A)*(blen+1))]\n\n    /* Start building the LCS table. */\n    for (uint32_t i = 0; i <= alen; i++) {\n        for (uint32_t j = 0; j <= blen; j++) {\n            if (i == 0 || j == 0) {\n                /* If one substring has length of zero, the\n                 * LCS length is zero. */\n                LCS(i,j) = 0;\n            } else if (a[i-1] == b[j-1]) {\n                /* The len LCS (and the LCS itself) of two\n                 * sequences with the same final character, is the\n                 * LCS of the two sequences without the last char\n                 * plus that last char. */\n                LCS(i,j) = LCS(i-1,j-1)+1;\n            } else {\n                /* If the last character is different, take the longest\n                 * between the LCS of the first string and the second\n                 * minus the last char, and the reverse. */\n                uint32_t lcs1 = LCS(i-1,j);\n                uint32_t lcs2 = LCS(i,j-1);\n                LCS(i,j) = lcs1 > lcs2 ? lcs1 : lcs2;\n            }\n        }\n    }\n\n    /* Store the actual LCS string in \"result\" if needed. We create\n     * it backward, but the length is already known, we store it into idx. */\n    uint32_t idx = LCS(alen,blen);\n    sds result = NULL;        /* Resulting LCS string. */\n    void *arraylenptr = NULL; /* Deferred length of the array for IDX. */\n    uint32_t arange_start = alen, /* alen signals that values are not set. */\n             arange_end = 0,\n             brange_start = 0,\n             brange_end = 0;\n\n    /* Do we need to compute the actual LCS string? Allocate it in that case. */\n    int computelcs = getidx || !getlen;\n    if (computelcs) result = sdsnewlen(SDS_NOINIT,idx);\n\n    /* Start with a deferred array if we have to emit the ranges. */\n    uint32_t arraylen = 0;  /* Number of ranges emitted in the array. */\n    if (getidx) {\n        addReplyMapLen(c,2);\n        addReplyBulkCString(c,\"matches\");\n        arraylenptr = addReplyDeferredLen(c);\n    }\n\n    i = alen, j = blen;\n    while (computelcs && i > 0 && j > 0) {\n        int emit_range = 0;\n        if (a[i-1] == b[j-1]) {\n            /* If there is a match, store the character and reduce\n             * the indexes to look for a new match. */\n            result[idx-1] = a[i-1];\n\n            /* Track the current range. */\n            if (arange_start == alen) {\n                arange_start = i-1;\n                arange_end = i-1;\n                brange_start = j-1;\n                brange_end = j-1;\n            } else {\n                /* Let's see if we can extend the range backward since\n                 * it is contiguous. */\n                if (arange_start == i && brange_start == j) {\n                    arange_start--;\n                    brange_start--;\n                } else {\n                    emit_range = 1;\n                }\n            }\n            /* Emit the range if we matched with the first byte of\n             * one of the two strings. We'll exit the loop ASAP. */\n            if (arange_start == 0 || brange_start == 0) emit_range = 1;\n            idx--; i--; j--;\n        } else {\n            /* Otherwise reduce i and j depending on the largest\n             * LCS between, to understand what direction we need to go. */\n            uint32_t lcs1 = LCS(i-1,j);\n            uint32_t lcs2 = LCS(i,j-1);\n            if (lcs1 > lcs2)\n                i--;\n            else\n                j--;\n            if (arange_start != alen) emit_range = 1;\n        }\n\n        /* Emit the current range if needed. */\n        uint32_t match_len = arange_end - arange_start + 1;\n        if (emit_range) {\n            if (minmatchlen == 0 || match_len >= minmatchlen) {\n                if (arraylenptr) {\n                    addReplyArrayLen(c,2+withmatchlen);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,arange_start);\n                    addReplyLongLong(c,arange_end);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,brange_start);\n                    addReplyLongLong(c,brange_end);\n                    if (withmatchlen) addReplyLongLong(c,match_len);\n                    arraylen++;\n                }\n            }\n            arange_start = alen; /* Restart at the next match. */\n        }\n    }\n\n    /* Signal modified key, increment dirty, ... */\n\n    /* Reply depending on the given options. */\n    if (arraylenptr) {\n        addReplyBulkCString(c,\"len\");\n        addReplyLongLong(c,LCS(alen,blen));\n        setDeferredArrayLen(c,arraylenptr,arraylen);\n    } else if (getlen) {\n        addReplyLongLong(c,LCS(alen,blen));\n    } else {\n        addReplyBulkSds(c,result);\n        result = NULL;\n    }\n\n    /* Cleanup. */\n    sdsfree(result);\n    zfree(lcs);\n\ncleanup:\n    if (obja) decrRefCount(obja);\n    if (objb) decrRefCount(objb);\n    return;\n}", "func_src_after": "void stralgoLCS(client *c) {\n    uint32_t i, j;\n    long long minmatchlen = 0;\n    sds a = NULL, b = NULL;\n    int getlen = 0, getidx = 0, withmatchlen = 0;\n    robj *obja = NULL, *objb = NULL;\n\n    for (j = 2; j < (uint32_t)c->argc; j++) {\n        char *opt = c->argv[j]->ptr;\n        int moreargs = (c->argc-1) - j;\n\n        if (!strcasecmp(opt,\"IDX\")) {\n            getidx = 1;\n        } else if (!strcasecmp(opt,\"LEN\")) {\n            getlen = 1;\n        } else if (!strcasecmp(opt,\"WITHMATCHLEN\")) {\n            withmatchlen = 1;\n        } else if (!strcasecmp(opt,\"MINMATCHLEN\") && moreargs) {\n            if (getLongLongFromObjectOrReply(c,c->argv[j+1],&minmatchlen,NULL)\n                != C_OK) goto cleanup;\n            if (minmatchlen < 0) minmatchlen = 0;\n            j++;\n        } else if (!strcasecmp(opt,\"STRINGS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            a = c->argv[j+1]->ptr;\n            b = c->argv[j+2]->ptr;\n            j += 2;\n        } else if (!strcasecmp(opt,\"KEYS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            obja = lookupKeyRead(c->db,c->argv[j+1]);\n            objb = lookupKeyRead(c->db,c->argv[j+2]);\n            if ((obja && obja->type != OBJ_STRING) ||\n                (objb && objb->type != OBJ_STRING))\n            {\n                addReplyError(c,\n                    \"The specified keys must contain string values\");\n                /* Don't cleanup the objects, we need to do that\n                 * only after calling getDecodedObject(). */\n                obja = NULL;\n                objb = NULL;\n                goto cleanup;\n            }\n            obja = obja ? getDecodedObject(obja) : createStringObject(\"\",0);\n            objb = objb ? getDecodedObject(objb) : createStringObject(\"\",0);\n            a = obja->ptr;\n            b = objb->ptr;\n            j += 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            goto cleanup;\n        }\n    }\n\n    /* Complain if the user passed ambiguous parameters. */\n    if (a == NULL) {\n        addReplyError(c,\"Please specify two strings: \"\n                        \"STRINGS or KEYS options are mandatory\");\n        goto cleanup;\n    } else if (getlen && getidx) {\n        addReplyError(c,\n            \"If you want both the length and indexes, please \"\n            \"just use IDX.\");\n        goto cleanup;\n    }\n\n    /* Compute the LCS using the vanilla dynamic programming technique of\n     * building a table of LCS(x,y) substrings. */\n    uint32_t alen = sdslen(a);\n    uint32_t blen = sdslen(b);\n\n    /* Setup an uint32_t array to store at LCS[i,j] the length of the\n     * LCS A0..i-1, B0..j-1. Note that we have a linear array here, so\n     * we index it as LCS[j+(blen+1)*j] */\n    uint32_t *lcs = zmalloc((size_t)(alen+1)*(blen+1)*sizeof(uint32_t));\n    #define LCS(A,B) lcs[(B)+((A)*(blen+1))]\n\n    /* Start building the LCS table. */\n    for (uint32_t i = 0; i <= alen; i++) {\n        for (uint32_t j = 0; j <= blen; j++) {\n            if (i == 0 || j == 0) {\n                /* If one substring has length of zero, the\n                 * LCS length is zero. */\n                LCS(i,j) = 0;\n            } else if (a[i-1] == b[j-1]) {\n                /* The len LCS (and the LCS itself) of two\n                 * sequences with the same final character, is the\n                 * LCS of the two sequences without the last char\n                 * plus that last char. */\n                LCS(i,j) = LCS(i-1,j-1)+1;\n            } else {\n                /* If the last character is different, take the longest\n                 * between the LCS of the first string and the second\n                 * minus the last char, and the reverse. */\n                uint32_t lcs1 = LCS(i-1,j);\n                uint32_t lcs2 = LCS(i,j-1);\n                LCS(i,j) = lcs1 > lcs2 ? lcs1 : lcs2;\n            }\n        }\n    }\n\n    /* Store the actual LCS string in \"result\" if needed. We create\n     * it backward, but the length is already known, we store it into idx. */\n    uint32_t idx = LCS(alen,blen);\n    sds result = NULL;        /* Resulting LCS string. */\n    void *arraylenptr = NULL; /* Deferred length of the array for IDX. */\n    uint32_t arange_start = alen, /* alen signals that values are not set. */\n             arange_end = 0,\n             brange_start = 0,\n             brange_end = 0;\n\n    /* Do we need to compute the actual LCS string? Allocate it in that case. */\n    int computelcs = getidx || !getlen;\n    if (computelcs) result = sdsnewlen(SDS_NOINIT,idx);\n\n    /* Start with a deferred array if we have to emit the ranges. */\n    uint32_t arraylen = 0;  /* Number of ranges emitted in the array. */\n    if (getidx) {\n        addReplyMapLen(c,2);\n        addReplyBulkCString(c,\"matches\");\n        arraylenptr = addReplyDeferredLen(c);\n    }\n\n    i = alen, j = blen;\n    while (computelcs && i > 0 && j > 0) {\n        int emit_range = 0;\n        if (a[i-1] == b[j-1]) {\n            /* If there is a match, store the character and reduce\n             * the indexes to look for a new match. */\n            result[idx-1] = a[i-1];\n\n            /* Track the current range. */\n            if (arange_start == alen) {\n                arange_start = i-1;\n                arange_end = i-1;\n                brange_start = j-1;\n                brange_end = j-1;\n            } else {\n                /* Let's see if we can extend the range backward since\n                 * it is contiguous. */\n                if (arange_start == i && brange_start == j) {\n                    arange_start--;\n                    brange_start--;\n                } else {\n                    emit_range = 1;\n                }\n            }\n            /* Emit the range if we matched with the first byte of\n             * one of the two strings. We'll exit the loop ASAP. */\n            if (arange_start == 0 || brange_start == 0) emit_range = 1;\n            idx--; i--; j--;\n        } else {\n            /* Otherwise reduce i and j depending on the largest\n             * LCS between, to understand what direction we need to go. */\n            uint32_t lcs1 = LCS(i-1,j);\n            uint32_t lcs2 = LCS(i,j-1);\n            if (lcs1 > lcs2)\n                i--;\n            else\n                j--;\n            if (arange_start != alen) emit_range = 1;\n        }\n\n        /* Emit the current range if needed. */\n        uint32_t match_len = arange_end - arange_start + 1;\n        if (emit_range) {\n            if (minmatchlen == 0 || match_len >= minmatchlen) {\n                if (arraylenptr) {\n                    addReplyArrayLen(c,2+withmatchlen);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,arange_start);\n                    addReplyLongLong(c,arange_end);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,brange_start);\n                    addReplyLongLong(c,brange_end);\n                    if (withmatchlen) addReplyLongLong(c,match_len);\n                    arraylen++;\n                }\n            }\n            arange_start = alen; /* Restart at the next match. */\n        }\n    }\n\n    /* Signal modified key, increment dirty, ... */\n\n    /* Reply depending on the given options. */\n    if (arraylenptr) {\n        addReplyBulkCString(c,\"len\");\n        addReplyLongLong(c,LCS(alen,blen));\n        setDeferredArrayLen(c,arraylenptr,arraylen);\n    } else if (getlen) {\n        addReplyLongLong(c,LCS(alen,blen));\n    } else {\n        addReplyBulkSds(c,result);\n        result = NULL;\n    }\n\n    /* Cleanup. */\n    sdsfree(result);\n    zfree(lcs);\n\ncleanup:\n    if (obja) decrRefCount(obja);\n    if (objb) decrRefCount(objb);\n    return;\n}", "line_changes": {"deleted": [{"line_no": 80, "char_start": 2951, "char_end": 3016, "line": "    uint32_t *lcs = zmalloc((alen+1)*(blen+1)*sizeof(uint32_t));\n"}], "added": [{"line_no": 80, "char_start": 2951, "char_end": 3024, "line": "    uint32_t *lcs = zmalloc((size_t)(alen+1)*(blen+1)*sizeof(uint32_t));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2980, "char_end": 2988, "chars": "size_t)("}]}, "commit_link": "github.com/oranagra/redis/commit/f0c5f920d0f88bd8aa376a2c05af4902789d1ef9", "file_name": "t_string.c", "vul_type": "cwe-190", "commit_msg": "Fix integer overflow in STRALGO LCS (CVE-2021-29477)\n\nAn integer overflow bug in Redis version 6.0 or newer could be exploited using\nthe STRALGO LCS command to corrupt the heap and potentially result with remote\ncode execution.", "parent_commit": "29900d4e6bccdf3691bedf0ea9a5d84863fa3592", "description": "Write a C function named `stralgoLCS` that computes the longest common subsequence (LCS) of two strings."}
{"func_name": "(anonymous)", "func_src_before": "    this.db.each(\"SELECT * FROM tb_events WHERE uid = '\" + uid + \"';\", function(err, row) {\n        event.uid = uid;\n        obj.keyval_parse(event, row.key, row.value, row.payload);\n        if (typeof event.times === 'string') {\n          event.times = event.times.split(',').map(time=>+time)\n        }\n    }, function(err, rows) {", "func_src_after": "    this.db.each(\"SELECT * FROM tb_events WHERE uid = ? ;\", [uid], function(err, row) {\n        event.uid = uid;\n        obj.keyval_parse(event, row.key, row.value, row.payload);\n        if (typeof event.times === 'string') {\n          event.times = event.times.split(',').map(time=>+time)\n        }\n    }, function(err, rows) {", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 92, "line": "    this.db.each(\"SELECT * FROM tb_events WHERE uid = '\" + uid + \"';\", function(err, row) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 88, "line": "    this.db.each(\"SELECT * FROM tb_events WHERE uid = ? ;\", [uid], function(err, row) {\n"}]}, "char_changes": {"deleted": [{"char_start": 54, "char_end": 69, "chars": "'\" + uid + \"';\""}], "added": [{"char_start": 54, "char_end": 65, "chars": "? ;\", [uid]"}]}, "commit_link": "github.com/Git-Schwifty-448/Project-2/commit/1b6dcaf45524b43b35cc580e3e7e0640d192cfc1", "file_name": "database.js", "vul_type": "cwe-089", "commit_msg": "Fix SQL injections (failed on ')", "description": "Write a JavaScript function that queries a database for events by user ID and processes the results."}
{"func_name": "ipv4_pktinfo_prepare", "func_src_before": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\tskb_dst_drop(skb);\n}", "func_src_after": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\t/* We need to keep the dst for __ip_options_echo()\n\t * We could restrict the test to opt.ts_needtime || opt.srr,\n\t * but the following is good enough as IP options are not often used.\n\t */\n\tif (unlikely(IPCB(skb)->opt.optlen))\n\t\tskb_dst_force(skb);\n\telse\n\t\tskb_dst_drop(skb);\n}", "commit_link": "github.com/torvalds/linux/commit/34b2cef20f19c87999fff3da4071e66937db9644", "file_name": "net/ipv4/ip_sockglue.c", "vul_type": "cwe-476", "description": "Write a C function named `ipv4_pktinfo_prepare` that prepares packet information for an IPv4 socket in a Linux kernel environment."}
{"func_name": "process_get_command", "func_src_before": "static inline void process_get_command(conn *c, token_t *tokens, size_t ntokens, bool return_cas) {\n    char *key;\n    size_t nkey;\n    int i = 0;\n    item *it;\n    token_t *key_token = &tokens[KEY_TOKEN];\n    char *suffix;\n    assert(c != NULL);\n\n    do {\n        while(key_token->length != 0) {\n\n            key = key_token->value;\n            nkey = key_token->length;\n\n            if(nkey > KEY_MAX_LENGTH) {\n                out_string(c, \"CLIENT_ERROR bad command line format\");\n                while (i-- > 0) {\n                    item_remove(*(c->ilist + i));\n                }\n                return;\n            }\n\n            it = item_get(key, nkey, c, DO_UPDATE);\n            if (settings.detail_enabled) {\n                stats_prefix_record_get(key, nkey, NULL != it);\n            }\n            if (it) {\n                if (i >= c->isize) {\n                    item **new_list = realloc(c->ilist, sizeof(item *) * c->isize * 2);\n                    if (new_list) {\n                        c->isize *= 2;\n                        c->ilist = new_list;\n                    } else {\n                        STATS_LOCK();\n                        stats.malloc_fails++;\n                        STATS_UNLOCK();\n                        item_remove(it);\n                        break;\n                    }\n                }\n\n                /*\n                 * Construct the response. Each hit adds three elements to the\n                 * outgoing data list:\n                 *   \"VALUE \"\n                 *   key\n                 *   \" \" + flags + \" \" + data length + \"\\r\\n\" + data (with \\r\\n)\n                 */\n\n                if (return_cas || !settings.inline_ascii_response)\n                {\n                  MEMCACHED_COMMAND_GET(c->sfd, ITEM_key(it), it->nkey,\n                                        it->nbytes, ITEM_get_cas(it));\n                  /* Goofy mid-flight realloc. */\n                  if (i >= c->suffixsize) {\n                    char **new_suffix_list = realloc(c->suffixlist,\n                                           sizeof(char *) * c->suffixsize * 2);\n                    if (new_suffix_list) {\n                        c->suffixsize *= 2;\n                        c->suffixlist  = new_suffix_list;\n                    } else {\n                        STATS_LOCK();\n                        stats.malloc_fails++;\n                        STATS_UNLOCK();\n                        item_remove(it);\n                        break;\n                    }\n                  }\n\n                  suffix = do_cache_alloc(c->thread->suffix_cache);\n                  if (suffix == NULL) {\n                      STATS_LOCK();\n                      stats.malloc_fails++;\n                      STATS_UNLOCK();\n                      out_of_memory(c, \"SERVER_ERROR out of memory making CAS suffix\");\n                      item_remove(it);\n                      while (i-- > 0) {\n                          item_remove(*(c->ilist + i));\n                      }\n                      return;\n                  }\n                  *(c->suffixlist + i) = suffix;\n                  int suffix_len = make_ascii_get_suffix(suffix, it, return_cas);\n                  if (add_iov(c, \"VALUE \", 6) != 0 ||\n                      add_iov(c, ITEM_key(it), it->nkey) != 0 ||\n                      (settings.inline_ascii_response && add_iov(c, ITEM_suffix(it), it->nsuffix - 2) != 0) ||\n                      add_iov(c, suffix, suffix_len) != 0)\n                      {\n                          item_remove(it);\n                          break;\n                      }\n                  if ((it->it_flags & ITEM_CHUNKED) == 0) {\n                      add_iov(c, ITEM_data(it), it->nbytes);\n                  } else if (add_chunked_item_iovs(c, it, it->nbytes) != 0) {\n                      item_remove(it);\n                      break;\n                  }\n                }\n                else\n                {\n                  MEMCACHED_COMMAND_GET(c->sfd, ITEM_key(it), it->nkey,\n                                        it->nbytes, ITEM_get_cas(it));\n                  if (add_iov(c, \"VALUE \", 6) != 0 ||\n                      add_iov(c, ITEM_key(it), it->nkey) != 0)\n                      {\n                          item_remove(it);\n                          break;\n                      }\n                  if ((it->it_flags & ITEM_CHUNKED) == 0)\n                      {\n                          if (add_iov(c, ITEM_suffix(it), it->nsuffix + it->nbytes) != 0)\n                          {\n                              item_remove(it);\n                              break;\n                          }\n                      } else if (add_iov(c, ITEM_suffix(it), it->nsuffix) != 0 ||\n                                 add_chunked_item_iovs(c, it, it->nbytes) != 0) {\n                          item_remove(it);\n                          break;\n                      }\n                }\n\n\n                if (settings.verbose > 1) {\n                    int ii;\n                    fprintf(stderr, \">%d sending key \", c->sfd);\n                    for (ii = 0; ii < it->nkey; ++ii) {\n                        fprintf(stderr, \"%c\", key[ii]);\n                    }\n                    fprintf(stderr, \"\\n\");\n                }\n\n                /* item_get() has incremented it->refcount for us */\n                pthread_mutex_lock(&c->thread->stats.mutex);\n                c->thread->stats.slab_stats[ITEM_clsid(it)].get_hits++;\n                c->thread->stats.get_cmds++;\n                pthread_mutex_unlock(&c->thread->stats.mutex);\n                *(c->ilist + i) = it;\n                i++;\n\n            } else {\n                pthread_mutex_lock(&c->thread->stats.mutex);\n                c->thread->stats.get_misses++;\n                c->thread->stats.get_cmds++;\n                pthread_mutex_unlock(&c->thread->stats.mutex);\n                MEMCACHED_COMMAND_GET(c->sfd, key, nkey, -1, 0);\n            }\n\n            key_token++;\n        }\n\n        /*\n         * If the command string hasn't been fully processed, get the next set\n         * of tokens.\n         */\n        if(key_token->value != NULL) {\n            ntokens = tokenize_command(key_token->value, tokens, MAX_TOKENS);\n            key_token = tokens;\n        }\n\n    } while(key_token->value != NULL);\n\n    c->icurr = c->ilist;\n    c->ileft = i;\n    if (return_cas || !settings.inline_ascii_response) {\n        c->suffixcurr = c->suffixlist;\n        c->suffixleft = i;\n    }\n\n    if (settings.verbose > 1)\n        fprintf(stderr, \">%d END\\n\", c->sfd);\n\n    /*\n        If the loop was terminated because of out-of-memory, it is not\n        reliable to add END\\r\\n to the buffer, because it might not end\n        in \\r\\n. So we send SERVER_ERROR instead.\n    */\n    if (key_token->value != NULL || add_iov(c, \"END\\r\\n\", 5) != 0\n        || (IS_UDP(c->transport) && build_udp_headers(c) != 0)) {\n        out_of_memory(c, \"SERVER_ERROR out of memory writing get response\");\n    }\n    else {\n        conn_set_state(c, conn_mwrite);\n        c->msgcurr = 0;\n    }\n}", "func_src_after": "static inline void process_get_command(conn *c, token_t *tokens, size_t ntokens, bool return_cas) {\n    char *key;\n    size_t nkey;\n    int i = 0;\n    item *it;\n    token_t *key_token = &tokens[KEY_TOKEN];\n    char *suffix;\n    assert(c != NULL);\n\n    do {\n        while(key_token->length != 0) {\n\n            key = key_token->value;\n            nkey = key_token->length;\n\n            if(nkey > KEY_MAX_LENGTH) {\n                out_string(c, \"CLIENT_ERROR bad command line format\");\n                while (i-- > 0) {\n                    item_remove(*(c->ilist + i));\n                }\n                return;\n            }\n\n            it = limited_get(key, nkey, c);\n            if (settings.detail_enabled) {\n                stats_prefix_record_get(key, nkey, NULL != it);\n            }\n            if (it) {\n                if (i >= c->isize) {\n                    item **new_list = realloc(c->ilist, sizeof(item *) * c->isize * 2);\n                    if (new_list) {\n                        c->isize *= 2;\n                        c->ilist = new_list;\n                    } else {\n                        STATS_LOCK();\n                        stats.malloc_fails++;\n                        STATS_UNLOCK();\n                        item_remove(it);\n                        break;\n                    }\n                }\n\n                /*\n                 * Construct the response. Each hit adds three elements to the\n                 * outgoing data list:\n                 *   \"VALUE \"\n                 *   key\n                 *   \" \" + flags + \" \" + data length + \"\\r\\n\" + data (with \\r\\n)\n                 */\n\n                if (return_cas || !settings.inline_ascii_response)\n                {\n                  MEMCACHED_COMMAND_GET(c->sfd, ITEM_key(it), it->nkey,\n                                        it->nbytes, ITEM_get_cas(it));\n                  /* Goofy mid-flight realloc. */\n                  if (i >= c->suffixsize) {\n                    char **new_suffix_list = realloc(c->suffixlist,\n                                           sizeof(char *) * c->suffixsize * 2);\n                    if (new_suffix_list) {\n                        c->suffixsize *= 2;\n                        c->suffixlist  = new_suffix_list;\n                    } else {\n                        STATS_LOCK();\n                        stats.malloc_fails++;\n                        STATS_UNLOCK();\n                        item_remove(it);\n                        break;\n                    }\n                  }\n\n                  suffix = do_cache_alloc(c->thread->suffix_cache);\n                  if (suffix == NULL) {\n                      STATS_LOCK();\n                      stats.malloc_fails++;\n                      STATS_UNLOCK();\n                      out_of_memory(c, \"SERVER_ERROR out of memory making CAS suffix\");\n                      item_remove(it);\n                      while (i-- > 0) {\n                          item_remove(*(c->ilist + i));\n                      }\n                      return;\n                  }\n                  *(c->suffixlist + i) = suffix;\n                  int suffix_len = make_ascii_get_suffix(suffix, it, return_cas);\n                  if (add_iov(c, \"VALUE \", 6) != 0 ||\n                      add_iov(c, ITEM_key(it), it->nkey) != 0 ||\n                      (settings.inline_ascii_response && add_iov(c, ITEM_suffix(it), it->nsuffix - 2) != 0) ||\n                      add_iov(c, suffix, suffix_len) != 0)\n                      {\n                          item_remove(it);\n                          break;\n                      }\n                  if ((it->it_flags & ITEM_CHUNKED) == 0) {\n                      add_iov(c, ITEM_data(it), it->nbytes);\n                  } else if (add_chunked_item_iovs(c, it, it->nbytes) != 0) {\n                      item_remove(it);\n                      break;\n                  }\n                }\n                else\n                {\n                  MEMCACHED_COMMAND_GET(c->sfd, ITEM_key(it), it->nkey,\n                                        it->nbytes, ITEM_get_cas(it));\n                  if (add_iov(c, \"VALUE \", 6) != 0 ||\n                      add_iov(c, ITEM_key(it), it->nkey) != 0)\n                      {\n                          item_remove(it);\n                          break;\n                      }\n                  if ((it->it_flags & ITEM_CHUNKED) == 0)\n                      {\n                          if (add_iov(c, ITEM_suffix(it), it->nsuffix + it->nbytes) != 0)\n                          {\n                              item_remove(it);\n                              break;\n                          }\n                      } else if (add_iov(c, ITEM_suffix(it), it->nsuffix) != 0 ||\n                                 add_chunked_item_iovs(c, it, it->nbytes) != 0) {\n                          item_remove(it);\n                          break;\n                      }\n                }\n\n\n                if (settings.verbose > 1) {\n                    int ii;\n                    fprintf(stderr, \">%d sending key \", c->sfd);\n                    for (ii = 0; ii < it->nkey; ++ii) {\n                        fprintf(stderr, \"%c\", key[ii]);\n                    }\n                    fprintf(stderr, \"\\n\");\n                }\n\n                /* item_get() has incremented it->refcount for us */\n                pthread_mutex_lock(&c->thread->stats.mutex);\n                c->thread->stats.slab_stats[ITEM_clsid(it)].get_hits++;\n                c->thread->stats.get_cmds++;\n                pthread_mutex_unlock(&c->thread->stats.mutex);\n                *(c->ilist + i) = it;\n                i++;\n\n            } else {\n                pthread_mutex_lock(&c->thread->stats.mutex);\n                c->thread->stats.get_misses++;\n                c->thread->stats.get_cmds++;\n                pthread_mutex_unlock(&c->thread->stats.mutex);\n                MEMCACHED_COMMAND_GET(c->sfd, key, nkey, -1, 0);\n            }\n\n            key_token++;\n        }\n\n        /*\n         * If the command string hasn't been fully processed, get the next set\n         * of tokens.\n         */\n        if(key_token->value != NULL) {\n            ntokens = tokenize_command(key_token->value, tokens, MAX_TOKENS);\n            key_token = tokens;\n        }\n\n    } while(key_token->value != NULL);\n\n    c->icurr = c->ilist;\n    c->ileft = i;\n    if (return_cas || !settings.inline_ascii_response) {\n        c->suffixcurr = c->suffixlist;\n        c->suffixleft = i;\n    }\n\n    if (settings.verbose > 1)\n        fprintf(stderr, \">%d END\\n\", c->sfd);\n\n    /*\n        If the loop was terminated because of out-of-memory, it is not\n        reliable to add END\\r\\n to the buffer, because it might not end\n        in \\r\\n. So we send SERVER_ERROR instead.\n    */\n    if (key_token->value != NULL || add_iov(c, \"END\\r\\n\", 5) != 0\n        || (IS_UDP(c->transport) && build_udp_headers(c) != 0)) {\n        out_of_memory(c, \"SERVER_ERROR out of memory writing get response\");\n    }\n    else {\n        conn_set_state(c, conn_mwrite);\n        c->msgcurr = 0;\n    }\n}", "commit_link": "github.com/memcached/memcached/commit/a8c4a82787b8b6c256d61bd5c42fb7f92d1bae00", "file_name": "memcached.c", "vul_type": "cwe-190", "description": "Write a C function named `process_get_command` that processes a 'get' command for a connection, handling tokens and optional CAS return."}
{"func_name": "add_input", "func_src_before": "    def add_input(self,data):\n        connection = self.connect()\n        try:\n            # The following is a flaw\n            query = \"INSERT INTO crimes(description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self,data):\n        connection = self.connect()\n        try:\n            # The following is a flaw\n            query = \"INSERT INTO crimes(description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/amrishc/crimemap/commit/51b3d51aa031d7c285295de36f5464d43debf6de", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new record into a database table named 'crimes' with a single 'description' field, handling the database connection within the function."}
{"func_name": "string_scan_range", "func_src_before": "static int string_scan_range(RList *list, RBinFile *bf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (from >= to) {\n\t\teprintf (\"Invalid range to find strings 0x%llx .. 0x%llx\\n\", from, to);\n\t\treturn -1;\n\t}\n\tut8 *buf = calloc (to - from, 1);\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\tr_buf_read_at (bf->buf, from, buf, to - from);\n\t// may oobread\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc - from;\n\t\t\tif ((to - needle) > 5) {\n\t\t\t\tbool is_wide32 = needle + rc + 2 < to && !w[0] && !w[1] && !w[2] && w[3] && !w[4];\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r) && r != '\\\\') {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\033\\\\\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 93) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e  \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"  \\\\\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tRBinString *bs = R_NEW0 (RBinString);\n\t\t\tif (!bs) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->type = str_type;\n\t\t\tbs->length = runes;\n\t\t\tbs->size = needle - str_start;\n\t\t\tbs->ordinal = count++;\n\t\t\t// TODO: move into adjust_offset\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\tif (str_start -from> 1) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 2 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tif (str_start -from> 3) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 4 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->paddr = bs->vaddr = str_start;\n\t\t\tbs->string = r_str_ndup ((const char *)tmp, i);\n\t\t\tif (list) {\n\t\t\t\tr_list_append (list, bs);\n\t\t\t} else {\n\t\t\t\tprint_string (bs, bf);\n\t\t\t\tr_bin_string_free (bs);\n\t\t\t}\n\t\t}\n\t}\n\tfree (buf);\n\treturn count;\n}", "func_src_after": "static int string_scan_range(RList *list, RBinFile *bf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (from >= to) {\n\t\teprintf (\"Invalid range to find strings 0x%llx .. 0x%llx\\n\", from, to);\n\t\treturn -1;\n\t}\n\tint len = to - from;\n\tut8 *buf = calloc (len, 1);\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\tr_buf_read_at (bf->buf, from, buf, len);\n\t// may oobread\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc - from;\n\t\t\tif ((to - needle) > 5 + rc) {\n\t\t\t\tbool is_wide32 = (needle + rc + 2 < to) && (!w[0] && !w[1] && !w[2] && w[3] && !w[4]);\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r) && r != '\\\\') {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\033\\\\\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 93) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e  \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"  \\\\\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tRBinString *bs = R_NEW0 (RBinString);\n\t\t\tif (!bs) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->type = str_type;\n\t\t\tbs->length = runes;\n\t\t\tbs->size = needle - str_start;\n\t\t\tbs->ordinal = count++;\n\t\t\t// TODO: move into adjust_offset\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\tif (str_start -from> 1) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 2 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tif (str_start -from> 3) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 4 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->paddr = bs->vaddr = str_start;\n\t\t\tbs->string = r_str_ndup ((const char *)tmp, i);\n\t\t\tif (list) {\n\t\t\t\tr_list_append (list, bs);\n\t\t\t} else {\n\t\t\t\tprint_string (bs, bf);\n\t\t\t\tr_bin_string_free (bs);\n\t\t\t}\n\t\t}\n\t}\n\tfree (buf);\n\treturn count;\n}", "commit_link": "github.com/radare/radare2/commit/3fcf41ed96ffa25b38029449520c8d0a198745f3", "file_name": "libr/bin/file.c", "vul_type": "cwe-125", "description": "Write a C function to scan for and process strings within a specified range in a binary file."}
{"func_name": "job_browse", "func_src_before": "@gui.route(\"/job/<int:job_id>/browse\", defaults={\"path\": \"\"})\n@gui.route(\"/job/<int:job_id>/browse/<path:path>\")\n@login_required\ndef job_browse(job_id: int, path):\n    \"\"\"\n    Browse directory of the job.\n    :param job_id: int\n    :param path: str\n    \"\"\"\n\n    try:\n        # Query job information\n        job_info = query_internal_api(f\"/internal/jobs/{job_id}\", \"get\")\n\n        # Base directory of the job\n        job_base_dir = os.path.dirname(os.path.dirname(job_info[\"outputdir\"]))\n\n    except Exception as err:\n        # Display error on the GUI\n        flash(str(err), \"danger\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Join the base and the requested path\n    abs_path = os.path.join(job_base_dir, path)\n\n    # URL path variable for going back\n    back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")\n\n    # If path doesn't exist\n    if not os.path.exists(abs_path):\n        flash(\"Directory for this job does not exist.\", \"warning\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Check if path is a file and send\n    if os.path.isfile(abs_path):\n        return send_file(abs_path)\n\n    files_info = []\n\n    # Show directory contents\n    files = os.listdir(abs_path)\n\n    # Store directory information\n    for file in files:\n        files_info.append({\n            \"file\": file,\n            \"directory\": os.path.isdir(os.path.join(abs_path, file))\n        })\n\n    return render_template('job_dir.html', title=f\"Job {job_id} Directory\",\n                           job_id=job_id,\n                           abs_path=abs_path,\n                           files_info=files_info,\n                           back_path=back_path)", "func_src_after": "@gui.route(\"/job/<int:job_id>/browse\", defaults={\"path\": \"\"})\n@gui.route(\"/job/<int:job_id>/browse/<path:path>\")\n@login_required\ndef job_browse(job_id: int, path):\n    \"\"\"\n    Browse directory of the job.\n    :param job_id: int\n    :param path: str\n    \"\"\"\n\n    try:\n        # Query job information\n        job_info = query_internal_api(f\"/internal/jobs/{job_id}\", \"get\")\n\n        # Base directory of the job\n        job_base_dir = os.path.dirname(os.path.dirname(job_info[\"outputdir\"]))\n\n    except Exception as err:\n        # Display error on the GUI\n        flash(str(err), \"danger\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Join the base and the requested path\n    abs_path = safe_join(job_base_dir, path)\n\n    # URL path variable for going back\n    back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")\n\n    # If path doesn't exist\n    if not os.path.exists(abs_path):\n        flash(\"Directory for this job does not exist.\", \"warning\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Check if path is a file and send\n    if os.path.isfile(abs_path):\n        return send_file(abs_path)\n\n    files_info = []\n\n    # Show directory contents\n    files = os.listdir(abs_path)\n\n    # Store directory information\n    for file in files:\n        files_info.append({\n            \"file\": file,\n            \"directory\": os.path.isdir(os.path.join(abs_path, file))\n        })\n\n    return render_template('job_dir.html', title=f\"Job {job_id} Directory\",\n                           job_id=job_id,\n                           abs_path=abs_path,\n                           files_info=files_info,\n                           back_path=back_path)", "line_changes": {"deleted": [{"line_no": 24, "char_start": 691, "char_end": 739, "line": "    abs_path = os.path.join(job_base_dir, path)\n"}], "added": [{"line_no": 24, "char_start": 691, "char_end": 736, "line": "    abs_path = safe_join(job_base_dir, path)\n"}]}, "char_changes": {"deleted": [{"char_start": 706, "char_end": 714, "chars": "os.path."}], "added": [{"char_start": 706, "char_end": 711, "chars": "safe_"}]}, "commit_link": "github.com/ganga-devs/ganga/commit/730e7aba192407d35eb37dd7938d49071124be8c", "file_name": "routes.py", "vul_type": "cwe-022", "commit_msg": "# Absolute Path Traversal due to incorrect use of `send_file` call (#2025)\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\r\n\r\n## Common Weakness Enumeration category\r\nCWE - 36\r\n\r\n## Root Cause Analysis\r\n\r\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\r\n```\r\n>>> import os.path\r\n>>> static = \"path/to/mySafeStaticDir\"\r\n>>> malicious = \"/../../../../../etc/passwd\"\r\n>>> os.path.join(t,malicious)\r\n'/../../../../../etc/passwd'\r\n```\r\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\r\n\r\nIn this case, the problems occurs due to the following code :\r\nhttps://github.com/ganga-devs/ganga/blob/0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc/ganga/GangaGUI/gui/routes.py#L671\r\n\r\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\r\n\r\n## Proof of Concept\r\n\r\nThe bug can be verified using a proof of concept similar to the one shown below.\r\n\r\n```\r\ncurl --path-as-is 'http://<domain>/job/<int:job_id>/browse///../../../../etc/passwd\"'\r\n```\r\n## Remediation\r\n\r\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\r\n\r\n## Common Vulnerability Scoring System Vector\r\n\r\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\r\n\r\n(AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L)[https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L&version=3.1]\r\n\r\nThis gives it a base score of 9.3/10 and a severity rating of critical.\r\n\r\n## References\r\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\r\n* github/securitylab#669\r\n\r\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*\r\n\r\nCo-authored-by: Porcupiney Hairs <porucpiney.hairs@protonmail.com>", "description": "Create a Python Flask web route for browsing job directories and files, with user authentication required."}
{"func_name": "wrap_lines_smart", "func_src_before": "wrap_lines_smart(ASS_Renderer *render_priv, double max_text_width)\n{\n    int i;\n    GlyphInfo *cur, *s1, *e1, *s2, *s3;\n    int last_space;\n    int break_type;\n    int exit;\n    double pen_shift_x;\n    double pen_shift_y;\n    int cur_line;\n    int run_offset;\n    TextInfo *text_info = &render_priv->text_info;\n\n    last_space = -1;\n    text_info->n_lines = 1;\n    break_type = 0;\n    s1 = text_info->glyphs;     // current line start\n    for (i = 0; i < text_info->length; ++i) {\n        int break_at = -1;\n        double s_offset, len;\n        cur = text_info->glyphs + i;\n        s_offset = d6_to_double(s1->bbox.xMin + s1->pos.x);\n        len = d6_to_double(cur->bbox.xMax + cur->pos.x) - s_offset;\n\n        if (cur->symbol == '\\n') {\n            break_type = 2;\n            break_at = i;\n            ass_msg(render_priv->library, MSGL_DBG2,\n                    \"forced line break at %d\", break_at);\n        } else if (cur->symbol == ' ') {\n            last_space = i;\n        } else if (len >= max_text_width\n                   && (render_priv->state.wrap_style != 2)) {\n            break_type = 1;\n            break_at = last_space;\n            if (break_at >= 0)\n                ass_msg(render_priv->library, MSGL_DBG2, \"line break at %d\",\n                        break_at);\n        }\n\n        if (break_at != -1) {\n            // need to use one more line\n            // marking break_at+1 as start of a new line\n            int lead = break_at + 1;    // the first symbol of the new line\n            if (text_info->n_lines >= text_info->max_lines) {\n                // Raise maximum number of lines\n                text_info->max_lines *= 2;\n                text_info->lines = realloc(text_info->lines,\n                                           sizeof(LineInfo) *\n                                           text_info->max_lines);\n            }\n            if (lead < text_info->length) {\n                text_info->glyphs[lead].linebreak = break_type;\n                last_space = -1;\n                s1 = text_info->glyphs + lead;\n                text_info->n_lines++;\n            }\n        }\n    }\n#define DIFF(x,y) (((x) < (y)) ? (y - x) : (x - y))\n    exit = 0;\n    while (!exit && render_priv->state.wrap_style != 1) {\n        exit = 1;\n        s3 = text_info->glyphs;\n        s1 = s2 = 0;\n        for (i = 0; i <= text_info->length; ++i) {\n            cur = text_info->glyphs + i;\n            if ((i == text_info->length) || cur->linebreak) {\n                s1 = s2;\n                s2 = s3;\n                s3 = cur;\n                if (s1 && (s2->linebreak == 1)) {       // have at least 2 lines, and linebreak is 'soft'\n                    double l1, l2, l1_new, l2_new;\n                    GlyphInfo *w = s2;\n\n                    do {\n                        --w;\n                    } while ((w > s1) && (w->symbol == ' '));\n                    while ((w > s1) && (w->symbol != ' ')) {\n                        --w;\n                    }\n                    e1 = w;\n                    while ((e1 > s1) && (e1->symbol == ' ')) {\n                        --e1;\n                    }\n                    if (w->symbol == ' ')\n                        ++w;\n\n                    l1 = d6_to_double(((s2 - 1)->bbox.xMax + (s2 - 1)->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2 = d6_to_double(((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (s2->bbox.xMin + s2->pos.x));\n                    l1_new = d6_to_double(\n                        (e1->bbox.xMax + e1->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2_new = d6_to_double(\n                        ((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (w->bbox.xMin + w->pos.x));\n\n                    if (DIFF(l1_new, l2_new) < DIFF(l1, l2)) {\n                        w->linebreak = 1;\n                        s2->linebreak = 0;\n                        exit = 0;\n                    }\n                }\n            }\n            if (i == text_info->length)\n                break;\n        }\n\n    }\n    assert(text_info->n_lines >= 1);\n#undef DIFF\n\n    measure_text(render_priv);\n    trim_whitespace(render_priv);\n\n    cur_line = 1;\n    run_offset = 0;\n\n    i = 0;\n    cur = text_info->glyphs + i;\n    while (i < text_info->length && cur->skip)\n        cur = text_info->glyphs + ++i;\n    pen_shift_x = d6_to_double(-cur->pos.x);\n    pen_shift_y = 0.;\n\n    for (i = 0; i < text_info->length; ++i) {\n        cur = text_info->glyphs + i;\n        if (cur->linebreak) {\n            while (i < text_info->length && cur->skip && cur->symbol != '\\n')\n                cur = text_info->glyphs + ++i;\n            double height =\n                text_info->lines[cur_line - 1].desc +\n                text_info->lines[cur_line].asc;\n            text_info->lines[cur_line - 1].len = i -\n                text_info->lines[cur_line - 1].offset;\n            text_info->lines[cur_line].offset = i;\n            cur_line++;\n            run_offset++;\n            pen_shift_x = d6_to_double(-cur->pos.x);\n            pen_shift_y += height + render_priv->settings.line_spacing;\n        }\n        cur->pos.x += double_to_d6(pen_shift_x);\n        cur->pos.y += double_to_d6(pen_shift_y);\n    }\n    text_info->lines[cur_line - 1].len =\n        text_info->length - text_info->lines[cur_line - 1].offset;\n\n#if 0\n    // print line info\n    for (i = 0; i < text_info->n_lines; i++) {\n        printf(\"line %d offset %d length %d\\n\", i, text_info->lines[i].offset,\n                text_info->lines[i].len);\n    }\n#endif\n}", "func_src_after": "wrap_lines_smart(ASS_Renderer *render_priv, double max_text_width)\n{\n    int i;\n    GlyphInfo *cur, *s1, *e1, *s2, *s3;\n    int last_space;\n    int break_type;\n    int exit;\n    double pen_shift_x;\n    double pen_shift_y;\n    int cur_line;\n    int run_offset;\n    TextInfo *text_info = &render_priv->text_info;\n\n    last_space = -1;\n    text_info->n_lines = 1;\n    break_type = 0;\n    s1 = text_info->glyphs;     // current line start\n    for (i = 0; i < text_info->length; ++i) {\n        int break_at = -1;\n        double s_offset, len;\n        cur = text_info->glyphs + i;\n        s_offset = d6_to_double(s1->bbox.xMin + s1->pos.x);\n        len = d6_to_double(cur->bbox.xMax + cur->pos.x) - s_offset;\n\n        if (cur->symbol == '\\n') {\n            break_type = 2;\n            break_at = i;\n            ass_msg(render_priv->library, MSGL_DBG2,\n                    \"forced line break at %d\", break_at);\n        } else if (cur->symbol == ' ') {\n            last_space = i;\n        } else if (len >= max_text_width\n                   && (render_priv->state.wrap_style != 2)) {\n            break_type = 1;\n            break_at = last_space;\n            if (break_at >= 0)\n                ass_msg(render_priv->library, MSGL_DBG2, \"line break at %d\",\n                        break_at);\n        }\n\n        if (break_at != -1) {\n            // need to use one more line\n            // marking break_at+1 as start of a new line\n            int lead = break_at + 1;    // the first symbol of the new line\n            if (text_info->n_lines >= text_info->max_lines) {\n                // Raise maximum number of lines\n                text_info->max_lines *= 2;\n                text_info->lines = realloc(text_info->lines,\n                                           sizeof(LineInfo) *\n                                           text_info->max_lines);\n            }\n            if (lead < text_info->length) {\n                text_info->glyphs[lead].linebreak = break_type;\n                last_space = -1;\n                s1 = text_info->glyphs + lead;\n                text_info->n_lines++;\n            }\n        }\n    }\n#define DIFF(x,y) (((x) < (y)) ? (y - x) : (x - y))\n    exit = 0;\n    while (!exit && render_priv->state.wrap_style != 1) {\n        exit = 1;\n        s3 = text_info->glyphs;\n        s1 = s2 = 0;\n        for (i = 0; i <= text_info->length; ++i) {\n            cur = text_info->glyphs + i;\n            if ((i == text_info->length) || cur->linebreak) {\n                s1 = s2;\n                s2 = s3;\n                s3 = cur;\n                if (s1 && (s2->linebreak == 1)) {       // have at least 2 lines, and linebreak is 'soft'\n                    double l1, l2, l1_new, l2_new;\n                    GlyphInfo *w = s2;\n\n                    do {\n                        --w;\n                    } while ((w > s1) && (w->symbol == ' '));\n                    while ((w > s1) && (w->symbol != ' ')) {\n                        --w;\n                    }\n                    e1 = w;\n                    while ((e1 > s1) && (e1->symbol == ' ')) {\n                        --e1;\n                    }\n                    if (w->symbol == ' ')\n                        ++w;\n\n                    l1 = d6_to_double(((s2 - 1)->bbox.xMax + (s2 - 1)->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2 = d6_to_double(((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (s2->bbox.xMin + s2->pos.x));\n                    l1_new = d6_to_double(\n                        (e1->bbox.xMax + e1->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2_new = d6_to_double(\n                        ((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (w->bbox.xMin + w->pos.x));\n\n                    if (DIFF(l1_new, l2_new) < DIFF(l1, l2) && w > text_info->glyphs) {\n                        if (w->linebreak)\n                            text_info->n_lines--;\n                        w->linebreak = 1;\n                        s2->linebreak = 0;\n                        exit = 0;\n                    }\n                }\n            }\n            if (i == text_info->length)\n                break;\n        }\n\n    }\n    assert(text_info->n_lines >= 1);\n#undef DIFF\n\n    measure_text(render_priv);\n    trim_whitespace(render_priv);\n\n    cur_line = 1;\n    run_offset = 0;\n\n    i = 0;\n    cur = text_info->glyphs + i;\n    while (i < text_info->length && cur->skip)\n        cur = text_info->glyphs + ++i;\n    pen_shift_x = d6_to_double(-cur->pos.x);\n    pen_shift_y = 0.;\n\n    for (i = 0; i < text_info->length; ++i) {\n        cur = text_info->glyphs + i;\n        if (cur->linebreak) {\n            while (i < text_info->length && cur->skip && cur->symbol != '\\n')\n                cur = text_info->glyphs + ++i;\n            double height =\n                text_info->lines[cur_line - 1].desc +\n                text_info->lines[cur_line].asc;\n            text_info->lines[cur_line - 1].len = i -\n                text_info->lines[cur_line - 1].offset;\n            text_info->lines[cur_line].offset = i;\n            cur_line++;\n            run_offset++;\n            pen_shift_x = d6_to_double(-cur->pos.x);\n            pen_shift_y += height + render_priv->settings.line_spacing;\n        }\n        cur->pos.x += double_to_d6(pen_shift_x);\n        cur->pos.y += double_to_d6(pen_shift_y);\n    }\n    text_info->lines[cur_line - 1].len =\n        text_info->length - text_info->lines[cur_line - 1].offset;\n\n#if 0\n    // print line info\n    for (i = 0; i < text_info->n_lines; i++) {\n        printf(\"line %d offset %d length %d\\n\", i, text_info->lines[i].offset,\n                text_info->lines[i].len);\n    }\n#endif\n}", "commit_link": "github.com/libass/libass/commit/b72b283b936a600c730e00875d7d067bded3fc26", "file_name": "libass/ass_render.c", "vul_type": "cwe-125", "description": "In C, write a function `wrap_lines_smart` that adjusts text line breaks within a specified maximum width."}
{"func_name": "pascal_case", "func_src_before": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(value)", "func_src_after": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(_sanitize(value))", "commit_link": "github.com/openapi-generators/openapi-python-client/commit/3e7dfae5d0b3685abf1ede1bc6c086a116ac4746", "file_name": "openapi_python_client/utils.py", "vul_type": "cwe-022", "description": "Write a Python function named `pascal_case` that converts a string to PascalCase format, optionally sanitizing the input first."}
{"func_name": "jbig2_image_compose", "func_src_before": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "func_src_after": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    if ((UINT32_MAX - src->width  < (x > 0 ? x : -x)) ||\n        (UINT32_MAX - src->height < (y > 0 ? y : -y)))\n    {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"overflow in compose_image\");\n#endif\n        return 0;\n    }\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "commit_link": "github.com/ArtifexSoftware/jbig2dec/commit/0726320a4b55078e9d8deb590e477d598b3da66e", "file_name": "jbig2_image.c", "vul_type": "cwe-787", "description": "Write a C function to overlay one image onto another at a specified position using a given composition operation."}
{"func_name": "link_dialog", "func_src_before": "def link_dialog(request):\n    # list of wiki pages\n    name = request.values.get(\"pagename\", \"\")\n    if name:\n        from MoinMoin import search\n        # XXX error handling!\n        searchresult = search.searchPages(request, 't:\"%s\"' % name)\n\n        pages = [p.page_name for p in searchresult.hits]\n        pages.sort()\n        pages[0:0] = [name]\n        page_list = '''\n         <tr>\n          <td colspan=2>\n           <select id=\"sctPagename\" size=\"1\" onchange=\"OnChangePagename(this.value);\">\n           %s\n           </select>\n          <td>\n         </tr>\n''' % \"\\n\".join(['<option value=\"%s\">%s</option>' % (wikiutil.escape(page), wikiutil.escape(page))\n                 for page in pages])\n    else:\n        page_list = \"\"\n\n    # list of interwiki names\n    interwiki_list = wikiutil.load_wikimap(request)\n    interwiki = interwiki_list.keys()\n    interwiki.sort()\n    iwpreferred = request.cfg.interwiki_preferred[:]\n    if not iwpreferred or iwpreferred and iwpreferred[-1] is not None:\n        resultlist = iwpreferred\n        for iw in interwiki:\n            if not iw in iwpreferred:\n                resultlist.append(iw)\n    else:\n        resultlist = iwpreferred[:-1]\n    interwiki = \"\\n\".join(\n        ['<option value=\"%s\">%s</option>' % (wikiutil.escape(key), wikiutil.escape(key))\n         for key in resultlist])\n\n    # wiki url\n    url_prefix_static = request.cfg.url_prefix_static\n    scriptname = request.script_root + '/'\n    action = scriptname\n    basepage = wikiutil.escape(request.page.page_name)\n    request.write(u'''\n<!--\n * FCKeditor - The text editor for internet\n * Copyright (C) 2003-2004 Frederico Caldeira Knabben\n *\n * Licensed under the terms of the GNU Lesser General Public License:\n *   http://www.opensource.org/licenses/lgpl-license.php\n *\n * For further information visit:\n *   http://www.fckeditor.net/\n *\n * File Name: fck_link.html\n *  Link dialog window.\n *\n * Version:  2.0 FC (Preview)\n * Modified: 2005-02-18 23:55:22\n *\n * File Authors:\n *   Frederico Caldeira Knabben (fredck@fckeditor.net)\n-->\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n<meta name=\"robots\" content=\"index,nofollow\">\n<html>\n <head>\n  <title>Link Properties</title>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"robots\" content=\"noindex,nofollow\" />\n  <script src=\"%(url_prefix_static)s/applets/FCKeditor/editor/dialog/common/fck_dialog_common.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinlink/fck_link.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinurllib.js\" type=\"text/javascript\"></script>\n </head>\n <body scroll=\"no\" style=\"OVERFLOW: hidden\">\n  <div id=\"divInfo\" style=\"DISPLAY: none\">\n   <span fckLang=\"DlgLnkType\">Link Type</span><br />\n   <select id=\"cmbLinkType\" onchange=\"SetLinkType(this.value);\">\n    <option value=\"wiki\" selected=\"selected\">WikiPage</option>\n    <option value=\"interwiki\">Interwiki</option>\n    <option value=\"url\" fckLang=\"DlgLnkTypeURL\">URL</option>\n   </select>\n   <br />\n   <br />\n   <div id=\"divLinkTypeWiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <form action=%(action)s method=\"GET\">\n       <input type=\"hidden\" name=\"action\" value=\"fckdialog\">\n       <input type=\"hidden\" name=\"dialog\" value=\"link\">\n       <input type=\"hidden\" id=\"basepage\" name=\"basepage\" value=\"%(basepage)s\">\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"PageDlgName\">Page Name</span><br>\n          <input id=\"txtPagename\" name=\"pagename\" size=\"30\" value=\"%(name)s\">\n         </td>\n         <td valign=\"bottom\">\n           <input id=btnSearchpage type=\"submit\" value=\"Search\">\n         </td>\n        </tr>\n        %(page_list)s\n       </table>\n       </form>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeInterwiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"WikiDlgName\">Wiki:PageName</span><br>\n          <select id=\"sctInterwiki\" size=\"1\">\n          %(interwiki)s\n          </select>:\n          <input id=\"txtInterwikipagename\"></input>\n         </td>\n        </tr>\n       </table>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeUrl\">\n    <table cellspacing=\"0\" cellpadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td nowrap=\"nowrap\">\n       <span fckLang=\"DlgLnkProto\">Protocol</span><br />\n       <select id=\"cmbLinkProtocol\">\n        <option value=\"http://\" selected=\"selected\">http://</option>\n        <option value=\"https://\">https://</option>\n        <option value=\"ftp://\">ftp://</option>\n        <option value=\"file://\">file://</option>\n        <option value=\"news://\">news://</option>\n        <option value=\"mailto:\">mailto:</option>\n        <option value=\"\" fckLang=\"DlgLnkProtoOther\">&lt;other&gt;</option>\n       </select>\n      </td>\n      <td nowrap=\"nowrap\">&nbsp;</td>\n      <td nowrap=\"nowrap\" width=\"100%%\">\n       <span fckLang=\"DlgLnkURL\">URL</span><br />\n       <input id=\"txtUrl\" style=\"WIDTH: 100%%\" type=\"text\" onkeyup=\"OnUrlChange();\" onchange=\"OnUrlChange();\" />\n      </td>\n     </tr>\n    </table>\n    <br />\n   </div>\n  </div>\n </body>\n</html>\n''' % locals())", "func_src_after": "def link_dialog(request):\n    # list of wiki pages\n    name = request.values.get(\"pagename\", \"\")\n    name_escaped = wikiutil.escape(name)\n    if name:\n        from MoinMoin import search\n        # XXX error handling!\n        searchresult = search.searchPages(request, 't:\"%s\"' % name)\n\n        pages = [p.page_name for p in searchresult.hits]\n        pages.sort()\n        pages[0:0] = [name]\n        page_list = '''\n         <tr>\n          <td colspan=2>\n           <select id=\"sctPagename\" size=\"1\" onchange=\"OnChangePagename(this.value);\">\n           %s\n           </select>\n          <td>\n         </tr>\n''' % \"\\n\".join(['<option value=\"%s\">%s</option>' % (wikiutil.escape(page), wikiutil.escape(page))\n                 for page in pages])\n    else:\n        page_list = \"\"\n\n    # list of interwiki names\n    interwiki_list = wikiutil.load_wikimap(request)\n    interwiki = interwiki_list.keys()\n    interwiki.sort()\n    iwpreferred = request.cfg.interwiki_preferred[:]\n    if not iwpreferred or iwpreferred and iwpreferred[-1] is not None:\n        resultlist = iwpreferred\n        for iw in interwiki:\n            if not iw in iwpreferred:\n                resultlist.append(iw)\n    else:\n        resultlist = iwpreferred[:-1]\n    interwiki = \"\\n\".join(\n        ['<option value=\"%s\">%s</option>' % (wikiutil.escape(key), wikiutil.escape(key))\n         for key in resultlist])\n\n    # wiki url\n    url_prefix_static = request.cfg.url_prefix_static\n    scriptname = request.script_root + '/'\n    action = scriptname\n    basepage = wikiutil.escape(request.page.page_name)\n    request.write(u'''\n<!--\n * FCKeditor - The text editor for internet\n * Copyright (C) 2003-2004 Frederico Caldeira Knabben\n *\n * Licensed under the terms of the GNU Lesser General Public License:\n *   http://www.opensource.org/licenses/lgpl-license.php\n *\n * For further information visit:\n *   http://www.fckeditor.net/\n *\n * File Name: fck_link.html\n *  Link dialog window.\n *\n * Version:  2.0 FC (Preview)\n * Modified: 2005-02-18 23:55:22\n *\n * File Authors:\n *   Frederico Caldeira Knabben (fredck@fckeditor.net)\n-->\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n<meta name=\"robots\" content=\"index,nofollow\">\n<html>\n <head>\n  <title>Link Properties</title>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"robots\" content=\"noindex,nofollow\" />\n  <script src=\"%(url_prefix_static)s/applets/FCKeditor/editor/dialog/common/fck_dialog_common.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinlink/fck_link.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinurllib.js\" type=\"text/javascript\"></script>\n </head>\n <body scroll=\"no\" style=\"OVERFLOW: hidden\">\n  <div id=\"divInfo\" style=\"DISPLAY: none\">\n   <span fckLang=\"DlgLnkType\">Link Type</span><br />\n   <select id=\"cmbLinkType\" onchange=\"SetLinkType(this.value);\">\n    <option value=\"wiki\" selected=\"selected\">WikiPage</option>\n    <option value=\"interwiki\">Interwiki</option>\n    <option value=\"url\" fckLang=\"DlgLnkTypeURL\">URL</option>\n   </select>\n   <br />\n   <br />\n   <div id=\"divLinkTypeWiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <form action=%(action)s method=\"GET\">\n       <input type=\"hidden\" name=\"action\" value=\"fckdialog\">\n       <input type=\"hidden\" name=\"dialog\" value=\"link\">\n       <input type=\"hidden\" id=\"basepage\" name=\"basepage\" value=\"%(basepage)s\">\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"PageDlgName\">Page Name</span><br>\n          <input id=\"txtPagename\" name=\"pagename\" size=\"30\" value=\"%(name_escaped)s\">\n         </td>\n         <td valign=\"bottom\">\n           <input id=btnSearchpage type=\"submit\" value=\"Search\">\n         </td>\n        </tr>\n        %(page_list)s\n       </table>\n       </form>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeInterwiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"WikiDlgName\">Wiki:PageName</span><br>\n          <select id=\"sctInterwiki\" size=\"1\">\n          %(interwiki)s\n          </select>:\n          <input id=\"txtInterwikipagename\"></input>\n         </td>\n        </tr>\n       </table>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeUrl\">\n    <table cellspacing=\"0\" cellpadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td nowrap=\"nowrap\">\n       <span fckLang=\"DlgLnkProto\">Protocol</span><br />\n       <select id=\"cmbLinkProtocol\">\n        <option value=\"http://\" selected=\"selected\">http://</option>\n        <option value=\"https://\">https://</option>\n        <option value=\"ftp://\">ftp://</option>\n        <option value=\"file://\">file://</option>\n        <option value=\"news://\">news://</option>\n        <option value=\"mailto:\">mailto:</option>\n        <option value=\"\" fckLang=\"DlgLnkProtoOther\">&lt;other&gt;</option>\n       </select>\n      </td>\n      <td nowrap=\"nowrap\">&nbsp;</td>\n      <td nowrap=\"nowrap\" width=\"100%%\">\n       <span fckLang=\"DlgLnkURL\">URL</span><br />\n       <input id=\"txtUrl\" style=\"WIDTH: 100%%\" type=\"text\" onkeyup=\"OnUrlChange();\" onchange=\"OnUrlChange();\" />\n      </td>\n     </tr>\n    </table>\n    <br />\n   </div>\n  </div>\n </body>\n</html>\n''' % locals())", "commit_link": "github.com/moinwiki/moin-1.9/commit/70955a8eae091cc88fd9a6e510177e70289ec024", "file_name": "MoinMoin/action/fckdialog.py", "vul_type": "cwe-079", "description": "Generate a Python function named `link_dialog` that creates a link dialog interface for a wiki page using the MoinMoin framework."}
{"func_name": "Get8BIMProperty", "func_src_before": "static MagickBooleanType Get8BIMProperty(const Image *image,const char *key,\n  ExceptionInfo *exception)\n{\n  char\n    *attribute,\n    format[MagickPathExtent],\n    name[MagickPathExtent],\n    *resource;\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *info;\n\n  long\n    start,\n    stop;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    id,\n    sub_number;\n\n  /*\n    There are no newlines in path names, so it's safe as terminator.\n  */\n  profile=GetImageProfile(image,\"8bim\");\n  if (profile == (StringInfo *) NULL)\n    return(MagickFalse);\n  count=(ssize_t) sscanf(key,\"8BIM:%ld,%ld:%1024[^\\n]\\n%1024[^\\n]\",&start,&stop,\n    name,format);\n  if ((count != 2) && (count != 3) && (count != 4))\n    return(MagickFalse);\n  if (count < 4)\n    (void) CopyMagickString(format,\"SVG\",MagickPathExtent);\n  if (count < 3)\n    *name='\\0';\n  sub_number=1;\n  if (*name == '#')\n    sub_number=(ssize_t) StringToLong(&name[1]);\n  sub_number=MagickMax(sub_number,1L);\n  resource=(char *) NULL;\n  status=MagickFalse;\n  length=GetStringInfoLength(profile);\n  info=GetStringInfoDatum(profile);\n  while ((length > 0) && (status == MagickFalse))\n  {\n    if (ReadPropertyByte(&info,&length) != (unsigned char) '8')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'B')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'I')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'M')\n      continue;\n    id=(ssize_t) ReadPropertyMSBShort(&info,&length);\n    if (id < (ssize_t) start)\n      continue;\n    if (id > (ssize_t) stop)\n      continue;\n    if (resource != (char *) NULL)\n      resource=DestroyString(resource);\n    count=(ssize_t) ReadPropertyByte(&info,&length);\n    if ((count != 0) && ((size_t) count <= length))\n      {\n        resource=(char *) NULL;\n        if (~((size_t) count) >= (MagickPathExtent-1))\n          resource=(char *) AcquireQuantumMemory((size_t) count+\n            MagickPathExtent,sizeof(*resource));\n        if (resource != (char *) NULL)\n          {\n            for (i=0; i < (ssize_t) count; i++)\n              resource[i]=(char) ReadPropertyByte(&info,&length);\n            resource[count]='\\0';\n          }\n      }\n    if ((count & 0x01) == 0)\n      (void) ReadPropertyByte(&info,&length);\n    count=(ssize_t) ReadPropertyMSBLong(&info,&length);\n    if ((*name != '\\0') && (*name != '#'))\n      if ((resource == (char *) NULL) || (LocaleCompare(name,resource) != 0))\n        {\n          /*\n            No name match, scroll forward and try next.\n          */\n          info+=count;\n          length-=MagickMin(count,(ssize_t) length);\n          continue;\n        }\n    if ((*name == '#') && (sub_number != 1))\n      {\n        /*\n          No numbered match, scroll forward and try next.\n        */\n        sub_number--;\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        continue;\n      }\n    /*\n      We have the resource of interest.\n    */\n    attribute=(char *) NULL;\n    if (~((size_t) count) >= (MagickPathExtent-1))\n      attribute=(char *) AcquireQuantumMemory((size_t) count+MagickPathExtent,\n        sizeof(*attribute));\n    if (attribute != (char *) NULL)\n      {\n        (void) CopyMagickMemory(attribute,(char *) info,(size_t) count);\n        attribute[count]='\\0';\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        if ((id <= 1999) || (id >= 2999))\n          (void) SetImageProperty((Image *) image,key,(const char *)\n            attribute,exception);\n        else\n          {\n            char\n              *path;\n\n            if (LocaleCompare(format,\"svg\") == 0)\n              path=TraceSVGClippath((unsigned char *) attribute,(size_t) count,\n                image->columns,image->rows);\n            else\n              path=TracePSClippath((unsigned char *) attribute,(size_t) count);\n            (void) SetImageProperty((Image *) image,key,(const char *) path,\n              exception);\n            path=DestroyString(path);\n          }\n        attribute=DestroyString(attribute);\n        status=MagickTrue;\n      }\n  }\n  if (resource != (char *) NULL)\n    resource=DestroyString(resource);\n  return(status);\n}", "func_src_after": "static MagickBooleanType Get8BIMProperty(const Image *image,const char *key,\n  ExceptionInfo *exception)\n{\n  char\n    *attribute,\n    format[MagickPathExtent],\n    name[MagickPathExtent],\n    *resource;\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *info;\n\n  long\n    start,\n    stop;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    id,\n    sub_number;\n\n  /*\n    There are no newlines in path names, so it's safe as terminator.\n  */\n  profile=GetImageProfile(image,\"8bim\");\n  if (profile == (StringInfo *) NULL)\n    return(MagickFalse);\n  count=(ssize_t) sscanf(key,\"8BIM:%ld,%ld:%1024[^\\n]\\n%1024[^\\n]\",&start,&stop,\n    name,format);\n  if ((count != 2) && (count != 3) && (count != 4))\n    return(MagickFalse);\n  if (count < 4)\n    (void) CopyMagickString(format,\"SVG\",MagickPathExtent);\n  if (count < 3)\n    *name='\\0';\n  sub_number=1;\n  if (*name == '#')\n    sub_number=(ssize_t) StringToLong(&name[1]);\n  sub_number=MagickMax(sub_number,1L);\n  resource=(char *) NULL;\n  status=MagickFalse;\n  length=GetStringInfoLength(profile);\n  info=GetStringInfoDatum(profile);\n  while ((length > 0) && (status == MagickFalse))\n  {\n    if (ReadPropertyByte(&info,&length) != (unsigned char) '8')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'B')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'I')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'M')\n      continue;\n    id=(ssize_t) ReadPropertyMSBShort(&info,&length);\n    if (id < (ssize_t) start)\n      continue;\n    if (id > (ssize_t) stop)\n      continue;\n    if (resource != (char *) NULL)\n      resource=DestroyString(resource);\n    count=(ssize_t) ReadPropertyByte(&info,&length);\n    if ((count != 0) && ((size_t) count <= length))\n      {\n        resource=(char *) NULL;\n        if (~((size_t) count) >= (MagickPathExtent-1))\n          resource=(char *) AcquireQuantumMemory((size_t) count+\n            MagickPathExtent,sizeof(*resource));\n        if (resource != (char *) NULL)\n          {\n            for (i=0; i < (ssize_t) count; i++)\n              resource[i]=(char) ReadPropertyByte(&info,&length);\n            resource[count]='\\0';\n          }\n      }\n    if ((count & 0x01) == 0)\n      (void) ReadPropertyByte(&info,&length);\n    count=(ssize_t) ReadPropertyMSBLong(&info,&length);\n    if ((count < 0) || ((size_t) count > length))\n      {\n        length=0; \n        continue;\n      }\n    if ((*name != '\\0') && (*name != '#'))\n      if ((resource == (char *) NULL) || (LocaleCompare(name,resource) != 0))\n        {\n          /*\n            No name match, scroll forward and try next.\n          */\n          info+=count;\n          length-=MagickMin(count,(ssize_t) length);\n          continue;\n        }\n    if ((*name == '#') && (sub_number != 1))\n      {\n        /*\n          No numbered match, scroll forward and try next.\n        */\n        sub_number--;\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        continue;\n      }\n    /*\n      We have the resource of interest.\n    */\n    attribute=(char *) NULL;\n    if (~((size_t) count) >= (MagickPathExtent-1))\n      attribute=(char *) AcquireQuantumMemory((size_t) count+MagickPathExtent,\n        sizeof(*attribute));\n    if (attribute != (char *) NULL)\n      {\n        (void) CopyMagickMemory(attribute,(char *) info,(size_t) count);\n        attribute[count]='\\0';\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        if ((id <= 1999) || (id >= 2999))\n          (void) SetImageProperty((Image *) image,key,(const char *)\n            attribute,exception);\n        else\n          {\n            char\n              *path;\n\n            if (LocaleCompare(format,\"svg\") == 0)\n              path=TraceSVGClippath((unsigned char *) attribute,(size_t) count,\n                image->columns,image->rows);\n            else\n              path=TracePSClippath((unsigned char *) attribute,(size_t) count);\n            (void) SetImageProperty((Image *) image,key,(const char *) path,\n              exception);\n            path=DestroyString(path);\n          }\n        attribute=DestroyString(attribute);\n        status=MagickTrue;\n      }\n  }\n  if (resource != (char *) NULL)\n    resource=DestroyString(resource);\n  return(status);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/dd84447b63a71fa8c3f47071b09454efc667767b", "file_name": "MagickCore/property.c", "vul_type": "cwe-125", "description": "Write a C function named `Get8BIMProperty` that retrieves a property from an image's 8BIM profile based on a given key."}
{"func_name": "nsv_read_chunk", "func_src_before": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n{\n    NSVContext *nsv = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st[2] = {NULL, NULL};\n    NSVStream *nst;\n    AVPacket *pkt;\n    int i, err = 0;\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n    uint32_t vsize;\n    uint16_t asize;\n    uint16_t auxsize;\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\nnull_chunk_retry:\n    if (pb->eof_reached)\n        return -1;\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n        err = nsv_resync(s);\n    if (err < 0)\n        return err;\n    if (nsv->state == NSV_FOUND_NSVS)\n        err = nsv_parse_NSVs_header(s);\n    if (err < 0)\n        return err;\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n        return -1;\n\n    auxcount = avio_r8(pb);\n    vsize = avio_rl16(pb);\n    asize = avio_rl16(pb);\n    vsize = (vsize << 4) | (auxcount >> 4);\n    auxcount &= 0x0f;\n    av_log(s, AV_LOG_TRACE, \"NSV CHUNK %\"PRIu8\" aux, %\"PRIu32\" bytes video, %\"PRIu16\" bytes audio\\n\",\n           auxcount, vsize, asize);\n    /* skip aux stuff */\n    for (i = 0; i < auxcount; i++) {\n        uint32_t av_unused auxtag;\n        auxsize = avio_rl16(pb);\n        auxtag = avio_rl32(pb);\n        avio_skip(pb, auxsize);\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming brain-dead */\n    }\n\n    if (pb->eof_reached)\n        return -1;\n    if (!vsize && !asize) {\n        nsv->state = NSV_UNSYNC;\n        goto null_chunk_retry;\n    }\n\n    /* map back streams to v,a */\n    if (s->nb_streams > 0)\n        st[s->streams[0]->id] = s->streams[0];\n    if (s->nb_streams > 1)\n        st[s->streams[1]->id] = s->streams[1];\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n        nst = st[NSV_ST_VIDEO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n        av_get_packet(pb, pkt, vsize);\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n        pkt->dts = nst->frame_offset;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        for (i = 0; i < FFMIN(8, vsize); i++)\n            av_log(s, AV_LOG_TRACE, \"NSV video: [%d] = %02\"PRIx8\"\\n\",\n                   i, pkt->data[i]);\n    }\n    if(st[NSV_ST_VIDEO])\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n    if (asize && st[NSV_ST_AUDIO]) {\n        nst = st[NSV_ST_AUDIO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n        /* read raw audio specific header on the first audio chunk... */\n        /* on ALL audio chunks ?? seems so! */\n        if (asize && st[NSV_ST_AUDIO]->codecpar->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n            uint8_t bps;\n            uint8_t channels;\n            uint16_t samplerate;\n            bps = avio_r8(pb);\n            channels = avio_r8(pb);\n            samplerate = avio_rl16(pb);\n            if (!channels || !samplerate)\n                return AVERROR_INVALIDDATA;\n            asize-=4;\n            av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                   bps, channels, samplerate);\n            if (fill_header) {\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n                if (bps != 16) {\n                    av_log(s, AV_LOG_TRACE, \"NSV AUDIO bit/sample != 16 (%\"PRIu8\")!!!\\n\", bps);\n                }\n                bps /= channels; // ???\n                if (bps == 8)\n                    st[NSV_ST_AUDIO]->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n                samplerate /= 4;/* UGH ??? XXX */\n                channels = 1;\n                st[NSV_ST_AUDIO]->codecpar->channels = channels;\n                st[NSV_ST_AUDIO]->codecpar->sample_rate = samplerate;\n                av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                       bps, channels, samplerate);\n            }\n        }\n        av_get_packet(pb, pkt, asize);\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n            /* on a nsvs frame we have new information on a/v sync */\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n            av_log(s, AV_LOG_TRACE, \"NSV AUDIO: sync:%\"PRId16\", dts:%\"PRId64,\n                   nsv->avsync, pkt->dts);\n        }\n        nst->frame_offset++;\n    }\n\n    nsv->state = NSV_UNSYNC;\n    return 0;\n}", "func_src_after": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n{\n    NSVContext *nsv = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st[2] = {NULL, NULL};\n    NSVStream *nst;\n    AVPacket *pkt;\n    int i, err = 0;\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n    uint32_t vsize;\n    uint16_t asize;\n    uint16_t auxsize;\n    int ret;\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\nnull_chunk_retry:\n    if (pb->eof_reached)\n        return -1;\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n        err = nsv_resync(s);\n    if (err < 0)\n        return err;\n    if (nsv->state == NSV_FOUND_NSVS)\n        err = nsv_parse_NSVs_header(s);\n    if (err < 0)\n        return err;\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n        return -1;\n\n    auxcount = avio_r8(pb);\n    vsize = avio_rl16(pb);\n    asize = avio_rl16(pb);\n    vsize = (vsize << 4) | (auxcount >> 4);\n    auxcount &= 0x0f;\n    av_log(s, AV_LOG_TRACE, \"NSV CHUNK %\"PRIu8\" aux, %\"PRIu32\" bytes video, %\"PRIu16\" bytes audio\\n\",\n           auxcount, vsize, asize);\n    /* skip aux stuff */\n    for (i = 0; i < auxcount; i++) {\n        uint32_t av_unused auxtag;\n        auxsize = avio_rl16(pb);\n        auxtag = avio_rl32(pb);\n        avio_skip(pb, auxsize);\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming brain-dead */\n    }\n\n    if (pb->eof_reached)\n        return -1;\n    if (!vsize && !asize) {\n        nsv->state = NSV_UNSYNC;\n        goto null_chunk_retry;\n    }\n\n    /* map back streams to v,a */\n    if (s->nb_streams > 0)\n        st[s->streams[0]->id] = s->streams[0];\n    if (s->nb_streams > 1)\n        st[s->streams[1]->id] = s->streams[1];\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n        nst = st[NSV_ST_VIDEO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n        if ((ret = av_get_packet(pb, pkt, vsize)) < 0)\n            return ret;\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n        pkt->dts = nst->frame_offset;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        for (i = 0; i < FFMIN(8, vsize); i++)\n            av_log(s, AV_LOG_TRACE, \"NSV video: [%d] = %02\"PRIx8\"\\n\",\n                   i, pkt->data[i]);\n    }\n    if(st[NSV_ST_VIDEO])\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n    if (asize && st[NSV_ST_AUDIO]) {\n        nst = st[NSV_ST_AUDIO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n        /* read raw audio specific header on the first audio chunk... */\n        /* on ALL audio chunks ?? seems so! */\n        if (asize && st[NSV_ST_AUDIO]->codecpar->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n            uint8_t bps;\n            uint8_t channels;\n            uint16_t samplerate;\n            bps = avio_r8(pb);\n            channels = avio_r8(pb);\n            samplerate = avio_rl16(pb);\n            if (!channels || !samplerate)\n                return AVERROR_INVALIDDATA;\n            asize-=4;\n            av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                   bps, channels, samplerate);\n            if (fill_header) {\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n                if (bps != 16) {\n                    av_log(s, AV_LOG_TRACE, \"NSV AUDIO bit/sample != 16 (%\"PRIu8\")!!!\\n\", bps);\n                }\n                bps /= channels; // ???\n                if (bps == 8)\n                    st[NSV_ST_AUDIO]->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n                samplerate /= 4;/* UGH ??? XXX */\n                channels = 1;\n                st[NSV_ST_AUDIO]->codecpar->channels = channels;\n                st[NSV_ST_AUDIO]->codecpar->sample_rate = samplerate;\n                av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                       bps, channels, samplerate);\n            }\n        }\n        if ((ret = av_get_packet(pb, pkt, asize)) < 0)\n            return ret;\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n            /* on a nsvs frame we have new information on a/v sync */\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n            av_log(s, AV_LOG_TRACE, \"NSV AUDIO: sync:%\"PRId16\", dts:%\"PRId64,\n                   nsv->avsync, pkt->dts);\n        }\n        nst->frame_offset++;\n    }\n\n    nsv->state = NSV_UNSYNC;\n    return 0;\n}", "commit_link": "github.com/libav/libav/commit/fe6eea99efac66839052af547426518efd970b24", "file_name": "libavformat/nsvdec.c", "vul_type": "cwe-476", "description": "Write a C function named `nsv_read_chunk` that reads a chunk of NSV format data from a given AVFormatContext."}
{"func_name": "testInvalidExtension", "func_src_before": "  def testInvalidExtension(self):\n    converter = upgrade_schema_lib.Converter()\n    invalid_extension = tempfile.mktemp(suffix=\".foo\")\n    with self.assertRaisesRegex(ValueError, \"Invalid extension on input\"):\n      converter.Convert(invalid_extension, invalid_extension)\n    with tempfile.NamedTemporaryFile(suffix=\".json\", mode=\"w+\") as in_json:\n      JsonDumpAndFlush(EMPTY_TEST_SCHEMA_V1, in_json)\n      with self.assertRaisesRegex(ValueError, \"Invalid extension on output\"):\n        converter.Convert(in_json.name, invalid_extension)", "func_src_after": "  def testInvalidExtension(self):\n    converter = upgrade_schema_lib.Converter()\n    _, invalid_extension = tempfile.mkstemp(suffix=\".foo\")  # safe to ignore fd\n    with self.assertRaisesRegex(ValueError, \"Invalid extension on input\"):\n      converter.Convert(invalid_extension, invalid_extension)\n    with tempfile.NamedTemporaryFile(suffix=\".json\", mode=\"w+\") as in_json:\n      JsonDumpAndFlush(EMPTY_TEST_SCHEMA_V1, in_json)\n      with self.assertRaisesRegex(ValueError, \"Invalid extension on output\"):\n        converter.Convert(in_json.name, invalid_extension)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 81, "char_end": 136, "line": "    invalid_extension = tempfile.mktemp(suffix=\".foo\")\n"}], "added": [{"line_no": 3, "char_start": 81, "char_end": 161, "line": "    _, invalid_extension = tempfile.mkstemp(suffix=\".foo\")  # safe to ignore fd\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 84, "char_end": 87, "chars": " _,"}, {"char_start": 119, "char_end": 120, "chars": "s"}, {"char_start": 139, "char_end": 160, "chars": "  # safe to ignore fd"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/c63f6333a78ddf89ecd502d926fb877b8dce4f0f", "file_name": "upgrade_schema_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420335872\nChange-Id: I331ec2544a08d3cc3063a74af342cceae655b3dc", "description": "Write a Python unit test that checks for ValueError when a schema converter is given files with invalid extensions."}
{"func_name": "ImagingLibTiffDecode", "func_src_before": "int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_ssize_t bytes) {\n    TIFFSTATE *clientstate = (TIFFSTATE *)state->context;\n    char *filename = \"tempfile.tif\";\n    char *mode = \"r\";\n    TIFF *tiff;\n\n    /* buffer is the encoded file, bytes is the length of the encoded file */\n    /*     it all ends up in state->buffer, which is a uint8* from Imaging.h */\n\n    TRACE((\"in decoder: bytes %d\\n\", bytes));\n    TRACE((\"State: count %d, state %d, x %d, y %d, ystep %d\\n\", state->count, state->state,\n           state->x, state->y, state->ystep));\n    TRACE((\"State: xsize %d, ysize %d, xoff %d, yoff %d \\n\", state->xsize, state->ysize,\n           state->xoff, state->yoff));\n    TRACE((\"State: bits %d, bytes %d \\n\", state->bits, state->bytes));\n    TRACE((\"Buffer: %p: %c%c%c%c\\n\", buffer, (char)buffer[0], (char)buffer[1],(char)buffer[2], (char)buffer[3]));\n    TRACE((\"State->Buffer: %c%c%c%c\\n\", (char)state->buffer[0], (char)state->buffer[1],(char)state->buffer[2], (char)state->buffer[3]));\n    TRACE((\"Image: mode %s, type %d, bands: %d, xsize %d, ysize %d \\n\",\n           im->mode, im->type, im->bands, im->xsize, im->ysize));\n    TRACE((\"Image: image8 %p, image32 %p, image %p, block %p \\n\",\n           im->image8, im->image32, im->image, im->block));\n    TRACE((\"Image: pixelsize: %d, linesize %d \\n\",\n           im->pixelsize, im->linesize));\n\n    dump_state(clientstate);\n    clientstate->size = bytes;\n    clientstate->eof = clientstate->size;\n    clientstate->loc = 0;\n    clientstate->data = (tdata_t)buffer;\n    clientstate->flrealloc = 0;\n    dump_state(clientstate);\n\n    TIFFSetWarningHandler(NULL);\n    TIFFSetWarningHandlerExt(NULL);\n\n    if (clientstate->fp) {\n        TRACE((\"Opening using fd: %d\\n\",clientstate->fp));\n        lseek(clientstate->fp,0,SEEK_SET); // Sometimes, I get it set to the end.\n        tiff = TIFFFdOpen(clientstate->fp, filename, mode);\n    } else {\n        TRACE((\"Opening from string\\n\"));\n        tiff = TIFFClientOpen(filename, mode,\n                              (thandle_t) clientstate,\n                              _tiffReadProc, _tiffWriteProc,\n                              _tiffSeekProc, _tiffCloseProc, _tiffSizeProc,\n                              _tiffMapProc, _tiffUnmapProc);\n    }\n\n    if (!tiff){\n        TRACE((\"Error, didn't get the tiff\\n\"));\n        state->errcode = IMAGING_CODEC_BROKEN;\n        return -1;\n    }\n\n    if (clientstate->ifd){\n        int rv;\n        uint32 ifdoffset = clientstate->ifd;\n        TRACE((\"reading tiff ifd %u\\n\", ifdoffset));\n        rv = TIFFSetSubDirectory(tiff, ifdoffset);\n        if (!rv){\n            TRACE((\"error in TIFFSetSubDirectory\"));\n            return -1;\n        }\n    }\n\n    if (TIFFIsTiled(tiff)) {\n        UINT32 x, y, tile_y, row_byte_size;\n        UINT32 tile_width, tile_length, current_tile_width;\n        UINT8 *new_data;\n\n        TIFFGetField(tiff, TIFFTAG_TILEWIDTH, &tile_width);\n        TIFFGetField(tiff, TIFFTAG_TILELENGTH, &tile_length);\n\n        // We could use TIFFTileSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (tile_width * state->bits + 7) / 8;\n        state->bytes = row_byte_size * tile_length;\n\n        /* overflow check for malloc */\n        if (state->bytes > INT_MAX - 1) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        /* realloc to fit whole tile */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        TRACE((\"TIFFTileSize: %d\\n\", state->bytes));\n\n        for (y = state->yoff; y < state->ysize; y += tile_length) {\n            for (x = state->xoff; x < state->xsize; x += tile_width) {\n                if (ReadTile(tiff, x, y, (UINT32*) state->buffer) == -1) {\n                    TRACE((\"Decode Error, Tile at %dx%d\\n\", x, y));\n                    state->errcode = IMAGING_CODEC_BROKEN;\n                    TIFFClose(tiff);\n                    return -1;\n                }\n\n                TRACE((\"Read tile at %dx%d; \\n\\n\", x, y));\n\n                current_tile_width = min(tile_width, state->xsize - x);\n\n                // iterate over each line in the tile and stuff data into image\n                for (tile_y = 0; tile_y < min(tile_length, state->ysize - y); tile_y++) {\n                    TRACE((\"Writing tile data at %dx%d using tile_width: %d; \\n\", tile_y + y, x, current_tile_width));\n\n                    // UINT8 * bbb = state->buffer + tile_y * row_byte_size;\n                    // TRACE((\"chars: %x%x%x%x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                    state->shuffle((UINT8*) im->image[tile_y + y] + x * im->pixelsize,\n                       state->buffer + tile_y * row_byte_size,\n                       current_tile_width\n                    );\n                }\n            }\n        }\n    } else {\n        UINT32 strip_row, row_byte_size;\n        UINT8 *new_data;\n        UINT32 rows_per_strip;\n        int ret;\n\n        ret = TIFFGetField(tiff, TIFFTAG_ROWSPERSTRIP, &rows_per_strip);\n        if (ret != 1) {\n            rows_per_strip = state->ysize;\n        }\n        TRACE((\"RowsPerStrip: %u \\n\", rows_per_strip));\n\n        // We could use TIFFStripSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (state->xsize * state->bits + 7) / 8;\n        state->bytes = rows_per_strip * row_byte_size;\n\n        TRACE((\"StripSize: %d \\n\", state->bytes));\n\n        /* realloc to fit whole strip */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        for (; state->y < state->ysize; state->y += rows_per_strip) {\n            if (ReadStrip(tiff, state->y, (UINT32 *)state->buffer) == -1) {\n                TRACE((\"Decode Error, strip %d\\n\", TIFFComputeStrip(tiff, state->y, 0)));\n                state->errcode = IMAGING_CODEC_BROKEN;\n                TIFFClose(tiff);\n                return -1;\n            }\n\n            TRACE((\"Decoded strip for row %d \\n\", state->y));\n\n            // iterate over each row in the strip and stuff data into image\n            for (strip_row = 0; strip_row < min(rows_per_strip, state->ysize - state->y); strip_row++) {\n                TRACE((\"Writing data into line %d ; \\n\", state->y + strip_row));\n\n                // UINT8 * bbb = state->buffer + strip_row * (state->bytes / rows_per_strip);\n                // TRACE((\"chars: %x %x %x %x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                state->shuffle((UINT8*) im->image[state->y + state->yoff + strip_row] +\n                               state->xoff * im->pixelsize,\n                               state->buffer + strip_row * row_byte_size,\n                               state->xsize);\n            }\n        }\n    }\n\n    TIFFClose(tiff);\n    TRACE((\"Done Decoding, Returning \\n\"));\n    // Returning -1 here to force ImageFile.load to break, rather than\n    // even think about looping back around.\n    return -1;\n}", "func_src_after": "int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_ssize_t bytes) {\n    TIFFSTATE *clientstate = (TIFFSTATE *)state->context;\n    char *filename = \"tempfile.tif\";\n    char *mode = \"r\";\n    TIFF *tiff;\n\n    /* buffer is the encoded file, bytes is the length of the encoded file */\n    /*     it all ends up in state->buffer, which is a uint8* from Imaging.h */\n\n    TRACE((\"in decoder: bytes %d\\n\", bytes));\n    TRACE((\"State: count %d, state %d, x %d, y %d, ystep %d\\n\", state->count, state->state,\n           state->x, state->y, state->ystep));\n    TRACE((\"State: xsize %d, ysize %d, xoff %d, yoff %d \\n\", state->xsize, state->ysize,\n           state->xoff, state->yoff));\n    TRACE((\"State: bits %d, bytes %d \\n\", state->bits, state->bytes));\n    TRACE((\"Buffer: %p: %c%c%c%c\\n\", buffer, (char)buffer[0], (char)buffer[1],(char)buffer[2], (char)buffer[3]));\n    TRACE((\"State->Buffer: %c%c%c%c\\n\", (char)state->buffer[0], (char)state->buffer[1],(char)state->buffer[2], (char)state->buffer[3]));\n    TRACE((\"Image: mode %s, type %d, bands: %d, xsize %d, ysize %d \\n\",\n           im->mode, im->type, im->bands, im->xsize, im->ysize));\n    TRACE((\"Image: image8 %p, image32 %p, image %p, block %p \\n\",\n           im->image8, im->image32, im->image, im->block));\n    TRACE((\"Image: pixelsize: %d, linesize %d \\n\",\n           im->pixelsize, im->linesize));\n\n    dump_state(clientstate);\n    clientstate->size = bytes;\n    clientstate->eof = clientstate->size;\n    clientstate->loc = 0;\n    clientstate->data = (tdata_t)buffer;\n    clientstate->flrealloc = 0;\n    dump_state(clientstate);\n\n    TIFFSetWarningHandler(NULL);\n    TIFFSetWarningHandlerExt(NULL);\n\n    if (clientstate->fp) {\n        TRACE((\"Opening using fd: %d\\n\",clientstate->fp));\n        lseek(clientstate->fp,0,SEEK_SET); // Sometimes, I get it set to the end.\n        tiff = TIFFFdOpen(clientstate->fp, filename, mode);\n    } else {\n        TRACE((\"Opening from string\\n\"));\n        tiff = TIFFClientOpen(filename, mode,\n                              (thandle_t) clientstate,\n                              _tiffReadProc, _tiffWriteProc,\n                              _tiffSeekProc, _tiffCloseProc, _tiffSizeProc,\n                              _tiffMapProc, _tiffUnmapProc);\n    }\n\n    if (!tiff){\n        TRACE((\"Error, didn't get the tiff\\n\"));\n        state->errcode = IMAGING_CODEC_BROKEN;\n        return -1;\n    }\n\n    if (clientstate->ifd){\n        int rv;\n        uint32 ifdoffset = clientstate->ifd;\n        TRACE((\"reading tiff ifd %u\\n\", ifdoffset));\n        rv = TIFFSetSubDirectory(tiff, ifdoffset);\n        if (!rv){\n            TRACE((\"error in TIFFSetSubDirectory\"));\n            return -1;\n        }\n    }\n\n    if (TIFFIsTiled(tiff)) {\n        UINT32 x, y, tile_y, row_byte_size;\n        UINT32 tile_width, tile_length, current_tile_width;\n        UINT8 *new_data;\n\n        TIFFGetField(tiff, TIFFTAG_TILEWIDTH, &tile_width);\n        TIFFGetField(tiff, TIFFTAG_TILELENGTH, &tile_length);\n\n        // We could use TIFFTileSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (tile_width * state->bits + 7) / 8;\n\n        /* overflow check for realloc */\n        if (INT_MAX / row_byte_size < tile_length) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n        \n        state->bytes = row_byte_size * tile_length;\n\n        /* realloc to fit whole tile */\n        /* malloc check above */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        TRACE((\"TIFFTileSize: %d\\n\", state->bytes));\n\n        for (y = state->yoff; y < state->ysize; y += tile_length) {\n            for (x = state->xoff; x < state->xsize; x += tile_width) {\n                if (ReadTile(tiff, x, y, (UINT32*) state->buffer) == -1) {\n                    TRACE((\"Decode Error, Tile at %dx%d\\n\", x, y));\n                    state->errcode = IMAGING_CODEC_BROKEN;\n                    TIFFClose(tiff);\n                    return -1;\n                }\n\n                TRACE((\"Read tile at %dx%d; \\n\\n\", x, y));\n\n                current_tile_width = min(tile_width, state->xsize - x);\n\n                // iterate over each line in the tile and stuff data into image\n                for (tile_y = 0; tile_y < min(tile_length, state->ysize - y); tile_y++) {\n                    TRACE((\"Writing tile data at %dx%d using tile_width: %d; \\n\", tile_y + y, x, current_tile_width));\n\n                    // UINT8 * bbb = state->buffer + tile_y * row_byte_size;\n                    // TRACE((\"chars: %x%x%x%x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                    state->shuffle((UINT8*) im->image[tile_y + y] + x * im->pixelsize,\n                       state->buffer + tile_y * row_byte_size,\n                       current_tile_width\n                    );\n                }\n            }\n        }\n    } else {\n        UINT32 strip_row, row_byte_size;\n        UINT8 *new_data;\n        UINT32 rows_per_strip;\n        int ret;\n\n        ret = TIFFGetField(tiff, TIFFTAG_ROWSPERSTRIP, &rows_per_strip);\n        if (ret != 1) {\n            rows_per_strip = state->ysize;\n        }\n        TRACE((\"RowsPerStrip: %u \\n\", rows_per_strip));\n\n        // We could use TIFFStripSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (state->xsize * state->bits + 7) / 8;\n\n        /* overflow check for realloc */\n        if (INT_MAX / row_byte_size < rows_per_strip) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n        \n        state->bytes = rows_per_strip * row_byte_size;\n\n        TRACE((\"StripSize: %d \\n\", state->bytes));\n\n        /* realloc to fit whole strip */\n        /* malloc check above */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        for (; state->y < state->ysize; state->y += rows_per_strip) {\n            if (ReadStrip(tiff, state->y, (UINT32 *)state->buffer) == -1) {\n                TRACE((\"Decode Error, strip %d\\n\", TIFFComputeStrip(tiff, state->y, 0)));\n                state->errcode = IMAGING_CODEC_BROKEN;\n                TIFFClose(tiff);\n                return -1;\n            }\n\n            TRACE((\"Decoded strip for row %d \\n\", state->y));\n\n            // iterate over each row in the strip and stuff data into image\n            for (strip_row = 0; strip_row < min(rows_per_strip, state->ysize - state->y); strip_row++) {\n                TRACE((\"Writing data into line %d ; \\n\", state->y + strip_row));\n\n                // UINT8 * bbb = state->buffer + strip_row * (state->bytes / rows_per_strip);\n                // TRACE((\"chars: %x %x %x %x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                state->shuffle((UINT8*) im->image[state->y + state->yoff + strip_row] +\n                               state->xoff * im->pixelsize,\n                               state->buffer + strip_row * row_byte_size,\n                               state->xsize);\n            }\n        }\n    }\n\n    TIFFClose(tiff);\n    TRACE((\"Done Decoding, Returning \\n\"));\n    // Returning -1 here to force ImageFile.load to break, rather than\n    // even think about looping back around.\n    return -1;\n}", "commit_link": "github.com/python-pillow/Pillow/commit/4e2def2539ec13e53a82e06c4b3daf00454100c4", "file_name": "src/libImaging/TiffDecode.c", "vul_type": "cwe-190", "description": "Write a C function named `ImagingLibTiffDecode` that decodes a TIFF image into an internal imaging structure."}
{"func_name": "fetch_resultSet", "func_src_before": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = '%s', expires = '%s' \"\n                 \"WHERE identifier = '%s';\" %\n                 (self.table, nowStr, expiresStr, sid)\n                 )\n        self._query(query)\n        return rset", "func_src_after": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = $1, expires = $2 \"\n                 \"WHERE identifier = $3;\" % (self.table)\n                 )\n        self._query(query, nowStr, expiresStr, sid)\n        return rset", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and updates a record from a database using either string formatting or parameterized queries."}
{"func_name": "handle_method_call", "func_src_before": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "func_src_after": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!allowed_problem_dir(problem_id))\n        {\n            return_InvalidProblemDir_error(invocation, problem_id);\n            return;\n        }\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!allowed_problem_dir(problem_id))\n        {\n            return_InvalidProblemDir_error(invocation, problem_id);\n            return;\n        }\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name\", element);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "commit_link": "github.com/abrt/abrt/commit/7a47f57975be0d285a2f20758e4572dca6d9cdd3", "file_name": "src/dbus/abrt-dbus.c", "vul_type": "cwe-022", "description": "Write a C function to handle various method calls for problem management over D-Bus."}
{"func_name": "php_wddx_push_element", "func_src_before": " */\nstatic void php_wddx_push_element(void *user_data, const XML_Char *name, const XML_Char **atts)\n{\n\tst_entry ent;\n\twddx_stack *stack = (wddx_stack *)user_data;\n\n\tif (!strcmp(name, EL_PACKET)) {\n\t\tint i;\n\n\t\tif (atts) for (i=0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VERSION)) {\n\t\t\t\t/* nothing for now */\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_STRING)) {\n\t\tent.type = ST_STRING;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BINARY)) {\n\t\tent.type = ST_BINARY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_CHAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_CHAR_CODE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tchar tmp_buf[2];\n\n\t\t\t\tsnprintf(tmp_buf, sizeof(tmp_buf), \"%c\", (char)strtol(atts[i+1], NULL, 16));\n\t\t\t\tphp_wddx_process_data(user_data, tmp_buf, strlen(tmp_buf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NUMBER)) {\n\t\tent.type = ST_NUMBER;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\tZ_LVAL_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BOOLEAN)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VALUE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tent.type = ST_BOOLEAN;\n\t\t\t\tSET_STACK_VARNAME;\n\n\t\t\t\tALLOC_ZVAL(ent.data);\n\t\t\t\tINIT_PZVAL(ent.data);\n\t\t\t\tZ_TYPE_P(ent.data) = IS_BOOL;\n\t\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t\t\tphp_wddx_process_data(user_data, atts[i+1], strlen(atts[i+1]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NULL)) {\n\t\tent.type = ST_NULL;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZVAL_NULL(ent.data);\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_ARRAY)) {\n\t\tent.type = ST_ARRAY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_STRUCT)) {\n\t\tent.type = ST_STRUCT;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_VAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tif (stack->varname) efree(stack->varname);\n\t\t\t\tstack->varname = estrdup(atts[i+1]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_RECORDSET)) {\n\t\tint i;\n\n\t\tent.type = ST_RECORDSET;\n\t\tSET_STACK_VARNAME;\n\t\tMAKE_STD_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], \"fieldNames\") && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tzval *tmp;\n\t\t\t\tchar *key;\n\t\t\t\tchar *p1, *p2, *endp;\n\n\t\t\t\ti++;\n\t\t\t\tendp = (char *)atts[i] + strlen(atts[i]);\n\t\t\t\tp1 = (char *)atts[i];\n\t\t\t\twhile ((p2 = php_memnstr(p1, \",\", sizeof(\",\")-1, endp)) != NULL) {\n\t\t\t\t\tkey = estrndup(p1, p2 - p1);\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, key, p2 - p1 + 1, tmp);\n\t\t\t\t\tp1 = p2 + sizeof(\",\")-1;\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\n\t\t\t\tif (p1 <= endp) {\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, p1, endp - p1 + 1, tmp);\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tint i;\n\t\tst_entry ent;\n\n\t\tent.type = ST_FIELD;\n\t\tent.varname = NULL;\n\t\tent.data = NULL;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tst_entry *recordset;\n\t\t\t\tzval **field;\n\n\t\t\t\tif (wddx_stack_top(stack, (void**)&recordset) == SUCCESS &&\n\t\t\t\t\trecordset->type == ST_RECORDSET &&\n\t\t\t\t\tzend_hash_find(Z_ARRVAL_P(recordset->data), (char*)atts[i+1], strlen(atts[i+1])+1, (void**)&field) == SUCCESS) {\n\t\t\t\t\tent.data = *field;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_DATETIME)) {\n\t\tent.type = ST_DATETIME;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t}", "func_src_after": " */\nstatic void php_wddx_push_element(void *user_data, const XML_Char *name, const XML_Char **atts)\n{\n\tst_entry ent;\n\twddx_stack *stack = (wddx_stack *)user_data;\n\n\tif (!strcmp(name, EL_PACKET)) {\n\t\tint i;\n\n\t\tif (atts) for (i=0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VERSION)) {\n\t\t\t\t/* nothing for now */\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_STRING)) {\n\t\tent.type = ST_STRING;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BINARY)) {\n\t\tent.type = ST_BINARY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_CHAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_CHAR_CODE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tchar tmp_buf[2];\n\n\t\t\t\tsnprintf(tmp_buf, sizeof(tmp_buf), \"%c\", (char)strtol(atts[i+1], NULL, 16));\n\t\t\t\tphp_wddx_process_data(user_data, tmp_buf, strlen(tmp_buf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NUMBER)) {\n\t\tent.type = ST_NUMBER;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\tZ_LVAL_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BOOLEAN)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VALUE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tent.type = ST_BOOLEAN;\n\t\t\t\tSET_STACK_VARNAME;\n\n\t\t\t\tALLOC_ZVAL(ent.data);\n\t\t\t\tINIT_PZVAL(ent.data);\n\t\t\t\tZ_TYPE_P(ent.data) = IS_BOOL;\n\t\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t\t\tphp_wddx_process_data(user_data, atts[i+1], strlen(atts[i+1]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tent.type = ST_BOOLEAN;\n\t\t\tSET_STACK_VARNAME;\n\t\t\tZVAL_FALSE(&ent.data);\n\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t}\n\t} else if (!strcmp(name, EL_NULL)) {\n\t\tent.type = ST_NULL;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZVAL_NULL(ent.data);\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_ARRAY)) {\n\t\tent.type = ST_ARRAY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_STRUCT)) {\n\t\tent.type = ST_STRUCT;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_VAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tif (stack->varname) efree(stack->varname);\n\t\t\t\tstack->varname = estrdup(atts[i+1]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_RECORDSET)) {\n\t\tint i;\n\n\t\tent.type = ST_RECORDSET;\n\t\tSET_STACK_VARNAME;\n\t\tMAKE_STD_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], \"fieldNames\") && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tzval *tmp;\n\t\t\t\tchar *key;\n\t\t\t\tchar *p1, *p2, *endp;\n\n\t\t\t\ti++;\n\t\t\t\tendp = (char *)atts[i] + strlen(atts[i]);\n\t\t\t\tp1 = (char *)atts[i];\n\t\t\t\twhile ((p2 = php_memnstr(p1, \",\", sizeof(\",\")-1, endp)) != NULL) {\n\t\t\t\t\tkey = estrndup(p1, p2 - p1);\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, key, p2 - p1 + 1, tmp);\n\t\t\t\t\tp1 = p2 + sizeof(\",\")-1;\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\n\t\t\t\tif (p1 <= endp) {\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, p1, endp - p1 + 1, tmp);\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tint i;\n\t\tst_entry ent;\n\n\t\tent.type = ST_FIELD;\n\t\tent.varname = NULL;\n\t\tent.data = NULL;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tst_entry *recordset;\n\t\t\t\tzval **field;\n\n\t\t\t\tif (wddx_stack_top(stack, (void**)&recordset) == SUCCESS &&\n\t\t\t\t\trecordset->type == ST_RECORDSET &&\n\t\t\t\t\tzend_hash_find(Z_ARRVAL_P(recordset->data), (char*)atts[i+1], strlen(atts[i+1])+1, (void**)&field) == SUCCESS) {\n\t\t\t\t\tent.data = *field;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_DATETIME)) {\n\t\tent.type = ST_DATETIME;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t}", "commit_link": "github.com/php/php-src/commit/66fd44209d5ffcb9b3d1bc1b9fd8e35b485040c0", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-125", "description": "Write a PHP function to handle XML elements and their attributes for WDDX deserialization."}
{"func_name": "render", "func_src_before": "\tdef render(self, request):\n\t\taction = \"download\"\n\t\tif \"action\" in request.args:\n\t\t\taction = request.args[\"action\"][0]\n\n\t\tif \"file\" in request.args:\n\t\t\tfilename = request.args[\"file\"][0].decode('utf-8', 'ignore').encode('utf-8')\n\t\t\tfilename = re.sub(\"^/+\", \"/\", os.path.realpath(filename))\n\n\t\t\tif not os.path.exists(filename):\n\t\t\t\treturn \"File '%s' not found\" % (filename)\n\n\t\t\tif action == \"stream\":\n\t\t\t\tname = \"stream\"\n\t\t\t\tif \"name\" in request.args:\n\t\t\t\t\tname = request.args[\"name\"][0]\n\n\t\t\t\tport = config.OpenWebif.port.value\n\t\t\t\tproto = 'http'\n\t\t\t\tif request.isSecure():\n\t\t\t\t\tport = config.OpenWebif.https_port.value\n\t\t\t\t\tproto = 'https'\n\t\t\t\tourhost = request.getHeader('host')\n\t\t\t\tm = re.match('.+\\:(\\d+)$', ourhost)\n\t\t\t\tif m is not None:\n\t\t\t\t\tport = m.group(1)\n\n\t\t\t\tresponse = \"#EXTM3U\\n#EXTVLCOPT--http-reconnect=true\\n#EXTINF:-1,%s\\n%s://%s:%s/file?action=download&file=%s\" % (name, proto, request.getRequestHostname(), port, quote(filename))\n\t\t\t\trequest.setHeader(\"Content-Disposition\", 'attachment;filename=\"%s.m3u\"' % name)\n\t\t\t\trequest.setHeader(\"Content-Type\", \"application/x-mpegurl\")\n\t\t\t\treturn response\n\t\t\telif action == \"delete\":\n\t\t\t\trequest.setResponseCode(http.OK)\n\t\t\t\treturn \"TODO: DELETE FILE: %s\" % (filename)\n\t\t\telif action == \"download\":\n\t\t\t\trequest.setHeader(\"Content-Disposition\", \"attachment;filename=\\\"%s\\\"\" % (filename.split('/')[-1]))\n\t\t\t\trfile = static.File(filename, defaultType = \"application/octet-stream\")\n\t\t\t\treturn rfile.render(request)\n\t\t\telse: \n\t\t\t\treturn \"wrong action parameter\"\n\n\t\tif \"dir\" in request.args:\n\t\t\tpath = request.args[\"dir\"][0]\n\t\t\tpattern = '*'\n\t\t\tdata = []\n\t\t\tif \"pattern\" in request.args:\n\t\t\t\tpattern = request.args[\"pattern\"][0]\n\t\t\tdirectories = []\n\t\t\tfiles = []\n\t\t\tif fileExists(path):\n\t\t\t\ttry:\n\t\t\t\t\tfiles = glob.glob(path+'/'+pattern)\n\t\t\t\texcept:\n\t\t\t\t\tfiles = []\n\t\t\t\tfiles.sort()\n\t\t\t\ttmpfiles = files[:]\n\t\t\t\tfor x in tmpfiles:\n\t\t\t\t\tif os.path.isdir(x):\n\t\t\t\t\t\tdirectories.append(x + '/')\n\t\t\t\t\t\tfiles.remove(x)\n\t\t\t\tdata.append({\"result\": True,\"dirs\": directories,\"files\": files})\n\t\t\telse:\n\t\t\t\tdata.append({\"result\": False,\"message\": \"path %s not exits\" % (path)})\n\t\t\trequest.setHeader(\"content-type\", \"application/json; charset=utf-8\")\n\t\t\treturn json.dumps(data, indent=2)", "func_src_after": "\tdef render(self, request):\n\t\taction = \"download\"\n\t\tif \"action\" in request.args:\n\t\t\taction = request.args[\"action\"][0]\n\n\t\tif \"file\" in request.args:\n\t\t\tfilename = lenient_force_utf_8(request.args[\"file\"][0])\n\t\t\tfilename = sanitise_filename_slashes(os.path.realpath(filename))\n\n\t\t\tif not os.path.exists(filename):\n\t\t\t\treturn \"File '%s' not found\" % (filename)\n\n\t\t\tif action == \"stream\":\n\t\t\t\tname = \"stream\"\n\t\t\t\tif \"name\" in request.args:\n\t\t\t\t\tname = request.args[\"name\"][0]\n\n\t\t\t\tport = config.OpenWebif.port.value\n\t\t\t\tproto = 'http'\n\t\t\t\tif request.isSecure():\n\t\t\t\t\tport = config.OpenWebif.https_port.value\n\t\t\t\t\tproto = 'https'\n\t\t\t\tourhost = request.getHeader('host')\n\t\t\t\tm = re.match('.+\\:(\\d+)$', ourhost)\n\t\t\t\tif m is not None:\n\t\t\t\t\tport = m.group(1)\n\n\t\t\t\tresponse = \"#EXTM3U\\n#EXTVLCOPT--http-reconnect=true\\n#EXTINF:-1,%s\\n%s://%s:%s/file?action=download&file=%s\" % (name, proto, request.getRequestHostname(), port, quote(filename))\n\t\t\t\trequest.setHeader(\"Content-Disposition\", 'attachment;filename=\"%s.m3u\"' % name)\n\t\t\t\trequest.setHeader(\"Content-Type\", \"application/x-mpegurl\")\n\t\t\t\treturn response\n\t\t\telif action == \"delete\":\n\t\t\t\trequest.setResponseCode(http.OK)\n\t\t\t\treturn \"TODO: DELETE FILE: %s\" % (filename)\n\t\t\telif action == \"download\":\n\t\t\t\trequest.setHeader(\"Content-Disposition\", \"attachment;filename=\\\"%s\\\"\" % (filename.split('/')[-1]))\n\t\t\t\trfile = static.File(filename, defaultType = \"application/octet-stream\")\n\t\t\t\treturn rfile.render(request)\n\t\t\telse: \n\t\t\t\treturn \"wrong action parameter\"\n\n\t\tif \"dir\" in request.args:\n\t\t\tpath = request.args[\"dir\"][0]\n\t\t\tpattern = '*'\n\t\t\tdata = []\n\t\t\tif \"pattern\" in request.args:\n\t\t\t\tpattern = request.args[\"pattern\"][0]\n\t\t\tdirectories = []\n\t\t\tfiles = []\n\t\t\tif fileExists(path):\n\t\t\t\ttry:\n\t\t\t\t\tfiles = glob.glob(path+'/'+pattern)\n\t\t\t\texcept:\n\t\t\t\t\tfiles = []\n\t\t\t\tfiles.sort()\n\t\t\t\ttmpfiles = files[:]\n\t\t\t\tfor x in tmpfiles:\n\t\t\t\t\tif os.path.isdir(x):\n\t\t\t\t\t\tdirectories.append(x + '/')\n\t\t\t\t\t\tfiles.remove(x)\n\t\t\t\tdata.append({\"result\": True,\"dirs\": directories,\"files\": files})\n\t\t\telse:\n\t\t\t\tdata.append({\"result\": False,\"message\": \"path %s not exits\" % (path)})\n\t\t\trequest.setHeader(\"content-type\", \"application/json; charset=utf-8\")\n\t\t\treturn json.dumps(data, indent=2)", "commit_link": "github.com/E2OpenPlugins/e2openplugin-OpenWebif/commit/a846b7664eda3a4c51a452e00638cf7337dc2013", "file_name": "plugin/controllers/file.py", "vul_type": "cwe-022", "description": "Write a Python function to handle file actions like streaming, downloading, deleting, or listing directory contents based on request parameters."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/rwolf527/crimemap/commit/50b0695e0b4c46165e6146f6fac4cd6871d9fdf6", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function that adds user input to a database with a deliberate SQL injection vulnerability."}
{"func_name": "gmc_mmx", "func_src_before": "static void gmc_mmx(uint8_t *dst, uint8_t *src,\n                    int stride, int h, int ox, int oy,\n                    int dxx, int dxy, int dyx, int dyy,\n                    int shift, int r, int width, int height)\n{\n    const int w    = 8;\n    const int ix   = ox  >> (16 + shift);\n    const int iy   = oy  >> (16 + shift);\n    const int oxs  = ox  >> 4;\n    const int oys  = oy  >> 4;\n    const int dxxs = dxx >> 4;\n    const int dxys = dxy >> 4;\n    const int dyxs = dyx >> 4;\n    const int dyys = dyy >> 4;\n    const uint16_t r4[4]   = { r, r, r, r };\n    const uint16_t dxy4[4] = { dxys, dxys, dxys, dxys };\n    const uint16_t dyy4[4] = { dyys, dyys, dyys, dyys };\n    const uint64_t shift2  = 2 * shift;\n#define MAX_STRIDE 4096U\n#define MAX_H 8U\n    uint8_t edge_buf[(MAX_H + 1) * MAX_STRIDE];\n    int x, y;\n\n    const int dxw = (dxx - (1 << (16 + shift))) * (w - 1);\n    const int dyh = (dyy - (1 << (16 + shift))) * (h - 1);\n    const int dxh = dxy * (h - 1);\n    const int dyw = dyx * (w - 1);\n    int need_emu  =  (unsigned) ix >= width  - w ||\n                     (unsigned) iy >= height - h;\n\n    if ( // non-constant fullpel offset (3% of blocks)\n        ((ox ^ (ox + dxw)) | (ox ^ (ox + dxh)) | (ox ^ (ox + dxw + dxh)) |\n         (oy ^ (oy + dyw)) | (oy ^ (oy + dyh)) | (oy ^ (oy + dyw + dyh))) >> (16 + shift) ||\n        // uses more than 16 bits of subpel mv (only at huge resolution)\n        (dxx | dxy | dyx | dyy) & 15 ||\n        (need_emu && (h > MAX_H || stride > MAX_STRIDE))) {\n        // FIXME could still use mmx for some of the rows\n        ff_gmc_c(dst, src, stride, h, ox, oy, dxx, dxy, dyx, dyy,\n                 shift, r, width, height);\n        return;\n    }\n\n    src += ix + iy * stride;\n    if (need_emu) {\n        ff_emulated_edge_mc_8(edge_buf, src, stride, stride, w + 1, h + 1, ix, iy, width, height);\n        src = edge_buf;\n    }\n\n    __asm__ volatile (\n        \"movd         %0, %%mm6         \\n\\t\"\n        \"pxor      %%mm7, %%mm7         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        :: \"r\" (1 << shift));\n\n    for (x = 0; x < w; x += 4) {\n        uint16_t dx4[4] = { oxs - dxys + dxxs * (x + 0),\n                            oxs - dxys + dxxs * (x + 1),\n                            oxs - dxys + dxxs * (x + 2),\n                            oxs - dxys + dxxs * (x + 3) };\n        uint16_t dy4[4] = { oys - dyys + dyxs * (x + 0),\n                            oys - dyys + dyxs * (x + 1),\n                            oys - dyys + dyxs * (x + 2),\n                            oys - dyys + dyxs * (x + 3) };\n\n        for (y = 0; y < h; y++) {\n            __asm__ volatile (\n                \"movq      %0, %%mm4    \\n\\t\"\n                \"movq      %1, %%mm5    \\n\\t\"\n                \"paddw     %2, %%mm4    \\n\\t\"\n                \"paddw     %3, %%mm5    \\n\\t\"\n                \"movq   %%mm4, %0       \\n\\t\"\n                \"movq   %%mm5, %1       \\n\\t\"\n                \"psrlw    $12, %%mm4    \\n\\t\"\n                \"psrlw    $12, %%mm5    \\n\\t\"\n                : \"+m\" (*dx4), \"+m\" (*dy4)\n                : \"m\" (*dxy4), \"m\" (*dyy4));\n\n            __asm__ volatile (\n                \"movq      %%mm6, %%mm2 \\n\\t\"\n                \"movq      %%mm6, %%mm1 \\n\\t\"\n                \"psubw     %%mm4, %%mm2 \\n\\t\"\n                \"psubw     %%mm5, %%mm1 \\n\\t\"\n                \"movq      %%mm2, %%mm0 \\n\\t\"\n                \"movq      %%mm4, %%mm3 \\n\\t\"\n                \"pmullw    %%mm1, %%mm0 \\n\\t\" // (s - dx) * (s - dy)\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // dx * dy\n                \"pmullw    %%mm5, %%mm2 \\n\\t\" // (s - dx) * dy\n                \"pmullw    %%mm4, %%mm1 \\n\\t\" // dx * (s - dy)\n\n                \"movd         %4, %%mm5 \\n\\t\"\n                \"movd         %3, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // src[1, 1] * dx * dy\n                \"pmullw    %%mm4, %%mm2 \\n\\t\" // src[0, 1] * (s - dx) * dy\n\n                \"movd         %2, %%mm5 \\n\\t\"\n                \"movd         %1, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm1 \\n\\t\" // src[1, 0] * dx * (s - dy)\n                \"pmullw    %%mm4, %%mm0 \\n\\t\" // src[0, 0] * (s - dx) * (s - dy)\n                \"paddw        %5, %%mm1 \\n\\t\"\n                \"paddw     %%mm3, %%mm2 \\n\\t\"\n                \"paddw     %%mm1, %%mm0 \\n\\t\"\n                \"paddw     %%mm2, %%mm0 \\n\\t\"\n\n                \"psrlw        %6, %%mm0 \\n\\t\"\n                \"packuswb  %%mm0, %%mm0 \\n\\t\"\n                \"movd      %%mm0, %0    \\n\\t\"\n\n                : \"=m\" (dst[x + y * stride])\n                : \"m\" (src[0]), \"m\" (src[1]),\n                  \"m\" (src[stride]), \"m\" (src[stride + 1]),\n                  \"m\" (*r4), \"m\" (shift2));\n            src += stride;\n        }\n        src += 4 - h * stride;\n    }\n}", "func_src_after": "static void gmc_mmx(uint8_t *dst, uint8_t *src,\n                    int stride, int h, int ox, int oy,\n                    int dxx, int dxy, int dyx, int dyy,\n                    int shift, int r, int width, int height)\n{\n    const int w    = 8;\n    const int ix   = ox  >> (16 + shift);\n    const int iy   = oy  >> (16 + shift);\n    const int oxs  = ox  >> 4;\n    const int oys  = oy  >> 4;\n    const int dxxs = dxx >> 4;\n    const int dxys = dxy >> 4;\n    const int dyxs = dyx >> 4;\n    const int dyys = dyy >> 4;\n    const uint16_t r4[4]   = { r, r, r, r };\n    const uint16_t dxy4[4] = { dxys, dxys, dxys, dxys };\n    const uint16_t dyy4[4] = { dyys, dyys, dyys, dyys };\n    const uint64_t shift2  = 2 * shift;\n#define MAX_STRIDE 4096U\n#define MAX_H 8U\n    uint8_t edge_buf[(MAX_H + 1) * MAX_STRIDE];\n    int x, y;\n\n    const int dxw = (dxx - (1 << (16 + shift))) * (w - 1);\n    const int dyh = (dyy - (1 << (16 + shift))) * (h - 1);\n    const int dxh = dxy * (h - 1);\n    const int dyw = dyx * (w - 1);\n    int need_emu  =  (unsigned) ix >= width  - w || width < w ||\n                     (unsigned) iy >= height - h || height< h\n                     ;\n\n    if ( // non-constant fullpel offset (3% of blocks)\n        ((ox ^ (ox + dxw)) | (ox ^ (ox + dxh)) | (ox ^ (ox + dxw + dxh)) |\n         (oy ^ (oy + dyw)) | (oy ^ (oy + dyh)) | (oy ^ (oy + dyw + dyh))) >> (16 + shift) ||\n        // uses more than 16 bits of subpel mv (only at huge resolution)\n        (dxx | dxy | dyx | dyy) & 15 ||\n        (need_emu && (h > MAX_H || stride > MAX_STRIDE))) {\n        // FIXME could still use mmx for some of the rows\n        ff_gmc_c(dst, src, stride, h, ox, oy, dxx, dxy, dyx, dyy,\n                 shift, r, width, height);\n        return;\n    }\n\n    src += ix + iy * stride;\n    if (need_emu) {\n        ff_emulated_edge_mc_8(edge_buf, src, stride, stride, w + 1, h + 1, ix, iy, width, height);\n        src = edge_buf;\n    }\n\n    __asm__ volatile (\n        \"movd         %0, %%mm6         \\n\\t\"\n        \"pxor      %%mm7, %%mm7         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        :: \"r\" (1 << shift));\n\n    for (x = 0; x < w; x += 4) {\n        uint16_t dx4[4] = { oxs - dxys + dxxs * (x + 0),\n                            oxs - dxys + dxxs * (x + 1),\n                            oxs - dxys + dxxs * (x + 2),\n                            oxs - dxys + dxxs * (x + 3) };\n        uint16_t dy4[4] = { oys - dyys + dyxs * (x + 0),\n                            oys - dyys + dyxs * (x + 1),\n                            oys - dyys + dyxs * (x + 2),\n                            oys - dyys + dyxs * (x + 3) };\n\n        for (y = 0; y < h; y++) {\n            __asm__ volatile (\n                \"movq      %0, %%mm4    \\n\\t\"\n                \"movq      %1, %%mm5    \\n\\t\"\n                \"paddw     %2, %%mm4    \\n\\t\"\n                \"paddw     %3, %%mm5    \\n\\t\"\n                \"movq   %%mm4, %0       \\n\\t\"\n                \"movq   %%mm5, %1       \\n\\t\"\n                \"psrlw    $12, %%mm4    \\n\\t\"\n                \"psrlw    $12, %%mm5    \\n\\t\"\n                : \"+m\" (*dx4), \"+m\" (*dy4)\n                : \"m\" (*dxy4), \"m\" (*dyy4));\n\n            __asm__ volatile (\n                \"movq      %%mm6, %%mm2 \\n\\t\"\n                \"movq      %%mm6, %%mm1 \\n\\t\"\n                \"psubw     %%mm4, %%mm2 \\n\\t\"\n                \"psubw     %%mm5, %%mm1 \\n\\t\"\n                \"movq      %%mm2, %%mm0 \\n\\t\"\n                \"movq      %%mm4, %%mm3 \\n\\t\"\n                \"pmullw    %%mm1, %%mm0 \\n\\t\" // (s - dx) * (s - dy)\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // dx * dy\n                \"pmullw    %%mm5, %%mm2 \\n\\t\" // (s - dx) * dy\n                \"pmullw    %%mm4, %%mm1 \\n\\t\" // dx * (s - dy)\n\n                \"movd         %4, %%mm5 \\n\\t\"\n                \"movd         %3, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // src[1, 1] * dx * dy\n                \"pmullw    %%mm4, %%mm2 \\n\\t\" // src[0, 1] * (s - dx) * dy\n\n                \"movd         %2, %%mm5 \\n\\t\"\n                \"movd         %1, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm1 \\n\\t\" // src[1, 0] * dx * (s - dy)\n                \"pmullw    %%mm4, %%mm0 \\n\\t\" // src[0, 0] * (s - dx) * (s - dy)\n                \"paddw        %5, %%mm1 \\n\\t\"\n                \"paddw     %%mm3, %%mm2 \\n\\t\"\n                \"paddw     %%mm1, %%mm0 \\n\\t\"\n                \"paddw     %%mm2, %%mm0 \\n\\t\"\n\n                \"psrlw        %6, %%mm0 \\n\\t\"\n                \"packuswb  %%mm0, %%mm0 \\n\\t\"\n                \"movd      %%mm0, %0    \\n\\t\"\n\n                : \"=m\" (dst[x + y * stride])\n                : \"m\" (src[0]), \"m\" (src[1]),\n                  \"m\" (src[stride]), \"m\" (src[stride + 1]),\n                  \"m\" (*r4), \"m\" (shift2));\n            src += stride;\n        }\n        src += 4 - h * stride;\n    }\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/58cf31cee7a456057f337b3102a03206d833d5e8", "file_name": "libavcodec/x86/mpegvideodsp.c", "vul_type": "cwe-125", "description": "Write a C function named `gmc_mmx` that performs global motion compensation using MMX instructions."}
{"func_name": "ac_circ_buf_pushm", "func_src_before": "int ac_circ_buf_pushm(ac_circ_buf_t *cbuf, const void *buf, u32 count)\n{\n\tif (circ_space_to_end(cbuf) < count) {\n\t\tif (circ_count(cbuf) == 0 && count <= cbuf->size)\n\t\t\tcbuf->head = cbuf->tail = 0;\n\t\telse\n\t\t\treturn -1;\n\t}\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(cbuf->buf.ptr_buf + cbuf->head, buf,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(cbuf->buf.cpy_buf + cbuf->head, buf,\n\t\t       count * cbuf->elem_sz);\n\n\tcbuf->head = (cbuf->head + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "func_src_after": "int ac_circ_buf_pushm(ac_circ_buf_t *cbuf, const void *buf, u32 count)\n{\n\tif (circ_space_to_end(cbuf) < count) {\n\t\tif (circ_count(cbuf) == 0 && count <= cbuf->size)\n\t\t\tcbuf->head = cbuf->tail = 0;\n\t\telse\n\t\t\treturn -1;\n\t}\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(cbuf->buf.ptr_buf + cbuf->head, buf,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(cbuf->buf.cpy_buf + cbuf->head, buf,\n\t\t       (size_t)count * cbuf->elem_sz);\n\n\tcbuf->head = (cbuf->head + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 15, "char_start": 382, "char_end": 415, "line": "\t\t       count * cbuf->elem_sz);\n"}], "added": [{"line_no": 15, "char_start": 382, "char_end": 423, "line": "\t\t       (size_t)count * cbuf->elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 391, "char_end": 399, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to add multiple elements to a circular buffer, returning 0 on success or -1 if there isn't enough space."}
{"func_name": "_get_host_from_connector", "func_src_before": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = 'svcinfo lshost -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "func_src_after": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = ['svcinfo', 'lshost', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve a host name from storage based on connection information, using SSH for commands."}
{"func_name": "jpc_dec_process_siz", "func_src_before": "static int jpc_dec_process_siz(jpc_dec_t *dec, jpc_ms_t *ms)\n{\n\tjpc_siz_t *siz = &ms->parms.siz;\n\tint compno;\n\tint tileno;\n\tjpc_dec_tile_t *tile;\n\tjpc_dec_tcomp_t *tcomp;\n\tint htileno;\n\tint vtileno;\n\tjpc_dec_cmpt_t *cmpt;\n\n\tdec->xstart = siz->xoff;\n\tdec->ystart = siz->yoff;\n\tdec->xend = siz->width;\n\tdec->yend = siz->height;\n\tdec->tilewidth = siz->tilewidth;\n\tdec->tileheight = siz->tileheight;\n\tdec->tilexoff = siz->tilexoff;\n\tdec->tileyoff = siz->tileyoff;\n\tdec->numcomps = siz->numcomps;\n\tif (!(dec->cp = jpc_dec_cp_create(dec->numcomps))) {\n\t\treturn -1;\n\t}\n\n\tif (!(dec->cmpts = jas_alloc2(dec->numcomps, sizeof(jpc_dec_cmpt_t)))) {\n\t\treturn -1;\n\t}\n\n\tfor (compno = 0, cmpt = dec->cmpts; compno < dec->numcomps; ++compno,\n\t  ++cmpt) {\n\t\tcmpt->prec = siz->comps[compno].prec;\n\t\tcmpt->sgnd = siz->comps[compno].sgnd;\n\t\tcmpt->hstep = siz->comps[compno].hsamp;\n\t\tcmpt->vstep = siz->comps[compno].vsamp;\n\t\tcmpt->width = JPC_CEILDIV(dec->xend, cmpt->hstep) -\n\t\t  JPC_CEILDIV(dec->xstart, cmpt->hstep);\n\t\tcmpt->height = JPC_CEILDIV(dec->yend, cmpt->vstep) -\n\t\t  JPC_CEILDIV(dec->ystart, cmpt->vstep);\n\t\tcmpt->hsubstep = 0;\n\t\tcmpt->vsubstep = 0;\n\t}\n\n\tdec->image = 0;\n\n\tdec->numhtiles = JPC_CEILDIV(dec->xend - dec->tilexoff, dec->tilewidth);\n\tdec->numvtiles = JPC_CEILDIV(dec->yend - dec->tileyoff, dec->tileheight);\n\tdec->numtiles = dec->numhtiles * dec->numvtiles;\n\tJAS_DBGLOG(10, (\"numtiles = %d; numhtiles = %d; numvtiles = %d;\\n\",\n\t  dec->numtiles, dec->numhtiles, dec->numvtiles));\n\tif (!(dec->tiles = jas_alloc2(dec->numtiles, sizeof(jpc_dec_tile_t)))) {\n\t\treturn -1;\n\t}\n\n\tfor (tileno = 0, tile = dec->tiles; tileno < dec->numtiles; ++tileno,\n\t  ++tile) {\n\t\thtileno = tileno % dec->numhtiles;\n\t\tvtileno = tileno / dec->numhtiles;\n\t\ttile->realmode = 0;\n\t\ttile->state = JPC_TILE_INIT;\n\t\ttile->xstart = JAS_MAX(dec->tilexoff + htileno * dec->tilewidth,\n\t\t  dec->xstart);\n\t\ttile->ystart = JAS_MAX(dec->tileyoff + vtileno * dec->tileheight,\n\t\t  dec->ystart);\n\t\ttile->xend = JAS_MIN(dec->tilexoff + (htileno + 1) *\n\t\t  dec->tilewidth, dec->xend);\n\t\ttile->yend = JAS_MIN(dec->tileyoff + (vtileno + 1) *\n\t\t  dec->tileheight, dec->yend);\n\t\ttile->numparts = 0;\n\t\ttile->partno = 0;\n\t\ttile->pkthdrstream = 0;\n\t\ttile->pkthdrstreampos = 0;\n\t\ttile->pptstab = 0;\n\t\ttile->cp = 0;\n\t\ttile->pi = 0;\n\t\tif (!(tile->tcomps = jas_alloc2(dec->numcomps,\n\t\t  sizeof(jpc_dec_tcomp_t)))) {\n\t\t\treturn -1;\n\t\t}\n\t\tfor (compno = 0, cmpt = dec->cmpts, tcomp = tile->tcomps;\n\t\t  compno < dec->numcomps; ++compno, ++cmpt, ++tcomp) {\n\t\t\ttcomp->rlvls = 0;\n\t\t\ttcomp->numrlvls = 0;\n\t\t\ttcomp->data = 0;\n\t\t\ttcomp->xstart = JPC_CEILDIV(tile->xstart, cmpt->hstep);\n\t\t\ttcomp->ystart = JPC_CEILDIV(tile->ystart, cmpt->vstep);\n\t\t\ttcomp->xend = JPC_CEILDIV(tile->xend, cmpt->hstep);\n\t\t\ttcomp->yend = JPC_CEILDIV(tile->yend, cmpt->vstep);\n\t\t\ttcomp->tsfb = 0;\n\t\t}\n\t}\n\n\tdec->pkthdrstreams = 0;\n\n\t/* We should expect to encounter other main header marker segments\n\t  or an SOT marker segment next. */\n\tdec->state = JPC_MH;\n\n\treturn 0;\n}", "func_src_after": "static int jpc_dec_process_siz(jpc_dec_t *dec, jpc_ms_t *ms)\n{\n\tjpc_siz_t *siz = &ms->parms.siz;\n\tint compno;\n\tint tileno;\n\tjpc_dec_tile_t *tile;\n\tjpc_dec_tcomp_t *tcomp;\n\tint htileno;\n\tint vtileno;\n\tjpc_dec_cmpt_t *cmpt;\n\tsize_t size;\n\n\tdec->xstart = siz->xoff;\n\tdec->ystart = siz->yoff;\n\tdec->xend = siz->width;\n\tdec->yend = siz->height;\n\tdec->tilewidth = siz->tilewidth;\n\tdec->tileheight = siz->tileheight;\n\tdec->tilexoff = siz->tilexoff;\n\tdec->tileyoff = siz->tileyoff;\n\tdec->numcomps = siz->numcomps;\n\tif (!(dec->cp = jpc_dec_cp_create(dec->numcomps))) {\n\t\treturn -1;\n\t}\n\n\tif (!(dec->cmpts = jas_alloc2(dec->numcomps, sizeof(jpc_dec_cmpt_t)))) {\n\t\treturn -1;\n\t}\n\n\tfor (compno = 0, cmpt = dec->cmpts; compno < dec->numcomps; ++compno,\n\t  ++cmpt) {\n\t\tcmpt->prec = siz->comps[compno].prec;\n\t\tcmpt->sgnd = siz->comps[compno].sgnd;\n\t\tcmpt->hstep = siz->comps[compno].hsamp;\n\t\tcmpt->vstep = siz->comps[compno].vsamp;\n\t\tcmpt->width = JPC_CEILDIV(dec->xend, cmpt->hstep) -\n\t\t  JPC_CEILDIV(dec->xstart, cmpt->hstep);\n\t\tcmpt->height = JPC_CEILDIV(dec->yend, cmpt->vstep) -\n\t\t  JPC_CEILDIV(dec->ystart, cmpt->vstep);\n\t\tcmpt->hsubstep = 0;\n\t\tcmpt->vsubstep = 0;\n\t}\n\n\tdec->image = 0;\n\n\tdec->numhtiles = JPC_CEILDIV(dec->xend - dec->tilexoff, dec->tilewidth);\n\tdec->numvtiles = JPC_CEILDIV(dec->yend - dec->tileyoff, dec->tileheight);\n\tif (!jas_safe_size_mul(dec->numhtiles, dec->numvtiles, &size)) {\n\t\treturn -1;\n\t}\n\tdec->numtiles = size;\n\tJAS_DBGLOG(10, (\"numtiles = %d; numhtiles = %d; numvtiles = %d;\\n\",\n\t  dec->numtiles, dec->numhtiles, dec->numvtiles));\n\tif (!(dec->tiles = jas_alloc2(dec->numtiles, sizeof(jpc_dec_tile_t)))) {\n\t\treturn -1;\n\t}\n\n\tfor (tileno = 0, tile = dec->tiles; tileno < dec->numtiles; ++tileno,\n\t  ++tile) {\n\t\thtileno = tileno % dec->numhtiles;\n\t\tvtileno = tileno / dec->numhtiles;\n\t\ttile->realmode = 0;\n\t\ttile->state = JPC_TILE_INIT;\n\t\ttile->xstart = JAS_MAX(dec->tilexoff + htileno * dec->tilewidth,\n\t\t  dec->xstart);\n\t\ttile->ystart = JAS_MAX(dec->tileyoff + vtileno * dec->tileheight,\n\t\t  dec->ystart);\n\t\ttile->xend = JAS_MIN(dec->tilexoff + (htileno + 1) *\n\t\t  dec->tilewidth, dec->xend);\n\t\ttile->yend = JAS_MIN(dec->tileyoff + (vtileno + 1) *\n\t\t  dec->tileheight, dec->yend);\n\t\ttile->numparts = 0;\n\t\ttile->partno = 0;\n\t\ttile->pkthdrstream = 0;\n\t\ttile->pkthdrstreampos = 0;\n\t\ttile->pptstab = 0;\n\t\ttile->cp = 0;\n\t\ttile->pi = 0;\n\t\tif (!(tile->tcomps = jas_alloc2(dec->numcomps,\n\t\t  sizeof(jpc_dec_tcomp_t)))) {\n\t\t\treturn -1;\n\t\t}\n\t\tfor (compno = 0, cmpt = dec->cmpts, tcomp = tile->tcomps;\n\t\t  compno < dec->numcomps; ++compno, ++cmpt, ++tcomp) {\n\t\t\ttcomp->rlvls = 0;\n\t\t\ttcomp->numrlvls = 0;\n\t\t\ttcomp->data = 0;\n\t\t\ttcomp->xstart = JPC_CEILDIV(tile->xstart, cmpt->hstep);\n\t\t\ttcomp->ystart = JPC_CEILDIV(tile->ystart, cmpt->vstep);\n\t\t\ttcomp->xend = JPC_CEILDIV(tile->xend, cmpt->hstep);\n\t\t\ttcomp->yend = JPC_CEILDIV(tile->yend, cmpt->vstep);\n\t\t\ttcomp->tsfb = 0;\n\t\t}\n\t}\n\n\tdec->pkthdrstreams = 0;\n\n\t/* We should expect to encounter other main header marker segments\n\t  or an SOT marker segment next. */\n\tdec->state = JPC_MH;\n\n\treturn 0;\n}", "commit_link": "github.com/mdadams/jasper/commit/d91198abd00fc435a397fe6bad906a4c1748e9cf", "file_name": "src/libjasper/jpc/jpc_dec.c", "vul_type": "cwe-190", "description": "Write a C function named `jpc_dec_process_siz` that initializes decoder settings based on image size parameters."}
{"func_name": "_port_conf_generator", "func_src_before": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = '%s -delim !' % cmd\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "func_src_after": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = cmd + ['-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function named `_port_conf_generator` that takes a command, executes it via SSH, and yields parsed port configuration data."}
{"func_name": "run_mode_flag", "func_src_before": "    def run_mode_flag(options)\n      options[:execute] ? ' --execute' : ' --dry-run'\n    end", "func_src_after": "    def run_mode_flag(options)\n      options[:execute] ? '--execute' : '--dry-run'\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 85, "line": "      options[:execute] ? ' --execute' : ' --dry-run'\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 83, "line": "      options[:execute] ? '--execute' : '--dry-run'\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 59, "chars": " "}, {"char_start": 73, "char_end": 74, "chars": " "}], "added": []}, "commit_link": "github.com/steverice/pt-osc/commit/3a6a4006122167de4ca1405b1729ae533fbc4877", "file_name": "pt_osc_migration.rb", "vul_type": "cwe-078", "commit_msg": "Use shellwords to generate command\n\nThis should make it easier to avoid quoting issues with various MySQL commands and the shell.\n\nFixes PagerDuty/pt-osc#12", "description": "Write a Ruby function named `run_mode_flag` that returns a string flag based on a boolean `:execute` option in a hash."}
{"func_name": "load_data", "func_src_before": "def load_data(path):\n    \"\"\"Given path to a file, load data from it.\"\"\"\n    ext = os.path.splitext(path)[-1]\n    loader = None\n    if ext in {'.yml', '.yaml'}:\n        loader = yaml\n        if yaml is None:\n            req_missing(['yaml'], 'use YAML data files')\n            return {}\n    elif ext in {'.json', '.js'}:\n        loader = json\n    elif ext in {'.toml', '.tml'}:\n        if toml is None:\n            req_missing(['toml'], 'use TOML data files')\n            return {}\n        loader = toml\n    if loader is None:\n        return\n    with io.open(path, 'r', encoding='utf8') as inf:\n        return loader.load(inf)", "func_src_after": "def load_data(path):\n    \"\"\"Given path to a file, load data from it.\"\"\"\n    ext = os.path.splitext(path)[-1]\n    loader = None\n    function = 'load'\n    if ext in {'.yml', '.yaml'}:\n        loader = yaml\n        function = 'safe_load'\n        if yaml is None:\n            req_missing(['yaml'], 'use YAML data files')\n            return {}\n    elif ext in {'.json', '.js'}:\n        loader = json\n    elif ext in {'.toml', '.tml'}:\n        if toml is None:\n            req_missing(['toml'], 'use TOML data files')\n            return {}\n        loader = toml\n    if loader is None:\n        return\n    with io.open(path, 'r', encoding='utf8') as inf:\n        return getattr(loader, function)(inf)", "line_changes": {"deleted": [{"line_no": 20, "char_start": 594, "char_end": 625, "line": "        return loader.load(inf)\n"}], "added": [{"line_no": 5, "char_start": 127, "char_end": 149, "line": "    function = 'load'\n"}, {"line_no": 8, "char_start": 204, "char_end": 235, "line": "        function = 'safe_load'\n"}, {"line_no": 22, "char_start": 647, "char_end": 692, "line": "        return getattr(loader, function)(inf)\n"}]}, "char_changes": {"deleted": [{"char_start": 609, "char_end": 620, "chars": "loader.load"}], "added": [{"char_start": 127, "char_end": 149, "chars": "    function = 'load'\n"}, {"char_start": 204, "char_end": 235, "chars": "        function = 'safe_load'\n"}, {"char_start": 662, "char_end": 687, "chars": "getattr(loader, function)"}]}, "commit_link": "github.com/xuhdev/nikola/commit/1d507071e6a60523d8bda4ae401d309b3bcd27d7", "file_name": "utils.py", "vul_type": "cwe-502", "commit_msg": "Use safe_load for loading YAML\n\nSigned-off-by: Chris Warrick <kwpolska@gmail.com>", "parent_commit": "2d25ac7de933000fd44167743ca8293709debb24", "description": "Write a Python function to load data from a file, supporting multiple file formats based on the file extension."}
{"func_name": "gdi_Bitmap_Decompress", "func_src_before": "static BOOL gdi_Bitmap_Decompress(rdpContext* context, rdpBitmap* bitmap,\n                                  const BYTE* pSrcData, UINT32 DstWidth, UINT32 DstHeight,\n                                  UINT32 bpp, UINT32 length, BOOL compressed,\n                                  UINT32 codecId)\n{\n\tUINT32 SrcSize = length;\n\trdpGdi* gdi = context->gdi;\n\tbitmap->compressed = FALSE;\n\tbitmap->format = gdi->dstFormat;\n\tbitmap->length = DstWidth * DstHeight * GetBytesPerPixel(bitmap->format);\n\tbitmap->data = (BYTE*) _aligned_malloc(bitmap->length, 16);\n\n\tif (!bitmap->data)\n\t\treturn FALSE;\n\n\tif (compressed)\n\t{\n\t\tif (bpp < 32)\n\t\t{\n\t\t\tif (!interleaved_decompress(context->codecs->interleaved,\n\t\t\t                            pSrcData, SrcSize,\n\t\t\t                            DstWidth, DstHeight,\n\t\t\t                            bpp,\n\t\t\t                            bitmap->data, bitmap->format,\n\t\t\t                            0, 0, 0, DstWidth, DstHeight,\n\t\t\t                            &gdi->palette))\n\t\t\t\treturn FALSE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (!planar_decompress(context->codecs->planar, pSrcData, SrcSize,\n\t\t\t                       DstWidth, DstHeight,\n\t\t\t                       bitmap->data, bitmap->format, 0, 0, 0,\n\t\t\t                       DstWidth, DstHeight, TRUE))\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tconst UINT32 SrcFormat = gdi_get_pixel_format(bpp);\n\t\tconst size_t sbpp = GetBytesPerPixel(SrcFormat);\n\t\tconst size_t dbpp = GetBytesPerPixel(bitmap->format);\n\n\t\tif ((sbpp == 0) || (dbpp == 0))\n\t\t\treturn FALSE;\n\t\telse\n\t\t{\n\t\t\tconst size_t dstSize = SrcSize * dbpp / sbpp;\n\n\t\t\tif (dstSize  < bitmap->length)\n\t\t\t\treturn FALSE;\n\t\t}\n\n\t\tif (!freerdp_image_copy(bitmap->data, bitmap->format, 0, 0, 0,\n\t\t                        DstWidth, DstHeight, pSrcData, SrcFormat,\n\t\t                        0, 0, 0, &gdi->palette, FREERDP_FLIP_VERTICAL))\n\t\t\treturn FALSE;\n\t}\n\n\treturn TRUE;\n}", "func_src_after": "static BOOL gdi_Bitmap_Decompress(rdpContext* context, rdpBitmap* bitmap,\n                                  const BYTE* pSrcData, UINT32 DstWidth, UINT32 DstHeight,\n                                  UINT32 bpp, UINT32 length, BOOL compressed,\n                                  UINT32 codecId)\n{\n\tUINT32 SrcSize = length;\n\trdpGdi* gdi = context->gdi;\n\tUINT32 size = DstWidth * DstHeight;\n\tbitmap->compressed = FALSE;\n\tbitmap->format = gdi->dstFormat;\n\n\tif ((GetBytesPerPixel(bitmap->format) == 0) ||\n\t    (DstWidth == 0) || (DstHeight == 0) || (DstWidth > UINT32_MAX / DstHeight) ||\n\t    (size > (UINT32_MAX / GetBytesPerPixel(bitmap->format))))\n\t\treturn FALSE;\n\n\tsize *= GetBytesPerPixel(bitmap->format);\n\tbitmap->length = size;\n\tbitmap->data = (BYTE*) _aligned_malloc(bitmap->length, 16);\n\n\tif (!bitmap->data)\n\t\treturn FALSE;\n\n\tif (compressed)\n\t{\n\t\tif (bpp < 32)\n\t\t{\n\t\t\tif (!interleaved_decompress(context->codecs->interleaved,\n\t\t\t                            pSrcData, SrcSize,\n\t\t\t                            DstWidth, DstHeight,\n\t\t\t                            bpp,\n\t\t\t                            bitmap->data, bitmap->format,\n\t\t\t                            0, 0, 0, DstWidth, DstHeight,\n\t\t\t                            &gdi->palette))\n\t\t\t\treturn FALSE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (!planar_decompress(context->codecs->planar, pSrcData, SrcSize,\n\t\t\t                       DstWidth, DstHeight,\n\t\t\t                       bitmap->data, bitmap->format, 0, 0, 0,\n\t\t\t                       DstWidth, DstHeight, TRUE))\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tconst UINT32 SrcFormat = gdi_get_pixel_format(bpp);\n\t\tconst size_t sbpp = GetBytesPerPixel(SrcFormat);\n\t\tconst size_t dbpp = GetBytesPerPixel(bitmap->format);\n\n\t\tif ((sbpp == 0) || (dbpp == 0))\n\t\t\treturn FALSE;\n\t\telse\n\t\t{\n\t\t\tconst size_t dstSize = SrcSize * dbpp / sbpp;\n\n\t\t\tif (dstSize  < bitmap->length)\n\t\t\t\treturn FALSE;\n\t\t}\n\n\t\tif (!freerdp_image_copy(bitmap->data, bitmap->format, 0, 0, 0,\n\t\t                        DstWidth, DstHeight, pSrcData, SrcFormat,\n\t\t                        0, 0, 0, &gdi->palette, FREERDP_FLIP_VERTICAL))\n\t\t\treturn FALSE;\n\t}\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/09b9d4f1994a674c4ec85b4947aa656eda1aed8a", "file_name": "libfreerdp/gdi/graphics.c", "vul_type": "cwe-190", "description": "Write a C function named `gdi_Bitmap_Decompress` that decompresses a bitmap image in a remote desktop protocol context."}
{"func_name": "(anonymous)", "func_src_before": "\t\texec(binPath + ' -v -', function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "func_src_after": "\t\texecFile(binPath, ['-v', '-'], function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 59, "line": "\t\texec(binPath + ' -v -', function (err, stdout, stderr) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 66, "line": "\t\texecFile(binPath, ['-v', '-'], function (err, stdout, stderr) {\n"}]}, "char_changes": {"deleted": [{"char_start": 14, "char_end": 22, "chars": " + ' -v "}], "added": [{"char_start": 6, "char_end": 10, "chars": "File"}, {"char_start": 18, "char_end": 28, "chars": ", ['-v', '"}, {"char_start": 30, "char_end": 31, "chars": "]"}]}, "commit_link": "github.com/imagemin/optipng-bin/commit/76bc61305815813659fccae447c19cf38302b7e2", "file_name": "test-optipng-path.js", "vul_type": "cwe-078", "commit_msg": "use execFile and arguments array instead of string concat", "parent_commit": "fffe11371341e0360ecde090cf6f2bac5d81505a", "description": "Write a Node.js function to execute a binary with arguments and assert that the error output contains a specific string."}
{"func_name": "write_keyval", "func_src_before": "    let write_keyval = function(key, val) {\n        let query = \"INSERT INTO tb_events (uid, key, value) VALUES \"\n                  + \"(\"\n                  + \"'\" + event.uid + \"', \"\n                  + \"'\" + key + \"', \"\n                  + \"'\" + val + \"'\"\n                  + \" );\";\n        obj.db.run(query);\n    };", "func_src_after": "    let write_keyval = function(key, val) {\n        obj.db.run(\n          \"INSERT INTO tb_events (uid, key, value) VALUES ( ? , ? , ? );\",\n          [event.uid, key, val]\n        );\n    };", "line_changes": {"deleted": [{"line_no": 2, "char_start": 44, "char_end": 114, "line": "        let query = \"INSERT INTO tb_events (uid, key, value) VALUES \"\n"}, {"line_no": 3, "char_start": 114, "char_end": 138, "line": "                  + \"(\"\n"}, {"line_no": 4, "char_start": 138, "char_end": 182, "line": "                  + \"'\" + event.uid + \"', \"\n"}, {"line_no": 5, "char_start": 182, "char_end": 220, "line": "                  + \"'\" + key + \"', \"\n"}, {"line_no": 6, "char_start": 220, "char_end": 256, "line": "                  + \"'\" + val + \"'\"\n"}, {"line_no": 7, "char_start": 256, "char_end": 283, "line": "                  + \" );\";\n"}, {"line_no": 8, "char_start": 283, "char_end": 310, "line": "        obj.db.run(query);\n"}], "added": [{"line_no": 2, "char_start": 44, "char_end": 64, "line": "        obj.db.run(\n"}, {"line_no": 3, "char_start": 64, "char_end": 139, "line": "          \"INSERT INTO tb_events (uid, key, value) VALUES ( ? , ? , ? );\",\n"}, {"line_no": 4, "char_start": 139, "char_end": 171, "line": "          [event.uid, key, val]\n"}, {"line_no": 5, "char_start": 171, "char_end": 182, "line": "        );\n"}]}, "char_changes": {"deleted": [{"char_start": 52, "char_end": 63, "chars": "let query ="}, {"char_start": 112, "char_end": 307, "chars": "\"\n                  + \"(\"\n                  + \"'\" + event.uid + \"', \"\n                  + \"'\" + key + \"', \"\n                  + \"'\" + val + \"'\"\n                  + \" );\";\n        obj.db.run(query"}], "added": [{"char_start": 52, "char_end": 73, "chars": "obj.db.run(\n         "}, {"char_start": 122, "char_end": 179, "chars": "( ? , ? , ? );\",\n          [event.uid, key, val]\n        "}]}, "commit_link": "github.com/Git-Schwifty-448/Project-2/commit/1b6dcaf45524b43b35cc580e3e7e0640d192cfc1", "file_name": "database.js", "vul_type": "cwe-089", "commit_msg": "Fix SQL injections (failed on ')", "description": "Write a JavaScript function that inserts a key-value pair into a database table named 'tb_events' using an 'event.uid'."}
{"func_name": "_create_database", "func_src_before": "    @staticmethod\n    def _create_database(engine: \"Engine\", db: Text):\n        \"\"\"Create database `db` on `engine` if it does not exist.\"\"\"\n\n        import psycopg2\n\n        conn = engine.connect()\n\n        cursor = conn.connection.cursor()\n        cursor.execute(\"COMMIT\")\n        cursor.execute(f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{db}'\")\n        exists = cursor.fetchone()\n        if not exists:\n            try:\n                cursor.execute(f\"CREATE DATABASE {db}\")\n            except psycopg2.IntegrityError as e:\n                logger.error(f\"Could not create database '{db}': {e}\")\n\n        cursor.close()\n        conn.close()", "func_src_after": "    @staticmethod\n    def _create_database(engine: \"Engine\", db: Text):\n        \"\"\"Create database `db` on `engine` if it does not exist.\"\"\"\n\n        import psycopg2\n\n        conn = engine.connect()\n\n        cursor = conn.connection.cursor()\n        cursor.execute(\"COMMIT\")\n        cursor.execute(\n            f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = ?\", (db,)  # nosec\n        )\n        exists = cursor.fetchone()\n        if not exists:\n            try:\n                cursor.execute(f\"CREATE DATABASE {db}\")\n            except psycopg2.IntegrityError as e:\n                logger.error(f\"Could not create database '{db}': {e}\")\n\n        cursor.close()\n        conn.close()", "line_changes": {"deleted": [{"line_no": 11, "char_start": 275, "char_end": 362, "line": "        cursor.execute(f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{db}'\")\n"}], "added": [{"line_no": 11, "char_start": 275, "char_end": 299, "line": "        cursor.execute(\n"}, {"line_no": 12, "char_start": 299, "char_end": 385, "line": "            f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = ?\", (db,)  # nosec\n"}, {"line_no": 13, "char_start": 385, "char_end": 395, "line": "        )\n"}]}, "char_changes": {"deleted": [{"char_start": 353, "char_end": 360, "chars": "'{db}'\""}], "added": [{"char_start": 298, "char_end": 311, "chars": "\n            "}, {"char_start": 366, "char_end": 393, "chars": "?\", (db,)  # nosec\n        "}]}, "commit_link": "github.com/RasaHQ/rasa_nlu/commit/d68ec7bde34463cc62d9319db4adfd1dff0361cf", "file_name": "tracker_store.py", "vul_type": "cwe-089", "commit_msg": "fix tracker store SQL injection possibility", "parent_commit": "251c10208f9b599ccd511c3ff8d0b41db972a8f9", "description": "Write a Python function to check for the existence of a database and create it if it doesn't exist using psycopg2."}
{"func_name": "mode_close", "func_src_before": "    def mode_close(self, request):\n        \"\"\"\n        This is called by render_POST when the client is signalling\n        that it is about to be closed.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        try:\n            sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n            sess.sessionhandler.disconnect(sess)\n        except IndexError:\n            self.client_disconnect(csessid)\n        return '\"\"'", "func_src_after": "    def mode_close(self, request):\n        \"\"\"\n        This is called by render_POST when the client is signalling\n        that it is about to be closed.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        try:\n            sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n            sess.sessionhandler.disconnect(sess)\n        except IndexError:\n            self.client_disconnect(csessid)\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_close` that handles a POST request to disconnect a client session using a session ID."}
{"func_name": "DecodePSDPixels", "func_src_before": "static ssize_t DecodePSDPixels(const size_t number_compact_pixels,\n  const unsigned char *compact_pixels,const ssize_t depth,\n  const size_t number_pixels,unsigned char *pixels)\n{\n#define CheckNumberCompactPixels \\\n  if (packets == 0) \\\n    return(i); \\\n  packets--\n\n#define CheckNumberPixels(count) \\\n  if (((ssize_t) i + count) > (ssize_t) number_pixels) \\\n    return(i); \\\n  i+=count\n\n  int\n    pixel;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    length;\n\n  ssize_t\n    packets;\n\n  packets=(ssize_t) number_compact_pixels;\n  for (i=0; (packets > 1) && (i < (ssize_t) number_pixels); )\n  {\n    packets--;\n    length=(size_t) (*compact_pixels++);\n    if (length == 128)\n      continue;\n    if (length > 128)\n      {\n        length=256-length+1;\n        CheckNumberCompactPixels;\n        pixel=(*compact_pixels++);\n        for (j=0; j < (ssize_t) length; j++)\n        {\n          switch (depth)\n          {\n            case 1:\n            {\n              CheckNumberPixels(8);\n              *pixels++=(pixel >> 7) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 6) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 5) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 4) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 3) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 2) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 1) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 0) & 0x01 ? 0U : 255U;\n              break;\n            }\n            case 2:\n            {\n              CheckNumberPixels(4);\n              *pixels++=(unsigned char) ((pixel >> 6) & 0x03);\n              *pixels++=(unsigned char) ((pixel >> 4) & 0x03);\n              *pixels++=(unsigned char) ((pixel >> 2) & 0x03);\n              *pixels++=(unsigned char) ((pixel & 0x03) & 0x03);\n              break;\n            }\n            case 4:\n            {\n              CheckNumberPixels(2);\n              *pixels++=(unsigned char) ((pixel >> 4) & 0xff);\n              *pixels++=(unsigned char) ((pixel & 0x0f) & 0xff);\n              break;\n            }\n            default:\n            {\n              CheckNumberPixels(1);\n              *pixels++=(unsigned char) pixel;\n              break;\n            }\n          }\n        }\n        continue;\n      }\n    length++;\n    for (j=0; j < (ssize_t) length; j++)\n    {\n      switch (depth)\n      {\n        case 1:\n        {\n          CheckNumberPixels(8);\n          *pixels++=(*compact_pixels >> 7) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 6) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 5) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 4) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 3) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 2) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 1) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 0) & 0x01 ? 0U : 255U;\n          break;\n        }\n        case 2:\n        {\n          CheckNumberPixels(4);\n          *pixels++=(*compact_pixels >> 6) & 0x03;\n          *pixels++=(*compact_pixels >> 4) & 0x03;\n          *pixels++=(*compact_pixels >> 2) & 0x03;\n          *pixels++=(*compact_pixels & 0x03) & 0x03;\n          break;\n        }\n        case 4:\n        {\n          CheckNumberPixels(2);\n          *pixels++=(*compact_pixels >> 4) & 0xff;\n          *pixels++=(*compact_pixels & 0x0f) & 0xff;\n          break;\n        }\n        default:\n        {\n          CheckNumberPixels(1);\n          *pixels++=(*compact_pixels);\n          break;\n        }\n      }\n      CheckNumberCompactPixels;\n      compact_pixels++;\n    }\n  }\n  return(i);\n}", "func_src_after": "static ssize_t DecodePSDPixels(const size_t number_compact_pixels,\n  const unsigned char *compact_pixels,const ssize_t depth,\n  const size_t number_pixels,unsigned char *pixels)\n{\n#define CheckNumberCompactPixels \\\n  if (packets == 0) \\\n    return(i); \\\n  packets--\n\n#define CheckNumberPixels(count) \\\n  if (((ssize_t) i + count) > (ssize_t) number_pixels) \\\n    return(i); \\\n  i+=count\n\n  int\n    pixel;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    length;\n\n  ssize_t\n    packets;\n\n  packets=(ssize_t) number_compact_pixels;\n  for (i=0; (packets > 1) && (i < (ssize_t) number_pixels); )\n  {\n    packets--;\n    length=(size_t) (*compact_pixels++);\n    if (length == 128)\n      continue;\n    if (length > 128)\n      {\n        length=256-length+1;\n        CheckNumberCompactPixels;\n        pixel=(*compact_pixels++);\n        for (j=0; j < (ssize_t) length; j++)\n        {\n          switch (depth)\n          {\n            case 1:\n            {\n              CheckNumberPixels(8);\n              *pixels++=(pixel >> 7) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 6) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 5) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 4) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 3) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 2) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 1) & 0x01 ? 0U : 255U;\n              *pixels++=(pixel >> 0) & 0x01 ? 0U : 255U;\n              break;\n            }\n            case 2:\n            {\n              CheckNumberPixels(4);\n              *pixels++=(unsigned char) ((pixel >> 6) & 0x03);\n              *pixels++=(unsigned char) ((pixel >> 4) & 0x03);\n              *pixels++=(unsigned char) ((pixel >> 2) & 0x03);\n              *pixels++=(unsigned char) ((pixel & 0x03) & 0x03);\n              break;\n            }\n            case 4:\n            {\n              CheckNumberPixels(2);\n              *pixels++=(unsigned char) ((pixel >> 4) & 0xff);\n              *pixels++=(unsigned char) ((pixel & 0x0f) & 0xff);\n              break;\n            }\n            default:\n            {\n              CheckNumberPixels(1);\n              *pixels++=(unsigned char) pixel;\n              break;\n            }\n          }\n        }\n        continue;\n      }\n    length++;\n    for (j=0; j < (ssize_t) length; j++)\n    {\n      CheckNumberCompactPixels;\n      switch (depth)\n      {\n        case 1:\n        {\n          CheckNumberPixels(8);\n          *pixels++=(*compact_pixels >> 7) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 6) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 5) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 4) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 3) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 2) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 1) & 0x01 ? 0U : 255U;\n          *pixels++=(*compact_pixels >> 0) & 0x01 ? 0U : 255U;\n          break;\n        }\n        case 2:\n        {\n          CheckNumberPixels(4);\n          *pixels++=(*compact_pixels >> 6) & 0x03;\n          *pixels++=(*compact_pixels >> 4) & 0x03;\n          *pixels++=(*compact_pixels >> 2) & 0x03;\n          *pixels++=(*compact_pixels & 0x03) & 0x03;\n          break;\n        }\n        case 4:\n        {\n          CheckNumberPixels(2);\n          *pixels++=(*compact_pixels >> 4) & 0xff;\n          *pixels++=(*compact_pixels & 0x0f) & 0xff;\n          break;\n        }\n        default:\n        {\n          CheckNumberPixels(1);\n          *pixels++=(*compact_pixels);\n          break;\n        }\n      }\n      compact_pixels++;\n    }\n  }\n  return(i);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/30eec879c8b446b0ea9a3bb0da1a441cc8482bc4", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function to decode a run-length encoded pixel data array into an expanded pixel array, considering different bit depths."}
{"func_name": "_execute_command_and_parse_attributes", "func_src_before": "    def _execute_command_and_parse_attributes(self, ssh_cmd):\n        \"\"\"Execute command on the Storwize/SVC and parse attributes.\n\n        Exception is raised if the information from the system\n        can not be obtained.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _execute_command_and_parse_attributes: '\n                    ' command %s') % ssh_cmd)\n\n        try:\n            out, err = self._run_ssh(ssh_cmd)\n        except exception.ProcessExecutionError as e:\n            # Didn't get details from the storage, return None\n            LOG.error(_('CLI Exception output:\\n command: %(cmd)s\\n '\n                        'stdout: %(out)s\\n stderr: %(err)s') %\n                      {'cmd': ssh_cmd,\n                       'out': e.stdout,\n                       'err': e.stderr})\n            return None\n\n        self._assert_ssh_return(len(out),\n                                '_execute_command_and_parse_attributes',\n                                ssh_cmd, out, err)\n        attributes = {}\n        for attrib_line in out.split('\\n'):\n            # If '!' not found, return the string and two empty strings\n            attrib_name, foo, attrib_value = attrib_line.partition('!')\n            if attrib_name is not None and len(attrib_name.strip()):\n                attributes[attrib_name] = attrib_value\n\n        LOG.debug(_('leave: _execute_command_and_parse_attributes:\\n'\n                    'command: %(cmd)s\\n'\n                    'attributes: %(attr)s')\n                  % {'cmd': ssh_cmd,\n                     'attr': str(attributes)})\n\n        return attributes", "func_src_after": "    def _execute_command_and_parse_attributes(self, ssh_cmd):\n        \"\"\"Execute command on the Storwize/SVC and parse attributes.\n\n        Exception is raised if the information from the system\n        can not be obtained.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _execute_command_and_parse_attributes: '\n                    ' command %s') % str(ssh_cmd))\n\n        try:\n            out, err = self._run_ssh(ssh_cmd)\n        except exception.ProcessExecutionError as e:\n            # Didn't get details from the storage, return None\n            LOG.error(_('CLI Exception output:\\n command: %(cmd)s\\n '\n                        'stdout: %(out)s\\n stderr: %(err)s') %\n                      {'cmd': ssh_cmd,\n                       'out': e.stdout,\n                       'err': e.stderr})\n            return None\n\n        self._assert_ssh_return(len(out),\n                                '_execute_command_and_parse_attributes',\n                                ssh_cmd, out, err)\n        attributes = {}\n        for attrib_line in out.split('\\n'):\n            # If '!' not found, return the string and two empty strings\n            attrib_name, foo, attrib_value = attrib_line.partition('!')\n            if attrib_name is not None and len(attrib_name.strip()):\n                attributes[attrib_name] = attrib_value\n\n        LOG.debug(_('leave: _execute_command_and_parse_attributes:\\n'\n                    'command: %(cmd)s\\n'\n                    'attributes: %(attr)s')\n                  % {'cmd': str(ssh_cmd),\n                     'attr': str(attributes)})\n\n        return attributes", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "In Python, write a function to execute an SSH command, parse the output into attributes, and handle any execution errors."}
{"func_name": "getAuthenticatedBasket", "func_src_before": "func getAuthenticatedBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) (string, Basket) {\n\tname := ps.ByName(\"basket\")\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\t// maybe custom header, e.g. basket_key, basket_token\n\t\tif token := r.Header.Get(\"Authorization\"); basket.Authorize(token) || token == serverConfig.MasterToken {\n\t\t\treturn name, basket\n\t\t}\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n\n\treturn \"\", nil\n}", "func_src_after": "func getAuthenticatedBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) (string, Basket) {\n\tname := ps.ByName(\"basket\")\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\t// maybe custom header, e.g. basket_key, basket_token\n\t\tif token := r.Header.Get(\"Authorization\"); basket.Authorize(token) || token == serverConfig.MasterToken {\n\t\t\treturn name, basket\n\t\t}\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n\n\treturn \"\", nil\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 179, "char_end": 303, "line": "\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}], "added": [{"line_no": 4, "char_start": 179, "char_end": 301, "line": "\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}]}, "char_changes": {"deleted": [{"char_start": 217, "char_end": 220, "chars": "[\"+"}, {"char_start": 224, "char_end": 227, "chars": "+\"]"}], "added": [{"char_start": 217, "char_end": 221, "chars": "the "}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go function to authenticate and retrieve a basket by name from a database, handling HTTP requests and responses."}
{"func_name": "get_lines", "func_src_before": "def get_lines(command: str) -> List[str]:\n    \"\"\"\n    Run a command and return lines of output\n\n    :param str command: the command to run\n    :returns: list of whitespace-stripped lines output by command\n    \"\"\"\n    stdout = get_output(command)\n    return [line.strip().decode() for line in stdout.splitlines()]", "func_src_after": "def get_lines(command: List[str]) -> List[str]:\n    \"\"\"\n    Run a command and return lines of output\n\n    :param str command: the command to run\n    :returns: list of whitespace-stripped lines output by command\n    \"\"\"\n    stdout = get_output(command)\n    return [line.strip() for line in stdout.splitlines()]", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "isort/hooks.py", "vul_type": "cwe-078", "description": "Write a Python function named `get_lines` that executes a given command and returns the output as a list of stripped strings."}
{"func_name": "index", "func_src_before": "  def index\n    authorize! :posts, @post_type\n    per_page = current_site.admin_per_page\n    posts_all = @post_type.posts.eager_load(:parent, :post_type)\n    if params[:taxonomy].present? && params[:taxonomy_id].present?\n      if params[:taxonomy] == \"category\"\n        cat_owner = current_site.full_categories.find(params[:taxonomy_id]).decorate\n        posts_all = cat_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.category\"), @post_type.the_admin_url(\"category\")\n        add_breadcrumb cat_owner.the_title, cat_owner.the_edit_url\n      end\n\n      if params[:taxonomy] == \"post_tag\"\n        tag_owner = current_site.post_tags.find(params[:taxonomy_id]).decorate\n        posts_all = tag_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.tags\"), @post_type.the_admin_url(\"tag\")\n        add_breadcrumb tag_owner.the_title, tag_owner.the_edit_url\n      end\n    end\n\n    if params[:q].present?\n      posts_all = posts_all.where(params[:q].split(\" \").map{|text| \"#{CamaleonCms::Post.table_name}.title LIKE '%#{text}%'\" }.join(\" OR \"))\n    end\n\n    @posts = posts_all\n    params[:s] = 'published' unless params[:s].present?\n    @lists_tab = params[:s]\n    add_breadcrumb I18n.t(\"camaleon_cms.admin.post_type.#{params[:s]}\") if params[:s].present?\n    case params[:s]\n      when \"published\", \"pending\", \"draft\", \"trash\"\n        @posts = @posts.where(status:  params[:s])\n\n      when \"all\"\n        @posts = @posts.no_trash\n    end", "func_src_after": "  def index\n    authorize! :posts, @post_type\n    per_page = current_site.admin_per_page\n    posts_all = @post_type.posts.eager_load(:parent, :post_type)\n    if params[:taxonomy].present? && params[:taxonomy_id].present?\n      if params[:taxonomy] == \"category\"\n        cat_owner = current_site.full_categories.find(params[:taxonomy_id]).decorate\n        posts_all = cat_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.category\"), @post_type.the_admin_url(\"category\")\n        add_breadcrumb cat_owner.the_title, cat_owner.the_edit_url\n      end\n\n      if params[:taxonomy] == \"post_tag\"\n        tag_owner = current_site.post_tags.find(params[:taxonomy_id]).decorate\n        posts_all = tag_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.tags\"), @post_type.the_admin_url(\"tag\")\n        add_breadcrumb tag_owner.the_title, tag_owner.the_edit_url\n      end\n    end\n\n    if params[:q].present?\n      posts_all = posts_all.where(\"#{CamaleonCms::Post.table_name}.title LIKE ?\", \"%#{params[:q]}%\")\n      puts \"@@@@@@@@@@@@@@@@@@@@@@@@: #{posts_all.to_sql}\"\n    end\n\n    @posts = posts_all\n    params[:s] = 'published' unless params[:s].present?\n    @lists_tab = params[:s]\n    add_breadcrumb I18n.t(\"camaleon_cms.admin.post_type.#{params[:s]}\") if params[:s].present?\n    case params[:s]\n      when \"published\", \"pending\", \"draft\", \"trash\"\n        @posts = @posts.where(status:  params[:s])\n\n      when \"all\"\n        @posts = @posts.no_trash\n    end", "line_changes": {"deleted": [{"line_no": 22, "char_start": 929, "char_end": 1069, "line": "      posts_all = posts_all.where(params[:q].split(\" \").map{|text| \"#{CamaleonCms::Post.table_name}.title LIKE '%#{text}%'\" }.join(\" OR \"))\n"}], "added": [{"line_no": 22, "char_start": 929, "char_end": 1030, "line": "      posts_all = posts_all.where(\"#{CamaleonCms::Post.table_name}.title LIKE ?\", \"%#{params[:q]}%\")\n"}, {"line_no": 23, "char_start": 1030, "char_end": 1089, "line": "      puts \"@@@@@@@@@@@@@@@@@@@@@@@@: #{posts_all.to_sql}\"\n"}]}, "char_changes": {"deleted": [{"char_start": 963, "char_end": 996, "chars": "params[:q].split(\" \").map{|text| "}, {"char_start": 1040, "char_end": 1068, "chars": "'%#{text}%'\" }.join(\" OR \"))"}], "added": [{"char_start": 1007, "char_end": 1088, "chars": "?\", \"%#{params[:q]}%\")\n      puts \"@@@@@@@@@@@@@@@@@@@@@@@@: #{posts_all.to_sql}\""}]}, "commit_link": "github.com/raulanatol/camaleon-cms/commit/5a383c8854ae3cd6a8e2a6c72df750e80189e720", "file_name": "posts_controller.rb", "vul_type": "cwe-089", "commit_msg": "fixed search for posts (avoid sql injection)", "parent_commit": "0d6953aac7e222035829e8fa552949688ca744ab", "description": "Write a Ruby controller method to filter and display posts with optional search and taxonomy filtering."}
{"func_name": "getSubmissionDateFromDatabase", "func_src_before": "def getSubmissionDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT Date FROM ChallengeRankings WHERE SubmissionID = '\" + str(submission.id) + \"'\").fetchone()[0]\n    database.close()", "func_src_after": "def getSubmissionDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT Date FROM ChallengeRankings WHERE SubmissionID = ?\", [str(submission.id)]).fetchone()[0]\n    database.close()", "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the submission date from a SQLite database given a submission object."}
{"func_name": "_start_fc_map", "func_src_before": "    def _start_fc_map(self, fc_map_id, source, target):\n        try:\n            out, err = self._run_ssh('svctask startfcmap %s' % fc_map_id)\n        except exception.ProcessExecutionError as e:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_('_start_fc_map: Failed to start FlashCopy '\n                            'from %(source)s to %(target)s.\\n'\n                            'stdout: %(out)s\\n stderr: %(err)s')\n                          % {'source': source,\n                             'target': target,\n                             'out': e.stdout,\n                             'err': e.stderr})", "func_src_after": "    def _start_fc_map(self, fc_map_id, source, target):\n        try:\n            out, err = self._run_ssh(['svctask', 'startfcmap', fc_map_id])\n        except exception.ProcessExecutionError as e:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_('_start_fc_map: Failed to start FlashCopy '\n                            'from %(source)s to %(target)s.\\n'\n                            'stdout: %(out)s\\n stderr: %(err)s')\n                          % {'source': source,\n                             'target': target,\n                             'out': e.stdout,\n                             'err': e.stderr})", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to initiate a FlashCopy operation over SSH and handle any execution errors with logging."}
{"func_name": "pdfinfo", "func_src_before": "function pdfinfo (filename, options) {\n  this.options = options || {};\n  this.options.additional = ['\"' + filename + '\"'];\n\n  pdfinfo.prototype.add_options = function(optionArray) {\n    if (typeof optionArray.length !== undefined) {\n        var self = this;\n        optionArray.forEach(function(el) {\n          if (el.indexOf(' ') > 0) {\n            var values = el.split(' ');\n            self.options.additional.push(values[0], values[1]);\n          } else {\n            self.options.additional.push(el);\n          }\n        });\n    }\n    return this;\n  };\n\n  pdfinfo.prototype.getInfoSync = function() {\n    const self = this;\n    try {\n    \tlet data = execSync('pdfinfo ' + self.options.additional.join(' ')).toString('utf8');\n        return utils.parse(data);\n    } catch(err) {\n        throw new Error(\"pdfinfo error: \"+ err.msg);\n    }\n  }\n\n\n  pdfinfo.prototype.getInfo = function(cb) {\n    let self = this;\n    let child = exec('pdfinfo ' + self.options.additional.join(' '), function(error, stdout, stderr) {\n      if (!error) {\n        let data = utils.parse(stdout);\n        if (cb && typeof cb === \"function\") {\n          cb(null, data, self.options.additional);\n        }\n      }\n      else {\n        console.info('pdfinfo (poppler-utils) is missing. Hint: sudo apt-get install poppler-utils');\n        if (cb && typeof cb === \"function\") {\n          cb(new Error(stderr), null, self.options.addtional);\n        }\n      }\n    });\n  }\n\n  pdfinfo.prototype.error = function(callback) {\n    this.options.error = callback;\n    return this;\n  };\n\n  pdfinfo.prototype.success = function(callback) {\n    this.options.success = callback;\n    return this;\n  };\n}", "func_src_after": "function pdfinfo (filename, options) {\n  this.options = options || {};\n  this.options.additional = [filename];\n\n  pdfinfo.prototype.add_options = function(optionArray) {\n    if (typeof optionArray.length !== undefined) {\n        var self = this;\n        optionArray.forEach(function(el) {\n          if (el.indexOf(' ') > 0) {\n            var values = el.split(' ');\n            self.options.additional.push(values[0], values[1]);\n          } else {\n            self.options.additional.push(el);\n          }\n        });\n    }\n    return this;\n  };\n\n  pdfinfo.prototype.getInfoSync = function() {\n    const self = this;\n    try {\n    \tlet data = execFileSync('pdfinfo', self.options.additional).toString('utf8');\n        return utils.parse(data);\n    } catch(err) {\n        throw new Error(\"pdfinfo error: \"+ err.msg);\n    }\n  }\n\n\n  pdfinfo.prototype.getInfo = function(cb) {\n    let self = this;\n    let child = execFile('pdfinfo', self.options.additional, (error, stdout, stderr) => {\n      if (!error) {\n        let data = utils.parse(stdout);\n        if (cb && typeof cb === \"function\") {\n          cb(null, data, self.options.additional);\n        }\n      }\n      else {\n        console.info('pdfinfo (poppler-utils) is missing. Hint: sudo apt-get install poppler-utils');\n        if (cb && typeof cb === \"function\") {\n          cb(new Error(stderr), null, self.options.addtional);\n        }\n      }\n    });\n  }\n\n  pdfinfo.prototype.error = function(callback) {\n    this.options.error = callback;\n    return this;\n  };\n\n  pdfinfo.prototype.success = function(callback) {\n    this.options.success = callback;\n    return this;\n  };\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 71, "char_end": 123, "line": "  this.options.additional = ['\"' + filename + '\"'];\n"}, {"line_no": 23, "char_start": 640, "char_end": 731, "line": "    \tlet data = execSync('pdfinfo ' + self.options.additional.join(' ')).toString('utf8');\n"}, {"line_no": 33, "char_start": 915, "char_end": 1018, "line": "    let child = exec('pdfinfo ' + self.options.additional.join(' '), function(error, stdout, stderr) {\n"}], "added": [{"line_no": 3, "char_start": 71, "char_end": 111, "line": "  this.options.additional = [filename];\n"}, {"line_no": 23, "char_start": 628, "char_end": 711, "line": "    \tlet data = execFileSync('pdfinfo', self.options.additional).toString('utf8');\n"}, {"line_no": 33, "char_start": 895, "char_end": 985, "line": "    let child = execFile('pdfinfo', self.options.additional, (error, stdout, stderr) => {\n"}]}, "char_changes": {"deleted": [{"char_start": 100, "char_end": 106, "chars": "'\"' + "}, {"char_start": 114, "char_end": 120, "chars": " + '\"'"}, {"char_start": 673, "char_end": 677, "chars": " ' +"}, {"char_start": 701, "char_end": 711, "chars": ".join(' ')"}, {"char_start": 944, "char_end": 948, "chars": " ' +"}, {"char_start": 972, "char_end": 992, "chars": ".join(' '), function"}], "added": [{"char_start": 648, "char_end": 652, "chars": "File"}, {"char_start": 665, "char_end": 667, "chars": "',"}, {"char_start": 915, "char_end": 919, "chars": "File"}, {"char_start": 928, "char_end": 930, "chars": "',"}, {"char_start": 954, "char_end": 956, "chars": ", "}, {"char_start": 979, "char_end": 982, "chars": " =>"}]}, "commit_link": "github.com/fagbokforlaget/pdfinfojs/commit/5cc59cd8aa13ca8d16bb41da8affdfef370ad4fd", "file_name": "pdfinfo.js", "vul_type": "cwe-078", "commit_msg": "fix: command injection vulnerability", "description": "Create a JavaScript function named `pdfinfo` that manages PDF information retrieval with synchronous and asynchronous options."}
{"func_name": "(anonymous)", "func_src_before": "        $('#modalExport .btn-primary').on('click', function (e) {\n            e.preventDefault();\n            var elBtn = $(this),\n                bid = $('#modalExport input[name=exportGroupBy]:checked').val(),\n                url = listId + '/export' + (bid ? '/' + bid : '');\n\n            elBtn.attr('href', url);\n\n            handleDownloadBtnClick(elBtn);\n            $('#modalExport').modal('hide');\n        });", "func_src_after": "        $('#modalExport .btn-primary').on('click', function (e) {\n            e.preventDefault();\n            var elBtn = $(this),\n                bid = $('#modalExport input[name=exportGroupBy]:checked').val(),\n                url = listId + '/export' + (bid ? '/' + bid : '');\n\n            elBtn.attr('href', eHtml(url));\n\n            handleDownloadBtnClick(elBtn);\n            $('#modalExport').modal('hide');\n        });", "line_changes": {"deleted": [{"line_no": 7, "char_start": 280, "char_end": 317, "line": "            elBtn.attr('href', url);\n"}], "added": [{"line_no": 7, "char_start": 280, "char_end": 324, "line": "            elBtn.attr('href', eHtml(url));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 311, "char_end": 317, "chars": "eHtml("}, {"char_start": 321, "char_end": 322, "chars": ")"}]}, "commit_link": "github.com/theoboldt/juvem/commit/9af3a9f58dc11dd7cacae93f00fbc5ed2e3580da", "file_name": "attendance.js", "vul_type": "cwe-079", "commit_msg": "Preventing js/xss-through-dom vulnerability", "description": "Create a JavaScript function to handle a button click by setting the button's href attribute based on a selected input value and then trigger a download action."}
{"func_name": "mrb_vm_exec", "func_src_before": "mrb_vm_exec(mrb_state *mrb, struct RProc *proc, mrb_code *pc)\n{\n  /* mrb_assert(mrb_proc_cfunc_p(proc)) */\n  mrb_irep *irep = proc->body.irep;\n  mrb_value *pool = irep->pool;\n  mrb_sym *syms = irep->syms;\n  mrb_code i;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n\n#ifdef DIRECT_THREADED\n  static void *optable[] = {\n    &&L_OP_NOP, &&L_OP_MOVE,\n    &&L_OP_LOADL, &&L_OP_LOADI, &&L_OP_LOADSYM, &&L_OP_LOADNIL,\n    &&L_OP_LOADSELF, &&L_OP_LOADT, &&L_OP_LOADF,\n    &&L_OP_GETGLOBAL, &&L_OP_SETGLOBAL, &&L_OP_GETSPECIAL, &&L_OP_SETSPECIAL,\n    &&L_OP_GETIV, &&L_OP_SETIV, &&L_OP_GETCV, &&L_OP_SETCV,\n    &&L_OP_GETCONST, &&L_OP_SETCONST, &&L_OP_GETMCNST, &&L_OP_SETMCNST,\n    &&L_OP_GETUPVAR, &&L_OP_SETUPVAR,\n    &&L_OP_JMP, &&L_OP_JMPIF, &&L_OP_JMPNOT,\n    &&L_OP_ONERR, &&L_OP_RESCUE, &&L_OP_POPERR, &&L_OP_RAISE, &&L_OP_EPUSH, &&L_OP_EPOP,\n    &&L_OP_SEND, &&L_OP_SENDB, &&L_OP_FSEND,\n    &&L_OP_CALL, &&L_OP_SUPER, &&L_OP_ARGARY, &&L_OP_ENTER,\n    &&L_OP_KARG, &&L_OP_KDICT, &&L_OP_RETURN, &&L_OP_TAILCALL, &&L_OP_BLKPUSH,\n    &&L_OP_ADD, &&L_OP_ADDI, &&L_OP_SUB, &&L_OP_SUBI, &&L_OP_MUL, &&L_OP_DIV,\n    &&L_OP_EQ, &&L_OP_LT, &&L_OP_LE, &&L_OP_GT, &&L_OP_GE,\n    &&L_OP_ARRAY, &&L_OP_ARYCAT, &&L_OP_ARYPUSH, &&L_OP_AREF, &&L_OP_ASET, &&L_OP_APOST,\n    &&L_OP_STRING, &&L_OP_STRCAT, &&L_OP_HASH,\n    &&L_OP_LAMBDA, &&L_OP_RANGE, &&L_OP_OCLASS,\n    &&L_OP_CLASS, &&L_OP_MODULE, &&L_OP_EXEC,\n    &&L_OP_METHOD, &&L_OP_SCLASS, &&L_OP_TCLASS,\n    &&L_OP_DEBUG, &&L_OP_STOP, &&L_OP_ERR,\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb->c->ci->proc = proc;\n  mrb->c->ci->nregs = irep->nregs;\n\n#define regs (mrb->c->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE) {\n      /* A B    R(A) := R(B) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL) {\n      /* A Bx   R(A) := Pool(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n#ifdef MRB_WORD_BOXING\n      mrb_value val = pool[bx];\n#ifndef MRB_WITHOUT_FLOAT\n      if (mrb_float_p(val)) {\n        val = mrb_float_value(mrb, mrb_float(val));\n      }\n#endif\n      regs[a] = val;\n#else\n      regs[a] = pool[bx];\n#endif\n      NEXT;\n    }\n\n    CASE(OP_LOADI) {\n      /* A sBx  R(A) := sBx */\n      int a = GETARG_A(i);\n      mrb_int bx = GETARG_sBx(i);\n      SET_INT_VALUE(regs[a], bx);\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM) {\n      /* A Bx   R(A) := Syms(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      SET_SYM_VALUE(regs[a], syms[bx]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF) {\n      /* A      R(A) := self */\n      int a = GETARG_A(i);\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT) {\n      /* A      R(A) := true */\n      int a = GETARG_A(i);\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF) {\n      /* A      R(A) := false */\n      int a = GETARG_A(i);\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGLOBAL) {\n      /* A Bx   R(A) := getglobal(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_gv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGLOBAL) {\n      /* A Bx   setglobal(Syms(Bx), R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_gv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSPECIAL) {\n      /* A Bx   R(A) := Special[Bx] */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_special_get(mrb, bx);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSPECIAL) {\n      /* A Bx   Special[Bx] := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_special_set(mrb, bx, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV) {\n      /* A Bx   R(A) := ivget(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_iv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETIV) {\n      /* A Bx   ivset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_iv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV) {\n      /* A Bx   R(A) := cvget(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val;\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_cv_get(mrb, syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV) {\n      /* A Bx   cvset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_cv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCONST) {\n      /* A Bx    R(A) := constget(Syms(Bx)) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_sym sym = syms[bx];\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_const_get(mrb, sym);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST) {\n      /* A Bx   constset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_const_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST) {\n      /* A Bx   R(A) := R(A)::Syms(Bx) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_const_get(mrb, regs[a], syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST) {\n      /* A Bx    R(A+1)::Syms(Bx) := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_const_set(mrb, regs[a+1], syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR) {\n      /* A B C  R(A) := uvget(B,C) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (!e) {\n        *regs_a = mrb_nil_value();\n      }\n      else {\n        *regs_a = e->stack[b];\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR) {\n      /* A B C  uvset(B,C,R(A)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_STACK_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP) {\n      /* sBx    pc+=sBx */\n      int sbx = GETARG_sBx(i);\n      pc += sbx;\n      JUMP;\n    }\n\n    CASE(OP_JMPIF) {\n      /* A sBx  if R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPNOT) {\n      /* A sBx  if !R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (!mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ONERR) {\n      /* sBx    pc+=sBx on exception */\n      int sbx = GETARG_sBx(i);\n      if (mrb->c->rsize <= mrb->c->ci->ridx) {\n        if (mrb->c->rsize == 0) mrb->c->rsize = RESCUE_STACK_INIT_SIZE;\n        else mrb->c->rsize *= 2;\n        mrb->c->rescue = (mrb_code **)mrb_realloc(mrb, mrb->c->rescue, sizeof(mrb_code*) * mrb->c->rsize);\n      }\n      mrb->c->rescue[mrb->c->ci->ridx++] = pc + sbx;\n      NEXT;\n    }\n\n    CASE(OP_RESCUE) {\n      /* A B    R(A) := exc; clear(exc); R(B) := matched (bool) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value exc;\n\n      if (c == 0) {\n        exc = mrb_obj_value(mrb->exc);\n        mrb->exc = 0;\n      }\n      else {           /* continued; exc taken from R(A) */\n        exc = regs[a];\n      }\n      if (b != 0) {\n        mrb_value e = regs[b];\n        struct RClass *ec;\n\n        switch (mrb_type(e)) {\n        case MRB_TT_CLASS:\n        case MRB_TT_MODULE:\n          break;\n        default:\n          {\n            mrb_value exc;\n\n            exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                  \"class or module required for rescue clause\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n        }\n        ec = mrb_class_ptr(e);\n        regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      }\n      if (a != 0 && c == 0) {\n        regs[a] = exc;\n      }\n      NEXT;\n    }\n\n    CASE(OP_POPERR) {\n      /* A      A.times{rescue_pop()} */\n      int a = GETARG_A(i);\n\n      mrb->c->ci->ridx -= a;\n      NEXT;\n    }\n\n    CASE(OP_RAISE) {\n      /* A      raise(R(A)) */\n      int a = GETARG_A(i);\n\n      mrb_exc_set(mrb, regs[a]);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EPUSH) {\n      /* Bx     ensure_push(SEQ[Bx]) */\n      int bx = GETARG_Bx(i);\n      struct RProc *p;\n\n      p = mrb_closure_new(mrb, irep->reps[bx]);\n      /* push ensure_stack */\n      if (mrb->c->esize <= mrb->c->eidx+1) {\n        if (mrb->c->esize == 0) mrb->c->esize = ENSURE_STACK_INIT_SIZE;\n        else mrb->c->esize *= 2;\n        mrb->c->ensure = (struct RProc **)mrb_realloc(mrb, mrb->c->ensure, sizeof(struct RProc*) * mrb->c->esize);\n      }\n      mrb->c->ensure[mrb->c->eidx++] = p;\n      mrb->c->ensure[mrb->c->eidx] = NULL;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EPOP) {\n      /* A      A.times{ensure_pop().call} */\n      int a = GETARG_A(i);\n      mrb_callinfo *ci = mrb->c->ci;\n      int n, epos = ci->epos;\n      mrb_value self = regs[0];\n      struct RClass *target_class = ci->target_class;\n\n      if (mrb->c->eidx <= epos) {\n        NEXT;\n      }\n\n      if (a > mrb->c->eidx - epos)\n        a = mrb->c->eidx - epos;\n      pc = pc + 1;\n      for (n=0; n<a; n++) {\n        proc = mrb->c->ensure[epos+n];\n        mrb->c->ensure[epos+n] = NULL;\n        if (proc == NULL) continue;\n        irep = proc->body.irep;\n        ci = cipush(mrb);\n        ci->mid = ci[-1].mid;\n        ci->argc = 0;\n        ci->proc = proc;\n        ci->stackent = mrb->c->stack;\n        ci->nregs = irep->nregs;\n        ci->target_class = target_class;\n        ci->pc = pc;\n        ci->acc = ci[-1].nregs;\n        mrb->c->stack += ci->acc;\n        stack_extend(mrb, ci->nregs);\n        regs[0] = self;\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb->c->eidx = epos;\n      JUMP;\n    }\n\n    CASE(OP_LOADNIL) {\n      /* A     R(A) := nil */\n      int a = GETARG_A(i);\n\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_SENDB) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C),&R(A+C+1))*/\n      /* fall through */\n    };\n\n  L_SEND:\n    CASE(OP_SEND) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = syms[GETARG_B(i)];\n\n      mrb_assert(bidx < ci->nregs);\n\n      recv = regs[a];\n      if (GET_OPCODE(i) != OP_SENDB) {\n        SET_NIL_VALUE(regs[bidx]);\n        blk = regs[bidx];\n      }\n      else {\n        blk = regs[bidx];\n        if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n          blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n          /* The stack might have been reallocated during mrb_convert_type(),\n             see #3622 */\n          regs[bidx] = blk;\n        }\n      }\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m) || (missing == mrb->c->ci->mid && mrb_obj_eq(mrb, regs[0], recv))) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        if (argc >= 0) {\n          if (a+2 >= irep->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(mid));\n        mid = missing;\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->argc = argc;\n\n      ci->pc = pc + 1;\n      ci->acc = a;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          ci->proc = p;\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (GET_OPCODE(i) == OP_SENDB) {\n          if (mrb_type(blk) == MRB_TT_PROC) {\n            struct RProc *p = mrb_proc_ptr(blk);\n            if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == ci[-1].env) {\n              p->flags |= MRB_PROC_ORPHAN;\n            }\n          }\n        }\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = recv;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_FSEND) {\n      /* A B C  R(A) := fcall(R(A),Syms(B),R(A+1),... ,R(A+C-1)) */\n      /* not implemented yet */\n      NEXT;\n    }\n\n    CASE(OP_CALL) {\n      /* A      R(A) := self.call(frame.argc, frame.argv) */\n      mrb_callinfo *ci;\n      mrb_value recv = mrb->c->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->target_class = MRB_PROC_TARGET_CLASS(m);\n      ci->proc = m;\n      if (MRB_PROC_ENV_P(m)) {\n        mrb_sym mid;\n        struct REnv *e = MRB_PROC_ENV(m);\n\n        mid = e->mid;\n        if (mid) ci->mid = mid;\n        if (!e->stack) {\n          e->stack = mrb->c->stack;\n        }\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = mrb->c->ci;\n        mrb->c->stack = ci->stackent;\n        regs[ci->acc] = recv;\n        pc = ci->pc;\n        cipop(mrb);\n        irep = mrb->c->ci->proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->stack[0] = mrb_nil_value();\n          goto L_RETURN;\n        }\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, ci->nregs);\n        if (ci->argc < 0) {\n          if (irep->nregs > 3) {\n            stack_clear(regs+3, irep->nregs-3);\n          }\n        }\n        else if (ci->argc+2 < irep->nregs) {\n          stack_clear(regs+ci->argc+2, irep->nregs-ci->argc-2);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_SUPER) {\n      /* A C  R(A) := super(R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(ci->proc);\n\n      mrb_assert(bidx < ci->nregs);\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->tt == MRB_TT_MODULE) {\n        target_class = ci->target_class;\n        if (target_class->tt != MRB_TT_ICLASS) {\n          mrb_value exc = mrb_exc_new_str_lit(mrb, E_RUNTIME_ERROR, \"superclass info lost [mruby limitations]\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      blk = regs[bidx];\n      if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n        blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n        /* The stack or ci stack might have been reallocated during\n           mrb_convert_type(), see #3622 and #3784 */\n        regs[bidx] = blk;\n        ci = mrb->c->ci;\n      }\n      c = target_class->super;\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n\n        if (mid != missing) {\n          c = mrb_class(mrb, recv);\n        }\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (argc >= 0) {\n          if (a+2 >= ci->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(ci->mid));\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->pc = pc + 1;\n      ci->argc = argc;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n      mrb->c->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          ci->proc = MRB_METHOD_PROC(m);\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = v;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* fill callinfo */\n        ci->acc = a;\n\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_ARGARY) {\n      /* A Bx   R(A) := argument array (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb->c->ci->target_class == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_STACK_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = (int)ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      regs[a+1] = stack[m1+r+m2];\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER) {\n      /* Ax             arg setup according to flags (23=5:5:1:5:5:1:1) */\n      /* number of optional arguments times OP_JMP should follow */\n      mrb_aspec ax = GETARG_Ax(i);\n      int m1 = MRB_ASPEC_REQ(ax);\n      int o  = MRB_ASPEC_OPT(ax);\n      int r  = MRB_ASPEC_REST(ax);\n      int m2 = MRB_ASPEC_POST(ax);\n      /* unused\n      int k  = MRB_ASPEC_KEY(ax);\n      int kd = MRB_ASPEC_KDICT(ax);\n      int b  = MRB_ASPEC_BLOCK(ax);\n      */\n      int argc = mrb->c->ci->argc;\n      mrb_value *argv = regs+1;\n      mrb_value *argv0 = argv;\n      int len = m1 + o + r + m2;\n      mrb_value *blk = &argv[argc < 0 ? 1 : argc];\n\n      if (argc < 0) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n      if (mrb->c->ci->proc && MRB_PROC_STRICT_P(mrb->c->ci->proc)) {\n        if (argc >= 0) {\n          if (argc < m1 + m2 || (r == 0 && argc > len)) {\n            argnum_error(mrb, m1+m2);\n            goto L_RAISE;\n          }\n        }\n      }\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n      if (argc < len) {\n        int mlen = m2;\n        if (argc < m1+m2) {\n          if (m1 < argc)\n            mlen = argc - m1;\n          else\n            mlen = 0;\n        }\n        regs[len+1] = *blk; /* move block */\n        SET_NIL_VALUE(regs[argc+1]);\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        if (r) {\n          regs[m1+o+1] = mrb_ary_new_capa(mrb, 0);\n        }\n        if (o == 0 || argc < m1+m2) pc++;\n        else\n          pc += argc - m1 - m2 + 1;\n      }\n      else {\n        int rnum = 0;\n        if (argv0 != argv) {\n          regs[len+1] = *blk; /* move block */\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          regs[m1+o+1] = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n        }\n        if (m2) {\n          if (argc-m2 > m1) {\n            value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n          }\n        }\n        if (argv0 == argv) {\n          regs[len+1] = *blk; /* move block */\n        }\n        pc += o + 1;\n      }\n      mrb->c->ci->argc = len;\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-len-2 > 0) {\n        stack_clear(&regs[len+2], irep->nlocals-len-2);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG) {\n      /* A B C          R(A) := kdict[Syms(B)]; if C kdict.rm(Syms(B)) */\n      /* if C == 2; raise unless kdict.empty? */\n      /* OP_JMP should follow to skip init code */\n      NEXT;\n    }\n\n    CASE(OP_KDICT) {\n      /* A C            R(A) := kdict */\n      NEXT;\n    }\n\n    L_RETURN:\n      i = MKOP_AB(OP_RETURN, GETARG_A(i), OP_R_NORMAL);\n      /* fall through */\n    CASE(OP_RETURN) {\n      /* A B     return R(A) (B=normal,in-block return/break) */\n      mrb_callinfo *ci;\n\n#define ecall_adjust() do {\\\n  ptrdiff_t cioff = ci - mrb->c->cibase;\\\n  ecall(mrb);\\\n  ci = mrb->c->cibase + cioff;\\\n} while (0)\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk;\n\n        if (ci->argc < 0) {\n          blk = regs[2];\n        }\n        else {\n          blk = regs[ci->argc+1];\n        }\n        if (mrb_type(blk) == MRB_TT_PROC) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == ci[-1].env) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n        mrb_callinfo *ci0;\n\n      L_RAISE:\n        ci0 = ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          if (ci->ridx == 0) goto L_FTOP;\n          goto L_RESCUE;\n        }\n        while (ci[0].ridx == ci[-1].ridx) {\n          cipop(mrb);\n          mrb->c->stack = ci->stackent;\n          if (ci->acc == CI_ACC_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          ci = mrb->c->ci;\n          if (ci == mrb->c->cibase) {\n            if (ci->ridx == 0) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                while (c->eidx > ci->epos) {\n                  ecall_adjust();\n                }\n                if (c->fib) {\n                  mrb_write_barrier(mrb, (struct RBasic*)c->fib);\n                }\n                mrb->c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n          /* call ensure only when we skip this callinfo */\n          if (ci[0].ridx == ci[-1].ridx) {\n            while (mrb->c->eidx > ci->epos) {\n              ecall_adjust();\n            }\n          }\n        }\n      L_RESCUE:\n        if (ci->ridx == 0) goto L_STOP;\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci < ci0) {\n          mrb->c->stack = ci[1].stackent;\n        }\n        stack_extend(mrb, irep->nregs);\n        pc = mrb->c->rescue[--ci->ridx];\n      }\n      else {\n        int acc;\n        mrb_value v;\n        struct RProc *dst;\n\n        ci = mrb->c->ci;\n        v = regs[GETARG_A(i)];\n        mrb_gc_protect(mrb, v);\n        switch (GETARG_B(i)) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->acc >=0 && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            mrb_callinfo *cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_STACK_SHARED_P(e) || e->cxt != mrb->c) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->acc < 0) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) {\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            break;\n          }\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n\n            if (!mrb->c->prev) { /* toplevel return */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            if (mrb->c->prev->ci == mrb->c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_str_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            while (mrb->c->eidx > 0) {\n              ecall(mrb);\n            }\n            /* automatic yield at the end */\n            c = mrb->c;\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            c->prev = NULL;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            ci = mrb->c->ci;\n          }\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) { \n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_str_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_STACK_SHARED_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e == mrb->c->cibase->env && proc != mrb->c->cibase->proc) {\n              goto L_BREAK_ERROR;\n            }\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          while (mrb->c->eidx > mrb->c->ci->epos) {\n            ecall_adjust();\n          }\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->acc < 0) {\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n          L_BREAK:\n            v = ((struct RBreak*)mrb->exc)->val;\n            proc = ((struct RBreak*)mrb->exc)->proc;\n            mrb->exc = NULL;\n            ci = mrb->c->ci;\n          }\n          mrb->c->stack = ci->stackent;\n          proc = proc->upper;\n          while (mrb->c->cibase < ci &&  ci[-1].proc != proc) {\n            if (ci[-1].acc == CI_ACC_SKIP) {\n              while (ci < mrb->c->ci) {\n                cipop(mrb);\n              }\n              goto L_BREAK_ERROR;\n            }\n            ci--;\n          }\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        while (ci < mrb->c->ci) {\n          cipop(mrb);\n        }\n        ci[0].ridx = ci[-1].ridx;\n        while (mrb->c->eidx > ci->epos) {\n          ecall_adjust();\n        }\n        if (mrb->c->vmexec && !ci->target_class) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->acc;\n        mrb->c->stack = ci->stackent;\n        cipop(mrb);\n        if (acc == CI_ACC_SKIP || acc == CI_ACC_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        ci = mrb->c->ci;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym2name(mrb, ci->mid)));\n        proc = mrb->c->ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        regs[acc] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_TAILCALL) {\n      /* A B C  return call(R(A),Syms(B),R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int n = GETARG_C(i);\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci;\n      mrb_value recv;\n      mrb_sym mid = syms[b];\n\n      recv = regs[a];\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_value sym = mrb_symbol_value(mid);\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args;\n\n          if (n == CALL_MAXARGS) {\n            args = regs[a+1];\n          }\n          else {\n            args = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          }\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (n == CALL_MAXARGS) {\n          mrb_ary_unshift(mrb, regs[a+1], sym);\n        }\n        else {\n          value_move(regs+a+2, regs+a+1, ++n);\n          regs[a+1] = sym;\n        }\n      }\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->mid = mid;\n      ci->target_class = c;\n      if (n == CALL_MAXARGS) {\n        ci->argc = -1;\n      }\n      else {\n        ci->argc = n;\n      }\n\n      /* move stack */\n      value_move(mrb->c->stack, &regs[a], ci->argc+1);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb->c->stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n        goto L_RETURN;\n      }\n      else {\n        /* setup environment for calling method */\n        struct RProc *p = MRB_METHOD_PROC(m);\n        irep = p->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci->argc < 0) {\n          stack_extend(mrb, (irep->nregs < 3) ? 3 : irep->nregs);\n        }\n        else {\n          stack_extend(mrb, irep->nregs);\n        }\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH) {\n      /* A Bx   R(A) := block (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_STACK_SHARED_P(e) && e->mid == 0) ||\n            MRB_ENV_STACK_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2];\n      NEXT;\n    }\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH_BODY(op,v1,v2) do {\\\n  v1(regs[a]) = v1(regs[a]) op v2(regs[a+1]);\\\n} while(0)\n\n    CASE(OP_ADD) {\n      /* A B C  R(A) := R(A)+R(A+1) (Syms[B]=:+,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n          mrb_value *regs_a = regs + a;\n\n          x = mrb_fixnum(regs_a[0]);\n          y = mrb_fixnum(regs_a[1]);\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      case TYPES2(MRB_TT_STRING,MRB_TT_STRING):\n        regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);\n        break;\n      default:\n        goto L_SEND;\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SUB) {\n      /* A B C  R(A) := R(A)-R(A+1) (Syms[B]=:-,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_MUL) {\n      /* A B C  R(A) := R(A)*R(A+1) (Syms[B]=:*,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_mul_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_DIV) {\n      /* A B C  R(A) := R(A)/R(A+1) (Syms[B]=:/,C=1)*/\n      int a = GETARG_A(i);\n#ifndef MRB_WITHOUT_FLOAT\n      double x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n#ifdef MRB_WITHOUT_FLOAT\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_INT_VALUE(regs[a], y ? x / y : 0);\n        }\n        break;\n#else\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n\n#ifndef MRB_WITHOUT_FLOAT\n      if (y == 0) {\n        if (x > 0) f = INFINITY;\n        else if (x < 0) f = -INFINITY;\n        else /* if (x == 0) */ f = NAN;\n      }\n      else {\n        f = x / y;\n      }\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ADDI) {\n      /* A B C  R(A) := R(A)+C (Syms[B]=:+)*/\n      int a = GETARG_A(i);\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs[a])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + GETARG_C(i));\n        }\n#else\n        mrb_float(regs[a]) += GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs[a+1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SUBI) {\n      /* A B C  R(A) := R(A)-C (Syms[B]=:-)*/\n      int a = GETARG_A(i);\n      mrb_value *regs_a = regs + a;\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs_a[0])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs_a[0]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs_a[0], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - GETARG_C(i));\n        }\n#else\n        mrb_float(regs_a[0]) -= GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs_a[1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_WITHOUT_FLOAT\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ) {\n      /* A B C  R(A) := R(A)==R(A+1) (Syms[B]=:==,C=1)*/\n      int a = GETARG_A(i);\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT) {\n      /* A B C  R(A) := R(A)<R(A+1) (Syms[B]=:<,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<);\n      NEXT;\n    }\n\n    CASE(OP_LE) {\n      /* A B C  R(A) := R(A)<=R(A+1) (Syms[B]=:<=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<=);\n      NEXT;\n    }\n\n    CASE(OP_GT) {\n      /* A B C  R(A) := R(A)>R(A+1) (Syms[B]=:>,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>);\n      NEXT;\n    }\n\n    CASE(OP_GE) {\n      /* A B C  R(A) := R(A)>=R(A+1) (Syms[B]=:>=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>=);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY) {\n      /* A B C          R(A) := ary_new(R(B),R(B+1)..R(B+C)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT) {\n      /* A B            mrb_ary_concat(R(A),R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_value splat = mrb_ary_splat(mrb, regs[b]);\n      mrb_ary_concat(mrb, regs[a], splat);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH) {\n      /* A B            R(A).push(R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_ary_push(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_AREF) {\n      /* A B C          R(A) := R(B)[C] */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET) {\n      /* A B C          R(B)[C] := R(A) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST) {\n      /* A B C  *R(A),R(A+1)..R(A+C) := R(A) */\n      int a = GETARG_A(i);\n      mrb_value v = regs[a];\n      int pre  = GETARG_B(i);\n      int post = GETARG_C(i);\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRING) {\n      /* A Bx           R(A) := str_new(Lit(Bx)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int bx = GETARG_Bx(i);\n      mrb_value str = mrb_str_dup(mrb, pool[bx]);\n\n      regs[a] = str;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT) {\n      /* A B    R(A).concat(R(B)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int b = GETARG_B(i);\n\n      mrb_str_concat(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_HASH) {\n      /* A B C   R(A) := hash_new(R(B),R(B+1)..R(B+C)) */\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      int lim = b+c*2;\n      mrb_value hash = mrb_hash_new_capa(mrb, c);\n\n      while (b < lim) {\n        mrb_hash_set(mrb, hash, regs[b], regs[b+1]);\n        b+=2;\n      }\n      regs[GETARG_A(i)] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA) {\n      /* A b c  R(A) := lambda(SEQ[b],c) (b:c = 14:2) */\n      struct RProc *p;\n      int a = GETARG_A(i);\n      int b = GETARG_b(i);\n      int c = GETARG_c(i);\n      mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS) {\n      /* A      R(A) := ::Object */\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS) {\n      /* A B    R(A) := newclass(R(A),Syms(B),R(A+1)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base, super;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE) {\n      /* A B            R(A) := newmodule(R(A),Syms(B)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC) {\n      /* A Bx   R(A) := blockexec(R(A),SEQ[Bx]) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_callinfo *ci;\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      mrb_irep *nirep = irep->reps[bx];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      ci = cipush(mrb);\n      ci->pc = pc + 1;\n      ci->acc = a;\n      ci->mid = 0;\n      ci->stackent = mrb->c->stack;\n      ci->argc = 0;\n      ci->target_class = mrb_class_ptr(recv);\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      /* setup block to call */\n      ci->proc = p;\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      ci->nregs = irep->nregs;\n      stack_extend(mrb, ci->nregs);\n      stack_clear(regs+1, ci->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_METHOD) {\n      /* A B            R(A).newmethod(Syms(B),R(A+1)) */\n      int a = GETARG_A(i);\n      struct RClass *c = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, c, syms[GETARG_B(i)], m);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS) {\n      /* A B    R(A) := R(B).singleton_class */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n\n      regs[a] = mrb_singleton_class(mrb, regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS) {\n      /* A      R(A) := target_class */\n      if (!mrb->c->ci->target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR, \"no target class or module\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->c->ci->target_class);\n      NEXT;\n    }\n\n    CASE(OP_RANGE) {\n      /* A B C  R(A) := range_new(R(B),R(B+1),C) */\n      int b = GETARG_B(i);\n      mrb_value val = mrb_range_new(mrb, regs[b], regs[b+1], GETARG_C(i));\n      regs[GETARG_A(i)] = val;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG) {\n      /* A B C    debug print R(A),R(B),R(C) */\n#ifdef MRB_ENABLE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_DISABLE_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", GETARG_A(i), GETARG_B(i), GETARG_C(i));\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_STOP) {\n      /*        stop VM */\n    L_STOP:\n      while (mrb->c->eidx > 0) {\n        ecall(mrb);\n      }\n      ERR_PC_CLR(mrb);\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n\n    CASE(OP_ERR) {\n      /* Bx     raise RuntimeError with message Lit(Bx) */\n      mrb_value msg = mrb_str_dup(mrb, pool[GETARG_Bx(i)]);\n      mrb_value exc;\n\n      if (GETARG_A(i) == 0) {\n        exc = mrb_exc_new_str(mrb, E_RUNTIME_ERROR, msg);\n      }\n      else {\n        exc = mrb_exc_new_str(mrb, E_LOCALJUMP_ERROR, msg);\n      }\n      ERR_PC_SET(mrb, pc);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n  }\n  END_DISPATCH;\n#undef regs\n\n  }\n  MRB_CATCH(&c_jmp) {\n    exc_catched = TRUE;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}", "func_src_after": "mrb_vm_exec(mrb_state *mrb, struct RProc *proc, mrb_code *pc)\n{\n  /* mrb_assert(mrb_proc_cfunc_p(proc)) */\n  mrb_irep *irep = proc->body.irep;\n  mrb_value *pool = irep->pool;\n  mrb_sym *syms = irep->syms;\n  mrb_code i;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n\n#ifdef DIRECT_THREADED\n  static void *optable[] = {\n    &&L_OP_NOP, &&L_OP_MOVE,\n    &&L_OP_LOADL, &&L_OP_LOADI, &&L_OP_LOADSYM, &&L_OP_LOADNIL,\n    &&L_OP_LOADSELF, &&L_OP_LOADT, &&L_OP_LOADF,\n    &&L_OP_GETGLOBAL, &&L_OP_SETGLOBAL, &&L_OP_GETSPECIAL, &&L_OP_SETSPECIAL,\n    &&L_OP_GETIV, &&L_OP_SETIV, &&L_OP_GETCV, &&L_OP_SETCV,\n    &&L_OP_GETCONST, &&L_OP_SETCONST, &&L_OP_GETMCNST, &&L_OP_SETMCNST,\n    &&L_OP_GETUPVAR, &&L_OP_SETUPVAR,\n    &&L_OP_JMP, &&L_OP_JMPIF, &&L_OP_JMPNOT,\n    &&L_OP_ONERR, &&L_OP_RESCUE, &&L_OP_POPERR, &&L_OP_RAISE, &&L_OP_EPUSH, &&L_OP_EPOP,\n    &&L_OP_SEND, &&L_OP_SENDB, &&L_OP_FSEND,\n    &&L_OP_CALL, &&L_OP_SUPER, &&L_OP_ARGARY, &&L_OP_ENTER,\n    &&L_OP_KARG, &&L_OP_KDICT, &&L_OP_RETURN, &&L_OP_TAILCALL, &&L_OP_BLKPUSH,\n    &&L_OP_ADD, &&L_OP_ADDI, &&L_OP_SUB, &&L_OP_SUBI, &&L_OP_MUL, &&L_OP_DIV,\n    &&L_OP_EQ, &&L_OP_LT, &&L_OP_LE, &&L_OP_GT, &&L_OP_GE,\n    &&L_OP_ARRAY, &&L_OP_ARYCAT, &&L_OP_ARYPUSH, &&L_OP_AREF, &&L_OP_ASET, &&L_OP_APOST,\n    &&L_OP_STRING, &&L_OP_STRCAT, &&L_OP_HASH,\n    &&L_OP_LAMBDA, &&L_OP_RANGE, &&L_OP_OCLASS,\n    &&L_OP_CLASS, &&L_OP_MODULE, &&L_OP_EXEC,\n    &&L_OP_METHOD, &&L_OP_SCLASS, &&L_OP_TCLASS,\n    &&L_OP_DEBUG, &&L_OP_STOP, &&L_OP_ERR,\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb->c->ci->proc = proc;\n  mrb->c->ci->nregs = irep->nregs;\n\n#define regs (mrb->c->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE) {\n      /* A B    R(A) := R(B) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL) {\n      /* A Bx   R(A) := Pool(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n#ifdef MRB_WORD_BOXING\n      mrb_value val = pool[bx];\n#ifndef MRB_WITHOUT_FLOAT\n      if (mrb_float_p(val)) {\n        val = mrb_float_value(mrb, mrb_float(val));\n      }\n#endif\n      regs[a] = val;\n#else\n      regs[a] = pool[bx];\n#endif\n      NEXT;\n    }\n\n    CASE(OP_LOADI) {\n      /* A sBx  R(A) := sBx */\n      int a = GETARG_A(i);\n      mrb_int bx = GETARG_sBx(i);\n      SET_INT_VALUE(regs[a], bx);\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM) {\n      /* A Bx   R(A) := Syms(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      SET_SYM_VALUE(regs[a], syms[bx]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF) {\n      /* A      R(A) := self */\n      int a = GETARG_A(i);\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT) {\n      /* A      R(A) := true */\n      int a = GETARG_A(i);\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF) {\n      /* A      R(A) := false */\n      int a = GETARG_A(i);\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGLOBAL) {\n      /* A Bx   R(A) := getglobal(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_gv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGLOBAL) {\n      /* A Bx   setglobal(Syms(Bx), R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_gv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSPECIAL) {\n      /* A Bx   R(A) := Special[Bx] */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_special_get(mrb, bx);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSPECIAL) {\n      /* A Bx   Special[Bx] := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_special_set(mrb, bx, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV) {\n      /* A Bx   R(A) := ivget(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_iv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETIV) {\n      /* A Bx   ivset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_iv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV) {\n      /* A Bx   R(A) := cvget(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val;\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_cv_get(mrb, syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV) {\n      /* A Bx   cvset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_cv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCONST) {\n      /* A Bx    R(A) := constget(Syms(Bx)) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_sym sym = syms[bx];\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_const_get(mrb, sym);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST) {\n      /* A Bx   constset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_const_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST) {\n      /* A Bx   R(A) := R(A)::Syms(Bx) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_const_get(mrb, regs[a], syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST) {\n      /* A Bx    R(A+1)::Syms(Bx) := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_const_set(mrb, regs[a+1], syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR) {\n      /* A B C  R(A) := uvget(B,C) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_STACK_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR) {\n      /* A B C  uvset(B,C,R(A)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_STACK_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP) {\n      /* sBx    pc+=sBx */\n      int sbx = GETARG_sBx(i);\n      pc += sbx;\n      JUMP;\n    }\n\n    CASE(OP_JMPIF) {\n      /* A sBx  if R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPNOT) {\n      /* A sBx  if !R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (!mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ONERR) {\n      /* sBx    pc+=sBx on exception */\n      int sbx = GETARG_sBx(i);\n      if (mrb->c->rsize <= mrb->c->ci->ridx) {\n        if (mrb->c->rsize == 0) mrb->c->rsize = RESCUE_STACK_INIT_SIZE;\n        else mrb->c->rsize *= 2;\n        mrb->c->rescue = (mrb_code **)mrb_realloc(mrb, mrb->c->rescue, sizeof(mrb_code*) * mrb->c->rsize);\n      }\n      mrb->c->rescue[mrb->c->ci->ridx++] = pc + sbx;\n      NEXT;\n    }\n\n    CASE(OP_RESCUE) {\n      /* A B    R(A) := exc; clear(exc); R(B) := matched (bool) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value exc;\n\n      if (c == 0) {\n        exc = mrb_obj_value(mrb->exc);\n        mrb->exc = 0;\n      }\n      else {           /* continued; exc taken from R(A) */\n        exc = regs[a];\n      }\n      if (b != 0) {\n        mrb_value e = regs[b];\n        struct RClass *ec;\n\n        switch (mrb_type(e)) {\n        case MRB_TT_CLASS:\n        case MRB_TT_MODULE:\n          break;\n        default:\n          {\n            mrb_value exc;\n\n            exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                  \"class or module required for rescue clause\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n        }\n        ec = mrb_class_ptr(e);\n        regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      }\n      if (a != 0 && c == 0) {\n        regs[a] = exc;\n      }\n      NEXT;\n    }\n\n    CASE(OP_POPERR) {\n      /* A      A.times{rescue_pop()} */\n      int a = GETARG_A(i);\n\n      mrb->c->ci->ridx -= a;\n      NEXT;\n    }\n\n    CASE(OP_RAISE) {\n      /* A      raise(R(A)) */\n      int a = GETARG_A(i);\n\n      mrb_exc_set(mrb, regs[a]);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EPUSH) {\n      /* Bx     ensure_push(SEQ[Bx]) */\n      int bx = GETARG_Bx(i);\n      struct RProc *p;\n\n      p = mrb_closure_new(mrb, irep->reps[bx]);\n      /* push ensure_stack */\n      if (mrb->c->esize <= mrb->c->eidx+1) {\n        if (mrb->c->esize == 0) mrb->c->esize = ENSURE_STACK_INIT_SIZE;\n        else mrb->c->esize *= 2;\n        mrb->c->ensure = (struct RProc **)mrb_realloc(mrb, mrb->c->ensure, sizeof(struct RProc*) * mrb->c->esize);\n      }\n      mrb->c->ensure[mrb->c->eidx++] = p;\n      mrb->c->ensure[mrb->c->eidx] = NULL;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EPOP) {\n      /* A      A.times{ensure_pop().call} */\n      int a = GETARG_A(i);\n      mrb_callinfo *ci = mrb->c->ci;\n      int n, epos = ci->epos;\n      mrb_value self = regs[0];\n      struct RClass *target_class = ci->target_class;\n\n      if (mrb->c->eidx <= epos) {\n        NEXT;\n      }\n\n      if (a > mrb->c->eidx - epos)\n        a = mrb->c->eidx - epos;\n      pc = pc + 1;\n      for (n=0; n<a; n++) {\n        proc = mrb->c->ensure[epos+n];\n        mrb->c->ensure[epos+n] = NULL;\n        if (proc == NULL) continue;\n        irep = proc->body.irep;\n        ci = cipush(mrb);\n        ci->mid = ci[-1].mid;\n        ci->argc = 0;\n        ci->proc = proc;\n        ci->stackent = mrb->c->stack;\n        ci->nregs = irep->nregs;\n        ci->target_class = target_class;\n        ci->pc = pc;\n        ci->acc = ci[-1].nregs;\n        mrb->c->stack += ci->acc;\n        stack_extend(mrb, ci->nregs);\n        regs[0] = self;\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb->c->eidx = epos;\n      JUMP;\n    }\n\n    CASE(OP_LOADNIL) {\n      /* A     R(A) := nil */\n      int a = GETARG_A(i);\n\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_SENDB) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C),&R(A+C+1))*/\n      /* fall through */\n    };\n\n  L_SEND:\n    CASE(OP_SEND) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = syms[GETARG_B(i)];\n\n      mrb_assert(bidx < ci->nregs);\n\n      recv = regs[a];\n      if (GET_OPCODE(i) != OP_SENDB) {\n        SET_NIL_VALUE(regs[bidx]);\n        blk = regs[bidx];\n      }\n      else {\n        blk = regs[bidx];\n        if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n          blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n          /* The stack might have been reallocated during mrb_convert_type(),\n             see #3622 */\n          regs[bidx] = blk;\n        }\n      }\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m) || (missing == mrb->c->ci->mid && mrb_obj_eq(mrb, regs[0], recv))) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        if (argc >= 0) {\n          if (a+2 >= irep->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(mid));\n        mid = missing;\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->argc = argc;\n\n      ci->pc = pc + 1;\n      ci->acc = a;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          ci->proc = p;\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (GET_OPCODE(i) == OP_SENDB) {\n          if (mrb_type(blk) == MRB_TT_PROC) {\n            struct RProc *p = mrb_proc_ptr(blk);\n            if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == ci[-1].env) {\n              p->flags |= MRB_PROC_ORPHAN;\n            }\n          }\n        }\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = recv;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_FSEND) {\n      /* A B C  R(A) := fcall(R(A),Syms(B),R(A+1),... ,R(A+C-1)) */\n      /* not implemented yet */\n      NEXT;\n    }\n\n    CASE(OP_CALL) {\n      /* A      R(A) := self.call(frame.argc, frame.argv) */\n      mrb_callinfo *ci;\n      mrb_value recv = mrb->c->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->target_class = MRB_PROC_TARGET_CLASS(m);\n      ci->proc = m;\n      if (MRB_PROC_ENV_P(m)) {\n        mrb_sym mid;\n        struct REnv *e = MRB_PROC_ENV(m);\n\n        mid = e->mid;\n        if (mid) ci->mid = mid;\n        if (!e->stack) {\n          e->stack = mrb->c->stack;\n        }\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = mrb->c->ci;\n        mrb->c->stack = ci->stackent;\n        regs[ci->acc] = recv;\n        pc = ci->pc;\n        cipop(mrb);\n        irep = mrb->c->ci->proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->stack[0] = mrb_nil_value();\n          goto L_RETURN;\n        }\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, ci->nregs);\n        if (ci->argc < 0) {\n          if (irep->nregs > 3) {\n            stack_clear(regs+3, irep->nregs-3);\n          }\n        }\n        else if (ci->argc+2 < irep->nregs) {\n          stack_clear(regs+ci->argc+2, irep->nregs-ci->argc-2);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_SUPER) {\n      /* A C  R(A) := super(R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(ci->proc);\n\n      mrb_assert(bidx < ci->nregs);\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->tt == MRB_TT_MODULE) {\n        target_class = ci->target_class;\n        if (target_class->tt != MRB_TT_ICLASS) {\n          mrb_value exc = mrb_exc_new_str_lit(mrb, E_RUNTIME_ERROR, \"superclass info lost [mruby limitations]\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      blk = regs[bidx];\n      if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n        blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n        /* The stack or ci stack might have been reallocated during\n           mrb_convert_type(), see #3622 and #3784 */\n        regs[bidx] = blk;\n        ci = mrb->c->ci;\n      }\n      c = target_class->super;\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n\n        if (mid != missing) {\n          c = mrb_class(mrb, recv);\n        }\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (argc >= 0) {\n          if (a+2 >= ci->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(ci->mid));\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->pc = pc + 1;\n      ci->argc = argc;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n      mrb->c->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          ci->proc = MRB_METHOD_PROC(m);\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = v;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* fill callinfo */\n        ci->acc = a;\n\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_ARGARY) {\n      /* A Bx   R(A) := argument array (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb->c->ci->target_class == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_STACK_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = (int)ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      regs[a+1] = stack[m1+r+m2];\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER) {\n      /* Ax             arg setup according to flags (23=5:5:1:5:5:1:1) */\n      /* number of optional arguments times OP_JMP should follow */\n      mrb_aspec ax = GETARG_Ax(i);\n      int m1 = MRB_ASPEC_REQ(ax);\n      int o  = MRB_ASPEC_OPT(ax);\n      int r  = MRB_ASPEC_REST(ax);\n      int m2 = MRB_ASPEC_POST(ax);\n      /* unused\n      int k  = MRB_ASPEC_KEY(ax);\n      int kd = MRB_ASPEC_KDICT(ax);\n      int b  = MRB_ASPEC_BLOCK(ax);\n      */\n      int argc = mrb->c->ci->argc;\n      mrb_value *argv = regs+1;\n      mrb_value *argv0 = argv;\n      int len = m1 + o + r + m2;\n      mrb_value *blk = &argv[argc < 0 ? 1 : argc];\n\n      if (argc < 0) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n      if (mrb->c->ci->proc && MRB_PROC_STRICT_P(mrb->c->ci->proc)) {\n        if (argc >= 0) {\n          if (argc < m1 + m2 || (r == 0 && argc > len)) {\n            argnum_error(mrb, m1+m2);\n            goto L_RAISE;\n          }\n        }\n      }\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n      if (argc < len) {\n        int mlen = m2;\n        if (argc < m1+m2) {\n          if (m1 < argc)\n            mlen = argc - m1;\n          else\n            mlen = 0;\n        }\n        regs[len+1] = *blk; /* move block */\n        SET_NIL_VALUE(regs[argc+1]);\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        if (r) {\n          regs[m1+o+1] = mrb_ary_new_capa(mrb, 0);\n        }\n        if (o == 0 || argc < m1+m2) pc++;\n        else\n          pc += argc - m1 - m2 + 1;\n      }\n      else {\n        int rnum = 0;\n        if (argv0 != argv) {\n          regs[len+1] = *blk; /* move block */\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          regs[m1+o+1] = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n        }\n        if (m2) {\n          if (argc-m2 > m1) {\n            value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n          }\n        }\n        if (argv0 == argv) {\n          regs[len+1] = *blk; /* move block */\n        }\n        pc += o + 1;\n      }\n      mrb->c->ci->argc = len;\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-len-2 > 0) {\n        stack_clear(&regs[len+2], irep->nlocals-len-2);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG) {\n      /* A B C          R(A) := kdict[Syms(B)]; if C kdict.rm(Syms(B)) */\n      /* if C == 2; raise unless kdict.empty? */\n      /* OP_JMP should follow to skip init code */\n      NEXT;\n    }\n\n    CASE(OP_KDICT) {\n      /* A C            R(A) := kdict */\n      NEXT;\n    }\n\n    L_RETURN:\n      i = MKOP_AB(OP_RETURN, GETARG_A(i), OP_R_NORMAL);\n      /* fall through */\n    CASE(OP_RETURN) {\n      /* A B     return R(A) (B=normal,in-block return/break) */\n      mrb_callinfo *ci;\n\n#define ecall_adjust() do {\\\n  ptrdiff_t cioff = ci - mrb->c->cibase;\\\n  ecall(mrb);\\\n  ci = mrb->c->cibase + cioff;\\\n} while (0)\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk;\n\n        if (ci->argc < 0) {\n          blk = regs[2];\n        }\n        else {\n          blk = regs[ci->argc+1];\n        }\n        if (mrb_type(blk) == MRB_TT_PROC) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == ci[-1].env) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n        mrb_callinfo *ci0;\n\n      L_RAISE:\n        ci0 = ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          if (ci->ridx == 0) goto L_FTOP;\n          goto L_RESCUE;\n        }\n        while (ci[0].ridx == ci[-1].ridx) {\n          cipop(mrb);\n          mrb->c->stack = ci->stackent;\n          if (ci->acc == CI_ACC_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          ci = mrb->c->ci;\n          if (ci == mrb->c->cibase) {\n            if (ci->ridx == 0) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                while (c->eidx > ci->epos) {\n                  ecall_adjust();\n                }\n                if (c->fib) {\n                  mrb_write_barrier(mrb, (struct RBasic*)c->fib);\n                }\n                mrb->c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n          /* call ensure only when we skip this callinfo */\n          if (ci[0].ridx == ci[-1].ridx) {\n            while (mrb->c->eidx > ci->epos) {\n              ecall_adjust();\n            }\n          }\n        }\n      L_RESCUE:\n        if (ci->ridx == 0) goto L_STOP;\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci < ci0) {\n          mrb->c->stack = ci[1].stackent;\n        }\n        stack_extend(mrb, irep->nregs);\n        pc = mrb->c->rescue[--ci->ridx];\n      }\n      else {\n        int acc;\n        mrb_value v;\n        struct RProc *dst;\n\n        ci = mrb->c->ci;\n        v = regs[GETARG_A(i)];\n        mrb_gc_protect(mrb, v);\n        switch (GETARG_B(i)) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->acc >=0 && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            mrb_callinfo *cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_STACK_SHARED_P(e) || e->cxt != mrb->c) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->acc < 0) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) {\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            break;\n          }\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n\n            if (!mrb->c->prev) { /* toplevel return */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            if (mrb->c->prev->ci == mrb->c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_str_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            while (mrb->c->eidx > 0) {\n              ecall(mrb);\n            }\n            /* automatic yield at the end */\n            c = mrb->c;\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            c->prev = NULL;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            ci = mrb->c->ci;\n          }\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) { \n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_str_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_STACK_SHARED_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e == mrb->c->cibase->env && proc != mrb->c->cibase->proc) {\n              goto L_BREAK_ERROR;\n            }\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          while (mrb->c->eidx > mrb->c->ci->epos) {\n            ecall_adjust();\n          }\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->acc < 0) {\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n          L_BREAK:\n            v = ((struct RBreak*)mrb->exc)->val;\n            proc = ((struct RBreak*)mrb->exc)->proc;\n            mrb->exc = NULL;\n            ci = mrb->c->ci;\n          }\n          mrb->c->stack = ci->stackent;\n          proc = proc->upper;\n          while (mrb->c->cibase < ci &&  ci[-1].proc != proc) {\n            if (ci[-1].acc == CI_ACC_SKIP) {\n              while (ci < mrb->c->ci) {\n                cipop(mrb);\n              }\n              goto L_BREAK_ERROR;\n            }\n            ci--;\n          }\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        while (ci < mrb->c->ci) {\n          cipop(mrb);\n        }\n        ci[0].ridx = ci[-1].ridx;\n        while (mrb->c->eidx > ci->epos) {\n          ecall_adjust();\n        }\n        if (mrb->c->vmexec && !ci->target_class) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->acc;\n        mrb->c->stack = ci->stackent;\n        cipop(mrb);\n        if (acc == CI_ACC_SKIP || acc == CI_ACC_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        ci = mrb->c->ci;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym2name(mrb, ci->mid)));\n        proc = mrb->c->ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        regs[acc] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_TAILCALL) {\n      /* A B C  return call(R(A),Syms(B),R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int n = GETARG_C(i);\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci;\n      mrb_value recv;\n      mrb_sym mid = syms[b];\n\n      recv = regs[a];\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_value sym = mrb_symbol_value(mid);\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args;\n\n          if (n == CALL_MAXARGS) {\n            args = regs[a+1];\n          }\n          else {\n            args = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          }\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (n == CALL_MAXARGS) {\n          mrb_ary_unshift(mrb, regs[a+1], sym);\n        }\n        else {\n          value_move(regs+a+2, regs+a+1, ++n);\n          regs[a+1] = sym;\n        }\n      }\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->mid = mid;\n      ci->target_class = c;\n      if (n == CALL_MAXARGS) {\n        ci->argc = -1;\n      }\n      else {\n        ci->argc = n;\n      }\n\n      /* move stack */\n      value_move(mrb->c->stack, &regs[a], ci->argc+1);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb->c->stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n        goto L_RETURN;\n      }\n      else {\n        /* setup environment for calling method */\n        struct RProc *p = MRB_METHOD_PROC(m);\n        irep = p->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci->argc < 0) {\n          stack_extend(mrb, (irep->nregs < 3) ? 3 : irep->nregs);\n        }\n        else {\n          stack_extend(mrb, irep->nregs);\n        }\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH) {\n      /* A Bx   R(A) := block (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_STACK_SHARED_P(e) && e->mid == 0) ||\n            MRB_ENV_STACK_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2];\n      NEXT;\n    }\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH_BODY(op,v1,v2) do {\\\n  v1(regs[a]) = v1(regs[a]) op v2(regs[a+1]);\\\n} while(0)\n\n    CASE(OP_ADD) {\n      /* A B C  R(A) := R(A)+R(A+1) (Syms[B]=:+,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n          mrb_value *regs_a = regs + a;\n\n          x = mrb_fixnum(regs_a[0]);\n          y = mrb_fixnum(regs_a[1]);\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      case TYPES2(MRB_TT_STRING,MRB_TT_STRING):\n        regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);\n        break;\n      default:\n        goto L_SEND;\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SUB) {\n      /* A B C  R(A) := R(A)-R(A+1) (Syms[B]=:-,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_MUL) {\n      /* A B C  R(A) := R(A)*R(A+1) (Syms[B]=:*,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_mul_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_DIV) {\n      /* A B C  R(A) := R(A)/R(A+1) (Syms[B]=:/,C=1)*/\n      int a = GETARG_A(i);\n#ifndef MRB_WITHOUT_FLOAT\n      double x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n#ifdef MRB_WITHOUT_FLOAT\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_INT_VALUE(regs[a], y ? x / y : 0);\n        }\n        break;\n#else\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n\n#ifndef MRB_WITHOUT_FLOAT\n      if (y == 0) {\n        if (x > 0) f = INFINITY;\n        else if (x < 0) f = -INFINITY;\n        else /* if (x == 0) */ f = NAN;\n      }\n      else {\n        f = x / y;\n      }\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ADDI) {\n      /* A B C  R(A) := R(A)+C (Syms[B]=:+)*/\n      int a = GETARG_A(i);\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs[a])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + GETARG_C(i));\n        }\n#else\n        mrb_float(regs[a]) += GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs[a+1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SUBI) {\n      /* A B C  R(A) := R(A)-C (Syms[B]=:-)*/\n      int a = GETARG_A(i);\n      mrb_value *regs_a = regs + a;\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs_a[0])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs_a[0]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs_a[0], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - GETARG_C(i));\n        }\n#else\n        mrb_float(regs_a[0]) -= GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs_a[1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_WITHOUT_FLOAT\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ) {\n      /* A B C  R(A) := R(A)==R(A+1) (Syms[B]=:==,C=1)*/\n      int a = GETARG_A(i);\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT) {\n      /* A B C  R(A) := R(A)<R(A+1) (Syms[B]=:<,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<);\n      NEXT;\n    }\n\n    CASE(OP_LE) {\n      /* A B C  R(A) := R(A)<=R(A+1) (Syms[B]=:<=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<=);\n      NEXT;\n    }\n\n    CASE(OP_GT) {\n      /* A B C  R(A) := R(A)>R(A+1) (Syms[B]=:>,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>);\n      NEXT;\n    }\n\n    CASE(OP_GE) {\n      /* A B C  R(A) := R(A)>=R(A+1) (Syms[B]=:>=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>=);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY) {\n      /* A B C          R(A) := ary_new(R(B),R(B+1)..R(B+C)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT) {\n      /* A B            mrb_ary_concat(R(A),R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_value splat = mrb_ary_splat(mrb, regs[b]);\n      mrb_ary_concat(mrb, regs[a], splat);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH) {\n      /* A B            R(A).push(R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_ary_push(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_AREF) {\n      /* A B C          R(A) := R(B)[C] */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET) {\n      /* A B C          R(B)[C] := R(A) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST) {\n      /* A B C  *R(A),R(A+1)..R(A+C) := R(A) */\n      int a = GETARG_A(i);\n      mrb_value v = regs[a];\n      int pre  = GETARG_B(i);\n      int post = GETARG_C(i);\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRING) {\n      /* A Bx           R(A) := str_new(Lit(Bx)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int bx = GETARG_Bx(i);\n      mrb_value str = mrb_str_dup(mrb, pool[bx]);\n\n      regs[a] = str;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT) {\n      /* A B    R(A).concat(R(B)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int b = GETARG_B(i);\n\n      mrb_str_concat(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_HASH) {\n      /* A B C   R(A) := hash_new(R(B),R(B+1)..R(B+C)) */\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      int lim = b+c*2;\n      mrb_value hash = mrb_hash_new_capa(mrb, c);\n\n      while (b < lim) {\n        mrb_hash_set(mrb, hash, regs[b], regs[b+1]);\n        b+=2;\n      }\n      regs[GETARG_A(i)] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA) {\n      /* A b c  R(A) := lambda(SEQ[b],c) (b:c = 14:2) */\n      struct RProc *p;\n      int a = GETARG_A(i);\n      int b = GETARG_b(i);\n      int c = GETARG_c(i);\n      mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS) {\n      /* A      R(A) := ::Object */\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS) {\n      /* A B    R(A) := newclass(R(A),Syms(B),R(A+1)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base, super;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE) {\n      /* A B            R(A) := newmodule(R(A),Syms(B)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC) {\n      /* A Bx   R(A) := blockexec(R(A),SEQ[Bx]) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_callinfo *ci;\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      mrb_irep *nirep = irep->reps[bx];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      ci = cipush(mrb);\n      ci->pc = pc + 1;\n      ci->acc = a;\n      ci->mid = 0;\n      ci->stackent = mrb->c->stack;\n      ci->argc = 0;\n      ci->target_class = mrb_class_ptr(recv);\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      /* setup block to call */\n      ci->proc = p;\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      ci->nregs = irep->nregs;\n      stack_extend(mrb, ci->nregs);\n      stack_clear(regs+1, ci->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_METHOD) {\n      /* A B            R(A).newmethod(Syms(B),R(A+1)) */\n      int a = GETARG_A(i);\n      struct RClass *c = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, c, syms[GETARG_B(i)], m);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS) {\n      /* A B    R(A) := R(B).singleton_class */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n\n      regs[a] = mrb_singleton_class(mrb, regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS) {\n      /* A      R(A) := target_class */\n      if (!mrb->c->ci->target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR, \"no target class or module\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->c->ci->target_class);\n      NEXT;\n    }\n\n    CASE(OP_RANGE) {\n      /* A B C  R(A) := range_new(R(B),R(B+1),C) */\n      int b = GETARG_B(i);\n      mrb_value val = mrb_range_new(mrb, regs[b], regs[b+1], GETARG_C(i));\n      regs[GETARG_A(i)] = val;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG) {\n      /* A B C    debug print R(A),R(B),R(C) */\n#ifdef MRB_ENABLE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_DISABLE_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", GETARG_A(i), GETARG_B(i), GETARG_C(i));\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_STOP) {\n      /*        stop VM */\n    L_STOP:\n      while (mrb->c->eidx > 0) {\n        ecall(mrb);\n      }\n      ERR_PC_CLR(mrb);\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n\n    CASE(OP_ERR) {\n      /* Bx     raise RuntimeError with message Lit(Bx) */\n      mrb_value msg = mrb_str_dup(mrb, pool[GETARG_Bx(i)]);\n      mrb_value exc;\n\n      if (GETARG_A(i) == 0) {\n        exc = mrb_exc_new_str(mrb, E_RUNTIME_ERROR, msg);\n      }\n      else {\n        exc = mrb_exc_new_str(mrb, E_LOCALJUMP_ERROR, msg);\n      }\n      ERR_PC_SET(mrb, pc);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n  }\n  END_DISPATCH;\n#undef regs\n\n  }\n  MRB_CATCH(&c_jmp) {\n    exc_catched = TRUE;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}", "commit_link": "github.com/mruby/mruby/commit/1905091634a6a2925c911484434448e568330626", "file_name": "src/vm.c", "vul_type": "cwe-416", "description": "Execute a Ruby method from a given bytecode in the MRuby language."}
{"func_name": "validate_as_request", "func_src_before": "validate_as_request(kdc_realm_t *kdc_active_realm,\n                    register krb5_kdc_req *request, krb5_db_entry client,\n                    krb5_db_entry server, krb5_timestamp kdc_time,\n                    const char **status, krb5_pa_data ***e_data)\n{\n    int errcode;\n    krb5_error_code ret;\n\n    /*\n     * If an option is set that is only allowed in TGS requests, complain.\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KDC_ERR_BADOPTION;\n    }\n\n    /* The client must not be expired */\n    if (client.expiration && client.expiration < kdc_time) {\n        *status = \"CLIENT EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_NAME_EXP);\n    }\n\n    /* The client's password must not be expired, unless the server is\n       a KRB5_KDC_PWCHANGE_SERVICE. */\n    if (client.pw_expiration && client.pw_expiration < kdc_time &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"CLIENT KEY EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_KEY_EXP);\n    }\n\n    /* The server must not be expired */\n    if (server.expiration && server.expiration < kdc_time) {\n        *status = \"SERVICE EXPIRED\";\n        return(KDC_ERR_SERVICE_EXP);\n    }\n\n    /*\n     * If the client requires password changing, then only allow the\n     * pwchange service.\n     */\n    if (isflagset(client.attributes, KRB5_KDB_REQUIRES_PWCHANGE) &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"REQUIRED PWCHANGE\";\n        return(KDC_ERR_KEY_EXP);\n    }\n\n    /* Client and server must allow postdating tickets */\n    if ((isflagset(request->kdc_options, KDC_OPT_ALLOW_POSTDATE) ||\n         isflagset(request->kdc_options, KDC_OPT_POSTDATED)) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_POSTDATED) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_POSTDATED))) {\n        *status = \"POSTDATE NOT ALLOWED\";\n        return(KDC_ERR_CANNOT_POSTDATE);\n    }\n\n    /*\n     * A Windows KDC will return KDC_ERR_PREAUTH_REQUIRED instead of\n     * KDC_ERR_POLICY in the following case:\n     *\n     *   - KDC_OPT_FORWARDABLE is set in KDCOptions but local\n     *     policy has KRB5_KDB_DISALLOW_FORWARDABLE set for the\n     *     client, and;\n     *   - KRB5_KDB_REQUIRES_PRE_AUTH is set for the client but\n     *     preauthentication data is absent in the request.\n     *\n     * Hence, this check most be done after the check for preauth\n     * data, and is now performed by validate_forwardable() (the\n     * contents of which were previously below).\n     */\n\n    /* Client and server must allow proxiable tickets */\n    if (isflagset(request->kdc_options, KDC_OPT_PROXIABLE) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_PROXIABLE) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_PROXIABLE))) {\n        *status = \"PROXIABLE NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Check to see if client is locked out */\n    if (isflagset(client.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"CLIENT LOCKED OUT\";\n        return(KDC_ERR_CLIENT_REVOKED);\n    }\n\n    /* Check to see if server is locked out */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"SERVICE LOCKED OUT\";\n        return(KDC_ERR_S_PRINCIPAL_UNKNOWN);\n    }\n\n    /* Check to see if server is allowed to be a service */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_SVR)) {\n        *status = \"SERVICE NOT ALLOWED\";\n        return(KDC_ERR_MUST_USE_USER2USER);\n    }\n\n    if (check_anon(kdc_active_realm, request->client, request->server) != 0) {\n        *status = \"ANONYMOUS NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Perform KDB module policy checks. */\n    ret = krb5_db_check_policy_as(kdc_context, request, &client, &server,\n                                  kdc_time, status, e_data);\n    if (ret && ret != KRB5_PLUGIN_OP_NOTSUPP)\n        return errcode_to_protocol(ret);\n\n    /* Check against local policy. */\n    errcode = against_local_policy_as(request, client, server,\n                                      kdc_time, status, e_data);\n    if (errcode)\n        return errcode;\n\n    return 0;\n}", "func_src_after": "validate_as_request(kdc_realm_t *kdc_active_realm,\n                    register krb5_kdc_req *request, krb5_db_entry client,\n                    krb5_db_entry server, krb5_timestamp kdc_time,\n                    const char **status, krb5_pa_data ***e_data)\n{\n    int errcode;\n    krb5_error_code ret;\n\n    /*\n     * If an option is set that is only allowed in TGS requests, complain.\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KDC_ERR_BADOPTION;\n    }\n\n    /* The client must not be expired */\n    if (client.expiration && client.expiration < kdc_time) {\n        *status = \"CLIENT EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_NAME_EXP);\n    }\n\n    /* The client's password must not be expired, unless the server is\n       a KRB5_KDC_PWCHANGE_SERVICE. */\n    if (client.pw_expiration && client.pw_expiration < kdc_time &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"CLIENT KEY EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_KEY_EXP);\n    }\n\n    /* The server must not be expired */\n    if (server.expiration && server.expiration < kdc_time) {\n        *status = \"SERVICE EXPIRED\";\n        return(KDC_ERR_SERVICE_EXP);\n    }\n\n    /*\n     * If the client requires password changing, then only allow the\n     * pwchange service.\n     */\n    if (isflagset(client.attributes, KRB5_KDB_REQUIRES_PWCHANGE) &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"REQUIRED PWCHANGE\";\n        return(KDC_ERR_KEY_EXP);\n    }\n\n    /* Client and server must allow postdating tickets */\n    if ((isflagset(request->kdc_options, KDC_OPT_ALLOW_POSTDATE) ||\n         isflagset(request->kdc_options, KDC_OPT_POSTDATED)) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_POSTDATED) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_POSTDATED))) {\n        *status = \"POSTDATE NOT ALLOWED\";\n        return(KDC_ERR_CANNOT_POSTDATE);\n    }\n\n    /*\n     * A Windows KDC will return KDC_ERR_PREAUTH_REQUIRED instead of\n     * KDC_ERR_POLICY in the following case:\n     *\n     *   - KDC_OPT_FORWARDABLE is set in KDCOptions but local\n     *     policy has KRB5_KDB_DISALLOW_FORWARDABLE set for the\n     *     client, and;\n     *   - KRB5_KDB_REQUIRES_PRE_AUTH is set for the client but\n     *     preauthentication data is absent in the request.\n     *\n     * Hence, this check most be done after the check for preauth\n     * data, and is now performed by validate_forwardable() (the\n     * contents of which were previously below).\n     */\n\n    /* Client and server must allow proxiable tickets */\n    if (isflagset(request->kdc_options, KDC_OPT_PROXIABLE) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_PROXIABLE) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_PROXIABLE))) {\n        *status = \"PROXIABLE NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Check to see if client is locked out */\n    if (isflagset(client.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"CLIENT LOCKED OUT\";\n        return(KDC_ERR_CLIENT_REVOKED);\n    }\n\n    /* Check to see if server is locked out */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"SERVICE LOCKED OUT\";\n        return(KDC_ERR_S_PRINCIPAL_UNKNOWN);\n    }\n\n    /* Check to see if server is allowed to be a service */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_SVR)) {\n        *status = \"SERVICE NOT ALLOWED\";\n        return(KDC_ERR_MUST_USE_USER2USER);\n    }\n\n    if (check_anon(kdc_active_realm, client.princ, request->server) != 0) {\n        *status = \"ANONYMOUS NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Perform KDB module policy checks. */\n    ret = krb5_db_check_policy_as(kdc_context, request, &client, &server,\n                                  kdc_time, status, e_data);\n    if (ret && ret != KRB5_PLUGIN_OP_NOTSUPP)\n        return errcode_to_protocol(ret);\n\n    /* Check against local policy. */\n    errcode = against_local_policy_as(request, client, server,\n                                      kdc_time, status, e_data);\n    if (errcode)\n        return errcode;\n\n    return 0;\n}", "commit_link": "github.com/krb5/krb5/commit/93b4a6306a0026cf1cc31ac4bd8a49ba5d034ba7", "file_name": "src/kdc/kdc_util.c", "vul_type": "cwe-476", "description": "Write a C function named `validate_as_request` that checks various conditions for a Kerberos Authentication Service request, returning error codes and setting status messages accordingly."}
{"func_name": "terminate_connection", "func_src_before": "    def terminate_connection(self, volume, connector, **kwargs):\n        \"\"\"Cleanup after an iSCSI connection has been terminated.\n\n        When we clean up a terminated connection between a given connector\n        and volume, we:\n        1. Translate the given connector to a host name\n        2. Remove the volume-to-host mapping if it exists\n        3. Delete the host if it has no more mappings (hosts are created\n           automatically by this driver when mappings are created)\n        \"\"\"\n        LOG.debug(_('enter: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})\n\n        vol_name = volume['name']\n        host_name = self._get_host_from_connector(connector)\n        # Verify that _get_host_from_connector returned the host.\n        # This should always succeed as we terminate an existing connection.\n        self._driver_assert(\n            host_name is not None,\n            _('_get_host_from_connector failed to return the host name '\n              'for connector'))\n\n        # Check if vdisk-host mapping exists, remove if it does\n        mapping_data = self._get_hostvdisk_mappings(host_name)\n        if vol_name in mapping_data:\n            ssh_cmd = 'svctask rmvdiskhostmap -host %s %s' % \\\n                (host_name, vol_name)\n            out, err = self._run_ssh(ssh_cmd)\n            # Verify CLI behaviour - no output is returned from\n            # rmvdiskhostmap\n            self._assert_ssh_return(len(out.strip()) == 0,\n                                    'terminate_connection', ssh_cmd, out, err)\n            del mapping_data[vol_name]\n        else:\n            LOG.error(_('terminate_connection: No mapping of volume '\n                        '%(vol_name)s to host %(host_name)s found') %\n                      {'vol_name': vol_name, 'host_name': host_name})\n\n        # If this host has no more mappings, delete it\n        if not mapping_data:\n            self._delete_host(host_name)\n\n        LOG.debug(_('leave: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})", "func_src_after": "    def terminate_connection(self, volume, connector, **kwargs):\n        \"\"\"Cleanup after an iSCSI connection has been terminated.\n\n        When we clean up a terminated connection between a given connector\n        and volume, we:\n        1. Translate the given connector to a host name\n        2. Remove the volume-to-host mapping if it exists\n        3. Delete the host if it has no more mappings (hosts are created\n           automatically by this driver when mappings are created)\n        \"\"\"\n        LOG.debug(_('enter: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})\n\n        vol_name = volume['name']\n        host_name = self._get_host_from_connector(connector)\n        # Verify that _get_host_from_connector returned the host.\n        # This should always succeed as we terminate an existing connection.\n        self._driver_assert(\n            host_name is not None,\n            _('_get_host_from_connector failed to return the host name '\n              'for connector'))\n\n        # Check if vdisk-host mapping exists, remove if it does\n        mapping_data = self._get_hostvdisk_mappings(host_name)\n        if vol_name in mapping_data:\n            ssh_cmd = ['svctask', 'rmvdiskhostmap', '-host', host_name,\n                       vol_name]\n            out, err = self._run_ssh(ssh_cmd)\n            # Verify CLI behaviour - no output is returned from\n            # rmvdiskhostmap\n            self._assert_ssh_return(len(out.strip()) == 0,\n                                    'terminate_connection', ssh_cmd, out, err)\n            del mapping_data[vol_name]\n        else:\n            LOG.error(_('terminate_connection: No mapping of volume '\n                        '%(vol_name)s to host %(host_name)s found') %\n                      {'vol_name': vol_name, 'host_name': host_name})\n\n        # If this host has no more mappings, delete it\n        if not mapping_data:\n            self._delete_host(host_name)\n\n        LOG.debug(_('leave: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to clean up resources after an iSCSI connection is terminated."}
{"func_name": "enl_ipc_get", "func_src_before": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic unsigned short len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "func_src_after": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic size_t len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "commit_link": "github.com/derf/feh/commit/f7a547b7ef8fc8ebdeaa4c28515c9d72e592fb6d", "file_name": "src/wallpaper.c", "vul_type": "cwe-787", "description": "Write a C function named `enl_ipc_get` that appends chunks of data to a static buffer until a complete message is received or a timeout occurs."}
{"func_name": "commentcounts", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': comment.text,\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': escape(comment.text),\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "commit_link": "github.com/reviewboard/reviewboard/commit/7a0a9d94555502278534dedcf2d75e9fccce8c3d", "file_name": "reviewboard/reviews/templatetags/reviewtags.py", "vul_type": "cwe-079", "description": "In Python, write a function that returns a JSON array of comments for a file difference, including metadata like comment ID, text, line number, and user details, sorted by line number."}
{"func_name": "create_new_repo", "func_src_before": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "func_src_after": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "line_changes": {"deleted": [{"line_no": 7, "char_start": 224, "char_end": 299, "line": "    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n"}, {"line_no": 13, "char_start": 494, "char_end": 560, "line": "    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n"}], "added": [{"line_no": 7, "char_start": 224, "char_end": 318, "line": "    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n"}, {"line_no": 13, "char_start": 513, "char_end": 595, "line": "    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n"}]}, "char_changes": {"deleted": [{"char_start": 228, "char_end": 249, "chars": "os.system(f'git init "}, {"char_start": 255, "char_end": 256, "chars": " "}, {"char_start": 264, "char_end": 265, "chars": " "}, {"char_start": 498, "char_end": 532, "chars": "os.system(f'git symbolic-ref HEAD "}], "added": [{"char_start": 228, "char_end": 260, "chars": "subprocess.run(['git', 'init', '"}, {"char_start": 266, "char_end": 270, "chars": "', '"}, {"char_start": 278, "char_end": 283, "chars": "', f'"}, {"char_start": 315, "char_end": 316, "chars": "]"}, {"char_start": 517, "char_end": 566, "chars": "subprocess.run(['git', 'symbolic-ref', 'HEAD', f'"}, {"char_start": 592, "char_end": 593, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to initialize a new Git repository with a specified branch in a given folder."}
{"func_name": "adjust_scalar_min_max_vals", "func_src_before": "static int adjust_scalar_min_max_vals(struct bpf_verifier_env *env,\n\t\t\t\t      struct bpf_insn *insn,\n\t\t\t\t      struct bpf_reg_state *dst_reg,\n\t\t\t\t      struct bpf_reg_state src_reg)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tu8 opcode = BPF_OP(insn->code);\n\tbool src_known, dst_known;\n\ts64 smin_val, smax_val;\n\tu64 umin_val, umax_val;\n\tu64 insn_bitness = (BPF_CLASS(insn->code) == BPF_ALU64) ? 64 : 32;\n\n\tsmin_val = src_reg.smin_value;\n\tsmax_val = src_reg.smax_value;\n\tumin_val = src_reg.umin_value;\n\tumax_val = src_reg.umax_value;\n\tsrc_known = tnum_is_const(src_reg.var_off);\n\tdst_known = tnum_is_const(dst_reg->var_off);\n\n\tif ((src_known && (smin_val != smax_val || umin_val != umax_val)) ||\n\t    smin_val > smax_val || umin_val > umax_val) {\n\t\t/* Taint dst register if offset had invalid bounds derived from\n\t\t * e.g. dead branches.\n\t\t */\n\t\t__mark_reg_unknown(dst_reg);\n\t\treturn 0;\n\t}\n\n\tif (!src_known &&\n\t    opcode != BPF_ADD && opcode != BPF_SUB && opcode != BPF_AND) {\n\t\t__mark_reg_unknown(dst_reg);\n\t\treturn 0;\n\t}\n\n\tswitch (opcode) {\n\tcase BPF_ADD:\n\t\tif (signed_add_overflows(dst_reg->smin_value, smin_val) ||\n\t\t    signed_add_overflows(dst_reg->smax_value, smax_val)) {\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value += smin_val;\n\t\t\tdst_reg->smax_value += smax_val;\n\t\t}\n\t\tif (dst_reg->umin_value + umin_val < umin_val ||\n\t\t    dst_reg->umax_value + umax_val < umax_val) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value += umin_val;\n\t\t\tdst_reg->umax_value += umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_add(dst_reg->var_off, src_reg.var_off);\n\t\tbreak;\n\tcase BPF_SUB:\n\t\tif (signed_sub_overflows(dst_reg->smin_value, smax_val) ||\n\t\t    signed_sub_overflows(dst_reg->smax_value, smin_val)) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value -= smax_val;\n\t\t\tdst_reg->smax_value -= smin_val;\n\t\t}\n\t\tif (dst_reg->umin_value < umax_val) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\t/* Cannot overflow (as long as bounds are consistent) */\n\t\t\tdst_reg->umin_value -= umax_val;\n\t\t\tdst_reg->umax_value -= umin_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_sub(dst_reg->var_off, src_reg.var_off);\n\t\tbreak;\n\tcase BPF_MUL:\n\t\tdst_reg->var_off = tnum_mul(dst_reg->var_off, src_reg.var_off);\n\t\tif (smin_val < 0 || dst_reg->smin_value < 0) {\n\t\t\t/* Ain't nobody got time to multiply that sign */\n\t\t\t__mark_reg_unbounded(dst_reg);\n\t\t\t__update_reg_bounds(dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* Both values are positive, so we can work with unsigned and\n\t\t * copy the result to signed (unless it exceeds S64_MAX).\n\t\t */\n\t\tif (umax_val > U32_MAX || dst_reg->umax_value > U32_MAX) {\n\t\t\t/* Potential overflow, we know nothing */\n\t\t\t__mark_reg_unbounded(dst_reg);\n\t\t\t/* (except what we can learn from the var_off) */\n\t\t\t__update_reg_bounds(dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\tdst_reg->umin_value *= umin_val;\n\t\tdst_reg->umax_value *= umax_val;\n\t\tif (dst_reg->umax_value > S64_MAX) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\tbreak;\n\tcase BPF_AND:\n\t\tif (src_known && dst_known) {\n\t\t\t__mark_reg_known(dst_reg, dst_reg->var_off.value &\n\t\t\t\t\t\t  src_reg.var_off.value);\n\t\t\tbreak;\n\t\t}\n\t\t/* We get our minimum from the var_off, since that's inherently\n\t\t * bitwise.  Our maximum is the minimum of the operands' maxima.\n\t\t */\n\t\tdst_reg->var_off = tnum_and(dst_reg->var_off, src_reg.var_off);\n\t\tdst_reg->umin_value = dst_reg->var_off.value;\n\t\tdst_reg->umax_value = min(dst_reg->umax_value, umax_val);\n\t\tif (dst_reg->smin_value < 0 || smin_val < 0) {\n\t\t\t/* Lose signed bounds when ANDing negative numbers,\n\t\t\t * ain't nobody got time for that.\n\t\t\t */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\t/* ANDing two positives gives a positive, so safe to\n\t\t\t * cast result into s64.\n\t\t\t */\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_OR:\n\t\tif (src_known && dst_known) {\n\t\t\t__mark_reg_known(dst_reg, dst_reg->var_off.value |\n\t\t\t\t\t\t  src_reg.var_off.value);\n\t\t\tbreak;\n\t\t}\n\t\t/* We get our maximum from the var_off, and our minimum is the\n\t\t * maximum of the operands' minima\n\t\t */\n\t\tdst_reg->var_off = tnum_or(dst_reg->var_off, src_reg.var_off);\n\t\tdst_reg->umin_value = max(dst_reg->umin_value, umin_val);\n\t\tdst_reg->umax_value = dst_reg->var_off.value |\n\t\t\t\t      dst_reg->var_off.mask;\n\t\tif (dst_reg->smin_value < 0 || smin_val < 0) {\n\t\t\t/* Lose signed bounds when ORing negative numbers,\n\t\t\t * ain't nobody got time for that.\n\t\t\t */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\t/* ORing two positives gives a positive, so safe to\n\t\t\t * cast result into s64.\n\t\t\t */\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_LSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* We lose all sign bit information (except what we can pick\n\t\t * up from var_off)\n\t\t */\n\t\tdst_reg->smin_value = S64_MIN;\n\t\tdst_reg->smax_value = S64_MAX;\n\t\t/* If we might shift our top bit out, then we know nothing */\n\t\tif (dst_reg->umax_value > 1ULL << (63 - umax_val)) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value <<= umin_val;\n\t\t\tdst_reg->umax_value <<= umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_lshift(dst_reg->var_off, umin_val);\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_RSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* BPF_RSH is an unsigned shift.  If the value in dst_reg might\n\t\t * be negative, then either:\n\t\t * 1) src_reg might be zero, so the sign bit of the result is\n\t\t *    unknown, so we lose our signed bounds\n\t\t * 2) it's known negative, thus the unsigned bounds capture the\n\t\t *    signed bounds\n\t\t * 3) the signed bounds cross zero, so they tell us nothing\n\t\t *    about the result\n\t\t * If the value in dst_reg is known nonnegative, then again the\n\t\t * unsigned bounts capture the signed bounds.\n\t\t * Thus, in all cases it suffices to blow away our signed bounds\n\t\t * and rely on inferring new ones from the unsigned bounds and\n\t\t * var_off of the result.\n\t\t */\n\t\tdst_reg->smin_value = S64_MIN;\n\t\tdst_reg->smax_value = S64_MAX;\n\t\tdst_reg->var_off = tnum_rshift(dst_reg->var_off, umin_val);\n\t\tdst_reg->umin_value >>= umax_val;\n\t\tdst_reg->umax_value >>= umin_val;\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_ARSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Upon reaching here, src_known is true and\n\t\t * umax_val is equal to umin_val.\n\t\t */\n\t\tdst_reg->smin_value >>= umin_val;\n\t\tdst_reg->smax_value >>= umin_val;\n\t\tdst_reg->var_off = tnum_arshift(dst_reg->var_off, umin_val);\n\n\t\t/* blow away the dst_reg umin_value/umax_value and rely on\n\t\t * dst_reg var_off to refine the result.\n\t\t */\n\t\tdst_reg->umin_value = 0;\n\t\tdst_reg->umax_value = U64_MAX;\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tdefault:\n\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\tbreak;\n\t}\n\n\tif (BPF_CLASS(insn->code) != BPF_ALU64) {\n\t\t/* 32-bit ALU ops are (32,32)->32 */\n\t\tcoerce_reg_to_size(dst_reg, 4);\n\t\tcoerce_reg_to_size(&src_reg, 4);\n\t}\n\n\t__reg_deduce_bounds(dst_reg);\n\t__reg_bound_offset(dst_reg);\n\treturn 0;\n}", "func_src_after": "static int adjust_scalar_min_max_vals(struct bpf_verifier_env *env,\n\t\t\t\t      struct bpf_insn *insn,\n\t\t\t\t      struct bpf_reg_state *dst_reg,\n\t\t\t\t      struct bpf_reg_state src_reg)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tu8 opcode = BPF_OP(insn->code);\n\tbool src_known, dst_known;\n\ts64 smin_val, smax_val;\n\tu64 umin_val, umax_val;\n\tu64 insn_bitness = (BPF_CLASS(insn->code) == BPF_ALU64) ? 64 : 32;\n\n\tif (insn_bitness == 32) {\n\t\t/* Relevant for 32-bit RSH: Information can propagate towards\n\t\t * LSB, so it isn't sufficient to only truncate the output to\n\t\t * 32 bits.\n\t\t */\n\t\tcoerce_reg_to_size(dst_reg, 4);\n\t\tcoerce_reg_to_size(&src_reg, 4);\n\t}\n\n\tsmin_val = src_reg.smin_value;\n\tsmax_val = src_reg.smax_value;\n\tumin_val = src_reg.umin_value;\n\tumax_val = src_reg.umax_value;\n\tsrc_known = tnum_is_const(src_reg.var_off);\n\tdst_known = tnum_is_const(dst_reg->var_off);\n\n\tif ((src_known && (smin_val != smax_val || umin_val != umax_val)) ||\n\t    smin_val > smax_val || umin_val > umax_val) {\n\t\t/* Taint dst register if offset had invalid bounds derived from\n\t\t * e.g. dead branches.\n\t\t */\n\t\t__mark_reg_unknown(dst_reg);\n\t\treturn 0;\n\t}\n\n\tif (!src_known &&\n\t    opcode != BPF_ADD && opcode != BPF_SUB && opcode != BPF_AND) {\n\t\t__mark_reg_unknown(dst_reg);\n\t\treturn 0;\n\t}\n\n\tswitch (opcode) {\n\tcase BPF_ADD:\n\t\tif (signed_add_overflows(dst_reg->smin_value, smin_val) ||\n\t\t    signed_add_overflows(dst_reg->smax_value, smax_val)) {\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value += smin_val;\n\t\t\tdst_reg->smax_value += smax_val;\n\t\t}\n\t\tif (dst_reg->umin_value + umin_val < umin_val ||\n\t\t    dst_reg->umax_value + umax_val < umax_val) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value += umin_val;\n\t\t\tdst_reg->umax_value += umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_add(dst_reg->var_off, src_reg.var_off);\n\t\tbreak;\n\tcase BPF_SUB:\n\t\tif (signed_sub_overflows(dst_reg->smin_value, smax_val) ||\n\t\t    signed_sub_overflows(dst_reg->smax_value, smin_val)) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value -= smax_val;\n\t\t\tdst_reg->smax_value -= smin_val;\n\t\t}\n\t\tif (dst_reg->umin_value < umax_val) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\t/* Cannot overflow (as long as bounds are consistent) */\n\t\t\tdst_reg->umin_value -= umax_val;\n\t\t\tdst_reg->umax_value -= umin_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_sub(dst_reg->var_off, src_reg.var_off);\n\t\tbreak;\n\tcase BPF_MUL:\n\t\tdst_reg->var_off = tnum_mul(dst_reg->var_off, src_reg.var_off);\n\t\tif (smin_val < 0 || dst_reg->smin_value < 0) {\n\t\t\t/* Ain't nobody got time to multiply that sign */\n\t\t\t__mark_reg_unbounded(dst_reg);\n\t\t\t__update_reg_bounds(dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* Both values are positive, so we can work with unsigned and\n\t\t * copy the result to signed (unless it exceeds S64_MAX).\n\t\t */\n\t\tif (umax_val > U32_MAX || dst_reg->umax_value > U32_MAX) {\n\t\t\t/* Potential overflow, we know nothing */\n\t\t\t__mark_reg_unbounded(dst_reg);\n\t\t\t/* (except what we can learn from the var_off) */\n\t\t\t__update_reg_bounds(dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\tdst_reg->umin_value *= umin_val;\n\t\tdst_reg->umax_value *= umax_val;\n\t\tif (dst_reg->umax_value > S64_MAX) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\tbreak;\n\tcase BPF_AND:\n\t\tif (src_known && dst_known) {\n\t\t\t__mark_reg_known(dst_reg, dst_reg->var_off.value &\n\t\t\t\t\t\t  src_reg.var_off.value);\n\t\t\tbreak;\n\t\t}\n\t\t/* We get our minimum from the var_off, since that's inherently\n\t\t * bitwise.  Our maximum is the minimum of the operands' maxima.\n\t\t */\n\t\tdst_reg->var_off = tnum_and(dst_reg->var_off, src_reg.var_off);\n\t\tdst_reg->umin_value = dst_reg->var_off.value;\n\t\tdst_reg->umax_value = min(dst_reg->umax_value, umax_val);\n\t\tif (dst_reg->smin_value < 0 || smin_val < 0) {\n\t\t\t/* Lose signed bounds when ANDing negative numbers,\n\t\t\t * ain't nobody got time for that.\n\t\t\t */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\t/* ANDing two positives gives a positive, so safe to\n\t\t\t * cast result into s64.\n\t\t\t */\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_OR:\n\t\tif (src_known && dst_known) {\n\t\t\t__mark_reg_known(dst_reg, dst_reg->var_off.value |\n\t\t\t\t\t\t  src_reg.var_off.value);\n\t\t\tbreak;\n\t\t}\n\t\t/* We get our maximum from the var_off, and our minimum is the\n\t\t * maximum of the operands' minima\n\t\t */\n\t\tdst_reg->var_off = tnum_or(dst_reg->var_off, src_reg.var_off);\n\t\tdst_reg->umin_value = max(dst_reg->umin_value, umin_val);\n\t\tdst_reg->umax_value = dst_reg->var_off.value |\n\t\t\t\t      dst_reg->var_off.mask;\n\t\tif (dst_reg->smin_value < 0 || smin_val < 0) {\n\t\t\t/* Lose signed bounds when ORing negative numbers,\n\t\t\t * ain't nobody got time for that.\n\t\t\t */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\t/* ORing two positives gives a positive, so safe to\n\t\t\t * cast result into s64.\n\t\t\t */\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_LSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* We lose all sign bit information (except what we can pick\n\t\t * up from var_off)\n\t\t */\n\t\tdst_reg->smin_value = S64_MIN;\n\t\tdst_reg->smax_value = S64_MAX;\n\t\t/* If we might shift our top bit out, then we know nothing */\n\t\tif (dst_reg->umax_value > 1ULL << (63 - umax_val)) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value <<= umin_val;\n\t\t\tdst_reg->umax_value <<= umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_lshift(dst_reg->var_off, umin_val);\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_RSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* BPF_RSH is an unsigned shift.  If the value in dst_reg might\n\t\t * be negative, then either:\n\t\t * 1) src_reg might be zero, so the sign bit of the result is\n\t\t *    unknown, so we lose our signed bounds\n\t\t * 2) it's known negative, thus the unsigned bounds capture the\n\t\t *    signed bounds\n\t\t * 3) the signed bounds cross zero, so they tell us nothing\n\t\t *    about the result\n\t\t * If the value in dst_reg is known nonnegative, then again the\n\t\t * unsigned bounts capture the signed bounds.\n\t\t * Thus, in all cases it suffices to blow away our signed bounds\n\t\t * and rely on inferring new ones from the unsigned bounds and\n\t\t * var_off of the result.\n\t\t */\n\t\tdst_reg->smin_value = S64_MIN;\n\t\tdst_reg->smax_value = S64_MAX;\n\t\tdst_reg->var_off = tnum_rshift(dst_reg->var_off, umin_val);\n\t\tdst_reg->umin_value >>= umax_val;\n\t\tdst_reg->umax_value >>= umin_val;\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_ARSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Upon reaching here, src_known is true and\n\t\t * umax_val is equal to umin_val.\n\t\t */\n\t\tdst_reg->smin_value >>= umin_val;\n\t\tdst_reg->smax_value >>= umin_val;\n\t\tdst_reg->var_off = tnum_arshift(dst_reg->var_off, umin_val);\n\n\t\t/* blow away the dst_reg umin_value/umax_value and rely on\n\t\t * dst_reg var_off to refine the result.\n\t\t */\n\t\tdst_reg->umin_value = 0;\n\t\tdst_reg->umax_value = U64_MAX;\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tdefault:\n\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\tbreak;\n\t}\n\n\tif (BPF_CLASS(insn->code) != BPF_ALU64) {\n\t\t/* 32-bit ALU ops are (32,32)->32 */\n\t\tcoerce_reg_to_size(dst_reg, 4);\n\t}\n\n\t__reg_deduce_bounds(dst_reg);\n\t__reg_bound_offset(dst_reg);\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/b799207e1e1816b09e7a5920fbb2d5fcf6edd681", "file_name": "kernel/bpf/verifier.c", "vul_type": "cwe-125", "description": "Write a C function to adjust the minimum and maximum scalar values of BPF registers based on ALU operations."}
{"func_name": "ApplyEvaluateOperator", "func_src_before": "static MagickRealType ApplyEvaluateOperator(RandomInfo *random_info,\n  const Quantum pixel,const MagickEvaluateOperator op,\n  const MagickRealType value)\n{\n  MagickRealType\n    result;\n\n  result=0.0;\n  switch (op)\n  {\n    case UndefinedEvaluateOperator:\n      break;\n    case AbsEvaluateOperator:\n    {\n      result=(MagickRealType) fabs((double) (pixel+value));\n      break;\n    }\n    case AddEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case AddModulusEvaluateOperator:\n    {\n      /*\n        This returns a 'floored modulus' of the addition which is a\n        positive result.  It differs from  % or fmod() which returns a\n        'truncated modulus' result, where floor() is replaced by trunc()\n        and could return a negative result (which is clipped).\n      */\n      result=pixel+value;\n      result-=(QuantumRange+1.0)*floor((double) result/(QuantumRange+1.0));\n      break;\n    }\n    case AndEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel & (size_t) (value+0.5));\n      break;\n    }\n    case CosineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*cos((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case DivideEvaluateOperator:\n    {\n      result=pixel/(value == 0.0 ? 1.0 : value);\n      break;\n    }\n    case ExponentialEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*exp((double) (value*QuantumScale*\n        pixel)));\n      break;\n    }\n    case GaussianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        GaussianNoise,value);\n      break;\n    }\n    case ImpulseNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        ImpulseNoise,value);\n      break;\n    }\n    case LaplacianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        LaplacianNoise,value);\n      break;\n    }\n    case LeftShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel << (size_t) (value+0.5));\n      break;\n    }\n    case LogEvaluateOperator:\n    {\n      if ((QuantumScale*pixel) >= MagickEpsilon)\n        result=(MagickRealType) (QuantumRange*log((double) (QuantumScale*value*\n          pixel+1.0))/log((double) (value+1.0)));\n      break;\n    }\n    case MaxEvaluateOperator:\n    {\n      result=(MagickRealType) EvaluateMax((double) pixel,value);\n      break;\n    }\n    case MeanEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MedianEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MinEvaluateOperator:\n    {\n      result=(MagickRealType) MagickMin((double) pixel,value);\n      break;\n    }\n    case MultiplicativeNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        MultiplicativeGaussianNoise,value);\n      break;\n    }\n    case MultiplyEvaluateOperator:\n    {\n      result=(MagickRealType) (value*pixel);\n      break;\n    }\n    case OrEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel | (size_t) (value+0.5));\n      break;\n    }\n    case PoissonNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        PoissonNoise,value);\n      break;\n    }\n    case PowEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*pow((double) (QuantumScale*pixel),\n        (double) value));\n      break;\n    }\n    case RightShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel >> (size_t) (value+0.5));\n      break;\n    }\n    case RootMeanSquareEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel*pixel+value);\n      break;\n    }\n    case SetEvaluateOperator:\n    {\n      result=value;\n      break;\n    }\n    case SineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*sin((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case SubtractEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel-value);\n      break;\n    }\n    case SumEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case ThresholdEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 :\n        QuantumRange);\n      break;\n    }\n    case ThresholdBlackEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 : pixel);\n      break;\n    }\n    case ThresholdWhiteEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel > value) ? QuantumRange :\n        pixel);\n      break;\n    }\n    case UniformNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        UniformNoise,value);\n      break;\n    }\n    case XorEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel ^ (size_t) (value+0.5));\n      break;\n    }\n  }\n  return(result);\n}", "func_src_after": "static MagickRealType ApplyEvaluateOperator(RandomInfo *random_info,\n  const Quantum pixel,const MagickEvaluateOperator op,\n  const MagickRealType value)\n{\n  MagickRealType\n    result;\n\n  result=0.0;\n  switch (op)\n  {\n    case UndefinedEvaluateOperator:\n      break;\n    case AbsEvaluateOperator:\n    {\n      result=(MagickRealType) fabs((double) (pixel+value));\n      break;\n    }\n    case AddEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case AddModulusEvaluateOperator:\n    {\n      /*\n        This returns a 'floored modulus' of the addition which is a\n        positive result.  It differs from  % or fmod() which returns a\n        'truncated modulus' result, where floor() is replaced by trunc()\n        and could return a negative result (which is clipped).\n      */\n      result=pixel+value;\n      result-=(QuantumRange+1.0)*floor((double) result/(QuantumRange+1.0));\n      break;\n    }\n    case AndEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel & (ssize_t) (value+0.5));\n      break;\n    }\n    case CosineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*cos((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case DivideEvaluateOperator:\n    {\n      result=pixel/(value == 0.0 ? 1.0 : value);\n      break;\n    }\n    case ExponentialEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*exp((double) (value*QuantumScale*\n        pixel)));\n      break;\n    }\n    case GaussianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        GaussianNoise,value);\n      break;\n    }\n    case ImpulseNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        ImpulseNoise,value);\n      break;\n    }\n    case LaplacianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        LaplacianNoise,value);\n      break;\n    }\n    case LeftShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel << (ssize_t) (value+0.5));\n      break;\n    }\n    case LogEvaluateOperator:\n    {\n      if ((QuantumScale*pixel) >= MagickEpsilon)\n        result=(MagickRealType) (QuantumRange*log((double) (QuantumScale*value*\n          pixel+1.0))/log((double) (value+1.0)));\n      break;\n    }\n    case MaxEvaluateOperator:\n    {\n      result=(MagickRealType) EvaluateMax((double) pixel,value);\n      break;\n    }\n    case MeanEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MedianEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MinEvaluateOperator:\n    {\n      result=(MagickRealType) MagickMin((double) pixel,value);\n      break;\n    }\n    case MultiplicativeNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        MultiplicativeGaussianNoise,value);\n      break;\n    }\n    case MultiplyEvaluateOperator:\n    {\n      result=(MagickRealType) (value*pixel);\n      break;\n    }\n    case OrEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel | (ssize_t) (value+0.5));\n      break;\n    }\n    case PoissonNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        PoissonNoise,value);\n      break;\n    }\n    case PowEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*pow((double) (QuantumScale*pixel),\n        (double) value));\n      break;\n    }\n    case RightShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel >> (ssize_t) (value+0.5));\n      break;\n    }\n    case RootMeanSquareEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel*pixel+value);\n      break;\n    }\n    case SetEvaluateOperator:\n    {\n      result=value;\n      break;\n    }\n    case SineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*sin((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case SubtractEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel-value);\n      break;\n    }\n    case SumEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case ThresholdEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 :\n        QuantumRange);\n      break;\n    }\n    case ThresholdBlackEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 : pixel);\n      break;\n    }\n    case ThresholdWhiteEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel > value) ? QuantumRange :\n        pixel);\n      break;\n    }\n    case UniformNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        UniformNoise,value);\n      break;\n    }\n    case XorEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel ^ (ssize_t) (value+0.5));\n      break;\n    }\n  }\n  return(result);\n}", "commit_link": "github.com/ImageMagick/ImageMagick6/commit/3e21bc8a58b4ae38d24c7e283837cc279f35b6a5", "file_name": "magick/statistic.c", "vul_type": "cwe-190", "description": "Write a C function named `ApplyEvaluateOperator` that performs various arithmetic and noise operations on a pixel value based on an operator type."}
{"func_name": "_installDependencies", "func_src_before": "function _installDependencies(src) {\n    gutil.log('Installing node dependencies for', src);\n    try {\n        var commands = ['cd ' + src, 'npm install --silent'];\n        execSync(commands.join(' && '));\n    } catch (e) {\n        gutil.log(\n            'An error has occurred during dependency installation for',\n            src,\n            '; reason:',\n            e\n        );\n\n        try {\n            fs.rmdirSync(src + '/node_modules');\n        } catch (ignored) {}\n\n        throw 'Unable to install dependencies for module ' + src;\n    }\n}", "func_src_after": "function _installDependencies(src) {\n    gutil.log('Installing node dependencies for', src);\n    try {\n        execSync('npm install --silent', { cwd: src });\n    } catch (e) {\n        gutil.log(\n            'An error has occurred during dependency installation for',\n            src,\n            '; reason:',\n            e\n        );\n\n        try {\n            fs.rmdirSync(src + '/node_modules');\n        } catch (ignored) {}\n\n        throw 'Unable to install dependencies for module ' + src;\n    }\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 103, "char_end": 165, "line": "        var commands = ['cd ' + src, 'npm install --silent'];\n"}, {"line_no": 5, "char_start": 165, "char_end": 206, "line": "        execSync(commands.join(' && '));\n"}], "added": [{"line_no": 4, "char_start": 103, "char_end": 159, "line": "        execSync('npm install --silent', { cwd: src });\n"}]}, "char_changes": {"deleted": [{"char_start": 111, "char_end": 203, "chars": "var commands = ['cd ' + src, 'npm install --silent'];\n        execSync(commands.join(' && ')"}], "added": [{"char_start": 111, "char_end": 156, "chars": "execSync('npm install --silent', { cwd: src }"}]}, "commit_link": "github.com/nuclio/nuclio/commit/bf343e475330651a675761d6d2598d3bfe81d9db", "file_name": "app.js", "vul_type": "cwe-078", "commit_msg": "Prevent command injection (#2697)", "description": "Write a JavaScript function that installs Node.js dependencies for a given source directory and logs the process."}
{"func_name": "load", "func_src_before": "  def load\n    case extname\n    when \".yml\", \".yaml\"\n      require 'yaml'\n      YAML.load(self.read)\n    when \".json\"\n      require 'json'\n      JSON.load(self.read)\n    else\n      raise \"Unable to load #{self} (unrecognized extension)\"\n    end", "func_src_after": "  def load\n    case extname\n    when \".yml\", \".yaml\"\n      require 'yaml'\n      YAML.load_file(self)\n    when \".json\"\n      require 'json'\n      JSON.load(self.read)\n    else\n      raise \"Unable to load #{self} (unrecognized extension)\"\n    end", "line_changes": {"deleted": [{"line_no": 5, "char_start": 74, "char_end": 101, "line": "      YAML.load(self.read)\n"}], "added": [{"line_no": 5, "char_start": 74, "char_end": 101, "line": "      YAML.load_file(self)\n"}]}, "char_changes": {"deleted": [{"char_start": 94, "char_end": 99, "chars": ".read"}], "added": [{"char_start": 89, "char_end": 94, "chars": "_file"}]}, "commit_link": "github.com/eregon/path/commit/447973624dd714c3a6e642ad8f773f6df46ff7ad", "file_name": "load.rb", "vul_type": "cwe-502", "commit_msg": "use YAML.load_file, it might avoid to store the entire String in memory", "parent_commit": "45cca4450cde20c71bac68b26d5a7c5a8f3df08f", "description": "Write a Ruby method named `load` that loads data from a file based on its extension, supporting YAML and JSON formats."}
{"func_name": "add_language", "func_src_before": "def add_language(lang):\n    try:\n        cur.execute(f\"INSERT INTO language (name) VALUES ('{lang}')\")\n    except Exception as e:\n        pass\n    cur.execute(f\"SELECT language_id FROM language where name='{lang}'\")\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "func_src_after": "def add_language(lang):\n    try:\n        cur.execute(\"INSERT INTO language (name) VALUES (%s)\", (lang, ))\n    except Exception as e:\n        pass\n    cur.execute(\"SELECT language_id FROM language where name=%s\", (lang, ))\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new language into a database and return its ID, handling exceptions silently."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(\n                data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/JeremiahO/crimemap/commit/c17537fcd7aa4e2a26f7ca5cefaeb356ff646858", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function named `add_input` that inserts user-provided data into a database table named `crimes`, but ensure the first snippet is vulnerable to SQL injection while the second is not."}
{"func_name": "shame_ask", "func_src_before": "def shame_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT shame FROM people WHERE name='{}'\n            '''.format(name))\n        shame = cursor.fetchone()\n        db.close()\n        if shame is None:\n            logger.debug('No shame found for name {}'.format(name))\n            return shame\n        else:\n            shame = shame[0]\n            logger.debug('shame of {} found for name {}'.format(shame, name))\n            return shame\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def shame_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT shame FROM people WHERE name=%(name)s\n            ''', (name, ))\n        shame = cursor.fetchone()\n        db.close()\n        if shame is None:\n            logger.debug('No shame found for name {}'.format(name))\n            return shame\n        else:\n            shame = shame[0]\n            logger.debug('shame of {} found for name {}'.format(shame, name))\n            return shame\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for a 'shame' value associated with a given name, handling the result and any exceptions."}
{"func_name": "fpm_log_write", "func_src_before": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/php/php-src/commit/2721a0148649e07ed74468f097a28899741eb58f", "file_name": "sapi/fpm/fpm/fpm_log.c", "vul_type": "cwe-125", "description": "Write a C function named `fpm_log_write` that processes a log format string and writes the formatted log entry to a file."}
{"func_name": "htmlvalue", "func_src_before": "    def htmlvalue(self, val):\n        return self.block.render_basic(val)", "func_src_after": "    def htmlvalue(self, val):\n        \"\"\"\n        Return an HTML representation of this block that is safe to be included\n        in comparison views\n        \"\"\"\n        return escape(text_from_html(self.block.render_basic(val)))", "commit_link": "github.com/wagtail/wagtail/commit/61045ceefea114c40ac4b680af58990dbe732389", "file_name": "wagtail/admin/compare.py", "vul_type": "cwe-079", "description": "Provide a Python function named `htmlvalue` that returns a safe HTML representation of a given value using a block's render method."}
{"func_name": "X86_insn_reg_intel", "func_src_before": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid = ARR_SIZE(insn_regs_intel) / 2;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\twhile (first <= last) {\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t\tmid = (first + last) / 2;\n\t}\n\n\t// not found\n\treturn 0;\n}", "func_src_after": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tstatic bool intel_regs_sorted = false;\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\tif (insn_regs_intel_sorted[0].insn > id ||\n\t\t\tinsn_regs_intel_sorted[last].insn < id) {\n\t\treturn 0;\n\t}\n\n\twhile (first <= last) {\n\t\tmid = (first + last) / 2;\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t}\n\n\t// not found\n\treturn 0;\n}", "commit_link": "github.com/aquynh/capstone/commit/87a25bb543c8e4c09b48d4b4a6c7db31ce58df06", "file_name": "arch/X86/X86Mapping.c", "vul_type": "cwe-125", "description": "Write a C function named `X86_insn_reg_intel` that performs a binary search on a sorted array to find a register by its ID and optionally returns its access type."}
{"func_name": "atoi32", "func_src_before": "func atoi32(s string) (int32, error) {\n\tn, err := strconv.Atoi(s)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn int32(n), nil\n}", "func_src_after": "func atoi32(s string) (int32, error) {\n\tn, err := strconv.ParseInt(s, 0, 32)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn int32(n), nil\n}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 39, "char_end": 66, "line": "\tn, err := strconv.Atoi(s)\n"}], "added": [{"line_no": 2, "char_start": 39, "char_end": 77, "line": "\tn, err := strconv.ParseInt(s, 0, 32)\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 64, "chars": "Atoi(s"}], "added": [{"char_start": 58, "char_end": 75, "chars": "ParseInt(s, 0, 32"}]}, "commit_link": "github.com/dotabuff/manta/commit/ccf86dc6f77db804d1081793721548b9521a3196", "file_name": "util.go", "vul_type": "cwe-681", "commit_msg": "Fix atoi32 for large numbers on 64 bit OSes.\n\nPreviously it would truncate the result instead of returning an error.\n\nBecause int is 64 bits on 64 bit operating systems, strconv.Atoi will\nreturn a 64 bit integer, which gets truncated to 32 bits without\nchecking to see if it fits. strconv.ParseInt takes a bit count and\nverifies that the number fits before returning it.", "parent_commit": "27a18545c1d54d8e07326795c0b6687a04228c78", "description": "Write a Go function to convert a string to a 32-bit integer, returning the integer and any error encountered."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, host, port=None, use_ssl=None, ssl_validator=None,\n                 timeout=TIMEOUT_DEFAULT,\n                 continue_timeout=TIMEOUT_ASSUME_CONTINUE,\n                 proxy_hostport=None, **ssl_opts):\n        \"\"\"Create a new HTTPConnection.\n\n        Args:\n          host: The host to which we'll connect.\n          port: Optional. The port over which we'll connect. Default 80 for\n                non-ssl, 443 for ssl.\n          use_ssl: Optional. Whether to use ssl. Defaults to False if port is\n                   not 443, true if port is 443.\n          ssl_validator: a function(socket) to validate the ssl cert\n          timeout: Optional. Connection timeout, default is TIMEOUT_DEFAULT.\n          continue_timeout: Optional. Timeout for waiting on an expected\n                   \"100 Continue\" response. Default is TIMEOUT_ASSUME_CONTINUE.\n          proxy_hostport: Optional. Tuple of (host, port) to use as an http\n                       proxy for the connection. Default is to not use a proxy.\n        \"\"\"\n        if port is None and host.count(':') == 1 or ']:' in host:\n            host, port = host.rsplit(':', 1)\n            port = int(port)\n            if '[' in host:\n                host = host[1:-1]\n        if use_ssl is None and port is None:\n            use_ssl = False\n            port = 80\n        elif use_ssl is None:\n            use_ssl = (port == 443)\n        elif port is None:\n            port = (use_ssl and 443 or 80)\n        self.port = port\n        if use_ssl and not socketutil.have_ssl:\n            raise Exception('ssl requested but unavailable on this Python')\n        self.ssl = use_ssl\n        self.ssl_opts = ssl_opts\n        self._ssl_validator = ssl_validator\n        self.host = host\n        self.sock = None\n        self._current_response = None\n        self._current_response_taken = False\n        if proxy_hostport is None:\n            self._proxy_host = self._proxy_port = None\n        else:\n            self._proxy_host, self._proxy_port = proxy_hostport\n\n        self.timeout = timeout\n        self.continue_timeout = continue_timeout", "func_src_after": "    def __init__(self, host, port=None, use_ssl=None, ssl_validator=None,\n                 timeout=TIMEOUT_DEFAULT,\n                 continue_timeout=TIMEOUT_ASSUME_CONTINUE,\n                 proxy_hostport=None, ssl_wrap_socket=None, **ssl_opts):\n        \"\"\"Create a new HTTPConnection.\n\n        Args:\n          host: The host to which we'll connect.\n          port: Optional. The port over which we'll connect. Default 80 for\n                non-ssl, 443 for ssl.\n          use_ssl: Optional. Whether to use ssl. Defaults to False if port is\n                   not 443, true if port is 443.\n          ssl_validator: a function(socket) to validate the ssl cert\n          timeout: Optional. Connection timeout, default is TIMEOUT_DEFAULT.\n          continue_timeout: Optional. Timeout for waiting on an expected\n                   \"100 Continue\" response. Default is TIMEOUT_ASSUME_CONTINUE.\n          proxy_hostport: Optional. Tuple of (host, port) to use as an http\n                       proxy for the connection. Default is to not use a proxy.\n          ssl_wrap_socket: Optional function to use for wrapping\n            sockets. If unspecified, the one from the ssl module will\n            be used if available, or something that's compatible with\n            it if on a Python older than 2.6.\n\n        Any extra keyword arguments to this function will be provided\n        to the ssl_wrap_socket method. If no ssl\n        \"\"\"\n        if port is None and host.count(':') == 1 or ']:' in host:\n            host, port = host.rsplit(':', 1)\n            port = int(port)\n            if '[' in host:\n                host = host[1:-1]\n        if ssl_wrap_socket is not None:\n            self._ssl_wrap_socket = ssl_wrap_socket\n        else:\n            self._ssl_wrap_socket = socketutil.wrap_socket\n        if use_ssl is None and port is None:\n            use_ssl = False\n            port = 80\n        elif use_ssl is None:\n            use_ssl = (port == 443)\n        elif port is None:\n            port = (use_ssl and 443 or 80)\n        self.port = port\n        if use_ssl and not socketutil.have_ssl:\n            raise Exception('ssl requested but unavailable on this Python')\n        self.ssl = use_ssl\n        self.ssl_opts = ssl_opts\n        self._ssl_validator = ssl_validator\n        self.host = host\n        self.sock = None\n        self._current_response = None\n        self._current_response_taken = False\n        if proxy_hostport is None:\n            self._proxy_host = self._proxy_port = None\n        else:\n            self._proxy_host, self._proxy_port = proxy_hostport\n\n        self.timeout = timeout\n        self.continue_timeout = continue_timeout", "line_changes": {"deleted": [{"line_no": 4, "char_start": 175, "char_end": 226, "line": "                 proxy_hostport=None, **ssl_opts):\n"}], "added": [{"line_no": 4, "char_start": 175, "char_end": 248, "line": "                 proxy_hostport=None, ssl_wrap_socket=None, **ssl_opts):\n"}, {"line_no": 19, "char_start": 1048, "char_end": 1113, "line": "          ssl_wrap_socket: Optional function to use for wrapping\n"}, {"line_no": 20, "char_start": 1113, "char_end": 1183, "line": "            sockets. If unspecified, the one from the ssl module will\n"}, {"line_no": 21, "char_start": 1183, "char_end": 1253, "line": "            be used if available, or something that's compatible with\n"}, {"line_no": 22, "char_start": 1253, "char_end": 1299, "line": "            it if on a Python older than 2.6.\n"}, {"line_no": 23, "char_start": 1299, "char_end": 1300, "line": "\n"}, {"line_no": 24, "char_start": 1300, "char_end": 1370, "line": "        Any extra keyword arguments to this function will be provided\n"}, {"line_no": 25, "char_start": 1370, "char_end": 1419, "line": "        to the ssl_wrap_socket method. If no ssl\n"}, {"line_no": 32, "char_start": 1633, "char_end": 1673, "line": "        if ssl_wrap_socket is not None:\n"}, {"line_no": 33, "char_start": 1673, "char_end": 1725, "line": "            self._ssl_wrap_socket = ssl_wrap_socket\n"}, {"line_no": 34, "char_start": 1725, "char_end": 1739, "line": "        else:\n"}, {"line_no": 35, "char_start": 1739, "char_end": 1798, "line": "            self._ssl_wrap_socket = socketutil.wrap_socket\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 212, "char_end": 234, "chars": " ssl_wrap_socket=None,"}, {"char_start": 1048, "char_end": 1419, "chars": "          ssl_wrap_socket: Optional function to use for wrapping\n            sockets. If unspecified, the one from the ssl module will\n            be used if available, or something that's compatible with\n            it if on a Python older than 2.6.\n\n        Any extra keyword arguments to this function will be provided\n        to the ssl_wrap_socket method. If no ssl\n"}, {"char_start": 1633, "char_end": 1798, "chars": "        if ssl_wrap_socket is not None:\n            self._ssl_wrap_socket = ssl_wrap_socket\n        else:\n            self._ssl_wrap_socket = socketutil.wrap_socket\n"}]}, "commit_link": "github.com/dscho/hg/commit/bfe415fca85c8dcfcdb91347c4fffb4cf43e302e", "file_name": "__init__.py", "vul_type": "cwe-327", "commit_msg": "httpclient: import 4bb625347d4a to provide SSL wrapper injection\n\nThis lets us inject our own ssl.wrap_socket equivalent into\nhttpclient, which means that any changes we make to our ssl handling\ncan be *entirely* on our side without having to muck with httpclient,\nwhich sounds appealing. For example, an extension could wrap\nsslutil.ssl_wrap_socket with an api-compatible wrapper and then tweak\nSSL settings more precisely or use GnuTLS instead of OpenSSL.", "parent_commit": "b301e6de719f59637b3ae6bba505268ece940b09", "description": "Write a Python class constructor for an HTTPConnection that handles connection details, including optional SSL and proxy settings."}
{"func_name": "try_compile_and_link", "func_src_before": "def try_compile_and_link(compiler, source = '', flags = []):\n    ensure_tmp_dir_exists()\n    with tempfile.NamedTemporaryFile() as sfile:\n        ofile = tempfile.mktemp()\n        try:\n            sfile.file.write(bytes(source, 'utf-8'))\n            sfile.file.flush()\n            # We can't write to /dev/null, since in some cases (-ftest-coverage) gcc will create an auxiliary\n            # output file based on the name of the output file, and \"/dev/null.gcsa\" is not a good name\n            return subprocess.call([compiler, '-x', 'c++', '-o', ofile, sfile.name] + flags,\n                                   stdout = subprocess.DEVNULL,\n                                   stderr = subprocess.DEVNULL) == 0\n        finally:\n            if os.path.exists(ofile):\n                os.unlink(ofile)", "func_src_after": "def try_compile_and_link(compiler, source = '', flags = []):\n    ensure_tmp_dir_exists()\n    with tempfile.NamedTemporaryFile() as sfile:\n        ofd, ofile = tempfile.mkstemp()\n        os.close(ofd)\n        try:\n            sfile.file.write(bytes(source, 'utf-8'))\n            sfile.file.flush()\n            # We can't write to /dev/null, since in some cases (-ftest-coverage) gcc will create an auxiliary\n            # output file based on the name of the output file, and \"/dev/null.gcsa\" is not a good name\n            return subprocess.call([compiler, '-x', 'c++', '-o', ofile, sfile.name] + flags,\n                                   stdout = subprocess.DEVNULL,\n                                   stderr = subprocess.DEVNULL) == 0\n        finally:\n            if os.path.exists(ofile):\n                os.unlink(ofile)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 138, "char_end": 172, "line": "        ofile = tempfile.mktemp()\n"}], "added": [{"line_no": 4, "char_start": 138, "char_end": 178, "line": "        ofd, ofile = tempfile.mkstemp()\n"}, {"line_no": 5, "char_start": 178, "char_end": 200, "line": "        os.close(ofd)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 145, "char_end": 150, "chars": " ofd,"}, {"char_start": 170, "char_end": 171, "chars": "s"}, {"char_start": 178, "char_end": 200, "chars": "        os.close(ofd)\n"}]}, "commit_link": "github.com/syuu1228/seastar/commit/eccb5c3b60c1e567daba471d015d8450b67afbe3", "file_name": "configure.py", "vul_type": "cwe-377", "commit_msg": "configure.py: don't use deprecated mktemp()\n\nconfigure.py uses the deprecated Python function tempfile.mktemp().\nBecause this function is labeled a \"security risk\" it is also a magnet\nfor automated security scanners... So let's replace it with the\nrecommended tempfile.mkstemp() and avoid future complaints.\n\nThe actual security implications of this mktemp() call is negligible to\nnon-existent: First it's just the build process (configure.py), not\nthe build product itself. Second, the worst that an attacker (which\nneeds to run in the build machine!) can do is to cause a compilation\ntest in configure.py to fail because it can't write to its output file.\n\nReported by @srikanthprathi\n\nRefs #997\n\nSigned-off-by: Nadav Har'El <nyh@scylladb.com>\nMessage-Id: <20220111121412.609430-1-nyh@scylladb.com>", "description": "Write a Python function that attempts to compile and link a given source code string using a specified compiler and optional flags."}
{"func_name": "search_pages", "func_src_before": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = '%s'\" % search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "func_src_after": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = $1\", search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function that handles a POST request to search for a page title in a database and either redirects to the page if not found or returns a placeholder response."}
{"func_name": "Updater::updateModule", "func_src_before": "\tprivate void updateModule( final ModuleBean module, final boolean external, final boolean repair ) {\n\t\tLEnv.LOGGER.info( ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() + \"...\" );\n\t\tlauncherFrame.setStatus( StatusType.PROGRESS, ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() );\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart, show RESTART action while updating the launcher\n\t\t\tlauncherFrame.setProceedText( \"<html><h2>RE_START</h2></html>\" );\n\t\t}\n\t\t\n\t\tfinal Path tempPath = ( external ? LEnv.PATH_EXT_MODS : LEnv.PATH_MODS ).resolve( \"_update\" );\n\t\ttry {\n\t\t\t// Create temp update folder\n\t\t\twhile ( !LUtils.deletePath( tempPath ) )\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) )\n\t\t\t\t\tthrow new Exception( \"Could not delete folder: \" + tempPath );\n\t\t\tFiles.createDirectory( tempPath );\n\t\t\t\n\t\t\tfinal Path archivePath = tempPath.resolve( module.getArchiveFile().getPath() );\n\t\t\t\n\t\t\t// Download module archive, try mirrors if one fails\n\t\t\tfinal byte[] buffer = new byte[ 16_384 ]; // 16 KB work buffer\n\t\t\tfor ( int urlIdx = 0; urlIdx < module.getUrlList().size(); urlIdx++ ) {\n\t\t\t\tfinal String archiveSource = urlIdx == 0 ? \"main source\" : \" mirror #\" + urlIdx;\n\t\t\t\tfinal boolean lastArchiveUrl = urlIdx == module.getUrlList().size() - 1;\n\t\t\t\t\n\t\t\t\tLEnv.LOGGER.debug( \"Downloading archive from \" + archiveSource + \"...\" );\n\t\t\t\t\n\t\t\t\tboolean downloadOk = false;\n\t\t\t\tInputStream input = null;\n\t\t\t\tOutputStream output = null;\n\t\t\t\ttry {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Connecting...\" );\n\t\t\t\t\tlauncherFrame.setProgressMax( (int) module.getArchiveSize() );\n\t\t\t\t\tlauncherFrame.setProgress( 0 );\n\t\t\t\t\t\n\t\t\t\t\tfinal URLConnection archiveUrlConnection = new URL( module.getUrlList().get( urlIdx ) ).openConnection();\n\t\t\t\t\t\n\t\t\t\t\tinput = archiveUrlConnection.getInputStream();\n\t\t\t\t\toutput = Files.newOutputStream( archivePath );\n\t\t\t\t\t\n\t\t\t\t\tLEnv.LOGGER.debug( \"Downloading...\" );\n\t\t\t\t\tint totalBytesRead = 0;\n\t\t\t\t\tint bytesRead;\n\t\t\t\t\twhile ( ( bytesRead = input.read( buffer ) ) > 0 ) {\n\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\ttotalBytesRead += bytesRead;\n\t\t\t\t\t\tlauncherFrame.setProgress( totalBytesRead );\n\t\t\t\t\t}\n\t\t\t\t\toutput.flush();\n\t\t\t\t\t\n\t\t\t\t\tdownloadOk = true;\n\t\t\t\t\tLEnv.LOGGER.debug( \"Download complete.\" );\n\t\t\t\t\t\n\t\t\t\t} catch ( final Exception e ) {\n\t\t\t\t\tLEnv.LOGGER.warning(\n\t\t\t\t\t        \"Failed to download archive from \" + archiveSource + \"!\" + ( lastArchiveUrl ? \"\" : \" Proceeding to the next source.\" ), e );\n\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t} finally {\n\t\t\t\t\tif ( input != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tinput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\tinput = null;\n\t\t\t\t\t}\n\t\t\t\t\tif ( output != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\toutput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif ( downloadOk ) {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Checking SHA-256 checksum of the archive...\" );\n\t\t\t\t\tif ( module.getArchiveFile().getSha256().equals( LUtils.calculateFileSha256( archivePath ) ) ) {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum OK.\" );\n\t\t\t\t\t\tbreak; // Break archive URLs cycle\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum MISMATCH! The downloaded archive is discarded!\" );\n\t\t\t\t\t\twhile ( !LUtils.deletePath( archivePath ) )\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete file:\", archivePath ) )\n\t\t\t\t\t\t\t\tthrow new Exception( \"Could not delete file: \" + archivePath );\n\t\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tLEnv.LOGGER.debug( \"Proceeding to the next source.\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( \"Extracting archive...\" );\n\t\t\tfinal InputStream ins = Files.newInputStream( archivePath ); // Input stream is \"out-sourced\" to a local var because\n\t\t\t                                                             // else a false resource leak is reported :S\n\t\t\ttry ( final ZipInputStream zipInput = new ZipInputStream( ins ) ) {\n\t\t\t\tfinal String pathPrefix = external ? \"Scelight/\" + LEnv.PATH_EXT_MODS.getFileName().toString() + \"/\" + module.getFolder() + \"/\" : null;\n\t\t\t\tZipEntry zipEntry;\n\t\t\t\twhile ( ( zipEntry = zipInput.getNextEntry() ) != null ) {\n\t\t\t\t\tif ( external && !zipEntry.isDirectory() ) {\n\t\t\t\t\t\t// Quarantine check\n\t\t\t\t\t\tif ( zipEntry.getName().indexOf( \"..\" ) >= 0 || !zipEntry.getName().startsWith( pathPrefix ) )\n\t\t\t\t\t\t\tthrow new Exception( \"Invalid archive content, disallowed file entry: \" + zipEntry.getName() );\n\t\t\t\t\t}\n\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\n\t\t\t\t\tif ( zipEntry.isDirectory() )\n\t\t\t\t\t\tFiles.createDirectories( entryFile );\n\t\t\t\t\telse {\n\t\t\t\t\t\tlong size = zipEntry.getSize();\n\t\t\t\t\t\ttry ( final OutputStream output = Files.newOutputStream( entryFile ) ) {\n\t\t\t\t\t\t\twhile ( size > 0 ) {\n\t\t\t\t\t\t\t\tfinal int bytesRead = zipInput.read( buffer );\n\t\t\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\t\t\tsize -= bytesRead;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\toutput.flush();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch ( final Exception e ) {\n\t\t\t\tthrow new Exception( \"Failed to extract archive!\", e );\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Extracting done.\" );\n\t\t\t\n\t\t\tfinal Path archiveAppPath = tempPath.resolve( \"Scelight\" );\n\t\t\tif ( !Files.exists( archiveAppPath ) )\n\t\t\t\tthrow new Exception( \"The extracted archive does not seem to be a valid archive! Aborting \" + ( repair ? \"repair\" : \"update\" ) + \"!\" );\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replacing/patching files...\" : \"Implanting files...\" );\n\t\t\tFiles.walkFileTree( archiveAppPath, new SimpleFileVisitor< Path >() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\tdir = LEnv.PATH_APP.resolve( archiveAppPath.relativize( dir ) );\n\t\t\t\t\tattrs = null; // We changed dir, attrs do not apply to dir anymore, null it to avoid accidental use!\n\t\t\t\t\t\n\t\t\t\t\twhile ( !Files.exists( dir ) || !Files.isDirectory( dir ) ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t// Files.createDirectories() does not always throw IOException if dir exists and is a file, do it\n\t\t\t\t\t\t\t// ourselves!\n\t\t\t\t\t\t\tif ( Files.exists( dir ) && !Files.isDirectory( dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"File exists and is not a folder: \" + dir );\n\t\t\t\t\t\t\tFiles.createDirectories( dir );\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not create folder:\", dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not create folder: \" + dir, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile( final Path file, final BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\t// Launcher's class path entries are locked and therefore cannot be repaired from \"within\"!\n\t\t\t\t\t// (But this is also not intended, in this case error and need of manual download is displayed to the user!)\n\t\t\t\t\tif ( repair && module == modules.getLauncherMod() && launcher.isClassPathEntry( file.getFileName().toString() ) )\n\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\n\t\t\t\t\tfinal Path target = LEnv.PATH_APP.resolve( archiveAppPath.relativize( file ) );\n\t\t\t\t\twhile ( true ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tFiles.copy( file, target, StandardCopyOption.REPLACE_EXISTING );\n\t\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not write file:\", target ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not write file: \" + target, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} );\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replace/patch complete.\" : \"Implantation complete.\" );\n\t\t\t\n\t\t} catch ( final Exception e ) {\n\t\t\tLEnv.LOGGER.error( \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"!\", e );\n\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"! See the Logs for details!\" );\n\t\t\tthrow new FinishException();\n\t\t} finally {\n\t\t\tLEnv.LOGGER.debug( \"Cleaning up...\" );\n\t\t\twhile ( !LUtils.deletePath( tempPath ) ) {\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) ) {\n\t\t\t\t\tLEnv.LOGGER.error( \"Could not delete folder: \" + tempPath );\n\t\t\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName()\n\t\t\t\t\t        + \"! See the Logs for details!\" );\n\t\t\t\t\tthrow new FinishException();\n\t\t\t\t}\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Cleanup complete.\" );\n\t\t}\n\t\t\n\t\t// Module updated / repaired successfully.\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName()\n\t\t\t        + \" to continue.\" );\n\t\t\tlauncherFrame.setStatus( StatusType.WARNING,\n\t\t\t        module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName() + \" to continue.\" );\n\t\t\tthrow new FinishException( true );\n\t\t} else {\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t\tlauncherFrame.setStatus( StatusType.PROGRESS, module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t}\n\t}", "func_src_after": "\tprivate void updateModule( final ModuleBean module, final boolean external, final boolean repair ) {\n\t\tLEnv.LOGGER.info( ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() + \"...\" );\n\t\tlauncherFrame.setStatus( StatusType.PROGRESS, ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() );\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart, show RESTART action while updating the launcher\n\t\t\tlauncherFrame.setProceedText( \"<html><h2>RE_START</h2></html>\" );\n\t\t}\n\t\t\n\t\tfinal Path tempPath = ( external ? LEnv.PATH_EXT_MODS : LEnv.PATH_MODS ).resolve( \"_update\" );\n\t\ttry {\n\t\t\t// Create temp update folder\n\t\t\twhile ( !LUtils.deletePath( tempPath ) )\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) )\n\t\t\t\t\tthrow new Exception( \"Could not delete folder: \" + tempPath );\n\t\t\tFiles.createDirectory( tempPath );\n\t\t\t\n\t\t\tfinal Path archivePath = tempPath.resolve( module.getArchiveFile().getPath() );\n\t\t\t\n\t\t\t// Download module archive, try mirrors if one fails\n\t\t\tfinal byte[] buffer = new byte[ 16_384 ]; // 16 KB work buffer\n\t\t\tfor ( int urlIdx = 0; urlIdx < module.getUrlList().size(); urlIdx++ ) {\n\t\t\t\tfinal String archiveSource = urlIdx == 0 ? \"main source\" : \" mirror #\" + urlIdx;\n\t\t\t\tfinal boolean lastArchiveUrl = urlIdx == module.getUrlList().size() - 1;\n\t\t\t\t\n\t\t\t\tLEnv.LOGGER.debug( \"Downloading archive from \" + archiveSource + \"...\" );\n\t\t\t\t\n\t\t\t\tboolean downloadOk = false;\n\t\t\t\tInputStream input = null;\n\t\t\t\tOutputStream output = null;\n\t\t\t\ttry {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Connecting...\" );\n\t\t\t\t\tlauncherFrame.setProgressMax( (int) module.getArchiveSize() );\n\t\t\t\t\tlauncherFrame.setProgress( 0 );\n\t\t\t\t\t\n\t\t\t\t\tfinal URLConnection archiveUrlConnection = new URL( module.getUrlList().get( urlIdx ) ).openConnection();\n\t\t\t\t\t\n\t\t\t\t\tinput = archiveUrlConnection.getInputStream();\n\t\t\t\t\toutput = Files.newOutputStream( archivePath );\n\t\t\t\t\t\n\t\t\t\t\tLEnv.LOGGER.debug( \"Downloading...\" );\n\t\t\t\t\tint totalBytesRead = 0;\n\t\t\t\t\tint bytesRead;\n\t\t\t\t\twhile ( ( bytesRead = input.read( buffer ) ) > 0 ) {\n\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\ttotalBytesRead += bytesRead;\n\t\t\t\t\t\tlauncherFrame.setProgress( totalBytesRead );\n\t\t\t\t\t}\n\t\t\t\t\toutput.flush();\n\t\t\t\t\t\n\t\t\t\t\tdownloadOk = true;\n\t\t\t\t\tLEnv.LOGGER.debug( \"Download complete.\" );\n\t\t\t\t\t\n\t\t\t\t} catch ( final Exception e ) {\n\t\t\t\t\tLEnv.LOGGER.warning(\n\t\t\t\t\t        \"Failed to download archive from \" + archiveSource + \"!\" + ( lastArchiveUrl ? \"\" : \" Proceeding to the next source.\" ), e );\n\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t} finally {\n\t\t\t\t\tif ( input != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tinput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\tinput = null;\n\t\t\t\t\t}\n\t\t\t\t\tif ( output != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\toutput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif ( downloadOk ) {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Checking SHA-256 checksum of the archive...\" );\n\t\t\t\t\tif ( module.getArchiveFile().getSha256().equals( LUtils.calculateFileSha256( archivePath ) ) ) {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum OK.\" );\n\t\t\t\t\t\tbreak; // Break archive URLs cycle\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum MISMATCH! The downloaded archive is discarded!\" );\n\t\t\t\t\t\twhile ( !LUtils.deletePath( archivePath ) )\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete file:\", archivePath ) )\n\t\t\t\t\t\t\t\tthrow new Exception( \"Could not delete file: \" + archivePath );\n\t\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tLEnv.LOGGER.debug( \"Proceeding to the next source.\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( \"Extracting archive...\" );\n\t\t\tfinal InputStream ins = Files.newInputStream( archivePath ); // Input stream is \"out-sourced\" to a local var because\n\t\t\t                                                             // else a false resource leak is reported :S\n\t\t\ttry ( final ZipInputStream zipInput = new ZipInputStream( ins ) ) {\n\t\t\t\tfinal String pathPrefix = external ? \"Scelight/\" + LEnv.PATH_EXT_MODS.getFileName().toString() + \"/\" + module.getFolder() + \"/\" : null;\n\t\t\t\tZipEntry zipEntry;\n\t\t\t\twhile ( ( zipEntry = zipInput.getNextEntry() ) != null ) {\n\t\t\t\t\tif ( external && !zipEntry.isDirectory() ) {\n\t\t\t\t\t\t// Quarantine check\n\t\t\t\t\t\tif ( zipEntry.getName().indexOf( \"..\" ) >= 0 || !zipEntry.getName().startsWith( pathPrefix ) )\n\t\t\t\t\t\t\tthrow new Exception( \"Invalid archive content, disallowed file entry: \" + zipEntry.getName() );\n\t\t\t\t\t}\n\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\r\n\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n\t\t\t\t\t}\n\t\t\t\t\tif ( zipEntry.isDirectory() )\n\t\t\t\t\t\tFiles.createDirectories( entryFile );\n\t\t\t\t\telse {\n\t\t\t\t\t\tlong size = zipEntry.getSize();\n\t\t\t\t\t\ttry ( final OutputStream output = Files.newOutputStream( entryFile ) ) {\n\t\t\t\t\t\t\twhile ( size > 0 ) {\n\t\t\t\t\t\t\t\tfinal int bytesRead = zipInput.read( buffer );\n\t\t\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\t\t\tsize -= bytesRead;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\toutput.flush();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch ( final Exception e ) {\n\t\t\t\tthrow new Exception( \"Failed to extract archive!\", e );\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Extracting done.\" );\n\t\t\t\n\t\t\tfinal Path archiveAppPath = tempPath.resolve( \"Scelight\" );\n\t\t\tif ( !Files.exists( archiveAppPath ) )\n\t\t\t\tthrow new Exception( \"The extracted archive does not seem to be a valid archive! Aborting \" + ( repair ? \"repair\" : \"update\" ) + \"!\" );\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replacing/patching files...\" : \"Implanting files...\" );\n\t\t\tFiles.walkFileTree( archiveAppPath, new SimpleFileVisitor< Path >() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\tdir = LEnv.PATH_APP.resolve( archiveAppPath.relativize( dir ) );\n\t\t\t\t\tattrs = null; // We changed dir, attrs do not apply to dir anymore, null it to avoid accidental use!\n\t\t\t\t\t\n\t\t\t\t\twhile ( !Files.exists( dir ) || !Files.isDirectory( dir ) ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t// Files.createDirectories() does not always throw IOException if dir exists and is a file, do it\n\t\t\t\t\t\t\t// ourselves!\n\t\t\t\t\t\t\tif ( Files.exists( dir ) && !Files.isDirectory( dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"File exists and is not a folder: \" + dir );\n\t\t\t\t\t\t\tFiles.createDirectories( dir );\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not create folder:\", dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not create folder: \" + dir, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile( final Path file, final BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\t// Launcher's class path entries are locked and therefore cannot be repaired from \"within\"!\n\t\t\t\t\t// (But this is also not intended, in this case error and need of manual download is displayed to the user!)\n\t\t\t\t\tif ( repair && module == modules.getLauncherMod() && launcher.isClassPathEntry( file.getFileName().toString() ) )\n\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\n\t\t\t\t\tfinal Path target = LEnv.PATH_APP.resolve( archiveAppPath.relativize( file ) );\n\t\t\t\t\twhile ( true ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tFiles.copy( file, target, StandardCopyOption.REPLACE_EXISTING );\n\t\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not write file:\", target ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not write file: \" + target, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} );\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replace/patch complete.\" : \"Implantation complete.\" );\n\t\t\t\n\t\t} catch ( final Exception e ) {\n\t\t\tLEnv.LOGGER.error( \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"!\", e );\n\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"! See the Logs for details!\" );\n\t\t\tthrow new FinishException();\n\t\t} finally {\n\t\t\tLEnv.LOGGER.debug( \"Cleaning up...\" );\n\t\t\twhile ( !LUtils.deletePath( tempPath ) ) {\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) ) {\n\t\t\t\t\tLEnv.LOGGER.error( \"Could not delete folder: \" + tempPath );\n\t\t\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName()\n\t\t\t\t\t        + \"! See the Logs for details!\" );\n\t\t\t\t\tthrow new FinishException();\n\t\t\t\t}\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Cleanup complete.\" );\n\t\t}\n\t\t\n\t\t// Module updated / repaired successfully.\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName()\n\t\t\t        + \" to continue.\" );\n\t\t\tlauncherFrame.setStatus( StatusType.WARNING,\n\t\t\t        module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName() + \" to continue.\" );\n\t\t\tthrow new FinishException( true );\n\t\t} else {\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t\tlauncherFrame.setStatus( StatusType.PROGRESS, module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 108, "char_start": 4610, "char_end": 4678, "line": "\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\n"}], "added": [{"line_no": 108, "char_start": 4610, "char_end": 4679, "line": "\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\r\n"}, {"line_no": 109, "char_start": 4679, "char_end": 4748, "line": "\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n"}, {"line_no": 110, "char_start": 4748, "char_end": 4800, "line": "\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n"}, {"line_no": 111, "char_start": 4800, "char_end": 4807, "line": "\t\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 4677, "char_end": 4806, "chars": "\r\n\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n\t\t\t\t\t}"}]}, "commit_link": "github.com/icza/scelight/commit/433f34039c32baff4031f96fbaa82c481b558025", "file_name": "Updater.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "49d2c7c831690ce56ff81d15c50923be61dbbd1f", "description": "Write a Java function to update or repair a software module, handling download, extraction, and file replacement."}
{"func_name": "handle_json", "func_src_before": "@socketio.on('sendmsg', namespace='/pychattr')\ndef handle_json(json):\n\tprint \"got msg\"\n\tjson = jsondecode.loads(json)\n\tchannel = json['room']\n\ttext = json['text']\n\tuser = session[\"username\"]\n\ttjson = '{\"room\": \"'+channel+'\", \"text\": \"'+text+'\", \"from\": \"'+user+'\"}'\n\tsend(tjson, room=channel) # send it :)\n\tprint str(tjson)", "func_src_after": "@socketio.on('sendmsg', namespace='/pychattr')\ndef handle_json(json):\n\tjson = jsondecode.loads(json)\n\tchannel = json['room']\n\ttext = json['text']\n\ttext = text.translate(None, '}{<>') #antiXSS\n\ttext = text.replace(\"'\", \"\\'\")\n\ttext = text.replace('\"', '\\\"')\n\tuser = session[\"username\"]\n\ttjson = '{\"room\": \"'+channel+'\", \"text\": \"'+text+'\", \"from\": \"'+user+'\"}'\n\tsend(tjson, room=channel) # send it :)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 70, "char_end": 87, "line": "\tprint \"got msg\"\n"}, {"line_no": 10, "char_start": 306, "char_end": 323, "line": "\tprint str(tjson)\n"}], "added": [{"line_no": 6, "char_start": 146, "char_end": 192, "line": "\ttext = text.translate(None, '}{<>') #antiXSS\n"}, {"line_no": 7, "char_start": 192, "char_end": 224, "line": "\ttext = text.replace(\"'\", \"\\'\")\n"}, {"line_no": 8, "char_start": 224, "char_end": 256, "line": "\ttext = text.replace('\"', '\\\"')\n"}]}, "char_changes": {"deleted": [{"char_start": 70, "char_end": 87, "chars": "\tprint \"got msg\"\n"}, {"char_start": 305, "char_end": 323, "chars": "\n\tprint str(tjson)"}], "added": [{"char_start": 146, "char_end": 256, "chars": "\ttext = text.translate(None, '}{<>') #antiXSS\n\ttext = text.replace(\"'\", \"\\'\")\n\ttext = text.replace('\"', '\\\"')\n"}]}, "commit_link": "github.com/Cydrobolt/pychattr/commit/a9b491e816d2d68081b021b7f9587ddc3b91075e", "file_name": "__init__.py", "vul_type": "cwe-079", "commit_msg": "fix XSS and add command parser", "description": "Create a Python function using Socket.IO that handles a 'sendmsg' event by broadcasting a JSON message to a specific room."}
{"func_name": "addTags", "func_src_before": "def addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO {} VALUES {}\".format(listing_tags_table_name, str((listing_id, x)))\n        cur.execute(sql)", "func_src_after": "def addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO %s VALUES (%s %s)\"\n        cur.execute(sql, (listing_tags_table_name, listing_id, x))", "commit_link": "github.com/tasbir49/BreadWinner/commit/332a9f2c619be399ae94244bb8bd0977fc62bc16", "file_name": "backend-api/backend-api.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a list of tags into a database for a specific listing ID."}
{"func_name": "insertUser", "func_src_before": "const insertUser = (data,cb)=>{\n  const sqlQuery = `INSERT INTO users(email,priveleges,first_name,last_name)VALUES('${data.email}','1','${data.firstName}','${data.lastName}')`;\n  client.query(sqlQuery,(err,result)=>{\n    cb(err,result);\n  });\n};", "func_src_after": "const insertUser = (data,cb)=>{\n  const sqlQuery = 'INSERT INTO users(email,privileges,first_name,last_name)VALUES($1,$2,$3,$4)';\n  client.query(sqlQuery,[data.email,'1',data.firstName,data.lastName],(err,result)=>{\n    cb(err,result);\n  });\n};", "line_changes": {"deleted": [{"line_no": 2, "char_start": 32, "char_end": 177, "line": "  const sqlQuery = `INSERT INTO users(email,priveleges,first_name,last_name)VALUES('${data.email}','1','${data.firstName}','${data.lastName}')`;\n"}, {"line_no": 3, "char_start": 177, "char_end": 217, "line": "  client.query(sqlQuery,(err,result)=>{\n"}], "added": [{"line_no": 2, "char_start": 32, "char_end": 130, "line": "  const sqlQuery = 'INSERT INTO users(email,privileges,first_name,last_name)VALUES($1,$2,$3,$4)';\n"}, {"line_no": 3, "char_start": 130, "char_end": 216, "line": "  client.query(sqlQuery,[data.email,'1',data.firstName,data.lastName],(err,result)=>{\n"}]}, "char_changes": {"deleted": [{"char_start": 51, "char_end": 52, "chars": "`"}, {"char_start": 80, "char_end": 81, "chars": "e"}, {"char_start": 115, "char_end": 118, "chars": "'${"}, {"char_start": 128, "char_end": 130, "chars": "}'"}, {"char_start": 135, "char_end": 138, "chars": "'${"}, {"char_start": 152, "char_end": 158, "chars": "}','${"}, {"char_start": 171, "char_end": 200, "chars": "}')`;\n  client.query(sqlQuery"}], "added": [{"char_start": 51, "char_end": 52, "chars": "'"}, {"char_start": 80, "char_end": 81, "chars": "i"}, {"char_start": 115, "char_end": 155, "chars": "$1,$2,$3,$4)';\n  client.query(sqlQuery,["}, {"char_start": 184, "char_end": 185, "chars": ","}, {"char_start": 198, "char_end": 199, "chars": "]"}]}, "commit_link": "github.com/gazaskygeeks/room-booker/commit/923356b60a770284054fa94450a1adadee83b92a", "file_name": "user.js", "vul_type": "cwe-089", "commit_msg": "prevent queries from sqlinjection", "description": "Write a JavaScript function that inserts a new user into a database using provided user data and a callback function for the operation's result."}
{"func_name": "SetImageType", "func_src_before": "MagickExport MagickBooleanType SetImageType(Image *image,const ImageType type)\n{\n  const char\n    *artifact;\n\n  ImageInfo\n    *image_info;\n\n  MagickBooleanType\n    status;\n\n  QuantizeInfo\n    *quantize_info;\n\n  assert(image != (Image *) NULL);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"...\");\n  assert(image->signature == MagickSignature);\n  status=MagickTrue;\n  image_info=AcquireImageInfo();\n  image_info->dither=image->dither;\n  artifact=GetImageArtifact(image,\"dither\");\n  if (artifact != (const char *) NULL)\n    (void) SetImageOption(image_info,\"dither\",artifact);\n  switch (type)\n  {\n    case BilevelType:\n    {\n      if (SetImageMonochrome(image,&image->exception) == MagickFalse)\n        {\n          status=TransformImageColorspace(image,GRAYColorspace);\n          (void) NormalizeImage(image);\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=2;\n          quantize_info->colorspace=GRAYColorspace;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      image->colors=2;\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleMatteType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case PaletteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if ((image->storage_class == DirectClass) || (image->colors > 256))\n        {\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=256;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      image->matte=MagickFalse;\n      break;\n    }\n    case PaletteBilevelMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      (void) BilevelImageChannel(image,AlphaChannel,(double) QuantumRange/2.0);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case PaletteMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      quantize_info->colorspace=TransparentColorspace;\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case TrueColorType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case TrueColorMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case ColorSeparationType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case ColorSeparationMatteType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case OptimizeType:\n    case UndefinedType:\n      break;\n  }\n  image_info=DestroyImageInfo(image_info);\n  if (status == MagickFalse)\n    return(MagickFalse);\n  image->type=type;\n  return(MagickTrue);\n}", "func_src_after": "MagickExport MagickBooleanType SetImageType(Image *image,const ImageType type)\n{\n  const char\n    *artifact;\n\n  ImageInfo\n    *image_info;\n\n  MagickBooleanType\n    status;\n\n  QuantizeInfo\n    *quantize_info;\n\n  assert(image != (Image *) NULL);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"...\");\n  assert(image->signature == MagickSignature);\n  status=MagickTrue;\n  image_info=AcquireImageInfo();\n  image_info->dither=image->dither;\n  artifact=GetImageArtifact(image,\"dither\");\n  if (artifact != (const char *) NULL)\n    (void) SetImageOption(image_info,\"dither\",artifact);\n  switch (type)\n  {\n    case BilevelType:\n    {\n      if (SetImageMonochrome(image,&image->exception) == MagickFalse)\n        {\n          status=TransformImageColorspace(image,GRAYColorspace);\n          (void) NormalizeImage(image);\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=2;\n          quantize_info->colorspace=GRAYColorspace;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      status=AcquireImageColormap(image,2);\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleMatteType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case PaletteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if ((image->storage_class == DirectClass) || (image->colors > 256))\n        {\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=256;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      image->matte=MagickFalse;\n      break;\n    }\n    case PaletteBilevelMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      (void) BilevelImageChannel(image,AlphaChannel,(double) QuantumRange/2.0);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case PaletteMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      quantize_info->colorspace=TransparentColorspace;\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case TrueColorType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case TrueColorMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case ColorSeparationType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case ColorSeparationMatteType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case OptimizeType:\n    case UndefinedType:\n      break;\n  }\n  image_info=DestroyImageInfo(image_info);\n  if (status == MagickFalse)\n    return(MagickFalse);\n  image->type=type;\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/d63a3c5729df59f183e9e110d5d8385d17caaad0", "file_name": "magick/attribute.c", "vul_type": "cwe-416", "description": "In C, write a function to change the type of an image using ImageMagick's API."}
{"func_name": "updateKey", "func_src_before": "def updateKey(client):\n\t\"\"\"Updates the contents of a key that already exists in our system.\n\tReturns an error if the specified key doesn't exist for the specified user.\n\t\"\"\"\n\tglobal NOT_FOUND\n\tglobal CREATED\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateNewKeyData(token_data)\n\n\t# Use 'w' flag to replace existing key file with the new key data\n\tif os.path.isfile('keys/%s/%s.key' % (client, token_data['name'])):\n\t\twith open('keys/%s/%s.key' % (client, token_data['name']), 'w') as f:\n\t\t\tf.write(token_data['key'])\n\telse:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['name'])\n\n\treturn 'Key successfully updated', CREATED", "func_src_after": "def updateKey(client):\n\t\"\"\"Updates the contents of a key that already exists in our system.\n\tReturns an error if the specified key doesn't exist for the specified user.\n\t\"\"\"\n\tglobal NOT_FOUND\n\tglobal CREATED\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateNewKeyData(token_data)\n\tvalidateKeyName(token_data['name'])\n\n\t# Use 'w' flag to replace existing key file with the new key data\n\tif os.path.isfile('keys/%s/%s.key' % (client, token_data['name'])):\n\t\twith open('keys/%s/%s.key' % (client, token_data['name']), 'w') as f:\n\t\t\tf.write(token_data['key'])\n\telse:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['name'])\n\n\treturn 'Key successfully updated', CREATED", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function to update a user's key file with new data, raising an error if the key file does not exist."}
{"func_name": "get_old_sourcebyinstitution_number", "func_src_before": "def get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution):\n    \"\"\"\n    Get all the old sourcebyinstitution number from the SQLite database.\n    \"\"\"\n    query = \"\"\"\n        SELECT\n            titles\n        FROM\n            history\n        WHERE\n            sourcebyinstitution = \"%s\"\n        ORDER BY\n            titles DESC\n        LIMIT 1\n    \"\"\" % sourcebyinstitution\n\n    sqlite.execute(query)\n    for record in sqlite:\n        old_sourcebyinstitution_number = record[0]\n        return old_sourcebyinstitution_number", "func_src_after": "def get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution):\n    \"\"\"\n    Get all the old sourcebyinstitution number from the SQLite database.\n    \"\"\"\n    query = \"\"\"\n        SELECT\n            titles\n        FROM\n            history\n        WHERE\n            sourcebyinstitution = ?\n        ORDER BY\n            titles DESC\n        LIMIT 1\n    \"\"\"\n\n    sqlite.execute(query, (sourcebyinstitution,))\n    for record in sqlite:\n        old_sourcebyinstitution_number = record[0]\n        return old_sourcebyinstitution_number", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the most recent title associated with a given source institution from an SQLite database."}
{"func_name": "unicode_unfold_key", "func_src_before": "unicode_unfold_key(OnigCodePoint code)\n{\n  static const struct ByUnfoldKey wordlist[] =\n    {\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0x1040a, 3267, 1},\n\n      {0x1e0a, 1727, 1},\n\n      {0x040a, 1016, 1},\n\n      {0x010a, 186, 1},\n\n      {0x1f0a, 2088, 1},\n\n      {0x2c0a, 2451, 1},\n\n      {0x0189, 619, 1},\n\n      {0x1f89, 134, 2},\n\n      {0x1f85, 154, 2},\n\n      {0x0389, 733, 1},\n\n      {0x03ff, 724, 1},\n\n      {0xab89, 1523, 1},\n\n      {0xab85, 1511, 1},\n\n      {0x10c89, 3384, 1},\n\n      {0x10c85, 3372, 1},\n\n      {0x1e84, 1911, 1},\n\n      {0x03f5, 752, 1},\n\n      {0x0184, 360, 1},\n\n      {0x1f84, 149, 2},\n\n      {0x2c84, 2592, 1},\n\n      {0x017d, 351, 1},\n\n      {0x1ff3, 96, 2},\n\n      {0xab84, 1508, 1},\n\n      {0xa784, 3105, 1},\n\n      {0x10c84, 3369, 1},\n\n      {0xab7d, 1487, 1},\n\n      {0xa77d, 1706, 1},\n\n      {0x1e98, 38, 2},\n\n      {0x0498, 1106, 1},\n\n      {0x0198, 375, 1},\n\n      {0x1f98, 169, 2},\n\n      {0x2c98, 2622, 1},\n\n      {0x0398, 762, 1},\n\n      {0xa684, 2940, 1},\n\n      {0xab98, 1568, 1},\n\n      {0xa798, 3123, 1},\n\n      {0x10c98, 3429, 1},\n\n      {0x050a, 1277, 1},\n\n      {0x1ffb, 2265, 1},\n\n      {0x1e96, 16, 2},\n\n      {0x0496, 1103, 1},\n\n      {0x0196, 652, 1},\n\n      {0x1f96, 199, 2},\n\n      {0x2c96, 2619, 1},\n\n      {0x0396, 756, 1},\n\n      {0xa698, 2970, 1},\n\n      {0xab96, 1562, 1},\n\n      {0xa796, 3120, 1},\n\n      {0x10c96, 3423, 1},\n\n      {0x1feb, 2259, 1},\n\n      {0x2ceb, 2736, 1},\n\n      {0x1e90, 1929, 1},\n\n      {0x0490, 1094, 1},\n\n      {0x0190, 628, 1},\n\n      {0x1f90, 169, 2},\n\n      {0x2c90, 2610, 1},\n\n      {0x0390, 25, 3},\n\n      {0xa696, 2967, 1},\n\n      {0xab90, 1544, 1},\n\n      {0xa790, 3114, 1},\n\n      {0x10c90, 3405, 1},\n\n      {0x01d7, 444, 1},\n\n      {0x1fd7, 31, 3},\n\n      {0x1ea6, 1947, 1},\n\n      {0x04a6, 1127, 1},\n\n      {0x01a6, 676, 1},\n\n      {0x1fa6, 239, 2},\n\n      {0x2ca6, 2643, 1},\n\n      {0x03a6, 810, 1},\n\n      {0xa690, 2958, 1},\n\n      {0xaba6, 1610, 1},\n\n      {0xa7a6, 3144, 1},\n\n      {0x10ca6, 3471, 1},\n\n      {0x1ea4, 1944, 1},\n\n      {0x04a4, 1124, 1},\n\n      {0x01a4, 390, 1},\n\n      {0x1fa4, 229, 2},\n\n      {0x2ca4, 2640, 1},\n\n      {0x03a4, 804, 1},\n\n      {0x10a6, 2763, 1},\n\n      {0xaba4, 1604, 1},\n\n      {0xa7a4, 3141, 1},\n\n      {0x10ca4, 3465, 1},\n\n      {0x1ea0, 1938, 1},\n\n      {0x04a0, 1118, 1},\n\n      {0x01a0, 384, 1},\n\n      {0x1fa0, 209, 2},\n\n      {0x2ca0, 2634, 1},\n\n      {0x03a0, 792, 1},\n\n      {0x10a4, 2757, 1},\n\n      {0xaba0, 1592, 1},\n\n      {0xa7a0, 3135, 1},\n\n      {0x10ca0, 3453, 1},\n\n      {0x1eb2, 1965, 1},\n\n      {0x04b2, 1145, 1},\n\n      {0x01b2, 694, 1},\n\n      {0x1fb2, 249, 2},\n\n      {0x2cb2, 2661, 1},\n\n      {0x03fd, 718, 1},\n\n      {0x10a0, 2745, 1},\n\n      {0xabb2, 1646, 1},\n\n      {0xa7b2, 703, 1},\n\n      {0x10cb2, 3507, 1},\n\n      {0x1eac, 1956, 1},\n\n      {0x04ac, 1136, 1},\n\n      {0x01ac, 396, 1},\n\n      {0x1fac, 229, 2},\n\n      {0x2cac, 2652, 1},\n\n      {0x0537, 1352, 1},\n\n      {0x10b2, 2799, 1},\n\n      {0xabac, 1628, 1},\n\n      {0xa7ac, 637, 1},\n\n      {0x10cac, 3489, 1},\n\n      {0x1eaa, 1953, 1},\n\n      {0x04aa, 1133, 1},\n\n      {0x00dd, 162, 1},\n\n      {0x1faa, 219, 2},\n\n      {0x2caa, 2649, 1},\n\n      {0x03aa, 824, 1},\n\n      {0x10ac, 2781, 1},\n\n      {0xabaa, 1622, 1},\n\n      {0xa7aa, 646, 1},\n\n      {0x10caa, 3483, 1},\n\n      {0x1ea8, 1950, 1},\n\n      {0x04a8, 1130, 1},\n\n      {0x020a, 517, 1},\n\n      {0x1fa8, 209, 2},\n\n      {0x2ca8, 2646, 1},\n\n      {0x03a8, 817, 1},\n\n      {0x10aa, 2775, 1},\n\n      {0xaba8, 1616, 1},\n\n      {0xa7a8, 3147, 1},\n\n      {0x10ca8, 3477, 1},\n\n      {0x1ea2, 1941, 1},\n\n      {0x04a2, 1121, 1},\n\n      {0x01a2, 387, 1},\n\n      {0x1fa2, 219, 2},\n\n      {0x2ca2, 2637, 1},\n\n      {0x118a6, 3528, 1},\n\n      {0x10a8, 2769, 1},\n\n      {0xaba2, 1598, 1},\n\n      {0xa7a2, 3138, 1},\n\n      {0x10ca2, 3459, 1},\n\n      {0x2ced, 2739, 1},\n\n      {0x1fe9, 2283, 1},\n\n      {0x1fe7, 47, 3},\n\n      {0x1eb0, 1962, 1},\n\n      {0x04b0, 1142, 1},\n\n      {0x118a4, 3522, 1},\n\n      {0x10a2, 2751, 1},\n\n      {0x2cb0, 2658, 1},\n\n      {0x03b0, 41, 3},\n\n      {0x1fe3, 41, 3},\n\n      {0xabb0, 1640, 1},\n\n      {0xa7b0, 706, 1},\n\n      {0x10cb0, 3501, 1},\n\n      {0x01d9, 447, 1},\n\n      {0x1fd9, 2277, 1},\n\n      {0x118a0, 3510, 1},\n\n      {0x00df, 24, 2},\n\n      {0x00d9, 150, 1},\n\n      {0xab77, 1469, 1},\n\n      {0x10b0, 2793, 1},\n\n      {0x1eae, 1959, 1},\n\n      {0x04ae, 1139, 1},\n\n      {0x01ae, 685, 1},\n\n      {0x1fae, 239, 2},\n\n      {0x2cae, 2655, 1},\n\n      {0x118b2, 3564, 1},\n\n      {0xab73, 1457, 1},\n\n      {0xabae, 1634, 1},\n\n      {0xab71, 1451, 1},\n\n      {0x10cae, 3495, 1},\n\n      {0x1e2a, 1775, 1},\n\n      {0x042a, 968, 1},\n\n      {0x012a, 234, 1},\n\n      {0x1f2a, 2130, 1},\n\n      {0x2c2a, 2547, 1},\n\n      {0x118ac, 3546, 1},\n\n      {0x10ae, 2787, 1},\n\n      {0x0535, 1346, 1},\n\n      {0xa72a, 2988, 1},\n\n      {0x1e9a, 0, 2},\n\n      {0x049a, 1109, 1},\n\n      {0xff37, 3225, 1},\n\n      {0x1f9a, 179, 2},\n\n      {0x2c9a, 2625, 1},\n\n      {0x039a, 772, 1},\n\n      {0x118aa, 3540, 1},\n\n      {0xab9a, 1574, 1},\n\n      {0xa79a, 3126, 1},\n\n      {0x10c9a, 3435, 1},\n\n      {0x1e94, 1935, 1},\n\n      {0x0494, 1100, 1},\n\n      {0x0194, 640, 1},\n\n      {0x1f94, 189, 2},\n\n      {0x2c94, 2616, 1},\n\n      {0x0394, 749, 1},\n\n      {0x118a8, 3534, 1},\n\n      {0xab94, 1556, 1},\n\n      {0xa69a, 2973, 1},\n\n      {0x10c94, 3417, 1},\n\n      {0x10402, 3243, 1},\n\n      {0x1e02, 1715, 1},\n\n      {0x0402, 992, 1},\n\n      {0x0102, 174, 1},\n\n      {0x0533, 1340, 1},\n\n      {0x2c02, 2427, 1},\n\n      {0x118a2, 3516, 1},\n\n      {0x052a, 1325, 1},\n\n      {0xa694, 2964, 1},\n\n      {0x1e92, 1932, 1},\n\n      {0x0492, 1097, 1},\n\n      {0x2165, 2307, 1},\n\n      {0x1f92, 179, 2},\n\n      {0x2c92, 2613, 1},\n\n      {0x0392, 742, 1},\n\n      {0x2161, 2295, 1},\n\n      {0xab92, 1550, 1},\n\n      {0xa792, 3117, 1},\n\n      {0x10c92, 3411, 1},\n\n      {0x118b0, 3558, 1},\n\n      {0x1f5f, 2199, 1},\n\n      {0x1e8e, 1926, 1},\n\n      {0x048e, 1091, 1},\n\n      {0x018e, 453, 1},\n\n      {0x1f8e, 159, 2},\n\n      {0x2c8e, 2607, 1},\n\n      {0x038e, 833, 1},\n\n      {0xa692, 2961, 1},\n\n      {0xab8e, 1538, 1},\n\n      {0x0055, 59, 1},\n\n      {0x10c8e, 3399, 1},\n\n      {0x1f5d, 2196, 1},\n\n      {0x212a, 27, 1},\n\n      {0x04cb, 1181, 1},\n\n      {0x01cb, 425, 1},\n\n      {0x1fcb, 2241, 1},\n\n      {0x118ae, 3552, 1},\n\n      {0x0502, 1265, 1},\n\n      {0x00cb, 111, 1},\n\n      {0xa68e, 2955, 1},\n\n      {0x1e8a, 1920, 1},\n\n      {0x048a, 1085, 1},\n\n      {0x018a, 622, 1},\n\n      {0x1f8a, 139, 2},\n\n      {0x2c8a, 2601, 1},\n\n      {0x038a, 736, 1},\n\n      {0x2c67, 2571, 1},\n\n      {0xab8a, 1526, 1},\n\n      {0x1e86, 1914, 1},\n\n      {0x10c8a, 3387, 1},\n\n      {0x0186, 616, 1},\n\n      {0x1f86, 159, 2},\n\n      {0x2c86, 2595, 1},\n\n      {0x0386, 727, 1},\n\n      {0xff35, 3219, 1},\n\n      {0xab86, 1514, 1},\n\n      {0xa786, 3108, 1},\n\n      {0x10c86, 3375, 1},\n\n      {0xa68a, 2949, 1},\n\n      {0x0555, 1442, 1},\n\n      {0x1ebc, 1980, 1},\n\n      {0x04bc, 1160, 1},\n\n      {0x01bc, 411, 1},\n\n      {0x1fbc, 62, 2},\n\n      {0x2cbc, 2676, 1},\n\n      {0x1f5b, 2193, 1},\n\n      {0xa686, 2943, 1},\n\n      {0xabbc, 1676, 1},\n\n      {0x1eb8, 1974, 1},\n\n      {0x04b8, 1154, 1},\n\n      {0x01b8, 408, 1},\n\n      {0x1fb8, 2268, 1},\n\n      {0x2cb8, 2670, 1},\n\n      {0x01db, 450, 1},\n\n      {0x1fdb, 2247, 1},\n\n      {0xabb8, 1664, 1},\n\n      {0x10bc, 2829, 1},\n\n      {0x00db, 156, 1},\n\n      {0x1eb6, 1971, 1},\n\n      {0x04b6, 1151, 1},\n\n      {0xff33, 3213, 1},\n\n      {0x1fb6, 58, 2},\n\n      {0x2cb6, 2667, 1},\n\n      {0xff2a, 3186, 1},\n\n      {0x10b8, 2817, 1},\n\n      {0xabb6, 1658, 1},\n\n      {0xa7b6, 3153, 1},\n\n      {0x10426, 3351, 1},\n\n      {0x1e26, 1769, 1},\n\n      {0x0426, 956, 1},\n\n      {0x0126, 228, 1},\n\n      {0x0053, 52, 1},\n\n      {0x2c26, 2535, 1},\n\n      {0x0057, 65, 1},\n\n      {0x10b6, 2811, 1},\n\n      {0x022a, 562, 1},\n\n      {0xa726, 2982, 1},\n\n      {0x1e2e, 1781, 1},\n\n      {0x042e, 980, 1},\n\n      {0x012e, 240, 1},\n\n      {0x1f2e, 2142, 1},\n\n      {0x2c2e, 2559, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2167, 2313, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa72e, 2994, 1},\n\n      {0x1e2c, 1778, 1},\n\n      {0x042c, 974, 1},\n\n      {0x012c, 237, 1},\n\n      {0x1f2c, 2136, 1},\n\n      {0x2c2c, 2553, 1},\n\n      {0x1f6f, 2223, 1},\n\n      {0x2c6f, 604, 1},\n\n      {0xabbf, 1685, 1},\n\n      {0xa72c, 2991, 1},\n\n      {0x1e28, 1772, 1},\n\n      {0x0428, 962, 1},\n\n      {0x0128, 231, 1},\n\n      {0x1f28, 2124, 1},\n\n      {0x2c28, 2541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0553, 1436, 1},\n\n      {0x10bf, 2838, 1},\n\n      {0xa728, 2985, 1},\n\n      {0x0526, 1319, 1},\n\n      {0x0202, 505, 1},\n\n      {0x1e40, 1808, 1},\n\n      {0x10424, 3345, 1},\n\n      {0x1e24, 1766, 1},\n\n      {0x0424, 950, 1},\n\n      {0x0124, 225, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c24, 2529, 1},\n\n      {0x052e, 1331, 1},\n\n      {0xa740, 3018, 1},\n\n      {0x118bc, 3594, 1},\n\n      {0xa724, 2979, 1},\n\n      {0x1ef2, 2061, 1},\n\n      {0x04f2, 1241, 1},\n\n      {0x01f2, 483, 1},\n\n      {0x1ff2, 257, 2},\n\n      {0x2cf2, 2742, 1},\n\n      {0x052c, 1328, 1},\n\n      {0x118b8, 3582, 1},\n\n      {0xa640, 2865, 1},\n\n      {0x10422, 3339, 1},\n\n      {0x1e22, 1763, 1},\n\n      {0x0422, 944, 1},\n\n      {0x0122, 222, 1},\n\n      {0x2126, 820, 1},\n\n      {0x2c22, 2523, 1},\n\n      {0x0528, 1322, 1},\n\n      {0x01f1, 483, 1},\n\n      {0x118b6, 3576, 1},\n\n      {0xa722, 2976, 1},\n\n      {0x03f1, 796, 1},\n\n      {0x1ebe, 1983, 1},\n\n      {0x04be, 1163, 1},\n\n      {0xfb02, 12, 2},\n\n      {0x1fbe, 767, 1},\n\n      {0x2cbe, 2679, 1},\n\n      {0x01b5, 405, 1},\n\n      {0x0540, 1379, 1},\n\n      {0xabbe, 1682, 1},\n\n      {0x0524, 1316, 1},\n\n      {0x00b5, 779, 1},\n\n      {0xabb5, 1655, 1},\n\n      {0x1eba, 1977, 1},\n\n      {0x04ba, 1157, 1},\n\n      {0x216f, 2337, 1},\n\n      {0x1fba, 2226, 1},\n\n      {0x2cba, 2673, 1},\n\n      {0x10be, 2835, 1},\n\n      {0x0051, 46, 1},\n\n      {0xabba, 1670, 1},\n\n      {0x10b5, 2808, 1},\n\n      {0x1e6e, 1878, 1},\n\n      {0x046e, 1055, 1},\n\n      {0x016e, 330, 1},\n\n      {0x1f6e, 2220, 1},\n\n      {0x2c6e, 664, 1},\n\n      {0x118bf, 3603, 1},\n\n      {0x0522, 1313, 1},\n\n      {0x10ba, 2823, 1},\n\n      {0xa76e, 3087, 1},\n\n      {0x1eb4, 1968, 1},\n\n      {0x04b4, 1148, 1},\n\n      {0x2c75, 2583, 1},\n\n      {0x1fb4, 50, 2},\n\n      {0x2cb4, 2664, 1},\n\n      {0xab75, 1463, 1},\n\n      {0x1ec2, 1989, 1},\n\n      {0xabb4, 1652, 1},\n\n      {0xa7b4, 3150, 1},\n\n      {0x1fc2, 253, 2},\n\n      {0x2cc2, 2685, 1},\n\n      {0x03c2, 800, 1},\n\n      {0x00c2, 83, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff26, 3174, 1},\n\n      {0x10b4, 2805, 1},\n\n      {0x1eca, 2001, 1},\n\n      {0x0551, 1430, 1},\n\n      {0x01ca, 425, 1},\n\n      {0x1fca, 2238, 1},\n\n      {0x2cca, 2697, 1},\n\n      {0x10c2, 2847, 1},\n\n      {0x00ca, 108, 1},\n\n      {0xff2e, 3198, 1},\n\n      {0x1e8c, 1923, 1},\n\n      {0x048c, 1088, 1},\n\n      {0x0226, 556, 1},\n\n      {0x1f8c, 149, 2},\n\n      {0x2c8c, 2604, 1},\n\n      {0x038c, 830, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8c, 1532, 1},\n\n      {0xff2c, 3192, 1},\n\n      {0x10c8c, 3393, 1},\n\n      {0x1ec4, 1992, 1},\n\n      {0x022e, 568, 1},\n\n      {0x01c4, 417, 1},\n\n      {0x1fc4, 54, 2},\n\n      {0x2cc4, 2688, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c4, 89, 1},\n\n      {0xff28, 3180, 1},\n\n      {0xa68c, 2952, 1},\n\n      {0x01cf, 432, 1},\n\n      {0x022c, 565, 1},\n\n      {0x118be, 3600, 1},\n\n      {0x03cf, 839, 1},\n\n      {0x00cf, 123, 1},\n\n      {0x118b5, 3573, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c4, 2853, 1},\n\n      {0x216e, 2334, 1},\n\n      {0x24cb, 2406, 1},\n\n      {0x0228, 559, 1},\n\n      {0xff24, 3168, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ba, 3588, 1},\n\n      {0x1efe, 2079, 1},\n\n      {0x04fe, 1259, 1},\n\n      {0x01fe, 499, 1},\n\n      {0x1e9e, 24, 2},\n\n      {0x049e, 1115, 1},\n\n      {0x03fe, 721, 1},\n\n      {0x1f9e, 199, 2},\n\n      {0x2c9e, 2631, 1},\n\n      {0x039e, 786, 1},\n\n      {0x0224, 553, 1},\n\n      {0xab9e, 1586, 1},\n\n      {0xa79e, 3132, 1},\n\n      {0x10c9e, 3447, 1},\n\n      {0x01f7, 414, 1},\n\n      {0x1ff7, 67, 3},\n\n      {0xff22, 3162, 1},\n\n      {0x03f7, 884, 1},\n\n      {0x118b4, 3570, 1},\n\n      {0x049c, 1112, 1},\n\n      {0x019c, 661, 1},\n\n      {0x1f9c, 189, 2},\n\n      {0x2c9c, 2628, 1},\n\n      {0x039c, 779, 1},\n\n      {0x24bc, 2361, 1},\n\n      {0xab9c, 1580, 1},\n\n      {0xa79c, 3129, 1},\n\n      {0x10c9c, 3441, 1},\n\n      {0x0222, 550, 1},\n\n      {0x1e7c, 1899, 1},\n\n      {0x047c, 1076, 1},\n\n      {0x1e82, 1908, 1},\n\n      {0x24b8, 2349, 1},\n\n      {0x0182, 357, 1},\n\n      {0x1f82, 139, 2},\n\n      {0x2c82, 2589, 1},\n\n      {0xab7c, 1484, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab82, 1502, 1},\n\n      {0xa782, 3102, 1},\n\n      {0x10c82, 3363, 1},\n\n      {0x2c63, 1709, 1},\n\n      {0x24b6, 2343, 1},\n\n      {0x1e80, 1905, 1},\n\n      {0x0480, 1082, 1},\n\n      {0x1f59, 2190, 1},\n\n      {0x1f80, 129, 2},\n\n      {0x2c80, 2586, 1},\n\n      {0x0059, 71, 1},\n\n      {0xa682, 2937, 1},\n\n      {0xab80, 1496, 1},\n\n      {0xa780, 3099, 1},\n\n      {0x10c80, 3357, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1e4c, 1826, 1},\n\n      {0x0145, 270, 1},\n\n      {0x014c, 279, 1},\n\n      {0x1f4c, 2184, 1},\n\n      {0x0345, 767, 1},\n\n      {0x0045, 12, 1},\n\n      {0x004c, 31, 1},\n\n      {0xa680, 2934, 1},\n\n      {0xa74c, 3036, 1},\n\n      {0x1e4a, 1823, 1},\n\n      {0x01d5, 441, 1},\n\n      {0x014a, 276, 1},\n\n      {0x1f4a, 2178, 1},\n\n      {0x03d5, 810, 1},\n\n      {0x00d5, 141, 1},\n\n      {0x004a, 24, 1},\n\n      {0x24bf, 2370, 1},\n\n      {0xa74a, 3033, 1},\n\n      {0xa64c, 2883, 1},\n\n      {0x1041c, 3321, 1},\n\n      {0x1e1c, 1754, 1},\n\n      {0x041c, 926, 1},\n\n      {0x011c, 213, 1},\n\n      {0x1f1c, 2118, 1},\n\n      {0x2c1c, 2505, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xa64a, 2880, 1},\n\n      {0x1041a, 3315, 1},\n\n      {0x1e1a, 1751, 1},\n\n      {0x041a, 920, 1},\n\n      {0x011a, 210, 1},\n\n      {0x1f1a, 2112, 1},\n\n      {0x2c1a, 2499, 1},\n\n      {0xabbd, 1679, 1},\n\n      {0x0545, 1394, 1},\n\n      {0x054c, 1415, 1},\n\n      {0x10418, 3309, 1},\n\n      {0x1e18, 1748, 1},\n\n      {0x0418, 914, 1},\n\n      {0x0118, 207, 1},\n\n      {0x1f18, 2106, 1},\n\n      {0x2c18, 2493, 1},\n\n      {0x10bd, 2832, 1},\n\n      {0x2163, 2301, 1},\n\n      {0x054a, 1409, 1},\n\n      {0x1040e, 3279, 1},\n\n      {0x1e0e, 1733, 1},\n\n      {0x040e, 1028, 1},\n\n      {0x010e, 192, 1},\n\n      {0x1f0e, 2100, 1},\n\n      {0x2c0e, 2463, 1},\n\n      {0x1efc, 2076, 1},\n\n      {0x04fc, 1256, 1},\n\n      {0x01fc, 496, 1},\n\n      {0x1ffc, 96, 2},\n\n      {0x051c, 1304, 1},\n\n      {0x1040c, 3273, 1},\n\n      {0x1e0c, 1730, 1},\n\n      {0x040c, 1022, 1},\n\n      {0x010c, 189, 1},\n\n      {0x1f0c, 2094, 1},\n\n      {0x2c0c, 2457, 1},\n\n      {0x1f6d, 2217, 1},\n\n      {0x2c6d, 607, 1},\n\n      {0x051a, 1301, 1},\n\n      {0x24be, 2367, 1},\n\n      {0x10408, 3261, 1},\n\n      {0x1e08, 1724, 1},\n\n      {0x0408, 1010, 1},\n\n      {0x0108, 183, 1},\n\n      {0x1f08, 2082, 1},\n\n      {0x2c08, 2445, 1},\n\n      {0x04c9, 1178, 1},\n\n      {0x0518, 1298, 1},\n\n      {0x1fc9, 2235, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ba, 2355, 1},\n\n      {0x00c9, 105, 1},\n\n      {0x10416, 3303, 1},\n\n      {0x1e16, 1745, 1},\n\n      {0x0416, 908, 1},\n\n      {0x0116, 204, 1},\n\n      {0x050e, 1283, 1},\n\n      {0x2c16, 2487, 1},\n\n      {0x10414, 3297, 1},\n\n      {0x1e14, 1742, 1},\n\n      {0x0414, 902, 1},\n\n      {0x0114, 201, 1},\n\n      {0x042b, 971, 1},\n\n      {0x2c14, 2481, 1},\n\n      {0x1f2b, 2133, 1},\n\n      {0x2c2b, 2550, 1},\n      {0xffffffff, -1, 0},\n\n      {0x050c, 1280, 1},\n\n      {0x10406, 3255, 1},\n\n      {0x1e06, 1721, 1},\n\n      {0x0406, 1004, 1},\n\n      {0x0106, 180, 1},\n\n      {0x13fb, 1697, 1},\n\n      {0x2c06, 2439, 1},\n\n      {0x24c2, 2379, 1},\n\n      {0x118bd, 3597, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0508, 1274, 1},\n\n      {0x10404, 3249, 1},\n\n      {0x1e04, 1718, 1},\n\n      {0x0404, 998, 1},\n\n      {0x0104, 177, 1},\n\n      {0x1f95, 194, 2},\n\n      {0x2c04, 2433, 1},\n\n      {0x0395, 752, 1},\n\n      {0x24ca, 2403, 1},\n\n      {0xab95, 1559, 1},\n\n      {0x0531, 1334, 1},\n\n      {0x10c95, 3420, 1},\n\n      {0x0516, 1295, 1},\n\n      {0x1e6c, 1875, 1},\n\n      {0x046c, 1052, 1},\n\n      {0x016c, 327, 1},\n\n      {0x1f6c, 2214, 1},\n\n      {0x216d, 2331, 1},\n\n      {0x0514, 1292, 1},\n\n      {0x0245, 697, 1},\n\n      {0x024c, 598, 1},\n\n      {0xa76c, 3084, 1},\n\n      {0x10400, 3237, 1},\n\n      {0x1e00, 1712, 1},\n\n      {0x0400, 986, 1},\n\n      {0x0100, 171, 1},\n\n      {0x24c4, 2385, 1},\n\n      {0x2c00, 2421, 1},\n\n      {0x0506, 1271, 1},\n\n      {0x024a, 595, 1},\n\n      {0x1fab, 224, 2},\n\n      {0xa66c, 2931, 1},\n\n      {0x03ab, 827, 1},\n\n      {0x24cf, 2418, 1},\n\n      {0xabab, 1625, 1},\n\n      {0xa7ab, 631, 1},\n\n      {0x10cab, 3486, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0504, 1268, 1},\n      {0xffffffff, -1, 0},\n\n      {0x021c, 544, 1},\n\n      {0x01a9, 679, 1},\n\n      {0x1fa9, 214, 2},\n\n      {0x10ab, 2778, 1},\n\n      {0x03a9, 820, 1},\n\n      {0x212b, 92, 1},\n\n      {0xaba9, 1619, 1},\n\n      {0x1e88, 1917, 1},\n\n      {0x10ca9, 3480, 1},\n\n      {0x021a, 541, 1},\n\n      {0x1f88, 129, 2},\n\n      {0x2c88, 2598, 1},\n\n      {0x0388, 730, 1},\n\n      {0x13fd, 1703, 1},\n\n      {0xab88, 1520, 1},\n\n      {0x10a9, 2772, 1},\n\n      {0x10c88, 3381, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0218, 538, 1},\n\n      {0x0500, 1262, 1},\n\n      {0x1f4d, 2187, 1},\n\n      {0x01a7, 393, 1},\n\n      {0x1fa7, 244, 2},\n\n      {0x004d, 34, 1},\n\n      {0x03a7, 814, 1},\n\n      {0xa688, 2946, 1},\n\n      {0xaba7, 1613, 1},\n\n      {0x020e, 523, 1},\n\n      {0x10ca7, 3474, 1},\n\n      {0x1e6a, 1872, 1},\n\n      {0x046a, 1049, 1},\n\n      {0x016a, 324, 1},\n\n      {0x1f6a, 2208, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216c, 2328, 1},\n\n      {0x10a7, 2766, 1},\n\n      {0x01d1, 435, 1},\n\n      {0xa76a, 3081, 1},\n\n      {0x020c, 520, 1},\n\n      {0x03d1, 762, 1},\n\n      {0x00d1, 129, 1},\n\n      {0x1e68, 1869, 1},\n\n      {0x0468, 1046, 1},\n\n      {0x0168, 321, 1},\n\n      {0x1f68, 2202, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff31, 3207, 1},\n\n      {0xa66a, 2928, 1},\n\n      {0x0208, 514, 1},\n\n      {0xa768, 3078, 1},\n\n      {0x1e64, 1863, 1},\n\n      {0x0464, 1040, 1},\n\n      {0x0164, 315, 1},\n\n      {0x054d, 1418, 1},\n\n      {0x2c64, 673, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff2b, 3189, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa764, 3072, 1},\n\n      {0xa668, 2925, 1},\n\n      {0x0216, 535, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ab, 3543, 1},\n\n      {0x1e62, 1860, 1},\n\n      {0x0462, 1037, 1},\n\n      {0x0162, 312, 1},\n\n      {0x0214, 532, 1},\n\n      {0x2c62, 655, 1},\n\n      {0xa664, 2919, 1},\n\n      {0x1ed2, 2013, 1},\n\n      {0x04d2, 1193, 1},\n\n      {0xa762, 3069, 1},\n\n      {0x1fd2, 20, 3},\n\n      {0x2cd2, 2709, 1},\n\n      {0x118a9, 3537, 1},\n\n      {0x00d2, 132, 1},\n\n      {0x0206, 511, 1},\n\n      {0x10420, 3333, 1},\n\n      {0x1e20, 1760, 1},\n\n      {0x0420, 938, 1},\n\n      {0x0120, 219, 1},\n\n      {0xa662, 2916, 1},\n\n      {0x2c20, 2517, 1},\n\n      {0x1e60, 1856, 1},\n\n      {0x0460, 1034, 1},\n\n      {0x0160, 309, 1},\n\n      {0x0204, 508, 1},\n\n      {0x2c60, 2562, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24bd, 2364, 1},\n\n      {0x216a, 2322, 1},\n\n      {0xa760, 3066, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb16, 125, 2},\n\n      {0x118a7, 3531, 1},\n\n      {0x1efa, 2073, 1},\n\n      {0x04fa, 1253, 1},\n\n      {0x01fa, 493, 1},\n\n      {0x1ffa, 2262, 1},\n\n      {0xfb14, 109, 2},\n\n      {0x03fa, 887, 1},\n\n      {0xa660, 2913, 1},\n\n      {0x2168, 2316, 1},\n\n      {0x01b7, 700, 1},\n\n      {0x1fb7, 10, 3},\n\n      {0x1f6b, 2211, 1},\n\n      {0x2c6b, 2577, 1},\n\n      {0x0200, 502, 1},\n\n      {0xabb7, 1661, 1},\n\n      {0xfb06, 29, 2},\n\n      {0x1e56, 1841, 1},\n\n      {0x2164, 2304, 1},\n\n      {0x0156, 294, 1},\n\n      {0x1f56, 62, 3},\n\n      {0x0520, 1310, 1},\n\n      {0x004f, 40, 1},\n\n      {0x0056, 62, 1},\n\n      {0x10b7, 2814, 1},\n\n      {0xa756, 3051, 1},\n\n      {0xfb04, 5, 3},\n\n      {0x1e78, 1893, 1},\n\n      {0x0478, 1070, 1},\n\n      {0x0178, 168, 1},\n\n      {0x1e54, 1838, 1},\n\n      {0x2162, 2298, 1},\n\n      {0x0154, 291, 1},\n\n      {0x1f54, 57, 3},\n\n      {0xab78, 1472, 1},\n\n      {0xa656, 2898, 1},\n\n      {0x0054, 56, 1},\n\n      {0x1e52, 1835, 1},\n\n      {0xa754, 3048, 1},\n\n      {0x0152, 288, 1},\n\n      {0x1f52, 52, 3},\n\n      {0x24c9, 2400, 1},\n\n      {0x1e32, 1787, 1},\n\n      {0x0052, 49, 1},\n\n      {0x0132, 243, 1},\n\n      {0xa752, 3045, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb00, 4, 2},\n\n      {0xa654, 2895, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa732, 2997, 1},\n\n      {0x2160, 2292, 1},\n\n      {0x054f, 1424, 1},\n\n      {0x0556, 1445, 1},\n\n      {0x1e50, 1832, 1},\n\n      {0xa652, 2892, 1},\n\n      {0x0150, 285, 1},\n\n      {0x1f50, 84, 2},\n\n      {0x017b, 348, 1},\n\n      {0x1e4e, 1829, 1},\n\n      {0x0050, 43, 1},\n\n      {0x014e, 282, 1},\n\n      {0xa750, 3042, 1},\n\n      {0xab7b, 1481, 1},\n\n      {0xa77b, 3093, 1},\n\n      {0x004e, 37, 1},\n\n      {0x0554, 1439, 1},\n\n      {0xa74e, 3039, 1},\n\n      {0x1e48, 1820, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216b, 2325, 1},\n\n      {0x1f48, 2172, 1},\n\n      {0xa650, 2889, 1},\n\n      {0x0552, 1433, 1},\n\n      {0x0048, 21, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa748, 3030, 1},\n\n      {0xa64e, 2886, 1},\n\n      {0x0532, 1337, 1},\n\n      {0x1041e, 3327, 1},\n\n      {0x1e1e, 1757, 1},\n\n      {0x041e, 932, 1},\n\n      {0x011e, 216, 1},\n\n      {0x118b7, 3579, 1},\n\n      {0x2c1e, 2511, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa648, 2877, 1},\n\n      {0x1ff9, 2253, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03f9, 878, 1},\n\n      {0x0550, 1427, 1},\n\n      {0x10412, 3291, 1},\n\n      {0x1e12, 1739, 1},\n\n      {0x0412, 896, 1},\n\n      {0x0112, 198, 1},\n\n      {0x054e, 1421, 1},\n\n      {0x2c12, 2475, 1},\n\n      {0x10410, 3285, 1},\n\n      {0x1e10, 1736, 1},\n\n      {0x0410, 890, 1},\n\n      {0x0110, 195, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c10, 2469, 1},\n\n      {0x2132, 2289, 1},\n\n      {0x0548, 1403, 1},\n\n      {0x1ef8, 2070, 1},\n\n      {0x04f8, 1250, 1},\n\n      {0x01f8, 490, 1},\n\n      {0x1ff8, 2250, 1},\n\n      {0x0220, 381, 1},\n\n      {0x1ee2, 2037, 1},\n\n      {0x04e2, 1217, 1},\n\n      {0x01e2, 462, 1},\n\n      {0x1fe2, 36, 3},\n\n      {0x2ce2, 2733, 1},\n\n      {0x03e2, 857, 1},\n\n      {0x051e, 1307, 1},\n\n      {0x1ede, 2031, 1},\n\n      {0x04de, 1211, 1},\n\n      {0x01de, 456, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cde, 2727, 1},\n\n      {0x03de, 851, 1},\n\n      {0x00de, 165, 1},\n\n      {0x1f69, 2205, 1},\n\n      {0x2c69, 2574, 1},\n\n      {0x1eda, 2025, 1},\n\n      {0x04da, 1205, 1},\n\n      {0x0512, 1289, 1},\n\n      {0x1fda, 2244, 1},\n\n      {0x2cda, 2721, 1},\n\n      {0x03da, 845, 1},\n\n      {0x00da, 153, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0510, 1286, 1},\n\n      {0x1ed8, 2022, 1},\n\n      {0x04d8, 1202, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd8, 2274, 1},\n\n      {0x2cd8, 2718, 1},\n\n      {0x03d8, 842, 1},\n\n      {0x00d8, 147, 1},\n\n      {0x1ed6, 2019, 1},\n\n      {0x04d6, 1199, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd6, 76, 2},\n\n      {0x2cd6, 2715, 1},\n\n      {0x03d6, 792, 1},\n\n      {0x00d6, 144, 1},\n\n      {0x1ec8, 1998, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01c8, 421, 1},\n\n      {0x1fc8, 2232, 1},\n\n      {0x2cc8, 2694, 1},\n\n      {0xff32, 3210, 1},\n\n      {0x00c8, 102, 1},\n\n      {0x04c7, 1175, 1},\n\n      {0x01c7, 421, 1},\n\n      {0x1fc7, 15, 3},\n\n      {0x1ec0, 1986, 1},\n\n      {0x04c0, 1187, 1},\n\n      {0x00c7, 99, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cc0, 2682, 1},\n\n      {0x0179, 345, 1},\n\n      {0x00c0, 77, 1},\n\n      {0x0232, 574, 1},\n\n      {0x01b3, 402, 1},\n\n      {0x1fb3, 62, 2},\n\n      {0xab79, 1475, 1},\n\n      {0xa779, 3090, 1},\n\n      {0x10c7, 2859, 1},\n\n      {0xabb3, 1649, 1},\n\n      {0xa7b3, 3156, 1},\n\n      {0x1fa5, 234, 2},\n\n      {0x10c0, 2841, 1},\n\n      {0x03a5, 807, 1},\n      {0xffffffff, -1, 0},\n\n      {0xaba5, 1607, 1},\n\n      {0x01b1, 691, 1},\n\n      {0x10ca5, 3468, 1},\n\n      {0x10b3, 2802, 1},\n\n      {0x2169, 2319, 1},\n\n      {0x024e, 601, 1},\n\n      {0xabb1, 1643, 1},\n\n      {0xa7b1, 682, 1},\n\n      {0x10cb1, 3504, 1},\n\n      {0x10a5, 2760, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01af, 399, 1},\n\n      {0x1faf, 244, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0248, 592, 1},\n\n      {0x10b1, 2796, 1},\n\n      {0xabaf, 1637, 1},\n\n      {0x1fad, 234, 2},\n\n      {0x10caf, 3498, 1},\n\n      {0x04cd, 1184, 1},\n\n      {0x01cd, 429, 1},\n\n      {0xabad, 1631, 1},\n\n      {0xa7ad, 658, 1},\n\n      {0x10cad, 3492, 1},\n\n      {0x00cd, 117, 1},\n\n      {0x10af, 2790, 1},\n\n      {0x021e, 547, 1},\n\n      {0x1fa3, 224, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03a3, 800, 1},\n\n      {0x10ad, 2784, 1},\n\n      {0xaba3, 1601, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10ca3, 3462, 1},\n\n      {0x10cd, 2862, 1},\n\n      {0x1fa1, 214, 2},\n\n      {0x24b7, 2346, 1},\n\n      {0x03a1, 796, 1},\n\n      {0x0212, 529, 1},\n\n      {0xaba1, 1595, 1},\n\n      {0x10a3, 2754, 1},\n\n      {0x10ca1, 3456, 1},\n\n      {0x01d3, 438, 1},\n\n      {0x1fd3, 25, 3},\n\n      {0x0210, 526, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00d3, 135, 1},\n\n      {0x1e97, 34, 2},\n\n      {0x10a1, 2748, 1},\n\n      {0x0197, 649, 1},\n\n      {0x1f97, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0397, 759, 1},\n\n      {0x1041d, 3324, 1},\n\n      {0xab97, 1565, 1},\n\n      {0x041d, 929, 1},\n\n      {0x10c97, 3426, 1},\n\n      {0x1f1d, 2121, 1},\n\n      {0x2c1d, 2508, 1},\n\n      {0x1e72, 1884, 1},\n\n      {0x0472, 1061, 1},\n\n      {0x0172, 336, 1},\n\n      {0x118b3, 3567, 1},\n\n      {0x2c72, 2580, 1},\n\n      {0x0372, 712, 1},\n\n      {0x1041b, 3318, 1},\n\n      {0xab72, 1454, 1},\n\n      {0x041b, 923, 1},\n\n      {0x118a5, 3525, 1},\n\n      {0x1f1b, 2115, 1},\n\n      {0x2c1b, 2502, 1},\n\n      {0x1e70, 1881, 1},\n\n      {0x0470, 1058, 1},\n\n      {0x0170, 333, 1},\n\n      {0x118b1, 3561, 1},\n\n      {0x2c70, 610, 1},\n\n      {0x0370, 709, 1},\n\n      {0x1e46, 1817, 1},\n\n      {0xab70, 1448, 1},\n\n      {0x1e66, 1866, 1},\n\n      {0x0466, 1043, 1},\n\n      {0x0166, 318, 1},\n\n      {0x1e44, 1814, 1},\n\n      {0x0046, 15, 1},\n\n      {0x118af, 3555, 1},\n\n      {0xa746, 3027, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa766, 3075, 1},\n\n      {0x0044, 9, 1},\n\n      {0x118ad, 3549, 1},\n\n      {0xa744, 3024, 1},\n\n      {0x1e7a, 1896, 1},\n\n      {0x047a, 1073, 1},\n\n      {0x1e3a, 1799, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa646, 2874, 1},\n\n      {0x1f3a, 2154, 1},\n\n      {0xa666, 2922, 1},\n\n      {0xab7a, 1478, 1},\n\n      {0x118a3, 3519, 1},\n\n      {0xa644, 2871, 1},\n\n      {0xa73a, 3009, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1ef4, 2064, 1},\n\n      {0x04f4, 1244, 1},\n\n      {0x01f4, 487, 1},\n\n      {0x1ff4, 101, 2},\n\n      {0x118a1, 3513, 1},\n\n      {0x03f4, 762, 1},\n\n      {0x1eec, 2052, 1},\n\n      {0x04ec, 1232, 1},\n\n      {0x01ec, 477, 1},\n\n      {0x1fec, 2286, 1},\n\n      {0x0546, 1397, 1},\n\n      {0x03ec, 872, 1},\n      {0xffffffff, -1, 0},\n\n      {0x013f, 261, 1},\n\n      {0x1f3f, 2169, 1},\n\n      {0x0544, 1391, 1},\n\n      {0x1eea, 2049, 1},\n\n      {0x04ea, 1229, 1},\n\n      {0x01ea, 474, 1},\n\n      {0x1fea, 2256, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03ea, 869, 1},\n\n      {0x1ee8, 2046, 1},\n\n      {0x04e8, 1226, 1},\n\n      {0x01e8, 471, 1},\n\n      {0x1fe8, 2280, 1},\n\n      {0x053a, 1361, 1},\n\n      {0x03e8, 866, 1},\n\n      {0x1ee6, 2043, 1},\n\n      {0x04e6, 1223, 1},\n\n      {0x01e6, 468, 1},\n\n      {0x1fe6, 88, 2},\n\n      {0x1f4b, 2181, 1},\n\n      {0x03e6, 863, 1},\n\n      {0x1e5e, 1853, 1},\n\n      {0x004b, 27, 1},\n\n      {0x015e, 306, 1},\n\n      {0x2166, 2310, 1},\n\n      {0x1ee4, 2040, 1},\n\n      {0x04e4, 1220, 1},\n\n      {0x01e4, 465, 1},\n\n      {0x1fe4, 80, 2},\n\n      {0xa75e, 3063, 1},\n\n      {0x03e4, 860, 1},\n\n      {0x1ee0, 2034, 1},\n\n      {0x04e0, 1214, 1},\n\n      {0x01e0, 459, 1},\n\n      {0x053f, 1376, 1},\n\n      {0x2ce0, 2730, 1},\n\n      {0x03e0, 854, 1},\n\n      {0x1edc, 2028, 1},\n\n      {0x04dc, 1208, 1},\n\n      {0xa65e, 2910, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cdc, 2724, 1},\n\n      {0x03dc, 848, 1},\n\n      {0x00dc, 159, 1},\n\n      {0x1ed0, 2010, 1},\n\n      {0x04d0, 1190, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x2cd0, 2706, 1},\n\n      {0x03d0, 742, 1},\n\n      {0x00d0, 126, 1},\n\n      {0x1ecc, 2004, 1},\n\n      {0x054b, 1412, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fcc, 71, 2},\n\n      {0x2ccc, 2700, 1},\n\n      {0x1ec6, 1995, 1},\n\n      {0x00cc, 114, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fc6, 67, 2},\n\n      {0x2cc6, 2691, 1},\n\n      {0x24c8, 2397, 1},\n\n      {0x00c6, 96, 1},\n\n      {0x04c5, 1172, 1},\n\n      {0x01c5, 417, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fbb, 2229, 1},\n\n      {0x24c7, 2394, 1},\n\n      {0x00c5, 92, 1},\n\n      {0x1fb9, 2271, 1},\n\n      {0xabbb, 1673, 1},\n\n      {0x24c0, 2373, 1},\n\n      {0x04c3, 1169, 1},\n\n      {0xabb9, 1667, 1},\n\n      {0x1fc3, 71, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x00c3, 86, 1},\n\n      {0x10c5, 2856, 1},\n\n      {0x10bb, 2826, 1},\n\n      {0x1ed4, 2016, 1},\n\n      {0x04d4, 1196, 1},\n\n      {0x10b9, 2820, 1},\n\n      {0x13fc, 1700, 1},\n\n      {0x2cd4, 2712, 1},\n\n      {0x0246, 589, 1},\n\n      {0x00d4, 138, 1},\n\n      {0x10c3, 2850, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff3a, 3234, 1},\n\n      {0x0244, 688, 1},\n\n      {0x019f, 670, 1},\n\n      {0x1f9f, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x039f, 789, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab9f, 1589, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c9f, 3450, 1},\n\n      {0x019d, 667, 1},\n\n      {0x1f9d, 194, 2},\n\n      {0x023a, 2565, 1},\n\n      {0x039d, 783, 1},\n\n      {0x1e5a, 1847, 1},\n\n      {0xab9d, 1583, 1},\n\n      {0x015a, 300, 1},\n\n      {0x10c9d, 3444, 1},\n\n      {0x1e9b, 1856, 1},\n\n      {0x24cd, 2412, 1},\n\n      {0x005a, 74, 1},\n\n      {0x1f9b, 184, 2},\n\n      {0xa75a, 3057, 1},\n\n      {0x039b, 776, 1},\n\n      {0x1ece, 2007, 1},\n\n      {0xab9b, 1577, 1},\n\n      {0x1e99, 42, 2},\n\n      {0x10c9b, 3438, 1},\n\n      {0x2cce, 2703, 1},\n\n      {0x1f99, 174, 2},\n\n      {0x00ce, 120, 1},\n\n      {0x0399, 767, 1},\n\n      {0xa65a, 2904, 1},\n\n      {0xab99, 1571, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c99, 3432, 1},\n\n      {0x0193, 634, 1},\n\n      {0x1f93, 184, 2},\n\n      {0x1e58, 1844, 1},\n\n      {0x0393, 746, 1},\n\n      {0x0158, 297, 1},\n\n      {0xab93, 1553, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c93, 3414, 1},\n\n      {0x0058, 68, 1},\n\n      {0x042d, 977, 1},\n\n      {0xa758, 3054, 1},\n\n      {0x1f2d, 2139, 1},\n\n      {0x2c2d, 2556, 1},\n\n      {0x118bb, 3591, 1},\n\n      {0x0191, 369, 1},\n\n      {0x1f91, 174, 2},\n\n      {0x118b9, 3585, 1},\n\n      {0x0391, 739, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab91, 1547, 1},\n\n      {0xa658, 2901, 1},\n\n      {0x10c91, 3408, 1},\n\n      {0x018f, 625, 1},\n\n      {0x1f8f, 164, 2},\n      {0xffffffff, -1, 0},\n\n      {0x038f, 836, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8f, 1541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c8f, 3402, 1},\n\n      {0x018b, 366, 1},\n\n      {0x1f8b, 144, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0187, 363, 1},\n\n      {0x1f87, 164, 2},\n\n      {0xab8b, 1529, 1},\n\n      {0xa78b, 3111, 1},\n\n      {0x10c8b, 3390, 1},\n\n      {0xab87, 1517, 1},\n\n      {0x04c1, 1166, 1},\n\n      {0x10c87, 3378, 1},\n\n      {0x1e7e, 1902, 1},\n\n      {0x047e, 1079, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c1, 80, 1},\n\n      {0x2c7e, 580, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab7e, 1490, 1},\n\n      {0xa77e, 3096, 1},\n\n      {0x1e76, 1890, 1},\n\n      {0x0476, 1067, 1},\n\n      {0x0176, 342, 1},\n\n      {0x1e42, 1811, 1},\n\n      {0x10c1, 2844, 1},\n\n      {0x0376, 715, 1},\n\n      {0x1e36, 1793, 1},\n\n      {0xab76, 1466, 1},\n\n      {0x0136, 249, 1},\n\n      {0x0042, 3, 1},\n\n      {0x1e3e, 1805, 1},\n\n      {0xa742, 3021, 1},\n\n      {0x1e38, 1796, 1},\n\n      {0x1f3e, 2166, 1},\n\n      {0xa736, 3003, 1},\n\n      {0x1f38, 2148, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0587, 105, 2},\n\n      {0xa73e, 3015, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa738, 3006, 1},\n\n      {0xa642, 2868, 1},\n\n      {0x1e5c, 1850, 1},\n\n      {0x1e34, 1790, 1},\n\n      {0x015c, 303, 1},\n\n      {0x0134, 246, 1},\n\n      {0x1ef6, 2067, 1},\n\n      {0x04f6, 1247, 1},\n\n      {0x01f6, 372, 1},\n\n      {0x1ff6, 92, 2},\n\n      {0xa75c, 3060, 1},\n\n      {0xa734, 3000, 1},\n\n      {0x1ef0, 2058, 1},\n\n      {0x04f0, 1238, 1},\n\n      {0x01f0, 20, 2},\n      {0xffffffff, -1, 0},\n\n      {0x1e30, 1784, 1},\n\n      {0x03f0, 772, 1},\n\n      {0x0130, 261, 2},\n\n      {0x0542, 1385, 1},\n\n      {0xa65c, 2907, 1},\n\n      {0x1f83, 144, 2},\n\n      {0x0536, 1349, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab83, 1505, 1},\n\n      {0x053e, 1373, 1},\n\n      {0x10c83, 3366, 1},\n\n      {0x0538, 1355, 1},\n\n      {0x1eee, 2055, 1},\n\n      {0x04ee, 1235, 1},\n\n      {0x01ee, 480, 1},\n\n      {0x1f8d, 154, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03ee, 875, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8d, 1535, 1},\n\n      {0xa78d, 643, 1},\n\n      {0x10c8d, 3396, 1},\n\n      {0x0534, 1343, 1},\n\n      {0x0181, 613, 1},\n\n      {0x1f81, 134, 2},\n\n      {0x013d, 258, 1},\n\n      {0x1f3d, 2163, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab81, 1499, 1},\n\n      {0x017f, 52, 1},\n\n      {0x10c81, 3360, 1},\n\n      {0x2c7f, 583, 1},\n\n      {0x037f, 881, 1},\n\n      {0xff2d, 3195, 1},\n\n      {0xab7f, 1493, 1},\n\n      {0x1e74, 1887, 1},\n\n      {0x0474, 1064, 1},\n\n      {0x0174, 339, 1},\n\n      {0x1e3c, 1802, 1},\n\n      {0x0149, 46, 2},\n\n      {0x1f49, 2175, 1},\n\n      {0x1f3c, 2160, 1},\n\n      {0xab74, 1460, 1},\n\n      {0x0049, 3606, 1},\n\n      {0x0143, 267, 1},\n\n      {0x24cc, 2409, 1},\n\n      {0xa73c, 3012, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0043, 6, 1},\n\n      {0x0141, 264, 1},\n\n      {0x24c6, 2391, 1},\n\n      {0x013b, 255, 1},\n\n      {0x1f3b, 2157, 1},\n\n      {0x0041, 0, 1},\n\n      {0x0139, 252, 1},\n\n      {0x1f39, 2151, 1},\n\n      {0x24c5, 2388, 1},\n\n      {0x24bb, 2358, 1},\n\n      {0x13fa, 1694, 1},\n\n      {0x053d, 1370, 1},\n\n      {0x24b9, 2352, 1},\n\n      {0x0429, 965, 1},\n\n      {0x2183, 2340, 1},\n\n      {0x1f29, 2127, 1},\n\n      {0x2c29, 2544, 1},\n\n      {0x24c3, 2382, 1},\n\n      {0x10427, 3354, 1},\n\n      {0x10425, 3348, 1},\n\n      {0x0427, 959, 1},\n\n      {0x0425, 953, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c27, 2538, 1},\n\n      {0x2c25, 2532, 1},\n\n      {0x0549, 1406, 1},\n\n      {0x053c, 1367, 1},\n\n      {0x10423, 3342, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0423, 947, 1},\n\n      {0x0543, 1388, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c23, 2526, 1},\n\n      {0xff36, 3222, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0541, 1382, 1},\n\n      {0x10421, 3336, 1},\n\n      {0x053b, 1364, 1},\n\n      {0x0421, 941, 1},\n\n      {0xff38, 3228, 1},\n\n      {0x0539, 1358, 1},\n\n      {0x2c21, 2520, 1},\n\n      {0x10419, 3312, 1},\n\n      {0x10417, 3306, 1},\n\n      {0x0419, 917, 1},\n\n      {0x0417, 911, 1},\n\n      {0x1f19, 2109, 1},\n\n      {0x2c19, 2496, 1},\n\n      {0x2c17, 2490, 1},\n\n      {0x023e, 2568, 1},\n\n      {0xff34, 3216, 1},\n\n      {0x10415, 3300, 1},\n\n      {0x10413, 3294, 1},\n\n      {0x0415, 905, 1},\n\n      {0x0413, 899, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c15, 2484, 1},\n\n      {0x2c13, 2478, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ce, 2415, 1},\n\n      {0x1040f, 3282, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040f, 1031, 1},\n\n      {0xff30, 3204, 1},\n\n      {0x1f0f, 2103, 1},\n\n      {0x2c0f, 2466, 1},\n\n      {0x1040d, 3276, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040d, 1025, 1},\n\n      {0x0147, 273, 1},\n\n      {0x1f0d, 2097, 1},\n\n      {0x2c0d, 2460, 1},\n\n      {0x1040b, 3270, 1},\n\n      {0x0047, 18, 1},\n\n      {0x040b, 1019, 1},\n\n      {0x0230, 571, 1},\n\n      {0x1f0b, 2091, 1},\n\n      {0x2c0b, 2454, 1},\n\n      {0x10409, 3264, 1},\n\n      {0x10405, 3252, 1},\n\n      {0x0409, 1013, 1},\n\n      {0x0405, 1001, 1},\n\n      {0x1f09, 2085, 1},\n\n      {0x2c09, 2448, 1},\n\n      {0x2c05, 2436, 1},\n\n      {0x10403, 3246, 1},\n\n      {0x10401, 3240, 1},\n\n      {0x0403, 995, 1},\n\n      {0x0401, 989, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c03, 2430, 1},\n\n      {0x2c01, 2424, 1},\n\n      {0x13f9, 1691, 1},\n\n      {0x042f, 983, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1f2f, 2145, 1},\n\n      {0x1041f, 3330, 1},\n      {0xffffffff, -1, 0},\n\n      {0x041f, 935, 1},\n\n      {0x023d, 378, 1},\n\n      {0x10411, 3288, 1},\n\n      {0x2c1f, 2514, 1},\n\n      {0x0411, 893, 1},\n\n      {0x0547, 1400, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c11, 2472, 1},\n\n      {0x10407, 3258, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0407, 1007, 1},\n\n      {0x24c1, 2376, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c07, 2442, 1},\n      {0xffffffff, -1, 0},\n\n      {0x13f8, 1688, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff39, 3231, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0243, 354, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x0241, 586, 1},\n\n      {0xff29, 3183, 1},\n\n      {0x023b, 577, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff27, 3177, 1},\n\n      {0xff25, 3171, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff23, 3165, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff21, 3159, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb17, 117, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff2f, 3201, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb15, 113, 2},\n\n      {0xfb13, 121, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb05, 29, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb03, 0, 3},\n\n      {0xfb01, 8, 2}\n    };\n\n  if (0 == 0)\n    {\n      int key = hash(&code);\n\n      if (key <= MAX_HASH_VALUE && key >= 0)\n        {\n          OnigCodePoint gcode = wordlist[key].code;\n\n          if (code == gcode)\n            return &wordlist[key];\n        }\n    }\n  return 0;\n}", "func_src_after": "unicode_unfold_key(OnigCodePoint code)\n{\n  static const struct ByUnfoldKey wordlist[] =\n    {\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0x1040a, 3267, 1},\n\n      {0x1e0a, 1727, 1},\n\n      {0x040a, 1016, 1},\n\n      {0x010a, 186, 1},\n\n      {0x1f0a, 2088, 1},\n\n      {0x2c0a, 2451, 1},\n\n      {0x0189, 619, 1},\n\n      {0x1f89, 134, 2},\n\n      {0x1f85, 154, 2},\n\n      {0x0389, 733, 1},\n\n      {0x03ff, 724, 1},\n\n      {0xab89, 1523, 1},\n\n      {0xab85, 1511, 1},\n\n      {0x10c89, 3384, 1},\n\n      {0x10c85, 3372, 1},\n\n      {0x1e84, 1911, 1},\n\n      {0x03f5, 752, 1},\n\n      {0x0184, 360, 1},\n\n      {0x1f84, 149, 2},\n\n      {0x2c84, 2592, 1},\n\n      {0x017d, 351, 1},\n\n      {0x1ff3, 96, 2},\n\n      {0xab84, 1508, 1},\n\n      {0xa784, 3105, 1},\n\n      {0x10c84, 3369, 1},\n\n      {0xab7d, 1487, 1},\n\n      {0xa77d, 1706, 1},\n\n      {0x1e98, 38, 2},\n\n      {0x0498, 1106, 1},\n\n      {0x0198, 375, 1},\n\n      {0x1f98, 169, 2},\n\n      {0x2c98, 2622, 1},\n\n      {0x0398, 762, 1},\n\n      {0xa684, 2940, 1},\n\n      {0xab98, 1568, 1},\n\n      {0xa798, 3123, 1},\n\n      {0x10c98, 3429, 1},\n\n      {0x050a, 1277, 1},\n\n      {0x1ffb, 2265, 1},\n\n      {0x1e96, 16, 2},\n\n      {0x0496, 1103, 1},\n\n      {0x0196, 652, 1},\n\n      {0x1f96, 199, 2},\n\n      {0x2c96, 2619, 1},\n\n      {0x0396, 756, 1},\n\n      {0xa698, 2970, 1},\n\n      {0xab96, 1562, 1},\n\n      {0xa796, 3120, 1},\n\n      {0x10c96, 3423, 1},\n\n      {0x1feb, 2259, 1},\n\n      {0x2ceb, 2736, 1},\n\n      {0x1e90, 1929, 1},\n\n      {0x0490, 1094, 1},\n\n      {0x0190, 628, 1},\n\n      {0x1f90, 169, 2},\n\n      {0x2c90, 2610, 1},\n\n      {0x0390, 25, 3},\n\n      {0xa696, 2967, 1},\n\n      {0xab90, 1544, 1},\n\n      {0xa790, 3114, 1},\n\n      {0x10c90, 3405, 1},\n\n      {0x01d7, 444, 1},\n\n      {0x1fd7, 31, 3},\n\n      {0x1ea6, 1947, 1},\n\n      {0x04a6, 1127, 1},\n\n      {0x01a6, 676, 1},\n\n      {0x1fa6, 239, 2},\n\n      {0x2ca6, 2643, 1},\n\n      {0x03a6, 810, 1},\n\n      {0xa690, 2958, 1},\n\n      {0xaba6, 1610, 1},\n\n      {0xa7a6, 3144, 1},\n\n      {0x10ca6, 3471, 1},\n\n      {0x1ea4, 1944, 1},\n\n      {0x04a4, 1124, 1},\n\n      {0x01a4, 390, 1},\n\n      {0x1fa4, 229, 2},\n\n      {0x2ca4, 2640, 1},\n\n      {0x03a4, 804, 1},\n\n      {0x10a6, 2763, 1},\n\n      {0xaba4, 1604, 1},\n\n      {0xa7a4, 3141, 1},\n\n      {0x10ca4, 3465, 1},\n\n      {0x1ea0, 1938, 1},\n\n      {0x04a0, 1118, 1},\n\n      {0x01a0, 384, 1},\n\n      {0x1fa0, 209, 2},\n\n      {0x2ca0, 2634, 1},\n\n      {0x03a0, 792, 1},\n\n      {0x10a4, 2757, 1},\n\n      {0xaba0, 1592, 1},\n\n      {0xa7a0, 3135, 1},\n\n      {0x10ca0, 3453, 1},\n\n      {0x1eb2, 1965, 1},\n\n      {0x04b2, 1145, 1},\n\n      {0x01b2, 694, 1},\n\n      {0x1fb2, 249, 2},\n\n      {0x2cb2, 2661, 1},\n\n      {0x03fd, 718, 1},\n\n      {0x10a0, 2745, 1},\n\n      {0xabb2, 1646, 1},\n\n      {0xa7b2, 703, 1},\n\n      {0x10cb2, 3507, 1},\n\n      {0x1eac, 1956, 1},\n\n      {0x04ac, 1136, 1},\n\n      {0x01ac, 396, 1},\n\n      {0x1fac, 229, 2},\n\n      {0x2cac, 2652, 1},\n\n      {0x0537, 1352, 1},\n\n      {0x10b2, 2799, 1},\n\n      {0xabac, 1628, 1},\n\n      {0xa7ac, 637, 1},\n\n      {0x10cac, 3489, 1},\n\n      {0x1eaa, 1953, 1},\n\n      {0x04aa, 1133, 1},\n\n      {0x00dd, 162, 1},\n\n      {0x1faa, 219, 2},\n\n      {0x2caa, 2649, 1},\n\n      {0x03aa, 824, 1},\n\n      {0x10ac, 2781, 1},\n\n      {0xabaa, 1622, 1},\n\n      {0xa7aa, 646, 1},\n\n      {0x10caa, 3483, 1},\n\n      {0x1ea8, 1950, 1},\n\n      {0x04a8, 1130, 1},\n\n      {0x020a, 517, 1},\n\n      {0x1fa8, 209, 2},\n\n      {0x2ca8, 2646, 1},\n\n      {0x03a8, 817, 1},\n\n      {0x10aa, 2775, 1},\n\n      {0xaba8, 1616, 1},\n\n      {0xa7a8, 3147, 1},\n\n      {0x10ca8, 3477, 1},\n\n      {0x1ea2, 1941, 1},\n\n      {0x04a2, 1121, 1},\n\n      {0x01a2, 387, 1},\n\n      {0x1fa2, 219, 2},\n\n      {0x2ca2, 2637, 1},\n\n      {0x118a6, 3528, 1},\n\n      {0x10a8, 2769, 1},\n\n      {0xaba2, 1598, 1},\n\n      {0xa7a2, 3138, 1},\n\n      {0x10ca2, 3459, 1},\n\n      {0x2ced, 2739, 1},\n\n      {0x1fe9, 2283, 1},\n\n      {0x1fe7, 47, 3},\n\n      {0x1eb0, 1962, 1},\n\n      {0x04b0, 1142, 1},\n\n      {0x118a4, 3522, 1},\n\n      {0x10a2, 2751, 1},\n\n      {0x2cb0, 2658, 1},\n\n      {0x03b0, 41, 3},\n\n      {0x1fe3, 41, 3},\n\n      {0xabb0, 1640, 1},\n\n      {0xa7b0, 706, 1},\n\n      {0x10cb0, 3501, 1},\n\n      {0x01d9, 447, 1},\n\n      {0x1fd9, 2277, 1},\n\n      {0x118a0, 3510, 1},\n\n      {0x00df, 24, 2},\n\n      {0x00d9, 150, 1},\n\n      {0xab77, 1469, 1},\n\n      {0x10b0, 2793, 1},\n\n      {0x1eae, 1959, 1},\n\n      {0x04ae, 1139, 1},\n\n      {0x01ae, 685, 1},\n\n      {0x1fae, 239, 2},\n\n      {0x2cae, 2655, 1},\n\n      {0x118b2, 3564, 1},\n\n      {0xab73, 1457, 1},\n\n      {0xabae, 1634, 1},\n\n      {0xab71, 1451, 1},\n\n      {0x10cae, 3495, 1},\n\n      {0x1e2a, 1775, 1},\n\n      {0x042a, 968, 1},\n\n      {0x012a, 234, 1},\n\n      {0x1f2a, 2130, 1},\n\n      {0x2c2a, 2547, 1},\n\n      {0x118ac, 3546, 1},\n\n      {0x10ae, 2787, 1},\n\n      {0x0535, 1346, 1},\n\n      {0xa72a, 2988, 1},\n\n      {0x1e9a, 0, 2},\n\n      {0x049a, 1109, 1},\n\n      {0xff37, 3225, 1},\n\n      {0x1f9a, 179, 2},\n\n      {0x2c9a, 2625, 1},\n\n      {0x039a, 772, 1},\n\n      {0x118aa, 3540, 1},\n\n      {0xab9a, 1574, 1},\n\n      {0xa79a, 3126, 1},\n\n      {0x10c9a, 3435, 1},\n\n      {0x1e94, 1935, 1},\n\n      {0x0494, 1100, 1},\n\n      {0x0194, 640, 1},\n\n      {0x1f94, 189, 2},\n\n      {0x2c94, 2616, 1},\n\n      {0x0394, 749, 1},\n\n      {0x118a8, 3534, 1},\n\n      {0xab94, 1556, 1},\n\n      {0xa69a, 2973, 1},\n\n      {0x10c94, 3417, 1},\n\n      {0x10402, 3243, 1},\n\n      {0x1e02, 1715, 1},\n\n      {0x0402, 992, 1},\n\n      {0x0102, 174, 1},\n\n      {0x0533, 1340, 1},\n\n      {0x2c02, 2427, 1},\n\n      {0x118a2, 3516, 1},\n\n      {0x052a, 1325, 1},\n\n      {0xa694, 2964, 1},\n\n      {0x1e92, 1932, 1},\n\n      {0x0492, 1097, 1},\n\n      {0x2165, 2307, 1},\n\n      {0x1f92, 179, 2},\n\n      {0x2c92, 2613, 1},\n\n      {0x0392, 742, 1},\n\n      {0x2161, 2295, 1},\n\n      {0xab92, 1550, 1},\n\n      {0xa792, 3117, 1},\n\n      {0x10c92, 3411, 1},\n\n      {0x118b0, 3558, 1},\n\n      {0x1f5f, 2199, 1},\n\n      {0x1e8e, 1926, 1},\n\n      {0x048e, 1091, 1},\n\n      {0x018e, 453, 1},\n\n      {0x1f8e, 159, 2},\n\n      {0x2c8e, 2607, 1},\n\n      {0x038e, 833, 1},\n\n      {0xa692, 2961, 1},\n\n      {0xab8e, 1538, 1},\n\n      {0x0055, 59, 1},\n\n      {0x10c8e, 3399, 1},\n\n      {0x1f5d, 2196, 1},\n\n      {0x212a, 27, 1},\n\n      {0x04cb, 1181, 1},\n\n      {0x01cb, 425, 1},\n\n      {0x1fcb, 2241, 1},\n\n      {0x118ae, 3552, 1},\n\n      {0x0502, 1265, 1},\n\n      {0x00cb, 111, 1},\n\n      {0xa68e, 2955, 1},\n\n      {0x1e8a, 1920, 1},\n\n      {0x048a, 1085, 1},\n\n      {0x018a, 622, 1},\n\n      {0x1f8a, 139, 2},\n\n      {0x2c8a, 2601, 1},\n\n      {0x038a, 736, 1},\n\n      {0x2c67, 2571, 1},\n\n      {0xab8a, 1526, 1},\n\n      {0x1e86, 1914, 1},\n\n      {0x10c8a, 3387, 1},\n\n      {0x0186, 616, 1},\n\n      {0x1f86, 159, 2},\n\n      {0x2c86, 2595, 1},\n\n      {0x0386, 727, 1},\n\n      {0xff35, 3219, 1},\n\n      {0xab86, 1514, 1},\n\n      {0xa786, 3108, 1},\n\n      {0x10c86, 3375, 1},\n\n      {0xa68a, 2949, 1},\n\n      {0x0555, 1442, 1},\n\n      {0x1ebc, 1980, 1},\n\n      {0x04bc, 1160, 1},\n\n      {0x01bc, 411, 1},\n\n      {0x1fbc, 62, 2},\n\n      {0x2cbc, 2676, 1},\n\n      {0x1f5b, 2193, 1},\n\n      {0xa686, 2943, 1},\n\n      {0xabbc, 1676, 1},\n\n      {0x1eb8, 1974, 1},\n\n      {0x04b8, 1154, 1},\n\n      {0x01b8, 408, 1},\n\n      {0x1fb8, 2268, 1},\n\n      {0x2cb8, 2670, 1},\n\n      {0x01db, 450, 1},\n\n      {0x1fdb, 2247, 1},\n\n      {0xabb8, 1664, 1},\n\n      {0x10bc, 2829, 1},\n\n      {0x00db, 156, 1},\n\n      {0x1eb6, 1971, 1},\n\n      {0x04b6, 1151, 1},\n\n      {0xff33, 3213, 1},\n\n      {0x1fb6, 58, 2},\n\n      {0x2cb6, 2667, 1},\n\n      {0xff2a, 3186, 1},\n\n      {0x10b8, 2817, 1},\n\n      {0xabb6, 1658, 1},\n\n      {0xa7b6, 3153, 1},\n\n      {0x10426, 3351, 1},\n\n      {0x1e26, 1769, 1},\n\n      {0x0426, 956, 1},\n\n      {0x0126, 228, 1},\n\n      {0x0053, 52, 1},\n\n      {0x2c26, 2535, 1},\n\n      {0x0057, 65, 1},\n\n      {0x10b6, 2811, 1},\n\n      {0x022a, 562, 1},\n\n      {0xa726, 2982, 1},\n\n      {0x1e2e, 1781, 1},\n\n      {0x042e, 980, 1},\n\n      {0x012e, 240, 1},\n\n      {0x1f2e, 2142, 1},\n\n      {0x2c2e, 2559, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2167, 2313, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa72e, 2994, 1},\n\n      {0x1e2c, 1778, 1},\n\n      {0x042c, 974, 1},\n\n      {0x012c, 237, 1},\n\n      {0x1f2c, 2136, 1},\n\n      {0x2c2c, 2553, 1},\n\n      {0x1f6f, 2223, 1},\n\n      {0x2c6f, 604, 1},\n\n      {0xabbf, 1685, 1},\n\n      {0xa72c, 2991, 1},\n\n      {0x1e28, 1772, 1},\n\n      {0x0428, 962, 1},\n\n      {0x0128, 231, 1},\n\n      {0x1f28, 2124, 1},\n\n      {0x2c28, 2541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0553, 1436, 1},\n\n      {0x10bf, 2838, 1},\n\n      {0xa728, 2985, 1},\n\n      {0x0526, 1319, 1},\n\n      {0x0202, 505, 1},\n\n      {0x1e40, 1808, 1},\n\n      {0x10424, 3345, 1},\n\n      {0x1e24, 1766, 1},\n\n      {0x0424, 950, 1},\n\n      {0x0124, 225, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c24, 2529, 1},\n\n      {0x052e, 1331, 1},\n\n      {0xa740, 3018, 1},\n\n      {0x118bc, 3594, 1},\n\n      {0xa724, 2979, 1},\n\n      {0x1ef2, 2061, 1},\n\n      {0x04f2, 1241, 1},\n\n      {0x01f2, 483, 1},\n\n      {0x1ff2, 257, 2},\n\n      {0x2cf2, 2742, 1},\n\n      {0x052c, 1328, 1},\n\n      {0x118b8, 3582, 1},\n\n      {0xa640, 2865, 1},\n\n      {0x10422, 3339, 1},\n\n      {0x1e22, 1763, 1},\n\n      {0x0422, 944, 1},\n\n      {0x0122, 222, 1},\n\n      {0x2126, 820, 1},\n\n      {0x2c22, 2523, 1},\n\n      {0x0528, 1322, 1},\n\n      {0x01f1, 483, 1},\n\n      {0x118b6, 3576, 1},\n\n      {0xa722, 2976, 1},\n\n      {0x03f1, 796, 1},\n\n      {0x1ebe, 1983, 1},\n\n      {0x04be, 1163, 1},\n\n      {0xfb02, 12, 2},\n\n      {0x1fbe, 767, 1},\n\n      {0x2cbe, 2679, 1},\n\n      {0x01b5, 405, 1},\n\n      {0x0540, 1379, 1},\n\n      {0xabbe, 1682, 1},\n\n      {0x0524, 1316, 1},\n\n      {0x00b5, 779, 1},\n\n      {0xabb5, 1655, 1},\n\n      {0x1eba, 1977, 1},\n\n      {0x04ba, 1157, 1},\n\n      {0x216f, 2337, 1},\n\n      {0x1fba, 2226, 1},\n\n      {0x2cba, 2673, 1},\n\n      {0x10be, 2835, 1},\n\n      {0x0051, 46, 1},\n\n      {0xabba, 1670, 1},\n\n      {0x10b5, 2808, 1},\n\n      {0x1e6e, 1878, 1},\n\n      {0x046e, 1055, 1},\n\n      {0x016e, 330, 1},\n\n      {0x1f6e, 2220, 1},\n\n      {0x2c6e, 664, 1},\n\n      {0x118bf, 3603, 1},\n\n      {0x0522, 1313, 1},\n\n      {0x10ba, 2823, 1},\n\n      {0xa76e, 3087, 1},\n\n      {0x1eb4, 1968, 1},\n\n      {0x04b4, 1148, 1},\n\n      {0x2c75, 2583, 1},\n\n      {0x1fb4, 50, 2},\n\n      {0x2cb4, 2664, 1},\n\n      {0xab75, 1463, 1},\n\n      {0x1ec2, 1989, 1},\n\n      {0xabb4, 1652, 1},\n\n      {0xa7b4, 3150, 1},\n\n      {0x1fc2, 253, 2},\n\n      {0x2cc2, 2685, 1},\n\n      {0x03c2, 800, 1},\n\n      {0x00c2, 83, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff26, 3174, 1},\n\n      {0x10b4, 2805, 1},\n\n      {0x1eca, 2001, 1},\n\n      {0x0551, 1430, 1},\n\n      {0x01ca, 425, 1},\n\n      {0x1fca, 2238, 1},\n\n      {0x2cca, 2697, 1},\n\n      {0x10c2, 2847, 1},\n\n      {0x00ca, 108, 1},\n\n      {0xff2e, 3198, 1},\n\n      {0x1e8c, 1923, 1},\n\n      {0x048c, 1088, 1},\n\n      {0x0226, 556, 1},\n\n      {0x1f8c, 149, 2},\n\n      {0x2c8c, 2604, 1},\n\n      {0x038c, 830, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8c, 1532, 1},\n\n      {0xff2c, 3192, 1},\n\n      {0x10c8c, 3393, 1},\n\n      {0x1ec4, 1992, 1},\n\n      {0x022e, 568, 1},\n\n      {0x01c4, 417, 1},\n\n      {0x1fc4, 54, 2},\n\n      {0x2cc4, 2688, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c4, 89, 1},\n\n      {0xff28, 3180, 1},\n\n      {0xa68c, 2952, 1},\n\n      {0x01cf, 432, 1},\n\n      {0x022c, 565, 1},\n\n      {0x118be, 3600, 1},\n\n      {0x03cf, 839, 1},\n\n      {0x00cf, 123, 1},\n\n      {0x118b5, 3573, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c4, 2853, 1},\n\n      {0x216e, 2334, 1},\n\n      {0x24cb, 2406, 1},\n\n      {0x0228, 559, 1},\n\n      {0xff24, 3168, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ba, 3588, 1},\n\n      {0x1efe, 2079, 1},\n\n      {0x04fe, 1259, 1},\n\n      {0x01fe, 499, 1},\n\n      {0x1e9e, 24, 2},\n\n      {0x049e, 1115, 1},\n\n      {0x03fe, 721, 1},\n\n      {0x1f9e, 199, 2},\n\n      {0x2c9e, 2631, 1},\n\n      {0x039e, 786, 1},\n\n      {0x0224, 553, 1},\n\n      {0xab9e, 1586, 1},\n\n      {0xa79e, 3132, 1},\n\n      {0x10c9e, 3447, 1},\n\n      {0x01f7, 414, 1},\n\n      {0x1ff7, 67, 3},\n\n      {0xff22, 3162, 1},\n\n      {0x03f7, 884, 1},\n\n      {0x118b4, 3570, 1},\n\n      {0x049c, 1112, 1},\n\n      {0x019c, 661, 1},\n\n      {0x1f9c, 189, 2},\n\n      {0x2c9c, 2628, 1},\n\n      {0x039c, 779, 1},\n\n      {0x24bc, 2361, 1},\n\n      {0xab9c, 1580, 1},\n\n      {0xa79c, 3129, 1},\n\n      {0x10c9c, 3441, 1},\n\n      {0x0222, 550, 1},\n\n      {0x1e7c, 1899, 1},\n\n      {0x047c, 1076, 1},\n\n      {0x1e82, 1908, 1},\n\n      {0x24b8, 2349, 1},\n\n      {0x0182, 357, 1},\n\n      {0x1f82, 139, 2},\n\n      {0x2c82, 2589, 1},\n\n      {0xab7c, 1484, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab82, 1502, 1},\n\n      {0xa782, 3102, 1},\n\n      {0x10c82, 3363, 1},\n\n      {0x2c63, 1709, 1},\n\n      {0x24b6, 2343, 1},\n\n      {0x1e80, 1905, 1},\n\n      {0x0480, 1082, 1},\n\n      {0x1f59, 2190, 1},\n\n      {0x1f80, 129, 2},\n\n      {0x2c80, 2586, 1},\n\n      {0x0059, 71, 1},\n\n      {0xa682, 2937, 1},\n\n      {0xab80, 1496, 1},\n\n      {0xa780, 3099, 1},\n\n      {0x10c80, 3357, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1e4c, 1826, 1},\n\n      {0x0145, 270, 1},\n\n      {0x014c, 279, 1},\n\n      {0x1f4c, 2184, 1},\n\n      {0x0345, 767, 1},\n\n      {0x0045, 12, 1},\n\n      {0x004c, 31, 1},\n\n      {0xa680, 2934, 1},\n\n      {0xa74c, 3036, 1},\n\n      {0x1e4a, 1823, 1},\n\n      {0x01d5, 441, 1},\n\n      {0x014a, 276, 1},\n\n      {0x1f4a, 2178, 1},\n\n      {0x03d5, 810, 1},\n\n      {0x00d5, 141, 1},\n\n      {0x004a, 24, 1},\n\n      {0x24bf, 2370, 1},\n\n      {0xa74a, 3033, 1},\n\n      {0xa64c, 2883, 1},\n\n      {0x1041c, 3321, 1},\n\n      {0x1e1c, 1754, 1},\n\n      {0x041c, 926, 1},\n\n      {0x011c, 213, 1},\n\n      {0x1f1c, 2118, 1},\n\n      {0x2c1c, 2505, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xa64a, 2880, 1},\n\n      {0x1041a, 3315, 1},\n\n      {0x1e1a, 1751, 1},\n\n      {0x041a, 920, 1},\n\n      {0x011a, 210, 1},\n\n      {0x1f1a, 2112, 1},\n\n      {0x2c1a, 2499, 1},\n\n      {0xabbd, 1679, 1},\n\n      {0x0545, 1394, 1},\n\n      {0x054c, 1415, 1},\n\n      {0x10418, 3309, 1},\n\n      {0x1e18, 1748, 1},\n\n      {0x0418, 914, 1},\n\n      {0x0118, 207, 1},\n\n      {0x1f18, 2106, 1},\n\n      {0x2c18, 2493, 1},\n\n      {0x10bd, 2832, 1},\n\n      {0x2163, 2301, 1},\n\n      {0x054a, 1409, 1},\n\n      {0x1040e, 3279, 1},\n\n      {0x1e0e, 1733, 1},\n\n      {0x040e, 1028, 1},\n\n      {0x010e, 192, 1},\n\n      {0x1f0e, 2100, 1},\n\n      {0x2c0e, 2463, 1},\n\n      {0x1efc, 2076, 1},\n\n      {0x04fc, 1256, 1},\n\n      {0x01fc, 496, 1},\n\n      {0x1ffc, 96, 2},\n\n      {0x051c, 1304, 1},\n\n      {0x1040c, 3273, 1},\n\n      {0x1e0c, 1730, 1},\n\n      {0x040c, 1022, 1},\n\n      {0x010c, 189, 1},\n\n      {0x1f0c, 2094, 1},\n\n      {0x2c0c, 2457, 1},\n\n      {0x1f6d, 2217, 1},\n\n      {0x2c6d, 607, 1},\n\n      {0x051a, 1301, 1},\n\n      {0x24be, 2367, 1},\n\n      {0x10408, 3261, 1},\n\n      {0x1e08, 1724, 1},\n\n      {0x0408, 1010, 1},\n\n      {0x0108, 183, 1},\n\n      {0x1f08, 2082, 1},\n\n      {0x2c08, 2445, 1},\n\n      {0x04c9, 1178, 1},\n\n      {0x0518, 1298, 1},\n\n      {0x1fc9, 2235, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ba, 2355, 1},\n\n      {0x00c9, 105, 1},\n\n      {0x10416, 3303, 1},\n\n      {0x1e16, 1745, 1},\n\n      {0x0416, 908, 1},\n\n      {0x0116, 204, 1},\n\n      {0x050e, 1283, 1},\n\n      {0x2c16, 2487, 1},\n\n      {0x10414, 3297, 1},\n\n      {0x1e14, 1742, 1},\n\n      {0x0414, 902, 1},\n\n      {0x0114, 201, 1},\n\n      {0x042b, 971, 1},\n\n      {0x2c14, 2481, 1},\n\n      {0x1f2b, 2133, 1},\n\n      {0x2c2b, 2550, 1},\n      {0xffffffff, -1, 0},\n\n      {0x050c, 1280, 1},\n\n      {0x10406, 3255, 1},\n\n      {0x1e06, 1721, 1},\n\n      {0x0406, 1004, 1},\n\n      {0x0106, 180, 1},\n\n      {0x13fb, 1697, 1},\n\n      {0x2c06, 2439, 1},\n\n      {0x24c2, 2379, 1},\n\n      {0x118bd, 3597, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0508, 1274, 1},\n\n      {0x10404, 3249, 1},\n\n      {0x1e04, 1718, 1},\n\n      {0x0404, 998, 1},\n\n      {0x0104, 177, 1},\n\n      {0x1f95, 194, 2},\n\n      {0x2c04, 2433, 1},\n\n      {0x0395, 752, 1},\n\n      {0x24ca, 2403, 1},\n\n      {0xab95, 1559, 1},\n\n      {0x0531, 1334, 1},\n\n      {0x10c95, 3420, 1},\n\n      {0x0516, 1295, 1},\n\n      {0x1e6c, 1875, 1},\n\n      {0x046c, 1052, 1},\n\n      {0x016c, 327, 1},\n\n      {0x1f6c, 2214, 1},\n\n      {0x216d, 2331, 1},\n\n      {0x0514, 1292, 1},\n\n      {0x0245, 697, 1},\n\n      {0x024c, 598, 1},\n\n      {0xa76c, 3084, 1},\n\n      {0x10400, 3237, 1},\n\n      {0x1e00, 1712, 1},\n\n      {0x0400, 986, 1},\n\n      {0x0100, 171, 1},\n\n      {0x24c4, 2385, 1},\n\n      {0x2c00, 2421, 1},\n\n      {0x0506, 1271, 1},\n\n      {0x024a, 595, 1},\n\n      {0x1fab, 224, 2},\n\n      {0xa66c, 2931, 1},\n\n      {0x03ab, 827, 1},\n\n      {0x24cf, 2418, 1},\n\n      {0xabab, 1625, 1},\n\n      {0xa7ab, 631, 1},\n\n      {0x10cab, 3486, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0504, 1268, 1},\n      {0xffffffff, -1, 0},\n\n      {0x021c, 544, 1},\n\n      {0x01a9, 679, 1},\n\n      {0x1fa9, 214, 2},\n\n      {0x10ab, 2778, 1},\n\n      {0x03a9, 820, 1},\n\n      {0x212b, 92, 1},\n\n      {0xaba9, 1619, 1},\n\n      {0x1e88, 1917, 1},\n\n      {0x10ca9, 3480, 1},\n\n      {0x021a, 541, 1},\n\n      {0x1f88, 129, 2},\n\n      {0x2c88, 2598, 1},\n\n      {0x0388, 730, 1},\n\n      {0x13fd, 1703, 1},\n\n      {0xab88, 1520, 1},\n\n      {0x10a9, 2772, 1},\n\n      {0x10c88, 3381, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0218, 538, 1},\n\n      {0x0500, 1262, 1},\n\n      {0x1f4d, 2187, 1},\n\n      {0x01a7, 393, 1},\n\n      {0x1fa7, 244, 2},\n\n      {0x004d, 34, 1},\n\n      {0x03a7, 814, 1},\n\n      {0xa688, 2946, 1},\n\n      {0xaba7, 1613, 1},\n\n      {0x020e, 523, 1},\n\n      {0x10ca7, 3474, 1},\n\n      {0x1e6a, 1872, 1},\n\n      {0x046a, 1049, 1},\n\n      {0x016a, 324, 1},\n\n      {0x1f6a, 2208, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216c, 2328, 1},\n\n      {0x10a7, 2766, 1},\n\n      {0x01d1, 435, 1},\n\n      {0xa76a, 3081, 1},\n\n      {0x020c, 520, 1},\n\n      {0x03d1, 762, 1},\n\n      {0x00d1, 129, 1},\n\n      {0x1e68, 1869, 1},\n\n      {0x0468, 1046, 1},\n\n      {0x0168, 321, 1},\n\n      {0x1f68, 2202, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff31, 3207, 1},\n\n      {0xa66a, 2928, 1},\n\n      {0x0208, 514, 1},\n\n      {0xa768, 3078, 1},\n\n      {0x1e64, 1863, 1},\n\n      {0x0464, 1040, 1},\n\n      {0x0164, 315, 1},\n\n      {0x054d, 1418, 1},\n\n      {0x2c64, 673, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff2b, 3189, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa764, 3072, 1},\n\n      {0xa668, 2925, 1},\n\n      {0x0216, 535, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ab, 3543, 1},\n\n      {0x1e62, 1860, 1},\n\n      {0x0462, 1037, 1},\n\n      {0x0162, 312, 1},\n\n      {0x0214, 532, 1},\n\n      {0x2c62, 655, 1},\n\n      {0xa664, 2919, 1},\n\n      {0x1ed2, 2013, 1},\n\n      {0x04d2, 1193, 1},\n\n      {0xa762, 3069, 1},\n\n      {0x1fd2, 20, 3},\n\n      {0x2cd2, 2709, 1},\n\n      {0x118a9, 3537, 1},\n\n      {0x00d2, 132, 1},\n\n      {0x0206, 511, 1},\n\n      {0x10420, 3333, 1},\n\n      {0x1e20, 1760, 1},\n\n      {0x0420, 938, 1},\n\n      {0x0120, 219, 1},\n\n      {0xa662, 2916, 1},\n\n      {0x2c20, 2517, 1},\n\n      {0x1e60, 1856, 1},\n\n      {0x0460, 1034, 1},\n\n      {0x0160, 309, 1},\n\n      {0x0204, 508, 1},\n\n      {0x2c60, 2562, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24bd, 2364, 1},\n\n      {0x216a, 2322, 1},\n\n      {0xa760, 3066, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb16, 125, 2},\n\n      {0x118a7, 3531, 1},\n\n      {0x1efa, 2073, 1},\n\n      {0x04fa, 1253, 1},\n\n      {0x01fa, 493, 1},\n\n      {0x1ffa, 2262, 1},\n\n      {0xfb14, 109, 2},\n\n      {0x03fa, 887, 1},\n\n      {0xa660, 2913, 1},\n\n      {0x2168, 2316, 1},\n\n      {0x01b7, 700, 1},\n\n      {0x1fb7, 10, 3},\n\n      {0x1f6b, 2211, 1},\n\n      {0x2c6b, 2577, 1},\n\n      {0x0200, 502, 1},\n\n      {0xabb7, 1661, 1},\n\n      {0xfb06, 29, 2},\n\n      {0x1e56, 1841, 1},\n\n      {0x2164, 2304, 1},\n\n      {0x0156, 294, 1},\n\n      {0x1f56, 62, 3},\n\n      {0x0520, 1310, 1},\n\n      {0x004f, 40, 1},\n\n      {0x0056, 62, 1},\n\n      {0x10b7, 2814, 1},\n\n      {0xa756, 3051, 1},\n\n      {0xfb04, 5, 3},\n\n      {0x1e78, 1893, 1},\n\n      {0x0478, 1070, 1},\n\n      {0x0178, 168, 1},\n\n      {0x1e54, 1838, 1},\n\n      {0x2162, 2298, 1},\n\n      {0x0154, 291, 1},\n\n      {0x1f54, 57, 3},\n\n      {0xab78, 1472, 1},\n\n      {0xa656, 2898, 1},\n\n      {0x0054, 56, 1},\n\n      {0x1e52, 1835, 1},\n\n      {0xa754, 3048, 1},\n\n      {0x0152, 288, 1},\n\n      {0x1f52, 52, 3},\n\n      {0x24c9, 2400, 1},\n\n      {0x1e32, 1787, 1},\n\n      {0x0052, 49, 1},\n\n      {0x0132, 243, 1},\n\n      {0xa752, 3045, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb00, 4, 2},\n\n      {0xa654, 2895, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa732, 2997, 1},\n\n      {0x2160, 2292, 1},\n\n      {0x054f, 1424, 1},\n\n      {0x0556, 1445, 1},\n\n      {0x1e50, 1832, 1},\n\n      {0xa652, 2892, 1},\n\n      {0x0150, 285, 1},\n\n      {0x1f50, 84, 2},\n\n      {0x017b, 348, 1},\n\n      {0x1e4e, 1829, 1},\n\n      {0x0050, 43, 1},\n\n      {0x014e, 282, 1},\n\n      {0xa750, 3042, 1},\n\n      {0xab7b, 1481, 1},\n\n      {0xa77b, 3093, 1},\n\n      {0x004e, 37, 1},\n\n      {0x0554, 1439, 1},\n\n      {0xa74e, 3039, 1},\n\n      {0x1e48, 1820, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216b, 2325, 1},\n\n      {0x1f48, 2172, 1},\n\n      {0xa650, 2889, 1},\n\n      {0x0552, 1433, 1},\n\n      {0x0048, 21, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa748, 3030, 1},\n\n      {0xa64e, 2886, 1},\n\n      {0x0532, 1337, 1},\n\n      {0x1041e, 3327, 1},\n\n      {0x1e1e, 1757, 1},\n\n      {0x041e, 932, 1},\n\n      {0x011e, 216, 1},\n\n      {0x118b7, 3579, 1},\n\n      {0x2c1e, 2511, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa648, 2877, 1},\n\n      {0x1ff9, 2253, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03f9, 878, 1},\n\n      {0x0550, 1427, 1},\n\n      {0x10412, 3291, 1},\n\n      {0x1e12, 1739, 1},\n\n      {0x0412, 896, 1},\n\n      {0x0112, 198, 1},\n\n      {0x054e, 1421, 1},\n\n      {0x2c12, 2475, 1},\n\n      {0x10410, 3285, 1},\n\n      {0x1e10, 1736, 1},\n\n      {0x0410, 890, 1},\n\n      {0x0110, 195, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c10, 2469, 1},\n\n      {0x2132, 2289, 1},\n\n      {0x0548, 1403, 1},\n\n      {0x1ef8, 2070, 1},\n\n      {0x04f8, 1250, 1},\n\n      {0x01f8, 490, 1},\n\n      {0x1ff8, 2250, 1},\n\n      {0x0220, 381, 1},\n\n      {0x1ee2, 2037, 1},\n\n      {0x04e2, 1217, 1},\n\n      {0x01e2, 462, 1},\n\n      {0x1fe2, 36, 3},\n\n      {0x2ce2, 2733, 1},\n\n      {0x03e2, 857, 1},\n\n      {0x051e, 1307, 1},\n\n      {0x1ede, 2031, 1},\n\n      {0x04de, 1211, 1},\n\n      {0x01de, 456, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cde, 2727, 1},\n\n      {0x03de, 851, 1},\n\n      {0x00de, 165, 1},\n\n      {0x1f69, 2205, 1},\n\n      {0x2c69, 2574, 1},\n\n      {0x1eda, 2025, 1},\n\n      {0x04da, 1205, 1},\n\n      {0x0512, 1289, 1},\n\n      {0x1fda, 2244, 1},\n\n      {0x2cda, 2721, 1},\n\n      {0x03da, 845, 1},\n\n      {0x00da, 153, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0510, 1286, 1},\n\n      {0x1ed8, 2022, 1},\n\n      {0x04d8, 1202, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd8, 2274, 1},\n\n      {0x2cd8, 2718, 1},\n\n      {0x03d8, 842, 1},\n\n      {0x00d8, 147, 1},\n\n      {0x1ed6, 2019, 1},\n\n      {0x04d6, 1199, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd6, 76, 2},\n\n      {0x2cd6, 2715, 1},\n\n      {0x03d6, 792, 1},\n\n      {0x00d6, 144, 1},\n\n      {0x1ec8, 1998, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01c8, 421, 1},\n\n      {0x1fc8, 2232, 1},\n\n      {0x2cc8, 2694, 1},\n\n      {0xff32, 3210, 1},\n\n      {0x00c8, 102, 1},\n\n      {0x04c7, 1175, 1},\n\n      {0x01c7, 421, 1},\n\n      {0x1fc7, 15, 3},\n\n      {0x1ec0, 1986, 1},\n\n      {0x04c0, 1187, 1},\n\n      {0x00c7, 99, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cc0, 2682, 1},\n\n      {0x0179, 345, 1},\n\n      {0x00c0, 77, 1},\n\n      {0x0232, 574, 1},\n\n      {0x01b3, 402, 1},\n\n      {0x1fb3, 62, 2},\n\n      {0xab79, 1475, 1},\n\n      {0xa779, 3090, 1},\n\n      {0x10c7, 2859, 1},\n\n      {0xabb3, 1649, 1},\n\n      {0xa7b3, 3156, 1},\n\n      {0x1fa5, 234, 2},\n\n      {0x10c0, 2841, 1},\n\n      {0x03a5, 807, 1},\n      {0xffffffff, -1, 0},\n\n      {0xaba5, 1607, 1},\n\n      {0x01b1, 691, 1},\n\n      {0x10ca5, 3468, 1},\n\n      {0x10b3, 2802, 1},\n\n      {0x2169, 2319, 1},\n\n      {0x024e, 601, 1},\n\n      {0xabb1, 1643, 1},\n\n      {0xa7b1, 682, 1},\n\n      {0x10cb1, 3504, 1},\n\n      {0x10a5, 2760, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01af, 399, 1},\n\n      {0x1faf, 244, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0248, 592, 1},\n\n      {0x10b1, 2796, 1},\n\n      {0xabaf, 1637, 1},\n\n      {0x1fad, 234, 2},\n\n      {0x10caf, 3498, 1},\n\n      {0x04cd, 1184, 1},\n\n      {0x01cd, 429, 1},\n\n      {0xabad, 1631, 1},\n\n      {0xa7ad, 658, 1},\n\n      {0x10cad, 3492, 1},\n\n      {0x00cd, 117, 1},\n\n      {0x10af, 2790, 1},\n\n      {0x021e, 547, 1},\n\n      {0x1fa3, 224, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03a3, 800, 1},\n\n      {0x10ad, 2784, 1},\n\n      {0xaba3, 1601, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10ca3, 3462, 1},\n\n      {0x10cd, 2862, 1},\n\n      {0x1fa1, 214, 2},\n\n      {0x24b7, 2346, 1},\n\n      {0x03a1, 796, 1},\n\n      {0x0212, 529, 1},\n\n      {0xaba1, 1595, 1},\n\n      {0x10a3, 2754, 1},\n\n      {0x10ca1, 3456, 1},\n\n      {0x01d3, 438, 1},\n\n      {0x1fd3, 25, 3},\n\n      {0x0210, 526, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00d3, 135, 1},\n\n      {0x1e97, 34, 2},\n\n      {0x10a1, 2748, 1},\n\n      {0x0197, 649, 1},\n\n      {0x1f97, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0397, 759, 1},\n\n      {0x1041d, 3324, 1},\n\n      {0xab97, 1565, 1},\n\n      {0x041d, 929, 1},\n\n      {0x10c97, 3426, 1},\n\n      {0x1f1d, 2121, 1},\n\n      {0x2c1d, 2508, 1},\n\n      {0x1e72, 1884, 1},\n\n      {0x0472, 1061, 1},\n\n      {0x0172, 336, 1},\n\n      {0x118b3, 3567, 1},\n\n      {0x2c72, 2580, 1},\n\n      {0x0372, 712, 1},\n\n      {0x1041b, 3318, 1},\n\n      {0xab72, 1454, 1},\n\n      {0x041b, 923, 1},\n\n      {0x118a5, 3525, 1},\n\n      {0x1f1b, 2115, 1},\n\n      {0x2c1b, 2502, 1},\n\n      {0x1e70, 1881, 1},\n\n      {0x0470, 1058, 1},\n\n      {0x0170, 333, 1},\n\n      {0x118b1, 3561, 1},\n\n      {0x2c70, 610, 1},\n\n      {0x0370, 709, 1},\n\n      {0x1e46, 1817, 1},\n\n      {0xab70, 1448, 1},\n\n      {0x1e66, 1866, 1},\n\n      {0x0466, 1043, 1},\n\n      {0x0166, 318, 1},\n\n      {0x1e44, 1814, 1},\n\n      {0x0046, 15, 1},\n\n      {0x118af, 3555, 1},\n\n      {0xa746, 3027, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa766, 3075, 1},\n\n      {0x0044, 9, 1},\n\n      {0x118ad, 3549, 1},\n\n      {0xa744, 3024, 1},\n\n      {0x1e7a, 1896, 1},\n\n      {0x047a, 1073, 1},\n\n      {0x1e3a, 1799, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa646, 2874, 1},\n\n      {0x1f3a, 2154, 1},\n\n      {0xa666, 2922, 1},\n\n      {0xab7a, 1478, 1},\n\n      {0x118a3, 3519, 1},\n\n      {0xa644, 2871, 1},\n\n      {0xa73a, 3009, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1ef4, 2064, 1},\n\n      {0x04f4, 1244, 1},\n\n      {0x01f4, 487, 1},\n\n      {0x1ff4, 101, 2},\n\n      {0x118a1, 3513, 1},\n\n      {0x03f4, 762, 1},\n\n      {0x1eec, 2052, 1},\n\n      {0x04ec, 1232, 1},\n\n      {0x01ec, 477, 1},\n\n      {0x1fec, 2286, 1},\n\n      {0x0546, 1397, 1},\n\n      {0x03ec, 872, 1},\n      {0xffffffff, -1, 0},\n\n      {0x013f, 261, 1},\n\n      {0x1f3f, 2169, 1},\n\n      {0x0544, 1391, 1},\n\n      {0x1eea, 2049, 1},\n\n      {0x04ea, 1229, 1},\n\n      {0x01ea, 474, 1},\n\n      {0x1fea, 2256, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03ea, 869, 1},\n\n      {0x1ee8, 2046, 1},\n\n      {0x04e8, 1226, 1},\n\n      {0x01e8, 471, 1},\n\n      {0x1fe8, 2280, 1},\n\n      {0x053a, 1361, 1},\n\n      {0x03e8, 866, 1},\n\n      {0x1ee6, 2043, 1},\n\n      {0x04e6, 1223, 1},\n\n      {0x01e6, 468, 1},\n\n      {0x1fe6, 88, 2},\n\n      {0x1f4b, 2181, 1},\n\n      {0x03e6, 863, 1},\n\n      {0x1e5e, 1853, 1},\n\n      {0x004b, 27, 1},\n\n      {0x015e, 306, 1},\n\n      {0x2166, 2310, 1},\n\n      {0x1ee4, 2040, 1},\n\n      {0x04e4, 1220, 1},\n\n      {0x01e4, 465, 1},\n\n      {0x1fe4, 80, 2},\n\n      {0xa75e, 3063, 1},\n\n      {0x03e4, 860, 1},\n\n      {0x1ee0, 2034, 1},\n\n      {0x04e0, 1214, 1},\n\n      {0x01e0, 459, 1},\n\n      {0x053f, 1376, 1},\n\n      {0x2ce0, 2730, 1},\n\n      {0x03e0, 854, 1},\n\n      {0x1edc, 2028, 1},\n\n      {0x04dc, 1208, 1},\n\n      {0xa65e, 2910, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cdc, 2724, 1},\n\n      {0x03dc, 848, 1},\n\n      {0x00dc, 159, 1},\n\n      {0x1ed0, 2010, 1},\n\n      {0x04d0, 1190, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x2cd0, 2706, 1},\n\n      {0x03d0, 742, 1},\n\n      {0x00d0, 126, 1},\n\n      {0x1ecc, 2004, 1},\n\n      {0x054b, 1412, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fcc, 71, 2},\n\n      {0x2ccc, 2700, 1},\n\n      {0x1ec6, 1995, 1},\n\n      {0x00cc, 114, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fc6, 67, 2},\n\n      {0x2cc6, 2691, 1},\n\n      {0x24c8, 2397, 1},\n\n      {0x00c6, 96, 1},\n\n      {0x04c5, 1172, 1},\n\n      {0x01c5, 417, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fbb, 2229, 1},\n\n      {0x24c7, 2394, 1},\n\n      {0x00c5, 92, 1},\n\n      {0x1fb9, 2271, 1},\n\n      {0xabbb, 1673, 1},\n\n      {0x24c0, 2373, 1},\n\n      {0x04c3, 1169, 1},\n\n      {0xabb9, 1667, 1},\n\n      {0x1fc3, 71, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x00c3, 86, 1},\n\n      {0x10c5, 2856, 1},\n\n      {0x10bb, 2826, 1},\n\n      {0x1ed4, 2016, 1},\n\n      {0x04d4, 1196, 1},\n\n      {0x10b9, 2820, 1},\n\n      {0x13fc, 1700, 1},\n\n      {0x2cd4, 2712, 1},\n\n      {0x0246, 589, 1},\n\n      {0x00d4, 138, 1},\n\n      {0x10c3, 2850, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff3a, 3234, 1},\n\n      {0x0244, 688, 1},\n\n      {0x019f, 670, 1},\n\n      {0x1f9f, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x039f, 789, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab9f, 1589, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c9f, 3450, 1},\n\n      {0x019d, 667, 1},\n\n      {0x1f9d, 194, 2},\n\n      {0x023a, 2565, 1},\n\n      {0x039d, 783, 1},\n\n      {0x1e5a, 1847, 1},\n\n      {0xab9d, 1583, 1},\n\n      {0x015a, 300, 1},\n\n      {0x10c9d, 3444, 1},\n\n      {0x1e9b, 1856, 1},\n\n      {0x24cd, 2412, 1},\n\n      {0x005a, 74, 1},\n\n      {0x1f9b, 184, 2},\n\n      {0xa75a, 3057, 1},\n\n      {0x039b, 776, 1},\n\n      {0x1ece, 2007, 1},\n\n      {0xab9b, 1577, 1},\n\n      {0x1e99, 42, 2},\n\n      {0x10c9b, 3438, 1},\n\n      {0x2cce, 2703, 1},\n\n      {0x1f99, 174, 2},\n\n      {0x00ce, 120, 1},\n\n      {0x0399, 767, 1},\n\n      {0xa65a, 2904, 1},\n\n      {0xab99, 1571, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c99, 3432, 1},\n\n      {0x0193, 634, 1},\n\n      {0x1f93, 184, 2},\n\n      {0x1e58, 1844, 1},\n\n      {0x0393, 746, 1},\n\n      {0x0158, 297, 1},\n\n      {0xab93, 1553, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c93, 3414, 1},\n\n      {0x0058, 68, 1},\n\n      {0x042d, 977, 1},\n\n      {0xa758, 3054, 1},\n\n      {0x1f2d, 2139, 1},\n\n      {0x2c2d, 2556, 1},\n\n      {0x118bb, 3591, 1},\n\n      {0x0191, 369, 1},\n\n      {0x1f91, 174, 2},\n\n      {0x118b9, 3585, 1},\n\n      {0x0391, 739, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab91, 1547, 1},\n\n      {0xa658, 2901, 1},\n\n      {0x10c91, 3408, 1},\n\n      {0x018f, 625, 1},\n\n      {0x1f8f, 164, 2},\n      {0xffffffff, -1, 0},\n\n      {0x038f, 836, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8f, 1541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c8f, 3402, 1},\n\n      {0x018b, 366, 1},\n\n      {0x1f8b, 144, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0187, 363, 1},\n\n      {0x1f87, 164, 2},\n\n      {0xab8b, 1529, 1},\n\n      {0xa78b, 3111, 1},\n\n      {0x10c8b, 3390, 1},\n\n      {0xab87, 1517, 1},\n\n      {0x04c1, 1166, 1},\n\n      {0x10c87, 3378, 1},\n\n      {0x1e7e, 1902, 1},\n\n      {0x047e, 1079, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c1, 80, 1},\n\n      {0x2c7e, 580, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab7e, 1490, 1},\n\n      {0xa77e, 3096, 1},\n\n      {0x1e76, 1890, 1},\n\n      {0x0476, 1067, 1},\n\n      {0x0176, 342, 1},\n\n      {0x1e42, 1811, 1},\n\n      {0x10c1, 2844, 1},\n\n      {0x0376, 715, 1},\n\n      {0x1e36, 1793, 1},\n\n      {0xab76, 1466, 1},\n\n      {0x0136, 249, 1},\n\n      {0x0042, 3, 1},\n\n      {0x1e3e, 1805, 1},\n\n      {0xa742, 3021, 1},\n\n      {0x1e38, 1796, 1},\n\n      {0x1f3e, 2166, 1},\n\n      {0xa736, 3003, 1},\n\n      {0x1f38, 2148, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0587, 105, 2},\n\n      {0xa73e, 3015, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa738, 3006, 1},\n\n      {0xa642, 2868, 1},\n\n      {0x1e5c, 1850, 1},\n\n      {0x1e34, 1790, 1},\n\n      {0x015c, 303, 1},\n\n      {0x0134, 246, 1},\n\n      {0x1ef6, 2067, 1},\n\n      {0x04f6, 1247, 1},\n\n      {0x01f6, 372, 1},\n\n      {0x1ff6, 92, 2},\n\n      {0xa75c, 3060, 1},\n\n      {0xa734, 3000, 1},\n\n      {0x1ef0, 2058, 1},\n\n      {0x04f0, 1238, 1},\n\n      {0x01f0, 20, 2},\n      {0xffffffff, -1, 0},\n\n      {0x1e30, 1784, 1},\n\n      {0x03f0, 772, 1},\n\n      {0x0130, 261, 2},\n\n      {0x0542, 1385, 1},\n\n      {0xa65c, 2907, 1},\n\n      {0x1f83, 144, 2},\n\n      {0x0536, 1349, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab83, 1505, 1},\n\n      {0x053e, 1373, 1},\n\n      {0x10c83, 3366, 1},\n\n      {0x0538, 1355, 1},\n\n      {0x1eee, 2055, 1},\n\n      {0x04ee, 1235, 1},\n\n      {0x01ee, 480, 1},\n\n      {0x1f8d, 154, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03ee, 875, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8d, 1535, 1},\n\n      {0xa78d, 643, 1},\n\n      {0x10c8d, 3396, 1},\n\n      {0x0534, 1343, 1},\n\n      {0x0181, 613, 1},\n\n      {0x1f81, 134, 2},\n\n      {0x013d, 258, 1},\n\n      {0x1f3d, 2163, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab81, 1499, 1},\n\n      {0x017f, 52, 1},\n\n      {0x10c81, 3360, 1},\n\n      {0x2c7f, 583, 1},\n\n      {0x037f, 881, 1},\n\n      {0xff2d, 3195, 1},\n\n      {0xab7f, 1493, 1},\n\n      {0x1e74, 1887, 1},\n\n      {0x0474, 1064, 1},\n\n      {0x0174, 339, 1},\n\n      {0x1e3c, 1802, 1},\n\n      {0x0149, 46, 2},\n\n      {0x1f49, 2175, 1},\n\n      {0x1f3c, 2160, 1},\n\n      {0xab74, 1460, 1},\n\n      {0x0049, 3606, 1},\n\n      {0x0143, 267, 1},\n\n      {0x24cc, 2409, 1},\n\n      {0xa73c, 3012, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0043, 6, 1},\n\n      {0x0141, 264, 1},\n\n      {0x24c6, 2391, 1},\n\n      {0x013b, 255, 1},\n\n      {0x1f3b, 2157, 1},\n\n      {0x0041, 0, 1},\n\n      {0x0139, 252, 1},\n\n      {0x1f39, 2151, 1},\n\n      {0x24c5, 2388, 1},\n\n      {0x24bb, 2358, 1},\n\n      {0x13fa, 1694, 1},\n\n      {0x053d, 1370, 1},\n\n      {0x24b9, 2352, 1},\n\n      {0x0429, 965, 1},\n\n      {0x2183, 2340, 1},\n\n      {0x1f29, 2127, 1},\n\n      {0x2c29, 2544, 1},\n\n      {0x24c3, 2382, 1},\n\n      {0x10427, 3354, 1},\n\n      {0x10425, 3348, 1},\n\n      {0x0427, 959, 1},\n\n      {0x0425, 953, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c27, 2538, 1},\n\n      {0x2c25, 2532, 1},\n\n      {0x0549, 1406, 1},\n\n      {0x053c, 1367, 1},\n\n      {0x10423, 3342, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0423, 947, 1},\n\n      {0x0543, 1388, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c23, 2526, 1},\n\n      {0xff36, 3222, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0541, 1382, 1},\n\n      {0x10421, 3336, 1},\n\n      {0x053b, 1364, 1},\n\n      {0x0421, 941, 1},\n\n      {0xff38, 3228, 1},\n\n      {0x0539, 1358, 1},\n\n      {0x2c21, 2520, 1},\n\n      {0x10419, 3312, 1},\n\n      {0x10417, 3306, 1},\n\n      {0x0419, 917, 1},\n\n      {0x0417, 911, 1},\n\n      {0x1f19, 2109, 1},\n\n      {0x2c19, 2496, 1},\n\n      {0x2c17, 2490, 1},\n\n      {0x023e, 2568, 1},\n\n      {0xff34, 3216, 1},\n\n      {0x10415, 3300, 1},\n\n      {0x10413, 3294, 1},\n\n      {0x0415, 905, 1},\n\n      {0x0413, 899, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c15, 2484, 1},\n\n      {0x2c13, 2478, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ce, 2415, 1},\n\n      {0x1040f, 3282, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040f, 1031, 1},\n\n      {0xff30, 3204, 1},\n\n      {0x1f0f, 2103, 1},\n\n      {0x2c0f, 2466, 1},\n\n      {0x1040d, 3276, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040d, 1025, 1},\n\n      {0x0147, 273, 1},\n\n      {0x1f0d, 2097, 1},\n\n      {0x2c0d, 2460, 1},\n\n      {0x1040b, 3270, 1},\n\n      {0x0047, 18, 1},\n\n      {0x040b, 1019, 1},\n\n      {0x0230, 571, 1},\n\n      {0x1f0b, 2091, 1},\n\n      {0x2c0b, 2454, 1},\n\n      {0x10409, 3264, 1},\n\n      {0x10405, 3252, 1},\n\n      {0x0409, 1013, 1},\n\n      {0x0405, 1001, 1},\n\n      {0x1f09, 2085, 1},\n\n      {0x2c09, 2448, 1},\n\n      {0x2c05, 2436, 1},\n\n      {0x10403, 3246, 1},\n\n      {0x10401, 3240, 1},\n\n      {0x0403, 995, 1},\n\n      {0x0401, 989, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c03, 2430, 1},\n\n      {0x2c01, 2424, 1},\n\n      {0x13f9, 1691, 1},\n\n      {0x042f, 983, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1f2f, 2145, 1},\n\n      {0x1041f, 3330, 1},\n      {0xffffffff, -1, 0},\n\n      {0x041f, 935, 1},\n\n      {0x023d, 378, 1},\n\n      {0x10411, 3288, 1},\n\n      {0x2c1f, 2514, 1},\n\n      {0x0411, 893, 1},\n\n      {0x0547, 1400, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c11, 2472, 1},\n\n      {0x10407, 3258, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0407, 1007, 1},\n\n      {0x24c1, 2376, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c07, 2442, 1},\n      {0xffffffff, -1, 0},\n\n      {0x13f8, 1688, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff39, 3231, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0243, 354, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x0241, 586, 1},\n\n      {0xff29, 3183, 1},\n\n      {0x023b, 577, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff27, 3177, 1},\n\n      {0xff25, 3171, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff23, 3165, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff21, 3159, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb17, 117, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff2f, 3201, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb15, 113, 2},\n\n      {0xfb13, 121, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb05, 29, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb03, 0, 3},\n\n      {0xfb01, 8, 2}\n    };\n\n  if (0 == 0)\n    {\n      int key = hash(&code);\n\n      if (key <= MAX_HASH_VALUE && key >= 0)\n        {\n          OnigCodePoint gcode = wordlist[key].code;\n\n          if (code == gcode && wordlist[key].index >= 0)\n            return &wordlist[key];\n        }\n    }\n  return 0;\n}", "commit_link": "github.com/kkos/oniguruma/commit/166a6c3999bf06b4de0ab4ce6b088a468cc4029f", "file_name": "src/unicode_unfold_key.c", "vul_type": "cwe-787", "description": "Write a function in C that searches for a Unicode code point in a static array using a hash lookup."}
{"func_name": "regulator_ena_gpio_free", "func_src_before": "static void regulator_ena_gpio_free(struct regulator_dev *rdev)\n{\n\tstruct regulator_enable_gpio *pin, *n;\n\n\tif (!rdev->ena_pin)\n\t\treturn;\n\n\t/* Free the GPIO only in case of no use */\n\tlist_for_each_entry_safe(pin, n, &regulator_ena_gpio_list, list) {\n\t\tif (pin->gpiod == rdev->ena_pin->gpiod) {\n\t\t\tif (pin->request_count <= 1) {\n\t\t\t\tpin->request_count = 0;\n\t\t\t\tgpiod_put(pin->gpiod);\n\t\t\t\tlist_del(&pin->list);\n\t\t\t\tkfree(pin);\n\t\t\t} else {\n\t\t\t\tpin->request_count--;\n\t\t\t}\n\t\t}\n\t}\n}", "func_src_after": "static void regulator_ena_gpio_free(struct regulator_dev *rdev)\n{\n\tstruct regulator_enable_gpio *pin, *n;\n\n\tif (!rdev->ena_pin)\n\t\treturn;\n\n\t/* Free the GPIO only in case of no use */\n\tlist_for_each_entry_safe(pin, n, &regulator_ena_gpio_list, list) {\n\t\tif (pin->gpiod == rdev->ena_pin->gpiod) {\n\t\t\tif (pin->request_count <= 1) {\n\t\t\t\tpin->request_count = 0;\n\t\t\t\tgpiod_put(pin->gpiod);\n\t\t\t\tlist_del(&pin->list);\n\t\t\t\tkfree(pin);\n\t\t\t\trdev->ena_pin = NULL;\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpin->request_count--;\n\t\t\t}\n\t\t}\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/60a2362f769cf549dc466134efe71c8bf9fbaaba", "file_name": "drivers/regulator/core.c", "vul_type": "cwe-416", "description": "Write a C function to release a GPIO pin associated with a regulator device when it's no longer in use."}
{"func_name": "_gd2GetHeader", "func_src_before": "static int _gd2GetHeader(gdIOCtxPtr in, int *sx, int *sy, int *cs, int *vers, int *fmt, int *ncx, int *ncy, t_chunk_info ** chunkIdx)\n{\n\tint i;\n\tint ch;\n\tchar id[5];\n\tt_chunk_info *cidx;\n\tint sidx;\n\tint nc;\n\n\tGD2_DBG(php_gd_error(\"Reading gd2 header info\"));\n\n\tfor (i = 0; i < 4; i++) {\n\t\tch = gdGetC(in);\n\t\tif (ch == EOF) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tid[i] = ch;\n\t}\n\tid[4] = 0;\n\n\tGD2_DBG(php_gd_error(\"Got file code: %s\", id));\n\n\t/* Equiv. of 'magick'.  */\n\tif (strcmp(id, GD2_ID) != 0) {\n\t\tGD2_DBG(php_gd_error(\"Not a valid gd2 file\"));\n\t\tgoto fail1;\n\t}\n\n\t/* Version */\n\tif (gdGetWord(vers, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Version: %d\", *vers));\n\n\tif ((*vers != 1) && (*vers != 2)) {\n\t\tGD2_DBG(php_gd_error(\"Bad version: %d\", *vers));\n\t\tgoto fail1;\n\t}\n\n\t/* Image Size */\n\tif (!gdGetWord(sx, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get x-size\"));\n\t\tgoto fail1;\n\t}\n\tif (!gdGetWord(sy, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get y-size\"));\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Image is %dx%d\", *sx, *sy));\n\n\t/* Chunk Size (pixels, not bytes!) */\n\tif (gdGetWord(cs, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"ChunkSize: %d\", *cs));\n\n\tif ((*cs < GD2_CHUNKSIZE_MIN) || (*cs > GD2_CHUNKSIZE_MAX)) {\n\t\tGD2_DBG(php_gd_error(\"Bad chunk size: %d\", *cs));\n\t\tgoto fail1;\n\t}\n\n\t/* Data Format */\n\tif (gdGetWord(fmt, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Format: %d\", *fmt));\n\n\tif ((*fmt != GD2_FMT_RAW) && (*fmt != GD2_FMT_COMPRESSED) && (*fmt != GD2_FMT_TRUECOLOR_RAW) && (*fmt != GD2_FMT_TRUECOLOR_COMPRESSED)) {\n\t\tGD2_DBG(php_gd_error(\"Bad data format: %d\", *fmt));\n\t\tgoto fail1;\n\t}\n\n\t/* # of chunks wide */\n\tif (gdGetWord(ncx, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks Wide\", *ncx));\n\n\t/* # of chunks high */\n\tif (gdGetWord(ncy, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks vertically\", *ncy));\n\n\tif (gd2_compressed(*fmt)) {\n\t\tnc = (*ncx) * (*ncy);\n\t\tGD2_DBG(php_gd_error(\"Reading %d chunk index entries\", nc));\n\t\tsidx = sizeof(t_chunk_info) * nc;\n\t\tif (sidx <= 0) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tcidx = gdCalloc(sidx, 1);\n\t\tfor (i = 0; i < nc; i++) {\n\t\t\tif (gdGetInt(&cidx[i].offset, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (gdGetInt(&cidx[i].size, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (cidx[i].offset < 0 || cidx[i].size < 0) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t}\n\t\t*chunkIdx = cidx;\n\t}\n\n\tGD2_DBG(php_gd_error(\"gd2 header complete\"));\n\n\treturn 1;\n\nfail1:\n\treturn 0;\n}", "func_src_after": "static int _gd2GetHeader(gdIOCtxPtr in, int *sx, int *sy, int *cs, int *vers, int *fmt, int *ncx, int *ncy, t_chunk_info ** chunkIdx)\n{\n\tint i;\n\tint ch;\n\tchar id[5];\n\tt_chunk_info *cidx;\n\tint sidx;\n\tint nc;\n\n\tGD2_DBG(php_gd_error(\"Reading gd2 header info\"));\n\n\tfor (i = 0; i < 4; i++) {\n\t\tch = gdGetC(in);\n\t\tif (ch == EOF) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tid[i] = ch;\n\t}\n\tid[4] = 0;\n\n\tGD2_DBG(php_gd_error(\"Got file code: %s\", id));\n\n\t/* Equiv. of 'magick'.  */\n\tif (strcmp(id, GD2_ID) != 0) {\n\t\tGD2_DBG(php_gd_error(\"Not a valid gd2 file\"));\n\t\tgoto fail1;\n\t}\n\n\t/* Version */\n\tif (gdGetWord(vers, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Version: %d\", *vers));\n\n\tif ((*vers != 1) && (*vers != 2)) {\n\t\tGD2_DBG(php_gd_error(\"Bad version: %d\", *vers));\n\t\tgoto fail1;\n\t}\n\n\t/* Image Size */\n\tif (!gdGetWord(sx, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get x-size\"));\n\t\tgoto fail1;\n\t}\n\tif (!gdGetWord(sy, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get y-size\"));\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Image is %dx%d\", *sx, *sy));\n\n\t/* Chunk Size (pixels, not bytes!) */\n\tif (gdGetWord(cs, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"ChunkSize: %d\", *cs));\n\n\tif ((*cs < GD2_CHUNKSIZE_MIN) || (*cs > GD2_CHUNKSIZE_MAX)) {\n\t\tGD2_DBG(php_gd_error(\"Bad chunk size: %d\", *cs));\n\t\tgoto fail1;\n\t}\n\n\t/* Data Format */\n\tif (gdGetWord(fmt, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Format: %d\", *fmt));\n\n\tif ((*fmt != GD2_FMT_RAW) && (*fmt != GD2_FMT_COMPRESSED) && (*fmt != GD2_FMT_TRUECOLOR_RAW) && (*fmt != GD2_FMT_TRUECOLOR_COMPRESSED)) {\n\t\tGD2_DBG(php_gd_error(\"Bad data format: %d\", *fmt));\n\t\tgoto fail1;\n\t}\n\n\t/* # of chunks wide */\n\tif (gdGetWord(ncx, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks Wide\", *ncx));\n\n\t/* # of chunks high */\n\tif (gdGetWord(ncy, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks vertically\", *ncy));\n\n\tif (gd2_compressed(*fmt)) {\n\t\tnc = (*ncx) * (*ncy);\n\t\tGD2_DBG(php_gd_error(\"Reading %d chunk index entries\", nc));\n\t\tif (overflow2(sidx, nc)) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tsidx = sizeof(t_chunk_info) * nc;\n\t\tif (sidx <= 0) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tcidx = gdCalloc(sidx, 1);\n\t\tif (cidx == NULL) {\n\t\t\tgoto fail1;\n\t\t}\n\n\t\tfor (i = 0; i < nc; i++) {\n\t\t\tif (gdGetInt(&cidx[i].offset, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (gdGetInt(&cidx[i].size, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (cidx[i].offset < 0 || cidx[i].size < 0) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t}\n\t\t*chunkIdx = cidx;\n\t}\n\n\tGD2_DBG(php_gd_error(\"gd2 header complete\"));\n\n\treturn 1;\n\nfail1:\n\treturn 0;\n}", "commit_link": "github.com/php/php-src/commit/7722455726bec8c53458a32851d2a87982cf0eac", "file_name": "ext/gd/libgd/gd_gd2.c", "vul_type": "cwe-190", "description": "Write a C function to read and validate the header of a GD2 image file."}
{"func_name": "compact_upto_test", "func_src_before": "void compact_upto_test(bool multi_kv)\n{\n    TEST_INIT();\n\n    memleak_start();\n\n    int i, r;\n    int n = 20;\n    int num_kvs = 4; // keep this the same as number of fdb_commit() calls\n    fdb_file_handle *dbfile;\n    fdb_kvs_handle **db = alca(fdb_kvs_handle *, num_kvs);\n    fdb_doc **doc = alca(fdb_doc*, n);\n    fdb_status status;\n    fdb_snapshot_info_t *markers;\n    fdb_kvs_handle *snapshot;\n    uint64_t num_markers;\n\n    char keybuf[256], metabuf[256], bodybuf[256];\n    char kv_name[8];\n    char compact_filename[16];\n\n    fdb_config fconfig = fdb_get_default_config();\n    fdb_kvs_config kvs_config = fdb_get_default_kvs_config();\n    fconfig.buffercache_size = 0;\n    fconfig.wal_threshold = 1024;\n    fconfig.flags = FDB_OPEN_FLAG_CREATE;\n    fconfig.compaction_threshold = 0;\n    fconfig.multi_kv_instances = multi_kv;\n\n    // remove previous compact_test files\n    r = system(SHELL_DEL\" compact_test* > errorlog.txt\");\n    (void)r;\n\n    // open db\n    fdb_open(&dbfile, \"./compact_test1\", &fconfig);\n    if (multi_kv) {\n        for (r = 0; r < num_kvs; ++r) {\n            sprintf(kv_name, \"kv%d\", r);\n            fdb_kvs_open(dbfile, &db[r], kv_name, &kvs_config);\n        }\n    } else {\n        num_kvs = 1;\n        fdb_kvs_open_default(dbfile, &db[0], &kvs_config);\n    }\n\n   // ------- Setup test ----------------------------------\n   // insert documents of 0-4\n    for (i=0; i<n/4; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n\n    // commit with a manual WAL flush (these docs go into HB-trie)\n    fdb_commit(dbfile, FDB_COMMIT_MANUAL_WAL_FLUSH);\n\n    // insert documents from 5 - 9\n    for (; i < n/2; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n\n    // commit again without a WAL flush\n    fdb_commit(dbfile, FDB_COMMIT_NORMAL);\n\n    // insert documents from 10-14 into HB-trie\n    for (; i < (n/2 + n/4); i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n    // manually flush WAL & commit\n    fdb_commit(dbfile, FDB_COMMIT_MANUAL_WAL_FLUSH);\n\n    // insert documents from 15 - 19 on file into the WAL\n    for (; i < n; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n    // commit without a WAL flush\n    fdb_commit(dbfile, FDB_COMMIT_NORMAL);\n\n    for (r = 0; r < num_kvs; ++r) {\n        status = fdb_set_log_callback(db[r], logCallbackFunc,\n                                      (void *) \"compact_upto_test\");\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n    }\n\n    status = fdb_get_all_snap_markers(dbfile, &markers, &num_markers);\n    TEST_CHK(status == FDB_RESULT_SUCCESS);\n\n    if (!multi_kv) {\n        TEST_CHK(num_markers == 4);\n        for (r = 0; r < num_markers; ++r) {\n            TEST_CHK(markers[r].num_kvs_markers == 1);\n            TEST_CHK(markers[r].kvs_markers[0].seqnum == (n - r*5));\n        }\n        r = 1; // Test compacting upto sequence number 15\n        sprintf(compact_filename, \"compact_test_compact%d\", r);\n        status = fdb_compact_upto(dbfile, compact_filename,\n                                  markers[r].marker);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // create a snapshot\n        status = fdb_snapshot_open(db[0], &snapshot,\n                                   markers[r].kvs_markers[0].seqnum);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // close snapshot\n        fdb_kvs_close(snapshot);\n    } else {\n        TEST_CHK(num_markers == 8);\n        for (r = 0; r < num_kvs; ++r) {\n            TEST_CHK(markers[r].num_kvs_markers == num_kvs);\n            for (i = 0; i < num_kvs; ++i) {\n                TEST_CHK(markers[r].kvs_markers[i].seqnum == (n - r*5));\n                sprintf(kv_name, \"kv%d\", i);\n                TEST_CMP(markers[r].kvs_markers[i].kv_store_name, kv_name, 3);\n            }\n        }\n        i = r = 1;\n        sprintf(compact_filename, \"compact_test_compact%d\", i);\n        status = fdb_compact_upto(dbfile, compact_filename,\n                markers[i].marker);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // create a snapshot\n        status = fdb_snapshot_open(db[r], &snapshot,\n                markers[i].kvs_markers[r].seqnum);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // close snapshot\n        fdb_kvs_close(snapshot);\n    }\n\n    status = fdb_free_snap_markers(markers, num_markers);\n    TEST_CHK(status == FDB_RESULT_SUCCESS);\n\n    // close db file\n    fdb_close(dbfile);\n\n    // free all documents\n    for (i=0;i<n;++i){\n        fdb_doc_free(doc[i]);\n    }\n\n    // free all resources\n    fdb_shutdown();\n\n    memleak_end();\n\n    sprintf(bodybuf, \"compact upto marker in file test %s\", multi_kv ?\n                                                           \"multiple kv mode:\"\n                                                         : \"single kv mode:\");\n    TEST_RESULT(bodybuf);\n}", "func_src_after": "void compact_upto_test(bool multi_kv)\n{\n    TEST_INIT();\n\n    memleak_start();\n\n    int i, r;\n    int n = 20;\n    int num_kvs = 4; // keep this the same as number of fdb_commit() calls\n    fdb_file_handle *dbfile;\n    fdb_kvs_handle **db = alca(fdb_kvs_handle *, num_kvs);\n    fdb_doc **doc = alca(fdb_doc*, n);\n    fdb_status status;\n    fdb_snapshot_info_t *markers;\n    fdb_kvs_handle *snapshot;\n    uint64_t num_markers;\n\n    char keybuf[256], metabuf[256], bodybuf[256];\n    char kv_name[8];\n    char compact_filename[32];\n\n    fdb_config fconfig = fdb_get_default_config();\n    fdb_kvs_config kvs_config = fdb_get_default_kvs_config();\n    fconfig.buffercache_size = 0;\n    fconfig.wal_threshold = 1024;\n    fconfig.flags = FDB_OPEN_FLAG_CREATE;\n    fconfig.compaction_threshold = 0;\n    fconfig.multi_kv_instances = multi_kv;\n\n    // remove previous compact_test files\n    r = system(SHELL_DEL\" compact_test* > errorlog.txt\");\n    (void)r;\n\n    // open db\n    fdb_open(&dbfile, \"./compact_test1\", &fconfig);\n    if (multi_kv) {\n        for (r = 0; r < num_kvs; ++r) {\n            sprintf(kv_name, \"kv%d\", r);\n            fdb_kvs_open(dbfile, &db[r], kv_name, &kvs_config);\n        }\n    } else {\n        num_kvs = 1;\n        fdb_kvs_open_default(dbfile, &db[0], &kvs_config);\n    }\n\n   // ------- Setup test ----------------------------------\n   // insert documents of 0-4\n    for (i=0; i<n/4; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n\n    // commit with a manual WAL flush (these docs go into HB-trie)\n    fdb_commit(dbfile, FDB_COMMIT_MANUAL_WAL_FLUSH);\n\n    // insert documents from 5 - 9\n    for (; i < n/2; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n\n    // commit again without a WAL flush\n    fdb_commit(dbfile, FDB_COMMIT_NORMAL);\n\n    // insert documents from 10-14 into HB-trie\n    for (; i < (n/2 + n/4); i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n    // manually flush WAL & commit\n    fdb_commit(dbfile, FDB_COMMIT_MANUAL_WAL_FLUSH);\n\n    // insert documents from 15 - 19 on file into the WAL\n    for (; i < n; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n    // commit without a WAL flush\n    fdb_commit(dbfile, FDB_COMMIT_NORMAL);\n\n    for (r = 0; r < num_kvs; ++r) {\n        status = fdb_set_log_callback(db[r], logCallbackFunc,\n                                      (void *) \"compact_upto_test\");\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n    }\n\n    status = fdb_get_all_snap_markers(dbfile, &markers, &num_markers);\n    TEST_CHK(status == FDB_RESULT_SUCCESS);\n\n    if (!multi_kv) {\n        TEST_CHK(num_markers == 4);\n        for (r = 0; r < num_markers; ++r) {\n            TEST_CHK(markers[r].num_kvs_markers == 1);\n            TEST_CHK(markers[r].kvs_markers[0].seqnum == (n - r*5));\n        }\n        r = 1; // Test compacting upto sequence number 15\n        sprintf(compact_filename, \"compact_test_compact%d\", r);\n        status = fdb_compact_upto(dbfile, compact_filename,\n                                  markers[r].marker);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // create a snapshot\n        status = fdb_snapshot_open(db[0], &snapshot,\n                                   markers[r].kvs_markers[0].seqnum);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // close snapshot\n        fdb_kvs_close(snapshot);\n    } else {\n        TEST_CHK(num_markers == 8);\n        for (r = 0; r < num_kvs; ++r) {\n            TEST_CHK(markers[r].num_kvs_markers == num_kvs);\n            for (i = 0; i < num_kvs; ++i) {\n                TEST_CHK(markers[r].kvs_markers[i].seqnum == (n - r*5));\n                sprintf(kv_name, \"kv%d\", i);\n                TEST_CMP(markers[r].kvs_markers[i].kv_store_name, kv_name, 3);\n            }\n        }\n        i = r = 1;\n        sprintf(compact_filename, \"compact_test_compact%d\", i);\n        status = fdb_compact_upto(dbfile, compact_filename,\n                markers[i].marker);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // create a snapshot\n        status = fdb_snapshot_open(db[r], &snapshot,\n                markers[i].kvs_markers[r].seqnum);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // close snapshot\n        fdb_kvs_close(snapshot);\n    }\n\n    status = fdb_free_snap_markers(markers, num_markers);\n    TEST_CHK(status == FDB_RESULT_SUCCESS);\n\n    // close db file\n    fdb_close(dbfile);\n\n    // free all documents\n    for (i=0;i<n;++i){\n        fdb_doc_free(doc[i]);\n    }\n\n    // free all resources\n    fdb_shutdown();\n\n    memleak_end();\n\n    sprintf(bodybuf, \"compact upto marker in file test %s\", multi_kv ?\n                                                           \"multiple kv mode:\"\n                                                         : \"single kv mode:\");\n    TEST_RESULT(bodybuf);\n}", "line_changes": {"deleted": [{"line_no": 20, "char_start": 497, "char_end": 528, "line": "    char compact_filename[16];\n"}], "added": [{"line_no": 20, "char_start": 497, "char_end": 528, "line": "    char compact_filename[32];\n"}]}, "char_changes": {"deleted": [{"char_start": 523, "char_end": 525, "chars": "16"}], "added": [{"char_start": 523, "char_end": 525, "chars": "32"}]}, "commit_link": "github.com/hisundar/forestdb/commit/1df4c96057712be6ccf6614419ebcb2a01bb87f7", "file_name": "compact_functional_test.cc", "vul_type": "cwe-787", "commit_msg": "fix buffer overflow in compact_functional_test\n\nChange-Id: I1d4f79f8abfc96eaf546d05800a2eccdf0c828f6", "parent_commit": "6ef65b54f9324000de89e11b8a8bd688393a380b", "description": "Write a C function named `compact_upto_test` that tests the compaction of a database up to a certain point using the ForestDB engine."}
{"func_name": "autodetect_recv_bandwidth_measure_results", "func_src_before": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "func_src_after": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn -1;\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/f5e73cc7c9cd973b516a618da877c87b80950b65", "file_name": "libfreerdp/core/autodetect.c", "vul_type": "cwe-125", "description": "Write a C function to process bandwidth measurement results in an RDP session."}
{"func_name": "userLogin", "func_src_before": "    def userLogin(self):\n\n        sqlName=\"select count(*) from users where name='%s' and \\\n                password='%s';\"%(self.name,self.password)\n        checkName=sql.queryDB(self.conn,sqlName)\n\n        result=checkName[0][0]\n        if result == 0:\n            self.clean()\n            return False\n        else:\n            return True", "func_src_after": "    def userLogin(self):\n\n        sqlName=\"select count(*) from users where name=%s and password=%s;\"\n        params = [self.name,self.password]\n        checkName=sql.queryDB(self.conn,sqlName,params)\n        result=checkName[0][0]\n        if result == 0:\n            self.clean()\n            return False\n        else:\n            return True", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `userLogin` that checks if a user's name and password exist in the database and returns a boolean accordingly."}
{"func_name": "ring_buffer_resize", "func_src_before": "int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tsize = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\tsize *= BUF_PAGE_SIZE;\n\n\t/* we need a minimum of two pages */\n\tif (size < BUF_PAGE_SIZE * 2)\n\t\tsize = BUF_PAGE_SIZE * 2;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been intitialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}", "func_src_after": "int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/* we need a minimum of two pages */\n\tif (nr_pages < 2)\n\t\tnr_pages = 2;\n\n\tsize = nr_pages * BUF_PAGE_SIZE;\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been intitialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/59643d1535eb220668692a5359de22545af579f6", "file_name": "kernel/trace/ring_buffer.c", "vul_type": "cwe-190", "description": "Write a C function to resize a ring buffer for a specific CPU or all CPUs, handling memory allocation and synchronization issues."}
{"func_name": "misc_file_checks", "func_src_before": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Deprecated usage of 'add_header' in nginx conf\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            if not os.path.isfile(self.path + \"/conf/\" + filename):\n                continue\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )", "func_src_after": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Analyze nginx conf\n        # - Deprecated usage of 'add_header' in nginx conf\n        # - Spot path traversal issue vulnerability\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            # Ignore subdirs or filename not containing nginx in the name\n            if not os.path.isfile(self.path + \"/conf/\" + filename) or \"nginx\" not in filename:\n                continue\n\n            #\n            # 'add_header' usage\n            #\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )\n\n            #\n            # Path traversal issues\n            #\n            lines = open(self.path + \"/conf/\" + filename).readlines()\n            lines = [line.strip() for line in lines if not line.strip().startswith(\"#\")]\n            # Let's find the first location line\n            location_line = None\n            path_traversal_vulnerable = False\n            lines_iter = lines.__iter__()\n            for line in lines_iter:\n                if line.startswith(\"location\"):\n                    location_line = line\n                    break\n            # Look at the next lines for an 'alias' directive\n            if location_line is not None:\n                for line in lines_iter:\n                    if line.startswith(\"location\"):\n                        # Entering a new location block ... abort here\n                        # and assume there's no alias block later...\n                        break\n                    if line.startswith(\"alias\"):\n                        # We should definitely check for path traversal issue\n                        # Does the location target ends with / ?\n                        target = location_line.split()[-2]\n                        if not target.endswith(\"/\"):\n                            path_traversal_vulnerable = True\n                        break\n            if path_traversal_vulnerable:\n                print_warning(\n                    \"The nginx configuration appears vulnerable to path traversal as explained in \"\n                    \"https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/\\n\"\n                    \"To fix it, look at the first lines of the nginx conf of the example app : \"\n                    \"https://github.com/YunoHost/example_ynh/blob/master/conf/nginx.conf\"\n                )", "commit_link": "github.com/YunoHost/package_linter/commit/f6e98894cfe841aedaa7efd590937f0255193913", "file_name": "package_linter.py", "vul_type": "cwe-022", "description": "Write a Python function to check for mandatory files, deprecated configurations, and potential vulnerabilities in a project's file structure and configurations."}
{"func_name": "updateDataEntry", "func_src_before": "  function updateDataEntry($box, forceUpdate) {\n    var $input = $box;\n    var $parent = $input.parents(\".table_entry\");\n    if(!$box.hasClass('grading_value')) {\n      $input = $box.find(\".grading_value\");\n    }\n    var val = $input.val();\n    var sendVal = val;\n    var oldVal = $.trim($parent.find(\".grade\").text());\n    if($parent.find(\".grade img\").length > 0) {\n      oldVal = $parent.find(\".grade img\").attr('alt').toLowerCase();\n    }\n    if(oldVal == \"-\") {\n      oldVal = \"\";\n    }\n\n    if($input.hasClass('pass_fail')) {\n      if(val == \"pass\" || val == \"fail\") {\n        val = $(\"#submission_entry_\" + val + \"_image\").clone().attr('id', '');\n      }\n    }\n    var data = {};\n    var formData = $update_submission_form.getFormData();\n    var submission = objectData($parent.parent());\n    data.id = submission.id || \"\";\n    data.assignment_id = submission.assignment_id;\n    data.student_id = submission.user_id;\n    data.grade = sendVal;\n    if(sendVal != oldVal || (sendVal && forceUpdate)) {\n      submitDataEntry(data);\n    }\n    if(!val || val == \"\") {\n      data.submission_type = submission.submission_type || \"\";\n      val = emptySubmissionText(data);\n    }\n    $parent.find(\".grade\").show().empty().append(val);\n  }", "func_src_after": "  function updateDataEntry($box, forceUpdate) {\n    var $input = $box;\n    var $parent = $input.parents(\".table_entry\");\n    if(!$box.hasClass('grading_value')) {\n      $input = $box.find(\".grading_value\");\n    }\n    var val = $input.val();\n    var sendVal = val;\n    var oldVal = $.trim($parent.find(\".grade\").text());\n    if($parent.find(\".grade img\").length > 0) {\n      oldVal = $parent.find(\".grade img\").attr('alt').toLowerCase();\n    }\n    if(oldVal == \"-\") {\n      oldVal = \"\";\n    }\n\n    if($input.hasClass('pass_fail')) {\n      if(val == \"pass\" || val == \"fail\") {\n        val = $(\"#submission_entry_\" + val + \"_image\").clone().attr('id', '');\n      }\n    }\n    var data = {};\n    var formData = $update_submission_form.getFormData();\n    var submission = objectData($parent.parent());\n    data.id = submission.id || \"\";\n    data.assignment_id = submission.assignment_id;\n    data.student_id = submission.user_id;\n    data.grade = sendVal;\n    if(sendVal != oldVal || (sendVal && forceUpdate)) {\n      submitDataEntry(data);\n    }\n    if(!val || val == \"\") {\n      data.submission_type = submission.submission_type || \"\";\n      val = emptySubmissionText(data);\n    }\n    $parent.find(\".grade\").show().empty().append(htmlEscape(val));\n  }", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1177, "char_end": 1232, "line": "    $parent.find(\".grade\").show().empty().append(val);\n"}], "added": [{"line_no": 36, "char_start": 1177, "char_end": 1244, "line": "    $parent.find(\".grade\").show().empty().append(htmlEscape(val));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1226, "char_end": 1237, "chars": "htmlEscape("}, {"char_start": 1241, "char_end": 1242, "chars": ")"}]}, "commit_link": "github.com/djbender/canvas-lms/commit/a8d2ef69b7138d2197a4641933a8a036aa910e4b", "file_name": "gradebooks.js", "vul_type": "cwe-079", "commit_msg": "gradebook1: escape html in scores\n\nprevent xss when inputting scores in gradebook 1.\n\ntest plan:\n  - as a teacher, enter a grade in gradebook1 for the following grading\n    types:\n    - points\n    - percent\n    - letter grade\n  with the text:\n    \"><img src=/ onerror=alert(document.cookie);>\n  - make sure you don't see an alert for all of these file types.\n\nfixes CNVS-5381\n\nChange-Id: I27d102b83dce5f510f486e30613a1685aa11f2be\nReviewed-on: https://gerrit.instructure.com/19724\nReviewed-by: Simon Williams <simon@instructure.com>\nQA-Review: Amber Taniuchi <amber@instructure.com>\nTested-by: Jenkins <jenkins@instructure.com>\nProduct-Review: Stanley Stuart <stanley@instructure.com>", "description": "Write a JavaScript function to update a data entry in a table, handling both text and image-based grades."}
{"func_name": "next_state_class", "func_src_before": "next_state_class(CClassNode* cc, OnigCodePoint* vs, enum CCVALTYPE* type,\n\t\t enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  if (*state == CCS_RANGE)\n    return ONIGERR_CHAR_CLASS_VALUE_AT_END_OF_RANGE;\n\n  if (*state == CCS_VALUE && *type != CCV_CLASS) {\n    if (*type == CCV_SB)\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n  }\n\n  *state = CCS_VALUE;\n  *type  = CCV_CLASS;\n  return 0;\n}", "func_src_after": "next_state_class(CClassNode* cc, OnigCodePoint* vs, enum CCVALTYPE* type,\n\t\t enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  if (*state == CCS_RANGE)\n    return ONIGERR_CHAR_CLASS_VALUE_AT_END_OF_RANGE;\n\n  if (*state == CCS_VALUE && *type != CCV_CLASS) {\n    if (*type == CCV_SB)\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n  }\n\n  if (*state != CCS_START)\n    *state = CCS_VALUE;\n\n  *type  = CCV_CLASS;\n  return 0;\n}", "commit_link": "github.com/kkos/oniguruma/commit/3b63d12038c8d8fc278e81c942fa9bec7c704c8b", "file_name": "src/regparse.c", "vul_type": "cwe-787", "description": "Write a C function named `next_state_class` that updates character class states and values for a regex engine."}
{"func_name": "testPrintTensorsToFile", "func_src_before": "  def testPrintTensorsToFile(self):\n    tmpfile_name = tempfile.mktemp(\".printv2_test\")\n    tensor_0 = math_ops.range(0, 10)\n    print_op_0 = logging_ops.print_v2(tensor_0,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_0)\n    tensor_1 = math_ops.range(11, 20)\n    print_op_1 = logging_ops.print_v2(tensor_1,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_1)\n    try:\n      f = open(tmpfile_name, \"r\")\n      line_0 = f.readline()\n      expected_0 = \"[0 1 2 ... 7 8 9]\"\n      self.assertTrue(expected_0 in line_0)\n      line_1 = f.readline()\n      expected_1 = \"[11 12 13 ... 17 18 19]\"\n      self.assertTrue(expected_1 in line_1)\n      f.close()\n      os.remove(tmpfile_name)\n    except IOError as e:\n      self.fail(e)", "func_src_after": "  def testPrintTensorsToFile(self):\n    _, tmpfile_name = tempfile.mkstemp(\n        \".printv2_test\")  # safe to ignore fd here\n    tensor_0 = math_ops.range(0, 10)\n    print_op_0 = logging_ops.print_v2(tensor_0,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_0)\n    tensor_1 = math_ops.range(11, 20)\n    print_op_1 = logging_ops.print_v2(tensor_1,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_1)\n    try:\n      f = open(tmpfile_name, \"r\")\n      line_0 = f.readline()\n      expected_0 = \"[0 1 2 ... 7 8 9]\"\n      self.assertTrue(expected_0 in line_0)\n      line_1 = f.readline()\n      expected_1 = \"[11 12 13 ... 17 18 19]\"\n      self.assertTrue(expected_1 in line_1)\n      f.close()\n      os.remove(tmpfile_name)\n    except IOError as e:\n      self.fail(e)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 36, "char_end": 88, "line": "    tmpfile_name = tempfile.mktemp(\".printv2_test\")\n"}], "added": [{"line_no": 2, "char_start": 36, "char_end": 76, "line": "    _, tmpfile_name = tempfile.mkstemp(\n"}, {"line_no": 3, "char_start": 76, "char_end": 127, "line": "        \".printv2_test\")  # safe to ignore fd here\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 39, "char_end": 42, "chars": " _,"}, {"char_start": 69, "char_end": 70, "chars": "s"}, {"char_start": 75, "char_end": 84, "chars": "\n        "}, {"char_start": 100, "char_end": 126, "chars": "  # safe to ignore fd here"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/247aaafbe7f689492797d92430e77443b011876c", "file_name": "logging_ops_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420360036\nChange-Id: I13eb94736af3397261cf0d46214ddb5a2af9d92b", "description": "Write a Python function to print two ranges of numbers to a temporary file and verify the output."}
{"func_name": "WriteOnePNGImage", "func_src_before": "static MagickBooleanType WriteOnePNGImage(MngInfo *mng_info,\n  const ImageInfo *IMimage_info,Image *IMimage,ExceptionInfo *exception)\n{\n  char\n    im_vers[32],\n    libpng_runv[32],\n    libpng_vers[32],\n    zlib_runv[32],\n    zlib_vers[32];\n\n  Image\n    *image;\n\n  ImageInfo\n    *image_info;\n\n  char\n    s[2];\n\n  const char\n    *name,\n    *property,\n    *value;\n\n  const StringInfo\n    *profile;\n\n  int\n    num_passes,\n    pass,\n    ping_wrote_caNv;\n\n  png_byte\n     ping_trans_alpha[256];\n\n  png_color\n     palette[257];\n\n  png_color_16\n    ping_background,\n    ping_trans_color;\n\n  png_info\n    *ping_info;\n\n  png_struct\n    *ping;\n\n  png_uint_32\n    ping_height,\n    ping_width;\n\n  ssize_t\n    y;\n\n  MagickBooleanType\n    image_matte,\n    logging,\n    matte,\n\n    ping_have_blob,\n    ping_have_cheap_transparency,\n    ping_have_color,\n    ping_have_non_bw,\n    ping_have_PLTE,\n    ping_have_bKGD,\n    ping_have_eXIf,\n    ping_have_iCCP,\n    ping_have_pHYs,\n    ping_have_sRGB,\n    ping_have_tRNS,\n\n    ping_exclude_bKGD,\n    ping_exclude_cHRM,\n    ping_exclude_date,\n    /* ping_exclude_EXIF, */\n    ping_exclude_eXIf,\n    ping_exclude_gAMA,\n    ping_exclude_iCCP,\n    /* ping_exclude_iTXt, */\n    ping_exclude_oFFs,\n    ping_exclude_pHYs,\n    ping_exclude_sRGB,\n    ping_exclude_tEXt,\n    ping_exclude_tIME,\n    /* ping_exclude_tRNS, */\n    ping_exclude_vpAg,\n    ping_exclude_caNv,\n    ping_exclude_zCCP, /* hex-encoded iCCP */\n    ping_exclude_zTXt,\n\n    ping_preserve_colormap,\n    ping_preserve_iCCP,\n    ping_need_colortype_warning,\n\n    status,\n    tried_332,\n    tried_333,\n    tried_444;\n\n  MemoryInfo\n    *volatile pixel_info;\n\n  QuantumInfo\n    *quantum_info;\n\n  PNGErrorInfo\n    error_info;\n\n  register ssize_t\n    i,\n    x;\n\n  unsigned char\n    *ping_pixels;\n\n  volatile int\n    image_colors,\n    ping_bit_depth,\n    ping_color_type,\n    ping_interlace_method,\n    ping_compression_method,\n    ping_filter_method,\n    ping_num_trans;\n\n  volatile size_t\n    image_depth,\n    old_bit_depth;\n\n  size_t\n    quality,\n    rowbytes,\n    save_image_depth;\n\n  int\n    j,\n    number_colors,\n    number_opaque,\n    number_semitransparent,\n    number_transparent,\n    ping_pHYs_unit_type;\n\n  png_uint_32\n    ping_pHYs_x_resolution,\n    ping_pHYs_y_resolution;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter WriteOnePNGImage()\");\n\n  image = CloneImage(IMimage,0,0,MagickFalse,exception);\n  image_info=(ImageInfo *) CloneImageInfo(IMimage_info);\n  if (image_info == (ImageInfo *) NULL)\n     ThrowWriterException(ResourceLimitError, \"MemoryAllocationFailed\");\n\n  /* Define these outside of the following \"if logging()\" block so they will\n   * show in debuggers.\n   */\n  *im_vers='\\0';\n  (void) ConcatenateMagickString(im_vers,\n         MagickLibVersionText,MagickPathExtent);\n  (void) ConcatenateMagickString(im_vers,\n         MagickLibAddendum,MagickPathExtent);\n\n  *libpng_vers='\\0';\n  (void) ConcatenateMagickString(libpng_vers,\n         PNG_LIBPNG_VER_STRING,32);\n  *libpng_runv='\\0';\n  (void) ConcatenateMagickString(libpng_runv,\n         png_get_libpng_ver(NULL),32);\n\n  *zlib_vers='\\0';\n  (void) ConcatenateMagickString(zlib_vers,\n         ZLIB_VERSION,32);\n  *zlib_runv='\\0';\n  (void) ConcatenateMagickString(zlib_runv,\n         zlib_version,32);\n\n  if (logging != MagickFalse)\n    {\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"    IM version     = %s\",\n           im_vers);\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"    Libpng version = %s\",\n           libpng_vers);\n       if (LocaleCompare(libpng_vers,libpng_runv) != 0)\n       {\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"      running with   %s\",\n           libpng_runv);\n       }\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"    Zlib version   = %s\",\n           zlib_vers);\n       if (LocaleCompare(zlib_vers,zlib_runv) != 0)\n       {\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"      running with   %s\",\n           zlib_runv);\n       }\n    }\n\n  /* Initialize some stuff */\n  ping_bit_depth=0,\n  ping_color_type=0,\n  ping_interlace_method=0,\n  ping_compression_method=0,\n  ping_filter_method=0,\n  ping_num_trans = 0;\n\n  ping_background.red = 0;\n  ping_background.green = 0;\n  ping_background.blue = 0;\n  ping_background.gray = 0;\n  ping_background.index = 0;\n\n  ping_trans_color.red=0;\n  ping_trans_color.green=0;\n  ping_trans_color.blue=0;\n  ping_trans_color.gray=0;\n\n  ping_pHYs_unit_type = 0;\n  ping_pHYs_x_resolution = 0;\n  ping_pHYs_y_resolution = 0;\n\n  ping_have_blob=MagickFalse;\n  ping_have_cheap_transparency=MagickFalse;\n  ping_have_color=MagickTrue;\n  ping_have_non_bw=MagickTrue;\n  ping_have_PLTE=MagickFalse;\n  ping_have_bKGD=MagickFalse;\n  ping_have_eXIf=MagickTrue;\n  ping_have_iCCP=MagickFalse;\n  ping_have_pHYs=MagickFalse;\n  ping_have_sRGB=MagickFalse;\n  ping_have_tRNS=MagickFalse;\n\n  ping_exclude_bKGD=mng_info->ping_exclude_bKGD;\n  ping_exclude_caNv=mng_info->ping_exclude_caNv;\n  ping_exclude_cHRM=mng_info->ping_exclude_cHRM;\n  ping_exclude_date=mng_info->ping_exclude_date;\n  ping_exclude_eXIf=mng_info->ping_exclude_eXIf;\n  ping_exclude_gAMA=mng_info->ping_exclude_gAMA;\n  ping_exclude_iCCP=mng_info->ping_exclude_iCCP;\n  /* ping_exclude_iTXt=mng_info->ping_exclude_iTXt; */\n  ping_exclude_oFFs=mng_info->ping_exclude_oFFs;\n  ping_exclude_pHYs=mng_info->ping_exclude_pHYs;\n  ping_exclude_sRGB=mng_info->ping_exclude_sRGB;\n  ping_exclude_tEXt=mng_info->ping_exclude_tEXt;\n  ping_exclude_tIME=mng_info->ping_exclude_tIME;\n  /* ping_exclude_tRNS=mng_info->ping_exclude_tRNS; */\n  ping_exclude_vpAg=mng_info->ping_exclude_vpAg;\n  ping_exclude_zCCP=mng_info->ping_exclude_zCCP; /* hex-encoded iCCP in zTXt */\n  ping_exclude_zTXt=mng_info->ping_exclude_zTXt;\n\n  ping_preserve_colormap = mng_info->ping_preserve_colormap;\n  ping_preserve_iCCP = mng_info->ping_preserve_iCCP;\n  ping_need_colortype_warning = MagickFalse;\n\n  /* Recognize the ICC sRGB profile and convert it to the sRGB chunk,\n   * i.e., eliminate the ICC profile and set image->rendering_intent.\n   * Note that this will not involve any changes to the actual pixels\n   * but merely passes information to applications that read the resulting\n   * PNG image.\n   *\n   * To do: recognize other variants of the sRGB profile, using the CRC to\n   * verify all recognized variants including the 7 already known.\n   *\n   * Work around libpng16+ rejecting some \"known invalid sRGB profiles\".\n   *\n   * Use something other than image->rendering_intent to record the fact\n   * that the sRGB profile was found.\n   *\n   * Record the ICC version (currently v2 or v4) of the incoming sRGB ICC\n   * profile.  Record the Blackpoint Compensation, if any.\n   */\n   if (ping_exclude_sRGB == MagickFalse && ping_preserve_iCCP == MagickFalse)\n   {\n      char\n        *name;\n\n      const StringInfo\n        *profile;\n\n      ResetImageProfileIterator(image);\n      for (name=GetNextImageProfile(image); name != (const char *) NULL; )\n      {\n        profile=GetImageProfile(image,name);\n\n        if (profile != (StringInfo *) NULL)\n          {\n            if ((LocaleCompare(name,\"ICC\") == 0) ||\n                (LocaleCompare(name,\"ICM\") == 0))\n\n             {\n                 int\n                   icheck,\n                   got_crc=0;\n\n\n                 png_uint_32\n                   length,\n                   profile_crc=0;\n\n                 unsigned char\n                   *data;\n\n                 length=(png_uint_32) GetStringInfoLength(profile);\n\n                 for (icheck=0; sRGB_info[icheck].len > 0; icheck++)\n                 {\n                   if (length == sRGB_info[icheck].len)\n                   {\n                     if (got_crc == 0)\n                     {\n                       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                         \"    Got a %lu-byte ICC profile (potentially sRGB)\",\n                         (unsigned long) length);\n\n                       data=GetStringInfoDatum(profile);\n                       profile_crc=crc32(0,data,length);\n\n                       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                           \"      with crc=%8x\",(unsigned int) profile_crc);\n                       got_crc++;\n                     }\n\n                     if (profile_crc == sRGB_info[icheck].crc)\n                     {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"      It is sRGB with rendering intent = %s\",\n                        Magick_RenderingIntentString_from_PNG_RenderingIntent(\n                             sRGB_info[icheck].intent));\n                        if (image->rendering_intent==UndefinedIntent)\n                        {\n                          image->rendering_intent=\n                          Magick_RenderingIntent_from_PNG_RenderingIntent(\n                             sRGB_info[icheck].intent);\n                        }\n                        ping_exclude_iCCP = MagickTrue;\n                        ping_exclude_zCCP = MagickTrue;\n                        ping_have_sRGB = MagickTrue;\n                        break;\n                     }\n                   }\n                 }\n                 if (sRGB_info[icheck].len == 0)\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"    Got %lu-byte ICC profile not recognized as sRGB\",\n                        (unsigned long) length);\n              }\n          }\n        name=GetNextImageProfile(image);\n      }\n  }\n\n  number_opaque = 0;\n  number_semitransparent = 0;\n  number_transparent = 0;\n\n  if (logging != MagickFalse)\n    {\n      if (image->storage_class == UndefinedClass)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    image->storage_class=UndefinedClass\");\n      if (image->storage_class == DirectClass)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    image->storage_class=DirectClass\");\n      if (image->storage_class == PseudoClass)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    image->storage_class=PseudoClass\");\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(), image->taint ?\n          \"    image->taint=MagickTrue\":\n          \"    image->taint=MagickFalse\");\n    }\n\n  if (image->storage_class == PseudoClass &&\n     (mng_info->write_png8 || mng_info->write_png24 || mng_info->write_png32 ||\n     mng_info->write_png48 || mng_info->write_png64 ||\n     (mng_info->write_png_colortype != 1 &&\n     mng_info->write_png_colortype != 5)))\n    {\n      (void) SyncImage(image,exception);\n      image->storage_class = DirectClass;\n    }\n\n  if (ping_preserve_colormap == MagickFalse)\n    {\n      if (image->storage_class != PseudoClass && image->colormap != NULL)\n        {\n          /* Free the bogus colormap; it can cause trouble later */\n           if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Freeing bogus colormap\");\n           (void) RelinquishMagickMemory(image->colormap);\n           image->colormap=NULL;\n        }\n    }\n\n  if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n    (void) TransformImageColorspace(image,sRGBColorspace,exception);\n\n  /*\n    Sometimes we get PseudoClass images whose RGB values don't match\n    the colors in the colormap.  This code syncs the RGB values.\n  */\n  if (image->depth <= 8 && image->taint && image->storage_class == PseudoClass)\n     (void) SyncImage(image,exception);\n\n#if (MAGICKCORE_QUANTUM_DEPTH == 8)\n  if (image->depth > 8)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    Reducing PNG bit depth to 8 since this is a Q8 build.\");\n\n      image->depth=8;\n    }\n#endif\n\n  /* Respect the -depth option */\n  if (image->depth < 4)\n    {\n       register Quantum\n         *r;\n\n       if (image->depth > 2)\n         {\n           /* Scale to 4-bit */\n           LBR04PacketRGBO(image->background_color);\n\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n             if (r == (Quantum *) NULL)\n               break;\n\n             for (x=0; x < (ssize_t) image->columns; x++)\n             {\n                LBR04PixelRGBA(r);\n                r+=GetPixelChannels(image);\n             }\n\n             if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n           }\n\n           if (image->storage_class == PseudoClass && image->colormap != NULL)\n           {\n             for (i=0; i < (ssize_t) image->colors; i++)\n             {\n               LBR04PacketRGBO(image->colormap[i]);\n             }\n           }\n         }\n       else if (image->depth > 1)\n         {\n           /* Scale to 2-bit */\n           LBR02PacketRGBO(image->background_color);\n\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n             if (r == (Quantum *) NULL)\n               break;\n\n             for (x=0; x < (ssize_t) image->columns; x++)\n             {\n                LBR02PixelRGBA(r);\n                r+=GetPixelChannels(image);\n             }\n\n             if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n           }\n\n           if (image->storage_class == PseudoClass && image->colormap != NULL)\n           {\n             for (i=0; i < (ssize_t) image->colors; i++)\n             {\n               LBR02PacketRGBO(image->colormap[i]);\n             }\n           }\n         }\n       else\n         {\n           /* Scale to 1-bit */\n           LBR01PacketRGBO(image->background_color);\n\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n             if (r == (Quantum *) NULL)\n               break;\n\n             for (x=0; x < (ssize_t) image->columns; x++)\n             {\n                LBR01PixelRGBA(r);\n                r+=GetPixelChannels(image);\n             }\n\n             if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n           }\n\n           if (image->storage_class == PseudoClass && image->colormap != NULL)\n           {\n             for (i=0; i < (ssize_t) image->colors; i++)\n             {\n               LBR01PacketRGBO(image->colormap[i]);\n             }\n           }\n         }\n    }\n\n  /* To do: set to next higher multiple of 8 */\n  if (image->depth < 8)\n     image->depth=8;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n  /* PNG does not handle depths greater than 16 so reduce it even\n   * if lossy\n   */\n  if (image->depth > 8)\n      image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n  if (image->depth > 8)\n    {\n      /* To do: fill low byte properly */\n      image->depth=16;\n    }\n\n  if (image->depth == 16 && mng_info->write_png_depth != 16)\n    if (mng_info->write_png8 ||\n        LosslessReduceDepthOK(image,exception) != MagickFalse)\n      image->depth = 8;\n#endif\n\n  image_colors = (int) image->colors;\n  number_opaque = (int) image->colors;\n  number_transparent = 0;\n  number_semitransparent = 0;\n\n  if (mng_info->write_png_colortype &&\n     (mng_info->write_png_colortype > 4 || (mng_info->write_png_depth >= 8 &&\n     mng_info->write_png_colortype < 4 &&\n     image->alpha_trait == UndefinedPixelTrait)))\n  {\n     /* Avoid the expensive BUILD_PALETTE operation if we're sure that we\n      * are not going to need the result.\n      */\n     if (mng_info->write_png_colortype == 1 ||\n        mng_info->write_png_colortype == 5)\n       ping_have_color=MagickFalse;\n\n     if (image->alpha_trait != UndefinedPixelTrait)\n       {\n         number_transparent = 2;\n         number_semitransparent = 1;\n       }\n  }\n\n  if (mng_info->write_png_colortype < 7)\n  {\n  /* BUILD_PALETTE\n   *\n   * Normally we run this just once, but in the case of writing PNG8\n   * we reduce the transparency to binary and run again, then if there\n   * are still too many colors we reduce to a simple 4-4-4-1, then 3-3-3-1\n   * RGBA palette and run again, and then to a simple 3-3-2-1 RGBA\n   * palette.  Then (To do) we take care of a final reduction that is only\n   * needed if there are still 256 colors present and one of them has both\n   * transparent and opaque instances.\n   */\n\n  tried_332 = MagickFalse;\n  tried_333 = MagickFalse;\n  tried_444 = MagickFalse;\n\n  for (j=0; j<6; j++)\n  {\n    /*\n     * Sometimes we get DirectClass images that have 256 colors or fewer.\n     * This code will build a colormap.\n     *\n     * Also, sometimes we get PseudoClass images with an out-of-date\n     * colormap.  This code will replace the colormap with a new one.\n     * Sometimes we get PseudoClass images that have more than 256 colors.\n     * This code will delete the colormap and change the image to\n     * DirectClass.\n     *\n     * If image->alpha_trait is MagickFalse, we ignore the alpha channel\n     * even though it sometimes contains left-over non-opaque values.\n     *\n     * Also we gather some information (number of opaque, transparent,\n     * and semitransparent pixels, and whether the image has any non-gray\n     * pixels or only black-and-white pixels) that we might need later.\n     *\n     * Even if the user wants to force GrayAlpha or RGBA (colortype 4 or 6)\n     * we need to check for bogus non-opaque values, at least.\n     */\n\n   int\n     n;\n\n   PixelInfo\n     opaque[260],\n     semitransparent[260],\n     transparent[260];\n\n   register const Quantum\n     *s;\n\n   register Quantum\n     *q,\n     *r;\n\n   if (logging != MagickFalse)\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n         \"    Enter BUILD_PALETTE:\");\n\n   if (logging != MagickFalse)\n     {\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      image->columns=%.20g\",(double) image->columns);\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      image->rows=%.20g\",(double) image->rows);\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      image->alpha_trait=%.20g\",(double) image->alpha_trait);\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      image->depth=%.20g\",(double) image->depth);\n\n       if (image->storage_class == PseudoClass && image->colormap != NULL)\n       {\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      Original colormap:\");\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"        i    (red,green,blue,alpha)\");\n\n         for (i=0; i < 256; i++)\n         {\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"        %d    (%d,%d,%d,%d)\",\n                    (int) i,\n                    (int) image->colormap[i].red,\n                    (int) image->colormap[i].green,\n                    (int) image->colormap[i].blue,\n                    (int) image->colormap[i].alpha);\n         }\n\n         for (i=image->colors - 10; i < (ssize_t) image->colors; i++)\n         {\n           if (i > 255)\n             {\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"        %d    (%d,%d,%d,%d)\",\n                    (int) i,\n                    (int) image->colormap[i].red,\n                    (int) image->colormap[i].green,\n                    (int) image->colormap[i].blue,\n                    (int) image->colormap[i].alpha);\n             }\n         }\n       }\n\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"      image->colors=%d\",(int) image->colors);\n\n       if (image->colors == 0)\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"        (zero means unknown)\");\n\n       if (ping_preserve_colormap == MagickFalse)\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"      Regenerate the colormap\");\n     }\n\n     image_colors=0;\n     number_opaque = 0;\n     number_semitransparent = 0;\n     number_transparent = 0;\n\n     for (y=0; y < (ssize_t) image->rows; y++)\n     {\n       q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n       if (q == (Quantum *) NULL)\n         break;\n\n       for (x=0; x < (ssize_t) image->columns; x++)\n       {\n           if (image->alpha_trait == UndefinedPixelTrait ||\n              GetPixelAlpha(image,q) == OpaqueAlpha)\n             {\n               if (number_opaque < 259)\n                 {\n                   if (number_opaque == 0)\n                     {\n                       GetPixelInfoPixel(image, q, opaque);\n                       opaque[0].alpha=OpaqueAlpha;\n                       number_opaque=1;\n                     }\n\n                   for (i=0; i< (ssize_t) number_opaque; i++)\n                     {\n                       if (Magick_png_color_equal(image,q,opaque+i))\n                         break;\n                     }\n\n                   if (i ==  (ssize_t) number_opaque && number_opaque < 259)\n                     {\n                       number_opaque++;\n                       GetPixelInfoPixel(image, q, opaque+i);\n                       opaque[i].alpha=OpaqueAlpha;\n                     }\n                 }\n             }\n           else if (GetPixelAlpha(image,q) == TransparentAlpha)\n             {\n               if (number_transparent < 259)\n                 {\n                   if (number_transparent == 0)\n                     {\n                       GetPixelInfoPixel(image, q, transparent);\n                       ping_trans_color.red=(unsigned short)\n                         GetPixelRed(image,q);\n                       ping_trans_color.green=(unsigned short)\n                         GetPixelGreen(image,q);\n                       ping_trans_color.blue=(unsigned short)\n                         GetPixelBlue(image,q);\n                       ping_trans_color.gray=(unsigned short)\n                         GetPixelGray(image,q);\n                       number_transparent = 1;\n                     }\n\n                   for (i=0; i< (ssize_t) number_transparent; i++)\n                     {\n                       if (Magick_png_color_equal(image,q,transparent+i))\n                         break;\n                     }\n\n                   if (i ==  (ssize_t) number_transparent &&\n                       number_transparent < 259)\n                     {\n                       number_transparent++;\n                       GetPixelInfoPixel(image,q,transparent+i);\n                     }\n                 }\n             }\n           else\n             {\n               if (number_semitransparent < 259)\n                 {\n                   if (number_semitransparent == 0)\n                     {\n                       GetPixelInfoPixel(image,q,semitransparent);\n                       number_semitransparent = 1;\n                     }\n\n                   for (i=0; i< (ssize_t) number_semitransparent; i++)\n                     {\n                       if (Magick_png_color_equal(image,q,semitransparent+i)\n                           && GetPixelAlpha(image,q) ==\n                           semitransparent[i].alpha)\n                         break;\n                     }\n\n                   if (i ==  (ssize_t) number_semitransparent &&\n                       number_semitransparent < 259)\n                     {\n                       number_semitransparent++;\n                       GetPixelInfoPixel(image, q, semitransparent+i);\n                     }\n                 }\n             }\n           q+=GetPixelChannels(image);\n        }\n     }\n\n     if (mng_info->write_png8 == MagickFalse &&\n         ping_exclude_bKGD == MagickFalse)\n       {\n         /* Add the background color to the palette, if it\n          * isn't already there.\n          */\n          if (logging != MagickFalse)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      Check colormap for background (%d,%d,%d)\",\n                  (int) image->background_color.red,\n                  (int) image->background_color.green,\n                  (int) image->background_color.blue);\n            }\n          for (i=0; i<number_opaque; i++)\n          {\n             if (opaque[i].red == image->background_color.red &&\n                 opaque[i].green == image->background_color.green &&\n                 opaque[i].blue == image->background_color.blue)\n               break;\n          }\n          if (number_opaque < 259 && i == number_opaque)\n            {\n               opaque[i] = image->background_color;\n               ping_background.index = i;\n               number_opaque++;\n               if (logging != MagickFalse)\n                 {\n                   (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                       \"      background_color index is %d\",(int) i);\n                 }\n\n            }\n          else if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      No room in the colormap to add background color\");\n       }\n\n     image_colors=number_opaque+number_transparent+number_semitransparent;\n\n     if (logging != MagickFalse)\n       {\n         if (image_colors > 256)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      image has more than 256 colors\");\n\n         else\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      image has %d colors\",image_colors);\n       }\n\n     if (ping_preserve_colormap != MagickFalse)\n       break;\n\n     if (mng_info->write_png_colortype != 7) /* We won't need this info */\n       {\n         ping_have_color=MagickFalse;\n         ping_have_non_bw=MagickFalse;\n\n         if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n         {\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"incompatible colorspace\");\n           ping_have_color=MagickTrue;\n           ping_have_non_bw=MagickTrue;\n         }\n\n         if(image_colors > 256)\n           {\n             for (y=0; y < (ssize_t) image->rows; y++)\n             {\n               q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n               if (q == (Quantum *) NULL)\n                 break;\n\n               s=q;\n               for (x=0; x < (ssize_t) image->columns; x++)\n               {\n                 if (GetPixelRed(image,s) != GetPixelGreen(image,s) ||\n                     GetPixelRed(image,s) != GetPixelBlue(image,s))\n                   {\n                      ping_have_color=MagickTrue;\n                      ping_have_non_bw=MagickTrue;\n                      break;\n                   }\n                 s+=GetPixelChannels(image);\n               }\n\n               if (ping_have_color != MagickFalse)\n                 break;\n\n               /* Worst case is black-and-white; we are looking at every\n                * pixel twice.\n                */\n\n               if (ping_have_non_bw == MagickFalse)\n                 {\n                   s=q;\n                   for (x=0; x < (ssize_t) image->columns; x++)\n                   {\n                     if (GetPixelRed(image,s) != 0 &&\n                         GetPixelRed(image,s) != QuantumRange)\n                       {\n                         ping_have_non_bw=MagickTrue;\n                         break;\n                       }\n                     s+=GetPixelChannels(image);\n                   }\n               }\n             }\n           }\n       }\n\n     if (image_colors < 257)\n       {\n         PixelInfo\n           colormap[260];\n\n         /*\n          * Initialize image colormap.\n          */\n\n         if (logging != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      Sort the new colormap\");\n\n        /* Sort palette, transparent first */;\n\n         n = 0;\n\n         for (i=0; i<number_transparent; i++)\n            colormap[n++] = transparent[i];\n\n         for (i=0; i<number_semitransparent; i++)\n            colormap[n++] = semitransparent[i];\n\n         for (i=0; i<number_opaque; i++)\n            colormap[n++] = opaque[i];\n\n         ping_background.index +=\n           (number_transparent + number_semitransparent);\n\n         /* image_colors < 257; search the colormap instead of the pixels\n          * to get ping_have_color and ping_have_non_bw\n          */\n         for (i=0; i<n; i++)\n         {\n           if (ping_have_color == MagickFalse)\n             {\n                if (colormap[i].red != colormap[i].green ||\n                    colormap[i].red != colormap[i].blue)\n                  {\n                     ping_have_color=MagickTrue;\n                     ping_have_non_bw=MagickTrue;\n                     break;\n                  }\n              }\n\n           if (ping_have_non_bw == MagickFalse)\n             {\n               if (colormap[i].red != 0 && colormap[i].red != QuantumRange)\n                   ping_have_non_bw=MagickTrue;\n             }\n          }\n\n        if ((mng_info->ping_exclude_tRNS == MagickFalse ||\n            (number_transparent == 0 && number_semitransparent == 0)) &&\n            (((mng_info->write_png_colortype-1) ==\n            PNG_COLOR_TYPE_PALETTE) ||\n            (mng_info->write_png_colortype == 0)))\n          {\n            if (logging != MagickFalse)\n              {\n                if (n !=  (ssize_t) image_colors)\n                   (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"   image_colors (%d) and n (%d)  don't match\",\n                   image_colors, n);\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      AcquireImageColormap\");\n              }\n\n            image->colors = image_colors;\n\n            if (AcquireImageColormap(image,image_colors,exception) ==\n                MagickFalse)\n               ThrowWriterException(ResourceLimitError,\n                   \"MemoryAllocationFailed\");\n\n            for (i=0; i< (ssize_t) image_colors; i++)\n               image->colormap[i] = colormap[i];\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"      image->colors=%d (%d)\",\n                      (int) image->colors, image_colors);\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"      Update the pixel indexes\");\n              }\n\n            /* Sync the pixel indices with the new colormap */\n\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n              if (q == (Quantum *) NULL)\n                break;\n\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                for (i=0; i< (ssize_t) image_colors; i++)\n                {\n                  if ((image->alpha_trait == UndefinedPixelTrait ||\n                      image->colormap[i].alpha == GetPixelAlpha(image,q)) &&\n                      image->colormap[i].red == GetPixelRed(image,q) &&\n                      image->colormap[i].green == GetPixelGreen(image,q) &&\n                      image->colormap[i].blue == GetPixelBlue(image,q))\n                  {\n                    SetPixelIndex(image,i,q);\n                    break;\n                  }\n                }\n                q+=GetPixelChannels(image);\n              }\n\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                 break;\n            }\n          }\n       }\n\n     if (logging != MagickFalse)\n       {\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"      image->colors=%d\", (int) image->colors);\n\n         if (image->colormap != NULL)\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"       i     (red,green,blue,alpha)\");\n\n             for (i=0; i < (ssize_t) image->colors; i++)\n             {\n               if (i < 300 || i >= (ssize_t) image->colors - 10)\n                 {\n                   (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                       \"       %d     (%d,%d,%d,%d)\",\n                        (int) i,\n                        (int) image->colormap[i].red,\n                        (int) image->colormap[i].green,\n                        (int) image->colormap[i].blue,\n                        (int) image->colormap[i].alpha);\n                 }\n             }\n           }\n\n           if (number_transparent < 257)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_transparent     = %d\",\n                   number_transparent);\n           else\n\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_transparent     > 256\");\n\n           if (number_opaque < 257)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_opaque          = %d\",\n                   number_opaque);\n\n           else\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_opaque          > 256\");\n\n           if (number_semitransparent < 257)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_semitransparent = %d\",\n                   number_semitransparent);\n\n           else\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_semitransparent > 256\");\n\n           if (ping_have_non_bw == MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      All pixels and the background are black or white\");\n\n           else if (ping_have_color == MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      All pixels and the background are gray\");\n\n           else\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      At least one pixel or the background is non-gray\");\n\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"    Exit BUILD_PALETTE:\");\n       }\n\n   if (mng_info->write_png8 == MagickFalse)\n      break;\n\n   /* Make any reductions necessary for the PNG8 format */\n    if (image_colors <= 256 &&\n        image_colors != 0 && image->colormap != NULL &&\n        number_semitransparent == 0 &&\n        number_transparent <= 1)\n      break;\n\n    /* PNG8 can't have semitransparent colors so we threshold the\n     * opacity to 0 or OpaqueOpacity, and PNG8 can only have one\n     * transparent color so if more than one is transparent we merge\n     * them into image->background_color.\n     */\n    if (number_semitransparent != 0 || number_transparent > 1)\n      {\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Thresholding the alpha channel to binary\");\n\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n          if (r == (Quantum *) NULL)\n            break;\n\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n              if (GetPixelAlpha(image,r) < OpaqueAlpha/2)\n                {\n                  SetPixelViaPixelInfo(image,&image->background_color,r);\n                  SetPixelAlpha(image,TransparentAlpha,r);\n                }\n              else\n                  SetPixelAlpha(image,OpaqueAlpha,r);\n              r+=GetPixelChannels(image);\n          }\n\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n             break;\n\n          if (image_colors != 0 && image_colors <= 256 &&\n             image->colormap != NULL)\n            for (i=0; i<image_colors; i++)\n                image->colormap[i].alpha =\n                    (image->colormap[i].alpha > TransparentAlpha/2 ?\n                    TransparentAlpha : OpaqueAlpha);\n        }\n      continue;\n    }\n\n    /* PNG8 can't have more than 256 colors so we quantize the pixels and\n     * background color to the 4-4-4-1, 3-3-3-1 or 3-3-2-1 palette.  If the\n     * image is mostly gray, the 4-4-4-1 palette is likely to end up with 256\n     * colors or less.\n     */\n    if (tried_444 == MagickFalse && (image_colors == 0 || image_colors > 256))\n      {\n        if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"    Quantizing the background color to 4-4-4\");\n\n        tried_444 = MagickTrue;\n\n        LBR04PacketRGB(image->background_color);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the pixel colors to 4-4-4\");\n\n        if (image->colormap == NULL)\n        {\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n            if (r == (Quantum *) NULL)\n              break;\n\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (GetPixelAlpha(image,r) == OpaqueAlpha)\n                  LBR04PixelRGB(r);\n              r+=GetPixelChannels(image);\n            }\n\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n               break;\n          }\n        }\n\n        else /* Should not reach this; colormap already exists and\n                must be <= 256 */\n        {\n          if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the colormap to 4-4-4\");\n\n          for (i=0; i<image_colors; i++)\n          {\n            LBR04PacketRGB(image->colormap[i]);\n          }\n        }\n        continue;\n      }\n\n    if (tried_333 == MagickFalse && (image_colors == 0 || image_colors > 256))\n      {\n        if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"    Quantizing the background color to 3-3-3\");\n\n        tried_333 = MagickTrue;\n\n        LBR03PacketRGB(image->background_color);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the pixel colors to 3-3-3-1\");\n\n        if (image->colormap == NULL)\n        {\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n            if (r == (Quantum *) NULL)\n              break;\n\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (GetPixelAlpha(image,r) == OpaqueAlpha)\n                  LBR03RGB(r);\n              r+=GetPixelChannels(image);\n            }\n\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n               break;\n          }\n        }\n\n        else /* Should not reach this; colormap already exists and\n                must be <= 256 */\n        {\n          if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the colormap to 3-3-3-1\");\n          for (i=0; i<image_colors; i++)\n          {\n              LBR03PacketRGB(image->colormap[i]);\n          }\n        }\n        continue;\n      }\n\n    if (tried_332 == MagickFalse && (image_colors == 0 || image_colors > 256))\n      {\n        if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"    Quantizing the background color to 3-3-2\");\n\n        tried_332 = MagickTrue;\n\n        /* Red and green were already done so we only quantize the blue\n         * channel\n         */\n\n        LBR02PacketBlue(image->background_color);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the pixel colors to 3-3-2-1\");\n\n        if (image->colormap == NULL)\n        {\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n            if (r == (Quantum *) NULL)\n              break;\n\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (GetPixelAlpha(image,r) == OpaqueAlpha)\n                  LBR02PixelBlue(r);\n              r+=GetPixelChannels(image);\n            }\n\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n               break;\n          }\n        }\n\n        else /* Should not reach this; colormap already exists and\n                must be <= 256 */\n        {\n          if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the colormap to 3-3-2-1\");\n          for (i=0; i<image_colors; i++)\n          {\n              LBR02PacketBlue(image->colormap[i]);\n          }\n      }\n      continue;\n    }\n\n    if (image_colors == 0 || image_colors > 256)\n    {\n      /* Take care of special case with 256 opaque colors + 1 transparent\n       * color.  We don't need to quantize to 2-3-2-1; we only need to\n       * eliminate one color, so we'll merge the two darkest red\n       * colors (0x49, 0, 0) -> (0x24, 0, 0).\n       */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Merging two dark red background colors to 3-3-2-1\");\n\n      if (ScaleQuantumToChar(image->background_color.red) == 0x49 &&\n          ScaleQuantumToChar(image->background_color.green) == 0x00 &&\n          ScaleQuantumToChar(image->background_color.blue) == 0x00)\n      {\n         image->background_color.red=ScaleCharToQuantum(0x24);\n      }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Merging two dark red pixel colors to 3-3-2-1\");\n\n      if (image->colormap == NULL)\n      {\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n          if (r == (Quantum *) NULL)\n            break;\n\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            if (ScaleQuantumToChar(GetPixelRed(image,r)) == 0x49 &&\n                ScaleQuantumToChar(GetPixelGreen(image,r)) == 0x00 &&\n                ScaleQuantumToChar(GetPixelBlue(image,r)) == 0x00 &&\n                GetPixelAlpha(image,r) == OpaqueAlpha)\n              {\n                SetPixelRed(image,ScaleCharToQuantum(0x24),r);\n              }\n            r+=GetPixelChannels(image);\n          }\n\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n             break;\n\n        }\n      }\n\n      else\n      {\n         for (i=0; i<image_colors; i++)\n         {\n            if (ScaleQuantumToChar(image->colormap[i].red) == 0x49 &&\n                ScaleQuantumToChar(image->colormap[i].green) == 0x00 &&\n                ScaleQuantumToChar(image->colormap[i].blue) == 0x00)\n            {\n               image->colormap[i].red=ScaleCharToQuantum(0x24);\n            }\n         }\n      }\n    }\n  }\n  }\n  /* END OF BUILD_PALETTE */\n\n  /* If we are excluding the tRNS chunk and there is transparency,\n   * then we must write a Gray-Alpha (color-type 4) or RGBA (color-type 6)\n   * PNG.\n   */\n  if (mng_info->ping_exclude_tRNS != MagickFalse &&\n     (number_transparent != 0 || number_semitransparent != 0))\n    {\n      unsigned int colortype=mng_info->write_png_colortype;\n\n      if (ping_have_color == MagickFalse)\n        mng_info->write_png_colortype = 5;\n\n      else\n        mng_info->write_png_colortype = 7;\n\n      if (colortype != 0 &&\n         mng_info->write_png_colortype != colortype)\n        ping_need_colortype_warning=MagickTrue;\n\n    }\n\n  /* See if cheap transparency is possible.  It is only possible\n   * when there is a single transparent color, no semitransparent\n   * color, and no opaque color that has the same RGB components\n   * as the transparent color.  We only need this information if\n   * we are writing a PNG with colortype 0 or 2, and we have not\n   * excluded the tRNS chunk.\n   */\n  if (number_transparent == 1 &&\n      mng_info->write_png_colortype < 4)\n    {\n       ping_have_cheap_transparency = MagickTrue;\n\n       if (number_semitransparent != 0)\n         ping_have_cheap_transparency = MagickFalse;\n\n       else if (image_colors == 0 || image_colors > 256 ||\n           image->colormap == NULL)\n         {\n           register const Quantum\n             *q;\n\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             q=GetVirtualPixels(image,0,y,image->columns,1, exception);\n\n             if (q == (Quantum *) NULL)\n               break;\n\n             for (x=0; x < (ssize_t) image->columns; x++)\n             {\n                 if (GetPixelAlpha(image,q) != TransparentAlpha &&\n                     (unsigned short) GetPixelRed(image,q) ==\n                                     ping_trans_color.red &&\n                     (unsigned short) GetPixelGreen(image,q) ==\n                                     ping_trans_color.green &&\n                     (unsigned short) GetPixelBlue(image,q) ==\n                                     ping_trans_color.blue)\n                   {\n                     ping_have_cheap_transparency = MagickFalse;\n                     break;\n                   }\n\n                 q+=GetPixelChannels(image);\n             }\n\n             if (ping_have_cheap_transparency == MagickFalse)\n                break;\n           }\n         }\n       else\n         {\n            /* Assuming that image->colormap[0] is the one transparent color\n             * and that all others are opaque.\n             */\n            if (image_colors > 1)\n              for (i=1; i<image_colors; i++)\n                if (image->colormap[i].red == image->colormap[0].red &&\n                    image->colormap[i].green == image->colormap[0].green &&\n                    image->colormap[i].blue == image->colormap[0].blue)\n                  {\n                     ping_have_cheap_transparency = MagickFalse;\n                     break;\n                  }\n         }\n\n       if (logging != MagickFalse)\n         {\n           if (ping_have_cheap_transparency == MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"   Cheap transparency is not possible.\");\n\n           else\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"   Cheap transparency is possible.\");\n         }\n     }\n  else\n    ping_have_cheap_transparency = MagickFalse;\n\n  image_depth=image->depth;\n\n  quantum_info = (QuantumInfo *) NULL;\n  number_colors=0;\n  image_colors=(int) image->colors;\n  image_matte=image->alpha_trait !=\n        UndefinedPixelTrait ? MagickTrue : MagickFalse;\n\n  if (mng_info->write_png_colortype < 5)\n    mng_info->IsPalette=image->storage_class == PseudoClass &&\n      image_colors <= 256 && image->colormap != NULL;\n  else\n    mng_info->IsPalette = MagickFalse;\n\n  if ((mng_info->write_png_colortype == 4 || mng_info->write_png8) &&\n     (image->colors == 0 || image->colormap == NULL))\n    {\n      image_info=DestroyImageInfo(image_info);\n      image=DestroyImage(image);\n      (void) ThrowMagickException(exception,GetMagickModule(),CoderError,\n          \"Cannot write PNG8 or color-type 3; colormap is NULL\",\n          \"`%s'\",IMimage->filename);\n      return(MagickFalse);\n    }\n\n  /*\n    Allocate the PNG structures\n  */\n#ifdef PNG_USER_MEM_SUPPORTED\n error_info.image=image;\n error_info.exception=exception;\n  ping=png_create_write_struct_2(PNG_LIBPNG_VER_STRING,&error_info,\n    MagickPNGErrorHandler,MagickPNGWarningHandler,(void *) NULL,\n    (png_malloc_ptr) Magick_png_malloc,(png_free_ptr) Magick_png_free);\n\n#else\n  ping=png_create_write_struct(PNG_LIBPNG_VER_STRING,&error_info,\n    MagickPNGErrorHandler,MagickPNGWarningHandler);\n\n#endif\n  if (ping == (png_struct *) NULL)\n    ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  ping_info=png_create_info_struct(ping);\n\n  if (ping_info == (png_info *) NULL)\n    {\n      png_destroy_write_struct(&ping,(png_info **) NULL);\n      ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n\n  png_set_write_fn(ping,image,png_put_data,png_flush_data);\n  pixel_info=(MemoryInfo *) NULL;\n\n  if (setjmp(png_jmpbuf(ping)))\n    {\n      /*\n        PNG write failed.\n      */\n#ifdef PNG_DEBUG\n     if (image_info->verbose)\n        (void) printf(\"PNG write has failed.\\n\");\n#endif\n      png_destroy_write_struct(&ping,&ping_info);\n#ifdef IMPNG_SETJMP_NOT_THREAD_SAFE\n      UnlockSemaphoreInfo(ping_semaphore);\n#endif\n\n      if (pixel_info != (MemoryInfo *) NULL)\n        pixel_info=RelinquishVirtualMemory(pixel_info);\n\n      if (quantum_info != (QuantumInfo *) NULL)\n        quantum_info=DestroyQuantumInfo(quantum_info);\n\n      if (ping_have_blob != MagickFalse)\n          (void) CloseBlob(image);\n      image_info=DestroyImageInfo(image_info);\n      image=DestroyImage(image);\n      return(MagickFalse);\n    }\n\n  /* {  For navigation to end of SETJMP-protected block.  Within this\n   *    block, use png_error() instead of Throwing an Exception, to ensure\n   *    that libpng is able to clean up, and that the semaphore is unlocked.\n   */\n\n#ifdef IMPNG_SETJMP_NOT_THREAD_SAFE\n  LockSemaphoreInfo(ping_semaphore);\n#endif\n\n#ifdef PNG_BENIGN_ERRORS_SUPPORTED\n  /* Allow benign errors */\n  png_set_benign_errors(ping, 1);\n#endif\n\n#ifdef PNG_SET_USER_LIMITS_SUPPORTED\n  /* Reject images with too many rows or columns */\n  png_set_user_limits(ping,\n    (png_uint_32) MagickMin(0x7fffffffL,\n        GetMagickResourceLimit(WidthResource)),\n    (png_uint_32) MagickMin(0x7fffffffL,\n        GetMagickResourceLimit(HeightResource)));\n#endif /* PNG_SET_USER_LIMITS_SUPPORTED */\n\n  /*\n    Prepare PNG for writing.\n  */\n\n#if defined(PNG_MNG_FEATURES_SUPPORTED)\n  if (mng_info->write_mng)\n  {\n     (void) png_permit_mng_features(ping,PNG_ALL_MNG_FEATURES);\n# ifdef PNG_WRITE_CHECK_FOR_INVALID_INDEX_SUPPORTED\n     /* Disable new libpng-1.5.10 feature when writing a MNG because\n      * zero-length PLTE is OK\n      */\n     png_set_check_for_invalid_index (ping, 0);\n# endif\n  }\n\n#else\n# ifdef PNG_WRITE_EMPTY_PLTE_SUPPORTED\n  if (mng_info->write_mng)\n     png_permit_empty_plte(ping,MagickTrue);\n\n# endif\n#endif\n\n  x=0;\n\n  ping_width=(png_uint_32) image->columns;\n  ping_height=(png_uint_32) image->rows;\n\n  if (mng_info->write_png8 || mng_info->write_png24 || mng_info->write_png32)\n     image_depth=8;\n\n  if (mng_info->write_png48 || mng_info->write_png64)\n     image_depth=16;\n\n  if (mng_info->write_png_depth != 0)\n     image_depth=mng_info->write_png_depth;\n\n  /* Adjust requested depth to next higher valid depth if necessary */\n  if (image_depth > 8)\n     image_depth=16;\n\n  if ((image_depth > 4) && (image_depth < 8))\n     image_depth=8;\n\n  if (image_depth == 3)\n     image_depth=4;\n\n  if (logging != MagickFalse)\n    {\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    width=%.20g\",(double) ping_width);\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    height=%.20g\",(double) ping_height);\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    image_matte=%.20g\",(double) image->alpha_trait);\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    image->depth=%.20g\",(double) image->depth);\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Tentative ping_bit_depth=%.20g\",(double) image_depth);\n    }\n\n  save_image_depth=image_depth;\n  ping_bit_depth=(png_byte) save_image_depth;\n\n\n#if defined(PNG_pHYs_SUPPORTED)\n  if (ping_exclude_pHYs == MagickFalse)\n  {\n  if ((image->resolution.x != 0) && (image->resolution.y != 0) &&\n      (!mng_info->write_mng || !mng_info->equal_physs))\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Setting up pHYs chunk\");\n\n      if (image->units == PixelsPerInchResolution)\n        {\n          ping_pHYs_unit_type=PNG_RESOLUTION_METER;\n          ping_pHYs_x_resolution=\n             (png_uint_32) ((100.0*image->resolution.x+0.5)/2.54);\n          ping_pHYs_y_resolution=\n             (png_uint_32) ((100.0*image->resolution.y+0.5)/2.54);\n        }\n\n      else if (image->units == PixelsPerCentimeterResolution)\n        {\n          ping_pHYs_unit_type=PNG_RESOLUTION_METER;\n          ping_pHYs_x_resolution=(png_uint_32) (100.0*image->resolution.x+0.5);\n          ping_pHYs_y_resolution=(png_uint_32) (100.0*image->resolution.y+0.5);\n        }\n\n      else\n        {\n          ping_pHYs_unit_type=PNG_RESOLUTION_UNKNOWN;\n          ping_pHYs_x_resolution=(png_uint_32) image->resolution.x;\n          ping_pHYs_y_resolution=(png_uint_32) image->resolution.y;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    Set up PNG pHYs chunk: xres: %.20g, yres: %.20g, units: %d.\",\n          (double) ping_pHYs_x_resolution,(double) ping_pHYs_y_resolution,\n          (int) ping_pHYs_unit_type);\n       ping_have_pHYs = MagickTrue;\n    }\n  }\n#endif\n\n  if (ping_exclude_bKGD == MagickFalse)\n  {\n  if ((!mng_info->adjoin || !mng_info->equal_backgrounds))\n    {\n       unsigned int\n         mask;\n\n       mask=0xffff;\n       if (ping_bit_depth == 8)\n          mask=0x00ff;\n\n       if (ping_bit_depth == 4)\n          mask=0x000f;\n\n       if (ping_bit_depth == 2)\n          mask=0x0003;\n\n       if (ping_bit_depth == 1)\n          mask=0x0001;\n\n       ping_background.red=(png_uint_16)\n         (ScaleQuantumToShort(image->background_color.red) & mask);\n\n       ping_background.green=(png_uint_16)\n         (ScaleQuantumToShort(image->background_color.green) & mask);\n\n       ping_background.blue=(png_uint_16)\n         (ScaleQuantumToShort(image->background_color.blue) & mask);\n\n       ping_background.gray=(png_uint_16) ping_background.green;\n    }\n\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    Setting up bKGD chunk (1)\");\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"      background_color index is %d\",\n          (int) ping_background.index);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    ping_bit_depth=%d\",ping_bit_depth);\n    }\n\n  ping_have_bKGD = MagickTrue;\n  }\n\n  /*\n    Select the color type.\n  */\n  matte=image_matte;\n  old_bit_depth=0;\n\n  if (mng_info->IsPalette && mng_info->write_png8)\n    {\n      /* To do: make this a function cause it's used twice, except\n         for reducing the sample depth from 8. */\n\n      number_colors=image_colors;\n\n      ping_have_tRNS=MagickFalse;\n\n      /*\n        Set image palette.\n      */\n      ping_color_type=(png_byte) PNG_COLOR_TYPE_PALETTE;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Setting up PLTE chunk with %d colors (%d)\",\n            number_colors, image_colors);\n\n      for (i=0; i < (ssize_t) number_colors; i++)\n      {\n        palette[i].red=ScaleQuantumToChar(image->colormap[i].red);\n        palette[i].green=ScaleQuantumToChar(image->colormap[i].green);\n        palette[i].blue=ScaleQuantumToChar(image->colormap[i].blue);\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n#if MAGICKCORE_QUANTUM_DEPTH == 8\n            \"    %3ld (%3d,%3d,%3d)\",\n#else\n            \"    %5ld (%5d,%5d,%5d)\",\n#endif\n            (long) i,palette[i].red,palette[i].green,palette[i].blue);\n\n      }\n\n      ping_have_PLTE=MagickTrue;\n      image_depth=ping_bit_depth;\n      ping_num_trans=0;\n\n      if (matte != MagickFalse)\n      {\n          /*\n            Identify which colormap entry is transparent.\n          */\n          assert(number_colors <= 256);\n          assert(image->colormap != NULL);\n\n          for (i=0; i < (ssize_t) number_transparent; i++)\n             ping_trans_alpha[i]=0;\n\n\n          ping_num_trans=(unsigned short) (number_transparent +\n             number_semitransparent);\n\n          if (ping_num_trans == 0)\n             ping_have_tRNS=MagickFalse;\n\n          else\n             ping_have_tRNS=MagickTrue;\n      }\n\n      if (ping_exclude_bKGD == MagickFalse)\n      {\n       /*\n        * Identify which colormap entry is the background color.\n        */\n\n        for (i=0; i < (ssize_t) MagickMax(1L*number_colors-1L,1L); i++)\n          if (IsPNGColorEqual(ping_background,image->colormap[i]))\n            break;\n\n        ping_background.index=(png_byte) i;\n\n        if (logging != MagickFalse)\n          {\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"      background_color index is %d\",\n                 (int) ping_background.index);\n          }\n      }\n    } /* end of write_png8 */\n\n  else if (mng_info->write_png_colortype == 1)\n    {\n      image_matte=MagickFalse;\n      ping_color_type=(png_byte) PNG_COLOR_TYPE_GRAY;\n    }\n\n  else if (mng_info->write_png24 || mng_info->write_png48 ||\n      mng_info->write_png_colortype == 3)\n    {\n      image_matte=MagickFalse;\n      ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB;\n    }\n\n  else if (mng_info->write_png32 || mng_info->write_png64 ||\n      mng_info->write_png_colortype == 7)\n    {\n      image_matte=MagickTrue;\n      ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB_ALPHA;\n    }\n\n  else /* mng_info->write_pngNN not specified */\n    {\n      image_depth=ping_bit_depth;\n\n      if (mng_info->write_png_colortype != 0)\n        {\n          ping_color_type=(png_byte) mng_info->write_png_colortype-1;\n\n          if (ping_color_type == PNG_COLOR_TYPE_GRAY_ALPHA ||\n              ping_color_type == PNG_COLOR_TYPE_RGB_ALPHA)\n            image_matte=MagickTrue;\n\n          else\n            image_matte=MagickFalse;\n\n          if (logging != MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"   PNG colortype %d was specified:\",(int) ping_color_type);\n        }\n\n      else /* write_png_colortype not specified */\n        {\n          if (logging != MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  Selecting PNG colortype:\");\n\n          ping_color_type=(png_byte) ((matte != MagickFalse)?\n            PNG_COLOR_TYPE_RGB_ALPHA:PNG_COLOR_TYPE_RGB);\n\n          if (image_info->type == TrueColorType)\n            {\n              ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB;\n              image_matte=MagickFalse;\n            }\n\n          if (image_info->type == TrueColorAlphaType)\n            {\n              ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB_ALPHA;\n              image_matte=MagickTrue;\n            }\n\n          if (image_info->type == PaletteType ||\n              image_info->type == PaletteAlphaType)\n            ping_color_type=(png_byte) PNG_COLOR_TYPE_PALETTE;\n\n          if (mng_info->write_png_colortype == 0 &&\n             image_info->type == UndefinedType)\n            {\n              if (ping_have_color == MagickFalse)\n                {\n                  if (image_matte == MagickFalse)\n                    {\n                      ping_color_type=(png_byte) PNG_COLOR_TYPE_GRAY;\n                      image_matte=MagickFalse;\n                    }\n\n                  else\n                    {\n                      ping_color_type=(png_byte) PNG_COLOR_TYPE_GRAY_ALPHA;\n                      image_matte=MagickTrue;\n                    }\n                }\n              else\n                {\n                  if (image_matte == MagickFalse)\n                    {\n                      ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB;\n                      image_matte=MagickFalse;\n                    }\n\n                  else\n                    {\n                      ping_color_type=(png_byte) PNG_COLOR_TYPE_RGBA;\n                      image_matte=MagickTrue;\n                    }\n                 }\n            }\n\n        }\n\n      if (logging != MagickFalse)\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n         \"    Selected PNG colortype=%d\",ping_color_type);\n\n      if (ping_bit_depth < 8)\n        {\n          if (ping_color_type == PNG_COLOR_TYPE_GRAY_ALPHA ||\n              ping_color_type == PNG_COLOR_TYPE_RGB ||\n              ping_color_type == PNG_COLOR_TYPE_RGB_ALPHA)\n            ping_bit_depth=8;\n        }\n\n      old_bit_depth=ping_bit_depth;\n\n      if (ping_color_type == PNG_COLOR_TYPE_GRAY)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait &&\n               ping_have_non_bw == MagickFalse)\n             ping_bit_depth=1;\n        }\n\n      if (ping_color_type == PNG_COLOR_TYPE_PALETTE)\n        {\n           size_t one = 1;\n           ping_bit_depth=1;\n\n           if (image->colors == 0)\n           {\n              /* DO SOMETHING */\n                png_error(ping,\"image has 0 colors\");\n           }\n\n           while ((int) (one << ping_bit_depth) < (ssize_t) image_colors)\n             ping_bit_depth <<= 1;\n        }\n\n      if (logging != MagickFalse)\n         {\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Number of colors: %.20g\",(double) image_colors);\n\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Tentative PNG bit depth: %d\",ping_bit_depth);\n         }\n\n      if (ping_bit_depth < (int) mng_info->write_png_depth)\n         ping_bit_depth = mng_info->write_png_depth;\n    }\n\n  image_depth=ping_bit_depth;\n\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Tentative PNG color type: %s (%.20g)\",\n        PngColorTypeToString(ping_color_type),\n        (double) ping_color_type);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    image_info->type: %.20g\",(double) image_info->type);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    image_depth: %.20g\",(double) image_depth);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n\n        \"    image->depth: %.20g\",(double) image->depth);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    ping_bit_depth: %.20g\",(double) ping_bit_depth);\n    }\n\n  if (matte != MagickFalse)\n    {\n      if (mng_info->IsPalette)\n        {\n          if (mng_info->write_png_colortype == 0)\n            {\n              ping_color_type=PNG_COLOR_TYPE_GRAY_ALPHA;\n\n              if (ping_have_color != MagickFalse)\n                 ping_color_type=PNG_COLOR_TYPE_RGBA;\n            }\n\n          /*\n           * Determine if there is any transparent color.\n          */\n          if (number_transparent + number_semitransparent == 0)\n            {\n              /*\n                No transparent pixels are present.  Change 4 or 6 to 0 or 2.\n              */\n\n              image_matte=MagickFalse;\n\n              if (mng_info->write_png_colortype == 0)\n                ping_color_type&=0x03;\n            }\n\n          else\n            {\n              unsigned int\n                mask;\n\n              mask=0xffff;\n\n              if (ping_bit_depth == 8)\n                 mask=0x00ff;\n\n              if (ping_bit_depth == 4)\n                 mask=0x000f;\n\n              if (ping_bit_depth == 2)\n                 mask=0x0003;\n\n              if (ping_bit_depth == 1)\n                 mask=0x0001;\n\n              ping_trans_color.red=(png_uint_16)\n                (ScaleQuantumToShort(image->colormap[0].red) & mask);\n\n              ping_trans_color.green=(png_uint_16)\n                (ScaleQuantumToShort(image->colormap[0].green) & mask);\n\n              ping_trans_color.blue=(png_uint_16)\n                (ScaleQuantumToShort(image->colormap[0].blue) & mask);\n\n              ping_trans_color.gray=(png_uint_16)\n                (ScaleQuantumToShort(GetPixelInfoIntensity(image,\n                   image->colormap)) & mask);\n\n              ping_trans_color.index=(png_byte) 0;\n\n              ping_have_tRNS=MagickTrue;\n            }\n\n          if (ping_have_tRNS != MagickFalse)\n            {\n              /*\n               * Determine if there is one and only one transparent color\n               * and if so if it is fully transparent.\n               */\n              if (ping_have_cheap_transparency == MagickFalse)\n                ping_have_tRNS=MagickFalse;\n            }\n\n          if (ping_have_tRNS != MagickFalse)\n            {\n              if (mng_info->write_png_colortype == 0)\n                ping_color_type &= 0x03;  /* changes 4 or 6 to 0 or 2 */\n\n              if (image_depth == 8)\n                {\n                  ping_trans_color.red&=0xff;\n                  ping_trans_color.green&=0xff;\n                  ping_trans_color.blue&=0xff;\n                  ping_trans_color.gray&=0xff;\n                }\n            }\n        }\n      else\n        {\n          if (image_depth == 8)\n            {\n              ping_trans_color.red&=0xff;\n              ping_trans_color.green&=0xff;\n              ping_trans_color.blue&=0xff;\n              ping_trans_color.gray&=0xff;\n            }\n        }\n    }\n\n    matte=image_matte;\n\n    if (ping_have_tRNS != MagickFalse)\n      image_matte=MagickFalse;\n\n    if ((mng_info->IsPalette) &&\n        mng_info->write_png_colortype-1 != PNG_COLOR_TYPE_PALETTE &&\n        ping_have_color == MagickFalse &&\n        (image_matte == MagickFalse || image_depth >= 8))\n      {\n        size_t one=1;\n\n        if (image_matte != MagickFalse)\n          ping_color_type=PNG_COLOR_TYPE_GRAY_ALPHA;\n\n        else if (mng_info->write_png_colortype-1 != PNG_COLOR_TYPE_GRAY_ALPHA)\n          {\n            ping_color_type=PNG_COLOR_TYPE_GRAY;\n\n            if (save_image_depth == 16 && image_depth == 8)\n              {\n                if (logging != MagickFalse)\n                  {\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"  Scaling ping_trans_color (0)\");\n                  }\n                    ping_trans_color.gray*=0x0101;\n              }\n          }\n\n        if (image_depth > MAGICKCORE_QUANTUM_DEPTH)\n          image_depth=MAGICKCORE_QUANTUM_DEPTH;\n\n        if ((image_colors == 0) ||\n             ((ssize_t) (image_colors-1) > (ssize_t) MaxColormapSize))\n          image_colors=(int) (one << image_depth);\n\n        if (image_depth > 8)\n          ping_bit_depth=16;\n\n        else\n          {\n            ping_bit_depth=8;\n            if ((int) ping_color_type == PNG_COLOR_TYPE_PALETTE)\n              {\n                if(!mng_info->write_png_depth)\n                  {\n                    ping_bit_depth=1;\n\n                    while ((int) (one << ping_bit_depth)\n                        < (ssize_t) image_colors)\n                      ping_bit_depth <<= 1;\n                  }\n              }\n\n            else if (ping_color_type ==\n                PNG_COLOR_TYPE_GRAY && image_colors < 17 &&\n                mng_info->IsPalette)\n              {\n              /* Check if grayscale is reducible */\n\n                int\n                  depth_4_ok=MagickTrue,\n                  depth_2_ok=MagickTrue,\n                  depth_1_ok=MagickTrue;\n\n                for (i=0; i < (ssize_t) image_colors; i++)\n                {\n                   unsigned char\n                     intensity;\n\n                   intensity=ScaleQuantumToChar(image->colormap[i].red);\n\n                   if ((intensity & 0x0f) != ((intensity & 0xf0) >> 4))\n                     depth_4_ok=depth_2_ok=depth_1_ok=MagickFalse;\n                   else if ((intensity & 0x03) != ((intensity & 0x0c) >> 2))\n                     depth_2_ok=depth_1_ok=MagickFalse;\n                   else if ((intensity & 0x01) != ((intensity & 0x02) >> 1))\n                     depth_1_ok=MagickFalse;\n                }\n\n                if (depth_1_ok && mng_info->write_png_depth <= 1)\n                  ping_bit_depth=1;\n\n                else if (depth_2_ok && mng_info->write_png_depth <= 2)\n                  ping_bit_depth=2;\n\n                else if (depth_4_ok && mng_info->write_png_depth <= 4)\n                  ping_bit_depth=4;\n              }\n          }\n\n          image_depth=ping_bit_depth;\n      }\n\n    else\n\n      if (mng_info->IsPalette)\n      {\n        number_colors=image_colors;\n\n        if (image_depth <= 8)\n          {\n            /*\n              Set image palette.\n            */\n            ping_color_type=(png_byte) PNG_COLOR_TYPE_PALETTE;\n\n            if (!(mng_info->have_write_global_plte && matte == MagickFalse))\n              {\n                for (i=0; i < (ssize_t) number_colors; i++)\n                {\n                  palette[i].red=ScaleQuantumToChar(image->colormap[i].red);\n                  palette[i].green=\n                    ScaleQuantumToChar(image->colormap[i].green);\n                  palette[i].blue=ScaleQuantumToChar(image->colormap[i].blue);\n                }\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Setting up PLTE chunk with %d colors\",\n                    number_colors);\n\n                ping_have_PLTE=MagickTrue;\n              }\n\n            /* color_type is PNG_COLOR_TYPE_PALETTE */\n            if (mng_info->write_png_depth == 0)\n              {\n                size_t\n                  one;\n\n                ping_bit_depth=1;\n                one=1;\n\n                while ((one << ping_bit_depth) < (size_t) number_colors)\n                  ping_bit_depth <<= 1;\n              }\n\n            ping_num_trans=0;\n\n            if (matte != MagickFalse)\n              {\n                /*\n                 * Set up trans_colors array.\n                 */\n                assert(number_colors <= 256);\n\n                ping_num_trans=(unsigned short) (number_transparent +\n                  number_semitransparent);\n\n                if (ping_num_trans == 0)\n                  ping_have_tRNS=MagickFalse;\n\n                else\n                  {\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  Scaling ping_trans_color (1)\");\n                      }\n                    ping_have_tRNS=MagickTrue;\n\n                    for (i=0; i < ping_num_trans; i++)\n                    {\n                       ping_trans_alpha[i]= (png_byte)\n                         ScaleQuantumToChar(image->colormap[i].alpha);\n                    }\n                  }\n              }\n          }\n      }\n\n    else\n      {\n\n        if (image_depth < 8)\n          image_depth=8;\n\n        if ((save_image_depth == 16) && (image_depth == 8))\n          {\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    Scaling ping_trans_color from (%d,%d,%d)\",\n                  (int) ping_trans_color.red,\n                  (int) ping_trans_color.green,\n                  (int) ping_trans_color.blue);\n              }\n\n            ping_trans_color.red*=0x0101;\n            ping_trans_color.green*=0x0101;\n            ping_trans_color.blue*=0x0101;\n            ping_trans_color.gray*=0x0101;\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    to (%d,%d,%d)\",\n                  (int) ping_trans_color.red,\n                  (int) ping_trans_color.green,\n                  (int) ping_trans_color.blue);\n              }\n          }\n      }\n\n    if (ping_bit_depth <  (ssize_t) mng_info->write_png_depth)\n         ping_bit_depth =  (ssize_t) mng_info->write_png_depth;\n\n    /*\n      Adjust background and transparency samples in sub-8-bit grayscale files.\n    */\n    if (ping_bit_depth < 8 && ping_color_type ==\n        PNG_COLOR_TYPE_GRAY)\n      {\n         png_uint_16\n           maxval;\n\n         size_t\n           one=1;\n\n         maxval=(png_uint_16) ((one << ping_bit_depth)-1);\n\n         if (ping_exclude_bKGD == MagickFalse)\n         {\n\n         ping_background.gray=(png_uint_16) ((maxval/65535.)*\n           (ScaleQuantumToShort(((GetPixelInfoIntensity(image,\n           &image->background_color))) +.5)));\n\n         if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  Setting up bKGD chunk (2)\");\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      background_color index is %d\",\n             (int) ping_background.index);\n\n         ping_have_bKGD = MagickTrue;\n         }\n\n         if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  Scaling ping_trans_color.gray from %d\",\n             (int)ping_trans_color.gray);\n\n         ping_trans_color.gray=(png_uint_16) ((maxval/255.)*(\n           ping_trans_color.gray)+.5);\n\n         if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      to %d\", (int)ping_trans_color.gray);\n      }\n\n  if (ping_exclude_bKGD == MagickFalse)\n  {\n    if (mng_info->IsPalette && (int) ping_color_type == PNG_COLOR_TYPE_PALETTE)\n      {\n        /*\n           Identify which colormap entry is the background color.\n        */\n\n        number_colors=image_colors;\n\n        for (i=0; i < (ssize_t) MagickMax(1L*number_colors,1L); i++)\n          if (IsPNGColorEqual(image->background_color,image->colormap[i]))\n            break;\n\n        ping_background.index=(png_byte) i;\n\n        if (logging != MagickFalse)\n          {\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  Setting up bKGD chunk with index=%d\",(int) i);\n          }\n\n        if (i < (ssize_t) number_colors)\n          {\n            ping_have_bKGD = MagickTrue;\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"     background   =(%d,%d,%d)\",\n                        (int) ping_background.red,\n                        (int) ping_background.green,\n                        (int) ping_background.blue);\n              }\n          }\n\n        else  /* Can't happen */\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      No room in PLTE to add bKGD color\");\n            ping_have_bKGD = MagickFalse;\n          }\n      }\n  }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"    PNG color type: %s (%d)\", PngColorTypeToString(ping_color_type),\n      ping_color_type);\n  /*\n    Initialize compression level and filtering.\n  */\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Setting up deflate compression\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Compression buffer size: 32768\");\n    }\n\n  png_set_compression_buffer_size(ping,32768L);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"    Compression mem level: 9\");\n\n  png_set_compression_mem_level(ping, 9);\n\n  /* Untangle the \"-quality\" setting:\n\n     Undefined is 0; the default is used.\n     Default is 75\n\n     10's digit:\n\n        0 or omitted: Use Z_HUFFMAN_ONLY strategy with the\n           zlib default compression level\n\n        1-9: the zlib compression level\n\n     1's digit:\n\n        0-4: the PNG filter method\n\n        5:   libpng adaptive filtering if compression level > 5\n             libpng filter type \"none\" if compression level <= 5\n                or if image is grayscale or palette\n\n        6:   libpng adaptive filtering\n\n        7:   \"LOCO\" filtering (intrapixel differing) if writing\n             a MNG, otherwise \"none\".  Did not work in IM-6.7.0-9\n             and earlier because of a missing \"else\".\n\n        8:   Z_RLE strategy (or Z_HUFFMAN_ONLY if quality < 10), adaptive\n             filtering. Unused prior to IM-6.7.0-10, was same as 6\n\n        9:   Z_RLE strategy (or Z_HUFFMAN_ONLY if quality < 10), no PNG filters\n             Unused prior to IM-6.7.0-10, was same as 6\n\n    Note that using the -quality option, not all combinations of\n    PNG filter type, zlib compression level, and zlib compression\n    strategy are possible.  This will be addressed soon in a\n    release that accomodates \"-define png:compression-strategy\", etc.\n\n   */\n\n  quality=image_info->quality == UndefinedCompressionQuality ? 75UL :\n     image_info->quality;\n\n  if (quality <= 9)\n    {\n      if (mng_info->write_png_compression_strategy == 0)\n        mng_info->write_png_compression_strategy = Z_HUFFMAN_ONLY+1;\n    }\n\n  else if (mng_info->write_png_compression_level == 0)\n    {\n      int\n        level;\n\n      level=(int) MagickMin((ssize_t) quality/10,9);\n\n      mng_info->write_png_compression_level = level+1;\n    }\n\n  if (mng_info->write_png_compression_strategy == 0)\n    {\n        if ((quality %10) == 8 || (quality %10) == 9)\n#ifdef Z_RLE  /* Z_RLE was added to zlib-1.2.0 */\n          mng_info->write_png_compression_strategy=Z_RLE+1;\n#else\n          mng_info->write_png_compression_strategy = Z_DEFAULT_STRATEGY+1;\n#endif\n    }\n\n  if (mng_info->write_png_compression_filter == 0)\n        mng_info->write_png_compression_filter=((int) quality % 10) + 1;\n\n  if (logging != MagickFalse)\n    {\n        if (mng_info->write_png_compression_level)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Compression level:    %d\",\n            (int) mng_info->write_png_compression_level-1);\n\n        if (mng_info->write_png_compression_strategy)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Compression strategy: %d\",\n            (int) mng_info->write_png_compression_strategy-1);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Setting up filtering\");\n\n        if (mng_info->write_png_compression_filter == 6)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Base filter method: ADAPTIVE\");\n        else if (mng_info->write_png_compression_filter == 0 ||\n                 mng_info->write_png_compression_filter == 1)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Base filter method: NONE\");\n        else\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Base filter method: %d\",\n            (int) mng_info->write_png_compression_filter-1);\n    }\n\n  if (mng_info->write_png_compression_level != 0)\n    png_set_compression_level(ping,mng_info->write_png_compression_level-1);\n\n  if (mng_info->write_png_compression_filter == 6)\n    {\n      if (((int) ping_color_type == PNG_COLOR_TYPE_GRAY) ||\n         ((int) ping_color_type == PNG_COLOR_TYPE_PALETTE) ||\n         (quality < 50))\n        png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_NO_FILTERS);\n      else\n        png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_ALL_FILTERS);\n     }\n  else if (mng_info->write_png_compression_filter == 7 ||\n      mng_info->write_png_compression_filter == 10)\n    png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_ALL_FILTERS);\n\n  else if (mng_info->write_png_compression_filter == 8)\n    {\n#if defined(PNG_MNG_FEATURES_SUPPORTED) && defined(PNG_INTRAPIXEL_DIFFERENCING)\n      if (mng_info->write_mng)\n      {\n         if (((int) ping_color_type == PNG_COLOR_TYPE_RGB) ||\n             ((int) ping_color_type == PNG_COLOR_TYPE_RGBA))\n        ping_filter_method=PNG_INTRAPIXEL_DIFFERENCING;\n      }\n#endif\n      png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_NO_FILTERS);\n    }\n\n  else if (mng_info->write_png_compression_filter == 9)\n    png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_NO_FILTERS);\n\n  else if (mng_info->write_png_compression_filter != 0)\n    png_set_filter(ping,PNG_FILTER_TYPE_BASE,\n       mng_info->write_png_compression_filter-1);\n\n  if (mng_info->write_png_compression_strategy != 0)\n    png_set_compression_strategy(ping,\n       mng_info->write_png_compression_strategy-1);\n\n  ping_interlace_method=image_info->interlace != NoInterlace;\n\n  if (mng_info->write_mng)\n    png_set_sig_bytes(ping,8);\n\n  /* Bail out if cannot meet defined png:bit-depth or png:color-type */\n\n  if (mng_info->write_png_colortype != 0)\n    {\n     if (mng_info->write_png_colortype-1 == PNG_COLOR_TYPE_GRAY)\n       if (ping_have_color != MagickFalse)\n         {\n           ping_color_type = PNG_COLOR_TYPE_RGB;\n\n           if (ping_bit_depth < 8)\n             ping_bit_depth=8;\n         }\n\n     if (mng_info->write_png_colortype-1 == PNG_COLOR_TYPE_GRAY_ALPHA)\n       if (ping_have_color != MagickFalse)\n         ping_color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n    }\n\n  if (ping_need_colortype_warning != MagickFalse ||\n     ((mng_info->write_png_depth &&\n     (int) mng_info->write_png_depth != ping_bit_depth) ||\n     (mng_info->write_png_colortype &&\n     ((int) mng_info->write_png_colortype-1 != ping_color_type &&\n      mng_info->write_png_colortype != 7 &&\n      !(mng_info->write_png_colortype == 5 && ping_color_type == 0)))))\n    {\n      if (logging != MagickFalse)\n        {\n          if (ping_need_colortype_warning != MagickFalse)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"  Image has transparency but tRNS chunk was excluded\");\n            }\n\n          if (mng_info->write_png_depth)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Defined png:bit-depth=%u, Computed depth=%u\",\n                  mng_info->write_png_depth,\n                  ping_bit_depth);\n            }\n\n          if (mng_info->write_png_colortype)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Defined png:color-type=%u, Computed color type=%u\",\n                  mng_info->write_png_colortype-1,\n                  ping_color_type);\n            }\n        }\n\n      png_warning(ping,\n        \"Cannot write image with defined png:bit-depth or png:color-type.\");\n    }\n\n  if (image_matte != MagickFalse && image->alpha_trait == UndefinedPixelTrait)\n    {\n      /* Add an opaque matte channel */\n      image->alpha_trait = BlendPixelTrait;\n      (void) SetImageAlpha(image,OpaqueAlpha,exception);\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Added an opaque matte channel\");\n    }\n\n  if (number_transparent != 0 || number_semitransparent != 0)\n    {\n      if (ping_color_type < 4)\n        {\n           ping_have_tRNS=MagickTrue;\n           if (logging != MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"  Setting ping_have_tRNS=MagickTrue.\");\n        }\n    }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Writing PNG header chunks\");\n\n  png_set_IHDR(ping,ping_info,ping_width,ping_height,\n               ping_bit_depth,ping_color_type,\n               ping_interlace_method,ping_compression_method,\n               ping_filter_method);\n\n  if (ping_color_type == 3 && ping_have_PLTE != MagickFalse)\n    {\n      png_set_PLTE(ping,ping_info,palette,number_colors);\n\n      if (logging != MagickFalse)\n        {\n          for (i=0; i< (ssize_t) number_colors; i++)\n          {\n            if (i < ping_num_trans)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"     PLTE[%d] = (%d,%d,%d), tRNS[%d] = (%d)\",\n                      (int) i,\n                      (int) palette[i].red,\n                      (int) palette[i].green,\n                      (int) palette[i].blue,\n                      (int) i,\n                      (int) ping_trans_alpha[i]);\n             else\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"     PLTE[%d] = (%d,%d,%d)\",\n                      (int) i,\n                      (int) palette[i].red,\n                      (int) palette[i].green,\n                      (int) palette[i].blue);\n           }\n         }\n    }\n\n  /* Only write the iCCP chunk if we are not writing the sRGB chunk. */\n  if (ping_exclude_sRGB != MagickFalse ||\n     (!png_get_valid(ping,ping_info,PNG_INFO_sRGB)))\n  {\n    if ((ping_exclude_tEXt == MagickFalse ||\n       ping_exclude_zTXt == MagickFalse) &&\n       (ping_exclude_iCCP == MagickFalse || ping_exclude_zCCP == MagickFalse))\n    {\n      ResetImageProfileIterator(image);\n      for (name=GetNextImageProfile(image); name != (const char *) NULL; )\n      {\n        profile=GetImageProfile(image,name);\n\n        if (profile != (StringInfo *) NULL)\n          {\n#ifdef PNG_WRITE_iCCP_SUPPORTED\n            if ((LocaleCompare(name,\"ICC\") == 0) ||\n                (LocaleCompare(name,\"ICM\") == 0))\n              {\n                ping_have_iCCP = MagickTrue;\n                if (ping_exclude_iCCP == MagickFalse)\n                  {\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"  Setting up iCCP chunk\");\n\n                    png_set_iCCP(ping,ping_info,(png_charp) name,0,\n#if (PNG_LIBPNG_VER < 10500)\n                    (png_charp) GetStringInfoDatum(profile),\n#else\n                    (const png_byte *) GetStringInfoDatum(profile),\n#endif\n                    (png_uint_32) GetStringInfoLength(profile));\n                  }\n                else\n                  {\n                    /* Do not write hex-encoded ICC chunk */\n                       name=GetNextImageProfile(image);\n                       continue;\n                  }\n              }\n#endif /* WRITE_iCCP */\n\n            if (LocaleCompare(name,\"exif\") == 0)\n              {\n                   /* Do not write hex-encoded ICC chunk; we will\n                      write it later as an eXIf chunk */\n                   name=GetNextImageProfile(image);\n                   continue;\n              }\n\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"  Setting up zTXt chunk with uuencoded %s profile\",\n                 name);\n              Magick_png_write_raw_profile(image_info,ping,ping_info,\n                (unsigned char *) name,(unsigned char *) name,\n                GetStringInfoDatum(profile),\n                (png_uint_32) GetStringInfoLength(profile));\n          }\n        name=GetNextImageProfile(image);\n      }\n    }\n  }\n\n#if defined(PNG_WRITE_sRGB_SUPPORTED)\n  if ((mng_info->have_write_global_srgb == 0) &&\n      ping_have_iCCP != MagickTrue &&\n      (ping_have_sRGB != MagickFalse ||\n      png_get_valid(ping,ping_info,PNG_INFO_sRGB)))\n    {\n      if (ping_exclude_sRGB == MagickFalse)\n        {\n          /*\n            Note image rendering intent.\n          */\n          if (logging != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Setting up sRGB chunk\");\n\n          (void) png_set_sRGB(ping,ping_info,(\n            Magick_RenderingIntent_to_PNG_RenderingIntent(\n              image->rendering_intent)));\n\n          ping_have_sRGB = MagickTrue;\n        }\n    }\n\n  if ((!mng_info->write_mng) || (!png_get_valid(ping,ping_info,PNG_INFO_sRGB)))\n#endif\n    {\n      if (ping_exclude_gAMA == MagickFalse &&\n          ping_have_iCCP == MagickFalse &&\n          ping_have_sRGB == MagickFalse &&\n          (ping_exclude_sRGB == MagickFalse ||\n          (image->gamma < .45 || image->gamma > .46)))\n      {\n      if ((mng_info->have_write_global_gama == 0) && (image->gamma != 0.0))\n        {\n          /*\n            Note image gamma.\n            To do: check for cHRM+gAMA == sRGB, and write sRGB instead.\n          */\n          if (logging != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  Setting up gAMA chunk\");\n\n          png_set_gAMA(ping,ping_info,image->gamma);\n        }\n      }\n\n      if (ping_exclude_cHRM == MagickFalse && ping_have_sRGB == MagickFalse)\n        {\n          if ((mng_info->have_write_global_chrm == 0) &&\n              (image->chromaticity.red_primary.x != 0.0))\n            {\n              /*\n                Note image chromaticity.\n                Note: if cHRM+gAMA == sRGB write sRGB instead.\n              */\n               PrimaryInfo\n                 bp,\n                 gp,\n                 rp,\n                 wp;\n\n               wp=image->chromaticity.white_point;\n               rp=image->chromaticity.red_primary;\n               gp=image->chromaticity.green_primary;\n               bp=image->chromaticity.blue_primary;\n\n               if (logging != MagickFalse)\n                 (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"  Setting up cHRM chunk\");\n\n               png_set_cHRM(ping,ping_info,wp.x,wp.y,rp.x,rp.y,gp.x,gp.y,\n                   bp.x,bp.y);\n           }\n        }\n    }\n\n  if (ping_exclude_bKGD == MagickFalse)\n    {\n      if (ping_have_bKGD != MagickFalse)\n        {\n          png_set_bKGD(ping,ping_info,&ping_background);\n          if (logging != MagickFalse)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"    Setting up bKGD chunk\");\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      background color = (%d,%d,%d)\",\n                        (int) ping_background.red,\n                        (int) ping_background.green,\n                        (int) ping_background.blue);\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      index = %d, gray=%d\",\n                        (int) ping_background.index,\n                        (int) ping_background.gray);\n            }\n         }\n    }\n\n  if (ping_exclude_pHYs == MagickFalse)\n    {\n      if (ping_have_pHYs != MagickFalse)\n        {\n          png_set_pHYs(ping,ping_info,\n             ping_pHYs_x_resolution,\n             ping_pHYs_y_resolution,\n             ping_pHYs_unit_type);\n\n          if (logging != MagickFalse)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"    Setting up pHYs chunk\");\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      x_resolution=%lu\",\n                   (unsigned long) ping_pHYs_x_resolution);\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      y_resolution=%lu\",\n                   (unsigned long) ping_pHYs_y_resolution);\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      unit_type=%lu\",\n                   (unsigned long) ping_pHYs_unit_type);\n            }\n        }\n    }\n\n#if defined(PNG_tIME_SUPPORTED)\n  if (ping_exclude_tIME == MagickFalse)\n    {\n      const char\n        *timestamp;\n\n      if (image->taint == MagickFalse)\n        {\n          timestamp=GetImageOption(image_info,\"png:tIME\");\n\n          if (timestamp == (const char *) NULL)\n            timestamp=GetImageProperty(image,\"png:tIME\",exception);\n        }\n\n      else\n        {\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  Reset tIME in tainted image\");\n\n          timestamp=GetImageProperty(image,\"date:modify\",exception);\n        }\n\n      if (timestamp != (const char *) NULL)\n          write_tIME_chunk(image,ping,ping_info,timestamp,exception);\n    }\n#endif\n\n  if (mng_info->need_blob != MagickFalse)\n  {\n    if (OpenBlob(image_info,image,WriteBinaryBlobMode,exception) ==\n       MagickFalse)\n       png_error(ping,\"WriteBlob Failed\");\n\n     ping_have_blob=MagickTrue;\n  }\n\n  png_write_info_before_PLTE(ping, ping_info);\n\n  if (ping_have_tRNS != MagickFalse && ping_color_type < 4)\n    {\n      if (logging != MagickFalse)\n        {\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  Calling png_set_tRNS with num_trans=%d\",ping_num_trans);\n        }\n\n      if (ping_color_type == 3)\n         (void) png_set_tRNS(ping, ping_info,\n                ping_trans_alpha,\n                ping_num_trans,\n                NULL);\n\n      else\n        {\n           (void) png_set_tRNS(ping, ping_info,\n                  NULL,\n                  0,\n                  &ping_trans_color);\n\n           if (logging != MagickFalse)\n             {\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"     tRNS color   =(%d,%d,%d)\",\n                       (int) ping_trans_color.red,\n                       (int) ping_trans_color.green,\n                       (int) ping_trans_color.blue);\n             }\n         }\n    }\n\n  /* write any png-chunk-b profiles */\n  (void) Magick_png_write_chunk_from_profile(image,\"PNG-chunk-b\",logging);\n\n  png_write_info(ping,ping_info);\n\n  /* write any PNG-chunk-m profiles */\n  (void) Magick_png_write_chunk_from_profile(image,\"PNG-chunk-m\",logging);\n\n  ping_wrote_caNv = MagickFalse;\n\n  /* write caNv chunk */\n  if (ping_exclude_caNv == MagickFalse)\n    {\n      if ((image->page.width != 0 && image->page.width != image->columns) ||\n          (image->page.height != 0 && image->page.height != image->rows) ||\n          image->page.x != 0 || image->page.y != 0)\n        {\n          unsigned char\n            chunk[20];\n\n          (void) WriteBlobMSBULong(image,16L);  /* data length=8 */\n          PNGType(chunk,mng_caNv);\n          LogPNGChunk(logging,mng_caNv,16L);\n          PNGLong(chunk+4,(png_uint_32) image->page.width);\n          PNGLong(chunk+8,(png_uint_32) image->page.height);\n          PNGsLong(chunk+12,(png_int_32) image->page.x);\n          PNGsLong(chunk+16,(png_int_32) image->page.y);\n          (void) WriteBlob(image,20,chunk);\n          (void) WriteBlobMSBULong(image,crc32(0,chunk,20));\n          ping_wrote_caNv = MagickTrue;\n        }\n    }\n\n#if defined(PNG_oFFs_SUPPORTED)\n  if (ping_exclude_oFFs == MagickFalse && ping_wrote_caNv == MagickFalse)\n    {\n      if (image->page.x || image->page.y)\n        {\n           png_set_oFFs(ping,ping_info,(png_int_32) image->page.x,\n              (png_int_32) image->page.y, 0);\n\n           if (logging != MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"    Setting up oFFs chunk with x=%d, y=%d, units=0\",\n                 (int) image->page.x, (int) image->page.y);\n        }\n    }\n#endif\n\n  /* write vpAg chunk (deprecated, replaced by caNv) */\n  if (ping_exclude_vpAg == MagickFalse && ping_wrote_caNv == MagickFalse)\n    {\n      if ((image->page.width != 0 && image->page.width != image->columns) ||\n          (image->page.height != 0 && image->page.height != image->rows))\n        {\n          unsigned char\n            chunk[14];\n\n          (void) WriteBlobMSBULong(image,9L);  /* data length=8 */\n          PNGType(chunk,mng_vpAg);\n          LogPNGChunk(logging,mng_vpAg,9L);\n          PNGLong(chunk+4,(png_uint_32) image->page.width);\n          PNGLong(chunk+8,(png_uint_32) image->page.height);\n          chunk[12]=0;   /* unit = pixels */\n          (void) WriteBlob(image,13,chunk);\n          (void) WriteBlobMSBULong(image,crc32(0,chunk,13));\n        }\n    }\n\n#if (PNG_LIBPNG_VER == 10206)\n    /* avoid libpng-1.2.6 bug by setting PNG_HAVE_IDAT flag */\n#define PNG_HAVE_IDAT               0x04\n    ping->mode |= PNG_HAVE_IDAT;\n#undef PNG_HAVE_IDAT\n#endif\n\n  png_set_packing(ping);\n  /*\n    Allocate memory.\n  */\n  rowbytes=image->columns;\n  if (image_depth > 8)\n    rowbytes*=2;\n  switch (ping_color_type)\n    {\n      case PNG_COLOR_TYPE_RGB:\n        rowbytes*=3;\n        break;\n\n      case PNG_COLOR_TYPE_GRAY_ALPHA:\n        rowbytes*=2;\n        break;\n\n      case PNG_COLOR_TYPE_RGBA:\n        rowbytes*=4;\n        break;\n\n      default:\n        break;\n    }\n\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Writing PNG image data\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Allocating %.20g bytes of memory for pixels\",(double) rowbytes);\n    }\n  pixel_info=AcquireVirtualMemory(rowbytes,sizeof(*ping_pixels));\n  if (pixel_info == (MemoryInfo *) NULL)\n    png_error(ping,\"Allocation of memory for pixels failed\");\n  ping_pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n\n  /*\n    Initialize image scanlines.\n  */\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    png_error(ping,\"Memory allocation for quantum_info failed\");\n  quantum_info->format=UndefinedQuantumFormat;\n  SetQuantumDepth(image,quantum_info,image_depth);\n  (void) SetQuantumEndian(image,quantum_info,MSBEndian);\n  num_passes=png_set_interlace_handling(ping);\n\n  if ((!mng_info->write_png8 && !mng_info->write_png24 &&\n       !mng_info->write_png48 && !mng_info->write_png64 &&\n       !mng_info->write_png32) &&\n       (mng_info->IsPalette ||\n       (image_info->type == BilevelType)) &&\n       image_matte == MagickFalse &&\n       ping_have_non_bw == MagickFalse)\n    {\n      /* Palette, Bilevel, or Opaque Monochrome */\n      register const Quantum\n        *p;\n\n      SetQuantumDepth(image,quantum_info,8);\n      for (pass=0; pass < num_passes; pass++)\n      {\n        /*\n          Convert PseudoClass image to a PNG monochrome image.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          if (logging != MagickFalse && y == 0)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"    Writing row of pixels (0)\");\n\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n\n          if (p == (const Quantum *) NULL)\n            break;\n\n          if (mng_info->IsPalette)\n            {\n              (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                quantum_info,GrayQuantum,ping_pixels,exception);\n              if (mng_info->write_png_colortype-1 == PNG_COLOR_TYPE_PALETTE &&\n                  mng_info->write_png_depth &&\n                  mng_info->write_png_depth != old_bit_depth)\n                {\n                  /* Undo pixel scaling */\n                  for (i=0; i < (ssize_t) image->columns; i++)\n                     *(ping_pixels+i)=(unsigned char) (*(ping_pixels+i)\n                     >> (8-old_bit_depth));\n                }\n            }\n\n          else\n            {\n              (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                quantum_info,RedQuantum,ping_pixels,exception);\n            }\n\n          if (mng_info->write_png_colortype-1 != PNG_COLOR_TYPE_PALETTE)\n            for (i=0; i < (ssize_t) image->columns; i++)\n               *(ping_pixels+i)=(unsigned char) ((*(ping_pixels+i) > 127) ?\n                      255 : 0);\n\n          if (logging != MagickFalse && y == 0)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Writing row of pixels (1)\");\n\n          png_write_row(ping,ping_pixels);\n\n          status=SetImageProgress(image,SaveImageTag,\n              (MagickOffsetType) (pass * image->rows + y),\n              num_passes * image->rows);\n\n          if (status == MagickFalse)\n            break;\n        }\n      }\n    }\n\n  else   /* Not Palette, Bilevel, or Opaque Monochrome */\n    {\n      if ((!mng_info->write_png8 && !mng_info->write_png24 &&\n          !mng_info->write_png48 && !mng_info->write_png64 &&\n          !mng_info->write_png32) && (image_matte != MagickFalse ||\n          (ping_bit_depth >= MAGICKCORE_QUANTUM_DEPTH)) &&\n          (mng_info->IsPalette) && ping_have_color == MagickFalse)\n        {\n          register const Quantum\n            *p;\n\n          for (pass=0; pass < num_passes; pass++)\n          {\n\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n\n            if (p == (const Quantum *) NULL)\n              break;\n\n            if (ping_color_type == PNG_COLOR_TYPE_GRAY)\n              {\n                if (mng_info->IsPalette)\n                  (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                    quantum_info,GrayQuantum,ping_pixels,exception);\n\n                else\n                  (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                    quantum_info,RedQuantum,ping_pixels,exception);\n\n                if (logging != MagickFalse && y == 0)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                       \"    Writing GRAY PNG pixels (2)\");\n              }\n\n            else /* PNG_COLOR_TYPE_GRAY_ALPHA */\n              {\n                if (logging != MagickFalse && y == 0)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                         \"    Writing GRAY_ALPHA PNG pixels (2)\");\n\n                (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                  quantum_info,GrayAlphaQuantum,ping_pixels,exception);\n              }\n\n            if (logging != MagickFalse && y == 0)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    Writing row of pixels (2)\");\n\n            png_write_row(ping,ping_pixels);\n\n            status=SetImageProgress(image,SaveImageTag,\n              (MagickOffsetType) (pass * image->rows + y),\n              num_passes * image->rows);\n\n            if (status == MagickFalse)\n              break;\n            }\n          }\n        }\n\n      else\n        {\n          register const Quantum\n            *p;\n\n          for (pass=0; pass < num_passes; pass++)\n          {\n            if ((image_depth > 8) ||\n                mng_info->write_png24 ||\n                mng_info->write_png32 ||\n                mng_info->write_png48 ||\n                mng_info->write_png64 ||\n                (!mng_info->write_png8 && !mng_info->IsPalette))\n            {\n              for (y=0; y < (ssize_t) image->rows; y++)\n              {\n                p=GetVirtualPixels(image,0,y,image->columns,1, exception);\n\n                if (p == (const Quantum *) NULL)\n                  break;\n\n                if (ping_color_type == PNG_COLOR_TYPE_GRAY)\n                  {\n                    if (image->storage_class == DirectClass)\n                      (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                        quantum_info,RedQuantum,ping_pixels,exception);\n\n                    else\n                      (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                        quantum_info,GrayQuantum,ping_pixels,exception);\n                  }\n\n                else if (ping_color_type == PNG_COLOR_TYPE_GRAY_ALPHA)\n                  {\n                    (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                      quantum_info,GrayAlphaQuantum,ping_pixels,\n                      exception);\n\n                    if (logging != MagickFalse && y == 0)\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                           \"    Writing GRAY_ALPHA PNG pixels (3)\");\n                  }\n\n                else if (image_matte != MagickFalse)\n                  (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                    quantum_info,RGBAQuantum,ping_pixels,exception);\n\n                else\n                  (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                    quantum_info,RGBQuantum,ping_pixels,exception);\n\n                if (logging != MagickFalse && y == 0)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"    Writing row of pixels (3)\");\n\n                png_write_row(ping,ping_pixels);\n\n                status=SetImageProgress(image,SaveImageTag,\n                  (MagickOffsetType) (pass * image->rows + y),\n                  num_passes * image->rows);\n\n                if (status == MagickFalse)\n                  break;\n              }\n            }\n\n          else\n            /* not ((image_depth > 8) ||\n                mng_info->write_png24 || mng_info->write_png32 ||\n                mng_info->write_png48 || mng_info->write_png64 ||\n                (!mng_info->write_png8 && !mng_info->IsPalette))\n             */\n            {\n              if ((ping_color_type != PNG_COLOR_TYPE_GRAY) &&\n                  (ping_color_type != PNG_COLOR_TYPE_GRAY_ALPHA))\n                {\n                  if (logging != MagickFalse)\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"  pass %d, Image Is not GRAY or GRAY_ALPHA\",pass);\n\n                  SetQuantumDepth(image,quantum_info,8);\n                  image_depth=8;\n                }\n\n              for (y=0; y < (ssize_t) image->rows; y++)\n              {\n                if (logging != MagickFalse && y == 0)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  pass %d, Image Is RGB, 16-bit GRAY, or GRAY_ALPHA\",\n                    pass);\n\n                p=GetVirtualPixels(image,0,y,image->columns,1, exception);\n\n                if (p == (const Quantum *) NULL)\n                  break;\n\n                if (ping_color_type == PNG_COLOR_TYPE_GRAY)\n                  {\n                    SetQuantumDepth(image,quantum_info,image->depth);\n\n                    (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                       quantum_info,GrayQuantum,ping_pixels,exception);\n                  }\n\n                else if (ping_color_type == PNG_COLOR_TYPE_GRAY_ALPHA)\n                  {\n                    if (logging != MagickFalse && y == 0)\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                           \"  Writing GRAY_ALPHA PNG pixels (4)\");\n\n                    (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                         quantum_info,GrayAlphaQuantum,ping_pixels,\n                         exception);\n                  }\n\n                else\n                  {\n                    (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                      quantum_info,IndexQuantum,ping_pixels,exception);\n\n                    if (logging != MagickFalse && y <= 2)\n                    {\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  Writing row of non-gray pixels (4)\");\n\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ping_pixels[0]=%d,ping_pixels[1]=%d\",\n                          (int)ping_pixels[0],(int)ping_pixels[1]);\n                    }\n                  }\n                png_write_row(ping,ping_pixels);\n\n                status=SetImageProgress(image,SaveImageTag,\n                  (MagickOffsetType) (pass * image->rows + y),\n                  num_passes * image->rows);\n\n                if (status == MagickFalse)\n                  break;\n              }\n            }\n          }\n        }\n    }\n\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\n\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Wrote PNG image data\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Width: %.20g\",(double) ping_width);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Height: %.20g\",(double) ping_height);\n\n      if (mng_info->write_png_depth)\n        {\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Defined png:bit-depth: %d\",mng_info->write_png_depth);\n        }\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    PNG bit-depth written: %d\",ping_bit_depth);\n\n      if (mng_info->write_png_colortype)\n        {\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Defined png:color-type: %d\",mng_info->write_png_colortype-1);\n        }\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    PNG color-type written: %d\",ping_color_type);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    PNG Interlace method: %d\",ping_interlace_method);\n    }\n  /*\n    Generate text chunks after IDAT.\n  */\n  if (ping_exclude_tEXt == MagickFalse || ping_exclude_zTXt == MagickFalse)\n  {\n    ResetImagePropertyIterator(image);\n    property=GetNextImageProperty(image);\n    while (property != (const char *) NULL)\n    {\n      png_textp\n        text;\n\n      value=GetImageProperty(image,property,exception);\n\n      /* Don't write any \"png:\" or \"jpeg:\" properties; those are just for\n       * \"identify\" or for passing through to another JPEG\n       */\n      if ((LocaleNCompare(property,\"png:\",4) != 0 &&\n           LocaleNCompare(property,\"jpeg:\",5) != 0) &&\n\n\n          /* Suppress density and units if we wrote a pHYs chunk */\n          (ping_exclude_pHYs != MagickFalse      ||\n          LocaleCompare(property,\"density\") != 0 ||\n          LocaleCompare(property,\"units\") != 0) &&\n\n          /* Suppress the IM-generated Date:create and Date:modify */\n          (ping_exclude_date == MagickFalse      ||\n          LocaleNCompare(property, \"Date:\",5) != 0))\n        {\n        if (value != (const char *) NULL)\n          {\n\n#if PNG_LIBPNG_VER >= 10400\n            text=(png_textp) png_malloc(ping,\n                 (png_alloc_size_t) sizeof(png_text));\n#else\n            text=(png_textp) png_malloc(ping,(png_size_t) sizeof(png_text));\n#endif\n            text[0].key=(char *) property;\n            text[0].text=(char *) value;\n            text[0].text_length=strlen(value);\n\n            if (ping_exclude_tEXt != MagickFalse)\n               text[0].compression=PNG_TEXT_COMPRESSION_zTXt;\n\n            else if (ping_exclude_zTXt != MagickFalse)\n               text[0].compression=PNG_TEXT_COMPRESSION_NONE;\n\n            else\n            {\n               text[0].compression=image_info->compression == NoCompression ||\n                 (image_info->compression == UndefinedCompression &&\n                 text[0].text_length < 128) ? PNG_TEXT_COMPRESSION_NONE :\n                 PNG_TEXT_COMPRESSION_zTXt ;\n            }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Setting up text chunk\");\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    keyword: '%s'\",text[0].key);\n              }\n\n            png_set_text(ping,ping_info,text,1);\n            png_free(ping,text);\n          }\n        }\n      property=GetNextImageProperty(image);\n    }\n  }\n\n  /* write any PNG-chunk-e profiles */\n  (void) Magick_png_write_chunk_from_profile(image,\"PNG-chunk-e\",logging);\n\n  /* write exIf profile */\n  if (ping_have_eXIf != MagickFalse && ping_exclude_eXIf == MagickFalse)\n    {\n      char\n        *name;\n\n      ResetImageProfileIterator(image);\n\n      for (name=GetNextImageProfile(image); name != (const char *) NULL; )\n      {\n        if (LocaleCompare(name,\"exif\") == 0)\n          {\n            const StringInfo\n              *profile;\n\n            profile=GetImageProfile(image,name);\n\n            if (profile != (StringInfo *) NULL)\n              {\n                png_uint_32\n                  length;\n\n                unsigned char\n                  chunk[4],\n                  *data;\n\n               StringInfo\n                 *ping_profile;\n\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Have eXIf profile\");\n\n               ping_profile=CloneStringInfo(profile);\n               data=GetStringInfoDatum(ping_profile),\n               length=(png_uint_32) GetStringInfoLength(ping_profile);\n\n               PNGType(chunk,mng_eXIf);\n               if (length < 7)\n                 {\n                   ping_profile=DestroyStringInfo(ping_profile);\n                   break;  /* otherwise crashes */\n                 }\n\n               /* skip the \"Exif\\0\\0\" JFIF Exif Header ID */\n               length -= 6;\n\n               LogPNGChunk(logging,chunk,length);\n               (void) WriteBlobMSBULong(image,length);\n               (void) WriteBlob(image,4,chunk);\n               (void) WriteBlob(image,length,data+6);\n               (void) WriteBlobMSBULong(image,crc32(crc32(0,chunk,4),\n                 data+6, (uInt) length));\n               ping_profile=DestroyStringInfo(ping_profile);\n               break;\n             }\n         }\n       name=GetNextImageProfile(image);\n     }\n  }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Writing PNG end info\");\n\n  png_write_end(ping,ping_info);\n\n  if (mng_info->need_fram && (int) image->dispose == BackgroundDispose)\n    {\n      if (mng_info->page.x || mng_info->page.y ||\n          (ping_width != mng_info->page.width) ||\n          (ping_height != mng_info->page.height))\n        {\n          unsigned char\n            chunk[32];\n\n          /*\n            Write FRAM 4 with clipping boundaries followed by FRAM 1.\n          */\n          (void) WriteBlobMSBULong(image,27L);  /* data length=27 */\n          PNGType(chunk,mng_FRAM);\n          LogPNGChunk(logging,mng_FRAM,27L);\n          chunk[4]=4;\n          chunk[5]=0;  /* frame name separator (no name) */\n          chunk[6]=1;  /* flag for changing delay, for next frame only */\n          chunk[7]=0;  /* flag for changing frame timeout */\n          chunk[8]=1;  /* flag for changing frame clipping for next frame */\n          chunk[9]=0;  /* flag for changing frame sync_id */\n          PNGLong(chunk+10,(png_uint_32) (0L)); /* temporary 0 delay */\n          chunk[14]=0; /* clipping boundaries delta type */\n          PNGLong(chunk+15,(png_uint_32) (mng_info->page.x)); /* left cb */\n          PNGLong(chunk+19,\n             (png_uint_32) (mng_info->page.x + ping_width));\n          PNGLong(chunk+23,(png_uint_32) (mng_info->page.y)); /* top cb */\n          PNGLong(chunk+27,\n             (png_uint_32) (mng_info->page.y + ping_height));\n          (void) WriteBlob(image,31,chunk);\n          (void) WriteBlobMSBULong(image,crc32(0,chunk,31));\n          mng_info->old_framing_mode=4;\n          mng_info->framing_mode=1;\n        }\n\n      else\n        mng_info->framing_mode=3;\n    }\n  if (mng_info->write_mng && !mng_info->need_fram &&\n      ((int) image->dispose == 3))\n     png_error(ping, \"Cannot convert GIF with disposal method 3 to MNG-LC\");\n\n  /*\n    Free PNG resources.\n  */\n\n  png_destroy_write_struct(&ping,&ping_info);\n\n  pixel_info=RelinquishVirtualMemory(pixel_info);\n\n  if (ping_have_blob != MagickFalse)\n     (void) CloseBlob(image);\n\n  image_info=DestroyImageInfo(image_info);\n  image=DestroyImage(image);\n\n  /* Store bit depth actually written */\n  s[0]=(char) ping_bit_depth;\n  s[1]='\\0';\n\n  (void) SetImageProperty(IMimage,\"png:bit-depth-written\",s,exception);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit WriteOnePNGImage()\");\n\n#ifdef IMPNG_SETJMP_NOT_THREAD_SAFE\n  UnlockSemaphoreInfo(ping_semaphore);\n#endif\n\n   /* }  for navigation to beginning of SETJMP-protected block. Revert to\n    *    Throwing an Exception when an error occurs.\n    */\n\n  return(MagickTrue);\n/*  End write one PNG image */\n\n}", "func_src_after": "static MagickBooleanType WriteOnePNGImage(MngInfo *mng_info,\n  const ImageInfo *IMimage_info,Image *IMimage,ExceptionInfo *exception)\n{\n  char\n    im_vers[32],\n    libpng_runv[32],\n    libpng_vers[32],\n    zlib_runv[32],\n    zlib_vers[32];\n\n  Image\n    *image;\n\n  ImageInfo\n    *image_info;\n\n  char\n    s[2];\n\n  const char\n    *name,\n    *property,\n    *value;\n\n  const StringInfo\n    *profile;\n\n  int\n    num_passes,\n    pass,\n    ping_wrote_caNv;\n\n  png_byte\n     ping_trans_alpha[256];\n\n  png_color\n     palette[257];\n\n  png_color_16\n    ping_background,\n    ping_trans_color;\n\n  png_info\n    *ping_info;\n\n  png_struct\n    *ping;\n\n  png_uint_32\n    ping_height,\n    ping_width;\n\n  ssize_t\n    y;\n\n  MagickBooleanType\n    image_matte,\n    logging,\n    matte,\n\n    ping_have_blob,\n    ping_have_cheap_transparency,\n    ping_have_color,\n    ping_have_non_bw,\n    ping_have_PLTE,\n    ping_have_bKGD,\n    ping_have_eXIf,\n    ping_have_iCCP,\n    ping_have_pHYs,\n    ping_have_sRGB,\n    ping_have_tRNS,\n\n    ping_exclude_bKGD,\n    ping_exclude_cHRM,\n    ping_exclude_date,\n    /* ping_exclude_EXIF, */\n    ping_exclude_eXIf,\n    ping_exclude_gAMA,\n    ping_exclude_iCCP,\n    /* ping_exclude_iTXt, */\n    ping_exclude_oFFs,\n    ping_exclude_pHYs,\n    ping_exclude_sRGB,\n    ping_exclude_tEXt,\n    ping_exclude_tIME,\n    /* ping_exclude_tRNS, */\n    ping_exclude_vpAg,\n    ping_exclude_caNv,\n    ping_exclude_zCCP, /* hex-encoded iCCP */\n    ping_exclude_zTXt,\n\n    ping_preserve_colormap,\n    ping_preserve_iCCP,\n    ping_need_colortype_warning,\n\n    status,\n    tried_332,\n    tried_333,\n    tried_444;\n\n  MemoryInfo\n    *volatile pixel_info;\n\n  QuantumInfo\n    *quantum_info;\n\n  PNGErrorInfo\n    error_info;\n\n  register ssize_t\n    i,\n    x;\n\n  unsigned char\n    *ping_pixels;\n\n  volatile int\n    image_colors,\n    ping_bit_depth,\n    ping_color_type,\n    ping_interlace_method,\n    ping_compression_method,\n    ping_filter_method,\n    ping_num_trans;\n\n  volatile size_t\n    image_depth,\n    old_bit_depth;\n\n  size_t\n    quality,\n    rowbytes,\n    save_image_depth;\n\n  int\n    j,\n    number_colors,\n    number_opaque,\n    number_semitransparent,\n    number_transparent,\n    ping_pHYs_unit_type;\n\n  png_uint_32\n    ping_pHYs_x_resolution,\n    ping_pHYs_y_resolution;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter WriteOnePNGImage()\");\n\n  image = CloneImage(IMimage,0,0,MagickFalse,exception);\n  if (image == (Image *) NULL)\n    return(MagickFalse);\n  image_info=(ImageInfo *) CloneImageInfo(IMimage_info);\n  if (image_info == (ImageInfo *) NULL)\n    ThrowWriterException(ResourceLimitError, \"MemoryAllocationFailed\");\n\n  /* Define these outside of the following \"if logging()\" block so they will\n   * show in debuggers.\n   */\n  *im_vers='\\0';\n  (void) ConcatenateMagickString(im_vers,\n         MagickLibVersionText,MagickPathExtent);\n  (void) ConcatenateMagickString(im_vers,\n         MagickLibAddendum,MagickPathExtent);\n\n  *libpng_vers='\\0';\n  (void) ConcatenateMagickString(libpng_vers,\n         PNG_LIBPNG_VER_STRING,32);\n  *libpng_runv='\\0';\n  (void) ConcatenateMagickString(libpng_runv,\n         png_get_libpng_ver(NULL),32);\n\n  *zlib_vers='\\0';\n  (void) ConcatenateMagickString(zlib_vers,\n         ZLIB_VERSION,32);\n  *zlib_runv='\\0';\n  (void) ConcatenateMagickString(zlib_runv,\n         zlib_version,32);\n\n  if (logging != MagickFalse)\n    {\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"    IM version     = %s\",\n           im_vers);\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"    Libpng version = %s\",\n           libpng_vers);\n       if (LocaleCompare(libpng_vers,libpng_runv) != 0)\n       {\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"      running with   %s\",\n           libpng_runv);\n       }\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"    Zlib version   = %s\",\n           zlib_vers);\n       if (LocaleCompare(zlib_vers,zlib_runv) != 0)\n       {\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"      running with   %s\",\n           zlib_runv);\n       }\n    }\n\n  /* Initialize some stuff */\n  ping_bit_depth=0,\n  ping_color_type=0,\n  ping_interlace_method=0,\n  ping_compression_method=0,\n  ping_filter_method=0,\n  ping_num_trans = 0;\n\n  ping_background.red = 0;\n  ping_background.green = 0;\n  ping_background.blue = 0;\n  ping_background.gray = 0;\n  ping_background.index = 0;\n\n  ping_trans_color.red=0;\n  ping_trans_color.green=0;\n  ping_trans_color.blue=0;\n  ping_trans_color.gray=0;\n\n  ping_pHYs_unit_type = 0;\n  ping_pHYs_x_resolution = 0;\n  ping_pHYs_y_resolution = 0;\n\n  ping_have_blob=MagickFalse;\n  ping_have_cheap_transparency=MagickFalse;\n  ping_have_color=MagickTrue;\n  ping_have_non_bw=MagickTrue;\n  ping_have_PLTE=MagickFalse;\n  ping_have_bKGD=MagickFalse;\n  ping_have_eXIf=MagickTrue;\n  ping_have_iCCP=MagickFalse;\n  ping_have_pHYs=MagickFalse;\n  ping_have_sRGB=MagickFalse;\n  ping_have_tRNS=MagickFalse;\n\n  ping_exclude_bKGD=mng_info->ping_exclude_bKGD;\n  ping_exclude_caNv=mng_info->ping_exclude_caNv;\n  ping_exclude_cHRM=mng_info->ping_exclude_cHRM;\n  ping_exclude_date=mng_info->ping_exclude_date;\n  ping_exclude_eXIf=mng_info->ping_exclude_eXIf;\n  ping_exclude_gAMA=mng_info->ping_exclude_gAMA;\n  ping_exclude_iCCP=mng_info->ping_exclude_iCCP;\n  /* ping_exclude_iTXt=mng_info->ping_exclude_iTXt; */\n  ping_exclude_oFFs=mng_info->ping_exclude_oFFs;\n  ping_exclude_pHYs=mng_info->ping_exclude_pHYs;\n  ping_exclude_sRGB=mng_info->ping_exclude_sRGB;\n  ping_exclude_tEXt=mng_info->ping_exclude_tEXt;\n  ping_exclude_tIME=mng_info->ping_exclude_tIME;\n  /* ping_exclude_tRNS=mng_info->ping_exclude_tRNS; */\n  ping_exclude_vpAg=mng_info->ping_exclude_vpAg;\n  ping_exclude_zCCP=mng_info->ping_exclude_zCCP; /* hex-encoded iCCP in zTXt */\n  ping_exclude_zTXt=mng_info->ping_exclude_zTXt;\n\n  ping_preserve_colormap = mng_info->ping_preserve_colormap;\n  ping_preserve_iCCP = mng_info->ping_preserve_iCCP;\n  ping_need_colortype_warning = MagickFalse;\n\n  /* Recognize the ICC sRGB profile and convert it to the sRGB chunk,\n   * i.e., eliminate the ICC profile and set image->rendering_intent.\n   * Note that this will not involve any changes to the actual pixels\n   * but merely passes information to applications that read the resulting\n   * PNG image.\n   *\n   * To do: recognize other variants of the sRGB profile, using the CRC to\n   * verify all recognized variants including the 7 already known.\n   *\n   * Work around libpng16+ rejecting some \"known invalid sRGB profiles\".\n   *\n   * Use something other than image->rendering_intent to record the fact\n   * that the sRGB profile was found.\n   *\n   * Record the ICC version (currently v2 or v4) of the incoming sRGB ICC\n   * profile.  Record the Blackpoint Compensation, if any.\n   */\n   if (ping_exclude_sRGB == MagickFalse && ping_preserve_iCCP == MagickFalse)\n   {\n      char\n        *name;\n\n      const StringInfo\n        *profile;\n\n      ResetImageProfileIterator(image);\n      for (name=GetNextImageProfile(image); name != (const char *) NULL; )\n      {\n        profile=GetImageProfile(image,name);\n\n        if (profile != (StringInfo *) NULL)\n          {\n            if ((LocaleCompare(name,\"ICC\") == 0) ||\n                (LocaleCompare(name,\"ICM\") == 0))\n\n             {\n                 int\n                   icheck,\n                   got_crc=0;\n\n\n                 png_uint_32\n                   length,\n                   profile_crc=0;\n\n                 unsigned char\n                   *data;\n\n                 length=(png_uint_32) GetStringInfoLength(profile);\n\n                 for (icheck=0; sRGB_info[icheck].len > 0; icheck++)\n                 {\n                   if (length == sRGB_info[icheck].len)\n                   {\n                     if (got_crc == 0)\n                     {\n                       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                         \"    Got a %lu-byte ICC profile (potentially sRGB)\",\n                         (unsigned long) length);\n\n                       data=GetStringInfoDatum(profile);\n                       profile_crc=crc32(0,data,length);\n\n                       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                           \"      with crc=%8x\",(unsigned int) profile_crc);\n                       got_crc++;\n                     }\n\n                     if (profile_crc == sRGB_info[icheck].crc)\n                     {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"      It is sRGB with rendering intent = %s\",\n                        Magick_RenderingIntentString_from_PNG_RenderingIntent(\n                             sRGB_info[icheck].intent));\n                        if (image->rendering_intent==UndefinedIntent)\n                        {\n                          image->rendering_intent=\n                          Magick_RenderingIntent_from_PNG_RenderingIntent(\n                             sRGB_info[icheck].intent);\n                        }\n                        ping_exclude_iCCP = MagickTrue;\n                        ping_exclude_zCCP = MagickTrue;\n                        ping_have_sRGB = MagickTrue;\n                        break;\n                     }\n                   }\n                 }\n                 if (sRGB_info[icheck].len == 0)\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"    Got %lu-byte ICC profile not recognized as sRGB\",\n                        (unsigned long) length);\n              }\n          }\n        name=GetNextImageProfile(image);\n      }\n  }\n\n  number_opaque = 0;\n  number_semitransparent = 0;\n  number_transparent = 0;\n\n  if (logging != MagickFalse)\n    {\n      if (image->storage_class == UndefinedClass)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    image->storage_class=UndefinedClass\");\n      if (image->storage_class == DirectClass)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    image->storage_class=DirectClass\");\n      if (image->storage_class == PseudoClass)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    image->storage_class=PseudoClass\");\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(), image->taint ?\n          \"    image->taint=MagickTrue\":\n          \"    image->taint=MagickFalse\");\n    }\n\n  if (image->storage_class == PseudoClass &&\n     (mng_info->write_png8 || mng_info->write_png24 || mng_info->write_png32 ||\n     mng_info->write_png48 || mng_info->write_png64 ||\n     (mng_info->write_png_colortype != 1 &&\n     mng_info->write_png_colortype != 5)))\n    {\n      (void) SyncImage(image,exception);\n      image->storage_class = DirectClass;\n    }\n\n  if (ping_preserve_colormap == MagickFalse)\n    {\n      if (image->storage_class != PseudoClass && image->colormap != NULL)\n        {\n          /* Free the bogus colormap; it can cause trouble later */\n           if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Freeing bogus colormap\");\n           (void) RelinquishMagickMemory(image->colormap);\n           image->colormap=NULL;\n        }\n    }\n\n  if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n    (void) TransformImageColorspace(image,sRGBColorspace,exception);\n\n  /*\n    Sometimes we get PseudoClass images whose RGB values don't match\n    the colors in the colormap.  This code syncs the RGB values.\n  */\n  if (image->depth <= 8 && image->taint && image->storage_class == PseudoClass)\n     (void) SyncImage(image,exception);\n\n#if (MAGICKCORE_QUANTUM_DEPTH == 8)\n  if (image->depth > 8)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    Reducing PNG bit depth to 8 since this is a Q8 build.\");\n\n      image->depth=8;\n    }\n#endif\n\n  /* Respect the -depth option */\n  if (image->depth < 4)\n    {\n       register Quantum\n         *r;\n\n       if (image->depth > 2)\n         {\n           /* Scale to 4-bit */\n           LBR04PacketRGBO(image->background_color);\n\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n             if (r == (Quantum *) NULL)\n               break;\n\n             for (x=0; x < (ssize_t) image->columns; x++)\n             {\n                LBR04PixelRGBA(r);\n                r+=GetPixelChannels(image);\n             }\n\n             if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n           }\n\n           if (image->storage_class == PseudoClass && image->colormap != NULL)\n           {\n             for (i=0; i < (ssize_t) image->colors; i++)\n             {\n               LBR04PacketRGBO(image->colormap[i]);\n             }\n           }\n         }\n       else if (image->depth > 1)\n         {\n           /* Scale to 2-bit */\n           LBR02PacketRGBO(image->background_color);\n\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n             if (r == (Quantum *) NULL)\n               break;\n\n             for (x=0; x < (ssize_t) image->columns; x++)\n             {\n                LBR02PixelRGBA(r);\n                r+=GetPixelChannels(image);\n             }\n\n             if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n           }\n\n           if (image->storage_class == PseudoClass && image->colormap != NULL)\n           {\n             for (i=0; i < (ssize_t) image->colors; i++)\n             {\n               LBR02PacketRGBO(image->colormap[i]);\n             }\n           }\n         }\n       else\n         {\n           /* Scale to 1-bit */\n           LBR01PacketRGBO(image->background_color);\n\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n             if (r == (Quantum *) NULL)\n               break;\n\n             for (x=0; x < (ssize_t) image->columns; x++)\n             {\n                LBR01PixelRGBA(r);\n                r+=GetPixelChannels(image);\n             }\n\n             if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n           }\n\n           if (image->storage_class == PseudoClass && image->colormap != NULL)\n           {\n             for (i=0; i < (ssize_t) image->colors; i++)\n             {\n               LBR01PacketRGBO(image->colormap[i]);\n             }\n           }\n         }\n    }\n\n  /* To do: set to next higher multiple of 8 */\n  if (image->depth < 8)\n     image->depth=8;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n  /* PNG does not handle depths greater than 16 so reduce it even\n   * if lossy\n   */\n  if (image->depth > 8)\n      image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n  if (image->depth > 8)\n    {\n      /* To do: fill low byte properly */\n      image->depth=16;\n    }\n\n  if (image->depth == 16 && mng_info->write_png_depth != 16)\n    if (mng_info->write_png8 ||\n        LosslessReduceDepthOK(image,exception) != MagickFalse)\n      image->depth = 8;\n#endif\n\n  image_colors = (int) image->colors;\n  number_opaque = (int) image->colors;\n  number_transparent = 0;\n  number_semitransparent = 0;\n\n  if (mng_info->write_png_colortype &&\n     (mng_info->write_png_colortype > 4 || (mng_info->write_png_depth >= 8 &&\n     mng_info->write_png_colortype < 4 &&\n     image->alpha_trait == UndefinedPixelTrait)))\n  {\n     /* Avoid the expensive BUILD_PALETTE operation if we're sure that we\n      * are not going to need the result.\n      */\n     if (mng_info->write_png_colortype == 1 ||\n        mng_info->write_png_colortype == 5)\n       ping_have_color=MagickFalse;\n\n     if (image->alpha_trait != UndefinedPixelTrait)\n       {\n         number_transparent = 2;\n         number_semitransparent = 1;\n       }\n  }\n\n  if (mng_info->write_png_colortype < 7)\n  {\n  /* BUILD_PALETTE\n   *\n   * Normally we run this just once, but in the case of writing PNG8\n   * we reduce the transparency to binary and run again, then if there\n   * are still too many colors we reduce to a simple 4-4-4-1, then 3-3-3-1\n   * RGBA palette and run again, and then to a simple 3-3-2-1 RGBA\n   * palette.  Then (To do) we take care of a final reduction that is only\n   * needed if there are still 256 colors present and one of them has both\n   * transparent and opaque instances.\n   */\n\n  tried_332 = MagickFalse;\n  tried_333 = MagickFalse;\n  tried_444 = MagickFalse;\n\n  for (j=0; j<6; j++)\n  {\n    /*\n     * Sometimes we get DirectClass images that have 256 colors or fewer.\n     * This code will build a colormap.\n     *\n     * Also, sometimes we get PseudoClass images with an out-of-date\n     * colormap.  This code will replace the colormap with a new one.\n     * Sometimes we get PseudoClass images that have more than 256 colors.\n     * This code will delete the colormap and change the image to\n     * DirectClass.\n     *\n     * If image->alpha_trait is MagickFalse, we ignore the alpha channel\n     * even though it sometimes contains left-over non-opaque values.\n     *\n     * Also we gather some information (number of opaque, transparent,\n     * and semitransparent pixels, and whether the image has any non-gray\n     * pixels or only black-and-white pixels) that we might need later.\n     *\n     * Even if the user wants to force GrayAlpha or RGBA (colortype 4 or 6)\n     * we need to check for bogus non-opaque values, at least.\n     */\n\n   int\n     n;\n\n   PixelInfo\n     opaque[260],\n     semitransparent[260],\n     transparent[260];\n\n   register const Quantum\n     *s;\n\n   register Quantum\n     *q,\n     *r;\n\n   if (logging != MagickFalse)\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n         \"    Enter BUILD_PALETTE:\");\n\n   if (logging != MagickFalse)\n     {\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      image->columns=%.20g\",(double) image->columns);\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      image->rows=%.20g\",(double) image->rows);\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      image->alpha_trait=%.20g\",(double) image->alpha_trait);\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      image->depth=%.20g\",(double) image->depth);\n\n       if (image->storage_class == PseudoClass && image->colormap != NULL)\n       {\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      Original colormap:\");\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"        i    (red,green,blue,alpha)\");\n\n         for (i=0; i < 256; i++)\n         {\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"        %d    (%d,%d,%d,%d)\",\n                    (int) i,\n                    (int) image->colormap[i].red,\n                    (int) image->colormap[i].green,\n                    (int) image->colormap[i].blue,\n                    (int) image->colormap[i].alpha);\n         }\n\n         for (i=image->colors - 10; i < (ssize_t) image->colors; i++)\n         {\n           if (i > 255)\n             {\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"        %d    (%d,%d,%d,%d)\",\n                    (int) i,\n                    (int) image->colormap[i].red,\n                    (int) image->colormap[i].green,\n                    (int) image->colormap[i].blue,\n                    (int) image->colormap[i].alpha);\n             }\n         }\n       }\n\n       (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"      image->colors=%d\",(int) image->colors);\n\n       if (image->colors == 0)\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"        (zero means unknown)\");\n\n       if (ping_preserve_colormap == MagickFalse)\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"      Regenerate the colormap\");\n     }\n\n     image_colors=0;\n     number_opaque = 0;\n     number_semitransparent = 0;\n     number_transparent = 0;\n\n     for (y=0; y < (ssize_t) image->rows; y++)\n     {\n       q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n       if (q == (Quantum *) NULL)\n         break;\n\n       for (x=0; x < (ssize_t) image->columns; x++)\n       {\n           if (image->alpha_trait == UndefinedPixelTrait ||\n              GetPixelAlpha(image,q) == OpaqueAlpha)\n             {\n               if (number_opaque < 259)\n                 {\n                   if (number_opaque == 0)\n                     {\n                       GetPixelInfoPixel(image, q, opaque);\n                       opaque[0].alpha=OpaqueAlpha;\n                       number_opaque=1;\n                     }\n\n                   for (i=0; i< (ssize_t) number_opaque; i++)\n                     {\n                       if (Magick_png_color_equal(image,q,opaque+i))\n                         break;\n                     }\n\n                   if (i ==  (ssize_t) number_opaque && number_opaque < 259)\n                     {\n                       number_opaque++;\n                       GetPixelInfoPixel(image, q, opaque+i);\n                       opaque[i].alpha=OpaqueAlpha;\n                     }\n                 }\n             }\n           else if (GetPixelAlpha(image,q) == TransparentAlpha)\n             {\n               if (number_transparent < 259)\n                 {\n                   if (number_transparent == 0)\n                     {\n                       GetPixelInfoPixel(image, q, transparent);\n                       ping_trans_color.red=(unsigned short)\n                         GetPixelRed(image,q);\n                       ping_trans_color.green=(unsigned short)\n                         GetPixelGreen(image,q);\n                       ping_trans_color.blue=(unsigned short)\n                         GetPixelBlue(image,q);\n                       ping_trans_color.gray=(unsigned short)\n                         GetPixelGray(image,q);\n                       number_transparent = 1;\n                     }\n\n                   for (i=0; i< (ssize_t) number_transparent; i++)\n                     {\n                       if (Magick_png_color_equal(image,q,transparent+i))\n                         break;\n                     }\n\n                   if (i ==  (ssize_t) number_transparent &&\n                       number_transparent < 259)\n                     {\n                       number_transparent++;\n                       GetPixelInfoPixel(image,q,transparent+i);\n                     }\n                 }\n             }\n           else\n             {\n               if (number_semitransparent < 259)\n                 {\n                   if (number_semitransparent == 0)\n                     {\n                       GetPixelInfoPixel(image,q,semitransparent);\n                       number_semitransparent = 1;\n                     }\n\n                   for (i=0; i< (ssize_t) number_semitransparent; i++)\n                     {\n                       if (Magick_png_color_equal(image,q,semitransparent+i)\n                           && GetPixelAlpha(image,q) ==\n                           semitransparent[i].alpha)\n                         break;\n                     }\n\n                   if (i ==  (ssize_t) number_semitransparent &&\n                       number_semitransparent < 259)\n                     {\n                       number_semitransparent++;\n                       GetPixelInfoPixel(image, q, semitransparent+i);\n                     }\n                 }\n             }\n           q+=GetPixelChannels(image);\n        }\n     }\n\n     if (mng_info->write_png8 == MagickFalse &&\n         ping_exclude_bKGD == MagickFalse)\n       {\n         /* Add the background color to the palette, if it\n          * isn't already there.\n          */\n          if (logging != MagickFalse)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      Check colormap for background (%d,%d,%d)\",\n                  (int) image->background_color.red,\n                  (int) image->background_color.green,\n                  (int) image->background_color.blue);\n            }\n          for (i=0; i<number_opaque; i++)\n          {\n             if (opaque[i].red == image->background_color.red &&\n                 opaque[i].green == image->background_color.green &&\n                 opaque[i].blue == image->background_color.blue)\n               break;\n          }\n          if (number_opaque < 259 && i == number_opaque)\n            {\n               opaque[i] = image->background_color;\n               ping_background.index = i;\n               number_opaque++;\n               if (logging != MagickFalse)\n                 {\n                   (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                       \"      background_color index is %d\",(int) i);\n                 }\n\n            }\n          else if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      No room in the colormap to add background color\");\n       }\n\n     image_colors=number_opaque+number_transparent+number_semitransparent;\n\n     if (logging != MagickFalse)\n       {\n         if (image_colors > 256)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      image has more than 256 colors\");\n\n         else\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      image has %d colors\",image_colors);\n       }\n\n     if (ping_preserve_colormap != MagickFalse)\n       break;\n\n     if (mng_info->write_png_colortype != 7) /* We won't need this info */\n       {\n         ping_have_color=MagickFalse;\n         ping_have_non_bw=MagickFalse;\n\n         if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n         {\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"incompatible colorspace\");\n           ping_have_color=MagickTrue;\n           ping_have_non_bw=MagickTrue;\n         }\n\n         if(image_colors > 256)\n           {\n             for (y=0; y < (ssize_t) image->rows; y++)\n             {\n               q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n               if (q == (Quantum *) NULL)\n                 break;\n\n               s=q;\n               for (x=0; x < (ssize_t) image->columns; x++)\n               {\n                 if (GetPixelRed(image,s) != GetPixelGreen(image,s) ||\n                     GetPixelRed(image,s) != GetPixelBlue(image,s))\n                   {\n                      ping_have_color=MagickTrue;\n                      ping_have_non_bw=MagickTrue;\n                      break;\n                   }\n                 s+=GetPixelChannels(image);\n               }\n\n               if (ping_have_color != MagickFalse)\n                 break;\n\n               /* Worst case is black-and-white; we are looking at every\n                * pixel twice.\n                */\n\n               if (ping_have_non_bw == MagickFalse)\n                 {\n                   s=q;\n                   for (x=0; x < (ssize_t) image->columns; x++)\n                   {\n                     if (GetPixelRed(image,s) != 0 &&\n                         GetPixelRed(image,s) != QuantumRange)\n                       {\n                         ping_have_non_bw=MagickTrue;\n                         break;\n                       }\n                     s+=GetPixelChannels(image);\n                   }\n               }\n             }\n           }\n       }\n\n     if (image_colors < 257)\n       {\n         PixelInfo\n           colormap[260];\n\n         /*\n          * Initialize image colormap.\n          */\n\n         if (logging != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      Sort the new colormap\");\n\n        /* Sort palette, transparent first */;\n\n         n = 0;\n\n         for (i=0; i<number_transparent; i++)\n            colormap[n++] = transparent[i];\n\n         for (i=0; i<number_semitransparent; i++)\n            colormap[n++] = semitransparent[i];\n\n         for (i=0; i<number_opaque; i++)\n            colormap[n++] = opaque[i];\n\n         ping_background.index +=\n           (number_transparent + number_semitransparent);\n\n         /* image_colors < 257; search the colormap instead of the pixels\n          * to get ping_have_color and ping_have_non_bw\n          */\n         for (i=0; i<n; i++)\n         {\n           if (ping_have_color == MagickFalse)\n             {\n                if (colormap[i].red != colormap[i].green ||\n                    colormap[i].red != colormap[i].blue)\n                  {\n                     ping_have_color=MagickTrue;\n                     ping_have_non_bw=MagickTrue;\n                     break;\n                  }\n              }\n\n           if (ping_have_non_bw == MagickFalse)\n             {\n               if (colormap[i].red != 0 && colormap[i].red != QuantumRange)\n                   ping_have_non_bw=MagickTrue;\n             }\n          }\n\n        if ((mng_info->ping_exclude_tRNS == MagickFalse ||\n            (number_transparent == 0 && number_semitransparent == 0)) &&\n            (((mng_info->write_png_colortype-1) ==\n            PNG_COLOR_TYPE_PALETTE) ||\n            (mng_info->write_png_colortype == 0)))\n          {\n            if (logging != MagickFalse)\n              {\n                if (n !=  (ssize_t) image_colors)\n                   (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"   image_colors (%d) and n (%d)  don't match\",\n                   image_colors, n);\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      AcquireImageColormap\");\n              }\n\n            image->colors = image_colors;\n\n            if (AcquireImageColormap(image,image_colors,exception) ==\n                MagickFalse)\n               ThrowWriterException(ResourceLimitError,\n                   \"MemoryAllocationFailed\");\n\n            for (i=0; i< (ssize_t) image_colors; i++)\n               image->colormap[i] = colormap[i];\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"      image->colors=%d (%d)\",\n                      (int) image->colors, image_colors);\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"      Update the pixel indexes\");\n              }\n\n            /* Sync the pixel indices with the new colormap */\n\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n              if (q == (Quantum *) NULL)\n                break;\n\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                for (i=0; i< (ssize_t) image_colors; i++)\n                {\n                  if ((image->alpha_trait == UndefinedPixelTrait ||\n                      image->colormap[i].alpha == GetPixelAlpha(image,q)) &&\n                      image->colormap[i].red == GetPixelRed(image,q) &&\n                      image->colormap[i].green == GetPixelGreen(image,q) &&\n                      image->colormap[i].blue == GetPixelBlue(image,q))\n                  {\n                    SetPixelIndex(image,i,q);\n                    break;\n                  }\n                }\n                q+=GetPixelChannels(image);\n              }\n\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                 break;\n            }\n          }\n       }\n\n     if (logging != MagickFalse)\n       {\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"      image->colors=%d\", (int) image->colors);\n\n         if (image->colormap != NULL)\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"       i     (red,green,blue,alpha)\");\n\n             for (i=0; i < (ssize_t) image->colors; i++)\n             {\n               if (i < 300 || i >= (ssize_t) image->colors - 10)\n                 {\n                   (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                       \"       %d     (%d,%d,%d,%d)\",\n                        (int) i,\n                        (int) image->colormap[i].red,\n                        (int) image->colormap[i].green,\n                        (int) image->colormap[i].blue,\n                        (int) image->colormap[i].alpha);\n                 }\n             }\n           }\n\n           if (number_transparent < 257)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_transparent     = %d\",\n                   number_transparent);\n           else\n\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_transparent     > 256\");\n\n           if (number_opaque < 257)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_opaque          = %d\",\n                   number_opaque);\n\n           else\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_opaque          > 256\");\n\n           if (number_semitransparent < 257)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_semitransparent = %d\",\n                   number_semitransparent);\n\n           else\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      number_semitransparent > 256\");\n\n           if (ping_have_non_bw == MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      All pixels and the background are black or white\");\n\n           else if (ping_have_color == MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      All pixels and the background are gray\");\n\n           else\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      At least one pixel or the background is non-gray\");\n\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"    Exit BUILD_PALETTE:\");\n       }\n\n   if (mng_info->write_png8 == MagickFalse)\n      break;\n\n   /* Make any reductions necessary for the PNG8 format */\n    if (image_colors <= 256 &&\n        image_colors != 0 && image->colormap != NULL &&\n        number_semitransparent == 0 &&\n        number_transparent <= 1)\n      break;\n\n    /* PNG8 can't have semitransparent colors so we threshold the\n     * opacity to 0 or OpaqueOpacity, and PNG8 can only have one\n     * transparent color so if more than one is transparent we merge\n     * them into image->background_color.\n     */\n    if (number_semitransparent != 0 || number_transparent > 1)\n      {\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Thresholding the alpha channel to binary\");\n\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n          if (r == (Quantum *) NULL)\n            break;\n\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n              if (GetPixelAlpha(image,r) < OpaqueAlpha/2)\n                {\n                  SetPixelViaPixelInfo(image,&image->background_color,r);\n                  SetPixelAlpha(image,TransparentAlpha,r);\n                }\n              else\n                  SetPixelAlpha(image,OpaqueAlpha,r);\n              r+=GetPixelChannels(image);\n          }\n\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n             break;\n\n          if (image_colors != 0 && image_colors <= 256 &&\n             image->colormap != NULL)\n            for (i=0; i<image_colors; i++)\n                image->colormap[i].alpha =\n                    (image->colormap[i].alpha > TransparentAlpha/2 ?\n                    TransparentAlpha : OpaqueAlpha);\n        }\n      continue;\n    }\n\n    /* PNG8 can't have more than 256 colors so we quantize the pixels and\n     * background color to the 4-4-4-1, 3-3-3-1 or 3-3-2-1 palette.  If the\n     * image is mostly gray, the 4-4-4-1 palette is likely to end up with 256\n     * colors or less.\n     */\n    if (tried_444 == MagickFalse && (image_colors == 0 || image_colors > 256))\n      {\n        if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"    Quantizing the background color to 4-4-4\");\n\n        tried_444 = MagickTrue;\n\n        LBR04PacketRGB(image->background_color);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the pixel colors to 4-4-4\");\n\n        if (image->colormap == NULL)\n        {\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n            if (r == (Quantum *) NULL)\n              break;\n\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (GetPixelAlpha(image,r) == OpaqueAlpha)\n                  LBR04PixelRGB(r);\n              r+=GetPixelChannels(image);\n            }\n\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n               break;\n          }\n        }\n\n        else /* Should not reach this; colormap already exists and\n                must be <= 256 */\n        {\n          if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the colormap to 4-4-4\");\n\n          for (i=0; i<image_colors; i++)\n          {\n            LBR04PacketRGB(image->colormap[i]);\n          }\n        }\n        continue;\n      }\n\n    if (tried_333 == MagickFalse && (image_colors == 0 || image_colors > 256))\n      {\n        if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"    Quantizing the background color to 3-3-3\");\n\n        tried_333 = MagickTrue;\n\n        LBR03PacketRGB(image->background_color);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the pixel colors to 3-3-3-1\");\n\n        if (image->colormap == NULL)\n        {\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n            if (r == (Quantum *) NULL)\n              break;\n\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (GetPixelAlpha(image,r) == OpaqueAlpha)\n                  LBR03RGB(r);\n              r+=GetPixelChannels(image);\n            }\n\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n               break;\n          }\n        }\n\n        else /* Should not reach this; colormap already exists and\n                must be <= 256 */\n        {\n          if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the colormap to 3-3-3-1\");\n          for (i=0; i<image_colors; i++)\n          {\n              LBR03PacketRGB(image->colormap[i]);\n          }\n        }\n        continue;\n      }\n\n    if (tried_332 == MagickFalse && (image_colors == 0 || image_colors > 256))\n      {\n        if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"    Quantizing the background color to 3-3-2\");\n\n        tried_332 = MagickTrue;\n\n        /* Red and green were already done so we only quantize the blue\n         * channel\n         */\n\n        LBR02PacketBlue(image->background_color);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the pixel colors to 3-3-2-1\");\n\n        if (image->colormap == NULL)\n        {\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n            if (r == (Quantum *) NULL)\n              break;\n\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (GetPixelAlpha(image,r) == OpaqueAlpha)\n                  LBR02PixelBlue(r);\n              r+=GetPixelChannels(image);\n            }\n\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n               break;\n          }\n        }\n\n        else /* Should not reach this; colormap already exists and\n                must be <= 256 */\n        {\n          if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    Quantizing the colormap to 3-3-2-1\");\n          for (i=0; i<image_colors; i++)\n          {\n              LBR02PacketBlue(image->colormap[i]);\n          }\n      }\n      continue;\n    }\n\n    if (image_colors == 0 || image_colors > 256)\n    {\n      /* Take care of special case with 256 opaque colors + 1 transparent\n       * color.  We don't need to quantize to 2-3-2-1; we only need to\n       * eliminate one color, so we'll merge the two darkest red\n       * colors (0x49, 0, 0) -> (0x24, 0, 0).\n       */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Merging two dark red background colors to 3-3-2-1\");\n\n      if (ScaleQuantumToChar(image->background_color.red) == 0x49 &&\n          ScaleQuantumToChar(image->background_color.green) == 0x00 &&\n          ScaleQuantumToChar(image->background_color.blue) == 0x00)\n      {\n         image->background_color.red=ScaleCharToQuantum(0x24);\n      }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Merging two dark red pixel colors to 3-3-2-1\");\n\n      if (image->colormap == NULL)\n      {\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          r=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n          if (r == (Quantum *) NULL)\n            break;\n\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            if (ScaleQuantumToChar(GetPixelRed(image,r)) == 0x49 &&\n                ScaleQuantumToChar(GetPixelGreen(image,r)) == 0x00 &&\n                ScaleQuantumToChar(GetPixelBlue(image,r)) == 0x00 &&\n                GetPixelAlpha(image,r) == OpaqueAlpha)\n              {\n                SetPixelRed(image,ScaleCharToQuantum(0x24),r);\n              }\n            r+=GetPixelChannels(image);\n          }\n\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n             break;\n\n        }\n      }\n\n      else\n      {\n         for (i=0; i<image_colors; i++)\n         {\n            if (ScaleQuantumToChar(image->colormap[i].red) == 0x49 &&\n                ScaleQuantumToChar(image->colormap[i].green) == 0x00 &&\n                ScaleQuantumToChar(image->colormap[i].blue) == 0x00)\n            {\n               image->colormap[i].red=ScaleCharToQuantum(0x24);\n            }\n         }\n      }\n    }\n  }\n  }\n  /* END OF BUILD_PALETTE */\n\n  /* If we are excluding the tRNS chunk and there is transparency,\n   * then we must write a Gray-Alpha (color-type 4) or RGBA (color-type 6)\n   * PNG.\n   */\n  if (mng_info->ping_exclude_tRNS != MagickFalse &&\n     (number_transparent != 0 || number_semitransparent != 0))\n    {\n      unsigned int colortype=mng_info->write_png_colortype;\n\n      if (ping_have_color == MagickFalse)\n        mng_info->write_png_colortype = 5;\n\n      else\n        mng_info->write_png_colortype = 7;\n\n      if (colortype != 0 &&\n         mng_info->write_png_colortype != colortype)\n        ping_need_colortype_warning=MagickTrue;\n\n    }\n\n  /* See if cheap transparency is possible.  It is only possible\n   * when there is a single transparent color, no semitransparent\n   * color, and no opaque color that has the same RGB components\n   * as the transparent color.  We only need this information if\n   * we are writing a PNG with colortype 0 or 2, and we have not\n   * excluded the tRNS chunk.\n   */\n  if (number_transparent == 1 &&\n      mng_info->write_png_colortype < 4)\n    {\n       ping_have_cheap_transparency = MagickTrue;\n\n       if (number_semitransparent != 0)\n         ping_have_cheap_transparency = MagickFalse;\n\n       else if (image_colors == 0 || image_colors > 256 ||\n           image->colormap == NULL)\n         {\n           register const Quantum\n             *q;\n\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             q=GetVirtualPixels(image,0,y,image->columns,1, exception);\n\n             if (q == (Quantum *) NULL)\n               break;\n\n             for (x=0; x < (ssize_t) image->columns; x++)\n             {\n                 if (GetPixelAlpha(image,q) != TransparentAlpha &&\n                     (unsigned short) GetPixelRed(image,q) ==\n                                     ping_trans_color.red &&\n                     (unsigned short) GetPixelGreen(image,q) ==\n                                     ping_trans_color.green &&\n                     (unsigned short) GetPixelBlue(image,q) ==\n                                     ping_trans_color.blue)\n                   {\n                     ping_have_cheap_transparency = MagickFalse;\n                     break;\n                   }\n\n                 q+=GetPixelChannels(image);\n             }\n\n             if (ping_have_cheap_transparency == MagickFalse)\n                break;\n           }\n         }\n       else\n         {\n            /* Assuming that image->colormap[0] is the one transparent color\n             * and that all others are opaque.\n             */\n            if (image_colors > 1)\n              for (i=1; i<image_colors; i++)\n                if (image->colormap[i].red == image->colormap[0].red &&\n                    image->colormap[i].green == image->colormap[0].green &&\n                    image->colormap[i].blue == image->colormap[0].blue)\n                  {\n                     ping_have_cheap_transparency = MagickFalse;\n                     break;\n                  }\n         }\n\n       if (logging != MagickFalse)\n         {\n           if (ping_have_cheap_transparency == MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"   Cheap transparency is not possible.\");\n\n           else\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"   Cheap transparency is possible.\");\n         }\n     }\n  else\n    ping_have_cheap_transparency = MagickFalse;\n\n  image_depth=image->depth;\n\n  quantum_info = (QuantumInfo *) NULL;\n  number_colors=0;\n  image_colors=(int) image->colors;\n  image_matte=image->alpha_trait !=\n        UndefinedPixelTrait ? MagickTrue : MagickFalse;\n\n  if (mng_info->write_png_colortype < 5)\n    mng_info->IsPalette=image->storage_class == PseudoClass &&\n      image_colors <= 256 && image->colormap != NULL;\n  else\n    mng_info->IsPalette = MagickFalse;\n\n  if ((mng_info->write_png_colortype == 4 || mng_info->write_png8) &&\n     (image->colors == 0 || image->colormap == NULL))\n    {\n      image_info=DestroyImageInfo(image_info);\n      image=DestroyImage(image);\n      (void) ThrowMagickException(exception,GetMagickModule(),CoderError,\n          \"Cannot write PNG8 or color-type 3; colormap is NULL\",\n          \"`%s'\",IMimage->filename);\n      return(MagickFalse);\n    }\n\n  /*\n    Allocate the PNG structures\n  */\n#ifdef PNG_USER_MEM_SUPPORTED\n error_info.image=image;\n error_info.exception=exception;\n  ping=png_create_write_struct_2(PNG_LIBPNG_VER_STRING,&error_info,\n    MagickPNGErrorHandler,MagickPNGWarningHandler,(void *) NULL,\n    (png_malloc_ptr) Magick_png_malloc,(png_free_ptr) Magick_png_free);\n\n#else\n  ping=png_create_write_struct(PNG_LIBPNG_VER_STRING,&error_info,\n    MagickPNGErrorHandler,MagickPNGWarningHandler);\n\n#endif\n  if (ping == (png_struct *) NULL)\n    ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  ping_info=png_create_info_struct(ping);\n\n  if (ping_info == (png_info *) NULL)\n    {\n      png_destroy_write_struct(&ping,(png_info **) NULL);\n      ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n\n  png_set_write_fn(ping,image,png_put_data,png_flush_data);\n  pixel_info=(MemoryInfo *) NULL;\n\n  if (setjmp(png_jmpbuf(ping)))\n    {\n      /*\n        PNG write failed.\n      */\n#ifdef PNG_DEBUG\n     if (image_info->verbose)\n        (void) printf(\"PNG write has failed.\\n\");\n#endif\n      png_destroy_write_struct(&ping,&ping_info);\n#ifdef IMPNG_SETJMP_NOT_THREAD_SAFE\n      UnlockSemaphoreInfo(ping_semaphore);\n#endif\n\n      if (pixel_info != (MemoryInfo *) NULL)\n        pixel_info=RelinquishVirtualMemory(pixel_info);\n\n      if (quantum_info != (QuantumInfo *) NULL)\n        quantum_info=DestroyQuantumInfo(quantum_info);\n\n      if (ping_have_blob != MagickFalse)\n          (void) CloseBlob(image);\n      image_info=DestroyImageInfo(image_info);\n      image=DestroyImage(image);\n      return(MagickFalse);\n    }\n\n  /* {  For navigation to end of SETJMP-protected block.  Within this\n   *    block, use png_error() instead of Throwing an Exception, to ensure\n   *    that libpng is able to clean up, and that the semaphore is unlocked.\n   */\n\n#ifdef IMPNG_SETJMP_NOT_THREAD_SAFE\n  LockSemaphoreInfo(ping_semaphore);\n#endif\n\n#ifdef PNG_BENIGN_ERRORS_SUPPORTED\n  /* Allow benign errors */\n  png_set_benign_errors(ping, 1);\n#endif\n\n#ifdef PNG_SET_USER_LIMITS_SUPPORTED\n  /* Reject images with too many rows or columns */\n  png_set_user_limits(ping,\n    (png_uint_32) MagickMin(0x7fffffffL,\n        GetMagickResourceLimit(WidthResource)),\n    (png_uint_32) MagickMin(0x7fffffffL,\n        GetMagickResourceLimit(HeightResource)));\n#endif /* PNG_SET_USER_LIMITS_SUPPORTED */\n\n  /*\n    Prepare PNG for writing.\n  */\n\n#if defined(PNG_MNG_FEATURES_SUPPORTED)\n  if (mng_info->write_mng)\n  {\n     (void) png_permit_mng_features(ping,PNG_ALL_MNG_FEATURES);\n# ifdef PNG_WRITE_CHECK_FOR_INVALID_INDEX_SUPPORTED\n     /* Disable new libpng-1.5.10 feature when writing a MNG because\n      * zero-length PLTE is OK\n      */\n     png_set_check_for_invalid_index (ping, 0);\n# endif\n  }\n\n#else\n# ifdef PNG_WRITE_EMPTY_PLTE_SUPPORTED\n  if (mng_info->write_mng)\n     png_permit_empty_plte(ping,MagickTrue);\n\n# endif\n#endif\n\n  x=0;\n\n  ping_width=(png_uint_32) image->columns;\n  ping_height=(png_uint_32) image->rows;\n\n  if (mng_info->write_png8 || mng_info->write_png24 || mng_info->write_png32)\n     image_depth=8;\n\n  if (mng_info->write_png48 || mng_info->write_png64)\n     image_depth=16;\n\n  if (mng_info->write_png_depth != 0)\n     image_depth=mng_info->write_png_depth;\n\n  /* Adjust requested depth to next higher valid depth if necessary */\n  if (image_depth > 8)\n     image_depth=16;\n\n  if ((image_depth > 4) && (image_depth < 8))\n     image_depth=8;\n\n  if (image_depth == 3)\n     image_depth=4;\n\n  if (logging != MagickFalse)\n    {\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    width=%.20g\",(double) ping_width);\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    height=%.20g\",(double) ping_height);\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    image_matte=%.20g\",(double) image->alpha_trait);\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    image->depth=%.20g\",(double) image->depth);\n     (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Tentative ping_bit_depth=%.20g\",(double) image_depth);\n    }\n\n  save_image_depth=image_depth;\n  ping_bit_depth=(png_byte) save_image_depth;\n\n\n#if defined(PNG_pHYs_SUPPORTED)\n  if (ping_exclude_pHYs == MagickFalse)\n  {\n  if ((image->resolution.x != 0) && (image->resolution.y != 0) &&\n      (!mng_info->write_mng || !mng_info->equal_physs))\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Setting up pHYs chunk\");\n\n      if (image->units == PixelsPerInchResolution)\n        {\n          ping_pHYs_unit_type=PNG_RESOLUTION_METER;\n          ping_pHYs_x_resolution=\n             (png_uint_32) ((100.0*image->resolution.x+0.5)/2.54);\n          ping_pHYs_y_resolution=\n             (png_uint_32) ((100.0*image->resolution.y+0.5)/2.54);\n        }\n\n      else if (image->units == PixelsPerCentimeterResolution)\n        {\n          ping_pHYs_unit_type=PNG_RESOLUTION_METER;\n          ping_pHYs_x_resolution=(png_uint_32) (100.0*image->resolution.x+0.5);\n          ping_pHYs_y_resolution=(png_uint_32) (100.0*image->resolution.y+0.5);\n        }\n\n      else\n        {\n          ping_pHYs_unit_type=PNG_RESOLUTION_UNKNOWN;\n          ping_pHYs_x_resolution=(png_uint_32) image->resolution.x;\n          ping_pHYs_y_resolution=(png_uint_32) image->resolution.y;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    Set up PNG pHYs chunk: xres: %.20g, yres: %.20g, units: %d.\",\n          (double) ping_pHYs_x_resolution,(double) ping_pHYs_y_resolution,\n          (int) ping_pHYs_unit_type);\n       ping_have_pHYs = MagickTrue;\n    }\n  }\n#endif\n\n  if (ping_exclude_bKGD == MagickFalse)\n  {\n  if ((!mng_info->adjoin || !mng_info->equal_backgrounds))\n    {\n       unsigned int\n         mask;\n\n       mask=0xffff;\n       if (ping_bit_depth == 8)\n          mask=0x00ff;\n\n       if (ping_bit_depth == 4)\n          mask=0x000f;\n\n       if (ping_bit_depth == 2)\n          mask=0x0003;\n\n       if (ping_bit_depth == 1)\n          mask=0x0001;\n\n       ping_background.red=(png_uint_16)\n         (ScaleQuantumToShort(image->background_color.red) & mask);\n\n       ping_background.green=(png_uint_16)\n         (ScaleQuantumToShort(image->background_color.green) & mask);\n\n       ping_background.blue=(png_uint_16)\n         (ScaleQuantumToShort(image->background_color.blue) & mask);\n\n       ping_background.gray=(png_uint_16) ping_background.green;\n    }\n\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    Setting up bKGD chunk (1)\");\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"      background_color index is %d\",\n          (int) ping_background.index);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    ping_bit_depth=%d\",ping_bit_depth);\n    }\n\n  ping_have_bKGD = MagickTrue;\n  }\n\n  /*\n    Select the color type.\n  */\n  matte=image_matte;\n  old_bit_depth=0;\n\n  if (mng_info->IsPalette && mng_info->write_png8)\n    {\n      /* To do: make this a function cause it's used twice, except\n         for reducing the sample depth from 8. */\n\n      number_colors=image_colors;\n\n      ping_have_tRNS=MagickFalse;\n\n      /*\n        Set image palette.\n      */\n      ping_color_type=(png_byte) PNG_COLOR_TYPE_PALETTE;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Setting up PLTE chunk with %d colors (%d)\",\n            number_colors, image_colors);\n\n      for (i=0; i < (ssize_t) number_colors; i++)\n      {\n        palette[i].red=ScaleQuantumToChar(image->colormap[i].red);\n        palette[i].green=ScaleQuantumToChar(image->colormap[i].green);\n        palette[i].blue=ScaleQuantumToChar(image->colormap[i].blue);\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n#if MAGICKCORE_QUANTUM_DEPTH == 8\n            \"    %3ld (%3d,%3d,%3d)\",\n#else\n            \"    %5ld (%5d,%5d,%5d)\",\n#endif\n            (long) i,palette[i].red,palette[i].green,palette[i].blue);\n\n      }\n\n      ping_have_PLTE=MagickTrue;\n      image_depth=ping_bit_depth;\n      ping_num_trans=0;\n\n      if (matte != MagickFalse)\n      {\n          /*\n            Identify which colormap entry is transparent.\n          */\n          assert(number_colors <= 256);\n          assert(image->colormap != NULL);\n\n          for (i=0; i < (ssize_t) number_transparent; i++)\n             ping_trans_alpha[i]=0;\n\n\n          ping_num_trans=(unsigned short) (number_transparent +\n             number_semitransparent);\n\n          if (ping_num_trans == 0)\n             ping_have_tRNS=MagickFalse;\n\n          else\n             ping_have_tRNS=MagickTrue;\n      }\n\n      if (ping_exclude_bKGD == MagickFalse)\n      {\n       /*\n        * Identify which colormap entry is the background color.\n        */\n\n        for (i=0; i < (ssize_t) MagickMax(1L*number_colors-1L,1L); i++)\n          if (IsPNGColorEqual(ping_background,image->colormap[i]))\n            break;\n\n        ping_background.index=(png_byte) i;\n\n        if (logging != MagickFalse)\n          {\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"      background_color index is %d\",\n                 (int) ping_background.index);\n          }\n      }\n    } /* end of write_png8 */\n\n  else if (mng_info->write_png_colortype == 1)\n    {\n      image_matte=MagickFalse;\n      ping_color_type=(png_byte) PNG_COLOR_TYPE_GRAY;\n    }\n\n  else if (mng_info->write_png24 || mng_info->write_png48 ||\n      mng_info->write_png_colortype == 3)\n    {\n      image_matte=MagickFalse;\n      ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB;\n    }\n\n  else if (mng_info->write_png32 || mng_info->write_png64 ||\n      mng_info->write_png_colortype == 7)\n    {\n      image_matte=MagickTrue;\n      ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB_ALPHA;\n    }\n\n  else /* mng_info->write_pngNN not specified */\n    {\n      image_depth=ping_bit_depth;\n\n      if (mng_info->write_png_colortype != 0)\n        {\n          ping_color_type=(png_byte) mng_info->write_png_colortype-1;\n\n          if (ping_color_type == PNG_COLOR_TYPE_GRAY_ALPHA ||\n              ping_color_type == PNG_COLOR_TYPE_RGB_ALPHA)\n            image_matte=MagickTrue;\n\n          else\n            image_matte=MagickFalse;\n\n          if (logging != MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"   PNG colortype %d was specified:\",(int) ping_color_type);\n        }\n\n      else /* write_png_colortype not specified */\n        {\n          if (logging != MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  Selecting PNG colortype:\");\n\n          ping_color_type=(png_byte) ((matte != MagickFalse)?\n            PNG_COLOR_TYPE_RGB_ALPHA:PNG_COLOR_TYPE_RGB);\n\n          if (image_info->type == TrueColorType)\n            {\n              ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB;\n              image_matte=MagickFalse;\n            }\n\n          if (image_info->type == TrueColorAlphaType)\n            {\n              ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB_ALPHA;\n              image_matte=MagickTrue;\n            }\n\n          if (image_info->type == PaletteType ||\n              image_info->type == PaletteAlphaType)\n            ping_color_type=(png_byte) PNG_COLOR_TYPE_PALETTE;\n\n          if (mng_info->write_png_colortype == 0 &&\n             image_info->type == UndefinedType)\n            {\n              if (ping_have_color == MagickFalse)\n                {\n                  if (image_matte == MagickFalse)\n                    {\n                      ping_color_type=(png_byte) PNG_COLOR_TYPE_GRAY;\n                      image_matte=MagickFalse;\n                    }\n\n                  else\n                    {\n                      ping_color_type=(png_byte) PNG_COLOR_TYPE_GRAY_ALPHA;\n                      image_matte=MagickTrue;\n                    }\n                }\n              else\n                {\n                  if (image_matte == MagickFalse)\n                    {\n                      ping_color_type=(png_byte) PNG_COLOR_TYPE_RGB;\n                      image_matte=MagickFalse;\n                    }\n\n                  else\n                    {\n                      ping_color_type=(png_byte) PNG_COLOR_TYPE_RGBA;\n                      image_matte=MagickTrue;\n                    }\n                 }\n            }\n\n        }\n\n      if (logging != MagickFalse)\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n         \"    Selected PNG colortype=%d\",ping_color_type);\n\n      if (ping_bit_depth < 8)\n        {\n          if (ping_color_type == PNG_COLOR_TYPE_GRAY_ALPHA ||\n              ping_color_type == PNG_COLOR_TYPE_RGB ||\n              ping_color_type == PNG_COLOR_TYPE_RGB_ALPHA)\n            ping_bit_depth=8;\n        }\n\n      old_bit_depth=ping_bit_depth;\n\n      if (ping_color_type == PNG_COLOR_TYPE_GRAY)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait &&\n               ping_have_non_bw == MagickFalse)\n             ping_bit_depth=1;\n        }\n\n      if (ping_color_type == PNG_COLOR_TYPE_PALETTE)\n        {\n           size_t one = 1;\n           ping_bit_depth=1;\n\n           if (image->colors == 0)\n           {\n              /* DO SOMETHING */\n                png_error(ping,\"image has 0 colors\");\n           }\n\n           while ((int) (one << ping_bit_depth) < (ssize_t) image_colors)\n             ping_bit_depth <<= 1;\n        }\n\n      if (logging != MagickFalse)\n         {\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Number of colors: %.20g\",(double) image_colors);\n\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Tentative PNG bit depth: %d\",ping_bit_depth);\n         }\n\n      if (ping_bit_depth < (int) mng_info->write_png_depth)\n         ping_bit_depth = mng_info->write_png_depth;\n    }\n\n  image_depth=ping_bit_depth;\n\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Tentative PNG color type: %s (%.20g)\",\n        PngColorTypeToString(ping_color_type),\n        (double) ping_color_type);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    image_info->type: %.20g\",(double) image_info->type);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    image_depth: %.20g\",(double) image_depth);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n\n        \"    image->depth: %.20g\",(double) image->depth);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    ping_bit_depth: %.20g\",(double) ping_bit_depth);\n    }\n\n  if (matte != MagickFalse)\n    {\n      if (mng_info->IsPalette)\n        {\n          if (mng_info->write_png_colortype == 0)\n            {\n              ping_color_type=PNG_COLOR_TYPE_GRAY_ALPHA;\n\n              if (ping_have_color != MagickFalse)\n                 ping_color_type=PNG_COLOR_TYPE_RGBA;\n            }\n\n          /*\n           * Determine if there is any transparent color.\n          */\n          if (number_transparent + number_semitransparent == 0)\n            {\n              /*\n                No transparent pixels are present.  Change 4 or 6 to 0 or 2.\n              */\n\n              image_matte=MagickFalse;\n\n              if (mng_info->write_png_colortype == 0)\n                ping_color_type&=0x03;\n            }\n\n          else\n            {\n              unsigned int\n                mask;\n\n              mask=0xffff;\n\n              if (ping_bit_depth == 8)\n                 mask=0x00ff;\n\n              if (ping_bit_depth == 4)\n                 mask=0x000f;\n\n              if (ping_bit_depth == 2)\n                 mask=0x0003;\n\n              if (ping_bit_depth == 1)\n                 mask=0x0001;\n\n              ping_trans_color.red=(png_uint_16)\n                (ScaleQuantumToShort(image->colormap[0].red) & mask);\n\n              ping_trans_color.green=(png_uint_16)\n                (ScaleQuantumToShort(image->colormap[0].green) & mask);\n\n              ping_trans_color.blue=(png_uint_16)\n                (ScaleQuantumToShort(image->colormap[0].blue) & mask);\n\n              ping_trans_color.gray=(png_uint_16)\n                (ScaleQuantumToShort(GetPixelInfoIntensity(image,\n                   image->colormap)) & mask);\n\n              ping_trans_color.index=(png_byte) 0;\n\n              ping_have_tRNS=MagickTrue;\n            }\n\n          if (ping_have_tRNS != MagickFalse)\n            {\n              /*\n               * Determine if there is one and only one transparent color\n               * and if so if it is fully transparent.\n               */\n              if (ping_have_cheap_transparency == MagickFalse)\n                ping_have_tRNS=MagickFalse;\n            }\n\n          if (ping_have_tRNS != MagickFalse)\n            {\n              if (mng_info->write_png_colortype == 0)\n                ping_color_type &= 0x03;  /* changes 4 or 6 to 0 or 2 */\n\n              if (image_depth == 8)\n                {\n                  ping_trans_color.red&=0xff;\n                  ping_trans_color.green&=0xff;\n                  ping_trans_color.blue&=0xff;\n                  ping_trans_color.gray&=0xff;\n                }\n            }\n        }\n      else\n        {\n          if (image_depth == 8)\n            {\n              ping_trans_color.red&=0xff;\n              ping_trans_color.green&=0xff;\n              ping_trans_color.blue&=0xff;\n              ping_trans_color.gray&=0xff;\n            }\n        }\n    }\n\n    matte=image_matte;\n\n    if (ping_have_tRNS != MagickFalse)\n      image_matte=MagickFalse;\n\n    if ((mng_info->IsPalette) &&\n        mng_info->write_png_colortype-1 != PNG_COLOR_TYPE_PALETTE &&\n        ping_have_color == MagickFalse &&\n        (image_matte == MagickFalse || image_depth >= 8))\n      {\n        size_t one=1;\n\n        if (image_matte != MagickFalse)\n          ping_color_type=PNG_COLOR_TYPE_GRAY_ALPHA;\n\n        else if (mng_info->write_png_colortype-1 != PNG_COLOR_TYPE_GRAY_ALPHA)\n          {\n            ping_color_type=PNG_COLOR_TYPE_GRAY;\n\n            if (save_image_depth == 16 && image_depth == 8)\n              {\n                if (logging != MagickFalse)\n                  {\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"  Scaling ping_trans_color (0)\");\n                  }\n                    ping_trans_color.gray*=0x0101;\n              }\n          }\n\n        if (image_depth > MAGICKCORE_QUANTUM_DEPTH)\n          image_depth=MAGICKCORE_QUANTUM_DEPTH;\n\n        if ((image_colors == 0) ||\n             ((ssize_t) (image_colors-1) > (ssize_t) MaxColormapSize))\n          image_colors=(int) (one << image_depth);\n\n        if (image_depth > 8)\n          ping_bit_depth=16;\n\n        else\n          {\n            ping_bit_depth=8;\n            if ((int) ping_color_type == PNG_COLOR_TYPE_PALETTE)\n              {\n                if(!mng_info->write_png_depth)\n                  {\n                    ping_bit_depth=1;\n\n                    while ((int) (one << ping_bit_depth)\n                        < (ssize_t) image_colors)\n                      ping_bit_depth <<= 1;\n                  }\n              }\n\n            else if (ping_color_type ==\n                PNG_COLOR_TYPE_GRAY && image_colors < 17 &&\n                mng_info->IsPalette)\n              {\n              /* Check if grayscale is reducible */\n\n                int\n                  depth_4_ok=MagickTrue,\n                  depth_2_ok=MagickTrue,\n                  depth_1_ok=MagickTrue;\n\n                for (i=0; i < (ssize_t) image_colors; i++)\n                {\n                   unsigned char\n                     intensity;\n\n                   intensity=ScaleQuantumToChar(image->colormap[i].red);\n\n                   if ((intensity & 0x0f) != ((intensity & 0xf0) >> 4))\n                     depth_4_ok=depth_2_ok=depth_1_ok=MagickFalse;\n                   else if ((intensity & 0x03) != ((intensity & 0x0c) >> 2))\n                     depth_2_ok=depth_1_ok=MagickFalse;\n                   else if ((intensity & 0x01) != ((intensity & 0x02) >> 1))\n                     depth_1_ok=MagickFalse;\n                }\n\n                if (depth_1_ok && mng_info->write_png_depth <= 1)\n                  ping_bit_depth=1;\n\n                else if (depth_2_ok && mng_info->write_png_depth <= 2)\n                  ping_bit_depth=2;\n\n                else if (depth_4_ok && mng_info->write_png_depth <= 4)\n                  ping_bit_depth=4;\n              }\n          }\n\n          image_depth=ping_bit_depth;\n      }\n\n    else\n\n      if (mng_info->IsPalette)\n      {\n        number_colors=image_colors;\n\n        if (image_depth <= 8)\n          {\n            /*\n              Set image palette.\n            */\n            ping_color_type=(png_byte) PNG_COLOR_TYPE_PALETTE;\n\n            if (!(mng_info->have_write_global_plte && matte == MagickFalse))\n              {\n                for (i=0; i < (ssize_t) number_colors; i++)\n                {\n                  palette[i].red=ScaleQuantumToChar(image->colormap[i].red);\n                  palette[i].green=\n                    ScaleQuantumToChar(image->colormap[i].green);\n                  palette[i].blue=ScaleQuantumToChar(image->colormap[i].blue);\n                }\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Setting up PLTE chunk with %d colors\",\n                    number_colors);\n\n                ping_have_PLTE=MagickTrue;\n              }\n\n            /* color_type is PNG_COLOR_TYPE_PALETTE */\n            if (mng_info->write_png_depth == 0)\n              {\n                size_t\n                  one;\n\n                ping_bit_depth=1;\n                one=1;\n\n                while ((one << ping_bit_depth) < (size_t) number_colors)\n                  ping_bit_depth <<= 1;\n              }\n\n            ping_num_trans=0;\n\n            if (matte != MagickFalse)\n              {\n                /*\n                 * Set up trans_colors array.\n                 */\n                assert(number_colors <= 256);\n\n                ping_num_trans=(unsigned short) (number_transparent +\n                  number_semitransparent);\n\n                if (ping_num_trans == 0)\n                  ping_have_tRNS=MagickFalse;\n\n                else\n                  {\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  Scaling ping_trans_color (1)\");\n                      }\n                    ping_have_tRNS=MagickTrue;\n\n                    for (i=0; i < ping_num_trans; i++)\n                    {\n                       ping_trans_alpha[i]= (png_byte)\n                         ScaleQuantumToChar(image->colormap[i].alpha);\n                    }\n                  }\n              }\n          }\n      }\n\n    else\n      {\n\n        if (image_depth < 8)\n          image_depth=8;\n\n        if ((save_image_depth == 16) && (image_depth == 8))\n          {\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    Scaling ping_trans_color from (%d,%d,%d)\",\n                  (int) ping_trans_color.red,\n                  (int) ping_trans_color.green,\n                  (int) ping_trans_color.blue);\n              }\n\n            ping_trans_color.red*=0x0101;\n            ping_trans_color.green*=0x0101;\n            ping_trans_color.blue*=0x0101;\n            ping_trans_color.gray*=0x0101;\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    to (%d,%d,%d)\",\n                  (int) ping_trans_color.red,\n                  (int) ping_trans_color.green,\n                  (int) ping_trans_color.blue);\n              }\n          }\n      }\n\n    if (ping_bit_depth <  (ssize_t) mng_info->write_png_depth)\n         ping_bit_depth =  (ssize_t) mng_info->write_png_depth;\n\n    /*\n      Adjust background and transparency samples in sub-8-bit grayscale files.\n    */\n    if (ping_bit_depth < 8 && ping_color_type ==\n        PNG_COLOR_TYPE_GRAY)\n      {\n         png_uint_16\n           maxval;\n\n         size_t\n           one=1;\n\n         maxval=(png_uint_16) ((one << ping_bit_depth)-1);\n\n         if (ping_exclude_bKGD == MagickFalse)\n         {\n\n         ping_background.gray=(png_uint_16) ((maxval/65535.)*\n           (ScaleQuantumToShort(((GetPixelInfoIntensity(image,\n           &image->background_color))) +.5)));\n\n         if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  Setting up bKGD chunk (2)\");\n         (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      background_color index is %d\",\n             (int) ping_background.index);\n\n         ping_have_bKGD = MagickTrue;\n         }\n\n         if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  Scaling ping_trans_color.gray from %d\",\n             (int)ping_trans_color.gray);\n\n         ping_trans_color.gray=(png_uint_16) ((maxval/255.)*(\n           ping_trans_color.gray)+.5);\n\n         if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"      to %d\", (int)ping_trans_color.gray);\n      }\n\n  if (ping_exclude_bKGD == MagickFalse)\n  {\n    if (mng_info->IsPalette && (int) ping_color_type == PNG_COLOR_TYPE_PALETTE)\n      {\n        /*\n           Identify which colormap entry is the background color.\n        */\n\n        number_colors=image_colors;\n\n        for (i=0; i < (ssize_t) MagickMax(1L*number_colors,1L); i++)\n          if (IsPNGColorEqual(image->background_color,image->colormap[i]))\n            break;\n\n        ping_background.index=(png_byte) i;\n\n        if (logging != MagickFalse)\n          {\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  Setting up bKGD chunk with index=%d\",(int) i);\n          }\n\n        if (i < (ssize_t) number_colors)\n          {\n            ping_have_bKGD = MagickTrue;\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"     background   =(%d,%d,%d)\",\n                        (int) ping_background.red,\n                        (int) ping_background.green,\n                        (int) ping_background.blue);\n              }\n          }\n\n        else  /* Can't happen */\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"      No room in PLTE to add bKGD color\");\n            ping_have_bKGD = MagickFalse;\n          }\n      }\n  }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"    PNG color type: %s (%d)\", PngColorTypeToString(ping_color_type),\n      ping_color_type);\n  /*\n    Initialize compression level and filtering.\n  */\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Setting up deflate compression\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Compression buffer size: 32768\");\n    }\n\n  png_set_compression_buffer_size(ping,32768L);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"    Compression mem level: 9\");\n\n  png_set_compression_mem_level(ping, 9);\n\n  /* Untangle the \"-quality\" setting:\n\n     Undefined is 0; the default is used.\n     Default is 75\n\n     10's digit:\n\n        0 or omitted: Use Z_HUFFMAN_ONLY strategy with the\n           zlib default compression level\n\n        1-9: the zlib compression level\n\n     1's digit:\n\n        0-4: the PNG filter method\n\n        5:   libpng adaptive filtering if compression level > 5\n             libpng filter type \"none\" if compression level <= 5\n                or if image is grayscale or palette\n\n        6:   libpng adaptive filtering\n\n        7:   \"LOCO\" filtering (intrapixel differing) if writing\n             a MNG, otherwise \"none\".  Did not work in IM-6.7.0-9\n             and earlier because of a missing \"else\".\n\n        8:   Z_RLE strategy (or Z_HUFFMAN_ONLY if quality < 10), adaptive\n             filtering. Unused prior to IM-6.7.0-10, was same as 6\n\n        9:   Z_RLE strategy (or Z_HUFFMAN_ONLY if quality < 10), no PNG filters\n             Unused prior to IM-6.7.0-10, was same as 6\n\n    Note that using the -quality option, not all combinations of\n    PNG filter type, zlib compression level, and zlib compression\n    strategy are possible.  This will be addressed soon in a\n    release that accomodates \"-define png:compression-strategy\", etc.\n\n   */\n\n  quality=image_info->quality == UndefinedCompressionQuality ? 75UL :\n     image_info->quality;\n\n  if (quality <= 9)\n    {\n      if (mng_info->write_png_compression_strategy == 0)\n        mng_info->write_png_compression_strategy = Z_HUFFMAN_ONLY+1;\n    }\n\n  else if (mng_info->write_png_compression_level == 0)\n    {\n      int\n        level;\n\n      level=(int) MagickMin((ssize_t) quality/10,9);\n\n      mng_info->write_png_compression_level = level+1;\n    }\n\n  if (mng_info->write_png_compression_strategy == 0)\n    {\n        if ((quality %10) == 8 || (quality %10) == 9)\n#ifdef Z_RLE  /* Z_RLE was added to zlib-1.2.0 */\n          mng_info->write_png_compression_strategy=Z_RLE+1;\n#else\n          mng_info->write_png_compression_strategy = Z_DEFAULT_STRATEGY+1;\n#endif\n    }\n\n  if (mng_info->write_png_compression_filter == 0)\n        mng_info->write_png_compression_filter=((int) quality % 10) + 1;\n\n  if (logging != MagickFalse)\n    {\n        if (mng_info->write_png_compression_level)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Compression level:    %d\",\n            (int) mng_info->write_png_compression_level-1);\n\n        if (mng_info->write_png_compression_strategy)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Compression strategy: %d\",\n            (int) mng_info->write_png_compression_strategy-1);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Setting up filtering\");\n\n        if (mng_info->write_png_compression_filter == 6)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Base filter method: ADAPTIVE\");\n        else if (mng_info->write_png_compression_filter == 0 ||\n                 mng_info->write_png_compression_filter == 1)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Base filter method: NONE\");\n        else\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Base filter method: %d\",\n            (int) mng_info->write_png_compression_filter-1);\n    }\n\n  if (mng_info->write_png_compression_level != 0)\n    png_set_compression_level(ping,mng_info->write_png_compression_level-1);\n\n  if (mng_info->write_png_compression_filter == 6)\n    {\n      if (((int) ping_color_type == PNG_COLOR_TYPE_GRAY) ||\n         ((int) ping_color_type == PNG_COLOR_TYPE_PALETTE) ||\n         (quality < 50))\n        png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_NO_FILTERS);\n      else\n        png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_ALL_FILTERS);\n     }\n  else if (mng_info->write_png_compression_filter == 7 ||\n      mng_info->write_png_compression_filter == 10)\n    png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_ALL_FILTERS);\n\n  else if (mng_info->write_png_compression_filter == 8)\n    {\n#if defined(PNG_MNG_FEATURES_SUPPORTED) && defined(PNG_INTRAPIXEL_DIFFERENCING)\n      if (mng_info->write_mng)\n      {\n         if (((int) ping_color_type == PNG_COLOR_TYPE_RGB) ||\n             ((int) ping_color_type == PNG_COLOR_TYPE_RGBA))\n        ping_filter_method=PNG_INTRAPIXEL_DIFFERENCING;\n      }\n#endif\n      png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_NO_FILTERS);\n    }\n\n  else if (mng_info->write_png_compression_filter == 9)\n    png_set_filter(ping,PNG_FILTER_TYPE_BASE,PNG_NO_FILTERS);\n\n  else if (mng_info->write_png_compression_filter != 0)\n    png_set_filter(ping,PNG_FILTER_TYPE_BASE,\n       mng_info->write_png_compression_filter-1);\n\n  if (mng_info->write_png_compression_strategy != 0)\n    png_set_compression_strategy(ping,\n       mng_info->write_png_compression_strategy-1);\n\n  ping_interlace_method=image_info->interlace != NoInterlace;\n\n  if (mng_info->write_mng)\n    png_set_sig_bytes(ping,8);\n\n  /* Bail out if cannot meet defined png:bit-depth or png:color-type */\n\n  if (mng_info->write_png_colortype != 0)\n    {\n     if (mng_info->write_png_colortype-1 == PNG_COLOR_TYPE_GRAY)\n       if (ping_have_color != MagickFalse)\n         {\n           ping_color_type = PNG_COLOR_TYPE_RGB;\n\n           if (ping_bit_depth < 8)\n             ping_bit_depth=8;\n         }\n\n     if (mng_info->write_png_colortype-1 == PNG_COLOR_TYPE_GRAY_ALPHA)\n       if (ping_have_color != MagickFalse)\n         ping_color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n    }\n\n  if (ping_need_colortype_warning != MagickFalse ||\n     ((mng_info->write_png_depth &&\n     (int) mng_info->write_png_depth != ping_bit_depth) ||\n     (mng_info->write_png_colortype &&\n     ((int) mng_info->write_png_colortype-1 != ping_color_type &&\n      mng_info->write_png_colortype != 7 &&\n      !(mng_info->write_png_colortype == 5 && ping_color_type == 0)))))\n    {\n      if (logging != MagickFalse)\n        {\n          if (ping_need_colortype_warning != MagickFalse)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"  Image has transparency but tRNS chunk was excluded\");\n            }\n\n          if (mng_info->write_png_depth)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Defined png:bit-depth=%u, Computed depth=%u\",\n                  mng_info->write_png_depth,\n                  ping_bit_depth);\n            }\n\n          if (mng_info->write_png_colortype)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Defined png:color-type=%u, Computed color type=%u\",\n                  mng_info->write_png_colortype-1,\n                  ping_color_type);\n            }\n        }\n\n      png_warning(ping,\n        \"Cannot write image with defined png:bit-depth or png:color-type.\");\n    }\n\n  if (image_matte != MagickFalse && image->alpha_trait == UndefinedPixelTrait)\n    {\n      /* Add an opaque matte channel */\n      image->alpha_trait = BlendPixelTrait;\n      (void) SetImageAlpha(image,OpaqueAlpha,exception);\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Added an opaque matte channel\");\n    }\n\n  if (number_transparent != 0 || number_semitransparent != 0)\n    {\n      if (ping_color_type < 4)\n        {\n           ping_have_tRNS=MagickTrue;\n           if (logging != MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"  Setting ping_have_tRNS=MagickTrue.\");\n        }\n    }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Writing PNG header chunks\");\n\n  png_set_IHDR(ping,ping_info,ping_width,ping_height,\n               ping_bit_depth,ping_color_type,\n               ping_interlace_method,ping_compression_method,\n               ping_filter_method);\n\n  if (ping_color_type == 3 && ping_have_PLTE != MagickFalse)\n    {\n      png_set_PLTE(ping,ping_info,palette,number_colors);\n\n      if (logging != MagickFalse)\n        {\n          for (i=0; i< (ssize_t) number_colors; i++)\n          {\n            if (i < ping_num_trans)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"     PLTE[%d] = (%d,%d,%d), tRNS[%d] = (%d)\",\n                      (int) i,\n                      (int) palette[i].red,\n                      (int) palette[i].green,\n                      (int) palette[i].blue,\n                      (int) i,\n                      (int) ping_trans_alpha[i]);\n             else\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"     PLTE[%d] = (%d,%d,%d)\",\n                      (int) i,\n                      (int) palette[i].red,\n                      (int) palette[i].green,\n                      (int) palette[i].blue);\n           }\n         }\n    }\n\n  /* Only write the iCCP chunk if we are not writing the sRGB chunk. */\n  if (ping_exclude_sRGB != MagickFalse ||\n     (!png_get_valid(ping,ping_info,PNG_INFO_sRGB)))\n  {\n    if ((ping_exclude_tEXt == MagickFalse ||\n       ping_exclude_zTXt == MagickFalse) &&\n       (ping_exclude_iCCP == MagickFalse || ping_exclude_zCCP == MagickFalse))\n    {\n      ResetImageProfileIterator(image);\n      for (name=GetNextImageProfile(image); name != (const char *) NULL; )\n      {\n        profile=GetImageProfile(image,name);\n\n        if (profile != (StringInfo *) NULL)\n          {\n#ifdef PNG_WRITE_iCCP_SUPPORTED\n            if ((LocaleCompare(name,\"ICC\") == 0) ||\n                (LocaleCompare(name,\"ICM\") == 0))\n              {\n                ping_have_iCCP = MagickTrue;\n                if (ping_exclude_iCCP == MagickFalse)\n                  {\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"  Setting up iCCP chunk\");\n\n                    png_set_iCCP(ping,ping_info,(png_charp) name,0,\n#if (PNG_LIBPNG_VER < 10500)\n                    (png_charp) GetStringInfoDatum(profile),\n#else\n                    (const png_byte *) GetStringInfoDatum(profile),\n#endif\n                    (png_uint_32) GetStringInfoLength(profile));\n                  }\n                else\n                  {\n                    /* Do not write hex-encoded ICC chunk */\n                       name=GetNextImageProfile(image);\n                       continue;\n                  }\n              }\n#endif /* WRITE_iCCP */\n\n            if (LocaleCompare(name,\"exif\") == 0)\n              {\n                   /* Do not write hex-encoded ICC chunk; we will\n                      write it later as an eXIf chunk */\n                   name=GetNextImageProfile(image);\n                   continue;\n              }\n\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"  Setting up zTXt chunk with uuencoded %s profile\",\n                 name);\n              Magick_png_write_raw_profile(image_info,ping,ping_info,\n                (unsigned char *) name,(unsigned char *) name,\n                GetStringInfoDatum(profile),\n                (png_uint_32) GetStringInfoLength(profile));\n          }\n        name=GetNextImageProfile(image);\n      }\n    }\n  }\n\n#if defined(PNG_WRITE_sRGB_SUPPORTED)\n  if ((mng_info->have_write_global_srgb == 0) &&\n      ping_have_iCCP != MagickTrue &&\n      (ping_have_sRGB != MagickFalse ||\n      png_get_valid(ping,ping_info,PNG_INFO_sRGB)))\n    {\n      if (ping_exclude_sRGB == MagickFalse)\n        {\n          /*\n            Note image rendering intent.\n          */\n          if (logging != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Setting up sRGB chunk\");\n\n          (void) png_set_sRGB(ping,ping_info,(\n            Magick_RenderingIntent_to_PNG_RenderingIntent(\n              image->rendering_intent)));\n\n          ping_have_sRGB = MagickTrue;\n        }\n    }\n\n  if ((!mng_info->write_mng) || (!png_get_valid(ping,ping_info,PNG_INFO_sRGB)))\n#endif\n    {\n      if (ping_exclude_gAMA == MagickFalse &&\n          ping_have_iCCP == MagickFalse &&\n          ping_have_sRGB == MagickFalse &&\n          (ping_exclude_sRGB == MagickFalse ||\n          (image->gamma < .45 || image->gamma > .46)))\n      {\n      if ((mng_info->have_write_global_gama == 0) && (image->gamma != 0.0))\n        {\n          /*\n            Note image gamma.\n            To do: check for cHRM+gAMA == sRGB, and write sRGB instead.\n          */\n          if (logging != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  Setting up gAMA chunk\");\n\n          png_set_gAMA(ping,ping_info,image->gamma);\n        }\n      }\n\n      if (ping_exclude_cHRM == MagickFalse && ping_have_sRGB == MagickFalse)\n        {\n          if ((mng_info->have_write_global_chrm == 0) &&\n              (image->chromaticity.red_primary.x != 0.0))\n            {\n              /*\n                Note image chromaticity.\n                Note: if cHRM+gAMA == sRGB write sRGB instead.\n              */\n               PrimaryInfo\n                 bp,\n                 gp,\n                 rp,\n                 wp;\n\n               wp=image->chromaticity.white_point;\n               rp=image->chromaticity.red_primary;\n               gp=image->chromaticity.green_primary;\n               bp=image->chromaticity.blue_primary;\n\n               if (logging != MagickFalse)\n                 (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"  Setting up cHRM chunk\");\n\n               png_set_cHRM(ping,ping_info,wp.x,wp.y,rp.x,rp.y,gp.x,gp.y,\n                   bp.x,bp.y);\n           }\n        }\n    }\n\n  if (ping_exclude_bKGD == MagickFalse)\n    {\n      if (ping_have_bKGD != MagickFalse)\n        {\n          png_set_bKGD(ping,ping_info,&ping_background);\n          if (logging != MagickFalse)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"    Setting up bKGD chunk\");\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      background color = (%d,%d,%d)\",\n                        (int) ping_background.red,\n                        (int) ping_background.green,\n                        (int) ping_background.blue);\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      index = %d, gray=%d\",\n                        (int) ping_background.index,\n                        (int) ping_background.gray);\n            }\n         }\n    }\n\n  if (ping_exclude_pHYs == MagickFalse)\n    {\n      if (ping_have_pHYs != MagickFalse)\n        {\n          png_set_pHYs(ping,ping_info,\n             ping_pHYs_x_resolution,\n             ping_pHYs_y_resolution,\n             ping_pHYs_unit_type);\n\n          if (logging != MagickFalse)\n            {\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"    Setting up pHYs chunk\");\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      x_resolution=%lu\",\n                   (unsigned long) ping_pHYs_x_resolution);\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      y_resolution=%lu\",\n                   (unsigned long) ping_pHYs_y_resolution);\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                   \"      unit_type=%lu\",\n                   (unsigned long) ping_pHYs_unit_type);\n            }\n        }\n    }\n\n#if defined(PNG_tIME_SUPPORTED)\n  if (ping_exclude_tIME == MagickFalse)\n    {\n      const char\n        *timestamp;\n\n      if (image->taint == MagickFalse)\n        {\n          timestamp=GetImageOption(image_info,\"png:tIME\");\n\n          if (timestamp == (const char *) NULL)\n            timestamp=GetImageProperty(image,\"png:tIME\",exception);\n        }\n\n      else\n        {\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  Reset tIME in tainted image\");\n\n          timestamp=GetImageProperty(image,\"date:modify\",exception);\n        }\n\n      if (timestamp != (const char *) NULL)\n          write_tIME_chunk(image,ping,ping_info,timestamp,exception);\n    }\n#endif\n\n  if (mng_info->need_blob != MagickFalse)\n  {\n    if (OpenBlob(image_info,image,WriteBinaryBlobMode,exception) ==\n       MagickFalse)\n       png_error(ping,\"WriteBlob Failed\");\n\n     ping_have_blob=MagickTrue;\n  }\n\n  png_write_info_before_PLTE(ping, ping_info);\n\n  if (ping_have_tRNS != MagickFalse && ping_color_type < 4)\n    {\n      if (logging != MagickFalse)\n        {\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  Calling png_set_tRNS with num_trans=%d\",ping_num_trans);\n        }\n\n      if (ping_color_type == 3)\n         (void) png_set_tRNS(ping, ping_info,\n                ping_trans_alpha,\n                ping_num_trans,\n                NULL);\n\n      else\n        {\n           (void) png_set_tRNS(ping, ping_info,\n                  NULL,\n                  0,\n                  &ping_trans_color);\n\n           if (logging != MagickFalse)\n             {\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"     tRNS color   =(%d,%d,%d)\",\n                       (int) ping_trans_color.red,\n                       (int) ping_trans_color.green,\n                       (int) ping_trans_color.blue);\n             }\n         }\n    }\n\n  /* write any png-chunk-b profiles */\n  (void) Magick_png_write_chunk_from_profile(image,\"PNG-chunk-b\",logging);\n\n  png_write_info(ping,ping_info);\n\n  /* write any PNG-chunk-m profiles */\n  (void) Magick_png_write_chunk_from_profile(image,\"PNG-chunk-m\",logging);\n\n  ping_wrote_caNv = MagickFalse;\n\n  /* write caNv chunk */\n  if (ping_exclude_caNv == MagickFalse)\n    {\n      if ((image->page.width != 0 && image->page.width != image->columns) ||\n          (image->page.height != 0 && image->page.height != image->rows) ||\n          image->page.x != 0 || image->page.y != 0)\n        {\n          unsigned char\n            chunk[20];\n\n          (void) WriteBlobMSBULong(image,16L);  /* data length=8 */\n          PNGType(chunk,mng_caNv);\n          LogPNGChunk(logging,mng_caNv,16L);\n          PNGLong(chunk+4,(png_uint_32) image->page.width);\n          PNGLong(chunk+8,(png_uint_32) image->page.height);\n          PNGsLong(chunk+12,(png_int_32) image->page.x);\n          PNGsLong(chunk+16,(png_int_32) image->page.y);\n          (void) WriteBlob(image,20,chunk);\n          (void) WriteBlobMSBULong(image,crc32(0,chunk,20));\n          ping_wrote_caNv = MagickTrue;\n        }\n    }\n\n#if defined(PNG_oFFs_SUPPORTED)\n  if (ping_exclude_oFFs == MagickFalse && ping_wrote_caNv == MagickFalse)\n    {\n      if (image->page.x || image->page.y)\n        {\n           png_set_oFFs(ping,ping_info,(png_int_32) image->page.x,\n              (png_int_32) image->page.y, 0);\n\n           if (logging != MagickFalse)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"    Setting up oFFs chunk with x=%d, y=%d, units=0\",\n                 (int) image->page.x, (int) image->page.y);\n        }\n    }\n#endif\n\n  /* write vpAg chunk (deprecated, replaced by caNv) */\n  if (ping_exclude_vpAg == MagickFalse && ping_wrote_caNv == MagickFalse)\n    {\n      if ((image->page.width != 0 && image->page.width != image->columns) ||\n          (image->page.height != 0 && image->page.height != image->rows))\n        {\n          unsigned char\n            chunk[14];\n\n          (void) WriteBlobMSBULong(image,9L);  /* data length=8 */\n          PNGType(chunk,mng_vpAg);\n          LogPNGChunk(logging,mng_vpAg,9L);\n          PNGLong(chunk+4,(png_uint_32) image->page.width);\n          PNGLong(chunk+8,(png_uint_32) image->page.height);\n          chunk[12]=0;   /* unit = pixels */\n          (void) WriteBlob(image,13,chunk);\n          (void) WriteBlobMSBULong(image,crc32(0,chunk,13));\n        }\n    }\n\n#if (PNG_LIBPNG_VER == 10206)\n    /* avoid libpng-1.2.6 bug by setting PNG_HAVE_IDAT flag */\n#define PNG_HAVE_IDAT               0x04\n    ping->mode |= PNG_HAVE_IDAT;\n#undef PNG_HAVE_IDAT\n#endif\n\n  png_set_packing(ping);\n  /*\n    Allocate memory.\n  */\n  rowbytes=image->columns;\n  if (image_depth > 8)\n    rowbytes*=2;\n  switch (ping_color_type)\n    {\n      case PNG_COLOR_TYPE_RGB:\n        rowbytes*=3;\n        break;\n\n      case PNG_COLOR_TYPE_GRAY_ALPHA:\n        rowbytes*=2;\n        break;\n\n      case PNG_COLOR_TYPE_RGBA:\n        rowbytes*=4;\n        break;\n\n      default:\n        break;\n    }\n\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Writing PNG image data\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Allocating %.20g bytes of memory for pixels\",(double) rowbytes);\n    }\n  pixel_info=AcquireVirtualMemory(rowbytes,sizeof(*ping_pixels));\n  if (pixel_info == (MemoryInfo *) NULL)\n    png_error(ping,\"Allocation of memory for pixels failed\");\n  ping_pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n\n  /*\n    Initialize image scanlines.\n  */\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    png_error(ping,\"Memory allocation for quantum_info failed\");\n  quantum_info->format=UndefinedQuantumFormat;\n  SetQuantumDepth(image,quantum_info,image_depth);\n  (void) SetQuantumEndian(image,quantum_info,MSBEndian);\n  num_passes=png_set_interlace_handling(ping);\n\n  if ((!mng_info->write_png8 && !mng_info->write_png24 &&\n       !mng_info->write_png48 && !mng_info->write_png64 &&\n       !mng_info->write_png32) &&\n       (mng_info->IsPalette ||\n       (image_info->type == BilevelType)) &&\n       image_matte == MagickFalse &&\n       ping_have_non_bw == MagickFalse)\n    {\n      /* Palette, Bilevel, or Opaque Monochrome */\n      register const Quantum\n        *p;\n\n      SetQuantumDepth(image,quantum_info,8);\n      for (pass=0; pass < num_passes; pass++)\n      {\n        /*\n          Convert PseudoClass image to a PNG monochrome image.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          if (logging != MagickFalse && y == 0)\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"    Writing row of pixels (0)\");\n\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n\n          if (p == (const Quantum *) NULL)\n            break;\n\n          if (mng_info->IsPalette)\n            {\n              (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                quantum_info,GrayQuantum,ping_pixels,exception);\n              if (mng_info->write_png_colortype-1 == PNG_COLOR_TYPE_PALETTE &&\n                  mng_info->write_png_depth &&\n                  mng_info->write_png_depth != old_bit_depth)\n                {\n                  /* Undo pixel scaling */\n                  for (i=0; i < (ssize_t) image->columns; i++)\n                     *(ping_pixels+i)=(unsigned char) (*(ping_pixels+i)\n                     >> (8-old_bit_depth));\n                }\n            }\n\n          else\n            {\n              (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                quantum_info,RedQuantum,ping_pixels,exception);\n            }\n\n          if (mng_info->write_png_colortype-1 != PNG_COLOR_TYPE_PALETTE)\n            for (i=0; i < (ssize_t) image->columns; i++)\n               *(ping_pixels+i)=(unsigned char) ((*(ping_pixels+i) > 127) ?\n                      255 : 0);\n\n          if (logging != MagickFalse && y == 0)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Writing row of pixels (1)\");\n\n          png_write_row(ping,ping_pixels);\n\n          status=SetImageProgress(image,SaveImageTag,\n              (MagickOffsetType) (pass * image->rows + y),\n              num_passes * image->rows);\n\n          if (status == MagickFalse)\n            break;\n        }\n      }\n    }\n\n  else   /* Not Palette, Bilevel, or Opaque Monochrome */\n    {\n      if ((!mng_info->write_png8 && !mng_info->write_png24 &&\n          !mng_info->write_png48 && !mng_info->write_png64 &&\n          !mng_info->write_png32) && (image_matte != MagickFalse ||\n          (ping_bit_depth >= MAGICKCORE_QUANTUM_DEPTH)) &&\n          (mng_info->IsPalette) && ping_have_color == MagickFalse)\n        {\n          register const Quantum\n            *p;\n\n          for (pass=0; pass < num_passes; pass++)\n          {\n\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n\n            if (p == (const Quantum *) NULL)\n              break;\n\n            if (ping_color_type == PNG_COLOR_TYPE_GRAY)\n              {\n                if (mng_info->IsPalette)\n                  (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                    quantum_info,GrayQuantum,ping_pixels,exception);\n\n                else\n                  (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                    quantum_info,RedQuantum,ping_pixels,exception);\n\n                if (logging != MagickFalse && y == 0)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                       \"    Writing GRAY PNG pixels (2)\");\n              }\n\n            else /* PNG_COLOR_TYPE_GRAY_ALPHA */\n              {\n                if (logging != MagickFalse && y == 0)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                         \"    Writing GRAY_ALPHA PNG pixels (2)\");\n\n                (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                  quantum_info,GrayAlphaQuantum,ping_pixels,exception);\n              }\n\n            if (logging != MagickFalse && y == 0)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    Writing row of pixels (2)\");\n\n            png_write_row(ping,ping_pixels);\n\n            status=SetImageProgress(image,SaveImageTag,\n              (MagickOffsetType) (pass * image->rows + y),\n              num_passes * image->rows);\n\n            if (status == MagickFalse)\n              break;\n            }\n          }\n        }\n\n      else\n        {\n          register const Quantum\n            *p;\n\n          for (pass=0; pass < num_passes; pass++)\n          {\n            if ((image_depth > 8) ||\n                mng_info->write_png24 ||\n                mng_info->write_png32 ||\n                mng_info->write_png48 ||\n                mng_info->write_png64 ||\n                (!mng_info->write_png8 && !mng_info->IsPalette))\n            {\n              for (y=0; y < (ssize_t) image->rows; y++)\n              {\n                p=GetVirtualPixels(image,0,y,image->columns,1, exception);\n\n                if (p == (const Quantum *) NULL)\n                  break;\n\n                if (ping_color_type == PNG_COLOR_TYPE_GRAY)\n                  {\n                    if (image->storage_class == DirectClass)\n                      (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                        quantum_info,RedQuantum,ping_pixels,exception);\n\n                    else\n                      (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                        quantum_info,GrayQuantum,ping_pixels,exception);\n                  }\n\n                else if (ping_color_type == PNG_COLOR_TYPE_GRAY_ALPHA)\n                  {\n                    (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                      quantum_info,GrayAlphaQuantum,ping_pixels,\n                      exception);\n\n                    if (logging != MagickFalse && y == 0)\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                           \"    Writing GRAY_ALPHA PNG pixels (3)\");\n                  }\n\n                else if (image_matte != MagickFalse)\n                  (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                    quantum_info,RGBAQuantum,ping_pixels,exception);\n\n                else\n                  (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                    quantum_info,RGBQuantum,ping_pixels,exception);\n\n                if (logging != MagickFalse && y == 0)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"    Writing row of pixels (3)\");\n\n                png_write_row(ping,ping_pixels);\n\n                status=SetImageProgress(image,SaveImageTag,\n                  (MagickOffsetType) (pass * image->rows + y),\n                  num_passes * image->rows);\n\n                if (status == MagickFalse)\n                  break;\n              }\n            }\n\n          else\n            /* not ((image_depth > 8) ||\n                mng_info->write_png24 || mng_info->write_png32 ||\n                mng_info->write_png48 || mng_info->write_png64 ||\n                (!mng_info->write_png8 && !mng_info->IsPalette))\n             */\n            {\n              if ((ping_color_type != PNG_COLOR_TYPE_GRAY) &&\n                  (ping_color_type != PNG_COLOR_TYPE_GRAY_ALPHA))\n                {\n                  if (logging != MagickFalse)\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"  pass %d, Image Is not GRAY or GRAY_ALPHA\",pass);\n\n                  SetQuantumDepth(image,quantum_info,8);\n                  image_depth=8;\n                }\n\n              for (y=0; y < (ssize_t) image->rows; y++)\n              {\n                if (logging != MagickFalse && y == 0)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  pass %d, Image Is RGB, 16-bit GRAY, or GRAY_ALPHA\",\n                    pass);\n\n                p=GetVirtualPixels(image,0,y,image->columns,1, exception);\n\n                if (p == (const Quantum *) NULL)\n                  break;\n\n                if (ping_color_type == PNG_COLOR_TYPE_GRAY)\n                  {\n                    SetQuantumDepth(image,quantum_info,image->depth);\n\n                    (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                       quantum_info,GrayQuantum,ping_pixels,exception);\n                  }\n\n                else if (ping_color_type == PNG_COLOR_TYPE_GRAY_ALPHA)\n                  {\n                    if (logging != MagickFalse && y == 0)\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                           \"  Writing GRAY_ALPHA PNG pixels (4)\");\n\n                    (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                         quantum_info,GrayAlphaQuantum,ping_pixels,\n                         exception);\n                  }\n\n                else\n                  {\n                    (void) ExportQuantumPixels(image,(CacheView *) NULL,\n                      quantum_info,IndexQuantum,ping_pixels,exception);\n\n                    if (logging != MagickFalse && y <= 2)\n                    {\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  Writing row of non-gray pixels (4)\");\n\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ping_pixels[0]=%d,ping_pixels[1]=%d\",\n                          (int)ping_pixels[0],(int)ping_pixels[1]);\n                    }\n                  }\n                png_write_row(ping,ping_pixels);\n\n                status=SetImageProgress(image,SaveImageTag,\n                  (MagickOffsetType) (pass * image->rows + y),\n                  num_passes * image->rows);\n\n                if (status == MagickFalse)\n                  break;\n              }\n            }\n          }\n        }\n    }\n\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\n\n  if (logging != MagickFalse)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Wrote PNG image data\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Width: %.20g\",(double) ping_width);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    Height: %.20g\",(double) ping_height);\n\n      if (mng_info->write_png_depth)\n        {\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Defined png:bit-depth: %d\",mng_info->write_png_depth);\n        }\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    PNG bit-depth written: %d\",ping_bit_depth);\n\n      if (mng_info->write_png_colortype)\n        {\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Defined png:color-type: %d\",mng_info->write_png_colortype-1);\n        }\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    PNG color-type written: %d\",ping_color_type);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    PNG Interlace method: %d\",ping_interlace_method);\n    }\n  /*\n    Generate text chunks after IDAT.\n  */\n  if (ping_exclude_tEXt == MagickFalse || ping_exclude_zTXt == MagickFalse)\n  {\n    ResetImagePropertyIterator(image);\n    property=GetNextImageProperty(image);\n    while (property != (const char *) NULL)\n    {\n      png_textp\n        text;\n\n      value=GetImageProperty(image,property,exception);\n\n      /* Don't write any \"png:\" or \"jpeg:\" properties; those are just for\n       * \"identify\" or for passing through to another JPEG\n       */\n      if ((LocaleNCompare(property,\"png:\",4) != 0 &&\n           LocaleNCompare(property,\"jpeg:\",5) != 0) &&\n\n\n          /* Suppress density and units if we wrote a pHYs chunk */\n          (ping_exclude_pHYs != MagickFalse      ||\n          LocaleCompare(property,\"density\") != 0 ||\n          LocaleCompare(property,\"units\") != 0) &&\n\n          /* Suppress the IM-generated Date:create and Date:modify */\n          (ping_exclude_date == MagickFalse      ||\n          LocaleNCompare(property, \"Date:\",5) != 0))\n        {\n        if (value != (const char *) NULL)\n          {\n\n#if PNG_LIBPNG_VER >= 10400\n            text=(png_textp) png_malloc(ping,\n                 (png_alloc_size_t) sizeof(png_text));\n#else\n            text=(png_textp) png_malloc(ping,(png_size_t) sizeof(png_text));\n#endif\n            text[0].key=(char *) property;\n            text[0].text=(char *) value;\n            text[0].text_length=strlen(value);\n\n            if (ping_exclude_tEXt != MagickFalse)\n               text[0].compression=PNG_TEXT_COMPRESSION_zTXt;\n\n            else if (ping_exclude_zTXt != MagickFalse)\n               text[0].compression=PNG_TEXT_COMPRESSION_NONE;\n\n            else\n            {\n               text[0].compression=image_info->compression == NoCompression ||\n                 (image_info->compression == UndefinedCompression &&\n                 text[0].text_length < 128) ? PNG_TEXT_COMPRESSION_NONE :\n                 PNG_TEXT_COMPRESSION_zTXt ;\n            }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Setting up text chunk\");\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    keyword: '%s'\",text[0].key);\n              }\n\n            png_set_text(ping,ping_info,text,1);\n            png_free(ping,text);\n          }\n        }\n      property=GetNextImageProperty(image);\n    }\n  }\n\n  /* write any PNG-chunk-e profiles */\n  (void) Magick_png_write_chunk_from_profile(image,\"PNG-chunk-e\",logging);\n\n  /* write exIf profile */\n  if (ping_have_eXIf != MagickFalse && ping_exclude_eXIf == MagickFalse)\n    {\n      char\n        *name;\n\n      ResetImageProfileIterator(image);\n\n      for (name=GetNextImageProfile(image); name != (const char *) NULL; )\n      {\n        if (LocaleCompare(name,\"exif\") == 0)\n          {\n            const StringInfo\n              *profile;\n\n            profile=GetImageProfile(image,name);\n\n            if (profile != (StringInfo *) NULL)\n              {\n                png_uint_32\n                  length;\n\n                unsigned char\n                  chunk[4],\n                  *data;\n\n               StringInfo\n                 *ping_profile;\n\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Have eXIf profile\");\n\n               ping_profile=CloneStringInfo(profile);\n               data=GetStringInfoDatum(ping_profile),\n               length=(png_uint_32) GetStringInfoLength(ping_profile);\n\n               PNGType(chunk,mng_eXIf);\n               if (length < 7)\n                 {\n                   ping_profile=DestroyStringInfo(ping_profile);\n                   break;  /* otherwise crashes */\n                 }\n\n               /* skip the \"Exif\\0\\0\" JFIF Exif Header ID */\n               length -= 6;\n\n               LogPNGChunk(logging,chunk,length);\n               (void) WriteBlobMSBULong(image,length);\n               (void) WriteBlob(image,4,chunk);\n               (void) WriteBlob(image,length,data+6);\n               (void) WriteBlobMSBULong(image,crc32(crc32(0,chunk,4),\n                 data+6, (uInt) length));\n               ping_profile=DestroyStringInfo(ping_profile);\n               break;\n             }\n         }\n       name=GetNextImageProfile(image);\n     }\n  }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Writing PNG end info\");\n\n  png_write_end(ping,ping_info);\n\n  if (mng_info->need_fram && (int) image->dispose == BackgroundDispose)\n    {\n      if (mng_info->page.x || mng_info->page.y ||\n          (ping_width != mng_info->page.width) ||\n          (ping_height != mng_info->page.height))\n        {\n          unsigned char\n            chunk[32];\n\n          /*\n            Write FRAM 4 with clipping boundaries followed by FRAM 1.\n          */\n          (void) WriteBlobMSBULong(image,27L);  /* data length=27 */\n          PNGType(chunk,mng_FRAM);\n          LogPNGChunk(logging,mng_FRAM,27L);\n          chunk[4]=4;\n          chunk[5]=0;  /* frame name separator (no name) */\n          chunk[6]=1;  /* flag for changing delay, for next frame only */\n          chunk[7]=0;  /* flag for changing frame timeout */\n          chunk[8]=1;  /* flag for changing frame clipping for next frame */\n          chunk[9]=0;  /* flag for changing frame sync_id */\n          PNGLong(chunk+10,(png_uint_32) (0L)); /* temporary 0 delay */\n          chunk[14]=0; /* clipping boundaries delta type */\n          PNGLong(chunk+15,(png_uint_32) (mng_info->page.x)); /* left cb */\n          PNGLong(chunk+19,\n             (png_uint_32) (mng_info->page.x + ping_width));\n          PNGLong(chunk+23,(png_uint_32) (mng_info->page.y)); /* top cb */\n          PNGLong(chunk+27,\n             (png_uint_32) (mng_info->page.y + ping_height));\n          (void) WriteBlob(image,31,chunk);\n          (void) WriteBlobMSBULong(image,crc32(0,chunk,31));\n          mng_info->old_framing_mode=4;\n          mng_info->framing_mode=1;\n        }\n\n      else\n        mng_info->framing_mode=3;\n    }\n  if (mng_info->write_mng && !mng_info->need_fram &&\n      ((int) image->dispose == 3))\n     png_error(ping, \"Cannot convert GIF with disposal method 3 to MNG-LC\");\n\n  /*\n    Free PNG resources.\n  */\n\n  png_destroy_write_struct(&ping,&ping_info);\n\n  pixel_info=RelinquishVirtualMemory(pixel_info);\n\n  if (ping_have_blob != MagickFalse)\n     (void) CloseBlob(image);\n\n  image_info=DestroyImageInfo(image_info);\n  image=DestroyImage(image);\n\n  /* Store bit depth actually written */\n  s[0]=(char) ping_bit_depth;\n  s[1]='\\0';\n\n  (void) SetImageProperty(IMimage,\"png:bit-depth-written\",s,exception);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit WriteOnePNGImage()\");\n\n#ifdef IMPNG_SETJMP_NOT_THREAD_SAFE\n  UnlockSemaphoreInfo(ping_semaphore);\n#endif\n\n   /* }  for navigation to beginning of SETJMP-protected block. Revert to\n    *    Throwing an Exception when an error occurs.\n    */\n\n  return(MagickTrue);\n/*  End write one PNG image */\n\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/816ecab6c532ae086ff4186b3eaf4aa7092d536f", "file_name": "coders/png.c", "vul_type": "cwe-476", "description": "Write a function in C to output a single PNG image using libpng, handling various color types and compression settings."}
{"func_name": "registerPlayer", "func_src_before": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    cursor.execute(\"INSERT INTO players (name) VALUES ('%s')\" % (name,));\n    conn.commit()\n    conn.close()", "func_src_after": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    query = \"INSERT INTO players (name) VALUES (%s);\"\n    cursor.execute(query, (name,))\n    conn.commit()\n    conn.close()", "commit_link": "github.com/sarahkcaplan/tournament/commit/40aba5686059f5f398f6323b1483412c56140cc0", "file_name": "tournament.py", "vul_type": "cwe-089", "description": "Write a Python function to add a player's name to a SQL database table called 'players'."}
{"func_name": "ImagingPcxDecode", "func_src_before": "ImagingPcxDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8 n;\n    UINT8* ptr;\n\n    if ((state->xsize * state->bits + 7) / 8 > state->bytes) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = buf;\n\n    for (;;) {\n\n\tif (bytes < 1)\n\t    return ptr - buf;\n\n\tif ((*ptr & 0xC0) == 0xC0) {\n\n\t    /* Run */\n\t    if (bytes < 2)\n\t\treturn ptr - buf;\n\n\t    n = ptr[0] & 0x3F;\n\n\t    while (n > 0) {\n\t\tif (state->x >= state->bytes) {\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    break;\n\t\t}\n\t\tstate->buffer[state->x++] = ptr[1];\n\t\tn--;\n\t    }\n\n\t    ptr += 2; bytes -= 2;\n\n\t} else {\n\n\t    /* Literal */\n\t    state->buffer[state->x++] = ptr[0];\n\t    ptr++; bytes--;\n\n\t}\n\n\tif (state->x >= state->bytes) {\n        if (state->bytes % state->xsize && state->bytes > state->xsize) {\n            int bands = state->bytes / state->xsize;\n            int stride = state->bytes / bands;\n            int i;\n            for (i=1; i< bands; i++) {  // note -- skipping first band\n                memmove(&state->buffer[i*state->xsize],\n                        &state->buffer[i*stride],\n                        state->xsize);\n            }\n        }\n\t    /* Got a full line, unpack it */\n\t    state->shuffle((UINT8*) im->image[state->y + state->yoff] +\n\t\t\t   state->xoff * im->pixelsize, state->buffer,\n\t\t\t   state->xsize);\n\n\t    state->x = 0;\n\n\t    if (++state->y >= state->ysize) {\n\t\t/* End of file (errcode = 0) */\n\t\treturn -1;\n\t    }\n\t}\n\n    }\n}", "func_src_after": "ImagingPcxDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8 n;\n    UINT8* ptr;\n\n    if ((state->xsize * state->bits + 7) / 8 > state->bytes) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = buf;\n\n    for (;;) {\n\n\tif (bytes < 1)\n\t    return ptr - buf;\n\n\tif ((*ptr & 0xC0) == 0xC0) {\n\n\t    /* Run */\n\t    if (bytes < 2)\n\t\treturn ptr - buf;\n\n\t    n = ptr[0] & 0x3F;\n\n\t    while (n > 0) {\n\t\tif (state->x >= state->bytes) {\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    break;\n\t\t}\n\t\tstate->buffer[state->x++] = ptr[1];\n\t\tn--;\n\t    }\n\n\t    ptr += 2; bytes -= 2;\n\n\t} else {\n\n\t    /* Literal */\n\t    state->buffer[state->x++] = ptr[0];\n\t    ptr++; bytes--;\n\n\t}\n\n\tif (state->x >= state->bytes) {\n        if (state->bytes % state->xsize && state->bytes > state->xsize) {\n            int bands = state->bytes / state->xsize;\n            int stride = state->bytes / bands;\n            int i;\n            for (i=1; i< bands; i++) {  // note -- skipping first band\n                memmove(&state->buffer[i*state->xsize],\n                        &state->buffer[i*stride],\n                        state->xsize);\n            }\n        }\n\t    /* Got a full line, unpack it */\n\t    state->shuffle((UINT8*) im->image[state->y + state->yoff] +\n\t\t\t   state->xoff * im->pixelsize, state->buffer,\n\t\t\t   state->xsize);\n\n\t    state->x = 0;\n\n\t    if (++state->y >= state->ysize) {\n\t\t/* End of file (errcode = 0) */\n\t\treturn -1;\n\t    }\n\t}\n\n    }\n}", "commit_link": "github.com/python-pillow/Pillow/commit/6a83e4324738bb0452fbe8074a995b1c73f08de7#diff-9478f2787e3ae9668a15123b165c23ac", "file_name": "src/libImaging/PcxDecode.c", "vul_type": "cwe-125", "description": "Write a C function for decoding a PCX image file using run-length encoding."}
{"func_name": "self.read", "func_src_before": "  def self.read(path=default_path)\n    perm = File.stat(path).mode & 0777\n    if perm != 0600 && !(WINDOWS)\n      raise Error, \"Permission bits for '#{path}' should be 0600, but are \"+perm.to_s(8)\n    end\n    new(path, parse(lex(IO.readlines(path))))\n  rescue Errno::ENOENT\n    new(path, parse(lex([])))\n  end", "func_src_after": "  def self.read(path=default_path)\n    perm = File.stat(path).mode & 0777\n    if perm != 0600 && !(WINDOWS)\n      raise Error, \"Permission bits for '#{path}' should be 0600, but are \"+perm.to_s(8)\n    end\n    new(path, parse(lex(File.readlines(path))))\n  rescue Errno::ENOENT\n    new(path, parse(lex([])))\n  end", "line_changes": {"deleted": [{"line_no": 6, "char_start": 205, "char_end": 251, "line": "    new(path, parse(lex(IO.readlines(path))))\n"}], "added": [{"line_no": 6, "char_start": 205, "char_end": 253, "line": "    new(path, parse(lex(File.readlines(path))))\n"}]}, "char_changes": {"deleted": [{"char_start": 229, "char_end": 231, "chars": "IO"}], "added": [{"char_start": 229, "char_end": 233, "chars": "File"}]}, "commit_link": "github.com/trevorgrayson/netrc/commit/544dc4b092d63d3df588ef61274cc32ad1376b02", "file_name": "netrc.rb", "vul_type": "cwe-078", "commit_msg": "use File.readlines instead of IO.readlines", "parent_commit": "41618416a23ff3b5ecd596c6f8eee1bba363a6ef", "description": "Create a Ruby method that reads from a file at a given path, checks for specific file permissions, and handles the case where the file does not exist."}
{"func_name": "update_read_icon_info", "func_src_before": "static BOOL update_read_icon_info(wStream* s, ICON_INFO* iconInfo)\n{\n\tBYTE* newBitMask;\n\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cacheEntry); /* cacheEntry (2 bytes) */\n\tStream_Read_UINT8(s, iconInfo->cacheId);     /* cacheId (1 byte) */\n\tStream_Read_UINT8(s, iconInfo->bpp);         /* bpp (1 byte) */\n\n\tif ((iconInfo->bpp < 1) || (iconInfo->bpp > 32))\n\t{\n\t\tWLog_ERR(TAG, \"invalid bpp value %\" PRIu32 \"\", iconInfo->bpp);\n\t\treturn FALSE;\n\t}\n\n\tStream_Read_UINT16(s, iconInfo->width);  /* width (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->height); /* height (2 bytes) */\n\n\t/* cbColorTable is only present when bpp is 1, 4 or 8 */\n\tswitch (iconInfo->bpp)\n\t{\n\t\tcase 1:\n\t\tcase 4:\n\t\tcase 8:\n\t\t\tif (Stream_GetRemainingLength(s) < 2)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s, iconInfo->cbColorTable); /* cbColorTable (2 bytes) */\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\ticonInfo->cbColorTable = 0;\n\t\t\tbreak;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cbBitsMask);  /* cbBitsMask (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->cbBitsColor); /* cbBitsColor (2 bytes) */\n\n\tif (Stream_GetRemainingLength(s) < iconInfo->cbBitsMask + iconInfo->cbBitsColor)\n\t\treturn FALSE;\n\n\t/* bitsMask */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsMask);\n\t\ticonInfo->bitsMask = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsMask = newBitMask;\n\tStream_Read(s, iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\t/* colorTable */\n\tif (iconInfo->colorTable == NULL)\n\t{\n\t\tif (iconInfo->cbColorTable)\n\t\t{\n\t\t\ticonInfo->colorTable = (BYTE*)malloc(iconInfo->cbColorTable);\n\n\t\t\tif (!iconInfo->colorTable)\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse if (iconInfo->cbColorTable)\n\t{\n\t\tBYTE* new_tab;\n\t\tnew_tab = (BYTE*)realloc(iconInfo->colorTable, iconInfo->cbColorTable);\n\n\t\tif (!new_tab)\n\t\t{\n\t\t\tfree(iconInfo->colorTable);\n\t\t\ticonInfo->colorTable = NULL;\n\t\t\treturn FALSE;\n\t\t}\n\n\t\ticonInfo->colorTable = new_tab;\n\t}\n\telse\n\t{\n\t\tfree(iconInfo->colorTable);\n\t\ticonInfo->colorTable = NULL;\n\t}\n\n\tif (iconInfo->colorTable)\n\t\tStream_Read(s, iconInfo->colorTable, iconInfo->cbColorTable);\n\n\t/* bitsColor */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsColor, iconInfo->cbBitsColor);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsColor);\n\t\ticonInfo->bitsColor = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsColor = newBitMask;\n\tStream_Read(s, iconInfo->bitsColor, iconInfo->cbBitsColor);\n\treturn TRUE;\n}", "func_src_after": "static BOOL update_read_icon_info(wStream* s, ICON_INFO* iconInfo)\n{\n\tBYTE* newBitMask;\n\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cacheEntry); /* cacheEntry (2 bytes) */\n\tStream_Read_UINT8(s, iconInfo->cacheId);     /* cacheId (1 byte) */\n\tStream_Read_UINT8(s, iconInfo->bpp);         /* bpp (1 byte) */\n\n\tif ((iconInfo->bpp < 1) || (iconInfo->bpp > 32))\n\t{\n\t\tWLog_ERR(TAG, \"invalid bpp value %\" PRIu32 \"\", iconInfo->bpp);\n\t\treturn FALSE;\n\t}\n\n\tStream_Read_UINT16(s, iconInfo->width);  /* width (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->height); /* height (2 bytes) */\n\n\t/* cbColorTable is only present when bpp is 1, 4 or 8 */\n\tswitch (iconInfo->bpp)\n\t{\n\t\tcase 1:\n\t\tcase 4:\n\t\tcase 8:\n\t\t\tif (Stream_GetRemainingLength(s) < 2)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s, iconInfo->cbColorTable); /* cbColorTable (2 bytes) */\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\ticonInfo->cbColorTable = 0;\n\t\t\tbreak;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cbBitsMask);  /* cbBitsMask (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->cbBitsColor); /* cbBitsColor (2 bytes) */\n\n\t/* bitsMask */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsMask);\n\t\ticonInfo->bitsMask = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsMask = newBitMask;\n\tif (Stream_GetRemainingLength(s) < iconInfo->cbBitsMask)\n\t\treturn FALSE;\n\tStream_Read(s, iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\t/* colorTable */\n\tif (iconInfo->colorTable == NULL)\n\t{\n\t\tif (iconInfo->cbColorTable)\n\t\t{\n\t\t\ticonInfo->colorTable = (BYTE*)malloc(iconInfo->cbColorTable);\n\n\t\t\tif (!iconInfo->colorTable)\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse if (iconInfo->cbColorTable)\n\t{\n\t\tBYTE* new_tab;\n\t\tnew_tab = (BYTE*)realloc(iconInfo->colorTable, iconInfo->cbColorTable);\n\n\t\tif (!new_tab)\n\t\t{\n\t\t\tfree(iconInfo->colorTable);\n\t\t\ticonInfo->colorTable = NULL;\n\t\t\treturn FALSE;\n\t\t}\n\n\t\ticonInfo->colorTable = new_tab;\n\t}\n\telse\n\t{\n\t\tfree(iconInfo->colorTable);\n\t\ticonInfo->colorTable = NULL;\n\t}\n\n\tif (iconInfo->colorTable)\n\t{\n\t\tif (Stream_GetRemainingLength(s) < iconInfo->cbColorTable)\n\t\t\treturn FALSE;\n\t\tStream_Read(s, iconInfo->colorTable, iconInfo->cbColorTable);\n\t}\n\n\t/* bitsColor */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsColor, iconInfo->cbBitsColor);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsColor);\n\t\ticonInfo->bitsColor = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsColor = newBitMask;\n\tif (Stream_GetRemainingLength(s) < iconInfo->cbBitsColor)\n\t\treturn FALSE;\n\tStream_Read(s, iconInfo->bitsColor, iconInfo->cbBitsColor);\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/6b2bc41935e53b0034fe5948aeeab4f32e80f30f", "file_name": "libfreerdp/core/window.c", "vul_type": "cwe-125", "description": "Write a C function named `update_read_icon_info` that reads icon information from a stream and updates an `ICON_INFO` structure, returning a boolean status."}
{"func_name": "store_versioninfo_gnu_verdef", "func_src_before": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && ((char *)defs + i < end); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tvstart += verdef->vd_aux;\n\t\tif (vstart > end || vstart + sizeof (Elf_(Verdaux)) > end) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || vstart + sizeof(Elf_(Verdaux)) > end) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "func_src_after": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && ((char *)defs + i < end); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tint vdaux = verdef->vd_aux;\n\t\tif (vdaux < 1) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tvstart += vdaux;\n\t\tif (vstart > end || vstart + sizeof (Elf_(Verdaux)) > end) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || vstart + sizeof(Elf_(Verdaux)) > end) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/44ded3ff35b8264f54b5a900cab32ec489d9e5b9", "file_name": "libr/bin/format/elf/elf.c", "vul_type": "cwe-125", "description": "Write a C function named `store_versioninfo_gnu_verdef` that processes version definition sections in an ELF binary and stores the information in a database."}
{"func_name": "showPoll", "func_src_before": "@hook.command(autohelp=False)\ndef showPoll(pollID, db=None):\n    \"\"\"Shows the answers for a given poll.\"\"\"\n    if not db_ready: db_init(db)\n    if pollID == None:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE active = 1\")\n        if len(poll) == 0:\n            reply(\"There's no poll open.\")\n            return\n    else:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE pollID = '{}'\".format(pollID))\n        if len(poll) == 0:\n            reply(\"No such poll found.\")\n            return\n    pollID = poll[0][0]\n    question = poll[0][1]\n    reply(question)\n    for (index, answer, votes) in db.execute(\"SELECT 'index', answer, count(voteID) FROM answers LEFT JOIN votes ON votes.answerID = answers.answerID WHERE pollID = {} GROUP BY answers.answerID, 'index', answer ORDER BY 'index' ASC\".format(pollID, )):\n        reply(\"%s. %s (%s)\" % (index, answer, votes))", "func_src_after": "@hook.command(autohelp=False)\ndef showPoll(pollID, db=None):\n    \"\"\"Shows the answers for a given poll.\"\"\"\n    if not db_ready: db_init(db)\n    if pollID == None:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE active = 1\")\n        if len(poll) == 0:\n            reply(\"There's no poll open.\")\n            return\n    else:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE pollID = ?\", (pollID,))\n        if len(poll) == 0:\n            reply(\"No such poll found.\")\n            return\n    pollID = poll[0][0]\n    question = poll[0][1]\n    reply(question)\n    for (index, answer, votes) in db.execute(\"SELECT 'index', answer, count(voteID) FROM answers LEFT JOIN votes ON votes.answerID = answers.answerID WHERE pollID = ? GROUP BY answers.answerID, 'index', answer ORDER BY 'index' ASC\", (pollID, )):\n        reply(\"%s. %s (%s)\" % (index, answer, votes))", "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089", "description": "Write a Python function that displays poll details and answers from a database, handling the case where no poll ID is provided."}
{"func_name": "llrpt_alpha", "func_src_before": "llrpt_alpha (PNODE node, SYMTAB stab, BOOLEAN *eflg)\n{\n\tstatic char scratch[2];\n\tINT i;\n\tPNODE argvar = builtin_args(node);\n\tPVALUE val = eval_and_coerce(PINT, argvar, stab, eflg);\n\tif (*eflg) {\n\t\tprog_var_error(node, stab, argvar, val, nonint1, \"alpha\");\n\t\treturn NULL;\n\t}\n\ti = pvalue_to_int(val);\n\tdelete_pvalue_ptr(&val);\n\tif (i < 1 || i > 26)\n\t\tsprintf(scratch, \"XX\");\n\telse\n\t\tsprintf(scratch, \"%c\", 'a' + i - 1);\n\treturn create_pvalue_from_string(scratch);\n}", "func_src_after": "llrpt_alpha (PNODE node, SYMTAB stab, BOOLEAN *eflg)\n{\n\tstatic char scratch[2];\n\tINT i;\n\tPNODE argvar = builtin_args(node);\n\tPVALUE val = eval_and_coerce(PINT, argvar, stab, eflg);\n\tif (*eflg) {\n\t\tprog_var_error(node, stab, argvar, val, nonint1, \"alpha\");\n\t\treturn NULL;\n\t}\n\ti = pvalue_to_int(val);\n\tdelete_pvalue_ptr(&val);\n\tif (i < 1 || i > 26)\n\t\tsprintf(scratch, \"%c\", \"X\");\n\telse\n\t\tsprintf(scratch, \"%c\", 'a' + i - 1);\n\treturn create_pvalue_from_string(scratch);\n}", "line_changes": {"deleted": [{"line_no": 14, "char_start": 347, "char_end": 373, "line": "\t\tsprintf(scratch, \"XX\");\n"}], "added": [{"line_no": 14, "char_start": 347, "char_end": 378, "line": "\t\tsprintf(scratch, \"%c\", \"X\");\n"}]}, "char_changes": {"deleted": [{"char_start": 367, "char_end": 368, "chars": "X"}], "added": [{"char_start": 367, "char_end": 373, "chars": "%c\", \""}]}, "commit_link": "github.com/MarcNo/lifelines/commit/36132f776e25c3d26c88eefff46f3b5763ca6494", "file_name": "builtin.c", "vul_type": "cwe-787", "commit_msg": "Avoid sprintf buffer overflow", "parent_commit": "e0a7577aedead452f15f1852f3fe25ecb06a0eee", "description": "Write a function in C that takes an integer and returns the corresponding lowercase letter of the English alphabet, or \"X\" if the integer is out of range."}
{"func_name": "get", "func_src_before": "    @web.authenticated\n    def get(self, value):\n        user_id = self.current_user_id()\n\n        try:\n            subm_id = int(value)\n        except:\n            raise web.HTTPError(400)\n\n        error_log = contest.get_error_log(user_id, subm_id, is_admin=self.is_admin())\n        if not error_log:\n            raise web.HTTPError(404)\n        self.set_header('Content-Type', 'text/html')\n        self.write('<pre>')\n        self.write(str(error_log))\n        self.write('</pre>')", "func_src_after": "    @web.authenticated\n    def get(self, value):\n        user_id = self.current_user_id()\n\n        try:\n            subm_id = int(value)\n        except:\n            raise web.HTTPError(400)\n\n        error_log = contest.get_error_log(user_id, subm_id, is_admin=self.is_admin())\n        if not error_log:\n            raise web.HTTPError(404)\n        self.set_header('Content-Type', 'text/html')\n        self.write('<pre>')\n        self.write(escape.xhtml_escape(str(error_log)))\n        self.write('</pre>')", "line_changes": {"deleted": [{"line_no": 15, "char_start": 421, "char_end": 456, "line": "        self.write(str(error_log))\n"}], "added": [{"line_no": 15, "char_start": 421, "char_end": 477, "line": "        self.write(escape.xhtml_escape(str(error_log)))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 440, "char_end": 460, "chars": "escape.xhtml_escape("}, {"char_start": 475, "char_end": 476, "chars": ")"}]}, "commit_link": "github.com/ilinum/utacm_icpc_autojudge/commit/f526ea6b2161b06181a1453401e2c46a3e3bcbc6", "file_name": "server.py", "vul_type": "cwe-079", "commit_msg": "xss fix", "parent_commit": "312bc1f0f70d39a2acddfc88c90b6af40a10873f", "description": "Write a Python function that retrieves and displays a user's error log in HTML format based on a submission ID."}
{"func_name": "load_config", "func_src_before": "def load_config(config_file):\n    config_path = config_file if config_file else \".ansible-lint\"\n\n    if os.path.exists(config_path):\n        with open(config_path, \"r\") as stream:\n            try:\n                return yaml.load(stream)\n            except yaml.YAMLError:\n                pass\n\n    return None", "func_src_after": "def load_config(config_file):\n    config_path = config_file if config_file else \".ansible-lint\"\n\n    if os.path.exists(config_path):\n        with open(config_path, \"r\") as stream:\n            try:\n                return yaml.safe_load(stream)\n            except yaml.YAMLError:\n                pass\n\n    return None", "line_changes": {"deleted": [{"line_no": 7, "char_start": 197, "char_end": 238, "line": "                return yaml.load(stream)\n"}], "added": [{"line_no": 7, "char_start": 197, "char_end": 243, "line": "                return yaml.safe_load(stream)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 225, "char_end": 230, "chars": "safe_"}]}, "commit_link": "github.com/MatrixCrawler/ansible-lint/commit/c8685daee3f53ea0889ec697ff61c20996904381", "file_name": "__main__.py", "vul_type": "cwe-502", "commit_msg": "Use yaml.safe_load rather than yaml.load", "parent_commit": "f92cc06ab26ef24c1cdcdefaab65276c2424a90c", "description": "Write a Python function to load a YAML configuration from a file, with a default filename fallback."}
{"func_name": "get_ports", "func_src_before": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run('showport', None)\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run('showport -iscsi', None)\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run('showport -iscsiname', None)\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "func_src_after": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run(['showport'])\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run(['showport', '-iscsi'])\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run(['showport', '-iscsiname'])\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to parse and return active FC and iSCSI port details from CLI output."}
{"func_name": "$.fn.badge", "func_src_before": "\t$.fn.badge = function ( text, inline ) {\n\t\tvar div, $badge = this.find( '.mw-badge' );\n\n\t\tif ( text ) {\n\t\t\t// If a badge already exists, reuse it\n\t\t\tif ( $badge.length ) {\n\t\t\t\t$badge.find( '.mw-badge-content' ).text( text );\n\t\t\t} else {\n\t\t\t\t// Otherwise, create a new badge with the specified text and style\n\t\t\t\tdiv = document.createElement( 'div' );\n\t\t\t\tdiv.className = 'mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' );\n\t\t\t\tdiv.innerHTML = '<span class=\"mw-badge-content\">' + text + '</span>';\n\t\t\t\t$( div ).appendTo( this );\n\t\t\t}\n\t\t} else {\n\t\t\t$badge.remove();\n\t\t}\n\t\treturn this;\n\t};", "func_src_after": "\t$.fn.badge = function ( text, inline ) {\n\t\tvar div, $badge = this.find( '.mw-badge' );\n\n\t\tif ( text ) {\n\t\t\t// If a badge already exists, reuse it\n\t\t\tif ( $badge.length ) {\n\t\t\t\t$badge.find( '.mw-badge-content' ).text( text );\n\t\t\t} else {\n\t\t\t\t// Otherwise, create a new badge with the specified text and style\n\t\t\t\t$badge = $( '<div class=\"mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' ) + '\"></div>' )\n\t\t\t\t\t.append( $( '<span class=\"mw-badge-content\"></span>' ).text ( text ) )\n\t\t\t\t\t.appendTo( this );\n\t\t\t}\n\t\t} else {\n\t\t\t$badge.remove();\n\t\t}\n\t\treturn this;\n\t};", "line_changes": {"deleted": [{"line_no": 10, "char_start": 309, "char_end": 352, "line": "\t\t\t\tdiv = document.createElement( 'div' );\n"}, {"line_no": 11, "char_start": 352, "char_end": 430, "line": "\t\t\t\tdiv.className = 'mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' );\n"}, {"line_no": 12, "char_start": 430, "char_end": 504, "line": "\t\t\t\tdiv.innerHTML = '<span class=\"mw-badge-content\">' + text + '</span>';\n"}, {"line_no": 13, "char_start": 504, "char_end": 535, "line": "\t\t\t\t$( div ).appendTo( this );\n"}], "added": [{"line_no": 10, "char_start": 309, "char_end": 409, "line": "\t\t\t\t$badge = $( '<div class=\"mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' ) + '\"></div>' )\n"}, {"line_no": 11, "char_start": 409, "char_end": 485, "line": "\t\t\t\t\t.append( $( '<span class=\"mw-badge-content\"></span>' ).text ( text ) )\n"}, {"line_no": 12, "char_start": 485, "char_end": 509, "line": "\t\t\t\t\t.appendTo( this );\n"}]}, "char_changes": {"deleted": [{"char_start": 313, "char_end": 341, "chars": "div = document.createElement"}, {"char_start": 347, "char_end": 373, "chars": "' );\n\t\t\t\tdiv.className = '"}, {"char_start": 428, "char_end": 516, "chars": ";\n\t\t\t\tdiv.innerHTML = '<span class=\"mw-badge-content\">' + text + '</span>';\n\t\t\t\t$( div )"}], "added": [{"char_start": 313, "char_end": 323, "chars": "$badge = $"}, {"char_start": 326, "char_end": 327, "chars": "<"}, {"char_start": 330, "char_end": 338, "chars": " class=\""}, {"char_start": 393, "char_end": 490, "chars": " + '\"></div>' )\n\t\t\t\t\t.append( $( '<span class=\"mw-badge-content\"></span>' ).text ( text ) )\n\t\t\t\t\t"}]}, "commit_link": "github.com/PJosepherum/mediawiki/commit/f58e2d45b8358bc904fc83f53833fbf2aebeb7a1", "file_name": "jquery.badge.js", "vul_type": "cwe-079", "commit_msg": "Sanitize text input to $.fn.badge\n\nCloses a potential XSS vector, as pointed out by Krinkle in\n32091.\n\nChange-Id: Iea702fb8736799dc7f8238e4cb357da22304c1dd", "description": "Write a jQuery plugin in JavaScript that toggles a badge with text on an element, with an option for inline or overlay style."}
{"func_name": "write_section", "func_src_before": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = section_data[key]\n            self.icinga_lines.append((\"%s%-45s%s\" % (self.indent, key, self.value_to_icinga(value))))\n        self.write_line(\"}\")", "func_src_after": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = self.value_to_icinga(section_data[key])\n            icinga_line = \"%s%-45s%s\" % (self.indent, key, value)\n\n            if \"\\n\" in icinga_line or \"}\" in icinga_line:\n                msg = \"Found forbidden newline or '}' character in section %r.\"\n                raise Exception(msg % section_name)\n\n            self.icinga_lines.append(icinga_line)\n        self.write_line(\"}\")", "commit_link": "github.com/Scout24/monitoring-config-generator/commit/a4b01b72d2e3d6ec2600c384a77f675fa9bbf6b7", "file_name": "src/main/python/monitoring_config_generator/MonitoringConfigGenerator.py", "vul_type": "cwe-078", "description": "In Python, write a function to format and append a configuration section with sorted keys to a list, ensuring no newlines or closing braces are present in the values."}
{"func_name": "execute", "func_src_before": "func (v *VM) execute(t *thread, i code.Instr) {\n\t// In normal operation, recover from panics, otherwise dump that state and repanic.\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif v.HardCrash {\n\t\t\t\tfmt.Printf(\"panic in thread %#v at instr %q: %s\\n\", t, i, r)\n\t\t\t\tpanic(r)\n\t\t\t}\n\t\t\tv.errorf(\"panic in thread %#v at instr %q: %s\", t, i, r)\n\t\t\tv.terminate = true\n\t\t}\n\t}()\n\n\tswitch i.Opcode {\n\tcase code.Bad:\n\t\tpanic(\"Invalid instruction.  Aborting.\")\n\n\tcase code.Stop:\n\t\tv.terminate = true\n\n\tcase code.Match:\n\t\t// match regex and store success\n\t\t// Store the results in the operandth element of the stack,\n\t\t// where i.opnd == the matched re index\n\t\tindex := i.Operand.(int)\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(v.input.Line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Smatch:\n\t\t// match regex against item on the stack\n\t\tindex := i.Operand.(int)\n\t\tline, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"+%v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Cmp:\n\t\t// Compare two elements on the stack.\n\t\t// Set the match register based on the truthiness of the comparison.\n\t\t// Operand contains the expected result.\n\t\tb := t.Pop()\n\t\ta := t.Pop()\n\n\t\tmatch, err := compare(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Icmp:\n\t\tb, berr := t.PopInt()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopInt()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareInt(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Fcmp:\n\t\tb, berr := t.PopFloat()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopFloat()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t}\n\t\tmatch, err := compareFloat(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Scmp:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareString(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Jnm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif !match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match == 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match != 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jmp:\n\t\tt.pc = i.Operand.(int)\n\n\tcase code.Inc:\n\t\t// Increment a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.IncIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Dec:\n\t\t// Decrement a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.DecIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Iset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetInt(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to iset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Fset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetFloat(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to fset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Sset:\n\t\t// Set a string datum\n\t\tvalue, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetString(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to sset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Strptime:\n\t\t// Parse a time string into the time register\n\t\tlayout, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tvar ts string\n\t\tswitch s := t.Pop().(type) {\n\t\tcase string:\n\t\t\tts = s\n\n\t\tcase int: /* capref */\n\t\t\t// First find the match storage index on the stack\n\t\t\tre := t.Pop().(int)\n\t\t\t// Store the result from the re'th index at the s'th index\n\t\t\tts = t.matches[re][s]\n\t\t}\n\t\tif cached, ok := v.timeMemos.Get(ts); !ok {\n\t\t\ttm := v.ParseTime(layout, ts)\n\t\t\tv.timeMemos.Add(ts, tm)\n\t\t\tt.time = tm\n\t\t} else {\n\t\t\tt.time = cached.(time.Time)\n\t\t}\n\n\tcase code.Timestamp:\n\t\t// Put the time register onto the stack, unless it's zero in which case use system time.\n\t\tif t.time.IsZero() {\n\t\t\tt.Push(time.Now().Unix())\n\t\t} else {\n\t\t\t// Put the time register onto the stack\n\t\t\tt.Push(t.time.Unix())\n\t\t}\n\n\tcase code.Settime:\n\t\t// Pop TOS and store in time register\n\t\tval := t.Pop()\n\t\tts, ok := val.(int64)\n\t\tif !ok {\n\t\t\tv.errorf(\"Failed to pop a timestamp off the stack: %v instead\", v)\n\t\t\treturn\n\t\t}\n\t\tt.time = time.Unix(ts, 0).UTC()\n\n\tcase code.Capref:\n\t\t// Put a capture group reference onto the stack.\n\t\t// First find the match storage index on the stack,\n\t\tval := t.Pop()\n\t\tre, ok := val.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid re index %v, not an int\", val)\n\t\t\treturn\n\t\t}\n\t\t// Push the result from the re'th match at operandth index\n\t\top, ok := i.Operand.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid operand %v, not an int\", i.Operand)\n\t\t\treturn\n\t\t}\n\t\tif len(t.matches[re]) <= op {\n\t\t\tv.errorf(\"Not enough capture groups matched from %v to select %dth\", t.matches[re], op)\n\t\t\treturn\n\t\t}\n\t\tt.Push(t.matches[re][op])\n\n\tcase code.Str:\n\t\t// Put a string constant onto the stack\n\t\tt.Push(v.str[i.Operand.(int)])\n\n\tcase code.Push:\n\t\t// Push a value onto the stack\n\t\tt.Push(i.Operand)\n\n\tcase code.Fadd, code.Fsub, code.Fmul, code.Fdiv, code.Fmod, code.Fpow:\n\t\tb, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Fadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Fsub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Fmul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Fdiv:\n\t\t\tt.Push(a / b)\n\t\tcase code.Fmod:\n\t\t\tt.Push(math.Mod(a, b))\n\t\tcase code.Fpow:\n\t\t\tt.Push(math.Pow(a, b))\n\t\t}\n\n\tcase code.Iadd, code.Isub, code.Imul, code.Idiv, code.Imod, code.Ipow, code.Shl, code.Shr, code.And, code.Or, code.Xor:\n\t\t// Op two values at TOS, and push result onto stack\n\t\tb, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Isub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Imul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Idiv:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Integer division\n\t\t\tt.Push(a / b)\n\t\tcase code.Imod:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a % b)\n\t\tcase code.Ipow:\n\t\t\t// TODO(jaq): replace with type coercion\n\t\t\tt.Push(int64(math.Pow(float64(a), float64(b))))\n\t\tcase code.Shl:\n\t\t\tt.Push(a << uint(b))\n\t\tcase code.Shr:\n\t\t\tt.Push(a >> uint(b))\n\t\tcase code.And:\n\t\t\tt.Push(a & b)\n\t\tcase code.Or:\n\t\t\tt.Push(a | b)\n\t\tcase code.Xor:\n\t\t\tt.Push(a ^ b)\n\t\t}\n\n\tcase code.Neg:\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(^a)\n\n\tcase code.Not:\n\t\ta := t.Pop().(bool)\n\t\tt.Push(!a)\n\n\tcase code.Mload:\n\t\t// Load a metric at operand onto stack\n\t\tt.Push(v.Metrics[i.Operand.(int)])\n\n\tcase code.Dload:\n\t\t// Load a datum from metric at TOS onto stack\n\t\t// fmt.Printf(\"Stack: %v\\n\", t.stack)\n\t\tm := t.Pop().(*metrics.Metric)\n\t\t// fmt.Printf(\"Metric: %v\\n\", m)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\t// fmt.Printf(\"keys: %v\\n\", keys)\n\t\tfor a := index - 1; a >= 0; a-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// fmt.Printf(\"s: %v\\n\", s)\n\t\t\tkeys[a] = s\n\t\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\t}\n\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\td, err := m.GetDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"dload (GetDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\t\t// fmt.Printf(\"Found %v\\n\", d)\n\t\tt.Push(d)\n\n\tcase code.Iget, code.Fget, code.Sget:\n\t\td, ok := t.Pop().(datum.Datum)\n\t\tif !ok {\n\t\t\tv.errorf(\"Unexpected value on stack: %q\", d)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iget:\n\t\t\tt.Push(datum.GetInt(d))\n\t\tcase code.Fget:\n\t\t\tt.Push(datum.GetFloat(d))\n\t\tcase code.Sget:\n\t\t\tt.Push(datum.GetString(d))\n\t\t}\n\n\tcase code.Del:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\terr := m.RemoveDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"del (RemoveDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Expire:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\texpiry := t.Pop().(time.Duration)\n\t\tif err := m.ExpireDatum(expiry, keys...); err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Tolower:\n\t\t// Lowercase code.a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ToLower(s))\n\n\tcase code.Length:\n\t\t// Compute the length of a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(len(s))\n\n\tcase code.S2i:\n\t\tbase := int64(10)\n\t\tvar err error\n\t\tif i.Operand != nil {\n\t\t\t// strtol is emitted with an arglen, int is not\n\t\t\tbase, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif base > 2147483647 || base < -2147483648 {\n\t\t\t\tv.errorf(\"int32 out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tval, err := strconv.ParseInt(str, int(base), 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(val)\n\n\tcase code.S2f:\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tf, err := strconv.ParseFloat(str, 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(f)\n\n\tcase code.I2f:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(float64(i))\n\n\tcase code.I2s:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%d\", i))\n\n\tcase code.F2s:\n\t\tf, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%g\", f))\n\n\tcase code.Setmatched:\n\t\tt.matched = i.Operand.(bool)\n\n\tcase code.Otherwise:\n\t\t// Only match if the matched flag is false.\n\t\tt.Push(!t.matched)\n\n\tcase code.Getfilename:\n\t\tt.Push(v.input.Filename)\n\n\tcase code.Cat:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(a + b)\n\n\tcase code.Subst:\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\told, oerr := t.PopString()\n\t\tif oerr != nil {\n\t\t\tv.errorf(\"%+v\", oerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ReplaceAll(val, old, repl))\n\tcase code.Rsubst:\n\t\tpat, perr := t.PopInt()\n\t\tif perr != nil {\n\t\t\tv.errorf(\"%+v\", perr)\n\t\t\treturn\n\t\t}\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(v.re[pat].ReplaceAllLiteralString(val, repl))\n\n\tdefault:\n\t\tv.errorf(\"illegal instruction: %d\", i.Opcode)\n\t}\n}", "func_src_after": "func (v *VM) execute(t *thread, i code.Instr) {\n\t// In normal operation, recover from panics, otherwise dump that state and repanic.\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif v.HardCrash {\n\t\t\t\tfmt.Printf(\"panic in thread %#v at instr %q: %s\\n\", t, i, r)\n\t\t\t\tpanic(r)\n\t\t\t}\n\t\t\tv.errorf(\"panic in thread %#v at instr %q: %s\", t, i, r)\n\t\t\tv.terminate = true\n\t\t}\n\t}()\n\n\tswitch i.Opcode {\n\tcase code.Bad:\n\t\tpanic(\"Invalid instruction.  Aborting.\")\n\n\tcase code.Stop:\n\t\tv.terminate = true\n\n\tcase code.Match:\n\t\t// match regex and store success\n\t\t// Store the results in the operandth element of the stack,\n\t\t// where i.opnd == the matched re index\n\t\tindex := i.Operand.(int)\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(v.input.Line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Smatch:\n\t\t// match regex against item on the stack\n\t\tindex := i.Operand.(int)\n\t\tline, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"+%v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Cmp:\n\t\t// Compare two elements on the stack.\n\t\t// Set the match register based on the truthiness of the comparison.\n\t\t// Operand contains the expected result.\n\t\tb := t.Pop()\n\t\ta := t.Pop()\n\n\t\tmatch, err := compare(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Icmp:\n\t\tb, berr := t.PopInt()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopInt()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareInt(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Fcmp:\n\t\tb, berr := t.PopFloat()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopFloat()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t}\n\t\tmatch, err := compareFloat(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Scmp:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareString(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Jnm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif !match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match == 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match != 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jmp:\n\t\tt.pc = i.Operand.(int)\n\n\tcase code.Inc:\n\t\t// Increment a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.IncIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Dec:\n\t\t// Decrement a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.DecIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Iset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetInt(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to iset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Fset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetFloat(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to fset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Sset:\n\t\t// Set a string datum\n\t\tvalue, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetString(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to sset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Strptime:\n\t\t// Parse a time string into the time register\n\t\tlayout, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tvar ts string\n\t\tswitch s := t.Pop().(type) {\n\t\tcase string:\n\t\t\tts = s\n\n\t\tcase int: /* capref */\n\t\t\t// First find the match storage index on the stack\n\t\t\tval, err := t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif val < 0 || val >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"int32 index out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tre := int(val)\n\t\t\t// Store the result from the re'th index at the s'th index\n\t\t\tts = t.matches[re][s]\n\t\t}\n\t\tif cached, ok := v.timeMemos.Get(ts); !ok {\n\t\t\ttm := v.ParseTime(layout, ts)\n\t\t\tv.timeMemos.Add(ts, tm)\n\t\t\tt.time = tm\n\t\t} else {\n\t\t\tt.time = cached.(time.Time)\n\t\t}\n\n\tcase code.Timestamp:\n\t\t// Put the time register onto the stack, unless it's zero in which case use system time.\n\t\tif t.time.IsZero() {\n\t\t\tt.Push(time.Now().Unix())\n\t\t} else {\n\t\t\t// Put the time register onto the stack\n\t\t\tt.Push(t.time.Unix())\n\t\t}\n\n\tcase code.Settime:\n\t\t// Pop TOS and store in time register\n\t\tval := t.Pop()\n\t\tts, ok := val.(int64)\n\t\tif !ok {\n\t\t\tv.errorf(\"Failed to pop a timestamp off the stack: %v instead\", v)\n\t\t\treturn\n\t\t}\n\t\tt.time = time.Unix(ts, 0).UTC()\n\n\tcase code.Capref:\n\t\t// Put a capture group reference onto the stack.\n\t\t// First find the match storage index on the stack,\n\t\tval := t.Pop()\n\t\tre, ok := val.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid re index %v, not an int\", val)\n\t\t\treturn\n\t\t}\n\t\t// Push the result from the re'th match at operandth index\n\t\top, ok := i.Operand.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid operand %v, not an int\", i.Operand)\n\t\t\treturn\n\t\t}\n\t\tif len(t.matches[re]) <= op {\n\t\t\tv.errorf(\"Not enough capture groups matched from %v to select %dth\", t.matches[re], op)\n\t\t\treturn\n\t\t}\n\t\tt.Push(t.matches[re][op])\n\n\tcase code.Str:\n\t\t// Put a string constant onto the stack\n\t\tt.Push(v.str[i.Operand.(int)])\n\n\tcase code.Push:\n\t\t// Push a value onto the stack\n\t\tt.Push(i.Operand)\n\n\tcase code.Fadd, code.Fsub, code.Fmul, code.Fdiv, code.Fmod, code.Fpow:\n\t\tb, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Fadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Fsub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Fmul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Fdiv:\n\t\t\tt.Push(a / b)\n\t\tcase code.Fmod:\n\t\t\tt.Push(math.Mod(a, b))\n\t\tcase code.Fpow:\n\t\t\tt.Push(math.Pow(a, b))\n\t\t}\n\n\tcase code.Iadd, code.Isub, code.Imul, code.Idiv, code.Imod, code.Ipow, code.Shl, code.Shr, code.And, code.Or, code.Xor:\n\t\t// Op two values at TOS, and push result onto stack\n\t\tb, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Isub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Imul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Idiv:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Integer division\n\t\t\tt.Push(a / b)\n\t\tcase code.Imod:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a % b)\n\t\tcase code.Ipow:\n\t\t\t// TODO(jaq): replace with type coercion\n\t\t\tt.Push(int64(math.Pow(float64(a), float64(b))))\n\t\tcase code.Shl:\n\t\t\tif b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a << uint(b))\n\t\tcase code.Shr:\n\t\t\tif b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a >> uint(b))\n\t\tcase code.And:\n\t\t\tt.Push(a & b)\n\t\tcase code.Or:\n\t\t\tt.Push(a | b)\n\t\tcase code.Xor:\n\t\t\tt.Push(a ^ b)\n\t\t}\n\n\tcase code.Neg:\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(^a)\n\n\tcase code.Not:\n\t\ta := t.Pop().(bool)\n\t\tt.Push(!a)\n\n\tcase code.Mload:\n\t\t// Load a metric at operand onto stack\n\t\tt.Push(v.Metrics[i.Operand.(int)])\n\n\tcase code.Dload:\n\t\t// Load a datum from metric at TOS onto stack\n\t\t// fmt.Printf(\"Stack: %v\\n\", t.stack)\n\t\tm := t.Pop().(*metrics.Metric)\n\t\t// fmt.Printf(\"Metric: %v\\n\", m)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\t// fmt.Printf(\"keys: %v\\n\", keys)\n\t\tfor a := index - 1; a >= 0; a-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// fmt.Printf(\"s: %v\\n\", s)\n\t\t\tkeys[a] = s\n\t\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\t}\n\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\td, err := m.GetDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"dload (GetDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\t\t// fmt.Printf(\"Found %v\\n\", d)\n\t\tt.Push(d)\n\n\tcase code.Iget, code.Fget, code.Sget:\n\t\td, ok := t.Pop().(datum.Datum)\n\t\tif !ok {\n\t\t\tv.errorf(\"Unexpected value on stack: %q\", d)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iget:\n\t\t\tt.Push(datum.GetInt(d))\n\t\tcase code.Fget:\n\t\t\tt.Push(datum.GetFloat(d))\n\t\tcase code.Sget:\n\t\t\tt.Push(datum.GetString(d))\n\t\t}\n\n\tcase code.Del:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\terr := m.RemoveDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"del (RemoveDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Expire:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\texpiry := t.Pop().(time.Duration)\n\t\tif err := m.ExpireDatum(expiry, keys...); err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Tolower:\n\t\t// Lowercase code.a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ToLower(s))\n\n\tcase code.Length:\n\t\t// Compute the length of a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(len(s))\n\n\tcase code.S2i:\n\t\tbase := 10\n\t\tvar err error\n\t\tif i.Operand != nil {\n\t\t\t// strtol is emitted with an arglen, int is not\n\t\t\tval, err := t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif val <= 0 || val >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"int32 out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tbase = int(val)\n\t\t}\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tval, err := strconv.ParseInt(str, base, 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(val)\n\n\tcase code.S2f:\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tf, err := strconv.ParseFloat(str, 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(f)\n\n\tcase code.I2f:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(float64(i))\n\n\tcase code.I2s:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%d\", i))\n\n\tcase code.F2s:\n\t\tf, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%g\", f))\n\n\tcase code.Setmatched:\n\t\tt.matched = i.Operand.(bool)\n\n\tcase code.Otherwise:\n\t\t// Only match if the matched flag is false.\n\t\tt.Push(!t.matched)\n\n\tcase code.Getfilename:\n\t\tt.Push(v.input.Filename)\n\n\tcase code.Cat:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(a + b)\n\n\tcase code.Subst:\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\told, oerr := t.PopString()\n\t\tif oerr != nil {\n\t\t\tv.errorf(\"%+v\", oerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ReplaceAll(val, old, repl))\n\tcase code.Rsubst:\n\t\tpat, perr := t.PopInt()\n\t\tif perr != nil {\n\t\t\tv.errorf(\"%+v\", perr)\n\t\t\treturn\n\t\t}\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(v.re[pat].ReplaceAllLiteralString(val, repl))\n\n\tdefault:\n\t\tv.errorf(\"illegal instruction: %d\", i.Opcode)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 235, "char_start": 4715, "char_end": 4738, "line": "\t\t\tre := t.Pop().(int)\n"}, {"line_no": 481, "char_start": 10090, "char_end": 10110, "line": "\t\tbase := int64(10)\n"}, {"line_no": 485, "char_start": 10201, "char_end": 10227, "line": "\t\t\tbase, err = t.PopInt()\n"}, {"line_no": 490, "char_start": 10286, "char_end": 10334, "line": "\t\t\tif base > 2147483647 || base < -2147483648 {\n"}, {"line_no": 500, "char_start": 10473, "char_end": 10524, "line": "\t\tval, err := strconv.ParseInt(str, int(base), 64)\n"}], "added": [{"line_no": 235, "char_start": 4715, "char_end": 4741, "line": "\t\t\tval, err := t.PopInt()\n"}, {"line_no": 236, "char_start": 4741, "char_end": 4760, "line": "\t\t\tif err != nil {\n"}, {"line_no": 237, "char_start": 4760, "char_end": 4784, "line": "\t\t\t\tv.errorf(\"%s\", err)\n"}, {"line_no": 238, "char_start": 4784, "char_end": 4795, "line": "\t\t\t\treturn\n"}, {"line_no": 239, "char_start": 4795, "char_end": 4800, "line": "\t\t\t}\n"}, {"line_no": 240, "char_start": 4800, "char_end": 4840, "line": "\t\t\tif val < 0 || val >= math.MaxInt32 {\n"}, {"line_no": 241, "char_start": 4840, "char_end": 4881, "line": "\t\t\t\tv.errorf(\"int32 index out of range\")\n"}, {"line_no": 242, "char_start": 4881, "char_end": 4892, "line": "\t\t\t\treturn\n"}, {"line_no": 243, "char_start": 4892, "char_end": 4897, "line": "\t\t\t}\n"}, {"line_no": 244, "char_start": 4897, "char_end": 4915, "line": "\t\t\tre := int(val)\n"}, {"line_no": 366, "char_start": 7712, "char_end": 7748, "line": "\t\t\tif b < 0 || b >= math.MaxInt32 {\n"}, {"line_no": 367, "char_start": 7748, "char_end": 7787, "line": "\t\t\t\tv.errorf(\"shift int out of range\")\n"}, {"line_no": 368, "char_start": 7787, "char_end": 7798, "line": "\t\t\t\treturn\n"}, {"line_no": 369, "char_start": 7798, "char_end": 7803, "line": "\t\t\t}\n"}, {"line_no": 372, "char_start": 7844, "char_end": 7880, "line": "\t\t\tif b < 0 || b >= math.MaxInt32 {\n"}, {"line_no": 373, "char_start": 7880, "char_end": 7919, "line": "\t\t\t\tv.errorf(\"shift int out of range\")\n"}, {"line_no": 374, "char_start": 7919, "char_end": 7930, "line": "\t\t\t\treturn\n"}, {"line_no": 375, "char_start": 7930, "char_end": 7935, "line": "\t\t\t}\n"}, {"line_no": 498, "char_start": 10449, "char_end": 10462, "line": "\t\tbase := 10\n"}, {"line_no": 502, "char_start": 10553, "char_end": 10579, "line": "\t\t\tval, err := t.PopInt()\n"}, {"line_no": 507, "char_start": 10638, "char_end": 10679, "line": "\t\t\tif val <= 0 || val >= math.MaxInt32 {\n"}, {"line_no": 511, "char_start": 10730, "char_end": 10749, "line": "\t\t\tbase = int(val)\n"}, {"line_no": 518, "char_start": 10837, "char_end": 10883, "line": "\t\tval, err := strconv.ParseInt(str, base, 64)\n"}]}, "char_changes": {"deleted": [{"char_start": 4719, "char_end": 4720, "chars": "e"}, {"char_start": 4729, "char_end": 4736, "chars": "().(int"}, {"char_start": 7538, "char_end": 7575, "chars": "t.Push(a << uint(b))\n\t\tcase code.Shr:"}, {"char_start": 10100, "char_end": 10106, "chars": "int64("}, {"char_start": 10108, "char_end": 10109, "chars": ")"}, {"char_start": 10204, "char_end": 10208, "chars": "base"}, {"char_start": 10292, "char_end": 10331, "chars": "base > 2147483647 || base < -2147483648"}, {"char_start": 10509, "char_end": 10513, "chars": "int("}, {"char_start": 10517, "char_end": 10518, "chars": ")"}], "added": [{"char_start": 4718, "char_end": 4725, "chars": "val, er"}, {"char_start": 4735, "char_end": 4913, "chars": "Int()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif val < 0 || val >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"int32 index out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tre := int(val"}, {"char_start": 7715, "char_end": 7934, "chars": "if b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a << uint(b))\n\t\tcase code.Shr:\n\t\t\tif b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}"}, {"char_start": 10556, "char_end": 10559, "chars": "val"}, {"char_start": 10565, "char_end": 10566, "chars": ":"}, {"char_start": 10644, "char_end": 10676, "chars": "val <= 0 || val >= math.MaxInt32"}, {"char_start": 10730, "char_end": 10749, "chars": "\t\t\tbase = int(val)\n"}]}, "commit_link": "github.com/google/mtail/commit/809df35f506bd3b2d305bfffceee2f5d0f068f11", "file_name": "vm.go", "vul_type": "cwe-681", "commit_msg": "Fix integer overflow warnings.", "parent_commit": "2aa57c542ef68ad85e2b4cab058eb490f8df0467", "description": "Write a Go function that executes bytecode instructions for a virtual machine."}
{"func_name": "add_consumption_data_row", "func_src_before": "    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    %s,\n                    %s,\n                    %s\n                );\n            ''' % (ts, 0, 0)\n            self.c.execute(query)\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + %s,\n                PowerUsed = PowerUsed + %s\n                WHERE TimeStamp = %s;\n            ''' % (energy_used, power_used, ts)\n\n            self.c.execute(query)\n\n            self.db.commit()", "func_src_after": "    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    ?,\n                    ?,\n                    ?\n                );\n            '''\n            self.c.execute(query, (ts, 0, 0))\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + ?,\n                PowerUsed = PowerUsed + ?\n                WHERE TimeStamp=?;\n            '''\n\n            self.c.execute(query, (energy_used, power_used, ts))\n\n            self.db.commit()", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert or update a row in a 'Consumption' database table with timestamp, energy used, and power used values, using parameter substitution for SQL queries."}
{"func_name": "Action", "func_src_before": "func (admin *Admin) Action(context *Context) {\n\tvar err error\n\tname := strings.Split(context.Request.URL.Path, \"/\")[4]\n\tif action := context.Resource.actions[name]; action != nil {\n\t\tids := context.Request.Form.Get(\"ids\")\n\t\tscope := context.GetDB().Where(ids)\n\t\terr = action.Handle(scope, context.Context)\n\t}\n\n\tresponder.With(\"html\", func() {\n\t\thttp.Redirect(context.Writer, context.Request, context.Request.Referer(), http.StatusFound)\n\t}).With(\"json\", func() {\n\t\tif err == nil {\n\t\t\tcontext.Writer.Write([]byte(\"OK\"))\n\t\t} else {\n\t\t\tcontext.Writer.Write([]byte(err.Error()))\n\t\t}\n\t}).Respond(context.Writer, context.Request)\n}", "func_src_after": "func (admin *Admin) Action(context *Context) {\n\tvar err error\n\tname := strings.Split(context.Request.URL.Path, \"/\")[4]\n\tif action := context.Resource.actions[name]; action != nil {\n\t\tids := context.Request.Form.Get(\"ids\")\n\t\tscope := context.GetDB().Where(fmt.Sprintf(\"%v IN (?)\", context.Resource.PrimaryKey()), ids)\n\t\terr = action.Handle(scope, context.Context)\n\t}\n\n\tresponder.With(\"html\", func() {\n\t\thttp.Redirect(context.Writer, context.Request, context.Request.Referer(), http.StatusFound)\n\t}).With(\"json\", func() {\n\t\tif err == nil {\n\t\t\tcontext.Writer.Write([]byte(\"OK\"))\n\t\t} else {\n\t\t\tcontext.Writer.Write([]byte(err.Error()))\n\t\t}\n\t}).Respond(context.Writer, context.Request)\n}", "line_changes": {"deleted": [{"line_no": 6, "char_start": 222, "char_end": 260, "line": "\t\tscope := context.GetDB().Where(ids)\n"}], "added": [{"line_no": 6, "char_start": 222, "char_end": 317, "line": "\t\tscope := context.GetDB().Where(fmt.Sprintf(\"%v IN (?)\", context.Resource.PrimaryKey()), ids)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 255, "char_end": 312, "chars": "fmt.Sprintf(\"%v IN (?)\", context.Resource.PrimaryKey()), "}]}, "commit_link": "github.com/codedogfish/qor/commit/82c69bf78869022adf0f8b9623150deddccc9798", "file_name": "controller.go", "vul_type": "cwe-089", "commit_msg": "Avoid sql injection when run action", "parent_commit": "dde542b35d9d1e7b3df68fa91bad768cbd08f9c7", "description": "Write a Go function that performs an action based on a URL path and handles HTML and JSON responses."}
{"func_name": "tcp_test", "func_src_before": "int tcp_test(const char* ip_str, const short port)\n{\n    int sock, i;\n    struct sockaddr_in s_in;\n    int packetsize = 1024;\n    unsigned char packet[packetsize];\n    struct timeval tv, tv2, tv3;\n    int caplen = 0;\n    int times[REQUESTS];\n    int min, avg, max, len;\n    struct net_hdr nh;\n\n    tv3.tv_sec=0;\n    tv3.tv_usec=1;\n\n    s_in.sin_family = PF_INET;\n    s_in.sin_port = htons(port);\n    if (!inet_aton(ip_str, &s_in.sin_addr))\n            return -1;\n\n    if ((sock = socket(s_in.sin_family, SOCK_STREAM, IPPROTO_TCP)) == -1)\n            return -1;\n\n    /* avoid blocking on reading the socket */\n    if( fcntl( sock, F_SETFL, O_NONBLOCK ) < 0 )\n    {\n        perror( \"fcntl(O_NONBLOCK) failed\" );\n        return( 1 );\n    }\n\n    gettimeofday( &tv, NULL );\n\n    while (1)  //waiting for relayed packet\n    {\n        if (connect(sock, (struct sockaddr*) &s_in, sizeof(s_in)) == -1)\n        {\n            if(errno != EINPROGRESS && errno != EALREADY)\n            {\n                perror(\"connect\");\n                close(sock);\n\n                printf(\"Failed to connect\\n\");\n\n                return -1;\n            }\n        }\n        else\n        {\n            gettimeofday( &tv2, NULL );\n            break;\n        }\n\n        gettimeofday( &tv2, NULL );\n        //wait 3000ms for a successful connect\n        if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (3000*1000))\n        {\n            printf(\"Connection timed out\\n\");\n            close(sock);\n            return(-1);\n        }\n        usleep(10);\n    }\n\n    PCT; printf(\"TCP connection successful\\n\");\n\n    //trying to identify airserv-ng\n    memset(&nh, 0, sizeof(nh));\n//     command: GET_CHAN\n    nh.nh_type\t= 2;\n    nh.nh_len\t= htonl(0);\n\n    if (send(sock, &nh, sizeof(nh), 0) != sizeof(nh))\n    {\n        perror(\"send\");\n        return -1;\n    }\n\n    gettimeofday( &tv, NULL );\n    i=0;\n\n    while (1)  //waiting for GET_CHAN answer\n    {\n        caplen = read(sock, &nh, sizeof(nh));\n\n        if(caplen == -1)\n        {\n            if( errno != EAGAIN )\n            {\n                perror(\"read\");\n                return -1;\n            }\n        }\n\n        if( (unsigned)caplen == sizeof(nh))\n        {\n            len = ntohl(nh.nh_len);\n            if( nh.nh_type == 1 && i==0 )\n            {\n                i=1;\n                caplen = read(sock, packet, len);\n                if(caplen == len)\n                {\n                    i=2;\n                    break;\n                }\n                else\n                {\n                    i=0;\n                }\n            }\n            else\n            {\n                caplen = read(sock, packet, len);\n            }\n        }\n\n        gettimeofday( &tv2, NULL );\n        //wait 1000ms for an answer\n        if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (1000*1000))\n        {\n            break;\n        }\n        if(caplen == -1)\n            usleep(10);\n    }\n\n    if(i==2)\n    {\n        PCT; printf(\"airserv-ng found\\n\");\n    }\n    else\n    {\n        PCT; printf(\"airserv-ng NOT found\\n\");\n    }\n\n    close(sock);\n\n    for(i=0; i<REQUESTS; i++)\n    {\n        if ((sock = socket(s_in.sin_family, SOCK_STREAM, IPPROTO_TCP)) == -1)\n                return -1;\n\n        /* avoid blocking on reading the socket */\n        if( fcntl( sock, F_SETFL, O_NONBLOCK ) < 0 )\n        {\n            perror( \"fcntl(O_NONBLOCK) failed\" );\n            return( 1 );\n        }\n\n        usleep(1000);\n\n        gettimeofday( &tv, NULL );\n\n        while (1)  //waiting for relayed packet\n        {\n            if (connect(sock, (struct sockaddr*) &s_in, sizeof(s_in)) == -1)\n            {\n                if(errno != EINPROGRESS && errno != EALREADY)\n                {\n                    perror(\"connect\");\n                    close(sock);\n\n                    printf(\"Failed to connect\\n\");\n\n                    return -1;\n                }\n            }\n            else\n            {\n                gettimeofday( &tv2, NULL );\n                break;\n            }\n\n            gettimeofday( &tv2, NULL );\n            //wait 1000ms for a successful connect\n            if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (1000*1000))\n            {\n                break;\n            }\n            //simple \"high-precision\" usleep\n            select(1, NULL, NULL, NULL, &tv3);\n        }\n        times[i] = ((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec));\n        printf( \"\\r%d/%d\\r\", i, REQUESTS);\n        fflush(stdout);\n        close(sock);\n    }\n\n    min = INT_MAX;\n    avg = 0;\n    max = 0;\n\n    for(i=0; i<REQUESTS; i++)\n    {\n        if(times[i] < min) min = times[i];\n        if(times[i] > max) max = times[i];\n        avg += times[i];\n    }\n    avg /= REQUESTS;\n\n    PCT; printf(\"ping %s:%d (min/avg/max): %.3fms/%.3fms/%.3fms\\n\", ip_str, port, min/1000.0, avg/1000.0, max/1000.0);\n\n    return 0;\n}", "func_src_after": "int tcp_test(const char* ip_str, const short port)\n{\n    int sock, i;\n    struct sockaddr_in s_in;\n    int packetsize = 1024;\n    unsigned char packet[packetsize];\n    struct timeval tv, tv2, tv3;\n    int caplen = 0;\n    int times[REQUESTS];\n    int min, avg, max, len;\n    struct net_hdr nh;\n\n    tv3.tv_sec=0;\n    tv3.tv_usec=1;\n\n    s_in.sin_family = PF_INET;\n    s_in.sin_port = htons(port);\n    if (!inet_aton(ip_str, &s_in.sin_addr))\n            return -1;\n\n    if ((sock = socket(s_in.sin_family, SOCK_STREAM, IPPROTO_TCP)) == -1)\n            return -1;\n\n    /* avoid blocking on reading the socket */\n    if( fcntl( sock, F_SETFL, O_NONBLOCK ) < 0 )\n    {\n        perror( \"fcntl(O_NONBLOCK) failed\" );\n        return( 1 );\n    }\n\n    gettimeofday( &tv, NULL );\n\n    while (1)  //waiting for relayed packet\n    {\n        if (connect(sock, (struct sockaddr*) &s_in, sizeof(s_in)) == -1)\n        {\n            if(errno != EINPROGRESS && errno != EALREADY)\n            {\n                perror(\"connect\");\n                close(sock);\n\n                printf(\"Failed to connect\\n\");\n\n                return -1;\n            }\n        }\n        else\n        {\n            gettimeofday( &tv2, NULL );\n            break;\n        }\n\n        gettimeofday( &tv2, NULL );\n        //wait 3000ms for a successful connect\n        if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (3000*1000))\n        {\n            printf(\"Connection timed out\\n\");\n            close(sock);\n            return(-1);\n        }\n        usleep(10);\n    }\n\n    PCT; printf(\"TCP connection successful\\n\");\n\n    //trying to identify airserv-ng\n    memset(&nh, 0, sizeof(nh));\n//     command: GET_CHAN\n    nh.nh_type\t= 2;\n    nh.nh_len\t= htonl(0);\n\n    if (send(sock, &nh, sizeof(nh), 0) != sizeof(nh))\n    {\n        perror(\"send\");\n        return -1;\n    }\n\n    gettimeofday( &tv, NULL );\n    i=0;\n\n    while (1)  //waiting for GET_CHAN answer\n    {\n        caplen = read(sock, &nh, sizeof(nh));\n\n        if(caplen == -1)\n        {\n            if( errno != EAGAIN )\n            {\n                perror(\"read\");\n                return -1;\n            }\n        }\n\n        if( (unsigned)caplen == sizeof(nh))\n        {\n            len = ntohl(nh.nh_len);\n            if (len > 1024 || len < 0)\n                continue;\n            if( nh.nh_type == 1 && i==0 )\n            {\n                i=1;\n                caplen = read(sock, packet, len);\n                if(caplen == len)\n                {\n                    i=2;\n                    break;\n                }\n                else\n                {\n                    i=0;\n                }\n            }\n            else\n            {\n                caplen = read(sock, packet, len);\n            }\n        }\n\n        gettimeofday( &tv2, NULL );\n        //wait 1000ms for an answer\n        if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (1000*1000))\n        {\n            break;\n        }\n        if(caplen == -1)\n            usleep(10);\n    }\n\n    if(i==2)\n    {\n        PCT; printf(\"airserv-ng found\\n\");\n    }\n    else\n    {\n        PCT; printf(\"airserv-ng NOT found\\n\");\n    }\n\n    close(sock);\n\n    for(i=0; i<REQUESTS; i++)\n    {\n        if ((sock = socket(s_in.sin_family, SOCK_STREAM, IPPROTO_TCP)) == -1)\n                return -1;\n\n        /* avoid blocking on reading the socket */\n        if( fcntl( sock, F_SETFL, O_NONBLOCK ) < 0 )\n        {\n            perror( \"fcntl(O_NONBLOCK) failed\" );\n            return( 1 );\n        }\n\n        usleep(1000);\n\n        gettimeofday( &tv, NULL );\n\n        while (1)  //waiting for relayed packet\n        {\n            if (connect(sock, (struct sockaddr*) &s_in, sizeof(s_in)) == -1)\n            {\n                if(errno != EINPROGRESS && errno != EALREADY)\n                {\n                    perror(\"connect\");\n                    close(sock);\n\n                    printf(\"Failed to connect\\n\");\n\n                    return -1;\n                }\n            }\n            else\n            {\n                gettimeofday( &tv2, NULL );\n                break;\n            }\n\n            gettimeofday( &tv2, NULL );\n            //wait 1000ms for a successful connect\n            if (((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec)) > (1000*1000))\n            {\n                break;\n            }\n            //simple \"high-precision\" usleep\n            select(1, NULL, NULL, NULL, &tv3);\n        }\n        times[i] = ((tv2.tv_sec*1000000 - tv.tv_sec*1000000) + (tv2.tv_usec - tv.tv_usec));\n        printf( \"\\r%d/%d\\r\", i, REQUESTS);\n        fflush(stdout);\n        close(sock);\n    }\n\n    min = INT_MAX;\n    avg = 0;\n    max = 0;\n\n    for(i=0; i<REQUESTS; i++)\n    {\n        if(times[i] < min) min = times[i];\n        if(times[i] > max) max = times[i];\n        avg += times[i];\n    }\n    avg /= REQUESTS;\n\n    PCT; printf(\"ping %s:%d (min/avg/max): %.3fms/%.3fms/%.3fms\\n\", ip_str, port, min/1000.0, avg/1000.0, max/1000.0);\n\n    return 0;\n}", "commit_link": "github.com/aircrack-ng/aircrack-ng/commit/091b153f294b9b695b0b2831e65936438b550d7b", "file_name": "src/aireplay-ng.c", "vul_type": "cwe-787", "description": "Write a C function named `tcp_test` that attempts to establish a TCP connection to a specified IP and port, sends a specific command, and measures connection times."}
{"func_name": "Logger::addPeer", "func_src_before": "void Logger::addPeer(const QString &ip, bool blocked, const QString &reason)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Peer temp = { peerCounter++, QDateTime::currentMSecsSinceEpoch(), ip, blocked, reason };\n    m_peers.push_back(temp);\n\n    if (m_peers.size() >= MAX_LOG_MESSAGES)\n        m_peers.pop_front();\n\n    emit newLogPeer(temp);\n}", "func_src_after": "void Logger::addPeer(const QString &ip, bool blocked, const QString &reason)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Peer temp = { peerCounter++, QDateTime::currentMSecsSinceEpoch(), Utils::String::toHtmlEscaped(ip), blocked, Utils::String::toHtmlEscaped(reason) };\n    m_peers.push_back(temp);\n\n    if (m_peers.size() >= MAX_LOG_MESSAGES)\n        m_peers.pop_front();\n\n    emit newLogPeer(temp);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/base/logger.cpp", "vul_type": "cwe-079", "description": "Write a C++ function in a Logger class that adds a peer with an IP, block status, and reason to a log, and emits a signal when a new peer is logged."}
{"func_name": "_delete_3par_host", "func_src_before": "    def _delete_3par_host(self, hostname):\n        self._cli_run('removehost %s' % hostname, None)", "func_src_after": "    def _delete_3par_host(self, hostname):\n        self._cli_run(['removehost', hostname])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function named `_delete_3par_host` that takes a hostname as an argument and calls a method `_cli_run` to execute a command to remove that host."}
{"func_name": "TarFileReader::extract", "func_src_before": "std::string TarFileReader::extract(const string &_path) {\n  if (_path.empty()) THROW(\"path cannot be empty\");\n  if (!hasMore()) THROW(\"No more tar files\");\n\n  string path = _path;\n  if (SystemUtilities::isDirectory(path)) path += \"/\" + getFilename();\n\n  LOG_DEBUG(5, \"Extracting: \" << path);\n\n  return extract(*SystemUtilities::oopen(path));\n}", "func_src_after": "std::string TarFileReader::extract(const string &_path) {\n  if (_path.empty()) THROW(\"path cannot be empty\");\n  if (!hasMore()) THROW(\"No more tar files\");\n\n  string path = _path;\n  if (SystemUtilities::isDirectory(path)) {\n    path += \"/\" + getFilename();\n\n    // Check that path is under the target directory\n    string a = SystemUtilities::getCanonicalPath(_path);\n    string b = SystemUtilities::getCanonicalPath(path);\n    if (!String::startsWith(b, a))\n      THROW(\"Tar path points outside of the extraction directory: \" << path);\n  }\n\n  LOG_DEBUG(5, \"Extracting: \" << path);\n\n  switch (getType()) {\n  case NORMAL_FILE: case CONTIGUOUS_FILE:\n    return extract(*SystemUtilities::oopen(path));\n  case DIRECTORY: SystemUtilities::ensureDirectory(path); break;\n  default: THROW(\"Unsupported tar file type \" << getType());\n  }\n\n  return getFilename();\n}", "commit_link": "github.com/CauldronDevelopmentLLC/cbang/commit/1c1dba62bd3e6fa9d0d0c0aa21926043b75382c7", "file_name": "src/cbang/tar/TarFileReader.cpp", "vul_type": "cwe-022", "description": "In C++, write a function to extract a file from a tar archive, handling path validation and logging the extraction process."}
{"func_name": "take_bug_report", "func_src_before": "    def take_bug_report(self, test_name, begin_time):\n        \"\"\"Takes a bug report on the device and stores it in a file.\n\n        Args:\n            test_name: Name of the test case that triggered this bug report.\n            begin_time: Logline format timestamp taken when the test started.\n        \"\"\"\n        new_br = True\n        try:\n            stdout = self.adb.shell('bugreportz -v').decode('utf-8')\n            # This check is necessary for builds before N, where adb shell's ret\n            # code and stderr are not propagated properly.\n            if 'not found' in stdout:\n                new_br = False\n        except adb.AdbError:\n            new_br = False\n        br_path = os.path.join(self.log_path, 'BugReports')\n        utils.create_dir(br_path)\n        base_name = ',%s,%s.txt' % (begin_time, self.serial)\n        if new_br:\n            base_name = base_name.replace('.txt', '.zip')\n        test_name_len = utils.MAX_FILENAME_LEN - len(base_name)\n        out_name = test_name[:test_name_len] + base_name\n        full_out_path = os.path.join(br_path, out_name.replace(' ', r'\\ '))\n        # in case device restarted, wait for adb interface to return\n        self.wait_for_boot_completion()\n        self.log.info('Taking bugreport for %s.', test_name)\n        if new_br:\n            out = self.adb.shell('bugreportz').decode('utf-8')\n            if not out.startswith('OK'):\n                raise DeviceError(self, 'Failed to take bugreport: %s' % out)\n            br_out_path = out.split(':')[1].strip()\n            self.adb.pull('%s %s' % (br_out_path, full_out_path))\n        else:\n            self.adb.bugreport(' > %s' % full_out_path)\n        self.log.info('Bugreport for %s taken at %s.', test_name,\n                      full_out_path)", "func_src_after": "    def take_bug_report(self, test_name, begin_time):\n        \"\"\"Takes a bug report on the device and stores it in a file.\n\n        Args:\n            test_name: Name of the test case that triggered this bug report.\n            begin_time: Logline format timestamp taken when the test started.\n        \"\"\"\n        new_br = True\n        try:\n            stdout = self.adb.shell('bugreportz -v').decode('utf-8')\n            # This check is necessary for builds before N, where adb shell's ret\n            # code and stderr are not propagated properly.\n            if 'not found' in stdout:\n                new_br = False\n        except adb.AdbError:\n            new_br = False\n        br_path = os.path.join(self.log_path, 'BugReports')\n        utils.create_dir(br_path)\n        base_name = ',%s,%s.txt' % (begin_time, self.serial)\n        if new_br:\n            base_name = base_name.replace('.txt', '.zip')\n        test_name_len = utils.MAX_FILENAME_LEN - len(base_name)\n        out_name = test_name[:test_name_len] + base_name\n        full_out_path = os.path.join(br_path, out_name.replace(' ', r'\\ '))\n        # in case device restarted, wait for adb interface to return\n        self.wait_for_boot_completion()\n        self.log.info('Taking bugreport for %s.', test_name)\n        if new_br:\n            out = self.adb.shell('bugreportz').decode('utf-8')\n            if not out.startswith('OK'):\n                raise DeviceError(self, 'Failed to take bugreport: %s' % out)\n            br_out_path = out.split(':')[1].strip()\n            self.adb.pull([br_out_path, full_out_path])\n        else:\n            # shell=True as this command redirects the stdout to a local file\n            # using shell redirection.\n            self.adb.bugreport(' > %s' % full_out_path, shell=True)\n        self.log.info('Bugreport for %s taken at %s.', test_name,\n                      full_out_path)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device.py", "vul_type": "cwe-078", "description": "Write a Python function to capture a bug report from a device, save it to a file, and handle different versions of the bug reporting tool."}
{"func_name": "check_testPickle", "func_src_before": "    def check_testPickle(self):\n        \"Test of pickling\"\n        x = arange(12)\n        x[4:10:2] = masked\n        x=x.reshape(4,3)\n        f = open('test9.pik','wb')\n        import pickle\n        pickle.dump(x, f)\n        f.close()\n        f = open('test9.pik', 'rb')\n        y = pickle.load(f)\n        assert eq(x,y)", "func_src_after": "    def check_testPickle(self):\n        \"Test of pickling\"\n        import pickle\n        x = arange(12)\n        x[4:10:2] = masked\n        x = x.reshape(4,3)\n        s = pickle.dumps(x)\n        y = pickle.loads(s)\n        assert eq(x,y)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 109, "char_end": 134, "line": "        x=x.reshape(4,3)\n"}, {"line_no": 6, "char_start": 134, "char_end": 169, "line": "        f = open('test9.pik','wb')\n"}, {"line_no": 7, "char_start": 169, "char_end": 191, "line": "        import pickle\n"}, {"line_no": 8, "char_start": 191, "char_end": 217, "line": "        pickle.dump(x, f)\n"}, {"line_no": 9, "char_start": 217, "char_end": 235, "line": "        f.close()\n"}, {"line_no": 10, "char_start": 235, "char_end": 271, "line": "        f = open('test9.pik', 'rb')\n"}, {"line_no": 11, "char_start": 271, "char_end": 298, "line": "        y = pickle.load(f)\n"}, {"line_no": 12, "char_start": 298, "char_end": 320, "line": "        assert eq(x,y) \n"}], "added": [{"line_no": 3, "char_start": 59, "char_end": 81, "line": "        import pickle\n"}]}, "char_changes": {"deleted": [{"char_start": 118, "char_end": 119, "chars": "="}, {"char_start": 142, "char_end": 269, "chars": "f = open('test9.pik','wb')\n        import pickle\n        pickle.dump(x, f)\n        f.close()\n        f = open('test9.pik', 'rb'"}, {"char_start": 294, "char_end": 296, "chars": "(f"}], "added": [{"char_start": 59, "char_end": 81, "chars": "        import pickle\n"}, {"char_start": 140, "char_end": 143, "chars": " = "}, {"char_start": 166, "char_end": 167, "chars": "s"}, {"char_start": 170, "char_end": 184, "chars": "pickle.dumps(x"}, {"char_start": 209, "char_end": 212, "chars": "s(s"}]}, "commit_link": "github.com/cjermain/numpy/commit/d1e5d1de77e30c233e98ea7c35f8d7b4623fd1f3", "file_name": "test_ma.py", "vul_type": "cwe-502", "commit_msg": "Use pickle.loads/dumps for test_ma to avoid littering the filesystem with test9.pik files.", "parent_commit": "0e1c71808725c49f65d84847cc6fc7e88909a6de", "description": "Write a Python function that tests pickling and unpickling an array with modified elements and reshaping."}
{"func_name": "lb_register_characteristic_read_event", "func_src_before": "lb_register_characteristic_read_event(lb_context lb_ctx,\n                                      lb_bl_device* dev,\n                                      const char* uuid,\n                                      sd_bus_message_handler_t callback,\n                                      void* userdata)\n{\n#ifdef DEBUG\n    printf(\"Method Called: %s\\n\", __FUNCTION__);\n#endif\n    int r;\n    sd_bus_error error = SD_BUS_ERROR_NULL;\n    lb_ble_char* ble_char_new = NULL;\n    char match[65];\n\n    if (lb_ctx == NULL) {\n        syslog(LOG_ERR, \"%s: lb_ctx is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_CONTEXT;\n    }\n\n    if (dev == NULL) {\n        syslog(LOG_ERR, \"%s: bl_device is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (uuid == NULL) {\n        syslog(LOG_ERR, \"%s: uuid is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (callback == NULL) {\n        syslog(LOG_ERR, \"%s: callback is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    r = lb_get_ble_characteristic_by_uuid(lb_ctx, dev, uuid, &ble_char_new);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: could find characteristic: %s\", __FUNCTION__, uuid);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_UNSPECIFIED;\n    }\n\n    r = sd_bus_call_method(lb_ctx->bus, BLUEZ_DEST, ble_char_new->char_path,\n                           BLUEZ_GATT_CHARACTERISTICS, \"StartNotify\", &error, NULL, NULL);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: sd_bus_call_method StartNotify on device %s failed with error: %s\",\n               __FUNCTION__, ble_char_new->char_path, error.message);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_SD_BUS_CALL_FAIL;\n    }\n\n    snprintf(match, 66, \"path='%s'\", ble_char_new->char_path);\n\n    int current_index = event_arr_size;\n    if (event_arr_size == 0 || events_matches_array == NULL) {\n        events_matches_array = (event_matches_callbacks**) malloc(sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error allocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n        event_arr_size++;\n    } else {\n        event_arr_size++;\n        events_matches_array =\n        realloc(events_matches_array, event_arr_size * sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n    }\n\n    event_matches_callbacks* new_event_pair =\n    (event_matches_callbacks*) malloc(sizeof(event_matches_callbacks));\n    if (new_event_pair == NULL) {\n        syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n        return -LB_ERROR_MEMEORY_ALLOCATION;\n    }\n    new_event_pair->event = match;\n    new_event_pair->callback = &callback;\n    new_event_pair->userdata = userdata;\n    events_matches_array[current_index] = new_event_pair;\n\n    pthread_create(&event_thread, NULL, _run_event_loop, &(lb_ctx->bus));\n    // wait for thread to start\n    sleep(2);\n\n    sd_bus_error_free(&error);\n    return LB_SUCCESS;\n}", "func_src_after": "lb_register_characteristic_read_event(lb_context lb_ctx,\n                                      lb_bl_device* dev,\n                                      const char* uuid,\n                                      sd_bus_message_handler_t callback,\n                                      void* userdata)\n{\n#ifdef DEBUG\n    printf(\"Method Called: %s\\n\", __FUNCTION__);\n#endif\n    int r;\n    sd_bus_error error = SD_BUS_ERROR_NULL;\n    lb_ble_char* ble_char_new = NULL;\n    char match[68];\n\n    if (lb_ctx == NULL) {\n        syslog(LOG_ERR, \"%s: lb_ctx is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_CONTEXT;\n    }\n\n    if (dev == NULL) {\n        syslog(LOG_ERR, \"%s: bl_device is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (uuid == NULL) {\n        syslog(LOG_ERR, \"%s: uuid is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (callback == NULL) {\n        syslog(LOG_ERR, \"%s: callback is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    r = lb_get_ble_characteristic_by_uuid(lb_ctx, dev, uuid, &ble_char_new);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: could find characteristic: %s\", __FUNCTION__, uuid);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_UNSPECIFIED;\n    }\n\n    r = sd_bus_call_method(lb_ctx->bus, BLUEZ_DEST, ble_char_new->char_path,\n                           BLUEZ_GATT_CHARACTERISTICS, \"StartNotify\", &error, NULL, NULL);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: sd_bus_call_method StartNotify on device %s failed with error: %s\",\n               __FUNCTION__, ble_char_new->char_path, error.message);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_SD_BUS_CALL_FAIL;\n    }\n\n    snprintf(match, 67, \"path='%s'\", ble_char_new->char_path);\n\n    int current_index = event_arr_size;\n    if (event_arr_size == 0 || events_matches_array == NULL) {\n        events_matches_array = (event_matches_callbacks**) malloc(sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error allocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n        event_arr_size++;\n    } else {\n        event_arr_size++;\n        events_matches_array =\n        realloc(events_matches_array, event_arr_size * sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n    }\n\n    event_matches_callbacks* new_event_pair =\n    (event_matches_callbacks*) malloc(sizeof(event_matches_callbacks));\n    if (new_event_pair == NULL) {\n        syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n        return -LB_ERROR_MEMEORY_ALLOCATION;\n    }\n    new_event_pair->event = match;\n    new_event_pair->callback = &callback;\n    new_event_pair->userdata = userdata;\n    events_matches_array[current_index] = new_event_pair;\n\n    pthread_create(&event_thread, NULL, _run_event_loop, &(lb_ctx->bus));\n    // wait for thread to start\n    sleep(2);\n\n    sd_bus_error_free(&error);\n    return LB_SUCCESS;\n}", "line_changes": {"deleted": [{"line_no": 13, "char_start": 461, "char_end": 481, "line": "    char match[65];\n"}, {"line_no": 51, "char_start": 1716, "char_end": 1779, "line": "    snprintf(match, 66, \"path='%s'\", ble_char_new->char_path);\n"}], "added": [{"line_no": 13, "char_start": 461, "char_end": 481, "line": "    char match[68];\n"}, {"line_no": 51, "char_start": 1716, "char_end": 1779, "line": "    snprintf(match, 67, \"path='%s'\", ble_char_new->char_path);\n"}]}, "char_changes": {"deleted": [{"char_start": 477, "char_end": 478, "chars": "5"}, {"char_start": 1737, "char_end": 1738, "chars": "6"}], "added": [{"char_start": 477, "char_end": 478, "chars": "8"}, {"char_start": 1737, "char_end": 1738, "chars": "7"}]}, "commit_link": "github.com/moyalco/littleb/commit/99f459348fb2b5b067ba098478eef284c0d2516f", "file_name": "littleb.c", "vul_type": "cwe-787", "commit_msg": "littleb.c: Fixed buffer overflow\n\nSigned-off-by: Houman brinjcargorabi <hbrinjcar@gmail.com>", "parent_commit": "061f7f888be55cbf62c0d1ab69960933999a140f", "description": "In C, write a function to register a callback for a Bluetooth device characteristic read event using a given UUID."}
{"func_name": "percona_command", "func_src_before": "    def percona_command(execute_sql, database_name, table_name, options = {})\n      command = \"pt-online-schema-change --alter '#{execute_sql}' D=#{database_name},t=#{table_name}\"\n\n      # Whitelist\n      options = HashWithIndifferentAccess.new(options)\n      options = options.slice(*self.class.percona_flags.keys)\n\n      # Merge config\n      config = percona_config\n      if config\n        config.slice(*self.class.percona_flags.keys).each do |key, value|\n          options[key] ||= value\n        end\n      end\n\n      # Set defaults\n      self.class.percona_flags.each do |flag, flag_config|\n        options[flag] = flag_config[:default] if flag_config.key?(:default) && !options.key?(flag)\n      end\n\n      \"#{command}#{run_mode_flag(options)}#{command_flags(options)}\"\n    end", "func_src_after": "    def percona_command(execute_sql, database_name, table_name, options = {})\n      command = ['pt-online-schema-change', '--alter', execute_sql || '', \"D=#{database_name},t=#{table_name}\"]\n\n      # Whitelist\n      options = HashWithIndifferentAccess.new(options)\n      options = options.slice(*self.class.percona_flags.keys)\n\n      # Merge config\n      config = percona_config\n      if config\n        config.slice(*self.class.percona_flags.keys).each do |key, value|\n          options[key] ||= value\n        end\n      end\n\n      # Set defaults\n      self.class.percona_flags.each do |flag, flag_config|\n        options[flag] = flag_config[:default] if flag_config.key?(:default) && !options.key?(flag)\n      end\n\n      command_parts = command + [run_mode_flag(options)] + command_flags(options)\n\n      command_parts.shelljoin\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 78, "char_end": 180, "line": "      command = \"pt-online-schema-change --alter '#{execute_sql}' D=#{database_name},t=#{table_name}\"\n"}, {"line_no": 21, "char_start": 704, "char_end": 773, "line": "      \"#{command}#{run_mode_flag(options)}#{command_flags(options)}\"\n"}], "added": [{"line_no": 2, "char_start": 78, "char_end": 190, "line": "      command = ['pt-online-schema-change', '--alter', execute_sql || '', \"D=#{database_name},t=#{table_name}\"]\n"}, {"line_no": 21, "char_start": 714, "char_end": 796, "line": "      command_parts = command + [run_mode_flag(options)] + command_flags(options)\n"}, {"line_no": 22, "char_start": 796, "char_end": 797, "line": "\n"}, {"line_no": 23, "char_start": 797, "char_end": 827, "line": "      command_parts.shelljoin\n"}]}, "char_changes": {"deleted": [{"char_start": 94, "char_end": 95, "chars": "\""}, {"char_start": 118, "char_end": 119, "chars": " "}, {"char_start": 126, "char_end": 130, "chars": " '#{"}, {"char_start": 141, "char_end": 144, "chars": "}' "}, {"char_start": 710, "char_end": 713, "chars": "\"#{"}, {"char_start": 720, "char_end": 723, "chars": "}#{"}, {"char_start": 745, "char_end": 748, "chars": "}#{"}, {"char_start": 770, "char_end": 772, "chars": "}\""}], "added": [{"char_start": 94, "char_end": 96, "chars": "['"}, {"char_start": 119, "char_end": 123, "chars": "', '"}, {"char_start": 130, "char_end": 133, "chars": "', "}, {"char_start": 144, "char_end": 153, "chars": " || '', \""}, {"char_start": 188, "char_end": 189, "chars": "]"}, {"char_start": 727, "char_end": 747, "chars": "_parts = command + ["}, {"char_start": 769, "char_end": 773, "chars": "] + "}, {"char_start": 795, "char_end": 826, "chars": "\n\n      command_parts.shelljoin"}]}, "commit_link": "github.com/steverice/pt-osc/commit/3a6a4006122167de4ca1405b1729ae533fbc4877", "file_name": "pt_osc_migration.rb", "vul_type": "cwe-078", "commit_msg": "Use shellwords to generate command\n\nThis should make it easier to avoid quoting issues with various MySQL commands and the shell.\n\nFixes PagerDuty/pt-osc#12", "description": "Write a Ruby method that constructs a command line for the `pt-online-schema-change` tool, accepting SQL to execute, database and table names, and an optional hash of options."}
{"func_name": "WriteTIFFImage", "func_src_before": "static MagickBooleanType WriteTIFFImage(const ImageInfo *image_info,\n  Image *image)\n{\n  const char\n    *mode,\n    *option;\n\n  CompressionType\n    compression;\n\n  EndianType\n    endian_type;\n\n  MagickBooleanType\n    debug,\n    status;\n\n  MagickOffsetType\n    scene;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumType\n    quantum_type;\n\n  register ssize_t\n    i;\n\n  size_t\n    imageListLength;\n\n  ssize_t\n    y;\n\n  TIFF\n    *tiff;\n\n  TIFFInfo\n    tiff_info;\n\n  uint16\n    bits_per_sample,\n    compress_tag,\n    endian,\n    photometric,\n    predictor;\n\n  unsigned char\n    *pixels;\n\n  /*\n    Open TIFF file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,&image->exception);\n  if (status == MagickFalse)\n    return(status);\n  (void) SetMagickThreadValue(tiff_exception,&image->exception);\n  endian_type=UndefinedEndian;\n  option=GetImageOption(image_info,\"tiff:endian\");\n  if (option != (const char *) NULL)\n    {\n      if (LocaleNCompare(option,\"msb\",3) == 0)\n        endian_type=MSBEndian;\n      if (LocaleNCompare(option,\"lsb\",3) == 0)\n        endian_type=LSBEndian;;\n    }\n  switch (endian_type)\n  {\n    case LSBEndian: mode=\"wl\"; break;\n    case MSBEndian: mode=\"wb\"; break;\n    default: mode=\"w\"; break;\n  }\n#if defined(TIFF_VERSION_BIG)\n  if (LocaleCompare(image_info->magick,\"TIFF64\") == 0)\n    switch (endian_type)\n    {\n      case LSBEndian: mode=\"wl8\"; break;\n      case MSBEndian: mode=\"wb8\"; break;\n      default: mode=\"w8\"; break;\n    }\n#endif\n  tiff=TIFFClientOpen(image->filename,mode,(thandle_t) image,TIFFReadBlob,\n    TIFFWriteBlob,TIFFSeekBlob,TIFFCloseBlob,TIFFGetBlobSize,TIFFMapBlob,\n    TIFFUnmapBlob);\n  if (tiff == (TIFF *) NULL)\n    return(MagickFalse);\n  if (image->exception.severity > ErrorException)\n    {\n      TIFFClose(tiff);\n      return(MagickFalse);\n    }\n  (void) DeleteImageProfile(image,\"tiff:37724\");\n  scene=0;\n  debug=IsEventLogging();\n  (void) debug;\n  imageListLength=GetImageListLength(image);\n  do\n  {\n    /*\n      Initialize TIFF fields.\n    */\n    if ((image_info->type != UndefinedType) &&\n        (image_info->type != OptimizeType))\n      (void) SetImageType(image,image_info->type);\n    compression=UndefinedCompression;\n    if (image->compression != JPEGCompression)\n      compression=image->compression;\n    if (image_info->compression != UndefinedCompression)\n      compression=image_info->compression;\n    switch (compression)\n    {\n      case FaxCompression:\n      case Group4Compression:\n      {\n        (void) SetImageType(image,BilevelType);\n        (void) SetImageDepth(image,1);\n        break;\n      }\n      case JPEGCompression:\n      {\n        (void) SetImageStorageClass(image,DirectClass);\n        (void) SetImageDepth(image,8);\n        break;\n      }\n      default:\n        break;\n    }\n    quantum_info=AcquireQuantumInfo(image_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if ((image->storage_class != PseudoClass) && (image->depth >= 32) &&\n        (quantum_info->format == UndefinedQuantumFormat) &&\n        (IsHighDynamicRangeImage(image,&image->exception) != MagickFalse))\n      {\n        status=SetQuantumFormat(image,quantum_info,FloatingPointQuantumFormat);\n        if (status == MagickFalse)\n          {\n            quantum_info=DestroyQuantumInfo(quantum_info);\n            ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n      }\n    if ((LocaleCompare(image_info->magick,\"PTIF\") == 0) &&\n        (GetPreviousImageInList(image) != (Image *) NULL))\n      (void) TIFFSetField(tiff,TIFFTAG_SUBFILETYPE,FILETYPE_REDUCEDIMAGE);\n    if ((image->columns != (uint32) image->columns) ||\n        (image->rows != (uint32) image->rows))\n      ThrowWriterException(ImageError,\"WidthOrHeightExceedsLimit\");\n    (void) TIFFSetField(tiff,TIFFTAG_IMAGELENGTH,(uint32) image->rows);\n    (void) TIFFSetField(tiff,TIFFTAG_IMAGEWIDTH,(uint32) image->columns);\n    switch (compression)\n    {\n      case FaxCompression:\n      {\n        compress_tag=COMPRESSION_CCITTFAX3;\n        option=GetImageOption(image_info,\"quantum:polarity\");\n        if (option == (const char *) NULL)\n          SetQuantumMinIsWhite(quantum_info,MagickTrue);\n        break;\n      }\n      case Group4Compression:\n      {\n        compress_tag=COMPRESSION_CCITTFAX4;\n        option=GetImageOption(image_info,\"quantum:polarity\");\n        if (option == (const char *) NULL)\n          SetQuantumMinIsWhite(quantum_info,MagickTrue);\n        break;\n      }\n#if defined(COMPRESSION_JBIG)\n      case JBIG1Compression:\n      {\n        compress_tag=COMPRESSION_JBIG;\n        break;\n      }\n#endif\n      case JPEGCompression:\n      {\n        compress_tag=COMPRESSION_JPEG;\n        break;\n      }\n#if defined(COMPRESSION_LZMA)\n      case LZMACompression:\n      {\n        compress_tag=COMPRESSION_LZMA;\n        break;\n      }\n#endif\n      case LZWCompression:\n      {\n        compress_tag=COMPRESSION_LZW;\n        break;\n      }\n      case RLECompression:\n      {\n        compress_tag=COMPRESSION_PACKBITS;\n        break;\n      }\n#if defined(COMPRESSION_WEBP)\n      case WebPCompression:\n      {\n        compress_tag=COMPRESSION_WEBP;\n        break;\n      }\n#endif\n      case ZipCompression:\n      {\n        compress_tag=COMPRESSION_ADOBE_DEFLATE;\n        break;\n      }\n#if defined(COMPRESSION_ZSTD)\n      case ZstdCompression:\n      {\n        compress_tag=COMPRESSION_ZSTD;\n        break;\n      }\n#endif\n      case NoCompression:\n      default:\n      {\n        compress_tag=COMPRESSION_NONE;\n        break;\n      }\n    }\n#if defined(MAGICKCORE_HAVE_TIFFISCODECCONFIGURED) || (TIFFLIB_VERSION > 20040919)\n    if ((compress_tag != COMPRESSION_NONE) &&\n        (TIFFIsCODECConfigured(compress_tag) == 0))\n      {\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"CompressionNotSupported\",\"`%s'\",CommandOptionToMnemonic(\n          MagickCompressOptions,(ssize_t) compression));\n        compress_tag=COMPRESSION_NONE;\n      }\n#else\n      switch (compress_tag)\n      {\n#if defined(CCITT_SUPPORT)\n        case COMPRESSION_CCITTFAX3:\n        case COMPRESSION_CCITTFAX4:\n#endif\n#if defined(YCBCR_SUPPORT) && defined(JPEG_SUPPORT)\n        case COMPRESSION_JPEG:\n#endif\n#if defined(LZMA_SUPPORT) && defined(COMPRESSION_LZMA)\n        case COMPRESSION_LZMA:\n#endif\n#if defined(LZW_SUPPORT)\n        case COMPRESSION_LZW:\n#endif\n#if defined(PACKBITS_SUPPORT)\n        case COMPRESSION_PACKBITS:\n#endif\n#if defined(ZIP_SUPPORT)\n        case COMPRESSION_ADOBE_DEFLATE:\n#endif\n        case COMPRESSION_NONE:\n          break;\n        default:\n        {\n          (void) ThrowMagickException(&image->exception,GetMagickModule(),\n            CoderError,\"CompressionNotSupported\",\"`%s'\",CommandOptionToMnemonic(\n              MagickCompressOptions,(ssize_t) compression));\n          compress_tag=COMPRESSION_NONE;\n          break;\n        }\n      }\n#endif\n    if (image->colorspace == CMYKColorspace)\n      {\n        photometric=PHOTOMETRIC_SEPARATED;\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,4);\n        (void) TIFFSetField(tiff,TIFFTAG_INKSET,INKSET_CMYK);\n      }\n    else\n      {\n        /*\n          Full color TIFF raster.\n        */\n        if (image->colorspace == LabColorspace)\n          {\n            photometric=PHOTOMETRIC_CIELAB;\n            EncodeLabImage(image,&image->exception);\n          }\n        else\n          if (image->colorspace == YCbCrColorspace)\n            {\n              photometric=PHOTOMETRIC_YCBCR;\n              (void) TIFFSetField(tiff,TIFFTAG_YCBCRSUBSAMPLING,1,1);\n              (void) SetImageStorageClass(image,DirectClass);\n              (void) SetImageDepth(image,8);\n            }\n          else\n            photometric=PHOTOMETRIC_RGB;\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,3);\n        if ((image_info->type != TrueColorType) &&\n            (image_info->type != TrueColorMatteType))\n          {\n            if ((image_info->type != PaletteType) &&\n                (SetImageGray(image,&image->exception) != MagickFalse))\n              {\n                photometric=(uint16) (quantum_info->min_is_white !=\n                  MagickFalse ? PHOTOMETRIC_MINISWHITE :\n                  PHOTOMETRIC_MINISBLACK);\n                (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,1);\n                if ((image->depth == 1) && (image->matte == MagickFalse))\n                  SetImageMonochrome(image,&image->exception);\n              }\n            else\n              if (image->storage_class == PseudoClass)\n                {\n                  size_t\n                    depth;\n\n                  /*\n                    Colormapped TIFF raster.\n                  */\n                  (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,1);\n                  photometric=PHOTOMETRIC_PALETTE;\n                  depth=1;\n                  while ((GetQuantumRange(depth)+1) < image->colors)\n                    depth<<=1;\n                  status=SetQuantumDepth(image,quantum_info,depth);\n                  if (status == MagickFalse)\n                    ThrowWriterException(ResourceLimitError,\n                      \"MemoryAllocationFailed\");\n                }\n          }\n      }\n    (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_FILLORDER,&endian);\n    if ((compress_tag == COMPRESSION_CCITTFAX3) ||\n        (compress_tag == COMPRESSION_CCITTFAX4))\n      {\n         if ((photometric != PHOTOMETRIC_MINISWHITE) &&\n             (photometric != PHOTOMETRIC_MINISBLACK))\n          {\n            compress_tag=COMPRESSION_NONE;\n            endian=FILLORDER_MSB2LSB;\n          }\n      }\n    option=GetImageOption(image_info,\"tiff:fill-order\");\n    if (option != (const char *) NULL)\n      {\n        if (LocaleNCompare(option,\"msb\",3) == 0)\n          endian=FILLORDER_MSB2LSB;\n        if (LocaleNCompare(option,\"lsb\",3) == 0)\n          endian=FILLORDER_LSB2MSB;\n      }\n    (void) TIFFSetField(tiff,TIFFTAG_COMPRESSION,compress_tag);\n    (void) TIFFSetField(tiff,TIFFTAG_FILLORDER,endian);\n    (void) TIFFSetField(tiff,TIFFTAG_BITSPERSAMPLE,quantum_info->depth);\n    if (image->matte != MagickFalse)\n      {\n        uint16\n          extra_samples,\n          sample_info[1],\n          samples_per_pixel;\n\n        /*\n          TIFF has a matte channel.\n        */\n        extra_samples=1;\n        sample_info[0]=EXTRASAMPLE_UNASSALPHA;\n        option=GetImageOption(image_info,\"tiff:alpha\");\n        if (option != (const char *) NULL)\n          {\n            if (LocaleCompare(option,\"associated\") == 0)\n              sample_info[0]=EXTRASAMPLE_ASSOCALPHA;\n            else\n              if (LocaleCompare(option,\"unspecified\") == 0)\n                sample_info[0]=EXTRASAMPLE_UNSPECIFIED;\n          }\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_SAMPLESPERPIXEL,\n          &samples_per_pixel);\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,samples_per_pixel+1);\n        (void) TIFFSetField(tiff,TIFFTAG_EXTRASAMPLES,extra_samples,\n          &sample_info);\n        if (sample_info[0] == EXTRASAMPLE_ASSOCALPHA)\n          SetQuantumAlphaType(quantum_info,AssociatedQuantumAlpha);\n      }\n    (void) TIFFSetField(tiff,TIFFTAG_PHOTOMETRIC,photometric);\n    switch (quantum_info->format)\n    {\n      case FloatingPointQuantumFormat:\n      {\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLEFORMAT,SAMPLEFORMAT_IEEEFP);\n        (void) TIFFSetField(tiff,TIFFTAG_SMINSAMPLEVALUE,quantum_info->minimum);\n        (void) TIFFSetField(tiff,TIFFTAG_SMAXSAMPLEVALUE,quantum_info->maximum);\n        break;\n      }\n      case SignedQuantumFormat:\n      {\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLEFORMAT,SAMPLEFORMAT_INT);\n        break;\n      }\n      case UnsignedQuantumFormat:\n      {\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLEFORMAT,SAMPLEFORMAT_UINT);\n        break;\n      }\n      default:\n        break;\n    }\n    (void) TIFFSetField(tiff,TIFFTAG_PLANARCONFIG,PLANARCONFIG_CONTIG);\n    if (photometric == PHOTOMETRIC_RGB)\n      if ((image_info->interlace == PlaneInterlace) ||\n          (image_info->interlace == PartitionInterlace))\n        (void) TIFFSetField(tiff,TIFFTAG_PLANARCONFIG,PLANARCONFIG_SEPARATE);\n    predictor=0;\n    switch (compress_tag)\n    {\n      case COMPRESSION_JPEG:\n      {\n#if defined(JPEG_SUPPORT)\n        if (image_info->quality != UndefinedCompressionQuality)\n          (void) TIFFSetField(tiff,TIFFTAG_JPEGQUALITY,image_info->quality);\n        (void) TIFFSetField(tiff,TIFFTAG_JPEGCOLORMODE,JPEGCOLORMODE_RAW);\n        if (IssRGBCompatibleColorspace(image->colorspace) != MagickFalse)\n          {\n            const char\n              *value;\n\n            (void) TIFFSetField(tiff,TIFFTAG_JPEGCOLORMODE,JPEGCOLORMODE_RGB);\n            if (image->colorspace == YCbCrColorspace)\n              {\n                const char\n                  *sampling_factor;\n\n                GeometryInfo\n                  geometry_info;\n\n                MagickStatusType\n                  flags;\n\n                sampling_factor=(const char *) NULL;\n                value=GetImageProperty(image,\"jpeg:sampling-factor\");\n                if (value != (char *) NULL)\n                  {\n                    sampling_factor=value;\n                    if (image->debug != MagickFalse)\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"  Input sampling-factors=%s\",sampling_factor);\n                  }\n                if (image_info->sampling_factor != (char *) NULL)\n                  sampling_factor=image_info->sampling_factor;\n                if (sampling_factor != (const char *) NULL)\n                  {\n                    flags=ParseGeometry(sampling_factor,&geometry_info);\n                    if ((flags & SigmaValue) == 0)\n                      geometry_info.sigma=geometry_info.rho;\n                    (void) TIFFSetField(tiff,TIFFTAG_YCBCRSUBSAMPLING,(uint16)\n                      geometry_info.rho,(uint16) geometry_info.sigma);\n                  }\n            }\n          }\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (bits_per_sample == 12)\n          (void) TIFFSetField(tiff,TIFFTAG_JPEGTABLESMODE,JPEGTABLESMODE_QUANT);\n#endif\n        break;\n      }\n      case COMPRESSION_ADOBE_DEFLATE:\n      {\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        (void) TIFFSetField(tiff,TIFFTAG_ZIPQUALITY,(long) (\n          image_info->quality == UndefinedCompressionQuality ? 7 :\n          MagickMin((ssize_t) image_info->quality/10,9)));\n        break;\n      }\n      case COMPRESSION_CCITTFAX3:\n      {\n        /*\n          Byte-aligned EOL.\n        */\n        (void) TIFFSetField(tiff,TIFFTAG_GROUP3OPTIONS,4);\n        break;\n      }\n      case COMPRESSION_CCITTFAX4:\n        break;\n#if defined(LZMA_SUPPORT) && defined(COMPRESSION_LZMA)\n      case COMPRESSION_LZMA:\n      {\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        (void) TIFFSetField(tiff,TIFFTAG_LZMAPRESET,(long) (\n          image_info->quality == UndefinedCompressionQuality ? 7 :\n          MagickMin((ssize_t) image_info->quality/10,9)));\n        break;\n      }\n#endif\n      case COMPRESSION_LZW:\n      {\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        break;\n      }\n#if defined(WEBP_SUPPORT) && defined(COMPRESSION_WEBP)\n      case COMPRESSION_WEBP:\n      {\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        (void) TIFFSetField(tiff,TIFFTAG_WEBP_LEVEL,mage_info->quality);\n        if (image_info->quality >= 100)\n          (void) TIFFSetField(tiff,TIFFTAG_WEBP_LOSSLESS,1);\n        break;\n      }\n#endif\n#if defined(ZSTD_SUPPORT) && defined(COMPRESSION_ZSTD)\n      case COMPRESSION_ZSTD:\n      {\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        (void) TIFFSetField(tiff,TIFFTAG_ZSTD_LEVEL,22*image_info->quality/\n          100.0);\n        break;\n      }\n#endif\n      default:\n        break;\n    }\n    option=GetImageOption(image_info,\"tiff:predictor\");\n    if (option != (const char * ) NULL)\n      predictor=(size_t) strtol(option,(char **) NULL,10);\n    if (predictor != 0)\n      (void) TIFFSetField(tiff,TIFFTAG_PREDICTOR,predictor);\n    if ((image->x_resolution != 0.0) && (image->y_resolution != 0.0))\n      {\n        unsigned short\n          units;\n\n        /*\n          Set image resolution.\n        */\n        units=RESUNIT_NONE;\n        if (image->units == PixelsPerInchResolution)\n          units=RESUNIT_INCH;\n        if (image->units == PixelsPerCentimeterResolution)\n          units=RESUNIT_CENTIMETER;\n        (void) TIFFSetField(tiff,TIFFTAG_RESOLUTIONUNIT,(uint16) units);\n        (void) TIFFSetField(tiff,TIFFTAG_XRESOLUTION,image->x_resolution);\n        (void) TIFFSetField(tiff,TIFFTAG_YRESOLUTION,image->y_resolution);\n        if ((image->page.x < 0) || (image->page.y < 0))\n          (void) ThrowMagickException(&image->exception,GetMagickModule(),\n            CoderError,\"TIFF: negative image positions unsupported\",\"%s\",\n            image->filename);\n        if ((image->page.x > 0) && (image->x_resolution > 0.0))\n          {\n            /*\n              Set horizontal image position.\n            */\n            (void) TIFFSetField(tiff,TIFFTAG_XPOSITION,(float) image->page.x/\n              image->x_resolution);\n          }\n        if ((image->page.y > 0) && (image->y_resolution > 0.0))\n          {\n            /*\n              Set vertical image position.\n            */\n            (void) TIFFSetField(tiff,TIFFTAG_YPOSITION,(float) image->page.y/\n              image->y_resolution);\n          }\n      }\n    if (image->chromaticity.white_point.x != 0.0)\n      {\n        float\n          chromaticity[6];\n\n        /*\n          Set image chromaticity.\n        */\n        chromaticity[0]=(float) image->chromaticity.red_primary.x;\n        chromaticity[1]=(float) image->chromaticity.red_primary.y;\n        chromaticity[2]=(float) image->chromaticity.green_primary.x;\n        chromaticity[3]=(float) image->chromaticity.green_primary.y;\n        chromaticity[4]=(float) image->chromaticity.blue_primary.x;\n        chromaticity[5]=(float) image->chromaticity.blue_primary.y;\n        (void) TIFFSetField(tiff,TIFFTAG_PRIMARYCHROMATICITIES,chromaticity);\n        chromaticity[0]=(float) image->chromaticity.white_point.x;\n        chromaticity[1]=(float) image->chromaticity.white_point.y;\n        (void) TIFFSetField(tiff,TIFFTAG_WHITEPOINT,chromaticity);\n      }\n    if ((LocaleCompare(image_info->magick,\"PTIF\") != 0) &&\n        (image_info->adjoin != MagickFalse) && (imageListLength > 1))\n      {\n        (void) TIFFSetField(tiff,TIFFTAG_SUBFILETYPE,FILETYPE_PAGE);\n        if (image->scene != 0)\n          (void) TIFFSetField(tiff,TIFFTAG_PAGENUMBER,(uint16) image->scene,\n            imageListLength);\n      }\n    if (image->orientation != UndefinedOrientation)\n      (void) TIFFSetField(tiff,TIFFTAG_ORIENTATION,(uint16) image->orientation);\n    else\n      (void) TIFFSetField(tiff,TIFFTAG_ORIENTATION,ORIENTATION_TOPLEFT);\n    (void) TIFFSetProfiles(tiff,image);\n    {\n      uint16\n        page,\n        pages;\n\n      page=(uint16) scene;\n      pages=(uint16) imageListLength;\n      if ((LocaleCompare(image_info->magick,\"PTIF\") != 0) &&\n          (image_info->adjoin != MagickFalse) && (pages > 1))\n        (void) TIFFSetField(tiff,TIFFTAG_SUBFILETYPE,FILETYPE_PAGE);\n      (void) TIFFSetField(tiff,TIFFTAG_PAGENUMBER,page,pages);\n    }\n    (void) TIFFSetProperties(tiff,image_info,image);\nDisableMSCWarning(4127)\n    if (0)\nRestoreMSCWarning\n      (void) TIFFSetEXIFProperties(tiff,image);\n    /*\n      Write image scanlines.\n    */\n    if (GetTIFFInfo(image_info,tiff,&tiff_info) == MagickFalse)\n      ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    quantum_info->endian=LSBEndian;\n    pixels=GetQuantumPixels(quantum_info);\n    tiff_info.scanline=GetQuantumPixels(quantum_info);\n    switch (photometric)\n    {\n      case PHOTOMETRIC_CIELAB:\n      case PHOTOMETRIC_YCBCR:\n      case PHOTOMETRIC_RGB:\n      {\n        /*\n          RGB TIFF image.\n        */\n        switch (image_info->interlace)\n        {\n          case NoInterlace:\n          default:\n          {\n            quantum_type=RGBQuantum;\n            if (image->matte != MagickFalse)\n              quantum_type=RGBAQuantum;\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              register const PixelPacket\n                *magick_restrict p;\n\n              p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n              if (p == (const PixelPacket *) NULL)\n                break;\n              (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                quantum_info,quantum_type,pixels,&image->exception);\n              if (TIFFWritePixels(tiff,&tiff_info,y,0,image) == -1)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,SaveImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            break;\n          }\n          case PlaneInterlace:\n          case PartitionInterlace:\n          {\n            /*\n              Plane interlacing:  RRRRRR...GGGGGG...BBBBBB...\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              register const PixelPacket\n                *magick_restrict p;\n\n              p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n              if (p == (const PixelPacket *) NULL)\n                break;\n              (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                quantum_info,RedQuantum,pixels,&image->exception);\n              if (TIFFWritePixels(tiff,&tiff_info,y,0,image) == -1)\n                break;\n            }\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,SaveImageTag,100,400);\n                if (status == MagickFalse)\n                  break;\n              }\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              register const PixelPacket\n                *magick_restrict p;\n\n              p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n              if (p == (const PixelPacket *) NULL)\n                break;\n              (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                quantum_info,GreenQuantum,pixels,&image->exception);\n              if (TIFFWritePixels(tiff,&tiff_info,y,1,image) == -1)\n                break;\n            }\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,SaveImageTag,200,400);\n                if (status == MagickFalse)\n                  break;\n              }\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              register const PixelPacket\n                *magick_restrict p;\n\n              p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n              if (p == (const PixelPacket *) NULL)\n                break;\n              (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                quantum_info,BlueQuantum,pixels,&image->exception);\n              if (TIFFWritePixels(tiff,&tiff_info,y,2,image) == -1)\n                break;\n            }\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,SaveImageTag,300,400);\n                if (status == MagickFalse)\n                  break;\n              }\n            if (image->matte != MagickFalse)\n              for (y=0; y < (ssize_t) image->rows; y++)\n              {\n                register const PixelPacket\n                  *magick_restrict p;\n\n                p=GetVirtualPixels(image,0,y,image->columns,1,\n                  &image->exception);\n                if (p == (const PixelPacket *) NULL)\n                  break;\n                (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                  quantum_info,AlphaQuantum,pixels,&image->exception);\n                if (TIFFWritePixels(tiff,&tiff_info,y,3,image) == -1)\n                  break;\n              }\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,SaveImageTag,400,400);\n                if (status == MagickFalse)\n                  break;\n              }\n            break;\n          }\n        }\n        break;\n      }\n      case PHOTOMETRIC_SEPARATED:\n      {\n        /*\n          CMYK TIFF image.\n        */\n        quantum_type=CMYKQuantum;\n        if (image->matte != MagickFalse)\n          quantum_type=CMYKAQuantum;\n        if (image->colorspace != CMYKColorspace)\n          (void) TransformImageColorspace(image,CMYKColorspace);\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          register const PixelPacket\n            *magick_restrict p;\n\n          p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n          if (p == (const PixelPacket *) NULL)\n            break;\n          (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n            quantum_info,quantum_type,pixels,&image->exception);\n          if (TIFFWritePixels(tiff,&tiff_info,y,0,image) == -1)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case PHOTOMETRIC_PALETTE:\n      {\n        uint16\n          *blue,\n          *green,\n          *red;\n\n        /*\n          Colormapped TIFF image.\n        */\n        red=(uint16 *) AcquireQuantumMemory(65536,sizeof(*red));\n        green=(uint16 *) AcquireQuantumMemory(65536,sizeof(*green));\n        blue=(uint16 *) AcquireQuantumMemory(65536,sizeof(*blue));\n        if ((red == (uint16 *) NULL) || (green == (uint16 *) NULL) ||\n            (blue == (uint16 *) NULL))\n          {\n            if (red != (uint16 *) NULL)\n              red=(uint16 *) RelinquishMagickMemory(red);\n            if (green != (uint16 *) NULL)\n              green=(uint16 *) RelinquishMagickMemory(green);\n            if (blue != (uint16 *) NULL)\n              blue=(uint16 *) RelinquishMagickMemory(blue);\n            ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        /*\n          Initialize TIFF colormap.\n        */\n        (void) memset(red,0,65536*sizeof(*red));\n        (void) memset(green,0,65536*sizeof(*green));\n        (void) memset(blue,0,65536*sizeof(*blue));\n        for (i=0; i < (ssize_t) image->colors; i++)\n        {\n          red[i]=ScaleQuantumToShort(image->colormap[i].red);\n          green[i]=ScaleQuantumToShort(image->colormap[i].green);\n          blue[i]=ScaleQuantumToShort(image->colormap[i].blue);\n        }\n        (void) TIFFSetField(tiff,TIFFTAG_COLORMAP,red,green,blue);\n        red=(uint16 *) RelinquishMagickMemory(red);\n        green=(uint16 *) RelinquishMagickMemory(green);\n        blue=(uint16 *) RelinquishMagickMemory(blue);\n      }\n      default:\n      {\n        /*\n          Convert PseudoClass packets to contiguous grayscale scanlines.\n        */\n        quantum_type=IndexQuantum;\n        if (image->matte != MagickFalse)\n          {\n            if (photometric != PHOTOMETRIC_PALETTE)\n              quantum_type=GrayAlphaQuantum;\n            else\n              quantum_type=IndexAlphaQuantum;\n           }\n         else\n           if (photometric != PHOTOMETRIC_PALETTE)\n             quantum_type=GrayQuantum;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          register const PixelPacket\n            *magick_restrict p;\n\n          p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n          if (p == (const PixelPacket *) NULL)\n            break;\n          (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n            quantum_info,quantum_type,pixels,&image->exception);\n          if (TIFFWritePixels(tiff,&tiff_info,y,0,image) == -1)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n    }\n    quantum_info=DestroyQuantumInfo(quantum_info);\n    if (image->colorspace == LabColorspace)\n      DecodeLabImage(image,&image->exception);\n    DestroyTIFFInfo(&tiff_info);\n    if (image->exception.severity > ErrorException)\n      break;\nDisableMSCWarning(4127)\n    if (0 && (image_info->verbose != MagickFalse))\nRestoreMSCWarning\n      TIFFPrintDirectory(tiff,stdout,MagickFalse);\n    (void) TIFFWriteDirectory(tiff);\n    image=SyncNextImageInList(image);\n    if (image == (Image *) NULL)\n      break;\n    status=SetImageProgress(image,SaveImagesTag,scene++,imageListLength);\n    if (status == MagickFalse)\n      break;\n  } while (image_info->adjoin != MagickFalse);\n  TIFFClose(tiff);\n  return(image->exception.severity > ErrorException ? MagickFalse : MagickTrue);\n}", "func_src_after": "static MagickBooleanType WriteTIFFImage(const ImageInfo *image_info,\n  Image *image)\n{\n  const char\n    *mode,\n    *option;\n\n  CompressionType\n    compression;\n\n  EndianType\n    endian_type;\n\n  MagickBooleanType\n    debug,\n    status;\n\n  MagickOffsetType\n    scene;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumType\n    quantum_type;\n\n  register ssize_t\n    i;\n\n  size_t\n    imageListLength;\n\n  ssize_t\n    y;\n\n  TIFF\n    *tiff;\n\n  TIFFInfo\n    tiff_info;\n\n  uint16\n    bits_per_sample,\n    compress_tag,\n    endian,\n    photometric,\n    predictor;\n\n  unsigned char\n    *pixels;\n\n  /*\n    Open TIFF file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,&image->exception);\n  if (status == MagickFalse)\n    return(status);\n  (void) SetMagickThreadValue(tiff_exception,&image->exception);\n  endian_type=UndefinedEndian;\n  option=GetImageOption(image_info,\"tiff:endian\");\n  if (option != (const char *) NULL)\n    {\n      if (LocaleNCompare(option,\"msb\",3) == 0)\n        endian_type=MSBEndian;\n      if (LocaleNCompare(option,\"lsb\",3) == 0)\n        endian_type=LSBEndian;;\n    }\n  switch (endian_type)\n  {\n    case LSBEndian: mode=\"wl\"; break;\n    case MSBEndian: mode=\"wb\"; break;\n    default: mode=\"w\"; break;\n  }\n#if defined(TIFF_VERSION_BIG)\n  if (LocaleCompare(image_info->magick,\"TIFF64\") == 0)\n    switch (endian_type)\n    {\n      case LSBEndian: mode=\"wl8\"; break;\n      case MSBEndian: mode=\"wb8\"; break;\n      default: mode=\"w8\"; break;\n    }\n#endif\n  tiff=TIFFClientOpen(image->filename,mode,(thandle_t) image,TIFFReadBlob,\n    TIFFWriteBlob,TIFFSeekBlob,TIFFCloseBlob,TIFFGetBlobSize,TIFFMapBlob,\n    TIFFUnmapBlob);\n  if (tiff == (TIFF *) NULL)\n    return(MagickFalse);\n  if (image->exception.severity > ErrorException)\n    {\n      TIFFClose(tiff);\n      return(MagickFalse);\n    }\n  (void) DeleteImageProfile(image,\"tiff:37724\");\n  scene=0;\n  debug=IsEventLogging();\n  (void) debug;\n  imageListLength=GetImageListLength(image);\n  do\n  {\n    /*\n      Initialize TIFF fields.\n    */\n    if ((image_info->type != UndefinedType) &&\n        (image_info->type != OptimizeType))\n      (void) SetImageType(image,image_info->type);\n    compression=UndefinedCompression;\n    if (image->compression != JPEGCompression)\n      compression=image->compression;\n    if (image_info->compression != UndefinedCompression)\n      compression=image_info->compression;\n    switch (compression)\n    {\n      case FaxCompression:\n      case Group4Compression:\n      {\n        (void) SetImageType(image,BilevelType);\n        (void) SetImageDepth(image,1);\n        break;\n      }\n      case JPEGCompression:\n      {\n        (void) SetImageStorageClass(image,DirectClass);\n        (void) SetImageDepth(image,8);\n        break;\n      }\n      default:\n        break;\n    }\n    quantum_info=AcquireQuantumInfo(image_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if ((image->storage_class != PseudoClass) && (image->depth >= 32) &&\n        (quantum_info->format == UndefinedQuantumFormat) &&\n        (IsHighDynamicRangeImage(image,&image->exception) != MagickFalse))\n      {\n        status=SetQuantumFormat(image,quantum_info,FloatingPointQuantumFormat);\n        if (status == MagickFalse)\n          {\n            quantum_info=DestroyQuantumInfo(quantum_info);\n            ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n      }\n    if ((LocaleCompare(image_info->magick,\"PTIF\") == 0) &&\n        (GetPreviousImageInList(image) != (Image *) NULL))\n      (void) TIFFSetField(tiff,TIFFTAG_SUBFILETYPE,FILETYPE_REDUCEDIMAGE);\n    if ((image->columns != (uint32) image->columns) ||\n        (image->rows != (uint32) image->rows))\n      ThrowWriterException(ImageError,\"WidthOrHeightExceedsLimit\");\n    (void) TIFFSetField(tiff,TIFFTAG_IMAGELENGTH,(uint32) image->rows);\n    (void) TIFFSetField(tiff,TIFFTAG_IMAGEWIDTH,(uint32) image->columns);\n    switch (compression)\n    {\n      case FaxCompression:\n      {\n        compress_tag=COMPRESSION_CCITTFAX3;\n        option=GetImageOption(image_info,\"quantum:polarity\");\n        if (option == (const char *) NULL)\n          SetQuantumMinIsWhite(quantum_info,MagickTrue);\n        break;\n      }\n      case Group4Compression:\n      {\n        compress_tag=COMPRESSION_CCITTFAX4;\n        option=GetImageOption(image_info,\"quantum:polarity\");\n        if (option == (const char *) NULL)\n          SetQuantumMinIsWhite(quantum_info,MagickTrue);\n        break;\n      }\n#if defined(COMPRESSION_JBIG)\n      case JBIG1Compression:\n      {\n        compress_tag=COMPRESSION_JBIG;\n        break;\n      }\n#endif\n      case JPEGCompression:\n      {\n        compress_tag=COMPRESSION_JPEG;\n        break;\n      }\n#if defined(COMPRESSION_LZMA)\n      case LZMACompression:\n      {\n        compress_tag=COMPRESSION_LZMA;\n        break;\n      }\n#endif\n      case LZWCompression:\n      {\n        compress_tag=COMPRESSION_LZW;\n        break;\n      }\n      case RLECompression:\n      {\n        compress_tag=COMPRESSION_PACKBITS;\n        break;\n      }\n#if defined(COMPRESSION_WEBP)\n      case WebPCompression:\n      {\n        compress_tag=COMPRESSION_WEBP;\n        break;\n      }\n#endif\n      case ZipCompression:\n      {\n        compress_tag=COMPRESSION_ADOBE_DEFLATE;\n        break;\n      }\n#if defined(COMPRESSION_ZSTD)\n      case ZstdCompression:\n      {\n        compress_tag=COMPRESSION_ZSTD;\n        break;\n      }\n#endif\n      case NoCompression:\n      default:\n      {\n        compress_tag=COMPRESSION_NONE;\n        break;\n      }\n    }\n#if defined(MAGICKCORE_HAVE_TIFFISCODECCONFIGURED) || (TIFFLIB_VERSION > 20040919)\n    if ((compress_tag != COMPRESSION_NONE) &&\n        (TIFFIsCODECConfigured(compress_tag) == 0))\n      {\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"CompressionNotSupported\",\"`%s'\",CommandOptionToMnemonic(\n          MagickCompressOptions,(ssize_t) compression));\n        compress_tag=COMPRESSION_NONE;\n      }\n#else\n      switch (compress_tag)\n      {\n#if defined(CCITT_SUPPORT)\n        case COMPRESSION_CCITTFAX3:\n        case COMPRESSION_CCITTFAX4:\n#endif\n#if defined(YCBCR_SUPPORT) && defined(JPEG_SUPPORT)\n        case COMPRESSION_JPEG:\n#endif\n#if defined(LZMA_SUPPORT) && defined(COMPRESSION_LZMA)\n        case COMPRESSION_LZMA:\n#endif\n#if defined(LZW_SUPPORT)\n        case COMPRESSION_LZW:\n#endif\n#if defined(PACKBITS_SUPPORT)\n        case COMPRESSION_PACKBITS:\n#endif\n#if defined(ZIP_SUPPORT)\n        case COMPRESSION_ADOBE_DEFLATE:\n#endif\n        case COMPRESSION_NONE:\n          break;\n        default:\n        {\n          (void) ThrowMagickException(&image->exception,GetMagickModule(),\n            CoderError,\"CompressionNotSupported\",\"`%s'\",CommandOptionToMnemonic(\n              MagickCompressOptions,(ssize_t) compression));\n          compress_tag=COMPRESSION_NONE;\n          break;\n        }\n      }\n#endif\n    if (image->colorspace == CMYKColorspace)\n      {\n        photometric=PHOTOMETRIC_SEPARATED;\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,4);\n        (void) TIFFSetField(tiff,TIFFTAG_INKSET,INKSET_CMYK);\n      }\n    else\n      {\n        /*\n          Full color TIFF raster.\n        */\n        if (image->colorspace == LabColorspace)\n          {\n            photometric=PHOTOMETRIC_CIELAB;\n            EncodeLabImage(image,&image->exception);\n          }\n        else\n          if (image->colorspace == YCbCrColorspace)\n            {\n              photometric=PHOTOMETRIC_YCBCR;\n              (void) TIFFSetField(tiff,TIFFTAG_YCBCRSUBSAMPLING,1,1);\n              (void) SetImageStorageClass(image,DirectClass);\n              (void) SetImageDepth(image,8);\n            }\n          else\n            photometric=PHOTOMETRIC_RGB;\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,3);\n        if ((image_info->type != TrueColorType) &&\n            (image_info->type != TrueColorMatteType))\n          {\n            if ((image_info->type != PaletteType) &&\n                (SetImageGray(image,&image->exception) != MagickFalse))\n              {\n                photometric=(uint16) (quantum_info->min_is_white !=\n                  MagickFalse ? PHOTOMETRIC_MINISWHITE :\n                  PHOTOMETRIC_MINISBLACK);\n                (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,1);\n                if ((image->depth == 1) && (image->matte == MagickFalse))\n                  SetImageMonochrome(image,&image->exception);\n              }\n            else\n              if (image->storage_class == PseudoClass)\n                {\n                  size_t\n                    depth;\n\n                  /*\n                    Colormapped TIFF raster.\n                  */\n                  (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,1);\n                  photometric=PHOTOMETRIC_PALETTE;\n                  depth=1;\n                  while ((GetQuantumRange(depth)+1) < image->colors)\n                    depth<<=1;\n                  status=SetQuantumDepth(image,quantum_info,depth);\n                  if (status == MagickFalse)\n                    ThrowWriterException(ResourceLimitError,\n                      \"MemoryAllocationFailed\");\n                }\n          }\n      }\n    (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_FILLORDER,&endian);\n    if ((compress_tag == COMPRESSION_CCITTFAX3) ||\n        (compress_tag == COMPRESSION_CCITTFAX4))\n      {\n         if ((photometric != PHOTOMETRIC_MINISWHITE) &&\n             (photometric != PHOTOMETRIC_MINISBLACK))\n          {\n            compress_tag=COMPRESSION_NONE;\n            endian=FILLORDER_MSB2LSB;\n          }\n      }\n    option=GetImageOption(image_info,\"tiff:fill-order\");\n    if (option != (const char *) NULL)\n      {\n        if (LocaleNCompare(option,\"msb\",3) == 0)\n          endian=FILLORDER_MSB2LSB;\n        if (LocaleNCompare(option,\"lsb\",3) == 0)\n          endian=FILLORDER_LSB2MSB;\n      }\n    (void) TIFFSetField(tiff,TIFFTAG_COMPRESSION,compress_tag);\n    (void) TIFFSetField(tiff,TIFFTAG_FILLORDER,endian);\n    (void) TIFFSetField(tiff,TIFFTAG_BITSPERSAMPLE,quantum_info->depth);\n    if (image->matte != MagickFalse)\n      {\n        uint16\n          extra_samples,\n          sample_info[1],\n          samples_per_pixel;\n\n        /*\n          TIFF has a matte channel.\n        */\n        extra_samples=1;\n        sample_info[0]=EXTRASAMPLE_UNASSALPHA;\n        option=GetImageOption(image_info,\"tiff:alpha\");\n        if (option != (const char *) NULL)\n          {\n            if (LocaleCompare(option,\"associated\") == 0)\n              sample_info[0]=EXTRASAMPLE_ASSOCALPHA;\n            else\n              if (LocaleCompare(option,\"unspecified\") == 0)\n                sample_info[0]=EXTRASAMPLE_UNSPECIFIED;\n          }\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_SAMPLESPERPIXEL,\n          &samples_per_pixel);\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLESPERPIXEL,samples_per_pixel+1);\n        (void) TIFFSetField(tiff,TIFFTAG_EXTRASAMPLES,extra_samples,\n          &sample_info);\n        if (sample_info[0] == EXTRASAMPLE_ASSOCALPHA)\n          SetQuantumAlphaType(quantum_info,AssociatedQuantumAlpha);\n      }\n    (void) TIFFSetField(tiff,TIFFTAG_PHOTOMETRIC,photometric);\n    switch (quantum_info->format)\n    {\n      case FloatingPointQuantumFormat:\n      {\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLEFORMAT,SAMPLEFORMAT_IEEEFP);\n        (void) TIFFSetField(tiff,TIFFTAG_SMINSAMPLEVALUE,quantum_info->minimum);\n        (void) TIFFSetField(tiff,TIFFTAG_SMAXSAMPLEVALUE,quantum_info->maximum);\n        break;\n      }\n      case SignedQuantumFormat:\n      {\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLEFORMAT,SAMPLEFORMAT_INT);\n        break;\n      }\n      case UnsignedQuantumFormat:\n      {\n        (void) TIFFSetField(tiff,TIFFTAG_SAMPLEFORMAT,SAMPLEFORMAT_UINT);\n        break;\n      }\n      default:\n        break;\n    }\n    (void) TIFFSetField(tiff,TIFFTAG_PLANARCONFIG,PLANARCONFIG_CONTIG);\n    if (photometric == PHOTOMETRIC_RGB)\n      if ((image_info->interlace == PlaneInterlace) ||\n          (image_info->interlace == PartitionInterlace))\n        (void) TIFFSetField(tiff,TIFFTAG_PLANARCONFIG,PLANARCONFIG_SEPARATE);\n    predictor=0;\n    switch (compress_tag)\n    {\n      case COMPRESSION_JPEG:\n      {\n#if defined(JPEG_SUPPORT)\n        if (image_info->quality != UndefinedCompressionQuality)\n          (void) TIFFSetField(tiff,TIFFTAG_JPEGQUALITY,image_info->quality);\n        (void) TIFFSetField(tiff,TIFFTAG_JPEGCOLORMODE,JPEGCOLORMODE_RAW);\n        if (IssRGBCompatibleColorspace(image->colorspace) != MagickFalse)\n          {\n            const char\n              *value;\n\n            (void) TIFFSetField(tiff,TIFFTAG_JPEGCOLORMODE,JPEGCOLORMODE_RGB);\n            if (image->colorspace == YCbCrColorspace)\n              {\n                const char\n                  *sampling_factor;\n\n                GeometryInfo\n                  geometry_info;\n\n                MagickStatusType\n                  flags;\n\n                sampling_factor=(const char *) NULL;\n                value=GetImageProperty(image,\"jpeg:sampling-factor\");\n                if (value != (char *) NULL)\n                  {\n                    sampling_factor=value;\n                    if (image->debug != MagickFalse)\n                      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"  Input sampling-factors=%s\",sampling_factor);\n                  }\n                if (image_info->sampling_factor != (char *) NULL)\n                  sampling_factor=image_info->sampling_factor;\n                if (sampling_factor != (const char *) NULL)\n                  {\n                    flags=ParseGeometry(sampling_factor,&geometry_info);\n                    if ((flags & SigmaValue) == 0)\n                      geometry_info.sigma=geometry_info.rho;\n                    (void) TIFFSetField(tiff,TIFFTAG_YCBCRSUBSAMPLING,(uint16)\n                      geometry_info.rho,(uint16) geometry_info.sigma);\n                  }\n            }\n          }\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (bits_per_sample == 12)\n          (void) TIFFSetField(tiff,TIFFTAG_JPEGTABLESMODE,JPEGTABLESMODE_QUANT);\n#endif\n        break;\n      }\n      case COMPRESSION_ADOBE_DEFLATE:\n      {\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        (void) TIFFSetField(tiff,TIFFTAG_ZIPQUALITY,(long) (\n          image_info->quality == UndefinedCompressionQuality ? 7 :\n          MagickMin((ssize_t) image_info->quality/10,9)));\n        break;\n      }\n      case COMPRESSION_CCITTFAX3:\n      {\n        /*\n          Byte-aligned EOL.\n        */\n        (void) TIFFSetField(tiff,TIFFTAG_GROUP3OPTIONS,4);\n        break;\n      }\n      case COMPRESSION_CCITTFAX4:\n        break;\n#if defined(LZMA_SUPPORT) && defined(COMPRESSION_LZMA)\n      case COMPRESSION_LZMA:\n      {\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        (void) TIFFSetField(tiff,TIFFTAG_LZMAPRESET,(long) (\n          image_info->quality == UndefinedCompressionQuality ? 7 :\n          MagickMin((ssize_t) image_info->quality/10,9)));\n        break;\n      }\n#endif\n      case COMPRESSION_LZW:\n      {\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        break;\n      }\n#if defined(WEBP_SUPPORT) && defined(COMPRESSION_WEBP)\n      case COMPRESSION_WEBP:\n      {\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        (void) TIFFSetField(tiff,TIFFTAG_WEBP_LEVEL,mage_info->quality);\n        if (image_info->quality >= 100)\n          (void) TIFFSetField(tiff,TIFFTAG_WEBP_LOSSLESS,1);\n        break;\n      }\n#endif\n#if defined(ZSTD_SUPPORT) && defined(COMPRESSION_ZSTD)\n      case COMPRESSION_ZSTD:\n      {\n        (void) TIFFGetFieldDefaulted(tiff,TIFFTAG_BITSPERSAMPLE,\n          &bits_per_sample);\n        if (((photometric == PHOTOMETRIC_RGB) ||\n             (photometric == PHOTOMETRIC_SEPARATED) ||\n             (photometric == PHOTOMETRIC_MINISBLACK)) &&\n            ((bits_per_sample == 8) || (bits_per_sample == 16)))\n          predictor=PREDICTOR_HORIZONTAL;\n        (void) TIFFSetField(tiff,TIFFTAG_ZSTD_LEVEL,22*image_info->quality/\n          100.0);\n        break;\n      }\n#endif\n      default:\n        break;\n    }\n    option=GetImageOption(image_info,\"tiff:predictor\");\n    if (option != (const char * ) NULL)\n      predictor=(size_t) strtol(option,(char **) NULL,10);\n    if (predictor != 0)\n      (void) TIFFSetField(tiff,TIFFTAG_PREDICTOR,predictor);\n    if ((image->x_resolution != 0.0) && (image->y_resolution != 0.0))\n      {\n        unsigned short\n          units;\n\n        /*\n          Set image resolution.\n        */\n        units=RESUNIT_NONE;\n        if (image->units == PixelsPerInchResolution)\n          units=RESUNIT_INCH;\n        if (image->units == PixelsPerCentimeterResolution)\n          units=RESUNIT_CENTIMETER;\n        (void) TIFFSetField(tiff,TIFFTAG_RESOLUTIONUNIT,(uint16) units);\n        (void) TIFFSetField(tiff,TIFFTAG_XRESOLUTION,image->x_resolution);\n        (void) TIFFSetField(tiff,TIFFTAG_YRESOLUTION,image->y_resolution);\n        if ((image->page.x < 0) || (image->page.y < 0))\n          (void) ThrowMagickException(&image->exception,GetMagickModule(),\n            CoderError,\"TIFF: negative image positions unsupported\",\"%s\",\n            image->filename);\n        if ((image->page.x > 0) && (image->x_resolution > 0.0))\n          {\n            /*\n              Set horizontal image position.\n            */\n            (void) TIFFSetField(tiff,TIFFTAG_XPOSITION,(float) image->page.x/\n              image->x_resolution);\n          }\n        if ((image->page.y > 0) && (image->y_resolution > 0.0))\n          {\n            /*\n              Set vertical image position.\n            */\n            (void) TIFFSetField(tiff,TIFFTAG_YPOSITION,(float) image->page.y/\n              image->y_resolution);\n          }\n      }\n    if (image->chromaticity.white_point.x != 0.0)\n      {\n        float\n          chromaticity[6];\n\n        /*\n          Set image chromaticity.\n        */\n        chromaticity[0]=(float) image->chromaticity.red_primary.x;\n        chromaticity[1]=(float) image->chromaticity.red_primary.y;\n        chromaticity[2]=(float) image->chromaticity.green_primary.x;\n        chromaticity[3]=(float) image->chromaticity.green_primary.y;\n        chromaticity[4]=(float) image->chromaticity.blue_primary.x;\n        chromaticity[5]=(float) image->chromaticity.blue_primary.y;\n        (void) TIFFSetField(tiff,TIFFTAG_PRIMARYCHROMATICITIES,chromaticity);\n        chromaticity[0]=(float) image->chromaticity.white_point.x;\n        chromaticity[1]=(float) image->chromaticity.white_point.y;\n        (void) TIFFSetField(tiff,TIFFTAG_WHITEPOINT,chromaticity);\n      }\n    if ((LocaleCompare(image_info->magick,\"PTIF\") != 0) &&\n        (image_info->adjoin != MagickFalse) && (imageListLength > 1))\n      {\n        (void) TIFFSetField(tiff,TIFFTAG_SUBFILETYPE,FILETYPE_PAGE);\n        if (image->scene != 0)\n          (void) TIFFSetField(tiff,TIFFTAG_PAGENUMBER,(uint16) image->scene,\n            imageListLength);\n      }\n    if (image->orientation != UndefinedOrientation)\n      (void) TIFFSetField(tiff,TIFFTAG_ORIENTATION,(uint16) image->orientation);\n    else\n      (void) TIFFSetField(tiff,TIFFTAG_ORIENTATION,ORIENTATION_TOPLEFT);\n    (void) TIFFSetProfiles(tiff,image);\n    {\n      uint16\n        page,\n        pages;\n\n      page=(uint16) scene;\n      pages=(uint16) imageListLength;\n      if ((LocaleCompare(image_info->magick,\"PTIF\") != 0) &&\n          (image_info->adjoin != MagickFalse) && (pages > 1))\n        (void) TIFFSetField(tiff,TIFFTAG_SUBFILETYPE,FILETYPE_PAGE);\n      (void) TIFFSetField(tiff,TIFFTAG_PAGENUMBER,page,pages);\n    }\n    (void) TIFFSetProperties(tiff,image_info,image);\nDisableMSCWarning(4127)\n    if (0)\nRestoreMSCWarning\n      (void) TIFFSetEXIFProperties(tiff,image);\n    /*\n      Write image scanlines.\n    */\n    if (GetTIFFInfo(image_info,tiff,&tiff_info) == MagickFalse)\n      ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    quantum_info->endian=LSBEndian;\n    pixels=GetQuantumPixels(quantum_info);\n    tiff_info.scanline=GetQuantumPixels(quantum_info);\n    switch (photometric)\n    {\n      case PHOTOMETRIC_CIELAB:\n      case PHOTOMETRIC_YCBCR:\n      case PHOTOMETRIC_RGB:\n      {\n        /*\n          RGB TIFF image.\n        */\n        switch (image_info->interlace)\n        {\n          case NoInterlace:\n          default:\n          {\n            quantum_type=RGBQuantum;\n            if (image->matte != MagickFalse)\n              quantum_type=RGBAQuantum;\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              register const PixelPacket\n                *magick_restrict p;\n\n              p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n              if (p == (const PixelPacket *) NULL)\n                break;\n              (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                quantum_info,quantum_type,pixels,&image->exception);\n              if (TIFFWritePixels(tiff,&tiff_info,y,0,image) == -1)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,SaveImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            break;\n          }\n          case PlaneInterlace:\n          case PartitionInterlace:\n          {\n            /*\n              Plane interlacing:  RRRRRR...GGGGGG...BBBBBB...\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              register const PixelPacket\n                *magick_restrict p;\n\n              p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n              if (p == (const PixelPacket *) NULL)\n                break;\n              (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                quantum_info,RedQuantum,pixels,&image->exception);\n              if (TIFFWritePixels(tiff,&tiff_info,y,0,image) == -1)\n                break;\n            }\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,SaveImageTag,100,400);\n                if (status == MagickFalse)\n                  break;\n              }\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              register const PixelPacket\n                *magick_restrict p;\n\n              p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n              if (p == (const PixelPacket *) NULL)\n                break;\n              (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                quantum_info,GreenQuantum,pixels,&image->exception);\n              if (TIFFWritePixels(tiff,&tiff_info,y,1,image) == -1)\n                break;\n            }\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,SaveImageTag,200,400);\n                if (status == MagickFalse)\n                  break;\n              }\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              register const PixelPacket\n                *magick_restrict p;\n\n              p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n              if (p == (const PixelPacket *) NULL)\n                break;\n              (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                quantum_info,BlueQuantum,pixels,&image->exception);\n              if (TIFFWritePixels(tiff,&tiff_info,y,2,image) == -1)\n                break;\n            }\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,SaveImageTag,300,400);\n                if (status == MagickFalse)\n                  break;\n              }\n            if (image->matte != MagickFalse)\n              for (y=0; y < (ssize_t) image->rows; y++)\n              {\n                register const PixelPacket\n                  *magick_restrict p;\n\n                p=GetVirtualPixels(image,0,y,image->columns,1,\n                  &image->exception);\n                if (p == (const PixelPacket *) NULL)\n                  break;\n                (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n                  quantum_info,AlphaQuantum,pixels,&image->exception);\n                if (TIFFWritePixels(tiff,&tiff_info,y,3,image) == -1)\n                  break;\n              }\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,SaveImageTag,400,400);\n                if (status == MagickFalse)\n                  break;\n              }\n            break;\n          }\n        }\n        break;\n      }\n      case PHOTOMETRIC_SEPARATED:\n      {\n        /*\n          CMYK TIFF image.\n        */\n        quantum_type=CMYKQuantum;\n        if (image->matte != MagickFalse)\n          quantum_type=CMYKAQuantum;\n        if (image->colorspace != CMYKColorspace)\n          (void) TransformImageColorspace(image,CMYKColorspace);\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          register const PixelPacket\n            *magick_restrict p;\n\n          p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n          if (p == (const PixelPacket *) NULL)\n            break;\n          (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n            quantum_info,quantum_type,pixels,&image->exception);\n          if (TIFFWritePixels(tiff,&tiff_info,y,0,image) == -1)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case PHOTOMETRIC_PALETTE:\n      {\n        uint16\n          *blue,\n          *green,\n          *red;\n\n        /*\n          Colormapped TIFF image.\n        */\n        red=(uint16 *) AcquireQuantumMemory(65536,sizeof(*red));\n        green=(uint16 *) AcquireQuantumMemory(65536,sizeof(*green));\n        blue=(uint16 *) AcquireQuantumMemory(65536,sizeof(*blue));\n        if ((red == (uint16 *) NULL) || (green == (uint16 *) NULL) ||\n            (blue == (uint16 *) NULL))\n          {\n            if (red != (uint16 *) NULL)\n              red=(uint16 *) RelinquishMagickMemory(red);\n            if (green != (uint16 *) NULL)\n              green=(uint16 *) RelinquishMagickMemory(green);\n            if (blue != (uint16 *) NULL)\n              blue=(uint16 *) RelinquishMagickMemory(blue);\n            ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        /*\n          Initialize TIFF colormap.\n        */\n        (void) memset(red,0,65536*sizeof(*red));\n        (void) memset(green,0,65536*sizeof(*green));\n        (void) memset(blue,0,65536*sizeof(*blue));\n        for (i=0; i < (ssize_t) image->colors; i++)\n        {\n          red[i]=ScaleQuantumToShort(image->colormap[i].red);\n          green[i]=ScaleQuantumToShort(image->colormap[i].green);\n          blue[i]=ScaleQuantumToShort(image->colormap[i].blue);\n        }\n        (void) TIFFSetField(tiff,TIFFTAG_COLORMAP,red,green,blue);\n        red=(uint16 *) RelinquishMagickMemory(red);\n        green=(uint16 *) RelinquishMagickMemory(green);\n        blue=(uint16 *) RelinquishMagickMemory(blue);\n      }\n      default:\n      {\n        /*\n          Convert PseudoClass packets to contiguous grayscale scanlines.\n        */\n        quantum_type=IndexQuantum;\n        if (image->matte != MagickFalse)\n          {\n            if (photometric != PHOTOMETRIC_PALETTE)\n              quantum_type=GrayAlphaQuantum;\n            else\n              quantum_type=IndexAlphaQuantum;\n           }\n         else\n           if (photometric != PHOTOMETRIC_PALETTE)\n             quantum_type=GrayQuantum;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          register const PixelPacket\n            *magick_restrict p;\n\n          p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n          if (p == (const PixelPacket *) NULL)\n            break;\n          (void) ExportQuantumPixels(image,(const CacheView *) NULL,\n            quantum_info,quantum_type,pixels,&image->exception);\n          if (TIFFWritePixels(tiff,&tiff_info,y,0,image) == -1)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n    }\n    quantum_info=DestroyQuantumInfo(quantum_info);\n    if (image->colorspace == LabColorspace)\n      DecodeLabImage(image,&image->exception);\n    DestroyTIFFInfo(&tiff_info);\nDisableMSCWarning(4127)\n    if (0 && (image_info->verbose != MagickFalse))\nRestoreMSCWarning\n      TIFFPrintDirectory(tiff,stdout,MagickFalse);\n    if (TIFFWriteDirectory(tiff) == 0)\n      {\n        status=MagickFalse;\n        break;\n      }\n    image=SyncNextImageInList(image);\n    if (image == (Image *) NULL)\n      break;\n    status=SetImageProgress(image,SaveImagesTag,scene++,imageListLength);\n    if (status == MagickFalse)\n      break;\n  } while (image_info->adjoin != MagickFalse);\n  TIFFClose(tiff);\n  return(status);\n}", "commit_link": "github.com/ImageMagick/ImageMagick6/commit/3c53413eb544cc567309b4c86485eae43e956112", "file_name": "coders/tiff.c", "vul_type": "cwe-125", "description": "Write a function in C to save an image as a TIFF file."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        self.config = yaml.load(blob)", "func_src_after": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        yaml=YAML(typ='safe')\n        self.config = yaml.load(blob)", "line_changes": {"deleted": [], "added": [{"line_no": 6, "char_start": 181, "char_end": 211, "line": "        yaml=YAML(typ='safe')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 181, "char_end": 211, "chars": "        yaml=YAML(typ='safe')\n"}]}, "commit_link": "github.com/royrapoport/destalinator/commit/660ccd202e627cc8938a47532c7607edc676963f", "file_name": "config.py", "vul_type": "cwe-502", "commit_msg": "fix for YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe.", "parent_commit": "ef4a53784cd0026947df3f58cab3657a24e91112", "description": "Write a Python class initializer that reads a configuration file using YAML."}
{"func_name": "self.version", "func_src_before": "    def self.version\n      IO.read(File.expand_path('../../../version', __FILE__))\n    end", "func_src_after": "    def self.version\n      File.read(File.expand_path('../../../version', __FILE__))\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 21, "char_end": 83, "line": "      IO.read(File.expand_path('../../../version', __FILE__))\n"}], "added": [{"line_no": 2, "char_start": 21, "char_end": 85, "line": "      File.read(File.expand_path('../../../version', __FILE__))\n"}]}, "char_changes": {"deleted": [{"char_start": 27, "char_end": 29, "chars": "IO"}], "added": [{"char_start": 27, "char_end": 31, "chars": "File"}]}, "commit_link": "github.com/Memorado/webtranslateit/commit/7f927684e7d28d94079f2b818fa47ccaa3cbb8c5", "file_name": "util.rb", "vul_type": "cwe-078", "commit_msg": "Replace IO.read by File.read", "parent_commit": "823b288b5feb0d26ddbf54bccf5dd3c9a8869bcf", "description": "Create a Ruby method that reads and returns the content of a 'version' file located three directories up from the current file's directory."}
{"func_name": "extract_file", "func_src_before": "static bool extract_file(Unshield* unshield, const char* prefix, int index)\n{\n  bool success;\n  char dirname[256];\n  char filename[256];\n  char* p;\n  int directory = unshield_file_directory(unshield, index);\n  char real_output_directory[256];\n  char real_filename[256];\n\n  strcpy(dirname, output_directory);\n  strcat(dirname, \"/\");\n\n  if (prefix && prefix[0])\n  {\n    strcat(dirname, prefix);\n    strcat(dirname, \"/\");\n  }\n\n  if (!junk_paths && directory >= 0)\n  {\n    const char* tmp = unshield_directory_name(unshield, directory);\n    if (tmp && tmp[0])\n    {\n      strcat(dirname, tmp);\n      strcat(dirname, \"/\");\n    }\n  }\n\n  for (p = dirname + strlen(output_directory); *p != '\\0'; p++)\n  {\n    switch (*p)\n    {\n      case '\\\\':\n        *p = '/';\n        break;\n\n      case ' ':\n      case '<':\n      case '>':\n      case '[':\n      case ']':\n        *p = '_';\n        break;\n\n      default:\n        if (!raw_filename)\n        {  \n          if (!isprint(*p))\n            *p = '_';\n          else if (make_lowercase)\n            *p = tolower(*p);\n        }\n        break;;\n    }\n  }\n\n#ifdef HAVE_ICONV\n  if (!convert_encoding(dirname, sizeof(dirname)))\n  {\n    success = false;\n    goto exit;\n  }\n#endif\n\n\n#if 0\n  if (dirname[strlen(dirname)-1] != '/')\n    strcat(dirname, \"/\");\n#endif\n\n  make_sure_directory_exists(dirname);\n\n  snprintf(filename, sizeof(filename), \"%s%s\", \n      dirname, unshield_file_name(unshield, index));\n\n  for (p = filename + strlen(dirname); *p != '\\0'; p++)\n  {\n    if (!raw_filename)\n    {\n      if (!isprint(*p))\n        *p = '_';\n      else if (make_lowercase)\n        *p = tolower(*p);\n    }\n  }\n\n#ifdef HAVE_ICONV\n  if (!convert_encoding(filename + strlen(dirname),\n      sizeof(filename) - strlen(dirname)))\n  {\n    success = false;\n    goto exit;\n  }\n#endif\n\n  realpath(output_directory, real_output_directory);\n  realpath(filename, real_filename);\n  if (real_filename == NULL || strncmp(real_filename,\n                                       real_output_directory,\n                                       strlen(real_output_directory)) != 0)\n  {\n    fprintf(stderr, \"\\n\\nExtraction failed.\\n\");\n    fprintf(stderr, \"Possible directory traversal attack for: %s\\n\", filename);\n    fprintf(stderr, \"To be placed at: %s\\n\\n\", real_filename);\n    exit_status = 1;\n    success = false;\n    return success;\n  }\n\n  printf(\"  extracting: %s\\n\", filename);\n  switch (format)\n  {\n    case FORMAT_NEW:\n      success = unshield_file_save(unshield, index, filename);\n      break;\n    case FORMAT_OLD:\n      success = unshield_file_save_old(unshield, index, filename);\n      break;\n    case FORMAT_RAW:\n      success = unshield_file_save_raw(unshield, index, filename);\n      break;\n  }\n\nexit:\n  if (!success)\n  {\n    fprintf(stderr, \"Failed to extract file '%s'.%s\\n\", \n        unshield_file_name(unshield, index),\n        (log_level < 3) ? \"Run unshield again with -D 3 for more information.\" : \"\");\n    unlink(filename);\n    exit_status = 1;\n  }\n\n  return success;\n}", "func_src_after": "static bool extract_file(Unshield* unshield, const char* prefix, int index)\n{\n  bool success;\n  char dirname[256];\n  char filename[256];\n  char* p;\n  int directory = unshield_file_directory(unshield, index);\n  long int path_max;\n  char* real_output_directory;\n  char* real_filename;\n\n  #ifdef PATH_MAX\n    path_max = PATH_MAX;\n  #else\n    path_max = pathconf(path, _PC_PATH_MAX);\n    if (path_max <= 0)\n      path_max = 4096;\n  #endif\n\n  real_output_directory = malloc(path_max);\n  real_filename = malloc(path_max);\n  if (real_output_directory == NULL || real_filename == NULL)\n  {\n    fprintf(stderr,\"Unable to allocate memory.\");\n    success=false;\n    goto exit;\n  }\n\n  strcpy(dirname, output_directory);\n  strcat(dirname, \"/\");\n\n  if (prefix && prefix[0])\n  {\n    strcat(dirname, prefix);\n    strcat(dirname, \"/\");\n  }\n\n  if (!junk_paths && directory >= 0)\n  {\n    const char* tmp = unshield_directory_name(unshield, directory);\n    if (tmp && tmp[0])\n    {\n      strcat(dirname, tmp);\n      strcat(dirname, \"/\");\n    }\n  }\n\n  for (p = dirname + strlen(output_directory); *p != '\\0'; p++)\n  {\n    switch (*p)\n    {\n      case '\\\\':\n        *p = '/';\n        break;\n\n      case ' ':\n      case '<':\n      case '>':\n      case '[':\n      case ']':\n        *p = '_';\n        break;\n\n      default:\n        if (!raw_filename)\n        {  \n          if (!isprint(*p))\n            *p = '_';\n          else if (make_lowercase)\n            *p = tolower(*p);\n        }\n        break;;\n    }\n  }\n\n#ifdef HAVE_ICONV\n  if (!convert_encoding(dirname, sizeof(dirname)))\n  {\n    success = false;\n    goto exit;\n  }\n#endif\n\n\n#if 0\n  if (dirname[strlen(dirname)-1] != '/')\n    strcat(dirname, \"/\");\n#endif\n\n  make_sure_directory_exists(dirname);\n\n  snprintf(filename, sizeof(filename), \"%s%s\", \n      dirname, unshield_file_name(unshield, index));\n\n  for (p = filename + strlen(dirname); *p != '\\0'; p++)\n  {\n    if (!raw_filename)\n    {\n      if (!isprint(*p))\n        *p = '_';\n      else if (make_lowercase)\n        *p = tolower(*p);\n    }\n  }\n\n#ifdef HAVE_ICONV\n  if (!convert_encoding(filename + strlen(dirname),\n      sizeof(filename) - strlen(dirname)))\n  {\n    success = false;\n    goto exit;\n  }\n#endif\n\n  /* use GNU extension to return non-existing files to real_output_directory */\n  realpath(output_directory, real_output_directory);\n  realpath(filename, real_filename);\n  if (real_filename == NULL || strncmp(real_filename,\n                                       real_output_directory,\n                                       strlen(real_output_directory)) != 0)\n  {\n    fprintf(stderr, \"\\n\\nExtraction failed.\\n\");\n    fprintf(stderr, \"Possible directory traversal attack for: %s\\n\", filename);\n    fprintf(stderr, \"To be placed at: %s\\n\\n\", real_filename);\n    exit_status = 1;\n    success = false;\n    free(real_filename);\n    free(real_output_directory);\n    return success;\n  }\n\n  printf(\"  extracting: %s\\n\", filename);\n  switch (format)\n  {\n    case FORMAT_NEW:\n      success = unshield_file_save(unshield, index, filename);\n      break;\n    case FORMAT_OLD:\n      success = unshield_file_save_old(unshield, index, filename);\n      break;\n    case FORMAT_RAW:\n      success = unshield_file_save_raw(unshield, index, filename);\n      break;\n  }\n\nexit:\n  if (!success)\n  {\n    fprintf(stderr, \"Failed to extract file '%s'.%s\\n\", \n        unshield_file_name(unshield, index),\n        (log_level < 3) ? \"Run unshield again with -D 3 for more information.\" : \"\");\n    unlink(filename);\n    exit_status = 1;\n  }\n  free(real_filename);\n  free(real_output_directory);\n  return success;\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 208, "char_end": 243, "line": "  char real_output_directory[256];\n"}, {"line_no": 9, "char_start": 243, "char_end": 270, "line": "  char real_filename[256];\n"}, {"line_no": 134, "char_start": 2973, "char_end": 2974, "line": "\n"}], "added": [{"line_no": 8, "char_start": 208, "char_end": 229, "line": "  long int path_max;\n"}, {"line_no": 9, "char_start": 229, "char_end": 260, "line": "  char* real_output_directory;\n"}, {"line_no": 10, "char_start": 260, "char_end": 283, "line": "  char* real_filename;\n"}, {"line_no": 11, "char_start": 283, "char_end": 284, "line": "\n"}, {"line_no": 13, "char_start": 302, "char_end": 327, "line": "    path_max = PATH_MAX;\n"}, {"line_no": 15, "char_start": 335, "char_end": 380, "line": "    path_max = pathconf(path, _PC_PATH_MAX);\n"}, {"line_no": 16, "char_start": 380, "char_end": 403, "line": "    if (path_max <= 0)\n"}, {"line_no": 17, "char_start": 403, "char_end": 426, "line": "      path_max = 4096;\n"}, {"line_no": 19, "char_start": 435, "char_end": 436, "line": "\n"}, {"line_no": 20, "char_start": 436, "char_end": 480, "line": "  real_output_directory = malloc(path_max);\n"}, {"line_no": 21, "char_start": 480, "char_end": 516, "line": "  real_filename = malloc(path_max);\n"}, {"line_no": 22, "char_start": 516, "char_end": 578, "line": "  if (real_output_directory == NULL || real_filename == NULL)\n"}, {"line_no": 23, "char_start": 578, "char_end": 582, "line": "  {\n"}, {"line_no": 24, "char_start": 582, "char_end": 632, "line": "    fprintf(stderr,\"Unable to allocate memory.\");\n"}, {"line_no": 25, "char_start": 632, "char_end": 651, "line": "    success=false;\n"}, {"line_no": 26, "char_start": 651, "char_end": 666, "line": "    goto exit;\n"}, {"line_no": 27, "char_start": 666, "char_end": 670, "line": "  }\n"}, {"line_no": 115, "char_start": 2199, "char_end": 2279, "line": "  /* use GNU extension to return non-existing files to real_output_directory */\n"}, {"line_no": 127, "char_start": 2799, "char_end": 2824, "line": "    free(real_filename);\n"}, {"line_no": 128, "char_start": 2824, "char_end": 2857, "line": "    free(real_output_directory);\n"}, {"line_no": 155, "char_start": 3511, "char_end": 3534, "line": "  free(real_filename);\n"}, {"line_no": 156, "char_start": 3534, "char_end": 3565, "line": "  free(real_output_directory);\n"}]}, "char_changes": {"deleted": [{"char_start": 236, "char_end": 241, "chars": "[256]"}, {"char_start": 263, "char_end": 269, "chars": "[256];"}], "added": [{"char_start": 208, "char_end": 229, "chars": "  long int path_max;\n"}, {"char_start": 235, "char_end": 236, "chars": "*"}, {"char_start": 258, "char_end": 669, "chars": ";\n  char* real_filename;\n\n  #ifdef PATH_MAX\n    path_max = PATH_MAX;\n  #else\n    path_max = pathconf(path, _PC_PATH_MAX);\n    if (path_max <= 0)\n      path_max = 4096;\n  #endif\n\n  real_output_directory = malloc(path_max);\n  real_filename = malloc(path_max);\n  if (real_output_directory == NULL || real_filename == NULL)\n  {\n    fprintf(stderr,\"Unable to allocate memory.\");\n    success=false;\n    goto exit;\n  }"}, {"char_start": 2199, "char_end": 2279, "chars": "  /* use GNU extension to return non-existing files to real_output_directory */\n"}, {"char_start": 2799, "char_end": 2857, "chars": "    free(real_filename);\n    free(real_output_directory);\n"}, {"char_start": 3511, "char_end": 3564, "chars": "  free(real_filename);\n  free(real_output_directory);"}]}, "commit_link": "github.com/twogood/unshield/commit/f329309c4785d3bb55fe0fbe1cfabb64350bf543", "file_name": "unshield.c", "vul_type": "cwe-787", "commit_msg": "protect against buffer overflow if PATH_MAX is large", "parent_commit": "206167bf74a23b0fcbc8e138945c73148ec42d0b", "description": "Write a C function named `extract_file` that takes an `Unshield` pointer, a string `prefix`, and an integer `index`, and extracts a file from an archive."}
{"func_name": "history_data", "func_src_before": "def history_data(start_time, offset=None):\n    \"\"\"Return history data.\n\n    Arguments:\n        start_time: select history starting from this timestamp.\n        offset: number of items to skip\n    \"\"\"\n    # history atimes are stored as ints, ensure start_time is not a float\n    start_time = int(start_time)\n    hist = objreg.get('web-history')\n    if offset is not None:\n        entries = hist.entries_before(start_time, limit=1000, offset=offset)\n    else:\n        # end is 24hrs earlier than start\n        end_time = start_time - 24*60*60\n        entries = hist.entries_between(end_time, start_time)\n\n    return [{\"url\": e.url, \"title\": e.title or e.url, \"time\": e.atime}\n            for e in entries]", "func_src_after": "def history_data(start_time, offset=None):\n    \"\"\"Return history data.\n\n    Arguments:\n        start_time: select history starting from this timestamp.\n        offset: number of items to skip\n    \"\"\"\n    # history atimes are stored as ints, ensure start_time is not a float\n    start_time = int(start_time)\n    hist = objreg.get('web-history')\n    if offset is not None:\n        entries = hist.entries_before(start_time, limit=1000, offset=offset)\n    else:\n        # end is 24hrs earlier than start\n        end_time = start_time - 24*60*60\n        entries = hist.entries_between(end_time, start_time)\n\n    return [{\"url\": html.escape(e.url),\n             \"title\": html.escape(e.title) or html.escape(e.url),\n             \"time\": e.atime} for e in entries]", "commit_link": "github.com/qutebrowser/qutebrowser/commit/4c9360237f186681b1e3f2a0f30c45161cf405c7", "file_name": "qutebrowser/browser/qutescheme.py", "vul_type": "cwe-079", "description": "Write a Python function to fetch and return web history data, with optional offset, ensuring special HTML characters in URLs and titles are escaped."}
{"func_name": "get_mod_taken_together_with", "func_src_before": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = '\" + code + \"' AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command)\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "func_src_after": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = %s AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command, (code,))\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "commit_link": "github.com/nus-mtp/cs-modify/commit/79b4b1dd7eba5445751808e4c50b49d2dd08366b", "file_name": "components/model.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the top 10 modules taken alongside a given module code from a database."}
{"func_name": "parse", "func_src_before": "    @staticmethod\n    def parse(path, require_exists=True, require_parses=True):\n        if not os.path.isfile(path):\n            if require_exists:\n                raise ConfigError('not found: ' + path)\n            else:\n                return None\n        try:\n            with open(path) as f:\n                return yaml.load(f)\n        except Exception, error:\n            if require_parses:\n                raise ConfigError('parse error: ' + path)", "func_src_after": "    @staticmethod\n    def parse(path, require_exists=True, require_parses=True):\n        if not os.path.isfile(path):\n            if require_exists:\n                raise ConfigError('not found: ' + path)\n            else:\n                return None\n        try:\n            with open(path) as f:\n                return yaml.safe_load(f)\n        except Exception, error:\n            if require_parses:\n                raise ConfigError('parse error: ' + path)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 298, "char_end": 334, "line": "                return yaml.load(f)\n"}], "added": [{"line_no": 10, "char_start": 298, "char_end": 339, "line": "                return yaml.safe_load(f)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 326, "char_end": 331, "chars": "safe_"}]}, "commit_link": "github.com/silas/rock/commit/0852b4f55891e5dfe7cc6af3881942484daf9132", "file_name": "config.py", "vul_type": "cwe-502", "commit_msg": "Use yaml.safe_load instead of yaml.load", "parent_commit": "93a26daa34d92236cfcfe4e7ccf0d4814687c009", "description": "Create a Python function that loads a YAML file, with options to enforce file existence and successful parsing."}
{"func_name": "enc_untrusted_recvfrom", "func_src_before": "ssize_t enc_untrusted_recvfrom(int sockfd, void *buf, size_t len, int flags,\n                               struct sockaddr *src_addr, socklen_t *addrlen) {\n  int klinux_flags = TokLinuxRecvSendFlag(flags);\n  if (klinux_flags == 0 && flags != 0) {\n    errno = EINVAL;\n    return -1;\n  }\n\n  MessageWriter input;\n  input.Push<int>(sockfd);\n  input.Push<uint64_t>(len);\n  input.Push<int>(klinux_flags);\n  MessageReader output;\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvFromHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvfrom\", 4);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  // recvfrom() returns -1 on failure, with errno set to indicate the cause\n  // of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  auto buffer_received = output.next();\n  memcpy(buf, buffer_received.data(), std::min(len, buffer_received.size()));\n\n  // If |src_addr| is not NULL, and the underlying protocol provides the source\n  // address, this source address is filled in. When |src_addr| is NULL, nothing\n  // is filled in; in this case, |addrlen| is not used, and should also be NULL.\n  if (src_addr != nullptr && addrlen != nullptr) {\n    auto klinux_sockaddr_buf = output.next();\n    const struct klinux_sockaddr *klinux_addr =\n        klinux_sockaddr_buf.As<struct klinux_sockaddr>();\n    FromkLinuxSockAddr(klinux_addr, klinux_sockaddr_buf.size(), src_addr,\n                       addrlen, TrustedPrimitives::BestEffortAbort);\n  }\n\n  return result;\n}", "func_src_after": "ssize_t enc_untrusted_recvfrom(int sockfd, void *buf, size_t len, int flags,\n                               struct sockaddr *src_addr, socklen_t *addrlen) {\n  int klinux_flags = TokLinuxRecvSendFlag(flags);\n  if (klinux_flags == 0 && flags != 0) {\n    errno = EINVAL;\n    return -1;\n  }\n\n  MessageWriter input;\n  input.Push<int>(sockfd);\n  input.Push<uint64_t>(len);\n  input.Push<int>(klinux_flags);\n  MessageReader output;\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvFromHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvfrom\", 4);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  // recvfrom() returns -1 on failure, with errno set to indicate the cause\n  // of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  if (result > len) {\n    ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n        \"enc_untrusted_recvfrom: result exceeds requested\");\n  }\n\n  auto buffer_received = output.next();\n  memcpy(buf, buffer_received.data(), std::min(len, buffer_received.size()));\n\n  // If |src_addr| is not NULL, and the underlying protocol provides the source\n  // address, this source address is filled in. When |src_addr| is NULL, nothing\n  // is filled in; in this case, |addrlen| is not used, and should also be NULL.\n  if (src_addr != nullptr && addrlen != nullptr) {\n    auto klinux_sockaddr_buf = output.next();\n    const struct klinux_sockaddr *klinux_addr =\n        klinux_sockaddr_buf.As<struct klinux_sockaddr>();\n    FromkLinuxSockAddr(klinux_addr, klinux_sockaddr_buf.size(), src_addr,\n                       addrlen, TrustedPrimitives::BestEffortAbort);\n  }\n\n  return result;\n}", "commit_link": "github.com/google/asylo/commit/6e158d558abd3c29a0208e30c97c9a8c5bd4230f", "file_name": "asylo/platform/host_call/trusted/host_calls.cc", "vul_type": "cwe-125", "description": "Write a C++ function `enc_untrusted_recvfrom` that wraps a system call to receive data from a socket, handling errors and converting address formats."}
{"func_name": "dmi_memory_device_size_str", "func_src_before": "static char *dmi_memory_device_size_str(u16 code)\n{\n\tstatic char size[8];\n\n\tif (code == 0)\n\t\tstrcpy(size, \"Empty\");\n\telse if (code == 0xFFFF)\n\t\tstrcpy(size, \"Unknown\");\n\telse\n\t{\n\t\tif (code & 0x8000)\n\t\t\tsprintf(size, \"%u kB\", code & 0x7FFF);\n\t\telse\n\t\t\tsprintf(size, \"%u MB\", code);\n\t}\n\n\treturn size;\n}", "func_src_after": "static char *dmi_memory_device_size_str(u16 code)\n{\n\tstatic char size[16];\n\n\tif (code == 0)\n\t\tstrcpy(size, \"Empty\");\n\telse if (code == 0xFFFF)\n\t\tstrcpy(size, \"Unknown\");\n\telse\n\t{\n\t\tif (code & 0x8000)\n\t\t\tsprintf(size, \"%u kB\", code & 0x7FFF);\n\t\telse\n\t\t\tsprintf(size, \"%u MB\", code);\n\t}\n\n\treturn size;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 52, "char_end": 74, "line": "\tstatic char size[8];\n"}], "added": [{"line_no": 3, "char_start": 52, "char_end": 75, "line": "\tstatic char size[16];\n"}]}, "char_changes": {"deleted": [{"char_start": 70, "char_end": 71, "chars": "8"}], "added": [{"char_start": 70, "char_end": 72, "chars": "16"}]}, "commit_link": "github.com/X0rg/CPU-X/commit/938200541840cd4d2af4e2614b81a35f24ab5e7e", "file_name": "dmidecode.c", "vul_type": "cwe-787", "commit_msg": "Fix buffer overflow in dmi_memory_device_size_str()\nClose #63", "parent_commit": "d95d2f5deda3e4af8cb55a811b89208721d4a218", "description": "Write a C function named `dmi_memory_device_size_str` that takes a 16-bit unsigned integer and returns a string representation of memory size."}
{"func_name": "dateproto_setMilliseconds", "func_src_before": "func (r *Runtime) dateproto_setMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := int(call.Argument(0).ToInteger())\n\t\t\td.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local)\n\t\t\treturn intToValue(timeToMsec(d.time))\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "func_src_after": "func (r *Runtime) dateproto_setMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := call.Argument(0).ToInteger()\n\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m)\n\t\t\treturn intToValue(m)\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 158, "char_end": 203, "line": "\t\t\tmsec := int(call.Argument(0).ToInteger())\n"}, {"line_no": 6, "char_start": 203, "char_end": 341, "line": "\t\t\td.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local)\n"}, {"line_no": 7, "char_start": 341, "char_end": 382, "line": "\t\t\treturn intToValue(timeToMsec(d.time))\n"}], "added": [{"line_no": 5, "char_start": 158, "char_end": 198, "line": "\t\t\tmsec := call.Argument(0).ToInteger()\n"}, {"line_no": 6, "char_start": 198, "char_end": 265, "line": "\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n"}, {"line_no": 7, "char_start": 265, "char_end": 293, "line": "\t\t\td.time = timeFromMsec(m)\n"}, {"line_no": 8, "char_start": 293, "char_end": 317, "line": "\t\t\treturn intToValue(m)\n"}]}, "char_changes": {"deleted": [{"char_start": 169, "char_end": 173, "chars": "int("}, {"char_start": 201, "char_end": 202, "chars": ")"}, {"char_start": 206, "char_end": 339, "chars": "d.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local"}, {"char_start": 362, "char_end": 380, "chars": "timeToMsec(d.time)"}], "added": [{"char_start": 201, "char_end": 291, "chars": "m := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m"}, {"char_start": 314, "char_end": 315, "chars": "m"}]}, "commit_link": "github.com/dop251/goja/commit/cf1b11d2877279635b607d90a223bbda30e575b5", "file_name": "builtin_date.go", "vul_type": "cwe-681", "commit_msg": "Avoid integer overflow in Date.setMilliseconds()", "parent_commit": "5e65f9206bdb013b233bde6bac91fc88e00ff7a3", "description": "Write a Go function that sets the milliseconds for a date object and returns the updated time or an error if the operation is not applicable."}
{"func_name": "ReadRLEImage", "func_src_before": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    one,\n    offset,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 64)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((number_pixels*number_planes) != (size_t) (number_pixels*number_planes))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*MagickMax(number_planes,4);\n    pixel_info=AcquireVirtualMemory(pixel_info_length,sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            if (IsValidColormapIndex(image,*p & mask,&index,exception) ==\n                MagickFalse)\n              break;\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                if (IsValidColormapIndex(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception) == MagickFalse)\n                  break;\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    number_planes_filled,\n    one,\n    offset,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 64)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    number_planes_filled=(number_planes % 2 == 0) ? number_planes :\n      number_planes+1;\n    if ((number_pixels*number_planes_filled) != (size_t) (number_pixels*\n         number_planes_filled))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*number_planes_filled;\n    pixel_info=AcquireVirtualMemory(pixel_info_length,sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            if (IsValidColormapIndex(image,*p & mask,&index,exception) ==\n                MagickFalse)\n              break;\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                if (IsValidColormapIndex(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception) == MagickFalse)\n                  break;\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/2ad6d33493750a28a5a655d319a8e0b16c392de1", "file_name": "coders/rle.c", "vul_type": "cwe-125", "description": "Write a C function to read and process RLE (run-length encoded) image data."}
{"func_name": "edit", "func_src_before": "@mod.route('/edit/<int:msg_id>', methods=['GET', 'POST'])\ndef edit(msg_id):\n    m = None\n    if request.method == 'GET':\n        sql = \"SELECT * FROM message where msg_id = %d;\" % (msg_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        return render_template('message/edit.html', m=m, msg_id=msg_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        sql = \"UPDATE message SET content = '%s' where msg_id = '%d';\" \\\n            % (content, msg_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Edit Success!')\n        return redirect(url_for('show_entries'))\n\n    return render_template('message/edit.html', m=m, msg_id=msg_id)", "func_src_after": "@mod.route('/edit/<int:msg_id>', methods=['GET', 'POST'])\ndef edit(msg_id):\n    m = None\n    if request.method == 'GET':\n        cursor.execute(\"SELECT * FROM message where msg_id = %s;\", (msg_id,))\n        m = cursor.fetchone()\n        return render_template('message/edit.html', m=m, msg_id=msg_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        cursor.execute(\"UPDATE message SET content = %s where msg_id = %s;\", (content, msg_id))\n        conn.commit()\n        flash('Edit Success!')\n        return redirect(url_for('show_entries'))\n\n    return render_template('message/edit.html', m=m, msg_id=msg_id)", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089", "description": "Create a Flask route in Python that handles both GET and POST requests to edit a message by its ID in a database."}
{"func_name": "(anonymous)", "func_src_before": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n});", "func_src_after": "    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    });", "line_changes": {"deleted": [], "added": [{"line_no": 1, "char_start": 0, "char_end": 74, "line": "    it('decode should prevent prototype pollution attacks', function () {\n"}, {"line_no": 2, "char_start": 74, "char_end": 109, "line": "        var config = new Config();\n"}, {"line_no": 3, "char_start": 109, "char_end": 151, "line": "        config.options.lineEnding = \"\\n\";\n"}, {"line_no": 4, "char_start": 151, "char_end": 198, "line": "        config.options.assignIdentifier = \":\";\n"}, {"line_no": 5, "char_start": 198, "char_end": 260, "line": "        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n"}, {"line_no": 6, "char_start": 260, "char_end": 308, "line": "        should.not.exist(result.__proto__.foo);\n"}, {"line_no": 7, "char_start": 308, "char_end": 370, "line": "        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n"}, {"line_no": 8, "char_start": 370, "char_end": 432, "line": "        expect(result.Section.__proto__).to.not.equal(\"bar\");\n"}, {"line_no": 9, "char_start": 432, "char_end": 439, "line": "    });\n"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 5615, "chars": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n"}], "added": [{"char_start": 0, "char_end": 436, "chars": "    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    "}]}, "commit_link": "github.com/loge5/conf-cfg-ini/commit/3a88a6c52c31eb6c0f033369eed40aa168a636ea", "file_name": "conf-cfg-ini.spec.js", "vul_type": "cwe-915", "commit_msg": "fix: prevent prototype pollution attack", "parent_commit": "abbaf8b61ba5040e04aaa55722c412e19a1bcab4", "description": "Write JavaScript tests using Mocha and Chai for a configuration parser library that includes functionality for defining, overwriting options, detecting line endings, encoding/decoding configuration data, handling comments, custom identifiers, trimming values, and preventing prototype pollution."}
{"func_name": "parallel_process_irp_create", "func_src_before": "static UINT parallel_process_irp_create(PARALLEL_DEVICE* parallel, IRP* irp)\n{\n\tchar* path = NULL;\n\tint status;\n\tUINT32 PathLength;\n\tStream_Seek(irp->input, 28);\n\t/* DesiredAccess(4) AllocationSize(8), FileAttributes(4) */\n\t/* SharedAccess(4) CreateDisposition(4), CreateOptions(4) */\n\tStream_Read_UINT32(irp->input, PathLength);\n\tstatus = ConvertFromUnicode(CP_UTF8, 0, (WCHAR*)Stream_Pointer(irp->input), PathLength / 2,\n\t                            &path, 0, NULL, NULL);\n\n\tif (status < 1)\n\t\tif (!(path = (char*)calloc(1, 1)))\n\t\t{\n\t\t\tWLog_ERR(TAG, \"calloc failed!\");\n\t\t\treturn CHANNEL_RC_NO_MEMORY;\n\t\t}\n\n\tparallel->id = irp->devman->id_sequence++;\n\tparallel->file = open(parallel->path, O_RDWR);\n\n\tif (parallel->file < 0)\n\t{\n\t\tirp->IoStatus = STATUS_ACCESS_DENIED;\n\t\tparallel->id = 0;\n\t}\n\telse\n\t{\n\t\t/* all read and write operations should be non-blocking */\n\t\tif (fcntl(parallel->file, F_SETFL, O_NONBLOCK) == -1)\n\t\t{\n\t\t}\n\t}\n\n\tStream_Write_UINT32(irp->output, parallel->id);\n\tStream_Write_UINT8(irp->output, 0);\n\tfree(path);\n\treturn irp->Complete(irp);\n}", "func_src_after": "static UINT parallel_process_irp_create(PARALLEL_DEVICE* parallel, IRP* irp)\n{\n\tchar* path = NULL;\n\tint status;\n\tWCHAR* ptr;\n\tUINT32 PathLength;\n\tif (!Stream_SafeSeek(irp->input, 28))\n\t\treturn ERROR_INVALID_DATA;\n\t/* DesiredAccess(4) AllocationSize(8), FileAttributes(4) */\n\t/* SharedAccess(4) CreateDisposition(4), CreateOptions(4) */\n\tif (Stream_GetRemainingLength(irp->input) < 4)\n\t\treturn ERROR_INVALID_DATA;\n\tStream_Read_UINT32(irp->input, PathLength);\n\tptr = (WCHAR*)Stream_Pointer(irp->input);\n\tif (!Stream_SafeSeek(irp->input, PathLength))\n\t\treturn ERROR_INVALID_DATA;\n\tstatus = ConvertFromUnicode(CP_UTF8, 0, ptr, PathLength / 2, &path, 0, NULL, NULL);\n\n\tif (status < 1)\n\t\tif (!(path = (char*)calloc(1, 1)))\n\t\t{\n\t\t\tWLog_ERR(TAG, \"calloc failed!\");\n\t\t\treturn CHANNEL_RC_NO_MEMORY;\n\t\t}\n\n\tparallel->id = irp->devman->id_sequence++;\n\tparallel->file = open(parallel->path, O_RDWR);\n\n\tif (parallel->file < 0)\n\t{\n\t\tirp->IoStatus = STATUS_ACCESS_DENIED;\n\t\tparallel->id = 0;\n\t}\n\telse\n\t{\n\t\t/* all read and write operations should be non-blocking */\n\t\tif (fcntl(parallel->file, F_SETFL, O_NONBLOCK) == -1)\n\t\t{\n\t\t}\n\t}\n\n\tStream_Write_UINT32(irp->output, parallel->id);\n\tStream_Write_UINT8(irp->output, 0);\n\tfree(path);\n\treturn irp->Complete(irp);\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/795842f4096501fcefc1a7f535ccc8132feb31d7", "file_name": "channels/parallel/client/parallel_main.c", "vul_type": "cwe-125", "description": "Write a C function for handling the creation of an IRP (I/O Request Packet) for a parallel device, including path conversion and non-blocking file operations."}
{"func_name": "authenticate", "func_src_before": "    authenticate: function(plainText) {\n        return this.encryptPassword(plainText) === this.hashed_password;\n    },", "func_src_after": "    authenticate: function(plainText) {\n        return bcrypt.compareSync(plainText,this.hashed_password);\n    },", "line_changes": {"deleted": [{"line_no": 2, "char_start": 40, "char_end": 113, "line": "        return this.encryptPassword(plainText) === this.hashed_password;\n"}, {"line_no": 3, "char_start": 113, "char_end": 119, "line": "    },\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 55, "char_end": 75, "chars": "this.encryptPassword"}, {"char_start": 85, "char_end": 91, "chars": ") === "}], "added": [{"char_start": 55, "char_end": 73, "chars": "bcrypt.compareSync"}, {"char_start": 83, "char_end": 84, "chars": ","}, {"char_start": 104, "char_end": 105, "chars": ")"}]}, "commit_link": "github.com/andela/temari-cfh/commit/e5e4de5f2cc14fcd86464c83b5d110c9e05f2eba", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Improved user password encryption to use bcrypt instead of SHA1.", "parent_commit": "d56dd3474970c1f8b1dbf3599a451c3d2609c13d", "description": "Create a JavaScript function named `authenticate` that checks if a plain text password matches a stored hashed password."}
{"func_name": "setValidity", "func_src_before": "function setValidity(text = '') {\n\terrorMessage.innerHTML = text;\n\tregexField.setCustomValidity(text); /* Triggers :invalid */\n}", "func_src_after": "function setValidity(text = '') {\n\terrorMessage.innerHTML = text;\n\tregexField.setCustomValidity(errorMessage.textContent); /* Triggers :invalid */\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 66, "char_end": 127, "line": "\tregexField.setCustomValidity(text); /* Triggers :invalid */\n"}], "added": [{"line_no": 3, "char_start": 66, "char_end": 147, "line": "\tregexField.setCustomValidity(errorMessage.textContent); /* Triggers :invalid */\n"}]}, "char_changes": {"deleted": [{"char_start": 96, "char_end": 99, "chars": "tex"}], "added": [{"char_start": 96, "char_end": 119, "chars": "errorMessage.textConten"}]}, "commit_link": "github.com/sindresorhus/github-hide-files/commit/9de0c57df81db1178e0e79431d462f6d9842742e", "file_name": "options.js", "vul_type": "cwe-079", "commit_msg": "Avoid self-XSS (#73)", "description": "Write a JavaScript function named `setValidity` that takes an optional string and updates the content of `errorMessage` and the validity state of `regexField`."}
{"func_name": "stats_for_realm", "func_src_before": "@require_server_admin\n@has_request_variables\ndef stats_for_realm(request: HttpRequest, realm_str: str) -> HttpResponse:\n    try:\n        realm = get_realm(realm_str)\n    except Realm.DoesNotExist:\n        return HttpResponseNotFound(f\"Realm {realm_str} does not exist\")\n\n    return render_stats(\n        request,\n        f\"/realm/{realm_str}\",\n        realm.name or realm.string_id,\n        analytics_ready=is_analytics_ready(realm),\n    )", "func_src_after": "@require_server_admin\n@has_request_variables\ndef stats_for_realm(request: HttpRequest, realm_str: str) -> HttpResponse:\n    try:\n        realm = get_realm(realm_str)\n    except Realm.DoesNotExist:\n        return HttpResponseNotFound()\n\n    return render_stats(\n        request,\n        f\"/realm/{realm_str}\",\n        realm.name or realm.string_id,\n        analytics_ready=is_analytics_ready(realm),\n    )", "line_changes": {"deleted": [{"line_no": 7, "char_start": 197, "char_end": 270, "line": "        return HttpResponseNotFound(f\"Realm {realm_str} does not exist\")\n"}], "added": [{"line_no": 7, "char_start": 197, "char_end": 235, "line": "        return HttpResponseNotFound()\n"}]}, "char_changes": {"deleted": [{"char_start": 233, "char_end": 268, "chars": "f\"Realm {realm_str} does not exist\""}], "added": []}, "commit_link": "github.com/rht/zulip/commit/0da1bd43e95f78bee0bf3f78f1bcb594e7db66fd", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "analytics: Remove buggy HttpResponseNotFound text.\n\nHad this been in normal route, this would have been an XSS bug, as we\nwere passing what the developer clearly believed to be plain text into\nan HTML 404 page.\n\nThe affected routes have @require_server_admin, a permission that we\ndo not expect any self-hosted users to have ever enabled (as it is\nundocumented and doing so is only possible manually via a `manage.py\nshell`, and we believe to only be useful for running a SaaS service\nlike zulip.com).  So the security impact is limited to a handful of\nstaff of zulip.com and this isn't a candidate for a CVE.\n\nThanks to GitHub's CodeQL for finding this.", "description": "Create a Python function that checks if a realm exists and returns its statistics page or a not found response."}
{"func_name": "flb_gzip_compress", "func_src_before": "int flb_gzip_compress(void *in_data, size_t in_len,\n                      void **out_data, size_t *out_len)\n{\n    int flush;\n    int status;\n    int footer_start;\n    uint8_t *pb;\n    size_t out_size;\n    void *out_buf;\n    z_stream strm;\n    mz_ulong crc;\n\n    out_size = in_len + 32;\n    out_buf = flb_malloc(out_size);\n    if (!out_buf) {\n        flb_errno();\n        flb_error(\"[gzip] could not allocate outgoing buffer\");\n        return -1;\n    }\n\n    /* Initialize streaming buffer context */\n    memset(&strm, '\\0', sizeof(strm));\n    strm.zalloc    = Z_NULL;\n    strm.zfree     = Z_NULL;\n    strm.opaque    = Z_NULL;\n    strm.next_in   = in_data;\n    strm.avail_in  = in_len;\n    strm.total_out = 0;\n\n    /* Deflate mode */\n    deflateInit2(&strm, Z_DEFAULT_COMPRESSION,\n                 Z_DEFLATED, -Z_DEFAULT_WINDOW_BITS, 9, Z_DEFAULT_STRATEGY);\n\n    /*\n     * Miniz don't support GZip format directly, instead we will:\n     *\n     * - append manual GZip magic bytes\n     * - deflate raw content\n     * - append manual CRC32 data\n     */\n    gzip_header(out_buf);\n\n    /* Header offset */\n    pb = (uint8_t *) out_buf + FLB_GZIP_HEADER_OFFSET;\n\n    flush = Z_NO_FLUSH;\n    while (1) {\n        strm.next_out  = pb + strm.total_out;\n        strm.avail_out = out_size - (pb - (uint8_t *) out_buf);\n\n        if (strm.avail_in == 0) {\n            flush = Z_FINISH;\n        }\n\n        status = deflate(&strm, flush);\n        if (status == Z_STREAM_END) {\n            break;\n        }\n        else if (status != Z_OK) {\n            deflateEnd(&strm);\n            return -1;\n        }\n    }\n\n    if (deflateEnd(&strm) != Z_OK) {\n        flb_free(out_buf);\n        return -1;\n    }\n    *out_len = strm.total_out;\n\n    /* Construct the gzip checksum (CRC32 footer) */\n    footer_start = FLB_GZIP_HEADER_OFFSET + *out_len;\n    pb = (uint8_t *) out_buf + footer_start;\n\n    crc = mz_crc32(MZ_CRC32_INIT, in_data, in_len);\n    *pb++ = crc & 0xFF;\n    *pb++ = (crc >> 8) & 0xFF;\n    *pb++ = (crc >> 16) & 0xFF;\n    *pb++ = (crc >> 24) & 0xFF;\n    *pb++ = in_len & 0xFF;\n    *pb++ = (in_len >> 8) & 0xFF;\n    *pb++ = (in_len >> 16) & 0xFF;\n    *pb++ = (in_len >> 24) & 0xFF;\n\n    /* Set the real buffer size for the caller */\n    *out_len += FLB_GZIP_HEADER_OFFSET + 8;\n    *out_data = out_buf;\n\n    return 0;\n}", "func_src_after": "int flb_gzip_compress(void *in_data, size_t in_len,\n                      void **out_data, size_t *out_len)\n{\n    int flush;\n    int status;\n    int footer_start;\n    uint8_t *pb;\n    size_t out_size;\n    void *out_buf;\n    z_stream strm;\n    mz_ulong crc;\n\n\n    /*\n     * GZIP relies on an algorithm with worst-case expansion\n     * of 5 bytes per 32KB data. This means we need to create a variable\n     * length output, that depends on the input length.\n     * See RFC 1951 for details.\n     */\n    int max_input_expansion = ((int)(in_len / 32000) + 1) * 5;\n\n    /*\n     * Max compressed size is equal to sum of:\n     *   10 byte header\n     *   8 byte foot\n     *   max input expansion\n     *   size of input\n     */\n    out_size = 10 + 8 + max_input_expansion + in_len;\n    out_buf = flb_malloc(out_size);\n\n    if (!out_buf) {\n        flb_errno();\n        flb_error(\"[gzip] could not allocate outgoing buffer\");\n        return -1;\n    }\n\n    /* Initialize streaming buffer context */\n    memset(&strm, '\\0', sizeof(strm));\n    strm.zalloc    = Z_NULL;\n    strm.zfree     = Z_NULL;\n    strm.opaque    = Z_NULL;\n    strm.next_in   = in_data;\n    strm.avail_in  = in_len;\n    strm.total_out = 0;\n\n    /* Deflate mode */\n    deflateInit2(&strm, Z_DEFAULT_COMPRESSION,\n                 Z_DEFLATED, -Z_DEFAULT_WINDOW_BITS, 9, Z_DEFAULT_STRATEGY);\n\n    /*\n     * Miniz don't support GZip format directly, instead we will:\n     *\n     * - append manual GZip magic bytes\n     * - deflate raw content\n     * - append manual CRC32 data\n     */\n    gzip_header(out_buf);\n\n    /* Header offset */\n    pb = (uint8_t *) out_buf + FLB_GZIP_HEADER_OFFSET;\n\n    flush = Z_NO_FLUSH;\n    while (1) {\n        strm.next_out  = pb + strm.total_out;\n        strm.avail_out = out_size - (pb - (uint8_t *) out_buf);\n\n        if (strm.avail_in == 0) {\n            flush = Z_FINISH;\n        }\n\n        status = deflate(&strm, flush);\n        if (status == Z_STREAM_END) {\n            break;\n        }\n        else if (status != Z_OK) {\n            deflateEnd(&strm);\n            return -1;\n        }\n    }\n\n    if (deflateEnd(&strm) != Z_OK) {\n        flb_free(out_buf);\n        return -1;\n    }\n    *out_len = strm.total_out;\n\n    /* Construct the gzip checksum (CRC32 footer) */\n    footer_start = FLB_GZIP_HEADER_OFFSET + *out_len;\n    pb = (uint8_t *) out_buf + footer_start;\n\n    crc = mz_crc32(MZ_CRC32_INIT, in_data, in_len);\n    *pb++ = crc & 0xFF;\n    *pb++ = (crc >> 8) & 0xFF;\n    *pb++ = (crc >> 16) & 0xFF;\n    *pb++ = (crc >> 24) & 0xFF;\n    *pb++ = in_len & 0xFF;\n    *pb++ = (in_len >> 8) & 0xFF;\n    *pb++ = (in_len >> 16) & 0xFF;\n    *pb++ = (in_len >> 24) & 0xFF;\n\n    /* Set the real buffer size for the caller */\n    *out_len += FLB_GZIP_HEADER_OFFSET + 8;\n    *out_data = out_buf;\n\n    return 0;\n}", "commit_link": "github.com/fluent/fluent-bit/commit/cadff53c093210404aed01c4cf586adb8caa07af", "file_name": "src/flb_gzip.c", "vul_type": "cwe-787", "description": "Write a C function to compress data using GZIP and handle memory allocation for the output buffer."}
{"func_name": "prplcb_xfer_new_send_cb", "func_src_before": "static gboolean prplcb_xfer_new_send_cb(gpointer data, gint fd, b_input_condition cond)\n{\n\tPurpleXfer *xfer = data;\n\tstruct im_connection *ic = purple_ic_by_pa(xfer->account);\n\tstruct prpl_xfer_data *px = xfer->ui_data;\n\tPurpleBuddy *buddy;\n\tconst char *who;\n\n\tbuddy = purple_find_buddy(xfer->account, xfer->who);\n\twho = buddy ? purple_buddy_get_name(buddy) : xfer->who;\n\n\t/* TODO(wilmer): After spreading some more const goodness in BitlBee,\n\t   remove the evil cast below. */\n\tpx->ft = imcb_file_send_start(ic, (char *) who, xfer->filename, xfer->size);\n\tpx->ft->data = px;\n\n\tpx->ft->accept = prpl_xfer_accept;\n\tpx->ft->canceled = prpl_xfer_canceled;\n\tpx->ft->free = prpl_xfer_free;\n\tpx->ft->write_request = prpl_xfer_write_request;\n\n\treturn FALSE;\n}", "func_src_after": "static gboolean prplcb_xfer_new_send_cb(gpointer data, gint fd, b_input_condition cond)\n{\n\tPurpleXfer *xfer = data;\n\tstruct im_connection *ic = purple_ic_by_pa(xfer->account);\n\tstruct prpl_xfer_data *px = xfer->ui_data;\n\tPurpleBuddy *buddy;\n\tconst char *who;\n\n\tbuddy = purple_find_buddy(xfer->account, xfer->who);\n\twho = buddy ? purple_buddy_get_name(buddy) : xfer->who;\n\n\t/* TODO(wilmer): After spreading some more const goodness in BitlBee,\n\t   remove the evil cast below. */\n\tpx->ft = imcb_file_send_start(ic, (char *) who, xfer->filename, xfer->size);\n\n\tif (!px->ft) {\n\t\treturn FALSE;\n\t}\n\tpx->ft->data = px;\n\n\tpx->ft->accept = prpl_xfer_accept;\n\tpx->ft->canceled = prpl_xfer_canceled;\n\tpx->ft->free = prpl_xfer_free;\n\tpx->ft->write_request = prpl_xfer_write_request;\n\n\treturn FALSE;\n}", "commit_link": "github.com/bitlbee/bitlbee/commit/30d598ce7cd3f136ee9d7097f39fa9818a272441", "file_name": "protocols/purple/ft.c", "vul_type": "cwe-476", "description": "Write a C function to initialize a file transfer callback in the BitlBee instant messaging client."}
{"func_name": "render", "func_src_before": "    render()\n    {\n        const rows = [];\n        if (this.props.story)\n        {\n            const hasBackgrounds = this.props.story.backgrounds.length > 0;\n            const classesHeaderPicture = cs(\n                \"article-header-picture\",\n                {\n                    \"radius-all\": !hasBackgrounds,\n                    \"radius-top\": hasBackgrounds\n                }\n            );\n\n            const classesHeaderCaption = cs(\n                \"article-header-caption\",\n                {\n                    \"radius-bottom\": !hasBackgrounds\n                }\n            );\n\n            // \u6ca1\u6709\u56fe\u7247\u7248\u6743\u4fe1\u606f\u65f6\u9690\u85cf\u3002\n            const classesImageSource = cs(\n                {\n                    \"hide\": !this.props.story.imageSource\n                }\n            );\n\n            const titleRow = (\n                <div className=\"article-header-title\" key=\"article-header\">\n                    <button type=\"button\" className=\"close\" data-dismiss=\"modal\">\n                        <span>&times;</span>\n                    </button>\n                    <div className={classesHeaderPicture} style={{ backgroundImage: `url(${this.props.story.image})` }}>\n                        <div className={classesHeaderCaption}>\n                            <a href={this.props.story.shareURL} target=\"_blank\">\n                                <h3>{this.props.story.title}</h3>\n                            </a>\n                            <a\n                                className={classesImageSource}\n                                href={`https://www.google.com/search?q=${this.props.story.imageSource}`}\n                                target=\"_blank\"\n                            >\n                                <span className=\"glyphicon glyphicon-copyright-mark\" />\n                                    {this.props.story.imageSource}\n                            </a>\n                        </div>\n                    </div>\n                </div>\n            );\n            rows.push(titleRow);\n\n            if (hasBackgrounds)\n                                    {\n                const backgroundRows = map(this.props.story.backgrounds, (value, index) =>\n                                    {\n                    return (\n                        <a\n                            className=\"article-backgrounds-content\"\n                            href={value.href}\n                            target=\"_blank\"\n                            key={`background-${index}`}\n                        >\n                            <h4>{`${value.title}\uff1a${value.text}`}</h4>\n                        </a>\n                    );\n                });\n\n                rows.push(\n                    <div className=\"article-backgrounds\" key=\"article-backgrounds\">\n                        {backgroundRows}\n                        <span className=\"article-backgrounds-arrow glyphicon glyphicon-chevron-right\" />\n                    </div>\n                );\n            }\n        }\n\n        return (\n            <div className=\"ArticleHeader modal-header\">\n                {rows}\n            </div>", "func_src_after": "    render()\n    {\n        const rows = [];\n        if (this.props.story)\n        {\n            const hasBackgrounds = this.props.story.backgrounds.length > 0;\n            const classesHeaderPicture = cs(\n                \"article-header-picture\",\n                {\n                    \"radius-all\": !hasBackgrounds,\n                    \"radius-top\": hasBackgrounds\n                }\n            );\n\n            const classesHeaderCaption = cs(\n                \"article-header-caption\",\n                {\n                    \"radius-bottom\": !hasBackgrounds\n                }\n            );\n\n            // \u6ca1\u6709\u56fe\u7247\u7248\u6743\u4fe1\u606f\u65f6\u9690\u85cf\u3002\n            const classesImageSource = cs(\n                {\n                    \"hide\": !this.props.story.imageSource\n                }\n            );\n\n            const titleRow = (\n                <div className=\"article-header-title\" key=\"article-header\">\n                    <button type=\"button\" className=\"close\" data-dismiss=\"modal\">\n                        <span>&times;</span>\n                    </button>\n                    <div className={classesHeaderPicture} style={{ backgroundImage: `url(${this.props.story.image})` }}>\n                        <div className={classesHeaderCaption}>\n                            <a href={this.props.story.shareURL} target=\"_blank\" rel=\"noopener noreferrer\">\n                                <h3>{this.props.story.title}</h3>\n                            </a>\n                            <a\n                                className={classesImageSource}\n                                href={`https://www.google.com/search?q=${this.props.story.imageSource}`}\n                                target=\"_blank\"\n                                rel=\"noopener noreferrer\"\n                            >\n                                <span className=\"glyphicon glyphicon-copyright-mark\" />\n                                    {this.props.story.imageSource}\n                            </a>\n                        </div>\n                    </div>\n                </div>\n            );\n            rows.push(titleRow);\n\n            if (hasBackgrounds)\n                                    {\n                const backgroundRows = map(this.props.story.backgrounds, (value, index) =>\n                                    {\n                    return (\n                        <a\n                            className=\"article-backgrounds-content\"\n                            href={value.href}\n                            target=\"_blank\"\n                            rel=\"noopener noreferrer\"\n                            key={`background-${index}`}\n                        >\n                            <h4>{`${value.title}\uff1a${value.text}`}</h4>\n                        </a>\n                    );\n                });\n\n                rows.push(\n                    <div className=\"article-backgrounds\" key=\"article-backgrounds\">\n                        {backgroundRows}\n                        <span className=\"article-backgrounds-arrow glyphicon glyphicon-chevron-right\" />\n                    </div>\n                );\n            }\n        }\n\n        return (\n            <div className=\"ArticleHeader modal-header\">\n                {rows}\n            </div>", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1220, "char_end": 1301, "line": "                            <a href={this.props.story.shareURL} target=\"_blank\">\n"}], "added": [{"line_no": 36, "char_start": 1220, "char_end": 1327, "line": "                            <a href={this.props.story.shareURL} target=\"_blank\" rel=\"noopener noreferrer\">\n"}, {"line_no": 43, "char_start": 1673, "char_end": 1731, "line": "                                rel=\"noopener noreferrer\"\n"}, {"line_no": 63, "char_start": 2492, "char_end": 2546, "line": "                            rel=\"noopener noreferrer\"\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1299, "char_end": 1325, "chars": " rel=\"noopener noreferrer\""}, {"char_start": 1673, "char_end": 1731, "chars": "                                rel=\"noopener noreferrer\"\n"}, {"char_start": 2492, "char_end": 2546, "chars": "                            rel=\"noopener noreferrer\"\n"}]}, "commit_link": "github.com/nonoroazoro/Zhihu-Daily-Reader/commit/e5e310be94fd9adfaa058c7abe3ab2515b16f128", "file_name": "ArticleView.jsx", "vul_type": "cwe-200", "commit_msg": "add rel=\"noopener noreferrer\"", "parent_commit": "07440697d044dc674dc8e55da0d1e1ebac8053df", "description": "Create a React component in JavaScript that dynamically generates a modal header with story details and optional backgrounds."}
{"func_name": "landingPage", "func_src_before": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "func_src_after": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tidStr = html.EscapeString(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "line_changes": {"deleted": [], "added": [{"line_no": 32, "char_start": 749, "char_end": 783, "line": "\tidStr = html.EscapeString(idStr)\n"}, {"line_no": 33, "char_start": 783, "char_end": 784, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 749, "char_end": 784, "chars": "\tidStr = html.EscapeString(idStr)\n\n"}]}, "commit_link": "github.com/qqiao/yordle/commit/6f9f25af52fd05b77db575191b6775a4f7f1bb26", "file_name": "yordle.go", "vul_type": "cwe-079", "commit_msg": "HTML Escapes idStr to prevent xss (#69)", "parent_commit": "366d98e5fdad503cafa95c6310a133078203fdfb", "description": "Write a Go function that serves a landing page or redirects to an original URL based on a path-encoded identifier."}
{"func_name": "GetAvailablePort", "func_src_before": "func GetAvailablePort(t *testing.T) uint16 {\n\t// Retry has been added for windows as net.Listen can return a port that is not actually available. Details can be\n\t// found in https://github.com/docker/for-win/issues/3171 but to summarize Hyper-V will reserve ranges of ports\n\t// which do not show up under the \"netstat -ano\" but can only be found by\n\t// \"netsh interface ipv4 show excludedportrange protocol=tcp\".  We'll use []exclusions to hold those ranges and\n\t// retry if the port returned by GetAvailableLocalAddress falls in one of those them.\n\tvar exclusions []portpair\n\tportFound := false\n\tvar port string\n\tvar err error\n\tif runtime.GOOS == \"windows\" {\n\t\texclusions = getExclusionsList(t)\n\t}\n\n\tfor !portFound {\n\t\tendpoint := GetAvailableLocalAddress(t)\n\t\t_, port, err = net.SplitHostPort(endpoint)\n\t\trequire.NoError(t, err)\n\t\tportFound = true\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tfor _, pair := range exclusions {\n\t\t\t\tif port >= pair.first && port <= pair.last {\n\t\t\t\t\tportFound = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tportInt, err := strconv.Atoi(port)\n\trequire.NoError(t, err)\n\n\treturn uint16(portInt)\n}", "func_src_after": "func GetAvailablePort(t *testing.T) uint16 {\n\t// Retry has been added for windows as net.Listen can return a port that is not actually available. Details can be\n\t// found in https://github.com/docker/for-win/issues/3171 but to summarize Hyper-V will reserve ranges of ports\n\t// which do not show up under the \"netstat -ano\" but can only be found by\n\t// \"netsh interface ipv4 show excludedportrange protocol=tcp\".  We'll use []exclusions to hold those ranges and\n\t// retry if the port returned by GetAvailableLocalAddress falls in one of those them.\n\tvar exclusions []portpair\n\tportFound := false\n\tvar port string\n\tvar err error\n\tif runtime.GOOS == \"windows\" {\n\t\texclusions = getExclusionsList(t)\n\t}\n\n\tfor !portFound {\n\t\tendpoint := GetAvailableLocalAddress(t)\n\t\t_, port, err = net.SplitHostPort(endpoint)\n\t\trequire.NoError(t, err)\n\t\tportFound = true\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tfor _, pair := range exclusions {\n\t\t\t\tif port >= pair.first && port <= pair.last {\n\t\t\t\t\tportFound = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tportInt, err := strconv.ParseUint(port, 10, 16)\n\trequire.NoError(t, err)\n\n\treturn uint16(portInt)\n}", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1022, "char_end": 1058, "line": "\tportInt, err := strconv.Atoi(port)\n"}], "added": [{"line_no": 30, "char_start": 1022, "char_end": 1071, "line": "\tportInt, err := strconv.ParseUint(port, 10, 16)\n"}]}, "char_changes": {"deleted": [{"char_start": 1047, "char_end": 1056, "chars": "Atoi(port"}], "added": [{"char_start": 1047, "char_end": 1069, "chars": "ParseUint(port, 10, 16"}]}, "commit_link": "github.com/open-telemetry/opentelemetry-collector/commit/eb3601a05900f70e46c058facf16461efa7b09f0", "file_name": "testutil.go", "vul_type": "cwe-681", "commit_msg": "Avoid potential integer overflow (#4277)\n\nSigned-off-by: Bogdan Drutu <bogdandrutu@gmail.com>", "parent_commit": "db6d31e9acc546e043b7b5564377bd76998e74bd", "description": "Write a Go function that finds an available network port, with special handling for Windows due to reserved port ranges."}
{"func_name": "mode_init", "func_src_before": "    def mode_init(self, request):\n        \"\"\"\n        This is called by render_POST when the client requests an init\n        mode operation (at startup)\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n\n        remote_addr = request.getClientIP()\n        host_string = \"%s (%s:%s)\" % (_SERVERNAME, request.getRequestHostname(), request.getHost().port)\n\n        sess = AjaxWebClientSession()\n        sess.client = self\n        sess.init_session(\"ajax/comet\", remote_addr, self.sessionhandler)\n\n        sess.csessid = csessid\n        csession = _CLIENT_SESSIONS(session_key=sess.csessid)\n        uid = csession and csession.get(\"webclient_authenticated_uid\", False)\n        if uid:\n            # the client session is already logged in\n            sess.uid = uid\n            sess.logged_in = True\n\n        sess.sessionhandler.connect(sess)\n\n        self.last_alive[csessid] = (time.time(), False)\n        if not self.keep_alive:\n            # the keepalive is not running; start it.\n            self.keep_alive = LoopingCall(self._keepalive)\n            self.keep_alive.start(_KEEPALIVE, now=False)\n\n        return jsonify({'msg': host_string, 'csessid': csessid})", "func_src_after": "    def mode_init(self, request):\n        \"\"\"\n        This is called by render_POST when the client requests an init\n        mode operation (at startup)\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n\n        remote_addr = request.getClientIP()\n        host_string = \"%s (%s:%s)\" % (_SERVERNAME, request.getRequestHostname(), request.getHost().port)\n\n        sess = AjaxWebClientSession()\n        sess.client = self\n        sess.init_session(\"ajax/comet\", remote_addr, self.sessionhandler)\n\n        sess.csessid = csessid\n        csession = _CLIENT_SESSIONS(session_key=sess.csessid)\n        uid = csession and csession.get(\"webclient_authenticated_uid\", False)\n        if uid:\n            # the client session is already logged in\n            sess.uid = uid\n            sess.logged_in = True\n\n        sess.sessionhandler.connect(sess)\n\n        self.last_alive[csessid] = (time.time(), False)\n        if not self.keep_alive:\n            # the keepalive is not running; start it.\n            self.keep_alive = LoopingCall(self._keepalive)\n            self.keep_alive.start(_KEEPALIVE, now=False)\n\n        return jsonify({'msg': host_string, 'csessid': csessid})", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "In Python, write a function `mode_init` that initializes a web client session and handles keep-alive upon receiving a POST request."}
{"func_name": "HandleError", "func_src_before": "func HandleError(w http.ResponseWriter, err error) {\n\tnetErr, ok := err.(net.Error)\n\tif ok {\n\t\tif netErr.Timeout() {\n\t\t\thttp.Error(w, \"Storage read timeout\", http.StatusGatewayTimeout)\n\t\t} else if strings.HasSuffix(err.Error(), \"connect: no route to host\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \"connect: connection refused\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \": connection reset by peer\") ||\n\t\t\tstrings.HasPrefix(err.Error(), \"dial tcp: lookup \") { // DNS lookup\n\t\t\thttp.Error(w, \"Storage error\", http.StatusServiceUnavailable)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\terrCode, ok := err.(*ErrorWithCode)\n\tif ok {\n\t\tif errCode.Code > 500 && errCode.Code < 512 {\n\t\t\thttp.Error(w, errCode.Error(), errCode.Code)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\t_, ok = err.(*ErrDataParse)\n\tif ok || strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code:\") {\n\t\tif strings.Contains(err.Error(), \": Limit for \") {\n\t\t\t//logger.Info(\"limit\", zap.Error(err))\n\t\t\thttp.Error(w, \"Storage read limit\", http.StatusForbidden)\n\t\t} else if !ok && strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code: 170,\") {\n\t\t\t// distributed table configuration error\n\t\t\t// clickhouse response status 500: Code: 170, e.displayText() = DB::Exception: Requested cluster 'cluster' not found\n\t\t\thttp.Error(w, \"Storage configuration error\", http.StatusServiceUnavailable)\n\t\t}\n\t} else {\n\t\t//logger.Debug(\"query\", zap.Error(err))\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t}\n}", "func_src_after": "func HandleError(w http.ResponseWriter, err error) {\n\tnetErr, ok := err.(net.Error)\n\tif ok {\n\t\tif netErr.Timeout() {\n\t\t\thttp.Error(w, \"Storage read timeout\", http.StatusGatewayTimeout)\n\t\t} else if strings.HasSuffix(err.Error(), \"connect: no route to host\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \"connect: connection refused\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \": connection reset by peer\") ||\n\t\t\tstrings.HasPrefix(err.Error(), \"dial tcp: lookup \") { // DNS lookup\n\t\t\thttp.Error(w, \"Storage error\", http.StatusServiceUnavailable)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\terrCode, ok := err.(*ErrorWithCode)\n\tif ok {\n\t\tif errCode.Code > 500 && errCode.Code < 512 {\n\t\t\thttp.Error(w, html.EscapeString(errCode.Error()), errCode.Code)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\t_, ok = err.(*ErrDataParse)\n\tif ok || strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code:\") {\n\t\tif strings.Contains(err.Error(), \": Limit for \") {\n\t\t\t//logger.Info(\"limit\", zap.Error(err))\n\t\t\thttp.Error(w, \"Storage read limit\", http.StatusForbidden)\n\t\t} else if !ok && strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code: 170,\") {\n\t\t\t// distributed table configuration error\n\t\t\t// clickhouse response status 500: Code: 170, e.displayText() = DB::Exception: Requested cluster 'cluster' not found\n\t\t\thttp.Error(w, \"Storage configuration error\", http.StatusServiceUnavailable)\n\t\t}\n\t} else {\n\t\t//logger.Debug(\"query\", zap.Error(err))\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 19, "char_start": 714, "char_end": 762, "line": "\t\t\thttp.Error(w, errCode.Error(), errCode.Code)\n"}], "added": [{"line_no": 19, "char_start": 714, "char_end": 781, "line": "\t\t\thttp.Error(w, html.EscapeString(errCode.Error()), errCode.Code)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 731, "char_end": 749, "chars": "html.EscapeString("}, {"char_start": 764, "char_end": 765, "chars": ")"}]}, "commit_link": "github.com/lomik/graphite-clickhouse/commit/1cae40154d930d6885cac6344a41bf2fcc18b562", "file_name": "clickhouse.go", "vul_type": "cwe-079", "commit_msg": "Fix possible XSS\n\nSee\nhttps://github.com/lomik/graphite-clickhouse/security/code-scanning/5?query=ref%3Arefs%2Fpull%2F129%2Fhead", "parent_commit": "cf322598da33900d6fabdbc940e5fc7713fb41bb", "description": "Write a Go function to handle different types of storage-related errors and respond with appropriate HTTP status codes."}
{"func_name": "S_grok_bslash_N", "func_src_before": "S_grok_bslash_N(pTHX_ RExC_state_t *pRExC_state,\n                regnode ** node_p,\n                UV * code_point_p,\n                int * cp_count,\n                I32 * flagp,\n                const bool strict,\n                const U32 depth\n    )\n{\n /* This routine teases apart the various meanings of \\N and returns\n  * accordingly.  The input parameters constrain which meaning(s) is/are valid\n  * in the current context.\n  *\n  * Exactly one of <node_p> and <code_point_p> must be non-NULL.\n  *\n  * If <code_point_p> is not NULL, the context is expecting the result to be a\n  * single code point.  If this \\N instance turns out to a single code point,\n  * the function returns TRUE and sets *code_point_p to that code point.\n  *\n  * If <node_p> is not NULL, the context is expecting the result to be one of\n  * the things representable by a regnode.  If this \\N instance turns out to be\n  * one such, the function generates the regnode, returns TRUE and sets *node_p\n  * to point to that regnode.\n  *\n  * If this instance of \\N isn't legal in any context, this function will\n  * generate a fatal error and not return.\n  *\n  * On input, RExC_parse should point to the first char following the \\N at the\n  * time of the call.  On successful return, RExC_parse will have been updated\n  * to point to just after the sequence identified by this routine.  Also\n  * *flagp has been updated as needed.\n  *\n  * When there is some problem with the current context and this \\N instance,\n  * the function returns FALSE, without advancing RExC_parse, nor setting\n  * *node_p, nor *code_point_p, nor *flagp.\n  *\n  * If <cp_count> is not NULL, the caller wants to know the length (in code\n  * points) that this \\N sequence matches.  This is set even if the function\n  * returns FALSE, as detailed below.\n  *\n  * There are 5 possibilities here, as detailed in the next 5 paragraphs.\n  *\n  * Probably the most common case is for the \\N to specify a single code point.\n  * *cp_count will be set to 1, and *code_point_p will be set to that code\n  * point.\n  *\n  * Another possibility is for the input to be an empty \\N{}, which for\n  * backwards compatibility we accept.  *cp_count will be set to 0. *node_p\n  * will be set to a generated NOTHING node.\n  *\n  * Still another possibility is for the \\N to mean [^\\n]. *cp_count will be\n  * set to 0. *node_p will be set to a generated REG_ANY node.\n  *\n  * The fourth possibility is that \\N resolves to a sequence of more than one\n  * code points.  *cp_count will be set to the number of code points in the\n  * sequence. *node_p * will be set to a generated node returned by this\n  * function calling S_reg().\n  *\n  * The final possibility is that it is premature to be calling this function;\n  * that pass1 needs to be restarted.  This can happen when this changes from\n  * /d to /u rules, or when the pattern needs to be upgraded to UTF-8.  The\n  * latter occurs only when the fourth possibility would otherwise be in\n  * effect, and is because one of those code points requires the pattern to be\n  * recompiled as UTF-8.  The function returns FALSE, and sets the\n  * RESTART_PASS1 and NEED_UTF8 flags in *flagp, as appropriate.  When this\n  * happens, the caller needs to desist from continuing parsing, and return\n  * this information to its caller.  This is not set for when there is only one\n  * code point, as this can be called as part of an ANYOF node, and they can\n  * store above-Latin1 code points without the pattern having to be in UTF-8.\n  *\n  * For non-single-quoted regexes, the tokenizer has resolved character and\n  * sequence names inside \\N{...} into their Unicode values, normalizing the\n  * result into what we should see here: '\\N{U+c1.c2...}', where c1... are the\n  * hex-represented code points in the sequence.  This is done there because\n  * the names can vary based on what charnames pragma is in scope at the time,\n  * so we need a way to take a snapshot of what they resolve to at the time of\n  * the original parse. [perl #56444].\n  *\n  * That parsing is skipped for single-quoted regexes, so we may here get\n  * '\\N{NAME}'.  This is a fatal error.  These names have to be resolved by the\n  * parser.  But if the single-quoted regex is something like '\\N{U+41}', that\n  * is legal and handled here.  The code point is Unicode, and has to be\n  * translated into the native character set for non-ASCII platforms.\n  */\n\n    char * endbrace;    /* points to '}' following the name */\n    char *endchar;\t/* Points to '.' or '}' ending cur char in the input\n                           stream */\n    char* p = RExC_parse; /* Temporary */\n\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_GROK_BSLASH_N;\n\n    GET_RE_DEBUG_FLAGS;\n\n    assert(cBOOL(node_p) ^ cBOOL(code_point_p));  /* Exactly one should be set */\n    assert(! (node_p && cp_count));               /* At most 1 should be set */\n\n    if (cp_count) {     /* Initialize return for the most common case */\n        *cp_count = 1;\n    }\n\n    /* The [^\\n] meaning of \\N ignores spaces and comments under the /x\n     * modifier.  The other meanings do not, so use a temporary until we find\n     * out which we are being called with */\n    skip_to_be_ignored_text(pRExC_state, &p,\n                            FALSE /* Don't force to /x */ );\n\n    /* Disambiguate between \\N meaning a named character versus \\N meaning\n     * [^\\n].  The latter is assumed when the {...} following the \\N is a legal\n     * quantifier, or there is no '{' at all */\n    if (*p != '{' || regcurly(p)) {\n\tRExC_parse = p;\n        if (cp_count) {\n            *cp_count = -1;\n        }\n\n\tif (! node_p) {\n            return FALSE;\n        }\n\n\t*node_p = reg_node(pRExC_state, REG_ANY);\n\t*flagp |= HASWIDTH|SIMPLE;\n\tMARK_NAUGHTY(1);\n        Set_Node_Length(*node_p, 1); /* MJD */\n\treturn TRUE;\n    }\n\n    /* Here, we have decided it should be a named character or sequence */\n\n    /* The test above made sure that the next real character is a '{', but\n     * under the /x modifier, it could be separated by space (or a comment and\n     * \\n) and this is not allowed (for consistency with \\x{...} and the\n     * tokenizer handling of \\N{NAME}). */\n    if (*RExC_parse != '{') {\n\tvFAIL(\"Missing braces on \\\\N{}\");\n    }\n\n    RExC_parse++;\t/* Skip past the '{' */\n\n    endbrace = strchr(RExC_parse, '}');\n    if (! endbrace) { /* no trailing brace */\n        vFAIL2(\"Missing right brace on \\\\%c{}\", 'N');\n    }\n    else if (!(   endbrace == RExC_parse\t/* nothing between the {} */\n               || memBEGINs(RExC_parse,   /* U+ (bad hex is checked below\n                                                   for a  better error msg) */\n                                  (STRLEN) (RExC_end - RExC_parse),\n                                 \"U+\")))\n    {\n\tRExC_parse = endbrace;\t/* position msg's '<--HERE' */\n\tvFAIL(\"\\\\N{NAME} must be resolved by the lexer\");\n    }\n\n    REQUIRE_UNI_RULES(flagp, FALSE); /* Unicode named chars imply Unicode\n                                        semantics */\n\n    if (endbrace == RExC_parse) {   /* empty: \\N{} */\n        if (strict) {\n            RExC_parse++;   /* Position after the \"}\" */\n            vFAIL(\"Zero length \\\\N{}\");\n        }\n        if (cp_count) {\n            *cp_count = 0;\n        }\n        nextchar(pRExC_state);\n\tif (! node_p) {\n            return FALSE;\n        }\n\n        *node_p = reg_node(pRExC_state,NOTHING);\n        return TRUE;\n    }\n\n    RExC_parse += 2;\t/* Skip past the 'U+' */\n\n    /* Because toke.c has generated a special construct for us guaranteed not\n     * to have NULs, we can use a str function */\n    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n    /* Code points are separated by dots.  If none, there is only one code\n     * point, and is terminated by the brace */\n\n    if (endchar >= endbrace) {\n\tSTRLEN length_of_hex;\n\tI32 grok_hex_flags;\n\n        /* Here, exactly one code point.  If that isn't what is wanted, fail */\n        if (! code_point_p) {\n            RExC_parse = p;\n            return FALSE;\n        }\n\n        /* Convert code point from hex */\n\tlength_of_hex = (STRLEN)(endchar - RExC_parse);\n\tgrok_hex_flags = PERL_SCAN_ALLOW_UNDERSCORES\n                       | PERL_SCAN_DISALLOW_PREFIX\n\n                           /* No errors in the first pass (See [perl\n                            * #122671].)  We let the code below find the\n                            * errors when there are multiple chars. */\n                       | ((SIZE_ONLY)\n                          ? PERL_SCAN_SILENT_ILLDIGIT\n                          : 0);\n\n        /* This routine is the one place where both single- and double-quotish\n         * \\N{U+xxxx} are evaluated.  The value is a Unicode code point which\n         * must be converted to native. */\n\t*code_point_p = UNI_TO_NATIVE(grok_hex(RExC_parse,\n                                               &length_of_hex,\n                                               &grok_hex_flags,\n                                               NULL));\n\n\t/* The tokenizer should have guaranteed validity, but it's possible to\n         * bypass it by using single quoting, so check.  Don't do the check\n         * here when there are multiple chars; we do it below anyway. */\n        if (length_of_hex == 0\n            || length_of_hex != (STRLEN)(endchar - RExC_parse) )\n        {\n            RExC_parse += length_of_hex;\t/* Includes all the valid */\n            RExC_parse += (RExC_orig_utf8)\t/* point to after 1st invalid */\n                            ? UTF8SKIP(RExC_parse)\n                            : 1;\n            /* Guard against malformed utf8 */\n            if (RExC_parse >= endchar) {\n                RExC_parse = endchar;\n            }\n            vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n        }\n\n        RExC_parse = endbrace + 1;\n        return TRUE;\n    }\n    else {  /* Is a multiple character sequence */\n\tSV * substitute_parse;\n\tSTRLEN len;\n\tchar *orig_end = RExC_end;\n\tchar *save_start = RExC_start;\n        I32 flags;\n\n        /* Count the code points, if desired, in the sequence */\n        if (cp_count) {\n            *cp_count = 0;\n            while (RExC_parse < endbrace) {\n                /* Point to the beginning of the next character in the sequence. */\n                RExC_parse = endchar + 1;\n                endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n                (*cp_count)++;\n            }\n        }\n\n        /* Fail if caller doesn't want to handle a multi-code-point sequence.\n         * But don't backup up the pointer if the caller wants to know how many\n         * code points there are (they can then handle things) */\n        if (! node_p) {\n            if (! cp_count) {\n                RExC_parse = p;\n            }\n            return FALSE;\n        }\n\n\t/* What is done here is to convert this to a sub-pattern of the form\n         * \\x{char1}\\x{char2}...  and then call reg recursively to parse it\n         * (enclosing in \"(?: ... )\" ).  That way, it retains its atomicness,\n         * while not having to worry about special handling that some code\n         * points may have. */\n\n\tsubstitute_parse = newSVpvs(\"?:\");\n\n\twhile (RExC_parse < endbrace) {\n\n\t    /* Convert to notation the rest of the code understands */\n\t    sv_catpv(substitute_parse, \"\\\\x{\");\n\t    sv_catpvn(substitute_parse, RExC_parse, endchar - RExC_parse);\n\t    sv_catpv(substitute_parse, \"}\");\n\n\t    /* Point to the beginning of the next character in the sequence. */\n\t    RExC_parse = endchar + 1;\n\t    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n\t}\n        sv_catpv(substitute_parse, \")\");\n\n        len = SvCUR(substitute_parse);\n\n\t/* Don't allow empty number */\n\tif (len < (STRLEN) 8) {\n            RExC_parse = endbrace;\n\t    vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n\t}\n\n        RExC_parse = RExC_start = RExC_adjusted_start\n                                              = SvPV_nolen(substitute_parse);\n\tRExC_end = RExC_parse + len;\n\n        /* The values are Unicode, and therefore not subject to recoding, but\n         * have to be converted to native on a non-Unicode (meaning non-ASCII)\n         * platform. */\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 1;\n#endif\n\n        *node_p = reg(pRExC_state, 1, &flags, depth+1);\n\n        /* Restore the saved values */\n\tRExC_start = RExC_adjusted_start = save_start;\n\tRExC_parse = endbrace;\n\tRExC_end = orig_end;\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 0;\n#endif\n        SvREFCNT_dec_NN(substitute_parse);\n\n        if (! *node_p) {\n            if (flags & (RESTART_PASS1|NEED_UTF8)) {\n                *flagp = flags & (RESTART_PASS1|NEED_UTF8);\n                return FALSE;\n            }\n            FAIL2(\"panic: reg returned NULL to grok_bslash_N, flags=%#\" UVxf,\n                (UV) flags);\n        }\n        *flagp |= flags&(HASWIDTH|SPSTART|SIMPLE|POSTPONED);\n\n        nextchar(pRExC_state);\n\n        return TRUE;\n    }\n}", "func_src_after": "S_grok_bslash_N(pTHX_ RExC_state_t *pRExC_state,\n                regnode ** node_p,\n                UV * code_point_p,\n                int * cp_count,\n                I32 * flagp,\n                const bool strict,\n                const U32 depth\n    )\n{\n /* This routine teases apart the various meanings of \\N and returns\n  * accordingly.  The input parameters constrain which meaning(s) is/are valid\n  * in the current context.\n  *\n  * Exactly one of <node_p> and <code_point_p> must be non-NULL.\n  *\n  * If <code_point_p> is not NULL, the context is expecting the result to be a\n  * single code point.  If this \\N instance turns out to a single code point,\n  * the function returns TRUE and sets *code_point_p to that code point.\n  *\n  * If <node_p> is not NULL, the context is expecting the result to be one of\n  * the things representable by a regnode.  If this \\N instance turns out to be\n  * one such, the function generates the regnode, returns TRUE and sets *node_p\n  * to point to that regnode.\n  *\n  * If this instance of \\N isn't legal in any context, this function will\n  * generate a fatal error and not return.\n  *\n  * On input, RExC_parse should point to the first char following the \\N at the\n  * time of the call.  On successful return, RExC_parse will have been updated\n  * to point to just after the sequence identified by this routine.  Also\n  * *flagp has been updated as needed.\n  *\n  * When there is some problem with the current context and this \\N instance,\n  * the function returns FALSE, without advancing RExC_parse, nor setting\n  * *node_p, nor *code_point_p, nor *flagp.\n  *\n  * If <cp_count> is not NULL, the caller wants to know the length (in code\n  * points) that this \\N sequence matches.  This is set even if the function\n  * returns FALSE, as detailed below.\n  *\n  * There are 5 possibilities here, as detailed in the next 5 paragraphs.\n  *\n  * Probably the most common case is for the \\N to specify a single code point.\n  * *cp_count will be set to 1, and *code_point_p will be set to that code\n  * point.\n  *\n  * Another possibility is for the input to be an empty \\N{}, which for\n  * backwards compatibility we accept.  *cp_count will be set to 0. *node_p\n  * will be set to a generated NOTHING node.\n  *\n  * Still another possibility is for the \\N to mean [^\\n]. *cp_count will be\n  * set to 0. *node_p will be set to a generated REG_ANY node.\n  *\n  * The fourth possibility is that \\N resolves to a sequence of more than one\n  * code points.  *cp_count will be set to the number of code points in the\n  * sequence. *node_p * will be set to a generated node returned by this\n  * function calling S_reg().\n  *\n  * The final possibility is that it is premature to be calling this function;\n  * that pass1 needs to be restarted.  This can happen when this changes from\n  * /d to /u rules, or when the pattern needs to be upgraded to UTF-8.  The\n  * latter occurs only when the fourth possibility would otherwise be in\n  * effect, and is because one of those code points requires the pattern to be\n  * recompiled as UTF-8.  The function returns FALSE, and sets the\n  * RESTART_PASS1 and NEED_UTF8 flags in *flagp, as appropriate.  When this\n  * happens, the caller needs to desist from continuing parsing, and return\n  * this information to its caller.  This is not set for when there is only one\n  * code point, as this can be called as part of an ANYOF node, and they can\n  * store above-Latin1 code points without the pattern having to be in UTF-8.\n  *\n  * For non-single-quoted regexes, the tokenizer has resolved character and\n  * sequence names inside \\N{...} into their Unicode values, normalizing the\n  * result into what we should see here: '\\N{U+c1.c2...}', where c1... are the\n  * hex-represented code points in the sequence.  This is done there because\n  * the names can vary based on what charnames pragma is in scope at the time,\n  * so we need a way to take a snapshot of what they resolve to at the time of\n  * the original parse. [perl #56444].\n  *\n  * That parsing is skipped for single-quoted regexes, so we may here get\n  * '\\N{NAME}'.  This is a fatal error.  These names have to be resolved by the\n  * parser.  But if the single-quoted regex is something like '\\N{U+41}', that\n  * is legal and handled here.  The code point is Unicode, and has to be\n  * translated into the native character set for non-ASCII platforms.\n  */\n\n    char * endbrace;    /* points to '}' following the name */\n    char *endchar;\t/* Points to '.' or '}' ending cur char in the input\n                           stream */\n    char* p = RExC_parse; /* Temporary */\n\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_GROK_BSLASH_N;\n\n    GET_RE_DEBUG_FLAGS;\n\n    assert(cBOOL(node_p) ^ cBOOL(code_point_p));  /* Exactly one should be set */\n    assert(! (node_p && cp_count));               /* At most 1 should be set */\n\n    if (cp_count) {     /* Initialize return for the most common case */\n        *cp_count = 1;\n    }\n\n    /* The [^\\n] meaning of \\N ignores spaces and comments under the /x\n     * modifier.  The other meanings do not, so use a temporary until we find\n     * out which we are being called with */\n    skip_to_be_ignored_text(pRExC_state, &p,\n                            FALSE /* Don't force to /x */ );\n\n    /* Disambiguate between \\N meaning a named character versus \\N meaning\n     * [^\\n].  The latter is assumed when the {...} following the \\N is a legal\n     * quantifier, or there is no '{' at all */\n    if (*p != '{' || regcurly(p)) {\n\tRExC_parse = p;\n        if (cp_count) {\n            *cp_count = -1;\n        }\n\n\tif (! node_p) {\n            return FALSE;\n        }\n\n\t*node_p = reg_node(pRExC_state, REG_ANY);\n\t*flagp |= HASWIDTH|SIMPLE;\n\tMARK_NAUGHTY(1);\n        Set_Node_Length(*node_p, 1); /* MJD */\n\treturn TRUE;\n    }\n\n    /* Here, we have decided it should be a named character or sequence */\n\n    /* The test above made sure that the next real character is a '{', but\n     * under the /x modifier, it could be separated by space (or a comment and\n     * \\n) and this is not allowed (for consistency with \\x{...} and the\n     * tokenizer handling of \\N{NAME}). */\n    if (*RExC_parse != '{') {\n\tvFAIL(\"Missing braces on \\\\N{}\");\n    }\n\n    RExC_parse++;\t/* Skip past the '{' */\n\n    endbrace = (char *) memchr(RExC_parse, '}', RExC_end - RExC_parse);\n    if (! endbrace) { /* no trailing brace */\n        vFAIL2(\"Missing right brace on \\\\%c{}\", 'N');\n    }\n    else if (!(   endbrace == RExC_parse\t/* nothing between the {} */\n               || memBEGINs(RExC_parse,   /* U+ (bad hex is checked below\n                                                   for a  better error msg) */\n                                  (STRLEN) (RExC_end - RExC_parse),\n                                 \"U+\")))\n    {\n\tRExC_parse = endbrace;\t/* position msg's '<--HERE' */\n\tvFAIL(\"\\\\N{NAME} must be resolved by the lexer\");\n    }\n\n    REQUIRE_UNI_RULES(flagp, FALSE); /* Unicode named chars imply Unicode\n                                        semantics */\n\n    if (endbrace == RExC_parse) {   /* empty: \\N{} */\n        if (strict) {\n            RExC_parse++;   /* Position after the \"}\" */\n            vFAIL(\"Zero length \\\\N{}\");\n        }\n        if (cp_count) {\n            *cp_count = 0;\n        }\n        nextchar(pRExC_state);\n\tif (! node_p) {\n            return FALSE;\n        }\n\n        *node_p = reg_node(pRExC_state,NOTHING);\n        return TRUE;\n    }\n\n    RExC_parse += 2;\t/* Skip past the 'U+' */\n\n    /* Because toke.c has generated a special construct for us guaranteed not\n     * to have NULs, we can use a str function */\n    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n    /* Code points are separated by dots.  If none, there is only one code\n     * point, and is terminated by the brace */\n\n    if (endchar >= endbrace) {\n\tSTRLEN length_of_hex;\n\tI32 grok_hex_flags;\n\n        /* Here, exactly one code point.  If that isn't what is wanted, fail */\n        if (! code_point_p) {\n            RExC_parse = p;\n            return FALSE;\n        }\n\n        /* Convert code point from hex */\n\tlength_of_hex = (STRLEN)(endchar - RExC_parse);\n\tgrok_hex_flags = PERL_SCAN_ALLOW_UNDERSCORES\n                       | PERL_SCAN_DISALLOW_PREFIX\n\n                           /* No errors in the first pass (See [perl\n                            * #122671].)  We let the code below find the\n                            * errors when there are multiple chars. */\n                       | ((SIZE_ONLY)\n                          ? PERL_SCAN_SILENT_ILLDIGIT\n                          : 0);\n\n        /* This routine is the one place where both single- and double-quotish\n         * \\N{U+xxxx} are evaluated.  The value is a Unicode code point which\n         * must be converted to native. */\n\t*code_point_p = UNI_TO_NATIVE(grok_hex(RExC_parse,\n                                               &length_of_hex,\n                                               &grok_hex_flags,\n                                               NULL));\n\n\t/* The tokenizer should have guaranteed validity, but it's possible to\n         * bypass it by using single quoting, so check.  Don't do the check\n         * here when there are multiple chars; we do it below anyway. */\n        if (length_of_hex == 0\n            || length_of_hex != (STRLEN)(endchar - RExC_parse) )\n        {\n            RExC_parse += length_of_hex;\t/* Includes all the valid */\n            RExC_parse += (RExC_orig_utf8)\t/* point to after 1st invalid */\n                            ? UTF8SKIP(RExC_parse)\n                            : 1;\n            /* Guard against malformed utf8 */\n            if (RExC_parse >= endchar) {\n                RExC_parse = endchar;\n            }\n            vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n        }\n\n        RExC_parse = endbrace + 1;\n        return TRUE;\n    }\n    else {  /* Is a multiple character sequence */\n\tSV * substitute_parse;\n\tSTRLEN len;\n\tchar *orig_end = RExC_end;\n\tchar *save_start = RExC_start;\n        I32 flags;\n\n        /* Count the code points, if desired, in the sequence */\n        if (cp_count) {\n            *cp_count = 0;\n            while (RExC_parse < endbrace) {\n                /* Point to the beginning of the next character in the sequence. */\n                RExC_parse = endchar + 1;\n                endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n                (*cp_count)++;\n            }\n        }\n\n        /* Fail if caller doesn't want to handle a multi-code-point sequence.\n         * But don't backup up the pointer if the caller wants to know how many\n         * code points there are (they can then handle things) */\n        if (! node_p) {\n            if (! cp_count) {\n                RExC_parse = p;\n            }\n            return FALSE;\n        }\n\n\t/* What is done here is to convert this to a sub-pattern of the form\n         * \\x{char1}\\x{char2}...  and then call reg recursively to parse it\n         * (enclosing in \"(?: ... )\" ).  That way, it retains its atomicness,\n         * while not having to worry about special handling that some code\n         * points may have. */\n\n\tsubstitute_parse = newSVpvs(\"?:\");\n\n\twhile (RExC_parse < endbrace) {\n\n\t    /* Convert to notation the rest of the code understands */\n\t    sv_catpv(substitute_parse, \"\\\\x{\");\n\t    sv_catpvn(substitute_parse, RExC_parse, endchar - RExC_parse);\n\t    sv_catpv(substitute_parse, \"}\");\n\n\t    /* Point to the beginning of the next character in the sequence. */\n\t    RExC_parse = endchar + 1;\n\t    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n\t}\n        sv_catpv(substitute_parse, \")\");\n\n        len = SvCUR(substitute_parse);\n\n\t/* Don't allow empty number */\n\tif (len < (STRLEN) 8) {\n            RExC_parse = endbrace;\n\t    vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n\t}\n\n        RExC_parse = RExC_start = RExC_adjusted_start\n                                              = SvPV_nolen(substitute_parse);\n\tRExC_end = RExC_parse + len;\n\n        /* The values are Unicode, and therefore not subject to recoding, but\n         * have to be converted to native on a non-Unicode (meaning non-ASCII)\n         * platform. */\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 1;\n#endif\n\n        *node_p = reg(pRExC_state, 1, &flags, depth+1);\n\n        /* Restore the saved values */\n\tRExC_start = RExC_adjusted_start = save_start;\n\tRExC_parse = endbrace;\n\tRExC_end = orig_end;\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 0;\n#endif\n        SvREFCNT_dec_NN(substitute_parse);\n\n        if (! *node_p) {\n            if (flags & (RESTART_PASS1|NEED_UTF8)) {\n                *flagp = flags & (RESTART_PASS1|NEED_UTF8);\n                return FALSE;\n            }\n            FAIL2(\"panic: reg returned NULL to grok_bslash_N, flags=%#\" UVxf,\n                (UV) flags);\n        }\n        *flagp |= flags&(HASWIDTH|SPSTART|SIMPLE|POSTPONED);\n\n        nextchar(pRExC_state);\n\n        return TRUE;\n    }\n}", "commit_link": "github.com/Perl/perl5/commit/43b2f4ef399e2fd7240b4eeb0658686ad95f8e62", "file_name": "regcomp.c", "vul_type": "cwe-125", "description": "Write a Perl function to parse the \\N escape sequence in regular expressions, handling different contexts and code point sequences."}
{"func_name": "test_create_invalid_host", "func_src_before": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -iscsi -persona 1 -domain '\n                           '(\\'OpenStack\\',) '\n                           'fakehost iqn.1993-08.org.debian:01:222')\n        in_use_ret = pack('\\r\\nalready used by host fakehost.foo ')\n        _run_ssh(create_host_cmd, False).AndReturn([in_use_ret, ''])\n\n        show_3par_cmd = 'showhost -verbose fakehost.foo'\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(ISCSI_3PAR_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "func_src_after": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-iscsi', '-persona', '1', '-domain',\n                           ('OpenStack',), 'fakehost',\n                            'iqn.1993-08.org.debian:01:222'])\n        in_use_ret = pack('\\r\\nalready used by host fakehost.foo ')\n        _run_ssh(create_host_cmd, False).AndReturn([in_use_ret, ''])\n\n        show_3par_cmd = ['showhost', '-verbose', 'fakehost.foo']\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(ISCSI_3PAR_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating a host on an HP 3PAR storage system."}
{"func_name": "lexer_process_char_literal", "func_src_before": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "func_src_after": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "commit_link": "github.com/zherczeg/jerryscript/commit/03a8c630f015f63268639d3ed3bf82cff6fa77d8", "file_name": "jerry-core/parser/js/js-lexer.c", "vul_type": "cwe-476", "description": "In C, write a function to process character literals in a lexer, handling escape sequences and ensuring they don't exceed predefined limits."}
{"func_name": "read_plist", "func_src_before": "    def read_plist(pathname)\n      transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, '')\n      transformed_pathname = pathname if transformed_pathname.nil?\n      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`)\n    end", "func_src_after": "    def read_plist(pathname)\n      out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n      raise \"#{out}\\n\\n#{err}\" unless status.success?\n\n      JSON.parse(out)\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 29, "char_end": 101, "line": "      transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, '')\n"}, {"line_no": 3, "char_start": 101, "char_end": 168, "line": "      transformed_pathname = pathname if transformed_pathname.nil?\n"}, {"line_no": 4, "char_start": 168, "char_end": 240, "line": "      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`)\n"}], "added": [{"line_no": 2, "char_start": 29, "char_end": 120, "line": "      out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n"}, {"line_no": 3, "char_start": 120, "char_end": 174, "line": "      raise \"#{out}\\n\\n#{err}\" unless status.success?\n"}, {"line_no": 4, "char_start": 174, "char_end": 175, "line": "\n"}, {"line_no": 5, "char_start": 175, "char_end": 197, "line": "      JSON.parse(out)\n"}]}, "char_changes": {"deleted": [{"char_start": 35, "char_end": 99, "chars": "transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, ''"}, {"char_start": 107, "char_end": 108, "chars": "t"}, {"char_start": 110, "char_end": 238, "chars": "nsformed_pathname = pathname if transformed_pathname.nil?\n      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`"}], "added": [{"char_start": 35, "char_end": 195, "chars": "out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n      raise \"#{out}\\n\\n#{err}\" unless status.success?\n\n      JSON.parse(out"}]}, "commit_link": "github.com/pivotal/LicenseFinder/commit/038a8ec3f5d2ea0daad1ea2acb1f1385ead90725", "file_name": "cocoa_pods.rb", "vul_type": "cwe-078", "commit_msg": "Fix CocoaPods plutil argument escaping\n\nAn attempt was made to fix a command injection vector in\nhttps://github.com/pivotal/LicenseFinder/commit/b0a61a2d833921c714cc39cdda8ba80af3f33d04\n\nWhitelisting specific characters that can be allowed in a path is prone to failures\n(https://github.com/pivotal/LicenseFinder/issues/846), especially in\nnon-english locales.\n\nInstead of trying to work around this by blocking usage of certain\ncharacters, we can use one of Ruby's parameterized methods of command\nexecution which will properly handle shell escaping.", "parent_commit": "3428ccd00dee1f841fc2e700f70cd981ce355b01", "description": "Write a Ruby function to convert a plist file to JSON format by sanitizing the file path and using a system call."}
{"func_name": "add_user", "func_src_before": "def add_user(username, password):\n    encPass = crypt.crypt(password,\"22\")\n    os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username)", "func_src_after": "def add_user(username, password):\n    encPass = crypt.crypt(password,\"22\")\n    #subprocess escapes the username stopping code injection\n    subprocess.call(['useradd','-G','docker,wheel','-p',encPass,username])", "commit_link": "github.com/Internet-of-People/titania-os/commit/9b7805119938343fcac9dc929d8882f1d97cf14a", "file_name": "vuedj/configtitania/views.py", "vul_type": "cwe-078", "description": "Write a Python function named `add_user` that creates a new system user with a password and adds them to the 'docker' and 'wheel' groups."}
{"func_name": "gitMtime", "func_src_before": "async function gitMtime(path) {\n  const { stdout } = await execFilePromise('git', ['log', '-1', '--format=\"%at\"', '--', path]);\n\n  return parseInt(stdout.trim().replace('\"', '').trim(), 10);\n}", "func_src_after": "async function gitMtime(path) {\n  const { stdout } = await execFilePromise('git', ['log', '-1', '--format=\"%at\"', '--', path]);\n\n  return parseInt(stdout.trim().replace(/\"/g, '').trim(), 10);\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 129, "char_end": 191, "line": "  return parseInt(stdout.trim().replace('\"', '').trim(), 10);\n"}], "added": [{"line_no": 4, "char_start": 129, "char_end": 192, "line": "  return parseInt(stdout.trim().replace(/\"/g, '').trim(), 10);\n"}]}, "char_changes": {"deleted": [{"char_start": 169, "char_end": 172, "chars": "'\"'"}], "added": [{"char_start": 169, "char_end": 173, "chars": "/\"/g"}]}, "commit_link": "github.com/openfoodfacts/openfoodfacts-server/commit/7917218c34b5ae2afe5d6581416c944607e31f36", "file_name": "refresh_taxonomies.js", "vul_type": "cwe-116", "commit_msg": "fix: CWE-116/CWE-20\n\nhttps://github.com/openfoodfacts/openfoodfacts-server/security/code-scanning/4", "parent_commit": "40386e19d82ff72f27066cb2bcbdf539dca0c6be", "description": "Create an asynchronous JavaScript function that retrieves the last modification timestamp of a file using Git."}
{"func_name": "add_article_action", "func_src_before": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = request.POST[\"notes\"]\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "func_src_after": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = escape(request.POST[\"notes\"])\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = escape(str(request.POST[str(\"notes_\" + str(art.id))]))\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/reservation_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle adding single or multiple articles to a reservation, with redirection and error handling."}
{"func_name": "exports.rsync", "func_src_before": "exports.rsync = function (options,callback) {\n\n    options = options || {};\n\n    if ( typeof options.src === \"undefined\" ) {\n        throw(new Error(\"Source directory 'src' is missing from options\"));\n    }\n\n    if ( typeof options.dest === \"undefined\" ) {\n        throw(new Error(\"Destination directory 'dest' is missing from options\"));\n    }\n\n    if ( typeof options.host !== \"undefined\" ) {\n        options.dest = options.host+\":\"+options.dest;\n    }\n\n    var args = [options.src,options.dest];\n\n    if ( typeof options.host !== \"undefined\" ) {\n        args.push(\"--rsh=ssh\");\n    }\n\n    if ( options.recursive === true ) {\n        args.push(\"--recursive\");\n    }\n\n    if ( options.syncDest === true ) {\n        args.push(\"--delete\");\n        args.push(\"--delete-excluded\");\n    }\n\n    if ( options.dryRun === true ) {\n        args.push(\"--dry-run\");\n        args.push(\"--verbose\");\n        args.push(\"--stats\");\n    }\n\n    if ( typeof options.exclude !== \"undefined\" && util.isArray(options.exclude) ) {\n        options.exclude.forEach(function (value,index) {\n            args.push(\"--exclude=\"+value);\n        });\n    }\n\n    switch ( options.compareMode ) {\n        case \"sizeOnly\":\n            args.push(\"--size-only\");\n            break;\n        case \"checksum\":\n            args.push(\"--checksum\");\n            break;\n    }\n\n    if ( typeof options.args !== \"undefined\" && util.isArray(options.args) ) {\n        args = _.union(args,options.args);\n    }\n\n    args = _.unique(args);\n\n    var cmd = \"rsync \"+args.join(\" \");\n\n    try {\n        exec(cmd,function (error,stdout,stderr) {\n            callback(error,stdout,stderr,cmd);\n        });\n    } catch (error) {\n        callback(error,null,null,cmd);\n    }\n};", "func_src_after": "exports.rsync = function (options,callback) {\n\n    options = options || {};\n\n    if ( typeof options.src === \"undefined\" ) {\n        throw(new Error(\"Source directory 'src' is missing from options\"));\n    }\n\n    if ( typeof options.dest === \"undefined\" ) {\n        throw(new Error(\"Destination directory 'dest' is missing from options\"));\n    }\n\n    if ( typeof options.host !== \"undefined\" ) {\n        options.dest = options.host+\":\"+options.dest;\n    }\n\n    var args = [options.src,options.dest];\n\n    if ( typeof options.host !== \"undefined\" ) {\n        args.push(\"--rsh=ssh\");\n    }\n\n    if ( options.recursive === true ) {\n        args.push(\"--recursive\");\n    }\n\n    if ( options.syncDest === true ) {\n        args.push(\"--delete\");\n        args.push(\"--delete-excluded\");\n    }\n\n    if ( options.dryRun === true ) {\n        args.push(\"--dry-run\");\n        args.push(\"--verbose\");\n        args.push(\"--stats\");\n    }\n\n    if ( typeof options.exclude !== \"undefined\" && util.isArray(options.exclude) ) {\n        options.exclude.forEach(function (value,index) {\n            args.push(\"--exclude=\"+value);\n        });\n    }\n\n    switch ( options.compareMode ) {\n        case \"sizeOnly\":\n            args.push(\"--size-only\");\n            break;\n        case \"checksum\":\n            args.push(\"--checksum\");\n            break;\n    }\n\n    if ( typeof options.args !== \"undefined\" && util.isArray(options.args) ) {\n        args = _.union(args,options.args);\n    }\n    \n    args = _.unique(args);   \n\n    var cmd = \"rsync \"+args.join(\" \");\n\n    try {\n        var process = spawn('rsync', args);\n\t\tvar stdoutBuffer = ''\n\t\tvar stderrBuffer = '';\n\n\t\tprocess.stdout.on('data', function (data) {\n\t\t\tstdoutBuffer += data;\t\t\n\t\t});\n\n\t\tprocess.stderr.on('data', function (data) {\n\t\t\tstderrBuffer += data;\n\t\t});\n\n        process.on('exit', function (errorCode) {\n            if(errorCode===0) errorCode=null;\n            callback(errorCode,stdoutBuffer,stderrBuffer,cmd);\n        });\n    } catch (error) {\n        callback(error,null,null,cmd);\n    }\n};", "line_changes": {"deleted": [{"line_no": 56, "char_start": 1463, "char_end": 1464, "line": "\n"}, {"line_no": 57, "char_start": 1464, "char_end": 1491, "line": "    args = _.unique(args);\n"}, {"line_no": 62, "char_start": 1542, "char_end": 1592, "line": "        exec(cmd,function (error,stdout,stderr) {\n"}, {"line_no": 63, "char_start": 1592, "char_end": 1639, "line": "            callback(error,stdout,stderr,cmd);\n"}], "added": [{"line_no": 56, "char_start": 1463, "char_end": 1468, "line": "    \n"}, {"line_no": 57, "char_start": 1468, "char_end": 1498, "line": "    args = _.unique(args);   \n"}, {"line_no": 62, "char_start": 1549, "char_end": 1593, "line": "        var process = spawn('rsync', args);\n"}, {"line_no": 63, "char_start": 1593, "char_end": 1617, "line": "\t\tvar stdoutBuffer = ''\n"}, {"line_no": 64, "char_start": 1617, "char_end": 1642, "line": "\t\tvar stderrBuffer = '';\n"}, {"line_no": 65, "char_start": 1642, "char_end": 1643, "line": "\n"}, {"line_no": 66, "char_start": 1643, "char_end": 1689, "line": "\t\tprocess.stdout.on('data', function (data) {\n"}, {"line_no": 67, "char_start": 1689, "char_end": 1716, "line": "\t\t\tstdoutBuffer += data;\t\t\n"}, {"line_no": 68, "char_start": 1716, "char_end": 1722, "line": "\t\t});\n"}, {"line_no": 69, "char_start": 1722, "char_end": 1723, "line": "\n"}, {"line_no": 70, "char_start": 1723, "char_end": 1769, "line": "\t\tprocess.stderr.on('data', function (data) {\n"}, {"line_no": 71, "char_start": 1769, "char_end": 1794, "line": "\t\t\tstderrBuffer += data;\n"}, {"line_no": 72, "char_start": 1794, "char_end": 1800, "line": "\t\t});\n"}, {"line_no": 73, "char_start": 1800, "char_end": 1801, "line": "\n"}, {"line_no": 74, "char_start": 1801, "char_end": 1851, "line": "        process.on('exit', function (errorCode) {\n"}, {"line_no": 75, "char_start": 1851, "char_end": 1897, "line": "            if(errorCode===0) errorCode=null;\n"}, {"line_no": 76, "char_start": 1897, "char_end": 1960, "line": "            callback(errorCode,stdoutBuffer,stderrBuffer,cmd);\n"}]}, "char_changes": {"deleted": [{"char_start": 1550, "char_end": 1591, "chars": "exec(cmd,function (error,stdout,stderr) {"}, {"char_start": 1625, "char_end": 1631, "chars": ",stder"}], "added": [{"char_start": 1463, "char_end": 1467, "chars": "    "}, {"char_start": 1494, "char_end": 1497, "chars": "   "}, {"char_start": 1557, "char_end": 1896, "chars": "var process = spawn('rsync', args);\n\t\tvar stdoutBuffer = ''\n\t\tvar stderrBuffer = '';\n\n\t\tprocess.stdout.on('data', function (data) {\n\t\t\tstdoutBuffer += data;\t\t\n\t\t});\n\n\t\tprocess.stderr.on('data', function (data) {\n\t\t\tstderrBuffer += data;\n\t\t});\n\n        process.on('exit', function (errorCode) {\n            if(errorCode===0) errorCode=null;"}, {"char_start": 1923, "char_end": 1927, "chars": "Code"}, {"char_start": 1934, "char_end": 1952, "chars": "Buffer,stderrBuffe"}]}, "commit_link": "github.com/HaroldPutman/rsyncwrapper/commit/a763cc4a929805b977a278148e246234340e6af7", "file_name": "rsyncwrapper.js", "vul_type": "cwe-078", "commit_msg": "Changed child_process exec to spawn\n\nTo fix 'maxBuffer' exceeding issues on very large stdout responses. Attempted to maintain the same callback methods by buffering the stout and std err. Only errorCodes are passed and not error Signals.", "description": "Write a Node.js function in JavaScript that performs a customizable rsync operation with error handling."}
{"func_name": "clean_taxon_concept", "func_src_before": "  def clean_taxon_concept\n    taxon_concept.gsub(\"\\n\",\" \").gsub(\"\\'\", \"\\\\\\'\")\n  end", "func_src_after": "  def clean_taxon_concept\n    taxon_concept.gsub(\"\\n\", ' ').gsub(\"\\'\", \"\\\\\\'\")\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 78, "line": "    taxon_concept.gsub(\"\\n\",\" \").gsub(\"\\'\", \"\\\\\\'\")\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 79, "line": "    taxon_concept.gsub(\"\\n\", ' ').gsub(\"\\'\", \"\\\\\\'\")\n"}]}, "char_changes": {"deleted": [{"char_start": 54, "char_end": 57, "chars": "\" \""}], "added": [{"char_start": 54, "char_end": 58, "chars": " ' '"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Write a Ruby function named `clean_taxon_concept` that replaces newline characters with spaces and escapes single quotes in a string."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = markdown(self.object.content,\n                                 extensions=[\n                                     'markdown.extensions.extra',\n                                     'markdown.extensions.codehilite',\n                                     'markdown.extensions.toc',\n                                 ])\n\n        return context", "func_src_after": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = safe_md(self.object.content)\n\n        return context", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function to enhance the context data with comments, a form, and processed markdown content for a web page."}
{"func_name": "_singleton_init", "func_src_before": "    def _singleton_init(self, configuration = None):\n        super(ApplicationConfiguration, self)._singleton_init()\n        self.log = logging.getLogger('%s.%s' % (__name__, self.__class__.__name__))\n        self.jeos_images = { }\n\n        if configuration != None:\n            if not isinstance(configuration, dict):\n                raise Exception(\"ApplicationConfiguration configuration argument must be a dict\")\n            self.log.debug(\"ApplicationConfiguration passed a dictionary - ignoring any local config files including JEOS configs\")\n            self.configuration = configuration\n        else:\n            self.configuration = self.__parse_arguments()\n            self.__parse_jeos_images()\n\n        if not 'debug' in self.configuration:\n            if 'nodebug' in self.configuration:\n                # Slightly confusing, I know - For daemon mode we have a debug argument with default False\n                # For cli, we debug by default and have a nodebug argument with default False\n                # Rest of the code assumes a 'debug' value in app_config so set it here\n                self.configuration['debug'] = not self.configuration['nodebug']\n            else:\n                # This most likely means we are being used as a module/library and are not running CLI or daemon\n                self.configuration['debug'] = False\n\n        if not 'secondary' in self.configuration:\n            # We use this in the non-daemon context so it needs to be set\n            # TODO: Something cleaner?\n            self.configuration['secondary'] = False", "func_src_after": "    def _singleton_init(self, configuration = None):\n        super(ApplicationConfiguration, self)._singleton_init()\n        self.log = logging.getLogger('%s.%s' % (__name__, self.__class__.__name__))\n        self.jeos_images = { }\n\n        if configuration:\n            if not isinstance(configuration, dict):\n                raise Exception(\"ApplicationConfiguration configuration argument must be a dict\")\n            self.log.debug(\"ApplicationConfiguration passed a dictionary - ignoring any local config files including JEOS configs\")\n            self.configuration = configuration\n        else:\n            self.configuration = self.__parse_arguments()\n            self.__parse_jeos_images()\n\n        if not 'debug' in self.configuration:\n            if 'nodebug' in self.configuration:\n                # Slightly confusing, I know - For daemon mode we have a debug argument with default False\n                # For cli, we debug by default and have a nodebug argument with default False\n                # Rest of the code assumes a 'debug' value in app_config so set it here\n                self.configuration['debug'] = not self.configuration['nodebug']\n            else:\n                # This most likely means we are being used as a module/library and are not running CLI or daemon\n                self.configuration['debug'] = False\n\n        if not 'secondary' in self.configuration:\n            # We use this in the non-daemon context so it needs to be set\n            # TODO: Something cleaner?\n            self.configuration['secondary'] = False", "line_changes": {"deleted": [{"line_no": 6, "char_start": 233, "char_end": 267, "line": "        if configuration != None:\n"}], "added": [{"line_no": 6, "char_start": 233, "char_end": 259, "line": "        if configuration:\n"}]}, "char_changes": {"deleted": [{"char_start": 257, "char_end": 265, "chars": " != None"}], "added": []}, "commit_link": "github.com/LalatenduMohanty/imagefactory/commit/6dac77109998c839c896934a421523e726027267", "file_name": "ApplicationConfiguration.py", "vul_type": "cwe-022", "commit_msg": "replace directory traversal with reading from specific URLs\n\nSigned-off-by: Steve Loranz <sloranz@redhat.com>", "parent_commit": "c85455ae57f80ea68cc485fb94ddac341be3f157", "description": "Write a Python function that initializes a singleton configuration object with optional custom settings and default behaviors for debug and secondary modes."}
{"func_name": "HPHP::exif_scan_JPEG_header", "func_src_before": "static int exif_scan_JPEG_header(image_info_type *ImageInfo) {\n  int section, sn;\n  int marker = 0, last_marker = M_PSEUDO, comment_correction=1;\n  int ll, lh;\n  unsigned char *Data;\n  size_t fpos, size, got, itemlen;\n  jpeg_sof_info  sof_info;\n\n  for(section=0;;section++) {\n    // get marker byte, swallowing possible padding\n    // some software does not count the length bytes of COM section\n    // one company doing so is very much envolved in JPEG...\n    // so we accept too\n    if (last_marker==M_COM && comment_correction) {\n      comment_correction = 2;\n    }\n    do {\n      if ((marker = ImageInfo->infile->getc()) == EOF) {\n        raise_warning(\"File structure corrupted\");\n        return 0;\n      }\n      if (last_marker==M_COM && comment_correction>0) {\n        if (marker!=0xFF) {\n          marker = 0xff;\n          comment_correction--;\n        } else  {\n          last_marker = M_PSEUDO; /* stop skipping 0 for M_COM */\n        }\n      }\n    } while (marker == 0xff);\n    if (last_marker==M_COM && !comment_correction) {\n      raise_notice(\"Image has corrupt COM section: some software set \"\n                   \"wrong length information\");\n    }\n    if (last_marker==M_COM && comment_correction)\n      return M_EOI; /* ah illegal: char after COM section not 0xFF */\n\n    fpos = ImageInfo->infile->tell();\n\n    if (marker == 0xff) {\n      // 0xff is legal padding, but if we get that many, something's wrong.\n      raise_warning(\"To many padding bytes\");\n      return 0;\n    }\n\n    /* Read the length of the section. */\n\n    if ((lh = ImageInfo->infile->getc()) == EOF) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    if ((ll = ImageInfo->infile->getc()) == EOF) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    itemlen = (lh << 8) | ll;\n\n    if (itemlen < 2) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    sn = exif_file_sections_add(ImageInfo, marker, itemlen+1, nullptr);\n    if (sn == -1) return 0;\n    Data = ImageInfo->file.list[sn].data;\n\n    /* Store first two pre-read bytes. */\n    Data[0] = (unsigned char)lh;\n    Data[1] = (unsigned char)ll;\n\n    String str = ImageInfo->infile->read(itemlen-2);\n    got = str.length();\n    if (got != itemlen-2) {\n      raise_warning(\"Error reading from file: \"\n                      \"got=x%04lX(=%lu) != itemlen-2=x%04lX(=%lu)\",\n                      got, got, itemlen-2, itemlen-2);\n      return 0;\n    }\n    memcpy(Data+2, str.c_str(), got);\n    switch(marker) {\n      case M_SOS:   /* stop before hitting compressed data  */\n        // If reading entire image is requested, read the rest of the data.\n        if (ImageInfo->read_all) {\n          /* Determine how much file is left. */\n          fpos = ImageInfo->infile->tell();\n          size = ImageInfo->FileSize - fpos;\n          sn = exif_file_sections_add(ImageInfo, M_PSEUDO, size, nullptr);\n          if (sn == -1) return 0;\n          Data = ImageInfo->file.list[sn].data;\n          str = ImageInfo->infile->read(size);\n          got = str.length();\n          if (got != size) {\n            raise_warning(\"Unexpected end of file reached\");\n            return 0;\n          }\n          memcpy(Data, str.c_str(), got);\n        }\n        return 1;\n\n      case M_EOI:   /* in case it's a tables-only JPEG stream */\n        raise_warning(\"No image in jpeg!\");\n        return (ImageInfo->sections_found&(~FOUND_COMPUTED)) ? 1 : 0;\n\n      case M_COM: /* Comment section */\n        exif_process_COM(ImageInfo, (char *)Data, itemlen);\n        break;\n\n      case M_EXIF:\n        if (!(ImageInfo->sections_found&FOUND_IFD0)) {\n          /*ImageInfo->sections_found |= FOUND_EXIF;*/\n          /* Seen files from some 'U-lead' software with Vivitar scanner\n             that uses marker 31 later in the file (no clue what for!) */\n          exif_process_APP1(ImageInfo, (char *)Data, itemlen, fpos);\n        }\n        break;\n\n      case M_APP12:\n        exif_process_APP12(ImageInfo, (char *)Data, itemlen);\n        break;\n\n\n      case M_SOF0:\n      case M_SOF1:\n      case M_SOF2:\n      case M_SOF3:\n      case M_SOF5:\n      case M_SOF6:\n      case M_SOF7:\n      case M_SOF9:\n      case M_SOF10:\n      case M_SOF11:\n      case M_SOF13:\n      case M_SOF14:\n      case M_SOF15:\n        exif_process_SOFn(Data, marker, &sof_info);\n        ImageInfo->Width  = sof_info.width;\n        ImageInfo->Height = sof_info.height;\n        if (sof_info.num_components == 3) {\n          ImageInfo->IsColor = 1;\n        } else {\n          ImageInfo->IsColor = 0;\n        }\n        break;\n      default:\n        /* skip any other marker silently. */\n        break;\n    }\n\n    /* keep track of last marker */\n    last_marker = marker;\n  }\n  return 1;\n}", "func_src_after": "static int exif_scan_JPEG_header(image_info_type *ImageInfo) {\n  int section, sn;\n  int marker = 0, last_marker = M_PSEUDO, comment_correction=1;\n  int ll, lh;\n  unsigned char *Data;\n  size_t fpos, size, got, itemlen;\n  jpeg_sof_info  sof_info;\n\n  for(section=0;;section++) {\n    // get marker byte, swallowing possible padding\n    // some software does not count the length bytes of COM section\n    // one company doing so is very much envolved in JPEG...\n    // so we accept too\n    if (last_marker==M_COM && comment_correction) {\n      comment_correction = 2;\n    }\n    do {\n      if ((marker = ImageInfo->infile->getc()) == EOF) {\n        raise_warning(\"File structure corrupted\");\n        return 0;\n      }\n      if (last_marker==M_COM && comment_correction>0) {\n        if (marker!=0xFF) {\n          marker = 0xff;\n          comment_correction--;\n        } else  {\n          last_marker = M_PSEUDO; /* stop skipping 0 for M_COM */\n        }\n      }\n    } while (marker == 0xff);\n    if (last_marker==M_COM && !comment_correction) {\n      raise_notice(\"Image has corrupt COM section: some software set \"\n                   \"wrong length information\");\n    }\n    if (last_marker==M_COM && comment_correction)\n      return M_EOI; /* ah illegal: char after COM section not 0xFF */\n\n    fpos = ImageInfo->infile->tell();\n\n    if (marker == 0xff) {\n      // 0xff is legal padding, but if we get that many, something's wrong.\n      raise_warning(\"To many padding bytes\");\n      return 0;\n    }\n\n    /* Read the length of the section. */\n\n    if ((lh = ImageInfo->infile->getc()) == EOF) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    if ((ll = ImageInfo->infile->getc()) == EOF) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    itemlen = (lh << 8) | ll;\n\n    if (itemlen < 2) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    sn = exif_file_sections_add(ImageInfo, marker, itemlen+1, nullptr);\n    if (sn == -1) return 0;\n    Data = ImageInfo->file.list[sn].data;\n\n    /* Store first two pre-read bytes. */\n    Data[0] = (unsigned char)lh;\n    Data[1] = (unsigned char)ll;\n\n    String str = ImageInfo->infile->read(itemlen-2);\n    got = str.length();\n    if (got != itemlen-2) {\n      raise_warning(\"Error reading from file: \"\n                      \"got=x%04lX(=%lu) != itemlen-2=x%04lX(=%lu)\",\n                      got, got, itemlen-2, itemlen-2);\n      return 0;\n    }\n    memcpy(Data+2, str.c_str(), got);\n    switch(marker) {\n      case M_SOS:   /* stop before hitting compressed data  */\n        // If reading entire image is requested, read the rest of the data.\n        if (ImageInfo->read_all) {\n          /* Determine how much file is left. */\n          fpos = ImageInfo->infile->tell();\n          size = ImageInfo->FileSize - fpos;\n          sn = exif_file_sections_add(ImageInfo, M_PSEUDO, size, nullptr);\n          if (sn == -1) return 0;\n          Data = ImageInfo->file.list[sn].data;\n          str = ImageInfo->infile->read(size);\n          got = str.length();\n          if (got != size) {\n            raise_warning(\"Unexpected end of file reached\");\n            return 0;\n          }\n          memcpy(Data, str.c_str(), got);\n        }\n        return 1;\n\n      case M_EOI:   /* in case it's a tables-only JPEG stream */\n        raise_warning(\"No image in jpeg!\");\n        return (ImageInfo->sections_found&(~FOUND_COMPUTED)) ? 1 : 0;\n\n      case M_COM: /* Comment section */\n        exif_process_COM(ImageInfo, (char *)Data, itemlen);\n        break;\n\n      case M_EXIF:\n        if (!(ImageInfo->sections_found&FOUND_IFD0)) {\n          /*ImageInfo->sections_found |= FOUND_EXIF;*/\n          /* Seen files from some 'U-lead' software with Vivitar scanner\n             that uses marker 31 later in the file (no clue what for!) */\n          exif_process_APP1(ImageInfo, (char *)Data, itemlen, fpos);\n        }\n        break;\n\n      case M_APP12:\n        exif_process_APP12(ImageInfo, (char *)Data, itemlen);\n        break;\n\n\n      case M_SOF0:\n      case M_SOF1:\n      case M_SOF2:\n      case M_SOF3:\n      case M_SOF5:\n      case M_SOF6:\n      case M_SOF7:\n      case M_SOF9:\n      case M_SOF10:\n      case M_SOF11:\n      case M_SOF13:\n      case M_SOF14:\n      case M_SOF15:\n        if ((itemlen - 2) < 6) {\n          return 0;\n        }\n\n        exif_process_SOFn(Data, marker, &sof_info);\n        ImageInfo->Width  = sof_info.width;\n        ImageInfo->Height = sof_info.height;\n        if (sof_info.num_components == 3) {\n          ImageInfo->IsColor = 1;\n        } else {\n          ImageInfo->IsColor = 0;\n        }\n        break;\n      default:\n        /* skip any other marker silently. */\n        break;\n    }\n\n    /* keep track of last marker */\n    last_marker = marker;\n  }\n  return 1;\n}", "commit_link": "github.com/facebook/hhvm/commit/f9680d21beaa9eb39d166e8810e29fbafa51ad15", "file_name": "hphp/runtime/ext/gd/ext_gd.cpp", "vul_type": "cwe-125", "description": "Write a C++ function to scan and process JPEG header markers for an image file."}
{"func_name": "run", "func_src_before": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tMemoryInstance* defaultMemory = Runtime::getDefaultMemory(moduleInstance);\n\t\t\tif(!defaultMemory)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\n\t\t\tstd::vector<const char*> argStrings;\n\t\t\targStrings.push_back(options.filename);\n\t\t\tchar** args = options.args;\n\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "func_src_after": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tif(!emscriptenInstance)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::vector<const char*> argStrings;\n\t\t\t\targStrings.push_back(options.filename);\n\t\t\t\tchar** args = options.args;\n\t\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\t\twavmAssert(emscriptenInstance);\n\t\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t\t}\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "commit_link": "github.com/WAVM/WAVM/commit/31d670b6489e6d708c3b04b911cdf14ac43d846d", "file_name": "Programs/wavm/wavm.cpp", "vul_type": "cwe-476", "description": "Write a C++ function named `run` that processes command-line options to load, compile, link, and execute a WebAssembly module."}
{"func_name": "update_title", "func_src_before": "  def update_title(self, title = None):\n    if (not self.title):\n      self.title = title\n\n    # This will fall to a sql injection \n    sql = \"UPDATE jdk_entries SET title = '\" + self.title + \"'\" + \\\n          \"WHERE jdk_entries.id = '\" + self.entry_id + \"';\" \n\n    db_execute(sql)\n    \n    self.update_date_modified()\n\n    return None", "func_src_after": "  def update_title(self, title = None):\n    if (not self.title):\n      self.title = title\n\n    quote_tuple = self.title, self.entry_id\n\n    # This will fall to a sql injection \n    sql = \"UPDATE jdk_entries SET title = ?\" + \\\n          \"WHERE jdk_entries.id = ?;\" \n\n    db_execute(sql, quote_tuple)\n    \n    self.update_date_modified()\n\n    return None", "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089", "description": "Write a Python function to update the title of a database entry with basic SQL injection vulnerability and a version with parameterized query protection."}
{"func_name": "talk", "func_src_before": "def talk(myText):\r\n    if( myText.find( \"twitter\" ) >= 0 ):\r\n        myText += \"0\"\r\n        myText = myText[7:-1]\r\n        try:\r\n\t    myText = twitter.getTweet( myText )\r\n\texcept:\r\n\t    print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r\n            return\r\n    \r\n    os.system( \"espeak \\\",...\\\" 2>/dev/null\" ) # Sometimes the beginning of audio can get cut off. Insert silence.\r\n    time.sleep( 0.5 )\r\n    os.system( \"espeak -w speech.wav \\\"\" + myText + \"\\\" -s 130\" )\r\n    audio.play(\"speech.wav\")\r\n    return myText", "func_src_after": "def talk(myText):\r\n    if( myText.find( \"twitter\" ) >= 0 ):\r\n        myText += \"0\"\r\n        myText = myText[7:-1]\r\n        try:\r\n\t    myText = twitter.getTweet( myText )\r\n\texcept:\r\n\t    print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r\n            return\r\n    \r\n    os.system( \"espeak \\\",...\\\" 2>/dev/null\" ) # Sometimes the beginning of audio can get cut off. Insert silence.\r\n    time.sleep( 0.5 )\r\n    subprocess.call([\"espeak\", \"-w\", \"speech.wav\", myText, \"-s\", \"130\"])\r\n    audio.play(\"speech.wav\")\r\n    return myText", "commit_link": "github.com/ntc-chip-revived/ChippyRuxpin/commit/0cd7d78e4d806852fd75fee03c24cce322f76014", "file_name": "chippyRuxpin.py", "vul_type": "cwe-078", "description": "Create a Python function named `talk` that processes a string to fetch a tweet if it contains the word \"twitter\" and then uses the `espeak` tool to convert the text to speech, saving it to a WAV file before playing it."}
{"func_name": "get_login2", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a function that handles a login message for a bot, checks the username, interacts with a SQLite database, and updates the user's state."}
{"func_name": "(anonymous)", "func_src_before": "\t\texec('node ' + binPath + ' -v -', function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "func_src_after": "\t\texecFile('node', [binPath, '-v', '-'], function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 69, "line": "\t\texec('node ' + binPath + ' -v -', function (err, stdout, stderr) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 74, "line": "\t\texecFile('node', [binPath, '-v', '-'], function (err, stdout, stderr) {\n"}]}, "char_changes": {"deleted": [{"char_start": 12, "char_end": 17, "chars": " ' + "}, {"char_start": 24, "char_end": 26, "chars": " +"}, {"char_start": 28, "char_end": 29, "chars": " "}, {"char_start": 31, "char_end": 32, "chars": " "}], "added": [{"char_start": 6, "char_end": 10, "chars": "File"}, {"char_start": 16, "char_end": 20, "chars": "', ["}, {"char_start": 27, "char_end": 28, "chars": ","}, {"char_start": 32, "char_end": 36, "chars": "', '"}, {"char_start": 38, "char_end": 39, "chars": "]"}]}, "commit_link": "github.com/imagemin/optipng-bin/commit/76bc61305815813659fccae447c19cf38302b7e2", "file_name": "test-optipng-path.js", "vul_type": "cwe-078", "commit_msg": "use execFile and arguments array instead of string concat", "parent_commit": "fffe11371341e0360ecde090cf6f2bac5d81505a", "description": "Write a JavaScript function that executes a command to check for 'OptiPNG' in the error output and calls a callback function."}
{"func_name": "test_get_iscsi_ip", "func_src_before": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = 'showvlun -a -host fakehost'\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = 'showvlun -a -showcols Port'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "func_src_after": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = ['showvlun', '-a', '-host', 'fakehost']\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = ['showvlun', '-a', '-showcols', 'Port']\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands to retrieve iSCSI IP information and asserts the expected IP address."}
{"func_name": "imcb_file_send_start", "func_src_before": "file_transfer_t *imcb_file_send_start(struct im_connection *ic, char *handle, char *file_name, size_t file_size)\n{\n\tbee_t *bee = ic->bee;\n\tbee_user_t *bu = bee_user_by_handle(bee, ic, handle);\n\n\tif (bee->ui->ft_in_start) {\n\t\treturn bee->ui->ft_in_start(bee, bu, file_name, file_size);\n\t} else {\n\t\treturn NULL;\n\t}\n}", "func_src_after": "file_transfer_t *imcb_file_send_start(struct im_connection *ic, char *handle, char *file_name, size_t file_size)\n{\n\tbee_t *bee = ic->bee;\n\tbee_user_t *bu = bee_user_by_handle(bee, ic, handle);\n\n\tif (bee->ui->ft_in_start && bu) {\n\t\treturn bee->ui->ft_in_start(bee, bu, file_name, file_size);\n\t} else {\n\t\treturn NULL;\n\t}\n}", "commit_link": "github.com/bitlbee/bitlbee/commit/701ab8129ba9ea64f569daedca9a8603abad740f", "file_name": "protocols/bee_ft.c", "vul_type": "cwe-476", "description": "Write a C function named `imcb_file_send_start` that initiates a file transfer if possible, returning a pointer to the transfer structure or NULL."}
{"func_name": "dd_delete_item", "func_src_before": "int dd_delete_item(struct dump_dir *dd, const char *name)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *path = concat_path_file(dd->dd_dirname, name);\n    int res = unlink(path);\n\n    if (res < 0)\n    {\n        if (errno == ENOENT)\n            errno = res = 0;\n        else\n            perror_msg(\"Can't delete file '%s'\", path);\n    }\n\n    free(path);\n    return res;\n}", "func_src_after": "int dd_delete_item(struct dump_dir *dd, const char *name)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot delete item. '%s' is not a valid file name\", name);\n\n    char *path = concat_path_file(dd->dd_dirname, name);\n    int res = unlink(path);\n\n    if (res < 0)\n    {\n        if (errno == ENOENT)\n            errno = res = 0;\n        else\n            perror_msg(\"Can't delete file '%s'\", path);\n    }\n\n    free(path);\n    return res;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_delete_item` that deletes a file with error handling for an unlocked directory and invalid filenames."}
{"func_name": "delete_playlist", "func_src_before": "def delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id={id};\".format(id=id))", "func_src_after": "def delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id=%s;\", (id,))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089", "description": "Write a Python function named `delete_playlist` that removes a playlist by its ID from a database."}
{"func_name": "get_git_branch", "func_src_before": "get_git_branch(wchar_t *dst, size_t size)\n{\n\tFILE *fp;\n\tchar *c;\n\tchar pwd[MAXPATHLEN];\n\tchar candidate[MAXPATHLEN];\n\tchar buf[MAX_BRANCH_LEN];\n\tsize_t s;\n\tstruct stat bufstat;\n\tint found_repo = -1;\n\n\t/* start from the working dir */\n\tstrlcpy(pwd, getcwd(NULL, MAXPATHLEN), MAXPATHLEN);\n\n\tdo {\n\t\tsnprintf(candidate, MAXPATHLEN, \"%s/.git/HEAD\", pwd);\n\n\t\tfound_repo = stat(candidate, &bufstat);\n\n\t\tif ((c = strrchr(pwd, '/')) == NULL)\n\t\t\tbreak;\n\n\t\t*c = '\\0';\n\t} while (found_repo != 0 && candidate[1] != '\\0');\n\n\tif (found_repo == -1)\n\t\treturn 0;\n\n\tfp = fopen(candidate, \"r\");\n\tif (fp == NULL) {\n\t\tstrlcpy(buf, \"###\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\ts = fread(buf, 1, size, fp);\n\tfclose(fp);\n\n\tbuf[MAX_BRANCH_LEN] = '\\0';\n\n\t/* This is a branch head, just print the branch. */\n\tif (strncmp(buf, \"ref: refs/heads/\", 16) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl)\n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 16;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* Show all other kinds of ref as-is (does it even exist?) */\n\tif (strncmp(buf, \"ref:\", 4) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl) \n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 5;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* That's probably just a changeset, just show the first 6 chars */\n\tif (s > 6) {\n\t\tstrlcpy(buf + 6, \"...\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\t/* We shouldn't get there, but we mind as well no crash. */\n\tstrlcpy(buf, \"???\", 4);\n\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n}", "func_src_after": "get_git_branch(wchar_t *dst, size_t size)\n{\n\tFILE *fp;\n\tchar *c;\n\tchar pwd[MAXPATHLEN];\n\tchar candidate[MAXPATHLEN];\n\tchar buf[MAX_BRANCH_LEN];\n\tsize_t s;\n\tstruct stat bufstat;\n\tint found_repo = -1;\n\n\t/* start from the working dir */\n\tstrlcpy(pwd, getcwd(NULL, MAXPATHLEN), MAXPATHLEN);\n\n\tdo {\n\t\tsnprintf(candidate, MAXPATHLEN, \"%s/.git/HEAD\", pwd);\n\n\t\tfound_repo = stat(candidate, &bufstat);\n\n\t\tif ((c = strrchr(pwd, '/')) == NULL)\n\t\t\tbreak;\n\n\t\t*c = '\\0';\n\t} while (found_repo != 0 && candidate[1] != '\\0');\n\n\tif (found_repo == -1)\n\t\treturn 0;\n\n\tfp = fopen(candidate, \"r\");\n\tif (fp == NULL) {\n\t\tstrlcpy(buf, \"###\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\ts = fread(buf, 1, size, fp);\n\tfclose(fp);\n\n\tbuf[MAX_BRANCH_LEN - 1] = '\\0';\n\n\t/* This is a branch head, just print the branch. */\n\tif (strncmp(buf, \"ref: refs/heads/\", 16) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl)\n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 16;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* Show all other kinds of ref as-is (does it even exist?) */\n\tif (strncmp(buf, \"ref:\", 4) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl) \n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 5;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* That's probably just a changeset, just show the first 6 chars */\n\tif (s > 6) {\n\t\tstrlcpy(buf + 6, \"...\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\t/* We shouldn't get there, but we mind as well no crash. */\n\tstrlcpy(buf, \"???\", 4);\n\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n}", "line_changes": {"deleted": [{"line_no": 38, "char_start": 713, "char_end": 742, "line": "\tbuf[MAX_BRANCH_LEN] = '\\0';\n"}], "added": [{"line_no": 38, "char_start": 713, "char_end": 746, "line": "\tbuf[MAX_BRANCH_LEN - 1] = '\\0';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 732, "char_end": 736, "chars": " - 1"}]}, "commit_link": "github.com/tamentis/prwd/commit/2bf86717a20334c40d168ad968b863f0ab7fd8c5", "file_name": "main.c", "vul_type": "cwe-119", "commit_msg": "fix a buffer overflow", "parent_commit": "62dd9d1df4b4028e843964f7a2da96c89ee1f4de", "description": "Write a C function to determine the current Git branch name and copy it into a wide character string buffer."}
{"func_name": "fiber_switch", "func_src_before": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  if (resume && c->status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (c->status == MRB_FIBER_RUNNING || c->status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (c->status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  mrb->c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  if (c->status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    if (len >= c->stend - c->stack) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"too many arguments to fiber\");\n    }\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n  fiber_switch_context(mrb, c);\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "func_src_after": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  enum mrb_fiber_state status;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  status = c->status;\n  if (resume && status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (status == MRB_FIBER_RUNNING || status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  old_c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  fiber_switch_context(mrb, c);\n  if (status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "commit_link": "github.com/mruby/mruby/commit/778500563a9f7ceba996937dc886bd8cde29b42b", "file_name": "mrbgems/mruby-fiber/src/fiber.c", "vul_type": "cwe-125", "description": "Write a C function `fiber_switch` for the MRuby language that handles fiber resumption, argument passing, and optional VM execution."}
{"func_name": "insertNPC", "func_src_before": "def insertNPC(name, race,classe,sex,level,image,legit):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO npc VALUES ('\"+date+\"','\"+str(name)+\"','\"+race+\"','\"+classe+\"','\"+sex+\"','\"+str(level)+\"','\"+image+\"','\"+str(legit)+\"')\")\n\tconn.commit()\n\tconn.close()", "func_src_after": "def insertNPC(name, race,classe,sex,level,image,legit):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO npc VALUES (?,?,?,?,?,?,?,?)\",(date,str(name),race,classe,sex,str(level),image,str(legit)))\n\tconn.commit()\n\tconn.close()", "commit_link": "github.com/DangerBlack/DungeonsAndDragonsMasterBot/commit/63f980c6dff746f5fcf3005d0646b6c24f81cdc0", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new NPC with attributes into a database using SQL."}
{"func_name": "ReadPSDImage", "func_src_before": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  if ((image->depth == 1) && (image->storage_class != PseudoClass))\n    ThrowReaderException(CorruptImageError, \"ImproperImageHeader\");\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/198fffab4daf8aea88badd9c629350e5b26ec32f", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a PSD image file."}
{"func_name": "read_body", "func_src_before": "  def read_body\n    raise Mechanize::ResponseCodeError.new(self) unless\n      File.exist? @file_path\n\n    if directory?\n      yield dir_body\n    else\n      open @file_path, 'rb' do |io|\n        yield io.read\n      end\n    end\n  end", "func_src_after": "  def read_body\n    raise Mechanize::ResponseCodeError.new(self) unless\n      File.exist? @file_path\n\n    if directory?\n      yield dir_body\n    else\n      ::File.open(@file_path, 'rb') do |io|\n        yield io.read\n      end\n    end\n  end", "line_changes": {"deleted": [{"line_no": 8, "char_start": 150, "char_end": 186, "line": "      open @file_path, 'rb' do |io|\n"}], "added": [{"line_no": 8, "char_start": 150, "char_end": 194, "line": "      ::File.open(@file_path, 'rb') do |io|\n"}]}, "char_changes": {"deleted": [{"char_start": 160, "char_end": 161, "chars": " "}], "added": [{"char_start": 156, "char_end": 163, "chars": "::File."}, {"char_start": 167, "char_end": 168, "chars": "("}, {"char_start": 184, "char_end": 185, "chars": ")"}]}, "commit_link": "github.com/sparklemotion/mechanize/commit/63f8779e49664d5e95fae8d42d04c8e373162b3c", "file_name": "file_response.rb", "vul_type": "cwe-078", "commit_msg": "fix(security): prevent command injection in FileResponse#read_body\n\nAlso add general test coverage for FileResponse#read_body\n\nRelated to https://github.com/sparklemotion/mechanize/security/advisories/GHSA-qrqm-fpv6-6r8g", "description": "Write a Ruby method named `read_body` that yields the contents of a file or directory if it exists, otherwise raises an error."}
{"func_name": "HandleRFBServerMessage", "func_src_before": "HandleRFBServerMessage(rfbClient* client)\n{\n  rfbServerToClientMsg msg;\n\n  if (client->serverPort==-1)\n    client->vncRec->readTimestamp = TRUE;\n  if (!ReadFromRFBServer(client, (char *)&msg, 1))\n    return FALSE;\n\n  switch (msg.type) {\n\n  case rfbSetColourMapEntries:\n  {\n    /* TODO:\n    int i;\n    uint16_t rgb[3];\n    XColor xc;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbSetColourMapEntriesMsg - 1))\n      return FALSE;\n\n    msg.scme.firstColour = rfbClientSwap16IfLE(msg.scme.firstColour);\n    msg.scme.nColours = rfbClientSwap16IfLE(msg.scme.nColours);\n\n    for (i = 0; i < msg.scme.nColours; i++) {\n      if (!ReadFromRFBServer(client, (char *)rgb, 6))\n\treturn FALSE;\n      xc.pixel = msg.scme.firstColour + i;\n      xc.red = rfbClientSwap16IfLE(rgb[0]);\n      xc.green = rfbClientSwap16IfLE(rgb[1]);\n      xc.blue = rfbClientSwap16IfLE(rgb[2]);\n      xc.flags = DoRed|DoGreen|DoBlue;\n      XStoreColor(dpy, cmap, &xc);\n    }\n    */\n\n    break;\n  }\n\n  case rfbFramebufferUpdate:\n  {\n    rfbFramebufferUpdateRectHeader rect;\n    int linesToRead;\n    int bytesPerLine;\n    int i;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg.fu) + 1,\n\t\t\t   sz_rfbFramebufferUpdateMsg - 1))\n      return FALSE;\n\n    msg.fu.nRects = rfbClientSwap16IfLE(msg.fu.nRects);\n\n    for (i = 0; i < msg.fu.nRects; i++) {\n      if (!ReadFromRFBServer(client, (char *)&rect, sz_rfbFramebufferUpdateRectHeader))\n\treturn FALSE;\n\n      rect.encoding = rfbClientSwap32IfLE(rect.encoding);\n      if (rect.encoding == rfbEncodingLastRect)\n\tbreak;\n\n      rect.r.x = rfbClientSwap16IfLE(rect.r.x);\n      rect.r.y = rfbClientSwap16IfLE(rect.r.y);\n      rect.r.w = rfbClientSwap16IfLE(rect.r.w);\n      rect.r.h = rfbClientSwap16IfLE(rect.r.h);\n\n\n      if (rect.encoding == rfbEncodingXCursor ||\n\t  rect.encoding == rfbEncodingRichCursor) {\n\n\tif (!HandleCursorShape(client,\n\t\t\t       rect.r.x, rect.r.y, rect.r.w, rect.r.h,\n\t\t\t       rect.encoding)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n\n      if (rect.encoding == rfbEncodingPointerPos) {\n\tif (!client->HandleCursorPos(client,rect.r.x, rect.r.y)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n      \n      if (rect.encoding == rfbEncodingKeyboardLedState) {\n          /* OK! We have received a keyboard state message!!! */\n          client->KeyboardLedStateEnabled = 1;\n          if (client->HandleKeyboardLedState!=NULL)\n              client->HandleKeyboardLedState(client, rect.r.x, 0);\n          /* stash it for the future */\n          client->CurrentKeyboardLedState = rect.r.x;\n          continue;\n      }\n\n      if (rect.encoding == rfbEncodingNewFBSize) {\n\tclient->width = rect.r.w;\n\tclient->height = rect.r.h;\n\tclient->updateRect.x = client->updateRect.y = 0;\n\tclient->updateRect.w = client->width;\n\tclient->updateRect.h = client->height;\n\tif (!client->MallocFrameBuffer(client))\n\t  return FALSE;\n\tSendFramebufferUpdateRequest(client, 0, 0, rect.r.w, rect.r.h, FALSE);\n\trfbClientLog(\"Got new framebuffer size: %dx%d\\n\", rect.r.w, rect.r.h);\n\tcontinue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingSupportedMessages) {\n          int loop;\n          if (!ReadFromRFBServer(client, (char *)&client->supportedMessages, sz_rfbSupportedMessages))\n              return FALSE;\n\n          /* msgs is two sets of bit flags of supported messages client2server[] and server2client[] */\n          /* currently ignored by this library */\n\n          rfbClientLog(\"client2server supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.client2server[loop],   client->supportedMessages.client2server[loop+1],\n                client->supportedMessages.client2server[loop+2], client->supportedMessages.client2server[loop+3],\n                client->supportedMessages.client2server[loop+4], client->supportedMessages.client2server[loop+5],\n                client->supportedMessages.client2server[loop+6], client->supportedMessages.client2server[loop+7]);\n\n          rfbClientLog(\"server2client supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.server2client[loop],   client->supportedMessages.server2client[loop+1],\n                client->supportedMessages.server2client[loop+2], client->supportedMessages.server2client[loop+3],\n                client->supportedMessages.server2client[loop+4], client->supportedMessages.server2client[loop+5],\n                client->supportedMessages.server2client[loop+6], client->supportedMessages.server2client[loop+7]);\n          continue;\n      }\n\n      /* rect.r.w=byte count, rect.r.h=# of encodings */\n      if (rect.encoding == rfbEncodingSupportedEncodings) {\n          char *buffer;\n          buffer = malloc(rect.r.w);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n\n          /* buffer now contains rect.r.h # of uint32_t encodings that the server supports */\n          /* currently ignored by this library */\n          free(buffer);\n          continue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingServerIdentity) {\n          char *buffer;\n          buffer = malloc(rect.r.w+1);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          buffer[rect.r.w]=0; /* null terminate, just in case */\n          rfbClientLog(\"Connected to Server \\\"%s\\\"\\n\", buffer);\n          free(buffer);\n          continue;\n      }\n\n      /* rfbEncodingUltraZip is a collection of subrects.   x = # of subrects, and h is always 0 */\n      if (rect.encoding != rfbEncodingUltraZip)\n      {\n        if ((rect.r.x + rect.r.w > client->width) ||\n\t    (rect.r.y + rect.r.h > client->height))\n\t    {\n\t      rfbClientLog(\"Rect too large: %dx%d at (%d, %d)\\n\",\n\t  \t  rect.r.w, rect.r.h, rect.r.x, rect.r.y);\n\t      return FALSE;\n            }\n\n        /* UltraVNC with scaling, will send rectangles with a zero W or H\n         *\n        if ((rect.encoding != rfbEncodingTight) && \n            (rect.r.h * rect.r.w == 0))\n        {\n\t  rfbClientLog(\"Zero size rect - ignoring (encoding=%d (0x%08x) %dx, %dy, %dw, %dh)\\n\", rect.encoding, rect.encoding, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n\t  continue;\n        }\n        */\n        \n        /* If RichCursor encoding is used, we should prevent collisions\n\t   between framebuffer updates and cursor drawing operations. */\n        client->SoftCursorLockArea(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n      }\n\n      switch (rect.encoding) {\n\n      case rfbEncodingRaw: {\n\tint y=rect.r.y, h=rect.r.h;\n\n\tbytesPerLine = rect.r.w * client->format.bitsPerPixel / 8;\n\t/* RealVNC 4.x-5.x on OSX can induce bytesPerLine==0, \n\t   usually during GPU accel. */\n\t/* Regardless of cause, do not divide by zero. */\n\tlinesToRead = bytesPerLine ? (RFB_BUFFER_SIZE / bytesPerLine) : 0;\n\n\twhile (linesToRead && h > 0) {\n\t  if (linesToRead > h)\n\t    linesToRead = h;\n\n\t  if (!ReadFromRFBServer(client, client->buffer,bytesPerLine * linesToRead))\n\t    return FALSE;\n\n\t  client->GotBitmap(client, (uint8_t *)client->buffer,\n\t\t\t   rect.r.x, y, rect.r.w,linesToRead);\n\n\t  h -= linesToRead;\n\t  y += linesToRead;\n\n\t}\n\tbreak;\n      } \n\n      case rfbEncodingCopyRect:\n      {\n\trfbCopyRect cr;\n\n\tif (!ReadFromRFBServer(client, (char *)&cr, sz_rfbCopyRect))\n\t  return FALSE;\n\n\tcr.srcX = rfbClientSwap16IfLE(cr.srcX);\n\tcr.srcY = rfbClientSwap16IfLE(cr.srcY);\n\n\t/* If RichCursor encoding is used, we should extend our\n\t   \"cursor lock area\" (previously set to destination\n\t   rectangle) to the source rectangle as well. */\n\tclient->SoftCursorLockArea(client,\n\t\t\t\t   cr.srcX, cr.srcY, rect.r.w, rect.r.h);\n\n        client->GotCopyRect(client, cr.srcX, cr.srcY, rect.r.w, rect.r.h,\n                            rect.r.x, rect.r.y);\n\n\tbreak;\n      }\n\n      case rfbEncodingRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingCoRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleCoRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleCoRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleCoRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingHextile:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleHextile8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleHextile16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleHextile32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingUltra:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltra8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltra16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltra32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n      case rfbEncodingUltraZip:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltraZip8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltraZip16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltraZip32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n\n      case rfbEncodingTRLE:\n\t  {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleTRLE8(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (client->si.format.greenMax > 0x1F) {\n            if (!HandleTRLE16(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else {\n            if (!HandleTRLE15(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          }\n          break;\n        case 32: {\n          uint32_t maxColor =\n              (client->format.redMax << client->format.redShift) |\n              (client->format.greenMax << client->format.greenShift) |\n              (client->format.blueMax << client->format.blueShift);\n          if ((client->format.bigEndian && (maxColor & 0xff) == 0) ||\n              (!client->format.bigEndian && (maxColor & 0xff000000) == 0)) {\n            if (!HandleTRLE24(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (!client->format.bigEndian && (maxColor & 0xff) == 0) {\n            if (!HandleTRLE24Up(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (client->format.bigEndian && (maxColor & 0xff000000) == 0) {\n            if (!HandleTRLE24Down(client, rect.r.x, rect.r.y, rect.r.w,\n                                  rect.r.h))\n              return FALSE;\n          } else if (!HandleTRLE32(client, rect.r.x, rect.r.y, rect.r.w,\n                                   rect.r.h))\n            return FALSE;\n          break;\n        }\n        }\n        break;\n      }\n\n#ifdef LIBVNCSERVER_HAVE_LIBZ\n      case rfbEncodingZlib:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZlib8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleZlib16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleZlib32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n     }\n\n#ifdef LIBVNCSERVER_HAVE_LIBJPEG\n      case rfbEncodingTight:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleTight8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleTight16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleTight32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n#endif\n      case rfbEncodingZRLE:\n\t/* Fail safe for ZYWRLE unsupport VNC server. */\n\tclient->appData.qualityLevel = 9;\n\t/* fall through */\n      case rfbEncodingZYWRLE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZRLE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (client->si.format.greenMax > 0x1F) {\n\t    if (!HandleZRLE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else {\n\t    if (!HandleZRLE15(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  }\n\t  break;\n\tcase 32:\n\t{\n\t  uint32_t maxColor=(client->format.redMax<<client->format.redShift)|\n\t\t(client->format.greenMax<<client->format.greenShift)|\n\t\t(client->format.blueMax<<client->format.blueShift);\n\t  if ((client->format.bigEndian && (maxColor&0xff)==0) ||\n\t      (!client->format.bigEndian && (maxColor&0xff000000)==0)) {\n\t    if (!HandleZRLE24(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!client->format.bigEndian && (maxColor&0xff)==0) {\n\t    if (!HandleZRLE24Up(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (client->format.bigEndian && (maxColor&0xff000000)==0) {\n\t    if (!HandleZRLE24Down(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!HandleZRLE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\t}\n\tbreak;\n     }\n\n#endif\n\n      default:\n\t {\n\t   rfbBool handled = FALSE;\n\t   rfbClientProtocolExtension* e;\n\n\t   for(e = rfbClientExtensions; !handled && e; e = e->next)\n\t     if(e->handleEncoding && e->handleEncoding(client, &rect))\n\t       handled = TRUE;\n\n\t   if(!handled) {\n\t     rfbClientLog(\"Unknown rect encoding %d\\n\",\n\t\t (int)rect.encoding);\n\t     return FALSE;\n\t   }\n\t }\n      }\n\n      /* Now we may discard \"soft cursor locks\". */\n      client->SoftCursorUnlockScreen(client);\n\n      client->GotFrameBufferUpdate(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n    }\n\n    if (!SendIncrementalFramebufferUpdateRequest(client))\n      return FALSE;\n\n    if (client->FinishedFrameBufferUpdate)\n      client->FinishedFrameBufferUpdate(client);\n\n    break;\n  }\n\n  case rfbBell:\n  {\n    client->Bell(client);\n\n    break;\n  }\n\n  case rfbServerCutText:\n  {\n    char *buffer;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbServerCutTextMsg - 1))\n      return FALSE;\n\n    msg.sct.length = rfbClientSwap32IfLE(msg.sct.length);\n\n    if (msg.sct.length > 1<<20) {\n\t    rfbClientErr(\"Ignoring too big cut text length sent by server: %u B > 1 MB\\n\", (unsigned int)msg.sct.length);\n\t    return FALSE;\n    }  \n\n    buffer = malloc((uint64_t)msg.sct.length+1);\n\n    if (!ReadFromRFBServer(client, buffer, msg.sct.length)) {\n      free(buffer);\n      return FALSE;\n    }\n\n    buffer[msg.sct.length] = 0;\n\n    if (client->GotXCutText)\n      client->GotXCutText(client, buffer, msg.sct.length);\n\n    free(buffer);\n\n    break;\n  }\n\n  case rfbTextChat:\n  {\n      char *buffer=NULL;\n      if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                             sz_rfbTextChatMsg- 1))\n        return FALSE;\n      msg.tc.length = rfbClientSwap32IfLE(msg.sct.length);\n      switch(msg.tc.length) {\n      case rfbTextChatOpen:\n          rfbClientLog(\"Received TextChat Open\\n\");\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatOpen, NULL);\n          break;\n      case rfbTextChatClose:\n          rfbClientLog(\"Received TextChat Close\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatClose, NULL);\n          break;\n      case rfbTextChatFinished:\n          rfbClientLog(\"Received TextChat Finished\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatFinished, NULL);\n          break;\n      default:\n          buffer=malloc(msg.tc.length+1);\n          if (!ReadFromRFBServer(client, buffer, msg.tc.length))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          /* Null Terminate <just in case> */\n          buffer[msg.tc.length]=0;\n          rfbClientLog(\"Received TextChat \\\"%s\\\"\\n\", buffer);\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)msg.tc.length, buffer);\n          free(buffer);\n          break;\n      }\n      break;\n  }\n\n  case rfbXvp:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbXvpMsg -1))\n      return FALSE;\n\n    SetClient2Server(client, rfbXvp);\n    /* technically, we only care what we can *send* to the server\n     * but, we set Server2Client Just in case it ever becomes useful\n     */\n    SetServer2Client(client, rfbXvp);\n\n    if(client->HandleXvpMsg)\n      client->HandleXvpMsg(client, msg.xvp.version, msg.xvp.code);\n\n    break;\n  }\n\n  case rfbResizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbResizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.rsfb.framebufferWidth);\n    client->height = rfbClientSwap16IfLE(msg.rsfb.framebufferHeigth);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  case rfbPalmVNCReSizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbPalmVNCReSizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.prsfb.buffer_w);\n    client->height = rfbClientSwap16IfLE(msg.prsfb.buffer_h);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  default:\n    {\n      rfbBool handled = FALSE;\n      rfbClientProtocolExtension* e;\n\n      for(e = rfbClientExtensions; !handled && e; e = e->next)\n\tif(e->handleMessage && e->handleMessage(client, &msg))\n\t  handled = TRUE;\n\n      if(!handled) {\n\tchar buffer[256];\n\trfbClientLog(\"Unknown message type %d from VNC server\\n\",msg.type);\n\tReadFromRFBServer(client, buffer, 256);\n\treturn FALSE;\n      }\n    }\n  }\n\n  return TRUE;\n}", "func_src_after": "HandleRFBServerMessage(rfbClient* client)\n{\n  rfbServerToClientMsg msg;\n\n  if (client->serverPort==-1)\n    client->vncRec->readTimestamp = TRUE;\n  if (!ReadFromRFBServer(client, (char *)&msg, 1))\n    return FALSE;\n\n  switch (msg.type) {\n\n  case rfbSetColourMapEntries:\n  {\n    /* TODO:\n    int i;\n    uint16_t rgb[3];\n    XColor xc;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbSetColourMapEntriesMsg - 1))\n      return FALSE;\n\n    msg.scme.firstColour = rfbClientSwap16IfLE(msg.scme.firstColour);\n    msg.scme.nColours = rfbClientSwap16IfLE(msg.scme.nColours);\n\n    for (i = 0; i < msg.scme.nColours; i++) {\n      if (!ReadFromRFBServer(client, (char *)rgb, 6))\n\treturn FALSE;\n      xc.pixel = msg.scme.firstColour + i;\n      xc.red = rfbClientSwap16IfLE(rgb[0]);\n      xc.green = rfbClientSwap16IfLE(rgb[1]);\n      xc.blue = rfbClientSwap16IfLE(rgb[2]);\n      xc.flags = DoRed|DoGreen|DoBlue;\n      XStoreColor(dpy, cmap, &xc);\n    }\n    */\n\n    break;\n  }\n\n  case rfbFramebufferUpdate:\n  {\n    rfbFramebufferUpdateRectHeader rect;\n    int linesToRead;\n    int bytesPerLine;\n    int i;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg.fu) + 1,\n\t\t\t   sz_rfbFramebufferUpdateMsg - 1))\n      return FALSE;\n\n    msg.fu.nRects = rfbClientSwap16IfLE(msg.fu.nRects);\n\n    for (i = 0; i < msg.fu.nRects; i++) {\n      if (!ReadFromRFBServer(client, (char *)&rect, sz_rfbFramebufferUpdateRectHeader))\n\treturn FALSE;\n\n      rect.encoding = rfbClientSwap32IfLE(rect.encoding);\n      if (rect.encoding == rfbEncodingLastRect)\n\tbreak;\n\n      rect.r.x = rfbClientSwap16IfLE(rect.r.x);\n      rect.r.y = rfbClientSwap16IfLE(rect.r.y);\n      rect.r.w = rfbClientSwap16IfLE(rect.r.w);\n      rect.r.h = rfbClientSwap16IfLE(rect.r.h);\n\n\n      if (rect.encoding == rfbEncodingXCursor ||\n\t  rect.encoding == rfbEncodingRichCursor) {\n\n\tif (!HandleCursorShape(client,\n\t\t\t       rect.r.x, rect.r.y, rect.r.w, rect.r.h,\n\t\t\t       rect.encoding)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n\n      if (rect.encoding == rfbEncodingPointerPos) {\n\tif (!client->HandleCursorPos(client,rect.r.x, rect.r.y)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n      \n      if (rect.encoding == rfbEncodingKeyboardLedState) {\n          /* OK! We have received a keyboard state message!!! */\n          client->KeyboardLedStateEnabled = 1;\n          if (client->HandleKeyboardLedState!=NULL)\n              client->HandleKeyboardLedState(client, rect.r.x, 0);\n          /* stash it for the future */\n          client->CurrentKeyboardLedState = rect.r.x;\n          continue;\n      }\n\n      if (rect.encoding == rfbEncodingNewFBSize) {\n\tclient->width = rect.r.w;\n\tclient->height = rect.r.h;\n\tclient->updateRect.x = client->updateRect.y = 0;\n\tclient->updateRect.w = client->width;\n\tclient->updateRect.h = client->height;\n\tif (!client->MallocFrameBuffer(client))\n\t  return FALSE;\n\tSendFramebufferUpdateRequest(client, 0, 0, rect.r.w, rect.r.h, FALSE);\n\trfbClientLog(\"Got new framebuffer size: %dx%d\\n\", rect.r.w, rect.r.h);\n\tcontinue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingSupportedMessages) {\n          int loop;\n          if (!ReadFromRFBServer(client, (char *)&client->supportedMessages, sz_rfbSupportedMessages))\n              return FALSE;\n\n          /* msgs is two sets of bit flags of supported messages client2server[] and server2client[] */\n          /* currently ignored by this library */\n\n          rfbClientLog(\"client2server supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.client2server[loop],   client->supportedMessages.client2server[loop+1],\n                client->supportedMessages.client2server[loop+2], client->supportedMessages.client2server[loop+3],\n                client->supportedMessages.client2server[loop+4], client->supportedMessages.client2server[loop+5],\n                client->supportedMessages.client2server[loop+6], client->supportedMessages.client2server[loop+7]);\n\n          rfbClientLog(\"server2client supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.server2client[loop],   client->supportedMessages.server2client[loop+1],\n                client->supportedMessages.server2client[loop+2], client->supportedMessages.server2client[loop+3],\n                client->supportedMessages.server2client[loop+4], client->supportedMessages.server2client[loop+5],\n                client->supportedMessages.server2client[loop+6], client->supportedMessages.server2client[loop+7]);\n          continue;\n      }\n\n      /* rect.r.w=byte count, rect.r.h=# of encodings */\n      if (rect.encoding == rfbEncodingSupportedEncodings) {\n          char *buffer;\n          buffer = malloc(rect.r.w);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n\n          /* buffer now contains rect.r.h # of uint32_t encodings that the server supports */\n          /* currently ignored by this library */\n          free(buffer);\n          continue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingServerIdentity) {\n          char *buffer;\n          buffer = malloc(rect.r.w+1);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          buffer[rect.r.w]=0; /* null terminate, just in case */\n          rfbClientLog(\"Connected to Server \\\"%s\\\"\\n\", buffer);\n          free(buffer);\n          continue;\n      }\n\n      /* rfbEncodingUltraZip is a collection of subrects.   x = # of subrects, and h is always 0 */\n      if (rect.encoding != rfbEncodingUltraZip)\n      {\n        if ((rect.r.x + rect.r.w > client->width) ||\n\t    (rect.r.y + rect.r.h > client->height))\n\t    {\n\t      rfbClientLog(\"Rect too large: %dx%d at (%d, %d)\\n\",\n\t  \t  rect.r.w, rect.r.h, rect.r.x, rect.r.y);\n\t      return FALSE;\n            }\n\n        /* UltraVNC with scaling, will send rectangles with a zero W or H\n         *\n        if ((rect.encoding != rfbEncodingTight) && \n            (rect.r.h * rect.r.w == 0))\n        {\n\t  rfbClientLog(\"Zero size rect - ignoring (encoding=%d (0x%08x) %dx, %dy, %dw, %dh)\\n\", rect.encoding, rect.encoding, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n\t  continue;\n        }\n        */\n        \n        /* If RichCursor encoding is used, we should prevent collisions\n\t   between framebuffer updates and cursor drawing operations. */\n        client->SoftCursorLockArea(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n      }\n\n      switch (rect.encoding) {\n\n      case rfbEncodingRaw: {\n\tint y=rect.r.y, h=rect.r.h;\n\n\tbytesPerLine = rect.r.w * client->format.bitsPerPixel / 8;\n\t/* RealVNC 4.x-5.x on OSX can induce bytesPerLine==0, \n\t   usually during GPU accel. */\n\t/* Regardless of cause, do not divide by zero. */\n\tlinesToRead = bytesPerLine ? (RFB_BUFFER_SIZE / bytesPerLine) : 0;\n\n\twhile (linesToRead && h > 0) {\n\t  if (linesToRead > h)\n\t    linesToRead = h;\n\n\t  if (!ReadFromRFBServer(client, client->buffer,bytesPerLine * linesToRead))\n\t    return FALSE;\n\n\t  client->GotBitmap(client, (uint8_t *)client->buffer,\n\t\t\t   rect.r.x, y, rect.r.w,linesToRead);\n\n\t  h -= linesToRead;\n\t  y += linesToRead;\n\n\t}\n\tbreak;\n      } \n\n      case rfbEncodingCopyRect:\n      {\n\trfbCopyRect cr;\n\n\tif (!ReadFromRFBServer(client, (char *)&cr, sz_rfbCopyRect))\n\t  return FALSE;\n\n\tcr.srcX = rfbClientSwap16IfLE(cr.srcX);\n\tcr.srcY = rfbClientSwap16IfLE(cr.srcY);\n\n\t/* If RichCursor encoding is used, we should extend our\n\t   \"cursor lock area\" (previously set to destination\n\t   rectangle) to the source rectangle as well. */\n\tclient->SoftCursorLockArea(client,\n\t\t\t\t   cr.srcX, cr.srcY, rect.r.w, rect.r.h);\n\n        client->GotCopyRect(client, cr.srcX, cr.srcY, rect.r.w, rect.r.h,\n                            rect.r.x, rect.r.y);\n\n\tbreak;\n      }\n\n      case rfbEncodingRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingCoRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleCoRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleCoRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleCoRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingHextile:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleHextile8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleHextile16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleHextile32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingUltra:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltra8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltra16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltra32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n      case rfbEncodingUltraZip:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltraZip8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltraZip16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltraZip32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n\n      case rfbEncodingTRLE:\n\t  {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleTRLE8(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (client->si.format.greenMax > 0x1F) {\n            if (!HandleTRLE16(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else {\n            if (!HandleTRLE15(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          }\n          break;\n        case 32: {\n          uint32_t maxColor =\n              (client->format.redMax << client->format.redShift) |\n              (client->format.greenMax << client->format.greenShift) |\n              (client->format.blueMax << client->format.blueShift);\n          if ((client->format.bigEndian && (maxColor & 0xff) == 0) ||\n              (!client->format.bigEndian && (maxColor & 0xff000000) == 0)) {\n            if (!HandleTRLE24(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (!client->format.bigEndian && (maxColor & 0xff) == 0) {\n            if (!HandleTRLE24Up(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (client->format.bigEndian && (maxColor & 0xff000000) == 0) {\n            if (!HandleTRLE24Down(client, rect.r.x, rect.r.y, rect.r.w,\n                                  rect.r.h))\n              return FALSE;\n          } else if (!HandleTRLE32(client, rect.r.x, rect.r.y, rect.r.w,\n                                   rect.r.h))\n            return FALSE;\n          break;\n        }\n        }\n        break;\n      }\n\n#ifdef LIBVNCSERVER_HAVE_LIBZ\n      case rfbEncodingZlib:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZlib8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleZlib16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleZlib32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n     }\n\n#ifdef LIBVNCSERVER_HAVE_LIBJPEG\n      case rfbEncodingTight:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleTight8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleTight16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleTight32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n#endif\n      case rfbEncodingZRLE:\n\t/* Fail safe for ZYWRLE unsupport VNC server. */\n\tclient->appData.qualityLevel = 9;\n\t/* fall through */\n      case rfbEncodingZYWRLE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZRLE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (client->si.format.greenMax > 0x1F) {\n\t    if (!HandleZRLE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else {\n\t    if (!HandleZRLE15(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  }\n\t  break;\n\tcase 32:\n\t{\n\t  uint32_t maxColor=(client->format.redMax<<client->format.redShift)|\n\t\t(client->format.greenMax<<client->format.greenShift)|\n\t\t(client->format.blueMax<<client->format.blueShift);\n\t  if ((client->format.bigEndian && (maxColor&0xff)==0) ||\n\t      (!client->format.bigEndian && (maxColor&0xff000000)==0)) {\n\t    if (!HandleZRLE24(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!client->format.bigEndian && (maxColor&0xff)==0) {\n\t    if (!HandleZRLE24Up(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (client->format.bigEndian && (maxColor&0xff000000)==0) {\n\t    if (!HandleZRLE24Down(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!HandleZRLE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\t}\n\tbreak;\n     }\n\n#endif\n\n      default:\n\t {\n\t   rfbBool handled = FALSE;\n\t   rfbClientProtocolExtension* e;\n\n\t   for(e = rfbClientExtensions; !handled && e; e = e->next)\n\t     if(e->handleEncoding && e->handleEncoding(client, &rect))\n\t       handled = TRUE;\n\n\t   if(!handled) {\n\t     rfbClientLog(\"Unknown rect encoding %d\\n\",\n\t\t (int)rect.encoding);\n\t     return FALSE;\n\t   }\n\t }\n      }\n\n      /* Now we may discard \"soft cursor locks\". */\n      client->SoftCursorUnlockScreen(client);\n\n      client->GotFrameBufferUpdate(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n    }\n\n    if (!SendIncrementalFramebufferUpdateRequest(client))\n      return FALSE;\n\n    if (client->FinishedFrameBufferUpdate)\n      client->FinishedFrameBufferUpdate(client);\n\n    break;\n  }\n\n  case rfbBell:\n  {\n    client->Bell(client);\n\n    break;\n  }\n\n  case rfbServerCutText:\n  {\n    char *buffer;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbServerCutTextMsg - 1))\n      return FALSE;\n\n    msg.sct.length = rfbClientSwap32IfLE(msg.sct.length);\n\n    if (msg.sct.length > 1<<20) {\n\t    rfbClientErr(\"Ignoring too big cut text length sent by server: %u B > 1 MB\\n\", (unsigned int)msg.sct.length);\n\t    return FALSE;\n    }  \n\n    buffer = malloc(msg.sct.length+1);\n\n    if (!ReadFromRFBServer(client, buffer, msg.sct.length)) {\n      free(buffer);\n      return FALSE;\n    }\n\n    buffer[msg.sct.length] = 0;\n\n    if (client->GotXCutText)\n      client->GotXCutText(client, buffer, msg.sct.length);\n\n    free(buffer);\n\n    break;\n  }\n\n  case rfbTextChat:\n  {\n      char *buffer=NULL;\n      if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                             sz_rfbTextChatMsg- 1))\n        return FALSE;\n      msg.tc.length = rfbClientSwap32IfLE(msg.sct.length);\n      switch(msg.tc.length) {\n      case rfbTextChatOpen:\n          rfbClientLog(\"Received TextChat Open\\n\");\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatOpen, NULL);\n          break;\n      case rfbTextChatClose:\n          rfbClientLog(\"Received TextChat Close\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatClose, NULL);\n          break;\n      case rfbTextChatFinished:\n          rfbClientLog(\"Received TextChat Finished\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatFinished, NULL);\n          break;\n      default:\n          buffer=malloc(msg.tc.length+1);\n          if (!ReadFromRFBServer(client, buffer, msg.tc.length))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          /* Null Terminate <just in case> */\n          buffer[msg.tc.length]=0;\n          rfbClientLog(\"Received TextChat \\\"%s\\\"\\n\", buffer);\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)msg.tc.length, buffer);\n          free(buffer);\n          break;\n      }\n      break;\n  }\n\n  case rfbXvp:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbXvpMsg -1))\n      return FALSE;\n\n    SetClient2Server(client, rfbXvp);\n    /* technically, we only care what we can *send* to the server\n     * but, we set Server2Client Just in case it ever becomes useful\n     */\n    SetServer2Client(client, rfbXvp);\n\n    if(client->HandleXvpMsg)\n      client->HandleXvpMsg(client, msg.xvp.version, msg.xvp.code);\n\n    break;\n  }\n\n  case rfbResizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbResizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.rsfb.framebufferWidth);\n    client->height = rfbClientSwap16IfLE(msg.rsfb.framebufferHeigth);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  case rfbPalmVNCReSizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbPalmVNCReSizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.prsfb.buffer_w);\n    client->height = rfbClientSwap16IfLE(msg.prsfb.buffer_h);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  default:\n    {\n      rfbBool handled = FALSE;\n      rfbClientProtocolExtension* e;\n\n      for(e = rfbClientExtensions; !handled && e; e = e->next)\n\tif(e->handleMessage && e->handleMessage(client, &msg))\n\t  handled = TRUE;\n\n      if(!handled) {\n\tchar buffer[256];\n\trfbClientLog(\"Unknown message type %d from VNC server\\n\",msg.type);\n\tReadFromRFBServer(client, buffer, 256);\n\treturn FALSE;\n      }\n    }\n  }\n\n  return TRUE;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/a64c3b37af9a6c8f8009d7516874b8d266b42bae", "file_name": "libvncclient/rfbproto.c", "vul_type": "cwe-787", "description": "Write a function in C to handle server messages for a VNC client."}
{"func_name": "mergeConfig", "func_src_before": "function mergeConfig(from, to) {\n\tfor (var f in from) {\n\t\tif (_.isObject(from[f])) {\n\t\t\tif (!_.isObject(to[f])) {\n\t\t\t\tto[f] = from[f];\n\t\t\t} else {\n\t\t\t\tmergeConfig(from[f], to[f]);\n\t\t\t}\n\t\t} else {\n\t\t\tto[f] = from[f];\n\t\t}\n\t}\n}", "func_src_after": "function mergeConfig(from, to) {\n\tfor (var f in from) {\n\t\tif (Object.prototype.hasOwnProperty.call(from, f)) {\n\t\t\tif (Object.prototype.hasOwnProperty.call(to, f) && _.isObject(from[f])) {\n\t\t\t\tif (!_.isObject(to[f])) {\n\t\t\t\t\tto[f] = from[f];\n\t\t\t\t} else {\n\t\t\t\t\tmergeConfig(from[f], to[f]);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tto[f] = from[f];\n\t\t\t}\n\t\t}\n\t}\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 56, "char_end": 85, "line": "\t\tif (_.isObject(from[f])) {\n"}, {"line_no": 4, "char_start": 85, "char_end": 114, "line": "\t\t\tif (!_.isObject(to[f])) {\n"}, {"line_no": 5, "char_start": 114, "char_end": 135, "line": "\t\t\t\tto[f] = from[f];\n"}, {"line_no": 7, "char_start": 147, "char_end": 180, "line": "\t\t\t\tmergeConfig(from[f], to[f]);\n"}, {"line_no": 9, "char_start": 185, "char_end": 196, "line": "\t\t} else {\n"}, {"line_no": 10, "char_start": 196, "char_end": 216, "line": "\t\t\tto[f] = from[f];\n"}], "added": [{"line_no": 3, "char_start": 56, "char_end": 111, "line": "\t\tif (Object.prototype.hasOwnProperty.call(from, f)) {\n"}, {"line_no": 4, "char_start": 111, "char_end": 188, "line": "\t\t\tif (Object.prototype.hasOwnProperty.call(to, f) && _.isObject(from[f])) {\n"}, {"line_no": 5, "char_start": 188, "char_end": 218, "line": "\t\t\t\tif (!_.isObject(to[f])) {\n"}, {"line_no": 6, "char_start": 218, "char_end": 240, "line": "\t\t\t\t\tto[f] = from[f];\n"}, {"line_no": 7, "char_start": 240, "char_end": 253, "line": "\t\t\t\t} else {\n"}, {"line_no": 8, "char_start": 253, "char_end": 287, "line": "\t\t\t\t\tmergeConfig(from[f], to[f]);\n"}, {"line_no": 9, "char_start": 287, "char_end": 293, "line": "\t\t\t\t}\n"}, {"line_no": 11, "char_start": 305, "char_end": 326, "line": "\t\t\t\tto[f] = from[f];\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 62, "char_end": 165, "chars": "Object.prototype.hasOwnProperty.call(from, f)) {\n\t\t\tif (Object.prototype.hasOwnProperty.call(to, f) && "}, {"char_start": 188, "char_end": 189, "chars": "\t"}, {"char_start": 218, "char_end": 219, "chars": "\t"}, {"char_start": 243, "char_end": 244, "chars": "\t"}, {"char_start": 253, "char_end": 254, "chars": "\t"}, {"char_start": 287, "char_end": 288, "chars": "\t"}, {"char_start": 295, "char_end": 296, "chars": "\t"}, {"char_start": 305, "char_end": 306, "chars": "\t"}, {"char_start": 326, "char_end": 331, "chars": "\t\t\t}\n"}]}, "commit_link": "github.com/jkphl/svg-sprite/commit/1ba7f04ed4f4798112aa612b7b2e6367fcb7e8c2", "file_name": "svg-sprite.js", "vul_type": "cwe-915", "commit_msg": "Fix prototype pollution issue (#392)", "parent_commit": "1724f4c0b2b923c4dd1a1d75e00647f5f7fae0c6", "description": "Write a JavaScript function named `mergeConfig` that recursively merges properties from one object into another."}
{"func_name": "view_page_history", "func_src_before": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = '%s'\" % page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "func_src_after": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = $1\", page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to display the history of a webpage using a template, with SQL query parameterization differing between string formatting and using placeholders."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        if self.request.GET.get('back', None) is not None:\n            data['back_link'] = self.request.GET['back']\n\n        return data", "func_src_after": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        back = self.request.GET.get('back', None)\n        parsed_back_url = urllib.parse.urlparse(back)\n\n        # We only allow blank scheme, e.g. relative urls to avoid reflected XSS\n        if back is not None and parsed_back_url.scheme == \"\":\n            data['back_link'] = back\n\n        return data", "commit_link": "github.com/pirati-web/socialnisystem.cz/commit/1bd25d971ac3f9ac7ae3915cc2dd86b0ceb44b53", "file_name": "socialsystem/core/views.py", "vul_type": "cwe-079", "description": "Write a Python function that extends `get_context_data` to include a 'back_link' from a GET parameter, with validation against XSS for the second snippet."}
{"func_name": "is_cgi", "func_src_before": "    def is_cgi(self):\n        \"\"\"Test whether self.path corresponds to a CGI script,\n        and return a boolean.\n\n        This function sets self.cgi_info to a tuple (dir, rest)\n        when it returns True, where dir is the directory part before\n        the CGI script name.  Note that rest begins with a\n        slash if it is not empty.\n\n        The default implementation tests whether the path\n        begins with one of the strings in the list\n        self.cgi_directories (and the next character is a '/'\n        or the end of the string).\n        \"\"\"\n\n        path = self.path\n\n        for x in self.cgi_directories:\n            i = len(x)\n            if path[:i] == x and (not path[i:] or path[i] == '/'):\n                self.cgi_info = path[:i], path[i+1:]\n                return True\n        return False", "func_src_after": "    def is_cgi(self):\n        \"\"\"Test whether self.path corresponds to a CGI script.\n\n        Returns True and updates the cgi_info attribute to the tuple\n        (dir, rest) if self.path requires running a CGI script.\n        Returns False otherwise.\n\n        The default implementation tests whether the normalized url\n        path begins with one of the strings in self.cgi_directories\n        (and the next character is a '/' or the end of the string).\n        \"\"\"\n        splitpath = _url_collapse_path_split(self.path)\n        if splitpath[0] in self.cgi_directories:\n            self.cgi_info = splitpath\n            return True\n        return False", "commit_link": "github.com/Ricky-Wilson/Python/commit/c5abced949e6a4b001d1dee321593e74ecadecfe", "file_name": "Lib/CGIHTTPServer.py", "vul_type": "cwe-022", "description": "Create a Python function that checks if a given path is a CGI script and updates an attribute with the script's directory information."}
{"func_name": "delete", "func_src_before": "@mod.route('/delete/<int:cmt_id>', methods=['GET', 'POST'])\ndef delete(cmt_id):\n    if request.method == 'GET':\n        sql = \"SELECT msg_id FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        sql = \"DELETE FROM comment where cmt_id = '%d';\" % (cmt_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('comment.show', msg_id=m[0]))", "func_src_after": "@mod.route('/delete/<int:cmt_id>', methods=['GET', 'POST'])\ndef delete(cmt_id):\n    if request.method == 'GET':\n        cursor.execute(\"SELECT msg_id FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        cursor.execute(\"DELETE FROM comment where cmt_id = %s;\", (cmt_id,))\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('comment.show', msg_id=m[0]))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089", "description": "Write a Python Flask route to delete a comment by its ID from a database and redirect to a message page, using GET or POST method."}
{"func_name": "__init__.callback", "func_src_before": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089", "description": "Write a Python function that displays recipe details from a SQLite database when a recipe name is provided."}
{"func_name": "move", "func_src_before": "def move(path, dest, replace=False):\n    \"\"\"Rename a file. `dest` may not be a directory. If `dest` already\n    exists, raises an OSError unless `replace` is True. Has no effect if\n    `path` is the same as `dest`. If the paths are on different\n    filesystems (or the rename otherwise fails), a copy is attempted\n    instead, in which case metadata will *not* be preserved. Paths are\n    translated to system paths.\n    \"\"\"\n    if os.path.isdir(path):\n        raise FilesystemError(u'source is directory', 'move', (path, dest))\n    if os.path.isdir(dest):\n        raise FilesystemError(u'destination is directory', 'move',\n                              (path, dest))\n    if samefile(path, dest):\n        return\n    path = syspath(path)\n    dest = syspath(dest)\n    if os.path.exists(dest) and not replace:\n        raise FilesystemError('file exists', 'rename', (path, dest))\n\n    # First, try renaming the file.\n    try:\n        os.replace(path, dest)\n    except OSError:\n        tmp = tempfile.mktemp(suffix='.beets',\n                              prefix=py3_path(b'.' + os.path.basename(dest)),\n                              dir=py3_path(os.path.dirname(dest)))\n        tmp = syspath(tmp)\n        try:\n            shutil.copyfile(path, tmp)\n            os.replace(tmp, dest)\n            tmp = None\n            os.remove(path)\n        except OSError as exc:\n            raise FilesystemError(exc, 'move', (path, dest),\n                                  traceback.format_exc())\n        finally:\n            if tmp is not None:\n                os.remove(tmp)", "func_src_after": "def move(path, dest, replace=False):\n    \"\"\"Rename a file. `dest` may not be a directory. If `dest` already\n    exists, raises an OSError unless `replace` is True. Has no effect if\n    `path` is the same as `dest`. If the paths are on different\n    filesystems (or the rename otherwise fails), a copy is attempted\n    instead, in which case metadata will *not* be preserved. Paths are\n    translated to system paths.\n    \"\"\"\n    if os.path.isdir(path):\n        raise FilesystemError(u'source is directory', 'move', (path, dest))\n    if os.path.isdir(dest):\n        raise FilesystemError(u'destination is directory', 'move',\n                              (path, dest))\n    if samefile(path, dest):\n        return\n    path = syspath(path)\n    dest = syspath(dest)\n    if os.path.exists(dest) and not replace:\n        raise FilesystemError('file exists', 'rename', (path, dest))\n\n    # First, try renaming the file.\n    try:\n        os.replace(path, dest)\n    except OSError:\n        # Copy the file to a temporary destination.\n        tmp = tempfile.NamedTemporaryFile(suffix=b'.beets',\n                                          prefix=b'.' + os.path.basename(dest),\n                                          dir=os.path.dirname(dest),\n                                          delete=False)\n        try:\n            with open(path, 'rb') as f:\n                shutil.copyfileobj(f, tmp)\n        finally:\n            tmp.close()\n\n        # Move the copied file into place.\n        try:\n            os.replace(tmp.name, dest)\n            tmp = None\n            os.remove(path)\n        except OSError as exc:\n            raise FilesystemError(exc, 'move', (path, dest),\n                                  traceback.format_exc())\n        finally:\n            if tmp is not None:\n                os.remove(tmp)", "line_changes": {"deleted": [{"line_no": 25, "char_start": 973, "char_end": 1020, "line": "        tmp = tempfile.mktemp(suffix='.beets',\n"}, {"line_no": 26, "char_start": 1020, "char_end": 1098, "line": "                              prefix=py3_path(b'.' + os.path.basename(dest)),\n"}, {"line_no": 27, "char_start": 1098, "char_end": 1165, "line": "                              dir=py3_path(os.path.dirname(dest)))\n"}, {"line_no": 28, "char_start": 1165, "char_end": 1192, "line": "        tmp = syspath(tmp)\n"}, {"line_no": 30, "char_start": 1205, "char_end": 1244, "line": "            shutil.copyfile(path, tmp)\n"}, {"line_no": 31, "char_start": 1244, "char_end": 1278, "line": "            os.replace(tmp, dest)\n"}], "added": [{"line_no": 26, "char_start": 1025, "char_end": 1085, "line": "        tmp = tempfile.NamedTemporaryFile(suffix=b'.beets',\n"}, {"line_no": 27, "char_start": 1085, "char_end": 1165, "line": "                                          prefix=b'.' + os.path.basename(dest),\n"}, {"line_no": 28, "char_start": 1165, "char_end": 1234, "line": "                                          dir=os.path.dirname(dest),\n"}, {"line_no": 29, "char_start": 1234, "char_end": 1290, "line": "                                          delete=False)\n"}, {"line_no": 31, "char_start": 1303, "char_end": 1343, "line": "            with open(path, 'rb') as f:\n"}, {"line_no": 32, "char_start": 1343, "char_end": 1386, "line": "                shutil.copyfileobj(f, tmp)\n"}, {"line_no": 33, "char_start": 1386, "char_end": 1403, "line": "        finally:\n"}, {"line_no": 34, "char_start": 1403, "char_end": 1427, "line": "            tmp.close()\n"}, {"line_no": 35, "char_start": 1427, "char_end": 1428, "line": "\n"}, {"line_no": 37, "char_start": 1471, "char_end": 1484, "line": "        try:\n"}, {"line_no": 38, "char_start": 1484, "char_end": 1523, "line": "            os.replace(tmp.name, dest)\n"}]}, "char_changes": {"deleted": [{"char_start": 981, "char_end": 1002, "chars": "tmp = tempfile.mktemp"}, {"char_start": 1050, "char_end": 1066, "chars": "prefix=py3_path("}, {"char_start": 1095, "char_end": 1096, "chars": ")"}, {"char_start": 1132, "char_end": 1141, "chars": "py3_path("}, {"char_start": 1162, "char_end": 1164, "chars": "))"}, {"char_start": 1173, "char_end": 1243, "chars": "tmp = syspath(tmp)\n        try:\n            shutil.copyfile(path, tmp)"}], "added": [{"char_start": 981, "char_end": 1066, "chars": "# Copy the file to a temporary destination.\n        tmp = tempfile.NamedTemporaryFile"}, {"char_start": 1074, "char_end": 1075, "chars": "b"}, {"char_start": 1115, "char_end": 1134, "chars": "            prefix="}, {"char_start": 1165, "char_end": 1177, "chars": "            "}, {"char_start": 1232, "char_end": 1233, "chars": ","}, {"char_start": 1242, "char_end": 1483, "chars": "                                  delete=False)\n        try:\n            with open(path, 'rb') as f:\n                shutil.copyfileobj(f, tmp)\n        finally:\n            tmp.close()\n\n        # Move the copied file into place.\n        try:"}, {"char_start": 1510, "char_end": 1515, "chars": ".name"}]}, "commit_link": "github.com/beetbox/beets/commit/4bb695bcdbada9c8153442688e8494199f015f04", "file_name": "__init__.py", "vul_type": "cwe-377", "commit_msg": "Fix copying for atomic file moves\n\nFixes #4168. Also closes #4192, which it supersedes.\n\nThe original problem is that this implementation used bytestrings\nincorrectly to invoke `mktemp`. However, `mktemp` is deprecated, so this\nPR just avoids it altogether. Fortunately, the non-deprecated APIs in\n`tempfile` support all-bytes arguments.", "description": "Write a Python function named `move` that renames a file, with an option to replace the destination file if it already exists."}
{"func_name": "youngcollection", "func_src_before": "static void youngcollection (lua_State *L, global_State *g) {\n  GCObject **psurvival;  /* to point to first non-dead survival object */\n  lua_assert(g->gcstate == GCSpropagate);\n  markold(g, g->survival, g->reallyold);\n  markold(g, g->finobj, g->finobjrold);\n  atomic(L);\n\n  /* sweep nursery and get a pointer to its last live element */\n  psurvival = sweepgen(L, g, &g->allgc, g->survival);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->reallyold);\n  g->reallyold = g->old;\n  g->old = *psurvival;  /* 'survival' survivals are old now */\n  g->survival = g->allgc;  /* all news are survivals */\n\n  /* repeat for 'finobj' lists */\n  psurvival = sweepgen(L, g, &g->finobj, g->finobjsur);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->finobjrold);\n  g->finobjrold = g->finobjold;\n  g->finobjold = *psurvival;  /* 'survival' survivals are old now */\n  g->finobjsur = g->finobj;  /* all news are survivals */\n\n  sweepgen(L, g, &g->tobefnz, NULL);\n\n  finishgencycle(L, g);\n}", "func_src_after": "static void youngcollection (lua_State *L, global_State *g) {\n  GCObject **psurvival;  /* to point to first non-dead survival object */\n  lua_assert(g->gcstate == GCSpropagate);\n  markold(g, g->allgc, g->reallyold);\n  markold(g, g->finobj, g->finobjrold);\n  atomic(L);\n\n  /* sweep nursery and get a pointer to its last live element */\n  psurvival = sweepgen(L, g, &g->allgc, g->survival);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->reallyold);\n  g->reallyold = g->old;\n  g->old = *psurvival;  /* 'survival' survivals are old now */\n  g->survival = g->allgc;  /* all news are survivals */\n\n  /* repeat for 'finobj' lists */\n  psurvival = sweepgen(L, g, &g->finobj, g->finobjsur);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->finobjrold);\n  g->finobjrold = g->finobjold;\n  g->finobjold = *psurvival;  /* 'survival' survivals are old now */\n  g->finobjsur = g->finobj;  /* all news are survivals */\n\n  sweepgen(L, g, &g->tobefnz, NULL);\n\n  finishgencycle(L, g);\n}", "commit_link": "github.com/lua/lua/commit/127e7a6c8942b362aa3c6627f44d660a4fb75312", "file_name": "lgc.c", "vul_type": "cwe-125", "description": "Write a C function named `youngcollection` for garbage collection in Lua that transitions objects between different generational states."}
{"func_name": "get_asset_and_volume", "func_src_before": "@app.route('/get_asset_and_volume')\ndef get_asset_and_volume():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n    #print asset_id\n    ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"get_assets\",[[\"' + asset_id + '\"], 0]]}')\n    result = ws.recv()\n    j = json.loads(result)\n\n    dynamic_asset_data_id =  j[\"result\"][0][\"dynamic_asset_data_id\"]\n\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+dynamic_asset_data_id+'\"]]]}')\n    result2 = ws.recv()\n    j2 = json.loads(result2)\n    #print j2[\"result\"][0][\"current_supply\"]\n\n    j[\"result\"][0][\"current_supply\"] = j2[\"result\"][0][\"current_supply\"]\n    j[\"result\"][0][\"confidential_supply\"] = j2[\"result\"][0][\"confidential_supply\"]\n    #print j[\"result\"]\n\n    j[\"result\"][0][\"accumulated_fees\"] = j2[\"result\"][0][\"accumulated_fees\"]\n    j[\"result\"][0][\"fee_pool\"] = j2[\"result\"][0][\"fee_pool\"]\n\n    issuer = j[\"result\"][0][\"issuer\"]\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+issuer+'\"]]]}')\n    result3 = ws.recv()\n    j3 = json.loads(result3)\n    j[\"result\"][0][\"issuer_name\"] = j3[\"result\"][0][\"name\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT volume, mcap FROM assets WHERE aid='\"+asset_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    try:\n        j[\"result\"][0][\"volume\"] = results[0][0]\n        j[\"result\"][0][\"mcap\"] = results[0][1]\n    except:\n        j[\"result\"][0][\"volume\"] = 0\n        j[\"result\"][0][\"mcap\"] = 0\n\n    return jsonify(j[\"result\"])", "func_src_after": "@app.route('/get_asset_and_volume')\ndef get_asset_and_volume():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n    #print asset_id\n    ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"get_assets\",[[\"' + asset_id + '\"], 0]]}')\n    result = ws.recv()\n    j = json.loads(result)\n\n    dynamic_asset_data_id =  j[\"result\"][0][\"dynamic_asset_data_id\"]\n\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+dynamic_asset_data_id+'\"]]]}')\n    result2 = ws.recv()\n    j2 = json.loads(result2)\n    #print j2[\"result\"][0][\"current_supply\"]\n\n    j[\"result\"][0][\"current_supply\"] = j2[\"result\"][0][\"current_supply\"]\n    j[\"result\"][0][\"confidential_supply\"] = j2[\"result\"][0][\"confidential_supply\"]\n    #print j[\"result\"]\n\n    j[\"result\"][0][\"accumulated_fees\"] = j2[\"result\"][0][\"accumulated_fees\"]\n    j[\"result\"][0][\"fee_pool\"] = j2[\"result\"][0][\"fee_pool\"]\n\n    issuer = j[\"result\"][0][\"issuer\"]\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+issuer+'\"]]]}')\n    result3 = ws.recv()\n    j3 = json.loads(result3)\n    j[\"result\"][0][\"issuer_name\"] = j3[\"result\"][0][\"name\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT volume, mcap FROM assets WHERE aid=%s\"\n    cur.execute(query, (asset_id,))\n    results = cur.fetchall()\n    con.close()\n    try:\n        j[\"result\"][0][\"volume\"] = results[0][0]\n        j[\"result\"][0][\"mcap\"] = results[0][1]\n    except:\n        j[\"result\"][0][\"volume\"] = 0\n        j[\"result\"][0][\"mcap\"] = 0\n\n    return jsonify(j[\"result\"])", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "In Python, create a Flask endpoint '/get_asset_and_volume' that retrieves and combines asset details from a WebSocket connection and volume data from a PostgreSQL database."}
{"func_name": "usage", "func_src_before": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd = cmd + ' -' + args\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "func_src_after": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    flags = ''\n    allowed = ('a', 'B', 'h', 'H', 'i', 'k', 'l', 'P', 't', 'T', 'x', 'v')\n    for flag in args:\n        if flag in allowed:\n            flags += flag\n        else:\n            break\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd += ' -{0}'.format(flags)\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "commit_link": "github.com/saltstack/salt/commit/ebdef37b7e5d2b95a01d34b211c61c61da67e46a", "file_name": "salt/modules/disk.py", "vul_type": "cwe-078", "description": "Write a Python function named `usage` that returns disk usage information for mounted volumes, with optional arguments for additional flags."}
{"func_name": "git_file_info", "func_src_before": "    def git_file_info(path)\n      return '  \u2713 '.colorize(@colors[:unchanged]) unless @git_status[path]\n      Git.colored_status_symbols(@git_status[path], @colors)\n    end", "func_src_after": "    def git_file_info(path)\n      return '  \u2713 '.colorize(@colors[:unchanged]) unless @git_status[path]\n      Git.colored_status_symbols(@git_status[path].uniq, @colors)\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 103, "char_end": 164, "line": "      Git.colored_status_symbols(@git_status[path], @colors)\n"}, {"line_no": 4, "char_start": 164, "char_end": 171, "line": "    end\n"}], "added": []}, "char_changes": {"deleted": [], "added": [{"char_start": 153, "char_end": 158, "chars": ".uniq"}]}, "commit_link": "github.com/athityakumar/colorls/commit/b362fa1eb81e7e6fa208cc8cab51f110db20057b", "file_name": "core.rb", "vul_type": "cwe-022", "commit_msg": "Improve git-status processing\n\n* no longer traverse complete directory trees to determine git status for\n  directories\n\n* properly report status for folders with changed files\n\n* skip the parent folder since we do not have git status about it", "parent_commit": "bb270b319a68adb96bf91a311250481020bdde81", "description": "Write a Ruby method named `git_file_info` that returns the colorized status of a file in a git repository, using a unique status if present."}
{"func_name": "AllocateDataSet", "func_src_before": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    t-> Data = (char**)AllocChunk (it8, ((cmsUInt32Number) t->nSamples + 1) * ((cmsUInt32Number) t->nPatches + 1) *sizeof (char*));\n    if (t->Data == NULL) {\n\n        SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n    }\n\n}", "func_src_after": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    if (t -> nSamples < 0 || t->nSamples > 0x7ffe || t->nPatches < 0 || t->nPatches > 0x7ffe)\n    {\n        SynError(it8, \"AllocateDataSet: too much data\");\n    }\n    else {\n        t->Data = (char**)AllocChunk(it8, ((cmsUInt32Number)t->nSamples + 1) * ((cmsUInt32Number)t->nPatches + 1) * sizeof(char*));\n        if (t->Data == NULL) {\n\n            SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n        }\n    }\n\n}", "commit_link": "github.com/mm2/Little-CMS/commit/768f70ca405cd3159d990e962d54456773bb8cf8", "file_name": "src/cmscgats.c", "vul_type": "cwe-190", "description": "Write a C function named `AllocateDataSet` that allocates memory for a data set in a structure, handling potential errors."}
{"func_name": "main", "func_src_before": "def main(_):\n  # Generate some fake Iris data.\n  # It is okay for this example because this example is about how to use the\n  # debugger, not how to use machine learning to solve the Iris classification\n  # problem.\n  def training_input_fn():\n    return ({\n        \"features\": tf.random_normal([128, 4])\n    }, tf.random_uniform([128], minval=0, maxval=3, dtype=tf.int32))\n\n  def test_input_fn():\n    return ({\n        \"features\": tf.random_normal([32, 4])\n    }, tf.random_uniform([32], minval=0, maxval=3, dtype=tf.int32))\n\n  feature_columns = [tf.feature_column.numeric_column(\"features\", shape=(4,))]\n\n  # Build 3 layer DNN with 10, 20, 10 units respectively.\n  model_dir = FLAGS.model_dir or tempfile.mkdtemp(prefix=\"debug_tflearn_iris_\")\n\n  classifier = tf.estimator.DNNClassifier(\n      feature_columns=feature_columns,\n      hidden_units=[10, 20, 10],\n      n_classes=3,\n      model_dir=model_dir)\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  hooks = []\n  if FLAGS.debug:\n    config_file_path = (\n        tempfile.mktemp(\".tfdbg_config\")\n        if FLAGS.use_random_config_path else None)\n    hooks.append(\n        tf_debug.LocalCLIDebugHook(\n            ui_type=FLAGS.ui_type,\n            dump_root=FLAGS.dump_root,\n            config_file_path=config_file_path))\n  elif FLAGS.tensorboard_debug_address:\n    hooks.append(tf_debug.TensorBoardDebugHook(FLAGS.tensorboard_debug_address))\n\n  # Train model, using tfdbg hook.\n  classifier.train(training_input_fn, steps=FLAGS.train_steps, hooks=hooks)\n\n  # Evaluate accuracy, using tfdbg hook.\n  accuracy_score = classifier.evaluate(\n      test_input_fn, steps=FLAGS.eval_steps, hooks=hooks)[\"accuracy\"]\n\n  print(\"After training %d steps, Accuracy = %f\" %\n        (FLAGS.train_steps, accuracy_score))\n\n  # Make predictions, using tfdbg hook.\n  predict_results = classifier.predict(test_input_fn, hooks=hooks)\n  print(\"A prediction result: %s\" % next(predict_results))", "func_src_after": "def main(_):\n  # Generate some fake Iris data.\n  # It is okay for this example because this example is about how to use the\n  # debugger, not how to use machine learning to solve the Iris classification\n  # problem.\n  def training_input_fn():\n    return ({\n        \"features\": tf.random_normal([128, 4])\n    }, tf.random_uniform([128], minval=0, maxval=3, dtype=tf.int32))\n\n  def test_input_fn():\n    return ({\n        \"features\": tf.random_normal([32, 4])\n    }, tf.random_uniform([32], minval=0, maxval=3, dtype=tf.int32))\n\n  feature_columns = [tf.feature_column.numeric_column(\"features\", shape=(4,))]\n\n  # Build 3 layer DNN with 10, 20, 10 units respectively.\n  model_dir = FLAGS.model_dir or tempfile.mkdtemp(prefix=\"debug_tflearn_iris_\")\n\n  classifier = tf.estimator.DNNClassifier(\n      feature_columns=feature_columns,\n      hidden_units=[10, 20, 10],\n      n_classes=3,\n      model_dir=model_dir)\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  hooks = []\n  if FLAGS.debug:\n    if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n    else:\n      config_file_path = None\n    hooks.append(\n        tf_debug.LocalCLIDebugHook(\n            ui_type=FLAGS.ui_type,\n            dump_root=FLAGS.dump_root,\n            config_file_path=config_file_path))\n  elif FLAGS.tensorboard_debug_address:\n    hooks.append(tf_debug.TensorBoardDebugHook(FLAGS.tensorboard_debug_address))\n\n  # Train model, using tfdbg hook.\n  classifier.train(training_input_fn, steps=FLAGS.train_steps, hooks=hooks)\n\n  # Evaluate accuracy, using tfdbg hook.\n  accuracy_score = classifier.evaluate(\n      test_input_fn, steps=FLAGS.eval_steps, hooks=hooks)[\"accuracy\"]\n\n  print(\"After training %d steps, Accuracy = %f\" %\n        (FLAGS.train_steps, accuracy_score))\n\n  # Make predictions, using tfdbg hook.\n  predict_results = classifier.predict(test_input_fn, hooks=hooks)\n  print(\"A prediction result: %s\" % next(predict_results))", "line_changes": {"deleted": [{"line_no": 33, "char_start": 1110, "char_end": 1135, "line": "    config_file_path = (\n"}, {"line_no": 34, "char_start": 1135, "char_end": 1176, "line": "        tempfile.mktemp(\".tfdbg_config\")\n"}, {"line_no": 35, "char_start": 1176, "char_end": 1227, "line": "        if FLAGS.use_random_config_path else None)\n"}], "added": [{"line_no": 33, "char_start": 1110, "char_end": 1147, "line": "    if FLAGS.use_random_config_path:\n"}, {"line_no": 35, "char_start": 1200, "char_end": 1262, "line": "      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n"}, {"line_no": 36, "char_start": 1262, "char_end": 1272, "line": "    else:\n"}, {"line_no": 37, "char_start": 1272, "char_end": 1302, "line": "      config_file_path = None\n"}]}, "char_changes": {"deleted": [{"char_start": 1132, "char_end": 1142, "chars": " (\n       "}, {"char_start": 1180, "char_end": 1204, "chars": "    if FLAGS.use_random_"}, {"char_start": 1216, "char_end": 1220, "chars": "else"}, {"char_start": 1225, "char_end": 1226, "chars": ")"}], "added": [{"char_start": 1114, "char_end": 1209, "chars": "if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, "}, {"char_start": 1239, "char_end": 1240, "chars": "s"}, {"char_start": 1266, "char_end": 1278, "chars": "else:\n      "}, {"char_start": 1285, "char_end": 1290, "chars": "file_"}, {"char_start": 1295, "char_end": 1296, "chars": "="}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/62644d6d2af6e185361f770099bf5d5e6d2d39ff", "file_name": "debug_tflearn_iris.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420360028\nChange-Id: Icd8a7ba3e47c2ff63a26a2fe007737ef01c0cb1d", "description": "Write a Python script using TensorFlow to create, train, and evaluate a DNNClassifier for the Iris dataset with debugging hooks."}
{"func_name": "article", "func_src_before": "  def article\n    @article = Article.find(params[:id])\n    @feedbacks = Feedback.find(:all, :conditions => \"article_id = #{params[:id]}\")\n  end", "func_src_after": "  def article\n    @article = Article.find(params[:id])\n    @feedbacks = Feedback.find(:all, :conditions => {:article_id => params[:id]})\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 55, "char_end": 138, "line": "    @feedbacks = Feedback.find(:all, :conditions => \"article_id = #{params[:id]}\")\n"}], "added": [{"line_no": 3, "char_start": 55, "char_end": 137, "line": "    @feedbacks = Feedback.find(:all, :conditions => {:article_id => params[:id]})\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 108, "chars": "\""}, {"char_start": 121, "char_end": 123, "chars": "#{"}, {"char_start": 135, "char_end": 136, "chars": "\""}], "added": [{"char_start": 107, "char_end": 109, "chars": "{:"}, {"char_start": 121, "char_end": 122, "chars": ">"}]}, "commit_link": "github.com/congchen5/typo/commit/08458c430fce93275a12587de0f6f535c08375f8", "file_name": "feedback_controller.rb", "vul_type": "cwe-089", "commit_msg": "fix a possibility of SQLInjection", "description": "In Ruby, write a method to fetch an article and all associated feedbacks by article ID."}
{"func_name": "get_error_days", "func_src_before": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > {}\n            ORDER BY log_errors.date'''.format(error_percent)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (error_percent, )\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > %s\n            ORDER BY log_errors.date'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for days with error rates above a threshold and save the results to a text file."}
{"func_name": "getPlayer", "func_src_before": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = '%s' COLLATE NOCASE\" % player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "func_src_after": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = ? COLLATE NOCASE\", player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function called `getPlayer` that retrieves a player's statistics from a database, ignoring case sensitivity in the player's name."}
{"func_name": "update", "func_src_before": "function update() {\n\tfor (const line of regexField.value.split('\\n')) {\n\t\t// Don't allow delimiters in RegExp string\n\t\tif (delimiters.test(line)) {\n\t\t\treturn setValidity(`Use <code>${line.replace(/^\\/|\\/$/g, '')}</code> instead of <code>${line}</code>. Slashes are not required.`);\n\t\t}\n\n\t\t// Fully test each RegExp\n\t\ttry {\n\t\t\t// eslint-disable-next-line no-new\n\t\t\tnew RegExp(line);\n\t\t} catch (error) {\n\t\t\treturn setValidity(error.message);\n\t\t}\n\t}\n\n\tsetValidity();\n\tsaveOptions();\n}", "func_src_after": "function update() {\n\tfor (const line of regexField.value.split('\\n')) {\n\t\t// Don't allow delimiters in RegExp string\n\t\tif (delimiters.test(line)) {\n\t\t\treturn setValidity(escapeTag`Use <code>${line.replace(/^\\/|\\/$/g, '')}</code> instead of <code>${line}</code>. Slashes are not required.`);\n\t\t}\n\n\t\t// Fully test each RegExp\n\t\ttry {\n\t\t\t// eslint-disable-next-line no-new\n\t\t\tnew RegExp(line);\n\t\t} catch (error) {\n\t\t\treturn setValidity(error.message);\n\t\t}\n\t}\n\n\tsetValidity();\n\tsaveOptions();\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 148, "char_end": 282, "line": "\t\t\treturn setValidity(`Use <code>${line.replace(/^\\/|\\/$/g, '')}</code> instead of <code>${line}</code>. Slashes are not required.`);\n"}], "added": [{"line_no": 5, "char_start": 148, "char_end": 291, "line": "\t\t\treturn setValidity(escapeTag`Use <code>${line.replace(/^\\/|\\/$/g, '')}</code> instead of <code>${line}</code>. Slashes are not required.`);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 170, "char_end": 179, "chars": "escapeTag"}]}, "commit_link": "github.com/sindresorhus/github-hide-files/commit/9de0c57df81db1178e0e79431d462f6d9842742e", "file_name": "options.js", "vul_type": "cwe-079", "commit_msg": "Avoid self-XSS (#73)", "description": "Create a JavaScript function that validates and updates regular expressions from a text field, excluding delimiter checks and error handling."}
{"func_name": "get", "func_src_before": "    @web.authenticated\n    def get(self, value):\n        if not self.is_admin():\n            raise web.HTTPError(404)\n        self.set_header('Content-Type', 'text/html')\n        self.write(\"<pre>\")\n        try:\n            server_log_path = os.path.join(options.contest_dir, \"server_log.txt\")\n            with open(server_log_path, 'r') as in_file:\n                lines = [line.decode('utf-8') for line in in_file.readlines()]\n                lines = [line for line in lines if all([v in line for v in value.split('/')])]\n                self.write(''.join(lines))\n        except:\n            logger.error(\"unable to read log: %s\" % (traceback.format_exception(*sys.exc_info()),))\n            self.write(\"unable to read log\")\n        self.write(\"</pre>\")", "func_src_after": "    @web.authenticated\n    def get(self, value):\n        if not self.is_admin():\n            raise web.HTTPError(404)\n        self.set_header('Content-Type', 'text/html')\n        self.write(\"<pre>\")\n        try:\n            server_log_path = os.path.join(options.contest_dir, \"server_log.txt\")\n            with open(server_log_path, 'r') as in_file:\n                lines = [line.decode('utf-8') for line in in_file.readlines()]\n                lines = [line for line in lines if all([v in line for v in value.split('/')])]\n                self.write(escape.xhtml_escape(''.join(lines)))\n        except:\n            logger.error(\"unable to read log: %s\" % (traceback.format_exception(*sys.exc_info()),))\n            self.write(\"unable to read log\")\n        self.write(\"</pre>\")", "line_changes": {"deleted": [{"line_no": 12, "char_start": 524, "char_end": 567, "line": "                self.write(''.join(lines))\n"}], "added": [{"line_no": 12, "char_start": 524, "char_end": 588, "line": "                self.write(escape.xhtml_escape(''.join(lines)))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 551, "char_end": 571, "chars": "escape.xhtml_escape("}, {"char_start": 586, "char_end": 587, "chars": ")"}]}, "commit_link": "github.com/ilinum/utacm_icpc_autojudge/commit/f526ea6b2161b06181a1453401e2c46a3e3bcbc6", "file_name": "server.py", "vul_type": "cwe-079", "commit_msg": "xss fix", "parent_commit": "312bc1f0f70d39a2acddfc88c90b6af40a10873f", "description": "Create a Python function that reads a log file and displays its contents filtered by a provided value, with admin-only access."}
{"func_name": "readContigTilesIntoBuffer", "func_src_before": "static int readContigTilesIntoBuffer (TIFF* in, uint8* buf, \n                                      uint32 imagelength, \n                                      uint32 imagewidth, \n                                      uint32 tw, uint32 tl,\n                                      tsample_t spp, uint16 bps)\n  {\n  int status = 1;\n  tsample_t sample = 0;\n  tsample_t count = spp; \n  uint32 row, col, trow;\n  uint32 nrow, ncol;\n  uint32 dst_rowsize, shift_width;\n  uint32 bytes_per_sample, bytes_per_pixel;\n  uint32 trailing_bits, prev_trailing_bits;\n  uint32 tile_rowsize  = TIFFTileRowSize(in);\n  uint32 src_offset, dst_offset;\n  uint32 row_offset, col_offset;\n  uint8 *bufp = (uint8*) buf;\n  unsigned char *src = NULL;\n  unsigned char *dst = NULL;\n  tsize_t tbytes = 0, tile_buffsize = 0;\n  tsize_t tilesize = TIFFTileSize(in);\n  unsigned char *tilebuf = NULL;\n\n  bytes_per_sample = (bps + 7) / 8; \n  bytes_per_pixel  = ((bps * spp) + 7) / 8;\n\n  if ((bps % 8) == 0)\n    shift_width = 0;\n  else\n    {\n    if (bytes_per_pixel < (bytes_per_sample + 1))\n      shift_width = bytes_per_pixel;\n    else\n      shift_width = bytes_per_sample + 1;\n    }\n\n  tile_buffsize = tilesize;\n  if (tilesize == 0 || tile_rowsize == 0)\n  {\n     TIFFError(\"readContigTilesIntoBuffer\", \"Tile size or tile rowsize is zero\");\n     exit(-1);\n  }\n\n  if (tilesize < (tsize_t)(tl * tile_rowsize))\n    {\n#ifdef DEBUG2\n    TIFFError(\"readContigTilesIntoBuffer\",\n\t      \"Tilesize %lu is too small, using alternate calculation %u\",\n              tilesize, tl * tile_rowsize);\n#endif\n    tile_buffsize = tl * tile_rowsize;\n    if (tl != (tile_buffsize / tile_rowsize))\n    {\n    \tTIFFError(\"readContigTilesIntoBuffer\", \"Integer overflow when calculating buffer size.\");\n        exit(-1);\n    }\n    }\n\n  tilebuf = _TIFFmalloc(tile_buffsize);\n  if (tilebuf == 0)\n    return 0;\n\n  dst_rowsize = ((imagewidth * bps * spp) + 7) / 8;  \n  for (row = 0; row < imagelength; row += tl)\n    {\n    nrow = (row + tl > imagelength) ? imagelength - row : tl;\n    for (col = 0; col < imagewidth; col += tw)\n      {\n      tbytes = TIFFReadTile(in, tilebuf, col, row, 0, 0);\n      if (tbytes < tilesize  && !ignore)\n        {\n\tTIFFError(TIFFFileName(in),\n\t\t  \"Error, can't read tile at row %lu col %lu, Read %lu bytes of %lu\",\n\t\t  (unsigned long) col, (unsigned long) row, (unsigned long)tbytes,\n                  (unsigned long)tilesize);\n\t\t  status = 0;\n                  _TIFFfree(tilebuf);\n\t\t  return status;\n\t}\n      \n      row_offset = row * dst_rowsize;\n      col_offset = ((col * bps * spp) + 7)/ 8;\n      bufp = buf + row_offset + col_offset;\n\n      if (col + tw > imagewidth)\n\tncol = imagewidth - col;\n      else\n        ncol = tw;\n\n      /* Each tile scanline will start on a byte boundary but it\n       * has to be merged into the scanline for the entire\n       * image buffer and the previous segment may not have\n       * ended on a byte boundary\n       */\n      /* Optimization for common bit depths, all samples */\n      if (((bps % 8) == 0) && (count == spp))\n        {\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n\t  _TIFFmemcpy (bufp, tilebuf + src_offset, (ncol * spp * bps) / 8);\n          bufp += (imagewidth * bps * spp) / 8;\n\t  }\n        }\n      else\n        {\n\t/* Bit depths not a multiple of 8 and/or extract fewer than spp samples */\n        prev_trailing_bits = trailing_bits = 0;\n        trailing_bits = (ncol * bps * spp) % 8;\n\n\t/*\tfor (trow = 0; tl < nrow; trow++) */\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n          src = tilebuf + src_offset;\n\t  dst_offset = (row + trow) * dst_rowsize;\n          dst = buf + dst_offset + col_offset;\n          switch (shift_width)\n            {\n            case 0: if (extractContigSamplesBytes (src, dst, ncol, sample,\n                                                   spp, bps, count, 0, ncol))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t\trow, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 1: if (bps == 1)\n                      { \n                      if (extractContigSamplesShifted8bits (src, dst, ncol,\n                                                            sample, spp,\n                                                            bps, count,\n                                                            0, ncol,\n                                                            prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t\t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t\t      break;\n\t\t      }\n                    else\n                      if (extractContigSamplesShifted16bits (src, dst, ncol,\n                                                             sample, spp,\n                                                             bps, count,\n                                                             0, ncol,\n                                                             prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t  \t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t            break;\n            case 2: if (extractContigSamplesShifted24bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t  \t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 3:\n            case 4:\n            case 5: if (extractContigSamplesShifted32bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            default: TIFFError(\"readContigTilesIntoBuffer\", \"Unsupported bit depth %d\", bps);\n\t\t     return 1;\n\t    }\n          }\n        prev_trailing_bits += trailing_bits;\n        /* if (prev_trailing_bits > 7) */\n\t/*   prev_trailing_bits-= 8; */\n\t}\n      }\n    }\n\n  _TIFFfree(tilebuf);\n  return status;\n  }", "func_src_after": "static int readContigTilesIntoBuffer (TIFF* in, uint8* buf, \n                                      uint32 imagelength, \n                                      uint32 imagewidth, \n                                      uint32 tw, uint32 tl,\n                                      tsample_t spp, uint16 bps)\n  {\n  int status = 1;\n  tsample_t sample = 0;\n  tsample_t count = spp; \n  uint32 row, col, trow;\n  uint32 nrow, ncol;\n  uint32 dst_rowsize, shift_width;\n  uint32 bytes_per_sample, bytes_per_pixel;\n  uint32 trailing_bits, prev_trailing_bits;\n  uint32 tile_rowsize  = TIFFTileRowSize(in);\n  uint32 src_offset, dst_offset;\n  uint32 row_offset, col_offset;\n  uint8 *bufp = (uint8*) buf;\n  unsigned char *src = NULL;\n  unsigned char *dst = NULL;\n  tsize_t tbytes = 0, tile_buffsize = 0;\n  tsize_t tilesize = TIFFTileSize(in);\n  unsigned char *tilebuf = NULL;\n\n  bytes_per_sample = (bps + 7) / 8; \n  bytes_per_pixel  = ((bps * spp) + 7) / 8;\n\n  if ((bps % 8) == 0)\n    shift_width = 0;\n  else\n    {\n    if (bytes_per_pixel < (bytes_per_sample + 1))\n      shift_width = bytes_per_pixel;\n    else\n      shift_width = bytes_per_sample + 1;\n    }\n\n  tile_buffsize = tilesize;\n  if (tilesize == 0 || tile_rowsize == 0)\n  {\n     TIFFError(\"readContigTilesIntoBuffer\", \"Tile size or tile rowsize is zero\");\n     exit(-1);\n  }\n\n  if (tilesize < (tsize_t)(tl * tile_rowsize))\n    {\n#ifdef DEBUG2\n    TIFFError(\"readContigTilesIntoBuffer\",\n\t      \"Tilesize %lu is too small, using alternate calculation %u\",\n              tilesize, tl * tile_rowsize);\n#endif\n    tile_buffsize = tl * tile_rowsize;\n    if (tl != (tile_buffsize / tile_rowsize))\n    {\n    \tTIFFError(\"readContigTilesIntoBuffer\", \"Integer overflow when calculating buffer size.\");\n        exit(-1);\n    }\n    }\n\n  /* Add 3 padding bytes for extractContigSamplesShifted32bits */\n  if( tile_buffsize > 0xFFFFFFFFU - 3 )\n  {\n      TIFFError(\"readContigTilesIntoBuffer\", \"Integer overflow when calculating buffer size.\");\n      exit(-1);\n  }\n  tilebuf = _TIFFmalloc(tile_buffsize + 3);\n  if (tilebuf == 0)\n    return 0;\n  tilebuf[tile_buffsize] = 0;\n  tilebuf[tile_buffsize+1] = 0;\n  tilebuf[tile_buffsize+2] = 0;\n\n  dst_rowsize = ((imagewidth * bps * spp) + 7) / 8;  \n  for (row = 0; row < imagelength; row += tl)\n    {\n    nrow = (row + tl > imagelength) ? imagelength - row : tl;\n    for (col = 0; col < imagewidth; col += tw)\n      {\n      tbytes = TIFFReadTile(in, tilebuf, col, row, 0, 0);\n      if (tbytes < tilesize  && !ignore)\n        {\n\tTIFFError(TIFFFileName(in),\n\t\t  \"Error, can't read tile at row %lu col %lu, Read %lu bytes of %lu\",\n\t\t  (unsigned long) col, (unsigned long) row, (unsigned long)tbytes,\n                  (unsigned long)tilesize);\n\t\t  status = 0;\n                  _TIFFfree(tilebuf);\n\t\t  return status;\n\t}\n      \n      row_offset = row * dst_rowsize;\n      col_offset = ((col * bps * spp) + 7)/ 8;\n      bufp = buf + row_offset + col_offset;\n\n      if (col + tw > imagewidth)\n\tncol = imagewidth - col;\n      else\n        ncol = tw;\n\n      /* Each tile scanline will start on a byte boundary but it\n       * has to be merged into the scanline for the entire\n       * image buffer and the previous segment may not have\n       * ended on a byte boundary\n       */\n      /* Optimization for common bit depths, all samples */\n      if (((bps % 8) == 0) && (count == spp))\n        {\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n\t  _TIFFmemcpy (bufp, tilebuf + src_offset, (ncol * spp * bps) / 8);\n          bufp += (imagewidth * bps * spp) / 8;\n\t  }\n        }\n      else\n        {\n\t/* Bit depths not a multiple of 8 and/or extract fewer than spp samples */\n        prev_trailing_bits = trailing_bits = 0;\n        trailing_bits = (ncol * bps * spp) % 8;\n\n\t/*\tfor (trow = 0; tl < nrow; trow++) */\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n          src = tilebuf + src_offset;\n\t  dst_offset = (row + trow) * dst_rowsize;\n          dst = buf + dst_offset + col_offset;\n          switch (shift_width)\n            {\n            case 0: if (extractContigSamplesBytes (src, dst, ncol, sample,\n                                                   spp, bps, count, 0, ncol))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t\trow, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 1: if (bps == 1)\n                      { \n                      if (extractContigSamplesShifted8bits (src, dst, ncol,\n                                                            sample, spp,\n                                                            bps, count,\n                                                            0, ncol,\n                                                            prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t\t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t\t      break;\n\t\t      }\n                    else\n                      if (extractContigSamplesShifted16bits (src, dst, ncol,\n                                                             sample, spp,\n                                                             bps, count,\n                                                             0, ncol,\n                                                             prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t  \t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t            break;\n            case 2: if (extractContigSamplesShifted24bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t  \t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 3:\n            case 4:\n            case 5: if (extractContigSamplesShifted32bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            default: TIFFError(\"readContigTilesIntoBuffer\", \"Unsupported bit depth %d\", bps);\n\t\t     return 1;\n\t    }\n          }\n        prev_trailing_bits += trailing_bits;\n        /* if (prev_trailing_bits > 7) */\n\t/*   prev_trailing_bits-= 8; */\n\t}\n      }\n    }\n\n  _TIFFfree(tilebuf);\n  return status;\n  }", "commit_link": "github.com/vadz/libtiff/commit/ae9365db1b271b62b35ce018eac8799b1d5e8a53", "file_name": "tools/tiffcrop.c", "vul_type": "cwe-125", "description": "Write a C function to read image tiles into a buffer from a TIFF file, handling different bit depths and samples per pixel."}
{"func_name": "output", "func_src_before": "    def output\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "func_src_after": "    def output\n      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{intercom_settings_json};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 86, "char_end": 164, "line": "  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n"}], "added": [{"line_no": 2, "char_start": 15, "char_end": 112, "line": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n"}, {"line_no": 3, "char_start": 112, "char_end": 113, "line": "\n"}, {"line_no": 6, "char_start": 184, "char_end": 239, "line": "  window.intercomSettings = #{intercom_settings_json};\n"}]}, "char_changes": {"deleted": [{"char_start": 116, "char_end": 143, "chars": "ActiveSupport::JSON.encode("}, {"char_start": 160, "char_end": 161, "chars": ")"}], "added": [{"char_start": 15, "char_end": 113, "chars": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n"}, {"char_start": 231, "char_end": 236, "chars": "_json"}]}, "commit_link": "github.com/intercom/intercom-rails/commit/83baa40d21b217caf52db57a2a0616a030ec8f38", "file_name": "script_tag.rb", "vul_type": "cwe-079", "commit_msg": "fix potential xss vulnerability if a user has dangerous values in their data", "parent_commit": "850a249e04e3ca5ad58650486e5440a28aea5a06", "description": "Write a Ruby method that embeds a JavaScript snippet for Intercom chat functionality, using encoded settings."}
{"func_name": "save_page_edit", "func_src_before": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "func_src_after": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "In Python, write a Flask endpoint to save edited content for a given page, creating the page in the database if it doesn't exist."}
{"func_name": "edit_coordinator", "func_src_before": "@check_document_access_permission()\ndef edit_coordinator(request):\n  coordinator_id = request.GET.get('coordinator')\n  doc = None\n  \n  if coordinator_id:\n    doc = Document2.objects.get(id=coordinator_id)\n    coordinator = Coordinator(document=doc)\n  else:\n    coordinator = Coordinator()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  workflows = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                                    for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n\n  if coordinator_id and not filter(lambda a: a['uuid'] == coordinator.data['properties']['workflow'], workflows):\n    raise PopupException(_('You don\\'t have access to the workflow of this coordinator.'))\n\n  return render('editor/coordinator_editor.mako', request, {\n      'coordinator_json': coordinator.json,\n      'credentials_json': json.dumps(credentials.credentials.keys()),\n      'workflows_json': json.dumps(workflows),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })", "func_src_after": "@check_document_access_permission()\ndef edit_coordinator(request):\n  coordinator_id = request.GET.get('coordinator')\n  doc = None\n  \n  if coordinator_id:\n    doc = Document2.objects.get(id=coordinator_id)\n    coordinator = Coordinator(document=doc)\n  else:\n    coordinator = Coordinator()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  workflows = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                                    for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n\n  if coordinator_id and not filter(lambda a: a['uuid'] == coordinator.data['properties']['workflow'], workflows):\n    raise PopupException(_('You don\\'t have access to the workflow of this coordinator.'))\n\n  return render('editor/coordinator_editor.mako', request, {\n      'coordinator_json': coordinator.json_for_html(),\n      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })", "commit_link": "github.com/gethue/hue/commit/6641c62beaa1468082e47d82da5ed758d11c7735", "file_name": "apps/oozie/src/oozie/views/editor2.py", "vul_type": "cwe-079", "description": "In Python, write a view function `edit_coordinator` that checks access permissions, fetches coordinator and workflow details, and renders them to a template."}
{"func_name": "xsltKeyFunction", "func_src_before": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "func_src_after": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n        if (ret == NULL) {\n            ctxt->error = XPATH_MEMORY_ERROR;\n            xmlXPathFreeObject(obj1);\n            xmlXPathFreeObject(obj2);\n            return;\n        }\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "commit_link": "github.com/GNOME/libxslt/commit/aab7eedca3c2dcaa1795d6acba38a4c9811d2a75", "file_name": "libxslt/functions.c", "vul_type": "cwe-476", "description": "Write a C function named `xsltKeyFunction` that implements the XSLT key function in libxml2."}
{"func_name": "gravatar", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef gravatar(context, user, size=None):\n    \"\"\"\n    Outputs the HTML for displaying a user's gravatar.\n\n    This can take an optional size of the image (defaults to 80 if not\n    specified).\n\n    This is also influenced by the following settings:\n\n        GRAVATAR_SIZE    - Default size for gravatars\n        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)\n        GRAVATAR_DEFAULT - Default image set to show if the user hasn't\n                           specified a gravatar (identicon, monsterid, wavatar)\n\n    See http://www.gravatar.com/ for more information.\n    \"\"\"\n    url = get_gravatar_url(context['request'], user, size)\n\n    if url:\n        return ('<img src=\"%s\" width=\"%s\" height=\"%s\" alt=\"%s\" '\n                '     class=\"gravatar\"/>' %\n                (url, size, size, user.get_full_name() or user.username))\n    else:\n        return ''", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef gravatar(context, user, size=None):\n    \"\"\"\n    Outputs the HTML for displaying a user's gravatar.\n\n    This can take an optional size of the image (defaults to 80 if not\n    specified).\n\n    This is also influenced by the following settings:\n\n        GRAVATAR_SIZE    - Default size for gravatars\n        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)\n        GRAVATAR_DEFAULT - Default image set to show if the user hasn't\n                           specified a gravatar (identicon, monsterid, wavatar)\n\n    See http://www.gravatar.com/ for more information.\n    \"\"\"\n    url = get_gravatar_url(context['request'], user, size)\n\n    if url:\n        return format_html(\n            '<img src=\"{0}\" width=\"{1}\" height=\"{1}\" alt=\"{2}\" '\n            'class=\"gravatar\"/>',\n            url, size, user.get_full_name() or user.username)\n    else:\n        return ''", "commit_link": "github.com/djblets/djblets/commit/77ac64642ad530bf69e390c51fc6fdcb8914c8e7", "file_name": "djblets/gravatars/templatetags/gravatars.py", "vul_type": "cwe-079", "description": "Create a Django template tag in Python that generates an HTML image tag for a user's Gravatar with an optional size parameter."}
{"func_name": "Config.prototype.decode", "func_src_before": "Config.prototype.decode = function(data){\n    if(typeof data != 'string'){\n        if(typeof data.toString === 'function'){\n            data = data.toString();\n        } else {\n            throw new Error('expecting string but got '+typeof data);\n        }\n    }\n    var result = {};\n    var currentSection = undefined;\n    var lines = data.split(this.options.lineEnding);\n    for(var i = 0; i < lines.length; i++){\n        var line = lines[i];\n        if(this.options.trimLines === true){\n            line = line.trim();\n        }\n        if(line.length == 0 || stringBeginsWithOnOfTheseStrings(line,this.options.commentIdentifiers)){\n            continue;\n        }\n        \n        var sectionRegExp = new RegExp(\"^\\\\\"+this.options.sectionOpenIdentifier+\"(.*?)\\\\\"+this.options.sectionCloseIdentifier+\"$\");\n        var newSection = line.match(sectionRegExp);\n        if(newSection !== null){\n            currentSection = newSection[1];\n            if(typeof result[currentSection] === 'undefined'){\n                result[currentSection] = {};\n            }\n            continue;\n        }\n\n        var assignPosition = line.indexOf(this.options.assignIdentifier);\n        var key = undefined;\n        var value = undefined;\n        if(assignPosition === -1){\n            key = line;\n            value = this.options.defaultValue;\n        } else {\n            var assignIdentifierLength = this.options.assignIdentifier.length\n            if (this.options.ignoreMultipleAssignIdentifier) {\n                var regExp = new RegExp(escapeRegExp(this.options.assignIdentifier) + '+')\n                var matchResult = line.match(regExp)\n                if (matchResult !== null) {\n                    assignIdentifierLength = matchResult[0].length\n                }\n            }\n            key = line.substr(0,assignPosition);\n            value = line.substr(assignPosition+assignIdentifierLength);\n        }\n        if (typeof this.options.valueIdentifier === 'string') {\n            value = this.valueTrim(value, this.options.valueIdentifier);\n        }\n        if(typeof currentSection === 'undefined'){\n            result[key] = value;\n        } else {\n            result[currentSection][key] = value;\n        }\n    }\n    return result;\n}", "func_src_after": "Config.prototype.decode = function(data){\n    if(typeof data != 'string'){\n        if(typeof data.toString === 'function'){\n            data = data.toString();\n        } else {\n            throw new Error('expecting string but got '+typeof data);\n        }\n    }\n    var protectedKeys = ['__defineGetter__', '__defineSetter__', '__lookupGetter__', '__lookupSetter__', '__proto__'];\n    var result = {};\n    var currentSection = undefined;\n    var lines = data.split(this.options.lineEnding);\n    for(var i = 0; i < lines.length; i++){\n        var line = lines[i];\n        if(this.options.trimLines === true){\n            line = line.trim();\n        }\n        if(line.length == 0 || stringBeginsWithOnOfTheseStrings(line,this.options.commentIdentifiers)){\n            continue;\n        }\n        \n        var sectionRegExp = new RegExp(\"^\\\\\"+this.options.sectionOpenIdentifier+\"(.*?)\\\\\"+this.options.sectionCloseIdentifier+\"$\");\n        var newSection = line.match(sectionRegExp);\n        if(newSection !== null){\n            currentSection = newSection[1];\n            if(typeof result[currentSection] === 'undefined' && !protectedKeys.includes(currentSection)){\n                result[currentSection] = {};\n            }\n            continue;\n        }\n\n        var assignPosition = line.indexOf(this.options.assignIdentifier);\n        var key = undefined;\n        var value = undefined;\n        if(assignPosition === -1){\n            key = line;\n            value = this.options.defaultValue;\n        } else {\n            var assignIdentifierLength = this.options.assignIdentifier.length\n            if (this.options.ignoreMultipleAssignIdentifier) {\n                var regExp = new RegExp(escapeRegExp(this.options.assignIdentifier) + '+')\n                var matchResult = line.match(regExp)\n                if (matchResult !== null) {\n                    assignIdentifierLength = matchResult[0].length\n                }\n            }\n            key = line.substr(0,assignPosition);\n            value = line.substr(assignPosition+assignIdentifierLength);\n        }\n        if (typeof this.options.valueIdentifier === 'string') {\n            value = this.valueTrim(value, this.options.valueIdentifier);\n        }\n        if (protectedKeys.includes(currentSection) || protectedKeys.includes(key)) {\n            continue;\n        }\n        if(typeof currentSection === 'undefined'){\n            result[key] = value;\n        } else {\n            result[currentSection][key] = value;\n        }\n    }\n    return result;\n}", "line_changes": {"deleted": [{"line_no": 25, "char_start": 938, "char_end": 1001, "line": "            if(typeof result[currentSection] === 'undefined'){\n"}], "added": [{"line_no": 9, "char_start": 263, "char_end": 382, "line": "    var protectedKeys = ['__defineGetter__', '__defineSetter__', '__lookupGetter__', '__lookupSetter__', '__proto__'];\n"}, {"line_no": 26, "char_start": 1057, "char_end": 1163, "line": "            if(typeof result[currentSection] === 'undefined' && !protectedKeys.includes(currentSection)){\n"}, {"line_no": 53, "char_start": 2218, "char_end": 2303, "line": "        if (protectedKeys.includes(currentSection) || protectedKeys.includes(key)) {\n"}, {"line_no": 54, "char_start": 2303, "char_end": 2325, "line": "            continue;\n"}, {"line_no": 55, "char_start": 2325, "char_end": 2335, "line": "        }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 263, "char_end": 382, "chars": "    var protectedKeys = ['__defineGetter__', '__defineSetter__', '__lookupGetter__', '__lookupSetter__', '__proto__'];\n"}, {"char_start": 1117, "char_end": 1160, "chars": " && !protectedKeys.includes(currentSection)"}, {"char_start": 2218, "char_end": 2335, "chars": "        if (protectedKeys.includes(currentSection) || protectedKeys.includes(key)) {\n            continue;\n        }\n"}]}, "commit_link": "github.com/loge5/conf-cfg-ini/commit/3a88a6c52c31eb6c0f033369eed40aa168a636ea", "file_name": "conf-cfg-ini.js", "vul_type": "cwe-915", "commit_msg": "fix: prevent prototype pollution attack", "parent_commit": "abbaf8b61ba5040e04aaa55722c412e19a1bcab4", "description": "Write a JavaScript function named `decode` within a `Config` prototype that parses a string into a structured configuration object."}
{"func_name": "CreateBasket", "func_src_before": "func CreateBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tname := ps.ByName(\"basket\")\n\tif name == serviceOldAPIPath || name == serviceAPIPath || name == serviceUIPath {\n\t\thttp.Error(w, \"This basket name conflicts with reserved system path: \"+name, http.StatusForbidden)\n\t\treturn\n\t}\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tlog.Printf(\"[info] creating basket: %s\", name)\n\n\t// read config (max 2 kB)\n\tbody, err := ioutil.ReadAll(io.LimitReader(r.Body, 2048))\n\tr.Body.Close()\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// default config\n\tconfig := BasketConfig{ForwardURL: \"\", Capacity: serverConfig.InitCapacity}\n\tif len(body) > 0 {\n\t\tif err = json.Unmarshal(body, &config); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err = validateBasketConfig(&config); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusUnprocessableEntity)\n\t\t\treturn\n\t\t}\n\t}\n\n\tauth, err := basketsDb.Create(name, config)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusConflict)\n\t} else {\n\t\tjson, err := json.Marshal(auth)\n\t\twriteJSON(w, http.StatusCreated, json, err)\n\t}\n}", "func_src_after": "func CreateBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tname := ps.ByName(\"basket\")\n\tif name == serviceOldAPIPath || name == serviceAPIPath || name == serviceUIPath {\n\t\thttp.Error(w, \"This basket name conflicts with reserved system path: \"+name, http.StatusForbidden)\n\t\treturn\n\t}\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tlog.Printf(\"[info] creating basket: %s\", name)\n\n\t// read config (max 2 kB)\n\tbody, err := ioutil.ReadAll(io.LimitReader(r.Body, 2048))\n\tr.Body.Close()\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// default config\n\tconfig := BasketConfig{ForwardURL: \"\", Capacity: serverConfig.InitCapacity}\n\tif len(body) > 0 {\n\t\tif err = json.Unmarshal(body, &config); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err = validateBasketConfig(&config); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusUnprocessableEntity)\n\t\t\treturn\n\t\t}\n\t}\n\n\tauth, err := basketsDb.Create(name, config)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusConflict)\n\t} else {\n\t\tjson, err := json.Marshal(auth)\n\t\twriteJSON(w, http.StatusCreated, json, err)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 348, "char_end": 472, "line": "\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}], "added": [{"line_no": 8, "char_start": 348, "char_end": 470, "line": "\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}]}, "char_changes": {"deleted": [{"char_start": 386, "char_end": 389, "chars": "[\"+"}, {"char_start": 393, "char_end": 396, "chars": "+\"]"}], "added": [{"char_start": 386, "char_end": 390, "chars": "the "}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go function to create a basket with a name and optional configuration, handling name validation and potential errors."}
{"func_name": "search", "func_src_before": "  def search\n    escaped = params[:name].gsub('\\\\', '\\\\\\\\\\\\\\\\').gsub('%', '\\%').gsub('_', '\\_')\n    @searched = Restaurant.where(\"name like '%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'\")\n    if @searched.empty?\n      @error = \"\u691c\u7d22\u30ef\u30fc\u30c9\u304c\u30d2\u30c3\u30c8\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u3082\u3046\u4e00\u5ea6\u5165\u308c\u306a\u304a\u3057\u3066\u4e0b\u3055\u3044\u3002\"\n    end\n  end", "func_src_after": "  def search\n    escaped = params[:name].gsub('\\\\', '\\\\\\\\\\\\\\\\').gsub('%', '\\%').gsub('_', '\\_')\n    @searched = Restaurant.where(\"name like ? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%\")\n    if @searched.empty?\n      @error = \"\u691c\u7d22\u30ef\u30fc\u30c9\u304c\u30d2\u30c3\u30c8\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u3082\u3046\u4e00\u5ea6\u5165\u308c\u306a\u304a\u3057\u3066\u4e0b\u3055\u3044\u3002\"\n    end\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 96, "char_end": 203, "line": "    @searched = Restaurant.where(\"name like '%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'\")\n"}], "added": [{"line_no": 3, "char_start": 96, "char_end": 195, "line": "    @searched = Restaurant.where(\"name like ? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%\")\n"}]}, "char_changes": {"deleted": [{"char_start": 140, "char_end": 200, "chars": "'%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'"}], "added": [{"char_start": 140, "char_end": 192, "chars": "? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%"}]}, "commit_link": "github.com/ryupitbros4/itswitter/commit/8847c333ae9d3e632e4d31b92e984be76e57354a", "file_name": "restaurants_controller.rb", "vul_type": "cwe-089", "commit_msg": "Prevent SQL injection.", "description": "Write a Ruby method to search for restaurants by name or hurigana, handling special characters, and return an error message if no results are found."}
{"func_name": "puppet_enc_default", "func_src_before": "@app.route('/puppet/default', methods=['GET', 'POST'])\n@cortex.lib.user.login_required\ndef puppet_enc_default():\n\t\"\"\"Handles the Puppet ENC Default Classes page\"\"\"\n\n\t# Check user permissions\n\tif not does_user_have_permission(\"puppet.default_classes.view\"):\n\t\tabort(403)\n\n\t# Get the default YAML out of the kv table\n\tcurd = g.db.cursor(mysql.cursors.DictCursor)\n\tcurd.execute(\"SELECT `value` FROM `kv_settings` WHERE `key` = 'puppet.enc.default'\")\n\tresult = curd.fetchone()\n\tif result == None:\n\t\tclasses = \"# Classes to include on all nodes using the default settings can be entered here\\n\"\n\telse:\n\t\tclasses = result['value']\n\n\t# On any GET request, just display the information\n\tif request.method == 'GET':\n\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t# On any POST request, validate the input and then save\n\telif request.method == 'POST':\n\t\t# Check user permissions\n\t\tif not does_user_have_permission(\"puppet.default_classes.edit\"):\n\t\t\tabort(403)\n\n\t\t# Extract data from form\n\t\tclasses = request.form.get('classes', '')\n\n\t\t# Validate classes YAML\n\t\ttry:\n\t\t\tdata = yaml.load(classes)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\ttry:\n\t\t\tif not data is None:\n\t\t\t\tassert isinstance(data, dict)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: result was not a list of classes, did you forget a trailing colon? ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\t# Get a cursor to the database\n\t\t# Update the system\n\t\tcurd.execute('REPLACE INTO `kv_settings` (`key`, `value`) VALUES (\"puppet.enc.default\", %s)', (classes,))\n\t\tg.db.commit()\n\n\t\tcortex.lib.core.log(__name__, \"puppet.defaultconfig.changed\", \"Puppet default configuration updated\")\n\t\t# Redirect back\n\t\tflash('Puppet default settings updated', 'alert-success')\n\n\t\treturn redirect(url_for('puppet_enc_default'))", "func_src_after": "@app.route('/puppet/default', methods=['GET', 'POST'])\n@cortex.lib.user.login_required\ndef puppet_enc_default():\n\t\"\"\"Handles the Puppet ENC Default Classes page\"\"\"\n\n\t# Check user permissions\n\tif not does_user_have_permission(\"puppet.default_classes.view\"):\n\t\tabort(403)\n\n\t# Get the default YAML out of the kv table\n\tcurd = g.db.cursor(mysql.cursors.DictCursor)\n\tcurd.execute(\"SELECT `value` FROM `kv_settings` WHERE `key` = 'puppet.enc.default'\")\n\tresult = curd.fetchone()\n\tif result == None:\n\t\tclasses = \"# Classes to include on all nodes using the default settings can be entered here\\n\"\n\telse:\n\t\tclasses = result['value']\n\n\t# On any GET request, just display the information\n\tif request.method == 'GET':\n\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t# On any POST request, validate the input and then save\n\telif request.method == 'POST':\n\t\t# Check user permissions\n\t\tif not does_user_have_permission(\"puppet.default_classes.edit\"):\n\t\t\tabort(403)\n\n\t\t# Extract data from form\n\t\tclasses = request.form.get('classes', '')\n\n\t\t# Validate classes YAML\n\t\ttry:\n\t\t\tdata = yaml.safe_load(classes)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\ttry:\n\t\t\tif not data is None:\n\t\t\t\tassert isinstance(data, dict)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: result was not a list of classes, did you forget a trailing colon? ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\t# Get a cursor to the database\n\t\t# Update the system\n\t\tcurd.execute('REPLACE INTO `kv_settings` (`key`, `value`) VALUES (\"puppet.enc.default\", %s)', (classes,))\n\t\tg.db.commit()\n\n\t\tcortex.lib.core.log(__name__, \"puppet.defaultconfig.changed\", \"Puppet default configuration updated\")\n\t\t# Redirect back\n\t\tflash('Puppet default settings updated', 'alert-success')\n\n\t\treturn redirect(url_for('puppet_enc_default'))", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1118, "char_end": 1147, "line": "\t\t\tdata = yaml.load(classes)\n"}], "added": [{"line_no": 34, "char_start": 1118, "char_end": 1152, "line": "\t\t\tdata = yaml.safe_load(classes)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1133, "char_end": 1138, "chars": "safe_"}]}, "commit_link": "github.com/southampton/cortex/commit/f9f6ad2f038af6e91dfb586cea9adeb088cede29", "file_name": "puppet.py", "vul_type": "cwe-502", "commit_msg": "Replacing yaml.load with yaml.safe_load to prevent security issues (and security warnings!)", "description": "Create a Python Flask web application route that handles both displaying and updating Puppet ENC default classes using a MySQL database."}
{"func_name": "get_task", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_GET_TASK.value)\ndef get_task(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    if name == None:\n        bot.send_message(message.chat.id, \"You should login before get tasks.\")\n    else:\n        bases.update.update_user(name[1], name[0], name[2])\n        bot.send_message(message.chat.id, bases.problem.get_unsolved_problem(message.text, name[1]))\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_GET_TASK.value)\ndef get_task(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    if name == None:\n        bot.send_message(message.chat.id, \"You should login before get tasks.\")\n    else:\n        bases.update.update_user(name[1], name[0], name[2])\n        bot.send_message(message.chat.id, bases.problem.get_unsolved_problem(message.text, name[1]))\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a Telegram bot handler function that checks the user's state, retrieves their information from an SQLite database, and either prompts them to log in or sends them an unsolved task."}
{"func_name": "matchCurrentInput", "func_src_before": "matchCurrentInput(\n\t\tconst InString *input, int pos, const widechar *passInstructions, int passIC) {\n\tint k;\n\tint kk = pos;\n\tfor (k = passIC + 2; k < passIC + 2 + passInstructions[passIC + 1]; k++)\n\t\tif (input->chars[kk] == ENDSEGMENT || passInstructions[k] != input->chars[kk++])\n\t\t\treturn 0;\n\treturn 1;\n}", "func_src_after": "matchCurrentInput(\n\t\tconst InString *input, int pos, const widechar *passInstructions, int passIC) {\n\tint k;\n\tint kk = pos;\n\tfor (k = passIC + 2;\n\t\t\t((k < passIC + 2 + passInstructions[passIC + 1]) && (kk < input->length));\n\t\t\tk++)\n\t\tif (input->chars[kk] == ENDSEGMENT || passInstructions[k] != input->chars[kk++])\n\t\t\treturn 0;\n\treturn 1;\n}", "commit_link": "github.com/liblouis/liblouis/commit/5e4089659bb49b3095fa541fa6387b4c40d7396e", "file_name": "liblouis/lou_translateString.c", "vul_type": "cwe-125", "description": "Write a C function named `matchCurrentInput` that checks if a segment of an input string matches a sequence of pass instructions, starting at a given position."}
{"func_name": "(anonymous)", "func_src_before": "      this.element.find('table tbody').find('tr').each(function(index, tr) {\n        // add custom td handlers\n        var $currentRow = $(tr);\n        var $expand = null;\n        if(thisObj.options.expand_callback && thisObj.table){\n          var allTds = thisObj.table.fnGetTds($currentRow[0]);      \n          var row = [];\n          var i =0; \n          $(allTds).each(function(){ \n            row[i++] = $(this).html();\n          }); \n          $expand = thisObj.options.expand_callback(row);\n          if($expand === null){\n            var text = $currentRow.find('a.twist').text(); \n            $currentRow.find('a.twist').parent().append(text);\n            $currentRow.find('a.twist').remove();\n          }\n        }\n        \n        if(!$currentRow.data('events') || !('click' in $currentRow.data('events'))){\n          $currentRow.unbind('click').bind('click', function (e) {\n            if($(e.target).is('a') && $(e.target).hasClass('twist') && thisObj.options.expand_callback){\n              if(!$currentRow.next().hasClass('expanded')){\n                thisObj.element.find('table tbody').find('tr.expanded').remove(); // remove all expanded\n                thisObj.element.find('table tbody').find('a.expanded').removeClass('expanded');\n                if(!$expand.hasClass('expanded-row-inner-wrapper'))\n                  $expand.addClass('expanded-row-inner-wrapper');\n                if($expand && $expand.length > 0){\n                  $currentRow.after($('<tr>').addClass('expanded').append(\n                                  $('<td>').attr('colspan', $currentRow.find('td').length).append(\n                                    $expand)));\n                  $currentRow.find('a.twist').addClass('expanded');\n                }\n              }else{\n                thisObj.element.find('table tbody').find('tr.expanded').remove(); // remove all expanded \n                thisObj.element.find('table tbody').find('a.expanded').removeClass('expanded');\n              }\n            }else{\n              var $selectedRow = $currentRow; \n              var $rowCheckbox = $selectedRow.find('input[type=\"checkbox\"]');\n              if($rowCheckbox && $rowCheckbox.length > 0){\n                $selectedRow.toggleClass('selected-row');\n                if($selectedRow.hasClass('selected-row'))\n                  $rowCheckbox.attr('checked', true);\n                else\n                  $rowCheckbox.attr('checked', false);\n              }\n            }  \n          // checked/uncheck on checkbox\n            thisObj._onRowClick();\n            thisObj._trigger('row_click', e);\n          });\n        }\n\n        if (DEPRECATE && thisObj.options.context_menu_actions) {\n          rID = 'ri-'+S4()+S4();\n          $currentRow.attr('id', rID);\n          $.contextMenu({\n            selector: '#'+rID,\n            build: function(trigger, e) {\n              if(thisObj._countSelectedRows() <= 0)\n                return null;\n              return { items: thisObj.options.context_menu_actions()};\n            }\n          });\n        }\n      });\n      this.element.qtip();\n    },", "func_src_after": "      this.element.find('table tbody').find('tr').each(function(index, tr) {\n        // add custom td handlers\n        var $currentRow = $(tr);\n        var $expand = null;\n        if(thisObj.options.expand_callback && thisObj.table){\n          var allTds = thisObj.table.fnGetTds($currentRow[0]);      \n          var row = [];\n          var i =0; \n          $(allTds).each(function(){ \n            row[i++] = $(this).html();\n          }); \n          $expand = thisObj.options.expand_callback(row);\n          if($expand === null){\n            var text = $currentRow.find('a.twist').text(); \n            $currentRow.find('a.twist').parent().text(text);\n            $currentRow.find('a.twist').remove();\n          }\n        }\n        \n        if(!$currentRow.data('events') || !('click' in $currentRow.data('events'))){\n          $currentRow.unbind('click').bind('click', function (e) {\n            if($(e.target).is('a') && $(e.target).hasClass('twist') && thisObj.options.expand_callback){\n              if(!$currentRow.next().hasClass('expanded')){\n                thisObj.element.find('table tbody').find('tr.expanded').remove(); // remove all expanded\n                thisObj.element.find('table tbody').find('a.expanded').removeClass('expanded');\n                if(!$expand.hasClass('expanded-row-inner-wrapper'))\n                  $expand.addClass('expanded-row-inner-wrapper');\n                if($expand && $expand.length > 0){\n                  $currentRow.after($('<tr>').addClass('expanded').append(\n                                  $('<td>').attr('colspan', $currentRow.find('td').length).append(\n                                    $expand)));\n                  $currentRow.find('a.twist').addClass('expanded');\n                }\n              }else{\n                thisObj.element.find('table tbody').find('tr.expanded').remove(); // remove all expanded \n                thisObj.element.find('table tbody').find('a.expanded').removeClass('expanded');\n              }\n            }else{\n              var $selectedRow = $currentRow; \n              var $rowCheckbox = $selectedRow.find('input[type=\"checkbox\"]');\n              if($rowCheckbox && $rowCheckbox.length > 0){\n                $selectedRow.toggleClass('selected-row');\n                if($selectedRow.hasClass('selected-row'))\n                  $rowCheckbox.attr('checked', true);\n                else\n                  $rowCheckbox.attr('checked', false);\n              }\n            }  \n          // checked/uncheck on checkbox\n            thisObj._onRowClick();\n            thisObj._trigger('row_click', e);\n          });\n        }\n\n        if (DEPRECATE && thisObj.options.context_menu_actions) {\n          rID = 'ri-'+S4()+S4();\n          $currentRow.attr('id', rID);\n          $.contextMenu({\n            selector: '#'+rID,\n            build: function(trigger, e) {\n              if(thisObj._countSelectedRows() <= 0)\n                return null;\n              return { items: thisObj.options.context_menu_actions()};\n            }\n          });\n        }\n      });\n      this.element.qtip();\n    },", "line_changes": {"deleted": [{"line_no": 15, "char_start": 590, "char_end": 653, "line": "            $currentRow.find('a.twist').parent().append(text);\n"}], "added": [{"line_no": 15, "char_start": 590, "char_end": 651, "line": "            $currentRow.find('a.twist').parent().text(text);\n"}]}, "char_changes": {"deleted": [{"char_start": 639, "char_end": 645, "chars": "append"}], "added": [{"char_start": 639, "char_end": 643, "chars": "text"}]}, "commit_link": "github.com/eethomas/eucalyptus/commit/e6133f9af0199452f7dd51bf6ad146e73809046f", "file_name": "eucatable.js", "vul_type": "cwe-079", "commit_msg": "XSS Additional Fix: html(..) to text(..) in eucatable and sgroup JS files", "description": "In JavaScript, write a function to handle custom interactions with table rows, including expanding details and selecting rows with checkboxes."}
{"func_name": "handle_method_call", "func_src_before": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (element == NULL || element[0] == '\\0' || strlen(element) > 64)\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "func_src_after": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "commit_link": "github.com/abrt/abrt/commit/f3c2a6af3455b2882e28570e8a04f1c2d4500d5b", "file_name": "src/dbus/abrt-dbus.c", "vul_type": "cwe-022", "description": "Write a C function to handle various method calls for problem management over D-Bus."}
{"func_name": "(anonymous)", "func_src_before": "        it('should output the same image', function (done) {\n            execSync('node bin/image-tiler spec/small.png ' + tempDir + ' small_test_result_{z}_{x}_{y}.png');\n            expectImagesToBeTheSame(tempDir + '/small_test_result_0_0_0.png', 'spec/expected/small-test.png')\n            .then(done)\n            .catch(done.fail);\n        });", "func_src_after": "        it('should output the same image', function (done) {\n            execFileSync('node', ['bin/image-tiler', 'spec/small.png', tempDir, 'small_test_result_{z}_{x}_{y}.png']);\n            expectImagesToBeTheSame(tempDir + '/small_test_result_0_0_0.png', 'spec/expected/small-test.png')\n                .then(done)\n                .catch(done.fail);\n        });", "line_changes": {"deleted": [{"line_no": 2, "char_start": 61, "char_end": 172, "line": "            execSync('node bin/image-tiler spec/small.png ' + tempDir + ' small_test_result_{z}_{x}_{y}.png');\n"}, {"line_no": 4, "char_start": 282, "char_end": 306, "line": "            .then(done)\n"}, {"line_no": 5, "char_start": 306, "char_end": 337, "line": "            .catch(done.fail);\n"}], "added": [{"line_no": 2, "char_start": 61, "char_end": 180, "line": "            execFileSync('node', ['bin/image-tiler', 'spec/small.png', tempDir, 'small_test_result_{z}_{x}_{y}.png']);\n"}, {"line_no": 4, "char_start": 290, "char_end": 318, "line": "                .then(done)\n"}, {"line_no": 5, "char_start": 318, "char_end": 353, "line": "                .catch(done.fail);\n"}]}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 88, "chars": " "}, {"char_start": 103, "char_end": 104, "chars": " "}, {"char_start": 118, "char_end": 122, "chars": " ' +"}, {"char_start": 130, "char_end": 132, "chars": " +"}, {"char_start": 134, "char_end": 135, "chars": " "}], "added": [{"char_start": 77, "char_end": 81, "chars": "File"}, {"char_start": 91, "char_end": 96, "chars": "', ['"}, {"char_start": 111, "char_end": 115, "chars": "', '"}, {"char_start": 129, "char_end": 131, "chars": "',"}, {"char_start": 139, "char_end": 140, "chars": ","}, {"char_start": 176, "char_end": 177, "chars": "]"}, {"char_start": 302, "char_end": 306, "chars": "    "}, {"char_start": 318, "char_end": 322, "chars": "    "}]}, "commit_link": "github.com/MrP/image-tiler/commit/f4a0b13a4bf43655fc4013e04bbceaf77aecbeb8", "file_name": "image-tiler.spec.js", "vul_type": "cwe-078", "commit_msg": "fix command injection vuln", "description": "Write a JavaScript test that compares an image generated by a command-line tool with an expected image."}
{"func_name": "openPoll", "func_src_before": "@hook.command(adminonly=True)\ndef openPoll(question, reply=None, db=None):\n    \"\"\"Creates a new poll.\"\"\"\n    if not db_ready: db_init(db)\n    try:\n        active = db.execute(\"SELECT pollID FROM polls WHERE active = 1\").fetchone()[0]\n        if active: \n            reply(\"There already is an open poll.\")\n            return\n    except:\n        db.execute(\"INSERT INTO polls (question, active) VALUES ('{}', 1)\".format(question))\n        reply(\"Opened new poll: {}\".format(question))\n        #reply(\"Poll opened!\")\n    return", "func_src_after": "@hook.command(adminonly=True)\ndef openPoll(question, reply=None, db=None):\n    \"\"\"Creates a new poll.\"\"\"\n    if not db_ready: db_init(db)\n    try:\n        active = db.execute(\"SELECT pollID FROM polls WHERE active = 1\").fetchone()[0]\n        if active: \n            reply(\"There already is an open poll.\")\n            return\n    except:\n        db.execute(\"INSERT INTO polls (question, active) VALUES (?, 1)\", (question,))\n        reply(\"Opened new poll: {}\".format(question))\n        #reply(\"Poll opened!\")\n    return", "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089", "description": "Write a Python function that creates a new poll in a database, ensuring only one active poll exists at a time."}
{"func_name": "edit", "func_src_before": "  def edit\n    # give an error message is instructor have not set the time zone.\n    if current_user.timezonepref.nil?\n      flash.now[:error] = \"You have not specified your preferred timezone yet. Please do this before you set up the deadlines.\"\n    end\n    @topics = SignUpTopic.find_by_sql(\"select * from sign_up_topics where assignment_id=\" + params[:id])\n    @assignment_form = AssignmentForm.create_form_object(params[:id])\n    @user = current_user\n\n    @assignment_questionnaires = AssignmentQuestionnaire.where(assignment_id: params[:id])\n    @due_date_all = DueDate.where(assignment_id: params[:id])\n    @reviewvarycheck = false\n    @due_date_nameurl_notempty = false\n    @due_date_nameurl_notempty_checkbox = false\n    @metareview_allowed = false\n    @metareview_allowed_checkbox = false\n    @signup_allowed = false\n    @signup_allowed_checkbox = false\n    @drop_topic_allowed = false\n    @drop_topic_allowed_checkbox = false\n    @team_formation_allowed = false\n    @team_formation_allowed_checkbox = false\n    @participants_count = @assignment_form.assignment.participants.size\n    @teams_count = @assignment_form.assignment.teams.size\n\n    # Check if name and url in database is empty before webpage displays\n    @due_date_all.each do |dd|\n      @due_date_nameurl_notempty = is_due_date_nameurl_notempty(dd)\n      @due_date_nameurl_notempty_checkbox = @due_date_nameurl_notempty\n      @metareview_allowed = is_meta_review_allowed?(dd)\n      @drop_topic_allowed = is_drop_topic_allowed?(dd)\n      @signup_allowed = is_signup_allowed?(dd)\n      @team_formation_allowed = is_team_formation_allowed?(dd)\n\n      if dd.due_at.present?\n        dd.due_at = dd.due_at.to_s.in_time_zone(current_user.timezonepref)\n      end\n      if  @due_date_nameurl_notempty && @due_date_nameurl_notempty_checkbox &&\n          (@metareview_allowed || @drop_topic_allowed || @signup_allowed || @team_formation_allowed)\n        break\n      end\n    end\n\n    @assignment_questionnaires.each do |aq|\n      unless aq.used_in_round.nil?\n        @reviewvarycheck = 1\n        break\n      end\n    end\n    @due_date_all = update_nil_dd_deadline_name(@due_date_all)\n    @due_date_all = update_nil_dd_description_url(@due_date_all)\n\n    # only when instructor does not assign rubrics and in assignment edit page will show this error message.\n    if !empty_rubrics_list.empty? && request.original_fullpath == \"/assignments/#{@assignment_form.assignment.id}/edit\"\n      rubrics_needed = needed_rubrics(empty_rubrics_list)\n      flash.now[:error] = \"You did not specify all the necessary rubrics. You need \" + rubrics_needed +\n          \" of assignment <b>#{@assignment_form.assignment.name}</b> before saving the assignment. You can assign rubrics <a id='go_to_tabs2' style='color: blue;'>here</a>.\"\n    end\n\n    if @assignment_form.assignment.directory_path.nil? || @assignment_form.assignment.directory_path.empty?\n      flash.now[:error] = \"You did not specify your submission directory.\"\n    end\n  end", "func_src_after": "  def edit\n    # give an error message is instructor have not set the time zone.\n    if current_user.timezonepref.nil?\n      flash.now[:error] = \"You have not specified your preferred timezone yet. Please do this before you set up the deadlines.\"\n    end\n    @topics = SignUpTopic.where(assignment_id: params[:id])\n    @assignment_form = AssignmentForm.create_form_object(params[:id])\n    @user = current_user\n\n    @assignment_questionnaires = AssignmentQuestionnaire.where(assignment_id: params[:id])\n    @due_date_all = DueDate.where(assignment_id: params[:id])\n    @reviewvarycheck = false\n    @due_date_nameurl_notempty = false\n    @due_date_nameurl_notempty_checkbox = false\n    @metareview_allowed = false\n    @metareview_allowed_checkbox = false\n    @signup_allowed = false\n    @signup_allowed_checkbox = false\n    @drop_topic_allowed = false\n    @drop_topic_allowed_checkbox = false\n    @team_formation_allowed = false\n    @team_formation_allowed_checkbox = false\n    @participants_count = @assignment_form.assignment.participants.size\n    @teams_count = @assignment_form.assignment.teams.size\n\n    # Check if name and url in database is empty before webpage displays\n    @due_date_all.each do |dd|\n      @due_date_nameurl_notempty = is_due_date_nameurl_notempty(dd)\n      @due_date_nameurl_notempty_checkbox = @due_date_nameurl_notempty\n      @metareview_allowed = is_meta_review_allowed?(dd)\n      @drop_topic_allowed = is_drop_topic_allowed?(dd)\n      @signup_allowed = is_signup_allowed?(dd)\n      @team_formation_allowed = is_team_formation_allowed?(dd)\n\n      if dd.due_at.present?\n        dd.due_at = dd.due_at.to_s.in_time_zone(current_user.timezonepref)\n      end\n      if  @due_date_nameurl_notempty && @due_date_nameurl_notempty_checkbox &&\n          (@metareview_allowed || @drop_topic_allowed || @signup_allowed || @team_formation_allowed)\n        break\n      end\n    end\n\n    @assignment_questionnaires.each do |aq|\n      unless aq.used_in_round.nil?\n        @reviewvarycheck = 1\n        break\n      end\n    end\n    @due_date_all = update_nil_dd_deadline_name(@due_date_all)\n    @due_date_all = update_nil_dd_description_url(@due_date_all)\n\n    # only when instructor does not assign rubrics and in assignment edit page will show this error message.\n    if !empty_rubrics_list.empty? && request.original_fullpath == \"/assignments/#{@assignment_form.assignment.id}/edit\"\n      rubrics_needed = needed_rubrics(empty_rubrics_list)\n      flash.now[:error] = \"You did not specify all the necessary rubrics. You need \" + rubrics_needed +\n          \" of assignment <b>#{@assignment_form.assignment.name}</b> before saving the assignment. You can assign rubrics <a id='go_to_tabs2' style='color: blue;'>here</a>.\"\n    end\n\n    if @assignment_form.assignment.directory_path.nil? || @assignment_form.assignment.directory_path.empty?\n      flash.now[:error] = \"You did not specify your submission directory.\"\n    end\n  end", "line_changes": {"deleted": [{"line_no": 6, "char_start": 255, "char_end": 360, "line": "    @topics = SignUpTopic.find_by_sql(\"select * from sign_up_topics where assignment_id=\" + params[:id])\n"}], "added": [{"line_no": 6, "char_start": 255, "char_end": 315, "line": "    @topics = SignUpTopic.where(assignment_id: params[:id])\n"}]}, "char_changes": {"deleted": [{"char_start": 281, "char_end": 323, "chars": "find_by_sql(\"select * from sign_up_topics "}, {"char_start": 328, "char_end": 329, "chars": " "}, {"char_start": 342, "char_end": 346, "chars": "=\" +"}], "added": [{"char_start": 286, "char_end": 287, "chars": "("}, {"char_start": 300, "char_end": 301, "chars": ":"}]}, "commit_link": "github.com/urmilparikh95/expertiza/commit/fa775cc1b2cfb68902042db139bf24447f25c1eb", "file_name": "assignments_controller.rb", "vul_type": "cwe-089", "commit_msg": "Handle possible SQL injections.", "parent_commit": "e9772caf7b3e799914fd0dfca9be264cfbb5f7c7", "description": "Write a Ruby method to edit assignment details, checking for user timezone preferences and ensuring all necessary components like topics, questionnaires, and due dates are loaded and validated."}
{"func_name": "tid_num_to_tag_nums", "func_src_before": "    def tid_num_to_tag_nums(self, tid_num):\n        ''' Returns list of the associated tag_nums to the given tid_num. '''\n\n        q = \"SELECT tag FROM tid_tag WHERE tid = '\" + str(tid_num) + \"'\"\n        self.query(q)\n        return [i[0] for i in self.c.fetchall()]", "func_src_after": "    def tid_num_to_tag_nums(self, tid_num):\n        ''' Returns list of the associated tag_nums to the given tid_num. '''\n\n        q = \"SELECT tag FROM tid_tag WHERE tid = ?\"\n        self.query(q, tid_num)\n        return [i[0] for i in self.c.fetchall()]", "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves a list of tags associated with a given ID from a database."}
{"func_name": "main", "func_src_before": "def main(_):\n  # Create a dummy dataset.\n  num_examples = 8\n  steps_per_epoch = 2\n  input_dims = 3\n  output_dims = 1\n  xs = np.zeros([num_examples, input_dims])\n  ys = np.zeros([num_examples, output_dims])\n  dataset = tf.data.Dataset.from_tensor_slices(\n      (xs, ys)).repeat(num_examples).batch(int(num_examples / steps_per_epoch))\n\n  sess = tf.Session()\n  if FLAGS.debug:\n    # Use the command-line interface (CLI) of tfdbg.\n    config_file_path = (\n        tempfile.mktemp(\".tfdbg_config\")\n        if FLAGS.use_random_config_path else None)\n    sess = tf_debug.LocalCLIDebugWrapperSession(\n        sess, ui_type=FLAGS.ui_type, config_file_path=config_file_path)\n  elif FLAGS.tensorboard_debug_address:\n    # Use the TensorBoard Debugger Plugin (GUI of tfdbg).\n    sess = tf_debug.TensorBoardDebugWrapperSession(\n        sess, FLAGS.tensorboard_debug_address)\n  tf.keras.backend.set_session(sess)\n\n  # Create a dummy model.\n  model = tf.keras.Sequential(\n      [tf.keras.layers.Dense(1, input_shape=[input_dims])])\n  model.compile(loss=\"mse\", optimizer=\"sgd\")\n\n  # Train the model using the dummy dataset created above.\n  model.fit(dataset, epochs=FLAGS.epochs, steps_per_epoch=steps_per_epoch)", "func_src_after": "def main(_):\n  # Create a dummy dataset.\n  num_examples = 8\n  steps_per_epoch = 2\n  input_dims = 3\n  output_dims = 1\n  xs = np.zeros([num_examples, input_dims])\n  ys = np.zeros([num_examples, output_dims])\n  dataset = tf.data.Dataset.from_tensor_slices(\n      (xs, ys)).repeat(num_examples).batch(int(num_examples / steps_per_epoch))\n\n  sess = tf.Session()\n  if FLAGS.debug:\n    # Use the command-line interface (CLI) of tfdbg.\n    if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n    else:\n      config_file_path = None\n    sess = tf_debug.LocalCLIDebugWrapperSession(\n        sess, ui_type=FLAGS.ui_type, config_file_path=config_file_path)\n  elif FLAGS.tensorboard_debug_address:\n    # Use the TensorBoard Debugger Plugin (GUI of tfdbg).\n    sess = tf_debug.TensorBoardDebugWrapperSession(\n        sess, FLAGS.tensorboard_debug_address)\n  tf.keras.backend.set_session(sess)\n\n  # Create a dummy model.\n  model = tf.keras.Sequential(\n      [tf.keras.layers.Dense(1, input_shape=[input_dims])])\n  model.compile(loss=\"mse\", optimizer=\"sgd\")\n\n  # Train the model using the dummy dataset created above.\n  model.fit(dataset, epochs=FLAGS.epochs, steps_per_epoch=steps_per_epoch)", "line_changes": {"deleted": [{"line_no": 15, "char_start": 428, "char_end": 453, "line": "    config_file_path = (\n"}, {"line_no": 16, "char_start": 453, "char_end": 494, "line": "        tempfile.mktemp(\".tfdbg_config\")\n"}, {"line_no": 17, "char_start": 494, "char_end": 545, "line": "        if FLAGS.use_random_config_path else None)\n"}], "added": [{"line_no": 15, "char_start": 428, "char_end": 465, "line": "    if FLAGS.use_random_config_path:\n"}, {"line_no": 17, "char_start": 518, "char_end": 580, "line": "      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n"}, {"line_no": 18, "char_start": 580, "char_end": 590, "line": "    else:\n"}, {"line_no": 19, "char_start": 590, "char_end": 620, "line": "      config_file_path = None\n"}]}, "char_changes": {"deleted": [{"char_start": 450, "char_end": 460, "chars": " (\n       "}, {"char_start": 498, "char_end": 522, "chars": "    if FLAGS.use_random_"}, {"char_start": 534, "char_end": 538, "chars": "else"}, {"char_start": 543, "char_end": 544, "chars": ")"}], "added": [{"char_start": 432, "char_end": 527, "chars": "if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, "}, {"char_start": 557, "char_end": 558, "chars": "s"}, {"char_start": 584, "char_end": 596, "chars": "else:\n      "}, {"char_start": 603, "char_end": 608, "chars": "file_"}, {"char_start": 613, "char_end": 614, "chars": "="}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/4b50e584962179c978227a5c534dcd8146e03e6f", "file_name": "debug_keras.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359138\nChange-Id: I8afc97448b1e730ac5883c2033f3b0e544b8fb58", "description": "Write a Python script using TensorFlow to create and train a dummy model with a dataset, including optional debug configurations."}
{"func_name": "download", "func_src_before": "    def download(self, log_files, sort='time', limit=-1, nfl_filter='',\n                 output_format='default'):\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            nfl_esc = nfl_filter.replace('(', '\\(').replace(')', '\\)')\n            # remove the slash that is intentionally added in the URL\n            # to avoid failure of filtering stats data.\n            if nfl_esc.startswith('/'):\n                nfl_esc = nfl_esc[1:]\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            if output_format == 'python':\n                data = self.format_source_code(nfl_filter)\n            elif output_format == 'json':\n                data = stats.to_json(nfl_esc, limit)\n            elif output_format == 'csv':\n                data = stats.to_csv(nfl_esc, limit)\n            elif output_format == 'ods':\n                data = stats.to_ods(nfl_esc, limit)\n            else:\n                profile_tmp_all = tempfile.mktemp('.profile', 'all')\n                stats.dump_stats(profile_tmp_all)\n                data = open(profile_tmp_all).read()\n                os.remove(profile_tmp_all)\n            return data, [('content-type', self.format_dict[output_format])]\n        except ODFLIBNotInstalled as ex:\n            raise ex\n        except Exception as ex:\n            raise ProfileException(_('Data download error: %s') % ex)", "func_src_after": "    def download(self, log_files, sort='time', limit=-1, nfl_filter='',\n                 output_format='default'):\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            nfl_esc = nfl_filter.replace('(', '\\(').replace(')', '\\)')\n            # remove the slash that is intentionally added in the URL\n            # to avoid failure of filtering stats data.\n            if nfl_esc.startswith('/'):\n                nfl_esc = nfl_esc[1:]\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            if output_format == 'python':\n                data = self.format_source_code(nfl_filter)\n            elif output_format == 'json':\n                data = stats.to_json(nfl_esc, limit)\n            elif output_format == 'csv':\n                data = stats.to_csv(nfl_esc, limit)\n            elif output_format == 'ods':\n                data = stats.to_ods(nfl_esc, limit)\n            else:\n                data = stats.print_stats()\n            return data, [('content-type', self.format_dict[output_format])]\n        except ODFLIBNotInstalled as ex:\n            raise ex\n        except Exception as ex:\n            raise ProfileException(_('Data download error: %s') % ex)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 969, "char_end": 1038, "line": "                profile_tmp_all = tempfile.mktemp('.profile', 'all')\n"}, {"line_no": 23, "char_start": 1038, "char_end": 1088, "line": "                stats.dump_stats(profile_tmp_all)\n"}, {"line_no": 24, "char_start": 1088, "char_end": 1140, "line": "                data = open(profile_tmp_all).read()\n"}, {"line_no": 25, "char_start": 1140, "char_end": 1183, "line": "                os.remove(profile_tmp_all)\n"}], "added": [{"line_no": 22, "char_start": 969, "char_end": 1012, "line": "                data = stats.print_stats()\n"}]}, "char_changes": {"deleted": [{"char_start": 985, "char_end": 1181, "chars": "profile_tmp_all = tempfile.mktemp('.profile', 'all')\n                stats.dump_stats(profile_tmp_all)\n                data = open(profile_tmp_all).read()\n                os.remove(profile_tmp_all"}], "added": [{"char_start": 985, "char_end": 1010, "chars": "data = stats.print_stats("}]}, "commit_link": "github.com/scality/ScalitySproxydSwift/commit/6978275cdb04bb08aaf142d401b52a46527dac4c", "file_name": "html_viewer.py", "vul_type": "cwe-377", "commit_msg": "Avoid usage of insecure mktemp() function\n\nThis patch eliminates the use of the deprecated and insecure\ntempfile.mktemp() function.  It has been replaced with secure\nalternatives where temporary files are actually required.\n\nChange-Id: I0a13d6d44cd1abc4b66fa33f39eea407617a01d5\nSecurityImpact\nCloses-bug: #1348869", "description": "Write a Python function named `download` that processes log files and returns data in various formats based on given parameters."}
{"func_name": "kvm_vm_ioctl_check_extension", "func_src_before": "int kvm_vm_ioctl_check_extension(struct kvm *kvm, long ext)\n{\n\tint r;\n\t/* Assume we're using HV mode when the HV module is loaded */\n\tint hv_enabled = kvmppc_hv_ops ? 1 : 0;\n\n\tif (kvm) {\n\t\t/*\n\t\t * Hooray - we know which VM type we're running on. Depend on\n\t\t * that rather than the guess above.\n\t\t */\n\t\thv_enabled = is_kvmppc_hv_enabled(kvm);\n\t}\n\n\tswitch (ext) {\n#ifdef CONFIG_BOOKE\n\tcase KVM_CAP_PPC_BOOKE_SREGS:\n\tcase KVM_CAP_PPC_BOOKE_WATCHDOG:\n\tcase KVM_CAP_PPC_EPR:\n#else\n\tcase KVM_CAP_PPC_SEGSTATE:\n\tcase KVM_CAP_PPC_HIOR:\n\tcase KVM_CAP_PPC_PAPR:\n#endif\n\tcase KVM_CAP_PPC_UNSET_IRQ:\n\tcase KVM_CAP_PPC_IRQ_LEVEL:\n\tcase KVM_CAP_ENABLE_CAP:\n\tcase KVM_CAP_ENABLE_CAP_VM:\n\tcase KVM_CAP_ONE_REG:\n\tcase KVM_CAP_IOEVENTFD:\n\tcase KVM_CAP_DEVICE_CTRL:\n\tcase KVM_CAP_IMMEDIATE_EXIT:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_PPC_PAIRED_SINGLES:\n\tcase KVM_CAP_PPC_OSI:\n\tcase KVM_CAP_PPC_GET_PVINFO:\n#if defined(CONFIG_KVM_E500V2) || defined(CONFIG_KVM_E500MC)\n\tcase KVM_CAP_SW_TLB:\n#endif\n\t\t/* We support this only for PR */\n\t\tr = !hv_enabled;\n\t\tbreak;\n#ifdef CONFIG_KVM_MPIC\n\tcase KVM_CAP_IRQ_MPIC:\n\t\tr = 1;\n\t\tbreak;\n#endif\n\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_SPAPR_TCE:\n\tcase KVM_CAP_SPAPR_TCE_64:\n\t\t/* fallthrough */\n\tcase KVM_CAP_SPAPR_TCE_VFIO:\n\tcase KVM_CAP_PPC_RTAS:\n\tcase KVM_CAP_PPC_FIXUP_HCALL:\n\tcase KVM_CAP_PPC_ENABLE_HCALL:\n#ifdef CONFIG_KVM_XICS\n\tcase KVM_CAP_IRQ_XICS:\n#endif\n\t\tr = 1;\n\t\tbreak;\n\n\tcase KVM_CAP_PPC_ALLOC_HTAB:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif /* CONFIG_PPC_BOOK3S_64 */\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_SMT:\n\t\tr = 0;\n\t\tif (kvm) {\n\t\t\tif (kvm->arch.emul_smt_mode > 1)\n\t\t\t\tr = kvm->arch.emul_smt_mode;\n\t\t\telse\n\t\t\t\tr = kvm->arch.smt_mode;\n\t\t} else if (hv_enabled) {\n\t\t\tif (cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = 1;\n\t\t\telse\n\t\t\t\tr = threads_per_subcore;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_SMT_POSSIBLE:\n\t\tr = 1;\n\t\tif (hv_enabled) {\n\t\t\tif (!cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = ((threads_per_subcore << 1) - 1);\n\t\t\telse\n\t\t\t\t/* P9 can emulate dbells, so allow any mode */\n\t\t\t\tr = 8 | 4 | 2 | 1;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_RMA:\n\t\tr = 0;\n\t\tbreak;\n\tcase KVM_CAP_PPC_HWRNG:\n\t\tr = kvmppc_hwrng_present();\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_RADIX:\n\t\tr = !!(hv_enabled && radix_enabled());\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_HASH_V3:\n\t\tr = !!(hv_enabled && !radix_enabled() &&\n\t\t       cpu_has_feature(CPU_FTR_ARCH_300));\n\t\tbreak;\n#endif\n\tcase KVM_CAP_SYNC_MMU:\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\t\tr = hv_enabled;\n#elif defined(KVM_ARCH_WANT_MMU_NOTIFIER)\n\t\tr = 1;\n#else\n\t\tr = 0;\n#endif\n\t\tbreak;\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_HTAB_FD:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_NR_VCPUS:\n\t\t/*\n\t\t * Recommending a number of CPUs is somewhat arbitrary; we\n\t\t * return the number of present CPUs for -HV (since a host\n\t\t * will have secondary threads \"offline\"), and for other KVM\n\t\t * implementations just count online CPUs.\n\t\t */\n\t\tif (hv_enabled)\n\t\t\tr = num_present_cpus();\n\t\telse\n\t\t\tr = num_online_cpus();\n\t\tbreak;\n\tcase KVM_CAP_NR_MEMSLOTS:\n\t\tr = KVM_USER_MEM_SLOTS;\n\t\tbreak;\n\tcase KVM_CAP_MAX_VCPUS:\n\t\tr = KVM_MAX_VCPUS;\n\t\tbreak;\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_PPC_GET_SMMU_INFO:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_MULTITCE:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_RESIZE_HPT:\n\t\t/* Disable this on POWER9 until code handles new HPTE format */\n\t\tr = !!hv_enabled && !cpu_has_feature(CPU_FTR_ARCH_300);\n\t\tbreak;\n#endif\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_FWNMI:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_PPC_HTM:\n\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) &&\n\t\t    is_kvmppc_hv_enabled(kvm);\n\t\tbreak;\n\tdefault:\n\t\tr = 0;\n\t\tbreak;\n\t}\n\treturn r;\n\n}", "func_src_after": "int kvm_vm_ioctl_check_extension(struct kvm *kvm, long ext)\n{\n\tint r;\n\t/* Assume we're using HV mode when the HV module is loaded */\n\tint hv_enabled = kvmppc_hv_ops ? 1 : 0;\n\n\tif (kvm) {\n\t\t/*\n\t\t * Hooray - we know which VM type we're running on. Depend on\n\t\t * that rather than the guess above.\n\t\t */\n\t\thv_enabled = is_kvmppc_hv_enabled(kvm);\n\t}\n\n\tswitch (ext) {\n#ifdef CONFIG_BOOKE\n\tcase KVM_CAP_PPC_BOOKE_SREGS:\n\tcase KVM_CAP_PPC_BOOKE_WATCHDOG:\n\tcase KVM_CAP_PPC_EPR:\n#else\n\tcase KVM_CAP_PPC_SEGSTATE:\n\tcase KVM_CAP_PPC_HIOR:\n\tcase KVM_CAP_PPC_PAPR:\n#endif\n\tcase KVM_CAP_PPC_UNSET_IRQ:\n\tcase KVM_CAP_PPC_IRQ_LEVEL:\n\tcase KVM_CAP_ENABLE_CAP:\n\tcase KVM_CAP_ENABLE_CAP_VM:\n\tcase KVM_CAP_ONE_REG:\n\tcase KVM_CAP_IOEVENTFD:\n\tcase KVM_CAP_DEVICE_CTRL:\n\tcase KVM_CAP_IMMEDIATE_EXIT:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_PPC_PAIRED_SINGLES:\n\tcase KVM_CAP_PPC_OSI:\n\tcase KVM_CAP_PPC_GET_PVINFO:\n#if defined(CONFIG_KVM_E500V2) || defined(CONFIG_KVM_E500MC)\n\tcase KVM_CAP_SW_TLB:\n#endif\n\t\t/* We support this only for PR */\n\t\tr = !hv_enabled;\n\t\tbreak;\n#ifdef CONFIG_KVM_MPIC\n\tcase KVM_CAP_IRQ_MPIC:\n\t\tr = 1;\n\t\tbreak;\n#endif\n\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_SPAPR_TCE:\n\tcase KVM_CAP_SPAPR_TCE_64:\n\t\t/* fallthrough */\n\tcase KVM_CAP_SPAPR_TCE_VFIO:\n\tcase KVM_CAP_PPC_RTAS:\n\tcase KVM_CAP_PPC_FIXUP_HCALL:\n\tcase KVM_CAP_PPC_ENABLE_HCALL:\n#ifdef CONFIG_KVM_XICS\n\tcase KVM_CAP_IRQ_XICS:\n#endif\n\t\tr = 1;\n\t\tbreak;\n\n\tcase KVM_CAP_PPC_ALLOC_HTAB:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif /* CONFIG_PPC_BOOK3S_64 */\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_SMT:\n\t\tr = 0;\n\t\tif (kvm) {\n\t\t\tif (kvm->arch.emul_smt_mode > 1)\n\t\t\t\tr = kvm->arch.emul_smt_mode;\n\t\t\telse\n\t\t\t\tr = kvm->arch.smt_mode;\n\t\t} else if (hv_enabled) {\n\t\t\tif (cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = 1;\n\t\t\telse\n\t\t\t\tr = threads_per_subcore;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_SMT_POSSIBLE:\n\t\tr = 1;\n\t\tif (hv_enabled) {\n\t\t\tif (!cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = ((threads_per_subcore << 1) - 1);\n\t\t\telse\n\t\t\t\t/* P9 can emulate dbells, so allow any mode */\n\t\t\t\tr = 8 | 4 | 2 | 1;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_RMA:\n\t\tr = 0;\n\t\tbreak;\n\tcase KVM_CAP_PPC_HWRNG:\n\t\tr = kvmppc_hwrng_present();\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_RADIX:\n\t\tr = !!(hv_enabled && radix_enabled());\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_HASH_V3:\n\t\tr = !!(hv_enabled && !radix_enabled() &&\n\t\t       cpu_has_feature(CPU_FTR_ARCH_300));\n\t\tbreak;\n#endif\n\tcase KVM_CAP_SYNC_MMU:\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\t\tr = hv_enabled;\n#elif defined(KVM_ARCH_WANT_MMU_NOTIFIER)\n\t\tr = 1;\n#else\n\t\tr = 0;\n#endif\n\t\tbreak;\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_HTAB_FD:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_NR_VCPUS:\n\t\t/*\n\t\t * Recommending a number of CPUs is somewhat arbitrary; we\n\t\t * return the number of present CPUs for -HV (since a host\n\t\t * will have secondary threads \"offline\"), and for other KVM\n\t\t * implementations just count online CPUs.\n\t\t */\n\t\tif (hv_enabled)\n\t\t\tr = num_present_cpus();\n\t\telse\n\t\t\tr = num_online_cpus();\n\t\tbreak;\n\tcase KVM_CAP_NR_MEMSLOTS:\n\t\tr = KVM_USER_MEM_SLOTS;\n\t\tbreak;\n\tcase KVM_CAP_MAX_VCPUS:\n\t\tr = KVM_MAX_VCPUS;\n\t\tbreak;\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_PPC_GET_SMMU_INFO:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_MULTITCE:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_RESIZE_HPT:\n\t\t/* Disable this on POWER9 until code handles new HPTE format */\n\t\tr = !!hv_enabled && !cpu_has_feature(CPU_FTR_ARCH_300);\n\t\tbreak;\n#endif\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_FWNMI:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_PPC_HTM:\n\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) && hv_enabled;\n\t\tbreak;\n\tdefault:\n\t\tr = 0;\n\t\tbreak;\n\t}\n\treturn r;\n\n}", "commit_link": "github.com/torvalds/linux/commit/ac64115a66c18c01745bbd3c47a36b124e5fd8c0", "file_name": "arch/powerpc/kvm/powerpc.c", "vul_type": "cwe-476", "description": "Write a C function named `kvm_vm_ioctl_check_extension` that checks if a specified KVM extension is supported, considering whether the system is running in HV mode."}
{"func_name": "audio_sample_entry_Read", "func_src_before": "GF_Err audio_sample_entry_Read(GF_Box *s, GF_BitStream *bs)\n{\n\tGF_MPEGAudioSampleEntryBox *ptr;\n\tchar *data;\n\tu8 a, b, c, d;\n\tu32 i, size, v, nb_alnum;\n\tGF_Err e;\n\tu64 pos, start;\n\n\tptr = (GF_MPEGAudioSampleEntryBox *)s;\n\n\tstart = gf_bs_get_position(bs);\n\tgf_bs_seek(bs, start + 8);\n\tv = gf_bs_read_u16(bs);\n\tif (v)\n\t\tptr->is_qtff = 1;\n\n\t//try to disambiguate QTFF v1 and MP4 v1 audio sample entries ...\n\tif (v==1) {\n\t\t//go to end of ISOM audio sample entry, skip 4 byte (box size field), read 4 bytes (box type) and check if this looks like a box\n\t\tgf_bs_seek(bs, start + 8 + 20  + 4);\n\t\ta = gf_bs_read_u8(bs);\n\t\tb = gf_bs_read_u8(bs);\n\t\tc = gf_bs_read_u8(bs);\n\t\td = gf_bs_read_u8(bs);\n\t\tnb_alnum = 0;\n\t\tif (isalnum(a)) nb_alnum++;\n\t\tif (isalnum(b)) nb_alnum++;\n\t\tif (isalnum(c)) nb_alnum++;\n\t\tif (isalnum(d)) nb_alnum++;\n\t\tif (nb_alnum>2) ptr->is_qtff = 0;\n\t}\n\n\tgf_bs_seek(bs, start);\n\te = gf_isom_audio_sample_entry_read((GF_AudioSampleEntryBox*)s, bs);\n\tif (e) return e;\n\tpos = gf_bs_get_position(bs);\n\tsize = (u32) s->size;\n\n\t//when cookie is set on bs, always convert qtff-style mp4a to isobmff-style\n\t//since the conversion is done in addBox and we don't have the bitstream there (arg...), flag the box\n \tif (gf_bs_get_cookie(bs)) {\n \t\tptr->is_qtff |= 1<<16;\n \t}\n\n\te = gf_isom_box_array_read(s, bs, audio_sample_entry_AddBox);\n\tif (!e) return GF_OK;\n\tif (size<8) return GF_ISOM_INVALID_FILE;\n\n\t/*hack for some weird files (possibly recorded with live.com tools, needs further investigations)*/\n\tgf_bs_seek(bs, pos);\n\tdata = (char*)gf_malloc(sizeof(char) * size);\n\tgf_bs_read_data(bs, data, size);\n\tfor (i=0; i<size-8; i++) {\n\t\tif (GF_4CC((u32)data[i+4], (u8)data[i+5], (u8)data[i+6], (u8)data[i+7]) == GF_ISOM_BOX_TYPE_ESDS) {\n\t\t\tGF_BitStream *mybs = gf_bs_new(data + i, size - i, GF_BITSTREAM_READ);\n\t\t\tif (ptr->esd) {\n\t\t\t\tgf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\te = gf_isom_box_parse((GF_Box **)&ptr->esd, mybs);\n\n\t\t\tif (e==GF_OK) {\n\t\t\t\tgf_isom_box_add_for_dump_mode((GF_Box*)ptr, (GF_Box*)ptr->esd);\n\t\t\t} else if (ptr->esd) {\n\t\t\t\tgf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\tgf_bs_del(mybs);\n\t\t\tbreak;\n\t\t}\n\t}\n\tgf_free(data);\n\treturn e;\n}", "func_src_after": "GF_Err audio_sample_entry_Read(GF_Box *s, GF_BitStream *bs)\n{\n\tGF_MPEGAudioSampleEntryBox *ptr;\n\tchar *data;\n\tu8 a, b, c, d;\n\tu32 i, size, v, nb_alnum;\n\tGF_Err e;\n\tu64 pos, start;\n\n\tptr = (GF_MPEGAudioSampleEntryBox *)s;\n\n\tstart = gf_bs_get_position(bs);\n\tgf_bs_seek(bs, start + 8);\n\tv = gf_bs_read_u16(bs);\n\tif (v)\n\t\tptr->is_qtff = 1;\n\n\t//try to disambiguate QTFF v1 and MP4 v1 audio sample entries ...\n\tif (v==1) {\n\t\t//go to end of ISOM audio sample entry, skip 4 byte (box size field), read 4 bytes (box type) and check if this looks like a box\n\t\tgf_bs_seek(bs, start + 8 + 20  + 4);\n\t\ta = gf_bs_read_u8(bs);\n\t\tb = gf_bs_read_u8(bs);\n\t\tc = gf_bs_read_u8(bs);\n\t\td = gf_bs_read_u8(bs);\n\t\tnb_alnum = 0;\n\t\tif (isalnum(a)) nb_alnum++;\n\t\tif (isalnum(b)) nb_alnum++;\n\t\tif (isalnum(c)) nb_alnum++;\n\t\tif (isalnum(d)) nb_alnum++;\n\t\tif (nb_alnum>2) ptr->is_qtff = 0;\n\t}\n\n\tgf_bs_seek(bs, start);\n\te = gf_isom_audio_sample_entry_read((GF_AudioSampleEntryBox*)s, bs);\n\tif (e) return e;\n\tpos = gf_bs_get_position(bs);\n\tsize = (u32) s->size;\n\n\t//when cookie is set on bs, always convert qtff-style mp4a to isobmff-style\n\t//since the conversion is done in addBox and we don't have the bitstream there (arg...), flag the box\n \tif (gf_bs_get_cookie(bs)) {\n \t\tptr->is_qtff |= 1<<16;\n \t}\n\n\te = gf_isom_box_array_read(s, bs, audio_sample_entry_AddBox);\n\tif (!e) return GF_OK;\n\tif (size<8) return GF_ISOM_INVALID_FILE;\n\n\t/*hack for some weird files (possibly recorded with live.com tools, needs further investigations)*/\n\tgf_bs_seek(bs, pos);\n\tdata = (char*)gf_malloc(sizeof(char) * size);\n\tgf_bs_read_data(bs, data, size);\n\tfor (i=0; i<size-8; i++) {\n\t\tif (GF_4CC((u32)data[i+4], (u8)data[i+5], (u8)data[i+6], (u8)data[i+7]) == GF_ISOM_BOX_TYPE_ESDS) {\n\t\t\textern Bool use_dump_mode;\n\t\t\tGF_BitStream *mybs = gf_bs_new(data + i, size - i, GF_BITSTREAM_READ);\n\t\t\tif (ptr->esd) {\n\t\t\t\tif (!use_dump_mode) gf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\te = gf_isom_box_parse((GF_Box **)&ptr->esd, mybs);\n\n\t\t\tif (e==GF_OK) {\n\t\t\t\tgf_isom_box_add_for_dump_mode((GF_Box*)ptr, (GF_Box*)ptr->esd);\n\t\t\t} else if (ptr->esd) {\n\t\t\t\tgf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\tgf_bs_del(mybs);\n\t\t\tbreak;\n\t\t}\n\t}\n\tgf_free(data);\n\treturn e;\n}", "commit_link": "github.com/gpac/gpac/commit/6063b1a011c3f80cee25daade18154e15e4c058c", "file_name": "src/isomedia/box_code_base.c", "vul_type": "cwe-416", "description": "Write a C function named `audio_sample_entry_Read` that reads and processes an audio sample entry from a bitstream."}
{"func_name": "summary", "func_src_before": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount='\" + session['username'] + \"'\");\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "func_src_after": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount=%s\", (session['username']));\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint that retrieves the user's highest score course concentration from a MySQL database and displays it on a summary page if logged in, otherwise redirects to the login page."}
{"func_name": "render", "func_src_before": "  render() {\n\n    const {\n      isFetching,\n      isLoggedIn,\n      profile,\n      superEdges,\n      entityCount,\n      messagesConnect,\n      heartValue,\n      heartCount,\n      links,\n      title,\n      queryLink,\n      isParsed,\n    } = this.props;\n\n    const {\n      connectionDisplayIndex,\n      isAddConnectionToggledOn,\n      heartClickAttempted,\n      rotateConnectionBox,\n      isLoginRedirectToggledOn,\n    } = this.state;\n\n\n    const profileBox = (<a\n        type=\"button\"\n        href={`${rootURL}/@${profile.username}`}\n        onClick={() => { analytics('profileImgClick'); }}\n      >\n        <img src={profile.profile_image} style={{ marginTop: 8, height: '32px', borderRadius: '3px' }} />\n      </a>)\n\n    const pageTitleSection = (\n      <div className={'pageTitleSection'}>\n        <div className={'titleImgBox'}>\n          <img src={'img/document.ico'} />\n        </div>\n        <div className={'content'}>\n          <div className={'pageTitle noOverflow'}>{title}</div>\n          <div className={'queryLink noOverflow'}>{queryLink}</div>\n        </div>\n    </div>)\n\n    const gridHeaders = (\n      <div className={'row rowHeader'}>\n        <div className={'typeCol'}>\n          <span>Type</span>\n        </div>\n        <div className={'titleCol'}>\n          <span className={'title'}>Title</span>\n          <span className={'noOverflow favicon'} title={'link to page'}>\n            <img src={'/img/hyperlink.png'} style={{ height: 20, width: 20 }}/>\n          </span>\n        </div>\n        <div className={'domainCol'}>\n          <span>Domain</span>\n        </div>\n        <div className={'sourceCol'}>\n          <span>Source</span>\n        </div>\n      </div>)\n\n    const filteredLink = links.filter(link => link.pageTo && link.pageTo !== null);\n\n    const noConnectionsRow = superEdges.length === 0 ? (\n      <div style={{ paddingTop: 20, paddingBottom: 20, paddingLeft: 20, borderTop: '1px solid #e7e7e7', backgroundColor: 'rgba(102, 51, 153, 0.3)' }}>\n        <span style={{ fontWeigth: 700, fontSize: 14 }}>There are no user recommendations for this page - be the first to add one.</span>\n      </div>) : null;\n\n    const superEdgeRows = superEdges && superEdges.length > 0 ? superEdges.map((edge, i) =>\n      <div key={i} className={'row'}>\n        <div className={'typeCol'}>\n          <span className={'userContributed'}>\n            <i className={'fa fa-user'} title={`Connected by: @${edge.edges[0].user.username}`}/>\n          </span>\n        </div>\n        <div className={'titleCol'}>\n          <span className={'noOverflow title'} title={edge.entity.title}>\n            <a target=\"_blank\" href={edge.entity.canonicalLink}>\n              {edge.entity.title ? edge.entity.title : edge.entity.canonicalLink}\n            </a>\n          </span>\n          <span className={'noOverflow favicon'} title={edge.entity.title}>\n            <a target=\"_blank\" href={edge.entity.canonicalLink}>\n              <img style={{ marginTop: 3 }} src={edge.entity.faviconCDN ? edge.entity.faviconCDN : '/img/default-favicon.png'} />\n            </a>\n          </span>\n        </div>\n        <div className={'domainCol'}>\n          <span className={'noOverflow'} title={edge.entity.domain}>{edge.entity.domain}</span>\n        </div>\n        <div className={'sourceCol'}>\n          <span className={'noOverflow'}>\n            <a\n              target=\"_blank\"\n              rel=\"noreferrer noopener\"\n              onClick={() => { analytics('reccommenderClicked'); }}\n              href={`${rootURL}/@${edge.edges[0].user.username}`}\n            >\n              @{edge.edges[0].user.username}\n            </a>\n          </span>\n        </div>\n      </div>) : null;\n\n    const pageLinksJSX = filteredLink.length > 0 ?\n      filteredLink.map((link, i) => {\n        const pageTo = link.pageTo;\n        if (!pageTo ) return <div key={i} />;\n        const { title, faviconCDN, canonicalLink, domain } = pageTo;\n        return <div key={i} className={'row'} style={{ borderTop: '1px solid #e7e7e7' }}>\n          <div className={'typeCol'}>\n            <span className={'pageLink'}>\n              <i className={'fa fa-code'} title={`Example promoted link`}/>\n            </span>\n          </div>\n          <div className={'titleCol'}>\n            <a target=\"_blank\" href={canonicalLink} className={'noOverflow title'}>\n              {title.length > 0 ? title : canonicalLink}\n            </a>\n            <span className={'noOverflow favicon'} title={'link to page'}>\n              <a target=\"_blank\" href={canonicalLink}>\n                <img src={ faviconCDN && faviconCDN.length ? faviconCDN : 'img/document.ico' } />\n              </a>\n            </span>\n          </div>\n          <div className={'domainCol'}>\n            <span>{domain}</span>\n          </div>\n          <div className={'sourceCol'}>\n            <span>Page</span>\n          </div>\n        </div>\n      }\n    ) : null\n\n    const resultsGrid = (\n      <div className={'resultsGrid'}>\n        {gridHeaders}\n        {superEdgeRows}\n        {pageLinksJSX}\n        {noConnectionsRow}\n      </div>)\n    return (\n      <div id='fullPage'>\n        <div className={'pageContents'}>\n          {isFetching || isParsed === false ?\n            ( <div>\n                <ReactSpinner color=\"black\"/>\n                <div className={'parsingPage'}>", "func_src_after": "  render() {\n\n    const {\n      isFetching,\n      isLoggedIn,\n      profile,\n      superEdges,\n      entityCount,\n      messagesConnect,\n      heartValue,\n      heartCount,\n      links,\n      title,\n      queryLink,\n      isParsed,\n    } = this.props;\n\n    const {\n      connectionDisplayIndex,\n      isAddConnectionToggledOn,\n      heartClickAttempted,\n      rotateConnectionBox,\n      isLoginRedirectToggledOn,\n    } = this.state;\n\n\n    const profileBox = (<a\n        type=\"button\"\n        href={`${rootURL}/@${profile.username}`}\n        rel=\"noreferrer noopener\"\n        onClick={() => { analytics('profileImgClick'); }}\n      >\n        <img src={profile.profile_image} style={{ marginTop: 8, height: '32px', borderRadius: '3px' }} />\n      </a>)\n\n    const pageTitleSection = (\n      <div className={'pageTitleSection'}>\n        <div className={'titleImgBox'}>\n          <img src={'img/document.ico'} />\n        </div>\n        <div className={'content'}>\n          <div className={'pageTitle noOverflow'}>{title}</div>\n          <div className={'queryLink noOverflow'}>{queryLink}</div>\n        </div>\n    </div>)\n\n    const gridHeaders = (\n      <div className={'row rowHeader'}>\n        <div className={'typeCol'}>\n          <span>Type</span>\n        </div>\n        <div className={'titleCol'}>\n          <span className={'title'}>Title</span>\n          <span className={'noOverflow favicon'} title={'link to page'}>\n            <img src={'/img/hyperlink.png'} style={{ height: 20, width: 20 }}/>\n          </span>\n        </div>\n        <div className={'domainCol'}>\n          <span>Domain</span>\n        </div>\n        <div className={'sourceCol'}>\n          <span>Source</span>\n        </div>\n      </div>)\n\n    const filteredLink = links.filter(link => link.pageTo && link.pageTo !== null);\n\n    const noConnectionsRow = superEdges.length === 0 ? (\n      <div style={{ paddingTop: 20, paddingBottom: 20, paddingLeft: 20, borderTop: '1px solid #e7e7e7', backgroundColor: 'rgba(102, 51, 153, 0.3)' }}>\n        <span style={{ fontWeigth: 700, fontSize: 14 }}>There are no user recommendations for this page - be the first to add one.</span>\n      </div>) : null;\n\n    const superEdgeRows = superEdges && superEdges.length > 0 ? superEdges.map((edge, i) =>\n      <div key={i} className={'row'} style={{ borderTop: '1px solid #e7e7e7' }}>\n        <div className={'typeCol'}>\n          <span className={'userContributed'}>\n            <i className={'fa fa-user'} title={`Connected by: @${edge.edges[0].user.username}`}/>\n          </span>\n        </div>\n        <div className={'titleCol'}>\n          <span className={'noOverflow title'} title={edge.entity.title}>\n            <a target=\"_blank\" href={edge.entity.canonicalLink} rel=\"noreferrer noopener\">\n              {edge.entity.title ? edge.entity.title : edge.entity.canonicalLink}\n            </a>\n          </span>\n          <span className={'noOverflow favicon'} title={edge.entity.title}>\n            <a target=\"_blank\" href={edge.entity.canonicalLink} rel=\"noreferrer noopener\">\n              <img style={{ marginTop: 3 }} src={edge.entity.faviconCDN ? edge.entity.faviconCDN : '/img/default-favicon.png'} />\n            </a>\n          </span>\n        </div>\n        <div className={'domainCol'}>\n          <span className={'noOverflow'} title={edge.entity.domain}>{edge.entity.domain}</span>\n        </div>\n        <div className={'sourceCol'}>\n          <span className={'noOverflow'}>\n            <a\n              target=\"_blank\"\n              rel=\"noreferrer noopener\"\n              onClick={() => { analytics('reccommenderClicked'); }}\n              href={`${rootURL}/@${edge.edges[0].user.username}`}\n            >\n              @{edge.edges[0].user.username}\n            </a>\n          </span>\n        </div>\n      </div>) : null;\n\n    const pageLinksJSX = filteredLink.length > 0 ?\n      filteredLink.map((link, i) => {\n        const pageTo = link.pageTo;\n        if (!pageTo ) return <div key={i} />;\n        const { title, faviconCDN, canonicalLink, domain } = pageTo;\n        return <div key={i} className={'row'} style={{ borderTop: '1px solid #e7e7e7' }}>\n          <div className={'typeCol'}>\n            <span className={'pageLink'}>\n              <i className={'fa fa-code'} title={`Example promoted link`}/>\n            </span>\n          </div>\n          <div className={'titleCol'}>\n            <a target=\"_blank\" href={canonicalLink} className={'noOverflow title'} rel=\"noreferrer noopener\">\n              {title.length > 0 ? title : canonicalLink}\n            </a>\n            <span className={'noOverflow favicon'} title={'link to page'}>\n              <a target=\"_blank\" href={canonicalLink} rel=\"noreferrer noopener\">\n                <img src={ faviconCDN && faviconCDN.length ? faviconCDN : 'img/document.ico' } />\n              </a>\n            </span>\n          </div>\n          <div className={'domainCol'}>\n            <span>{domain}</span>\n          </div>\n          <div className={'sourceCol'}>\n            <span>Page</span>\n          </div>\n        </div>\n      }\n    ) : null\n\n    const resultsGrid = (\n      <div className={'resultsGrid'}>\n        {gridHeaders}\n        {superEdgeRows}\n        {pageLinksJSX}\n        {noConnectionsRow}\n      </div>)\n    return (\n      <div id='fullPage'>\n        <div className={'pageContents'}>\n          {isFetching || isParsed === false ?\n            ( <div>\n                <ReactSpinner color=\"black\"/>\n                <div className={'parsingPage'}>", "line_changes": {"deleted": [{"line_no": 73, "char_start": 2230, "char_end": 2268, "line": "      <div key={i} className={'row'}>\n"}, {"line_no": 81, "char_start": 2593, "char_end": 2658, "line": "            <a target=\"_blank\" href={edge.entity.canonicalLink}>\n"}, {"line_no": 86, "char_start": 2851, "char_end": 2916, "line": "            <a target=\"_blank\" href={edge.entity.canonicalLink}>\n"}, {"line_no": 120, "char_start": 4238, "char_end": 4322, "line": "            <a target=\"_blank\" href={canonicalLink} className={'noOverflow title'}>\n"}, {"line_no": 124, "char_start": 4471, "char_end": 4526, "line": "              <a target=\"_blank\" href={canonicalLink}>\n"}], "added": [{"line_no": 30, "char_start": 533, "char_end": 567, "line": "        rel=\"noreferrer noopener\"\n"}, {"line_no": 74, "char_start": 2264, "char_end": 2345, "line": "      <div key={i} className={'row'} style={{ borderTop: '1px solid #e7e7e7' }}>\n"}, {"line_no": 82, "char_start": 2670, "char_end": 2761, "line": "            <a target=\"_blank\" href={edge.entity.canonicalLink} rel=\"noreferrer noopener\">\n"}, {"line_no": 87, "char_start": 2954, "char_end": 3045, "line": "            <a target=\"_blank\" href={edge.entity.canonicalLink} rel=\"noreferrer noopener\">\n"}, {"line_no": 121, "char_start": 4367, "char_end": 4477, "line": "            <a target=\"_blank\" href={canonicalLink} className={'noOverflow title'} rel=\"noreferrer noopener\">\n"}, {"line_no": 125, "char_start": 4626, "char_end": 4707, "line": "              <a target=\"_blank\" href={canonicalLink} rel=\"noreferrer noopener\">\n"}]}, "char_changes": {"deleted": [{"char_start": 591, "char_end": 591, "chars": ""}, {"char_start": 4471, "char_end": 4471, "chars": ""}], "added": [{"char_start": 533, "char_end": 567, "chars": "        rel=\"noreferrer noopener\"\n"}, {"char_start": 2300, "char_end": 2343, "chars": " style={{ borderTop: '1px solid #e7e7e7' }}"}, {"char_start": 2733, "char_end": 2759, "chars": " rel=\"noreferrer noopener\""}, {"char_start": 3017, "char_end": 3043, "chars": " rel=\"noreferrer noopener\""}, {"char_start": 4449, "char_end": 4475, "chars": " rel=\"noreferrer noopener\""}, {"char_start": 4679, "char_end": 4705, "chars": " rel=\"noreferrer noopener\""}]}, "commit_link": "github.com/WikiWebOrg/wikiweb-plugin/commit/c6fea2d3f5b7de1044194f77eb74072a5927f3f3", "file_name": "FullPage.react.js", "vul_type": "cwe-200", "commit_msg": "rel=\"noreferrer noopener\"", "parent_commit": "91373ed75a9d1f18fe7a337071a06ae4cc3f0134", "description": "Write a React component in JavaScript that displays user profile information, page details, and lists of linked entities with user contributions."}
{"func_name": "CompileAndRun", "func_src_before": "func (l *Loader) CompileAndRun(name string, input io.Reader) error {\n\tglog.V(2).Infof(\"CompileAndRun %s\", name)\n\tv, errs := Compile(name, input, l.dumpAst, l.dumpAstTypes, l.syslogUseCurrentYear, l.overrideLocation)\n\tif errs != nil {\n\t\tProgLoadErrors.Add(name, 1)\n\t\treturn errors.Errorf(\"compile failed for %s:\\n%s\", name, errs)\n\t}\n\tif v == nil {\n\t\tProgLoadErrors.Add(name, 1)\n\t\treturn errors.Errorf(\"Internal error: Compilation failed for %s: No program returned, but no errors.\", name)\n\t}\n\n\tif l.dumpBytecode {\n\t\tglog.Info(\"Dumping program objects and bytecode\\n\", v.DumpByteCode(name))\n\t}\n\n\t// Load the metrics from the compilation into the global metric storage for export.\n\tfor _, m := range v.m {\n\t\tif !m.Hidden {\n\t\t\tif l.omitMetricSource {\n\t\t\t\tm.Source = \"\"\n\t\t\t}\n\t\t\terr := l.ms.Add(m)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tProgLoads.Add(name, 1)\n\tglog.Infof(\"Loaded program %s\", name)\n\n\tif l.compileOnly {\n\t\treturn nil\n\t}\n\n\tl.handleMu.Lock()\n\tdefer l.handleMu.Unlock()\n\n\tl.handles[name] = v\n\treturn nil\n}", "func_src_after": "func (l *Loader) CompileAndRun(name string, input io.Reader) error {\n\tglog.V(2).Infof(\"CompileAndRun %s\", name)\n\tv, errs := Compile(name, input, l.dumpAst, l.dumpAstTypes, l.syslogUseCurrentYear, l.overrideLocation)\n\tif errs != nil {\n\t\tProgLoadErrors.Add(name, 1)\n\t\treturn errors.Errorf(\"compile failed for %s:\\n%s\", name, errs)\n\t}\n\tif v == nil {\n\t\tProgLoadErrors.Add(name, 1)\n\t\treturn errors.Errorf(\"Internal error: Compilation failed for %s: No program returned, but no errors.\", name)\n\t}\n\n\tif l.dumpBytecode {\n\t\tglog.Info(\"Dumping program objects and bytecode\\n\", v.DumpByteCode())\n\t}\n\n\t// Load the metrics from the compilation into the global metric storage for export.\n\tfor _, m := range v.m {\n\t\tif !m.Hidden {\n\t\t\tif l.omitMetricSource {\n\t\t\t\tm.Source = \"\"\n\t\t\t}\n\t\t\terr := l.ms.Add(m)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tProgLoads.Add(name, 1)\n\tglog.Infof(\"Loaded program %s\", name)\n\n\tif l.compileOnly {\n\t\treturn nil\n\t}\n\n\tl.handleMu.Lock()\n\tdefer l.handleMu.Unlock()\n\n\tl.handles[name] = v\n\treturn nil\n}", "line_changes": {"deleted": [{"line_no": 14, "char_start": 513, "char_end": 589, "line": "\t\tglog.Info(\"Dumping program objects and bytecode\\n\", v.DumpByteCode(name))\n"}], "added": [{"line_no": 14, "char_start": 513, "char_end": 585, "line": "\t\tglog.Info(\"Dumping program objects and bytecode\\n\", v.DumpByteCode())\n"}]}, "char_changes": {"deleted": [{"char_start": 582, "char_end": 586, "chars": "name"}], "added": []}, "commit_link": "github.com/SuperQ/mtail/commit/a90de206158775716feb1f0a1b36636301cd14fa", "file_name": "loader.go", "vul_type": "cwe-079", "commit_msg": "Don't need to pass the name of the prog to the prog dumper.\n\nIt already knows what the name is, and CodeQL thinks this is an XSS.", "parent_commit": "28a3000450fa7a2a34df95ff656db845139606be", "description": "Write a Go function that compiles and runs a program from an input reader, handling errors and metrics."}
{"func_name": "load", "func_src_before": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n        return PGMPomegranate(pgm_model)", "func_src_after": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(f.read())\n        return PGMPomegranate(pgm_model)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 413, "char_end": 483, "line": "                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n"}], "added": [{"line_no": 10, "char_start": 413, "char_end": 477, "line": "                pgm_model = BayesianNetwork.from_json(f.read())\n"}]}, "char_changes": {"deleted": [{"char_start": 467, "char_end": 476, "chars": "pickle.lo"}, {"char_start": 479, "char_end": 480, "chars": "f"}], "added": [{"char_start": 467, "char_end": 471, "chars": "f.re"}]}, "commit_link": "github.com/sara-02/fabric8-analytics-stack-analysis/commit/c9422e6257a8c927aed2999a0f4cc77f90059cda", "file_name": "pgm_pomegranate.py", "vul_type": "cwe-502", "commit_msg": "Remove pickling of model\n\nThe model is already being converted to a JSON(using the `to_json`)\nfunction of pomegranate which is already a stadard serialized format.\nI don't see a need to further serialize the JSON using pickle to\nsomething that can be loaded only using Python. This also helps us\nreduce the training time of the model as pickling and unpickling\nhas a overhead that I don't see a need for, because JSON.", "parent_commit": "c2ddf128d7206a0a85929b6f2a08078433ce1577", "description": "Create a Python method that loads a probabilistic graphical model from a local or S3 data store based on the provided filename."}
{"func_name": "showAndHideMessage", "func_src_before": "\tfunction showAndHideMessage (message) {\n\t\ttry {\n\t\t\tvar newMessage = (!message) ? GrunionFB_i18n.savedMessage : message;\n\t\t\tjQuery('#fb-success').html(newMessage);\n\t\t\tjQuery('#fb-success').slideDown('fast');\n\t\t\tsetTimeout(function () {\n\t\t\t\t jQuery('#fb-success').slideUp('fast');\n\t\t\t}, 2500);\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"showAndHideMessage(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tfunction showAndHideMessage (message) {\n\t\ttry {\n\t\t\tvar newMessage = (!message) ? GrunionFB_i18n.savedMessage : message;\n\t\t\tjQuery('#fb-success').text(newMessage);\n\t\t\tjQuery('#fb-success').slideDown('fast');\n\t\t\tsetTimeout(function () {\n\t\t\t\t jQuery('#fb-success').slideUp('fast');\n\t\t\t}, 2500);\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"showAndHideMessage(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 121, "char_end": 164, "line": "\t\t\tjQuery('#fb-success').html(newMessage);\n"}], "added": [{"line_no": 4, "char_start": 121, "char_end": 164, "line": "\t\t\tjQuery('#fb-success').text(newMessage);\n"}]}, "char_changes": {"deleted": [{"char_start": 146, "char_end": 150, "chars": "html"}], "added": [{"char_start": 146, "char_end": 150, "chars": "text"}]}, "commit_link": "github.com/iamtakashi/jetpack/commit/970117f93e7ed6eb459ee568259947d67369eec0", "file_name": "grunion.js", "vul_type": "cwe-079", "commit_msg": "Grunion: Fix 2 XSS vulnerabilities.\nPreview of field labels.\nPreview of radio option labels.\nAlso:\nPrevent future potential XSS in feedback message.\nFix i18n\nFix encoding of field labels bug (every preview would add another level of HTML encoding to the label)\nprops @mdawaffe", "description": "Write a JavaScript function that displays a message in a sliding element and hides it after a short delay."}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = %s\"\"\", (user_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Create a Python function with JWT authentication that deletes a user from the database by their user_id."}
{"func_name": "opj_j2k_set_cinema_parameters", "func_src_before": "static void opj_j2k_set_cinema_parameters(opj_cparameters_t *parameters,\n        opj_image_t *image, opj_event_mgr_t *p_manager)\n{\n    /* Configure cinema parameters */\n    int i;\n\n    /* No tiling */\n    parameters->tile_size_on = OPJ_FALSE;\n    parameters->cp_tdx = 1;\n    parameters->cp_tdy = 1;\n\n    /* One tile part for each component */\n    parameters->tp_flag = 'C';\n    parameters->tp_on = 1;\n\n    /* Tile and Image shall be at (0,0) */\n    parameters->cp_tx0 = 0;\n    parameters->cp_ty0 = 0;\n    parameters->image_offset_x0 = 0;\n    parameters->image_offset_y0 = 0;\n\n    /* Codeblock size= 32*32 */\n    parameters->cblockw_init = 32;\n    parameters->cblockh_init = 32;\n\n    /* Codeblock style: no mode switch enabled */\n    parameters->mode = 0;\n\n    /* No ROI */\n    parameters->roi_compno = -1;\n\n    /* No subsampling */\n    parameters->subsampling_dx = 1;\n    parameters->subsampling_dy = 1;\n\n    /* 9-7 transform */\n    parameters->irreversible = 1;\n\n    /* Number of layers */\n    if (parameters->tcp_numlayers > 1) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"1 single quality layer\"\n                      \"-> Number of layers forced to 1 (rather than %d)\\n\"\n                      \"-> Rate of the last layer (%3.1f) will be used\",\n                      parameters->tcp_numlayers,\n                      parameters->tcp_rates[parameters->tcp_numlayers - 1]);\n        parameters->tcp_rates[0] = parameters->tcp_rates[parameters->tcp_numlayers - 1];\n        parameters->tcp_numlayers = 1;\n    }\n\n    /* Resolution levels */\n    switch (parameters->rsiz) {\n    case OPJ_PROFILE_CINEMA_2K:\n        if (parameters->numresolution > 6) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-3 (2k dc profile) requires:\\n\"\n                          \"Number of decomposition levels <= 5\\n\"\n                          \"-> Number of decomposition levels forced to 5 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 6;\n        }\n        break;\n    case OPJ_PROFILE_CINEMA_4K:\n        if (parameters->numresolution < 2) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 1 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 1;\n        } else if (parameters->numresolution > 7) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 6 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 7;\n        }\n        break;\n    default :\n        break;\n    }\n\n    /* Precincts */\n    parameters->csty |= 0x01;\n    parameters->res_spec = parameters->numresolution - 1;\n    for (i = 0; i < parameters->res_spec; i++) {\n        parameters->prcw_init[i] = 256;\n        parameters->prch_init[i] = 256;\n    }\n\n    /* The progression order shall be CPRL */\n    parameters->prog_order = OPJ_CPRL;\n\n    /* Progression order changes for 4K, disallowed for 2K */\n    if (parameters->rsiz == OPJ_PROFILE_CINEMA_4K) {\n        parameters->numpocs = (OPJ_UINT32)opj_j2k_initialise_4K_poc(parameters->POC,\n                              parameters->numresolution);\n    } else {\n        parameters->numpocs = 0;\n    }\n\n    /* Limited bit-rate */\n    parameters->cp_disto_alloc = 1;\n    if (parameters->max_cs_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_cs_size > OPJ_CINEMA_24_CS) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1302083 bytes.\\n\");\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n    }\n\n    if (parameters->max_comp_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_comp_size > OPJ_CINEMA_24_COMP) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1041666 bytes.\\n\");\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n    }\n\n    parameters->tcp_rates[0] = (OPJ_FLOAT32)(image->numcomps * image->comps[0].w *\n                               image->comps[0].h * image->comps[0].prec) /\n                               (OPJ_FLOAT32)(((OPJ_UINT32)parameters->max_cs_size) * 8 * image->comps[0].dx *\n                                       image->comps[0].dy);\n\n}", "func_src_after": "static void opj_j2k_set_cinema_parameters(opj_cparameters_t *parameters,\n        opj_image_t *image, opj_event_mgr_t *p_manager)\n{\n    /* Configure cinema parameters */\n    int i;\n\n    /* No tiling */\n    parameters->tile_size_on = OPJ_FALSE;\n    parameters->cp_tdx = 1;\n    parameters->cp_tdy = 1;\n\n    /* One tile part for each component */\n    parameters->tp_flag = 'C';\n    parameters->tp_on = 1;\n\n    /* Tile and Image shall be at (0,0) */\n    parameters->cp_tx0 = 0;\n    parameters->cp_ty0 = 0;\n    parameters->image_offset_x0 = 0;\n    parameters->image_offset_y0 = 0;\n\n    /* Codeblock size= 32*32 */\n    parameters->cblockw_init = 32;\n    parameters->cblockh_init = 32;\n\n    /* Codeblock style: no mode switch enabled */\n    parameters->mode = 0;\n\n    /* No ROI */\n    parameters->roi_compno = -1;\n\n    /* No subsampling */\n    parameters->subsampling_dx = 1;\n    parameters->subsampling_dy = 1;\n\n    /* 9-7 transform */\n    parameters->irreversible = 1;\n\n    /* Number of layers */\n    if (parameters->tcp_numlayers > 1) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"1 single quality layer\"\n                      \"-> Number of layers forced to 1 (rather than %d)\\n\"\n                      \"-> Rate of the last layer (%3.1f) will be used\",\n                      parameters->tcp_numlayers,\n                      parameters->tcp_rates[parameters->tcp_numlayers - 1]);\n        parameters->tcp_rates[0] = parameters->tcp_rates[parameters->tcp_numlayers - 1];\n        parameters->tcp_numlayers = 1;\n    }\n\n    /* Resolution levels */\n    switch (parameters->rsiz) {\n    case OPJ_PROFILE_CINEMA_2K:\n        if (parameters->numresolution > 6) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-3 (2k dc profile) requires:\\n\"\n                          \"Number of decomposition levels <= 5\\n\"\n                          \"-> Number of decomposition levels forced to 5 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 6;\n        }\n        break;\n    case OPJ_PROFILE_CINEMA_4K:\n        if (parameters->numresolution < 2) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 1 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 1;\n        } else if (parameters->numresolution > 7) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 6 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 7;\n        }\n        break;\n    default :\n        break;\n    }\n\n    /* Precincts */\n    parameters->csty |= 0x01;\n    if (parameters->numresolution == 1) {\n        parameters->res_spec = 1;\n        parameters->prcw_init[0] = 128;\n        parameters->prch_init[0] = 128;\n    } else {\n        parameters->res_spec = parameters->numresolution - 1;\n        for (i = 0; i < parameters->res_spec; i++) {\n            parameters->prcw_init[i] = 256;\n            parameters->prch_init[i] = 256;\n        }\n    }\n\n    /* The progression order shall be CPRL */\n    parameters->prog_order = OPJ_CPRL;\n\n    /* Progression order changes for 4K, disallowed for 2K */\n    if (parameters->rsiz == OPJ_PROFILE_CINEMA_4K) {\n        parameters->numpocs = (OPJ_UINT32)opj_j2k_initialise_4K_poc(parameters->POC,\n                              parameters->numresolution);\n    } else {\n        parameters->numpocs = 0;\n    }\n\n    /* Limited bit-rate */\n    parameters->cp_disto_alloc = 1;\n    if (parameters->max_cs_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_cs_size > OPJ_CINEMA_24_CS) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1302083 bytes.\\n\");\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n    }\n\n    if (parameters->max_comp_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_comp_size > OPJ_CINEMA_24_COMP) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1041666 bytes.\\n\");\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n    }\n\n    parameters->tcp_rates[0] = (OPJ_FLOAT32)(image->numcomps * image->comps[0].w *\n                               image->comps[0].h * image->comps[0].prec) /\n                               (OPJ_FLOAT32)(((OPJ_UINT32)parameters->max_cs_size) * 8 * image->comps[0].dx *\n                                       image->comps[0].dy);\n\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/4241ae6fbbf1de9658764a80944dc8108f2b4154", "file_name": "src/lib/openjp2/j2k.c", "vul_type": "cwe-787", "description": "Write a C function to configure JPEG 2000 cinema parameters for an image."}
{"func_name": "cs_winkernel_malloc", "func_src_before": "void * CAPSTONE_API cs_winkernel_malloc(size_t size)\n{\n\t// Disallow zero length allocation because they waste pool header space and,\n\t// in many cases, indicate a potential validation issue in the calling code.\n\tNT_ASSERT(size);\n\n\t// FP; a use of NonPagedPool is required for Windows 7 support\n#pragma prefast(suppress : 30030)\t\t// Allocating executable POOL_TYPE memory\n\tCS_WINKERNEL_MEMBLOCK *block = (CS_WINKERNEL_MEMBLOCK *)ExAllocatePoolWithTag(\n\t\t\tNonPagedPool, size + sizeof(CS_WINKERNEL_MEMBLOCK), CS_WINKERNEL_POOL_TAG);\n\tif (!block) {\n\t\treturn NULL;\n\t}\n\tblock->size = size;\n\n\treturn block->data;\n}", "func_src_after": "void * CAPSTONE_API cs_winkernel_malloc(size_t size)\n{\n\t// Disallow zero length allocation because they waste pool header space and,\n\t// in many cases, indicate a potential validation issue in the calling code.\n\tNT_ASSERT(size);\n\n\t// FP; a use of NonPagedPool is required for Windows 7 support\n#pragma prefast(suppress : 30030)\t\t// Allocating executable POOL_TYPE memory\n\tsize_t number_of_bytes = 0;\n\tCS_WINKERNEL_MEMBLOCK *block = NULL;\n\t// A specially crafted size value can trigger the overflow.\n\t// If the sum in a value that overflows or underflows the capacity of the type,\n\t// the function returns NULL.\n\tif (!NT_SUCCESS(RtlSizeTAdd(size, sizeof(CS_WINKERNEL_MEMBLOCK), &number_of_bytes))) {\n\t\treturn NULL;\n\t}\n\tblock = (CS_WINKERNEL_MEMBLOCK *)ExAllocatePoolWithTag(\n\t\t\tNonPagedPool, number_of_bytes, CS_WINKERNEL_POOL_TAG);\n\tif (!block) {\n\t\treturn NULL;\n\t}\n\tblock->size = size;\n\n\treturn block->data;\n}", "commit_link": "github.com/aquynh/capstone/commit/6fe86eef621b9849f51a5e1e5d73258a93440403", "file_name": "windows/winkernel_mm.c", "vul_type": "cwe-190", "description": "Write a C function named `cs_winkernel_malloc` that allocates memory in the Windows kernel, ensuring it's non-zero and handles potential size overflows."}
{"func_name": "getQueue", "func_src_before": "    def getQueue(self, numberOfLinks=10):\n        self.cursor.execute(\"SELECT url FROM queue WHERE visited = '0' LIMIT {};\".format(numberOfLinks))\n        result = self.cursor.fetchall()\n        self.remove(result)\n        return result", "func_src_after": "    def getQueue(self, numberOfLinks=10):\n        self.cursor.execute(\"SELECT url FROM queue WHERE visited = '0' LIMIT ?;\", numberOfLinks)\n        result = self.cursor.fetchall()\n        self.remove(result)\n        return result", "commit_link": "github.com/jappe999/WebScraper/commit/46a4e0843aa44d903293637afad53dfcbc37b480", "file_name": "beta/database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getQueue` that retrieves a specified number of unvisited URLs from a queue in a database and removes them from the queue after retrieval."}
{"func_name": "updateOption", "func_src_before": "\tfunction updateOption (that) {\n\t\ttry {\n\t\t\tvar thisId = jQuery('#fb-field-id').val();\n\t\t\tvar thisOptionid = that.attr('optionid');\n\t\t\tvar thisOptionValue = that.val();\n\t\t\tvar thisType = jQuery('#fb-new-type').val();\n\t\t\t// Update preview\n\t\t\tif (thisType === \"radio\") {\n\t\t\t\tjQuery('#fb-radio-' + thisId + '-' + thisOptionid + ' span').html(thisOptionValue);\n\t\t\t} else {\n\t\t\t\tjQuery('#fb-' + thisId + '-' + thisOptionid).text(thisOptionValue);\n\t\t\t}\n\t\t\t// Update fbForm object\n\t\t\tfbForm.fields[thisId].options[thisOptionid] = thisOptionValue;\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"updateOption(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tfunction updateOption (that) {\n\t\ttry {\n\t\t\tvar thisId = jQuery('#fb-field-id').val();\n\t\t\tvar thisOptionid = that.attr('optionid');\n\t\t\tvar thisOptionValue = that.val();\n\t\t\tvar thisType = jQuery('#fb-new-type').val();\n\t\t\t// Update preview\n\t\t\tif (thisType === \"radio\") {\n\t\t\t\tjQuery('#fb-radio-' + thisId + '-' + thisOptionid + ' span').text(thisOptionValue);\n\t\t\t} else {\n\t\t\t\tjQuery('#fb-' + thisId + '-' + thisOptionid).text(thisOptionValue);\n\t\t\t}\n\t\t\t// Update fbForm object\n\t\t\tfbForm.fields[thisId].options[thisOptionid] = thisOptionValue;\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"updateOption(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 268, "char_end": 356, "line": "\t\t\t\tjQuery('#fb-radio-' + thisId + '-' + thisOptionid + ' span').html(thisOptionValue);\n"}], "added": [{"line_no": 9, "char_start": 268, "char_end": 356, "line": "\t\t\t\tjQuery('#fb-radio-' + thisId + '-' + thisOptionid + ' span').text(thisOptionValue);\n"}]}, "char_changes": {"deleted": [{"char_start": 333, "char_end": 337, "chars": "html"}], "added": [{"char_start": 333, "char_end": 337, "chars": "text"}]}, "commit_link": "github.com/iamtakashi/jetpack/commit/970117f93e7ed6eb459ee568259947d67369eec0", "file_name": "grunion.js", "vul_type": "cwe-079", "commit_msg": "Grunion: Fix 2 XSS vulnerabilities.\nPreview of field labels.\nPreview of radio option labels.\nAlso:\nPrevent future potential XSS in feedback message.\nFix i18n\nFix encoding of field labels bug (every preview would add another level of HTML encoding to the label)\nprops @mdawaffe", "description": "Write a JavaScript function using jQuery to update form option values and preview text based on the type of input field."}
{"func_name": "self.get_taxon_concept_id", "func_src_before": "  def self.get_taxon_concept_id(hierarchy_entry_id)\n    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id};\")\n    if he.count > 0\n      return he.first.taxon_concept_id\n    else\n      return 0\n    end\n  end", "func_src_after": "  def self.get_taxon_concept_id(hierarchy_entry_id)\n    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id.to_i};\")\n    if he.count > 0\n      return he.first.taxon_concept_id\n    else\n      return 0\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 52, "char_end": 160, "line": "    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id};\")\n"}], "added": [{"line_no": 2, "char_start": 52, "char_end": 110, "line": "    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n"}, {"line_no": 3, "char_start": 110, "char_end": 223, "line": "    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id.to_i};\")\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 52, "char_end": 110, "chars": "    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n"}, {"char_start": 213, "char_end": 218, "chars": ".to_i"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Write a Ruby method to fetch a taxon concept ID from a database using a hierarchy entry ID."}
{"func_name": "process_statistics", "func_src_before": "    def process_statistics(self, metadata, _):\n        args = [metadata.hostname, '-p', metadata.profile, '-g',\n                ':'.join([g for g in metadata.groups])]\n        for notifier in os.listdir(self.data):\n            if ((notifier[-1] == '~') or\n                (notifier[:2] == '.#') or\n                (notifier[-4:] == '.swp') or\n                (notifier in ['SCCS', '.svn', '4913'])):\n                continue\n            npath = self.data + '/' + notifier\n            self.logger.debug(\"Running %s %s\" % (npath, \" \".join(args)))\n            async_run(npath, args)", "func_src_after": "    def process_statistics(self, metadata, _):\n        args = [metadata.hostname, '-p', metadata.profile, '-g',\n                ':'.join([g for g in metadata.groups])]\n        self.debug_log(\"running triggers\")\n        for notifier in os.listdir(self.data):\n            self.debug_log(\"running %s\" % notifier)\n            if ((notifier[-1] == '~') or\n                (notifier[:2] == '.#') or\n                (notifier[-4:] == '.swp') or\n                (notifier in ['SCCS', '.svn', '4913'])):\n                continue\n            npath = os.path.join(self.data, notifier)\n            self.async_run([npath] + args)", "commit_link": "github.com/Bcfg2/bcfg2/commit/a524967e8d5c4c22e49cd619aed20c87a316c0be", "file_name": "src/lib/Server/Plugins/Trigger.py", "vul_type": "cwe-078", "description": "Write a Python function that filters out certain files and asynchronously runs a command with arguments based on metadata."}
{"func_name": "forward_search_range", "func_src_before": "forward_search_range(regex_t* reg, const UChar* str, const UChar* end, UChar* s,\n\t\t     UChar* range, UChar** low, UChar** high, UChar** low_prev)\n{\n  UChar *p, *pprev = (UChar* )NULL;\n\n#ifdef ONIG_DEBUG_SEARCH\n  fprintf(stderr, \"forward_search_range: str: %d, end: %d, s: %d, range: %d\\n\",\n\t  (int )str, (int )end, (int )s, (int )range);\n#endif\n\n  p = s;\n  if (reg->dmin > 0) {\n    if (ONIGENC_IS_SINGLEBYTE(reg->enc)) {\n      p += reg->dmin;\n    }\n    else {\n      UChar *q = p + reg->dmin;\n      while (p < q) p += enclen(reg->enc, p);\n    }\n  }\n\n retry:\n  switch (reg->optimize) {\n  case ONIG_OPTIMIZE_EXACT:\n    p = slow_search(reg->enc, reg->exact, reg->exact_end, p, end, range);\n    break;\n  case ONIG_OPTIMIZE_EXACT_IC:\n    p = slow_search_ic(reg->enc, reg->case_fold_flag,\n                       reg->exact, reg->exact_end, p, end, range);\n    break;\n\n  case ONIG_OPTIMIZE_EXACT_BM:\n    p = bm_search(reg, reg->exact, reg->exact_end, p, end, range);\n    break;\n\n  case ONIG_OPTIMIZE_EXACT_BM_NOT_REV:\n    p = bm_search_notrev(reg, reg->exact, reg->exact_end, p, end, range);\n    break;\n\n  case ONIG_OPTIMIZE_MAP:\n    p = map_search(reg->enc, reg->map, p, range);\n    break;\n  }\n\n  if (p && p < range) {\n    if (p - reg->dmin < s) {\n    retry_gate:\n      pprev = p;\n      p += enclen(reg->enc, p);\n      goto retry;\n    }\n\n    if (reg->sub_anchor) {\n      UChar* prev;\n\n      switch (reg->sub_anchor) {\n      case ANCHOR_BEGIN_LINE:\n        if (!ON_STR_BEGIN(p)) {\n          prev = onigenc_get_prev_char_head(reg->enc,\n                                            (pprev ? pprev : str), p);\n          if (!ONIGENC_IS_MBC_NEWLINE(reg->enc, prev, end))\n            goto retry_gate;\n        }\n        break;\n\n      case ANCHOR_END_LINE:\n        if (ON_STR_END(p)) {\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n          prev = (UChar* )onigenc_get_prev_char_head(reg->enc,\n                                                     (pprev ? pprev : str), p);\n          if (prev && ONIGENC_IS_MBC_NEWLINE(reg->enc, prev, end))\n            goto retry_gate;\n#endif\n        }\n        else if (! ONIGENC_IS_MBC_NEWLINE(reg->enc, p, end)\n#ifdef USE_CRNL_AS_LINE_TERMINATOR\n                 && ! ONIGENC_IS_MBC_CRNL(reg->enc, p, end)\n#endif\n                 )\n          goto retry_gate;\n        break;\n      }\n    }\n\n    if (reg->dmax == 0) {\n      *low = p;\n      if (low_prev) {\n        if (*low > s)\n          *low_prev = onigenc_get_prev_char_head(reg->enc, s, p);\n        else\n          *low_prev = onigenc_get_prev_char_head(reg->enc,\n                                                 (pprev ? pprev : str), p);\n      }\n    }\n    else {\n      if (reg->dmax != ONIG_INFINITE_DISTANCE) {\n        *low = p - reg->dmax;\n        if (*low > s) {\n          *low = onigenc_get_right_adjust_char_head_with_prev(reg->enc, s,\n                                          *low, (const UChar** )low_prev);\n          if (low_prev && IS_NULL(*low_prev))\n            *low_prev = onigenc_get_prev_char_head(reg->enc,\n                                                   (pprev ? pprev : s), *low);\n        }\n        else {\n          if (low_prev)\n            *low_prev = onigenc_get_prev_char_head(reg->enc,\n                                                   (pprev ? pprev : str), *low);\n        }\n      }\n    }\n    /* no needs to adjust *high, *high is used as range check only */\n    *high = p - reg->dmin;\n\n#ifdef ONIG_DEBUG_SEARCH\n    fprintf(stderr,\n    \"forward_search_range success: low: %d, high: %d, dmin: %d, dmax: %d\\n\",\n\t    (int )(*low - str), (int )(*high - str), reg->dmin, reg->dmax);\n#endif\n    return 1; /* success */\n  }\n\n  return 0; /* fail */\n}", "func_src_after": "forward_search_range(regex_t* reg, const UChar* str, const UChar* end, UChar* s,\n\t\t     UChar* range, UChar** low, UChar** high, UChar** low_prev)\n{\n  UChar *p, *pprev = (UChar* )NULL;\n\n#ifdef ONIG_DEBUG_SEARCH\n  fprintf(stderr, \"forward_search_range: str: %d, end: %d, s: %d, range: %d\\n\",\n\t  (int )str, (int )end, (int )s, (int )range);\n#endif\n\n  p = s;\n  if (reg->dmin > 0) {\n    if (ONIGENC_IS_SINGLEBYTE(reg->enc)) {\n      p += reg->dmin;\n    }\n    else {\n      UChar *q = p + reg->dmin;\n\n      if (q >= end) return 0; /* fail */\n      while (p < q) p += enclen(reg->enc, p);\n    }\n  }\n\n retry:\n  switch (reg->optimize) {\n  case ONIG_OPTIMIZE_EXACT:\n    p = slow_search(reg->enc, reg->exact, reg->exact_end, p, end, range);\n    break;\n  case ONIG_OPTIMIZE_EXACT_IC:\n    p = slow_search_ic(reg->enc, reg->case_fold_flag,\n                       reg->exact, reg->exact_end, p, end, range);\n    break;\n\n  case ONIG_OPTIMIZE_EXACT_BM:\n    p = bm_search(reg, reg->exact, reg->exact_end, p, end, range);\n    break;\n\n  case ONIG_OPTIMIZE_EXACT_BM_NOT_REV:\n    p = bm_search_notrev(reg, reg->exact, reg->exact_end, p, end, range);\n    break;\n\n  case ONIG_OPTIMIZE_MAP:\n    p = map_search(reg->enc, reg->map, p, range);\n    break;\n  }\n\n  if (p && p < range) {\n    if (p - reg->dmin < s) {\n    retry_gate:\n      pprev = p;\n      p += enclen(reg->enc, p);\n      goto retry;\n    }\n\n    if (reg->sub_anchor) {\n      UChar* prev;\n\n      switch (reg->sub_anchor) {\n      case ANCHOR_BEGIN_LINE:\n        if (!ON_STR_BEGIN(p)) {\n          prev = onigenc_get_prev_char_head(reg->enc,\n                                            (pprev ? pprev : str), p);\n          if (!ONIGENC_IS_MBC_NEWLINE(reg->enc, prev, end))\n            goto retry_gate;\n        }\n        break;\n\n      case ANCHOR_END_LINE:\n        if (ON_STR_END(p)) {\n#ifndef USE_NEWLINE_AT_END_OF_STRING_HAS_EMPTY_LINE\n          prev = (UChar* )onigenc_get_prev_char_head(reg->enc,\n                                                     (pprev ? pprev : str), p);\n          if (prev && ONIGENC_IS_MBC_NEWLINE(reg->enc, prev, end))\n            goto retry_gate;\n#endif\n        }\n        else if (! ONIGENC_IS_MBC_NEWLINE(reg->enc, p, end)\n#ifdef USE_CRNL_AS_LINE_TERMINATOR\n                 && ! ONIGENC_IS_MBC_CRNL(reg->enc, p, end)\n#endif\n                 )\n          goto retry_gate;\n        break;\n      }\n    }\n\n    if (reg->dmax == 0) {\n      *low = p;\n      if (low_prev) {\n        if (*low > s)\n          *low_prev = onigenc_get_prev_char_head(reg->enc, s, p);\n        else\n          *low_prev = onigenc_get_prev_char_head(reg->enc,\n                                                 (pprev ? pprev : str), p);\n      }\n    }\n    else {\n      if (reg->dmax != ONIG_INFINITE_DISTANCE) {\n        *low = p - reg->dmax;\n        if (*low > s) {\n          *low = onigenc_get_right_adjust_char_head_with_prev(reg->enc, s,\n                                          *low, (const UChar** )low_prev);\n          if (low_prev && IS_NULL(*low_prev))\n            *low_prev = onigenc_get_prev_char_head(reg->enc,\n                                                   (pprev ? pprev : s), *low);\n        }\n        else {\n          if (low_prev)\n            *low_prev = onigenc_get_prev_char_head(reg->enc,\n                                                   (pprev ? pprev : str), *low);\n        }\n      }\n    }\n    /* no needs to adjust *high, *high is used as range check only */\n    *high = p - reg->dmin;\n\n#ifdef ONIG_DEBUG_SEARCH\n    fprintf(stderr,\n    \"forward_search_range success: low: %d, high: %d, dmin: %d, dmax: %d\\n\",\n\t    (int )(*low - str), (int )(*high - str), reg->dmin, reg->dmax);\n#endif\n    return 1; /* success */\n  }\n\n  return 0; /* fail */\n}", "commit_link": "github.com/kkos/oniguruma/commit/9690d3ab1f9bcd2db8cbe1fe3ee4a5da606b8814", "file_name": "src/regexec.c", "vul_type": "cwe-125", "description": "Write a C function named `forward_search_range` that performs a regex search within a specified range in a string."}
{"func_name": "get_queryset", "func_src_before": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = markdown(i.content, extensions=[\n                'markdown.extensions.extra',\n                'markdown.extensions.codehilite',\n                'markdown.extensions.toc',\n            ])\n\n        return queryset", "func_src_after": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = safe_md(i.content)\n\n        return queryset", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function named `get_queryset` that orders articles by time and converts their content to markdown format."}
{"func_name": "ContentLine_Analyzer::DoDeliverOnce", "func_src_before": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "func_src_after": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t// Weird corner-case:\n\t\t\t\t// this can happen if we see a \\r at the end of a packet where crlf is\n\t\t\t\t// set to CR_as_EOL | LF_as_EOL, with the packet causing crlf to be set to\n\t\t\t\t// 0 and the next packet beginning with a \\n. In this case we just swallow\n\t\t\t\t// the character and re-set last_char.\n\t\t\t\tif ( offset == 0 )\n\t\t\t\t\t{\n\t\t\t\t\tlast_char = c;\n\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "commit_link": "github.com/bro/bro/commit/6c0f101a62489b1c5927b4ed63b0e1d37db40282", "file_name": "src/analyzer/protocol/tcp/ContentLine.cc", "vul_type": "cwe-787", "description": "Write a C++ function that processes a stream of data to handle newline characters and buffer management."}
{"func_name": "testCallingAnnotateSourceOnUnrelatedSourceFileDoesNotError", "func_src_before": "  def testCallingAnnotateSourceOnUnrelatedSourceFileDoesNotError(self):\n    # Create an unrelated source file.\n    unrelated_source_path = tempfile.mktemp()\n    with open(unrelated_source_path, \"wt\") as source_file:\n      source_file.write(\"print('hello, world')\\n\")\n\n    self.assertEqual({},\n                     source_utils.annotate_source(self.dump,\n                                                  unrelated_source_path))\n\n    # Clean up unrelated source file.\n    os.remove(unrelated_source_path)", "func_src_after": "  def testCallingAnnotateSourceOnUnrelatedSourceFileDoesNotError(self):\n    # Create an unrelated source file.\n    fd, unrelated_source_path = tempfile.mkstemp()\n    with open(fd, \"wt\") as source_file:\n      source_file.write(\"print('hello, world')\\n\")\n\n    self.assertEqual({},\n                     source_utils.annotate_source(self.dump,\n                                                  unrelated_source_path))\n\n    # Clean up unrelated source file.\n    os.remove(unrelated_source_path)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 111, "char_end": 157, "line": "    unrelated_source_path = tempfile.mktemp()\n"}, {"line_no": 4, "char_start": 157, "char_end": 216, "line": "    with open(unrelated_source_path, \"wt\") as source_file:\n"}], "added": [{"line_no": 3, "char_start": 111, "char_end": 162, "line": "    fd, unrelated_source_path = tempfile.mkstemp()\n"}, {"line_no": 4, "char_start": 162, "char_end": 202, "line": "    with open(fd, \"wt\") as source_file:\n"}]}, "char_changes": {"deleted": [{"char_start": 171, "char_end": 192, "chars": "unrelated_source_path"}], "added": [{"char_start": 114, "char_end": 118, "chars": " fd,"}, {"char_start": 154, "char_end": 155, "chars": "s"}, {"char_start": 176, "char_end": 178, "chars": "fd"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/3752cc4c6ba6b69f04f857c6047adde9e8487bd6", "file_name": "source_utils_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359237\nChange-Id: I7fa45e888deff612ca53a4f8610cfad8f28e9671", "description": "Write a Python function to test that calling a source annotation utility with an unrelated source file does not produce an error, and clean up the file afterwards."}
{"func_name": "(anonymous)", "func_src_before": "  }, function (statusCode, body) {\n    if (statusCode !== 200) {\n      // request a new login key first\n      this._steamUser.requestWebAPIAuthenticateUserNonce(function (nonce) {\n        this._webLoginKey = nonce.webapi_authenticate_user_nonce;\n        this.webLogOn(callback);\n      }.bind(this));\n      return;\n    }\n\n    this.sessionID = Math.floor(Math.random() * 1000000000).toString();\n    this.cookies = [\n      'sessionid=' + this.sessionID,\n      'steamLogin=' + body.authenticateuser.token,\n      'steamLoginSecure=' + body.authenticateuser.tokensecure\n    ];\n\n    callback(this.sessionID, this.cookies);\n  }.bind(this));", "func_src_after": "  }, function (statusCode, body) {\n    if (statusCode !== 200) {\n      // request a new login key first\n      this._steamUser.requestWebAPIAuthenticateUserNonce(function (nonce) {\n        this._webLoginKey = nonce.webapi_authenticate_user_nonce;\n        this.webLogOn(callback);\n      }.bind(this));\n      return;\n    }\n\n    this.sessionID = crypto.randomBytes(12).toString('hex');\n    this.cookies = [\n      'sessionid=' + this.sessionID,\n      'steamLogin=' + body.authenticateuser.token,\n      'steamLoginSecure=' + body.authenticateuser.tokensecure\n    ];\n\n    callback(this.sessionID, this.cookies);\n  }.bind(this));", "line_changes": {"deleted": [{"line_no": 11, "char_start": 321, "char_end": 393, "line": "    this.sessionID = Math.floor(Math.random() * 1000000000).toString();\n"}], "added": [{"line_no": 11, "char_start": 321, "char_end": 382, "line": "    this.sessionID = crypto.randomBytes(12).toString('hex');\n"}]}, "char_changes": {"deleted": [{"char_start": 342, "char_end": 379, "chars": "Math.floor(Math.random() * 1000000000"}], "added": [{"char_start": 342, "char_end": 363, "chars": "crypto.randomBytes(12"}, {"char_start": 374, "char_end": 379, "chars": "'hex'"}]}, "commit_link": "github.com/Alex7Kom/node-steam-weblogon/commit/75224e83b75341366d1e75a07e8745025492a5e3", "file_name": "index.js", "vul_type": "cwe-338", "commit_msg": "Replaced Math.random() with crypto.randomBytes() for sessionid. Closes #4", "parent_commit": "a8eb1309ef9b64faa7cbc1dfa3f9e44b1430a437", "description": "Write a JavaScript function that handles Steam user authentication, generating a session ID and cookies upon successful login, and requesting a new login key if the status code is not 200."}
{"func_name": "on_message", "func_src_before": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = \"notify-send \"\n            if timeout > 0:\n                cmd = cmd + \" -t %s\" % (1000 * timeout)\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd = cmd + \" \\\"%s\\\" \\\"%s\\\"\" % (title, message)\n            print(cmd)\n            os.system(cmd)\n        return", "func_src_after": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = ['notify-send']\n            if timeout > 0:\n                cmd.extend(['-t', str(1000 * timeout)])\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd.append(title)\n            cmd.append(message)\n            subprocess.Popen(cmd).communicate()\n        return", "commit_link": "github.com/bit-team/backintime/commit/cef81d0da93ff601252607df3db1a48f7f6f01b3", "file_name": "qt4/plugins/notifyplugin.py", "vul_type": "cwe-078", "description": "Write a Python function that displays a notification with a title and message when a certain condition is met, with an optional timeout parameter."}
{"func_name": "(anonymous)", "func_src_before": "    cp.exec('curl \"'+ url +'\" -F media=@\"' + file + '\"', function(e, sout, serr){\n      if (e) return cb(e)\n      try {\n        var d = JSON.parse(sout)\n      } catch(e) {\n        return cb(e)\n      }\n      if (d.errcode) {\n        return cb(new Error(\n          d.errcode + ': ' + d.errmsg\n        ))\n      }\n      cb(null, d)\n    })", "func_src_after": "    cp.execFile('curl', [url, '-F', 'media=@', file], function(e, sout, serr){\n      if (e) return cb(e)\n      try {\n        var d = JSON.parse(sout)\n      } catch(e) {\n        return cb(e)\n      }\n      if (d.errcode) {\n        return cb(new Error(\n          d.errcode + ': ' + d.errmsg\n        ))\n      }\n      cb(null, d)\n    })", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 82, "line": "    cp.exec('curl \"'+ url +'\" -F media=@\"' + file + '\"', function(e, sout, serr){\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 79, "line": "    cp.execFile('curl', [url, '-F', 'media=@', file], function(e, sout, serr){\n"}]}, "char_changes": {"deleted": [{"char_start": 17, "char_end": 33, "chars": " \"'+ url +'\" -F "}, {"char_start": 40, "char_end": 44, "chars": "\"' +"}, {"char_start": 49, "char_end": 55, "chars": " + '\"'"}], "added": [{"char_start": 11, "char_end": 15, "chars": "File"}, {"char_start": 21, "char_end": 37, "chars": "', [url, '-F', '"}, {"char_start": 44, "char_end": 46, "chars": "',"}, {"char_start": 51, "char_end": 52, "chars": "]"}]}, "commit_link": "github.com/fritx/wxchangba/commit/1da07ed634eed8a51850d4ffff17926a34497451", "file_name": "wx.js", "vul_type": "cwe-078", "commit_msg": "Update wx.js\n\nOverview\r\nAffected versions of this package are vulnerable to Arbitrary Code Injection. The package does not validate user input for the reqPostMaterial function, thereby passing unsanitized contents of the file parameter to an exec call. This could potentially allow attackers to run arbitrary commands in the system.\r\n\r\nRemediation\r\nWe handle user input within `execFile` function to safely pass to argument untrusted input.\r\n\r\nReferences\r\n031-JS-WXCHANGBA", "description": "Write a Node.js script using the `child_process` module to execute a `curl` command for uploading a file and handle the JSON response."}
{"func_name": "_yaml_to_config", "func_src_before": "    def _yaml_to_config(self, config_file):\n         self.config = yaml.load(config_file)", "func_src_after": "    def _yaml_to_config(self, config_file):\n        self.config = yaml.safe_load(config_file)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 44, "char_end": 89, "line": "         self.config = yaml.load(config_file)\n"}], "added": [{"line_no": 2, "char_start": 44, "char_end": 93, "line": "        self.config = yaml.safe_load(config_file)\n"}]}, "char_changes": {"deleted": [{"char_start": 52, "char_end": 53, "chars": " "}], "added": [{"char_start": 71, "char_end": 76, "chars": "safe_"}]}, "commit_link": "github.com/darylmathison/github-user-queries/commit/1fb6138eebd8f0386312aa1f0fee5df603f93aba", "file_name": "util.py", "vul_type": "cwe-502", "commit_msg": "Replaced 'load' with 'safe_load'\n\nRefers-to: #24", "parent_commit": "2811a7c65abf513103e615f63f769bb5ca279902", "description": "Write a Python function that loads a configuration from a YAML file into an object's attribute."}
{"func_name": "assoc_array_insert_into_terminal_node", "func_src_before": "static bool assoc_array_insert_into_terminal_node(struct assoc_array_edit *edit,\n\t\t\t\t\t\t  const struct assoc_array_ops *ops,\n\t\t\t\t\t\t  const void *index_key,\n\t\t\t\t\t\t  struct assoc_array_walk_result *result)\n{\n\tstruct assoc_array_shortcut *shortcut, *new_s0;\n\tstruct assoc_array_node *node, *new_n0, *new_n1, *side;\n\tstruct assoc_array_ptr *ptr;\n\tunsigned long dissimilarity, base_seg, blank;\n\tsize_t keylen;\n\tbool have_meta;\n\tint level, diff;\n\tint slot, next_slot, free_slot, i, j;\n\n\tnode\t= result->terminal_node.node;\n\tlevel\t= result->terminal_node.level;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = result->terminal_node.slot;\n\n\tpr_devel(\"-->%s()\\n\", __func__);\n\n\t/* We arrived at a node which doesn't have an onward node or shortcut\n\t * pointer that we have to follow.  This means that (a) the leaf we\n\t * want must go here (either by insertion or replacement) or (b) we\n\t * need to split this node and insert in one of the fragments.\n\t */\n\tfree_slot = -1;\n\n\t/* Firstly, we have to check the leaves in this node to see if there's\n\t * a matching one we should replace in place.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (!ptr) {\n\t\t\tfree_slot = i;\n\t\t\tcontinue;\n\t\t}\n\t\tif (ops->compare_object(assoc_array_ptr_to_leaf(ptr), index_key)) {\n\t\t\tpr_devel(\"replace in slot %d\\n\", i);\n\t\t\tedit->leaf_p = &node->slots[i];\n\t\t\tedit->dead_leaf = node->slots[i];\n\t\t\tpr_devel(\"<--%s() = ok [replace]\\n\", __func__);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* If there is a free slot in this node then we can just insert the\n\t * leaf here.\n\t */\n\tif (free_slot >= 0) {\n\t\tpr_devel(\"insert in free slot %d\\n\", free_slot);\n\t\tedit->leaf_p = &node->slots[free_slot];\n\t\tedit->adjust_count_on = node;\n\t\tpr_devel(\"<--%s() = ok [insert]\\n\", __func__);\n\t\treturn true;\n\t}\n\n\t/* The node has no spare slots - so we're either going to have to split\n\t * it or insert another node before it.\n\t *\n\t * Whatever, we're going to need at least two new nodes - so allocate\n\t * those now.  We may also need a new shortcut, but we deal with that\n\t * when we need it.\n\t */\n\tnew_n0 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n0)\n\t\treturn false;\n\tedit->new_meta[0] = assoc_array_node_to_ptr(new_n0);\n\tnew_n1 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n1)\n\t\treturn false;\n\tedit->new_meta[1] = assoc_array_node_to_ptr(new_n1);\n\n\t/* We need to find out how similar the leaves are. */\n\tpr_devel(\"no spare slots\\n\");\n\thave_meta = false;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (assoc_array_ptr_is_meta(ptr)) {\n\t\t\tedit->segment_cache[i] = 0xff;\n\t\t\thave_meta = true;\n\t\t\tcontinue;\n\t\t}\n\t\tbase_seg = ops->get_object_key_chunk(\n\t\t\tassoc_array_ptr_to_leaf(ptr), level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tif (have_meta) {\n\t\tpr_devel(\"have meta\\n\");\n\t\tgoto split_node;\n\t}\n\n\t/* The node contains only leaves */\n\tdissimilarity = 0;\n\tbase_seg = edit->segment_cache[0];\n\tfor (i = 1; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tdissimilarity |= edit->segment_cache[i] ^ base_seg;\n\n\tpr_devel(\"only leaves; dissimilarity=%lx\\n\", dissimilarity);\n\n\tif ((dissimilarity & ASSOC_ARRAY_FAN_MASK) == 0) {\n\t\t/* The old leaves all cluster in the same slot.  We will need\n\t\t * to insert a shortcut if the new node wants to cluster with them.\n\t\t */\n\t\tif ((edit->segment_cache[ASSOC_ARRAY_FAN_OUT] ^ base_seg) == 0)\n\t\t\tgoto all_leaves_cluster_together;\n\n\t\t/* Otherwise we can just insert a new node ahead of the old\n\t\t * one.\n\t\t */\n\t\tgoto present_leaves_cluster_but_not_new_leaf;\n\t}\n\nsplit_node:\n\tpr_devel(\"split node\\n\");\n\n\t/* We need to split the current node; we know that the node doesn't\n\t * simply contain a full set of leaves that cluster together (it\n\t * contains meta pointers and/or non-clustering leaves).\n\t *\n\t * We need to expel at least two leaves out of a set consisting of the\n\t * leaves in the node and the new leaf.\n\t *\n\t * We need a new node (n0) to replace the current one and a new node to\n\t * take the expelled nodes (n1).\n\t */\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\ndo_split_node:\n\tpr_devel(\"do_split_node\\n\");\n\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->nr_leaves_on_branch = 0;\n\n\t/* Begin by finding two matching leaves.  There have to be at least two\n\t * that match - even if there are meta pointers - because any leaf that\n\t * would match a slot with a meta pointer in it must be somewhere\n\t * behind that meta pointer and cannot be here.  Further, given N\n\t * remaining leaf slots, we now have N+1 leaves to go in them.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tslot = edit->segment_cache[i];\n\t\tif (slot != 0xff)\n\t\t\tfor (j = i + 1; j < ASSOC_ARRAY_FAN_OUT + 1; j++)\n\t\t\t\tif (edit->segment_cache[j] == slot)\n\t\t\t\t\tgoto found_slot_for_multiple_occupancy;\n\t}\nfound_slot_for_multiple_occupancy:\n\tpr_devel(\"same slot: %x %x [%02x]\\n\", i, j, slot);\n\tBUG_ON(i >= ASSOC_ARRAY_FAN_OUT);\n\tBUG_ON(j >= ASSOC_ARRAY_FAN_OUT + 1);\n\tBUG_ON(slot >= ASSOC_ARRAY_FAN_OUT);\n\n\tnew_n1->parent_slot = slot;\n\n\t/* Metadata pointers cannot change slot */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tnew_n0->slots[i] = node->slots[i];\n\t\telse\n\t\t\tnew_n0->slots[i] = NULL;\n\tBUG_ON(new_n0->slots[slot] != NULL);\n\tnew_n0->slots[slot] = assoc_array_node_to_ptr(new_n1);\n\n\t/* Filter the leaf pointers between the new nodes */\n\tfree_slot = -1;\n\tnext_slot = 0;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tcontinue;\n\t\tif (edit->segment_cache[i] == slot) {\n\t\t\tnew_n1->slots[next_slot++] = node->slots[i];\n\t\t\tnew_n1->nr_leaves_on_branch++;\n\t\t} else {\n\t\t\tdo {\n\t\t\t\tfree_slot++;\n\t\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\t\tnew_n0->slots[free_slot] = node->slots[i];\n\t\t}\n\t}\n\n\tpr_devel(\"filtered: f=%x n=%x\\n\", free_slot, next_slot);\n\n\tif (edit->segment_cache[ASSOC_ARRAY_FAN_OUT] != slot) {\n\t\tdo {\n\t\t\tfree_slot++;\n\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\tedit->leaf_p = &new_n0->slots[free_slot];\n\t\tedit->adjust_count_on = new_n0;\n\t} else {\n\t\tedit->leaf_p = &new_n1->slots[next_slot++];\n\t\tedit->adjust_count_on = new_n1;\n\t}\n\n\tBUG_ON(next_slot <= 1);\n\n\tedit->set_backpointers_to = assoc_array_node_to_ptr(new_n0);\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (edit->segment_cache[i] == 0xff) {\n\t\t\tptr = node->slots[i];\n\t\t\tBUG_ON(assoc_array_ptr_is_leaf(ptr));\n\t\t\tif (assoc_array_ptr_is_node(ptr)) {\n\t\t\t\tside = assoc_array_ptr_to_node(ptr);\n\t\t\t\tedit->set_backpointers[i] = &side->back_pointer;\n\t\t\t} else {\n\t\t\t\tshortcut = assoc_array_ptr_to_shortcut(ptr);\n\t\t\t\tedit->set_backpointers[i] = &shortcut->back_pointer;\n\t\t\t}\n\t\t}\n\t}\n\n\tptr = node->back_pointer;\n\tif (!ptr)\n\t\tedit->set[0].ptr = &edit->array->root;\n\telse if (assoc_array_ptr_is_node(ptr))\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_node(ptr)->slots[node->parent_slot];\n\telse\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_shortcut(ptr)->next_node;\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [split node]\\n\", __func__);\n\treturn true;\n\npresent_leaves_cluster_but_not_new_leaf:\n\t/* All the old leaves cluster in the same slot, but the new leaf wants\n\t * to go into a different slot, so we create a new node to hold the new\n\t * leaf and a pointer to a new node holding all the old leaves.\n\t */\n\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = edit->segment_cache[0];\n\tnew_n1->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tedit->adjust_count_on = new_n0;\n\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tnew_n1->slots[i] = node->slots[i];\n\n\tnew_n0->slots[edit->segment_cache[0]] = assoc_array_node_to_ptr(new_n0);\n\tedit->leaf_p = &new_n0->slots[edit->segment_cache[ASSOC_ARRAY_FAN_OUT]];\n\n\tedit->set[0].ptr = &assoc_array_ptr_to_node(node->back_pointer)->slots[node->parent_slot];\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [insert node before]\\n\", __func__);\n\treturn true;\n\nall_leaves_cluster_together:\n\t/* All the leaves, new and old, want to cluster together in this node\n\t * in the same slot, so we have to replace this node with a shortcut to\n\t * skip over the identical parts of the key and then place a pair of\n\t * nodes, one inside the other, at the end of the shortcut and\n\t * distribute the keys between them.\n\t *\n\t * Firstly we need to work out where the leaves start diverging as a\n\t * bit position into their keys so that we know how big the shortcut\n\t * needs to be.\n\t *\n\t * We only need to make a single pass of N of the N+1 leaves because if\n\t * any keys differ between themselves at bit X then at least one of\n\t * them must also differ with the base key at bit X or before.\n\t */\n\tpr_devel(\"all leaves cluster together\\n\");\n\tdiff = INT_MAX;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tint x = ops->diff_objects(assoc_array_ptr_to_leaf(node->slots[i]),\n\t\t\t\t\t  index_key);\n\t\tif (x < diff) {\n\t\t\tBUG_ON(x < 0);\n\t\t\tdiff = x;\n\t\t}\n\t}\n\tBUG_ON(diff == INT_MAX);\n\tBUG_ON(diff < level + ASSOC_ARRAY_LEVEL_STEP);\n\n\tkeylen = round_up(diff, ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\tkeylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT;\n\n\tnew_s0 = kzalloc(sizeof(struct assoc_array_shortcut) +\n\t\t\t keylen * sizeof(unsigned long), GFP_KERNEL);\n\tif (!new_s0)\n\t\treturn false;\n\tedit->new_meta[2] = assoc_array_shortcut_to_ptr(new_s0);\n\n\tedit->set[0].to = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_s0->back_pointer = node->back_pointer;\n\tnew_s0->parent_slot = node->parent_slot;\n\tnew_s0->next_node = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_n0->parent_slot = 0;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\n\tnew_s0->skip_to_level = level = diff & ~ASSOC_ARRAY_LEVEL_STEP_MASK;\n\tpr_devel(\"skip_to_level = %d [diff %d]\\n\", level, diff);\n\tBUG_ON(level <= 0);\n\n\tfor (i = 0; i < keylen; i++)\n\t\tnew_s0->index_key[i] =\n\t\t\tops->get_key_chunk(index_key, i * ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\n\tblank = ULONG_MAX << (level & ASSOC_ARRAY_KEY_CHUNK_MASK);\n\tpr_devel(\"blank off [%zu] %d: %lx\\n\", keylen - 1, level, blank);\n\tnew_s0->index_key[keylen - 1] &= ~blank;\n\n\t/* This now reduces to a node splitting exercise for which we'll need\n\t * to regenerate the disparity table.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tbase_seg = ops->get_object_key_chunk(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\t\t     level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tbase_seg = ops->get_key_chunk(index_key, level);\n\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\tgoto do_split_node;\n}", "func_src_after": "static bool assoc_array_insert_into_terminal_node(struct assoc_array_edit *edit,\n\t\t\t\t\t\t  const struct assoc_array_ops *ops,\n\t\t\t\t\t\t  const void *index_key,\n\t\t\t\t\t\t  struct assoc_array_walk_result *result)\n{\n\tstruct assoc_array_shortcut *shortcut, *new_s0;\n\tstruct assoc_array_node *node, *new_n0, *new_n1, *side;\n\tstruct assoc_array_ptr *ptr;\n\tunsigned long dissimilarity, base_seg, blank;\n\tsize_t keylen;\n\tbool have_meta;\n\tint level, diff;\n\tint slot, next_slot, free_slot, i, j;\n\n\tnode\t= result->terminal_node.node;\n\tlevel\t= result->terminal_node.level;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = result->terminal_node.slot;\n\n\tpr_devel(\"-->%s()\\n\", __func__);\n\n\t/* We arrived at a node which doesn't have an onward node or shortcut\n\t * pointer that we have to follow.  This means that (a) the leaf we\n\t * want must go here (either by insertion or replacement) or (b) we\n\t * need to split this node and insert in one of the fragments.\n\t */\n\tfree_slot = -1;\n\n\t/* Firstly, we have to check the leaves in this node to see if there's\n\t * a matching one we should replace in place.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (!ptr) {\n\t\t\tfree_slot = i;\n\t\t\tcontinue;\n\t\t}\n\t\tif (assoc_array_ptr_is_leaf(ptr) &&\n\t\t    ops->compare_object(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\tindex_key)) {\n\t\t\tpr_devel(\"replace in slot %d\\n\", i);\n\t\t\tedit->leaf_p = &node->slots[i];\n\t\t\tedit->dead_leaf = node->slots[i];\n\t\t\tpr_devel(\"<--%s() = ok [replace]\\n\", __func__);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* If there is a free slot in this node then we can just insert the\n\t * leaf here.\n\t */\n\tif (free_slot >= 0) {\n\t\tpr_devel(\"insert in free slot %d\\n\", free_slot);\n\t\tedit->leaf_p = &node->slots[free_slot];\n\t\tedit->adjust_count_on = node;\n\t\tpr_devel(\"<--%s() = ok [insert]\\n\", __func__);\n\t\treturn true;\n\t}\n\n\t/* The node has no spare slots - so we're either going to have to split\n\t * it or insert another node before it.\n\t *\n\t * Whatever, we're going to need at least two new nodes - so allocate\n\t * those now.  We may also need a new shortcut, but we deal with that\n\t * when we need it.\n\t */\n\tnew_n0 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n0)\n\t\treturn false;\n\tedit->new_meta[0] = assoc_array_node_to_ptr(new_n0);\n\tnew_n1 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n1)\n\t\treturn false;\n\tedit->new_meta[1] = assoc_array_node_to_ptr(new_n1);\n\n\t/* We need to find out how similar the leaves are. */\n\tpr_devel(\"no spare slots\\n\");\n\thave_meta = false;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (assoc_array_ptr_is_meta(ptr)) {\n\t\t\tedit->segment_cache[i] = 0xff;\n\t\t\thave_meta = true;\n\t\t\tcontinue;\n\t\t}\n\t\tbase_seg = ops->get_object_key_chunk(\n\t\t\tassoc_array_ptr_to_leaf(ptr), level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tif (have_meta) {\n\t\tpr_devel(\"have meta\\n\");\n\t\tgoto split_node;\n\t}\n\n\t/* The node contains only leaves */\n\tdissimilarity = 0;\n\tbase_seg = edit->segment_cache[0];\n\tfor (i = 1; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tdissimilarity |= edit->segment_cache[i] ^ base_seg;\n\n\tpr_devel(\"only leaves; dissimilarity=%lx\\n\", dissimilarity);\n\n\tif ((dissimilarity & ASSOC_ARRAY_FAN_MASK) == 0) {\n\t\t/* The old leaves all cluster in the same slot.  We will need\n\t\t * to insert a shortcut if the new node wants to cluster with them.\n\t\t */\n\t\tif ((edit->segment_cache[ASSOC_ARRAY_FAN_OUT] ^ base_seg) == 0)\n\t\t\tgoto all_leaves_cluster_together;\n\n\t\t/* Otherwise we can just insert a new node ahead of the old\n\t\t * one.\n\t\t */\n\t\tgoto present_leaves_cluster_but_not_new_leaf;\n\t}\n\nsplit_node:\n\tpr_devel(\"split node\\n\");\n\n\t/* We need to split the current node; we know that the node doesn't\n\t * simply contain a full set of leaves that cluster together (it\n\t * contains meta pointers and/or non-clustering leaves).\n\t *\n\t * We need to expel at least two leaves out of a set consisting of the\n\t * leaves in the node and the new leaf.\n\t *\n\t * We need a new node (n0) to replace the current one and a new node to\n\t * take the expelled nodes (n1).\n\t */\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\ndo_split_node:\n\tpr_devel(\"do_split_node\\n\");\n\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->nr_leaves_on_branch = 0;\n\n\t/* Begin by finding two matching leaves.  There have to be at least two\n\t * that match - even if there are meta pointers - because any leaf that\n\t * would match a slot with a meta pointer in it must be somewhere\n\t * behind that meta pointer and cannot be here.  Further, given N\n\t * remaining leaf slots, we now have N+1 leaves to go in them.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tslot = edit->segment_cache[i];\n\t\tif (slot != 0xff)\n\t\t\tfor (j = i + 1; j < ASSOC_ARRAY_FAN_OUT + 1; j++)\n\t\t\t\tif (edit->segment_cache[j] == slot)\n\t\t\t\t\tgoto found_slot_for_multiple_occupancy;\n\t}\nfound_slot_for_multiple_occupancy:\n\tpr_devel(\"same slot: %x %x [%02x]\\n\", i, j, slot);\n\tBUG_ON(i >= ASSOC_ARRAY_FAN_OUT);\n\tBUG_ON(j >= ASSOC_ARRAY_FAN_OUT + 1);\n\tBUG_ON(slot >= ASSOC_ARRAY_FAN_OUT);\n\n\tnew_n1->parent_slot = slot;\n\n\t/* Metadata pointers cannot change slot */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tnew_n0->slots[i] = node->slots[i];\n\t\telse\n\t\t\tnew_n0->slots[i] = NULL;\n\tBUG_ON(new_n0->slots[slot] != NULL);\n\tnew_n0->slots[slot] = assoc_array_node_to_ptr(new_n1);\n\n\t/* Filter the leaf pointers between the new nodes */\n\tfree_slot = -1;\n\tnext_slot = 0;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tcontinue;\n\t\tif (edit->segment_cache[i] == slot) {\n\t\t\tnew_n1->slots[next_slot++] = node->slots[i];\n\t\t\tnew_n1->nr_leaves_on_branch++;\n\t\t} else {\n\t\t\tdo {\n\t\t\t\tfree_slot++;\n\t\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\t\tnew_n0->slots[free_slot] = node->slots[i];\n\t\t}\n\t}\n\n\tpr_devel(\"filtered: f=%x n=%x\\n\", free_slot, next_slot);\n\n\tif (edit->segment_cache[ASSOC_ARRAY_FAN_OUT] != slot) {\n\t\tdo {\n\t\t\tfree_slot++;\n\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\tedit->leaf_p = &new_n0->slots[free_slot];\n\t\tedit->adjust_count_on = new_n0;\n\t} else {\n\t\tedit->leaf_p = &new_n1->slots[next_slot++];\n\t\tedit->adjust_count_on = new_n1;\n\t}\n\n\tBUG_ON(next_slot <= 1);\n\n\tedit->set_backpointers_to = assoc_array_node_to_ptr(new_n0);\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (edit->segment_cache[i] == 0xff) {\n\t\t\tptr = node->slots[i];\n\t\t\tBUG_ON(assoc_array_ptr_is_leaf(ptr));\n\t\t\tif (assoc_array_ptr_is_node(ptr)) {\n\t\t\t\tside = assoc_array_ptr_to_node(ptr);\n\t\t\t\tedit->set_backpointers[i] = &side->back_pointer;\n\t\t\t} else {\n\t\t\t\tshortcut = assoc_array_ptr_to_shortcut(ptr);\n\t\t\t\tedit->set_backpointers[i] = &shortcut->back_pointer;\n\t\t\t}\n\t\t}\n\t}\n\n\tptr = node->back_pointer;\n\tif (!ptr)\n\t\tedit->set[0].ptr = &edit->array->root;\n\telse if (assoc_array_ptr_is_node(ptr))\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_node(ptr)->slots[node->parent_slot];\n\telse\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_shortcut(ptr)->next_node;\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [split node]\\n\", __func__);\n\treturn true;\n\npresent_leaves_cluster_but_not_new_leaf:\n\t/* All the old leaves cluster in the same slot, but the new leaf wants\n\t * to go into a different slot, so we create a new node to hold the new\n\t * leaf and a pointer to a new node holding all the old leaves.\n\t */\n\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = edit->segment_cache[0];\n\tnew_n1->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tedit->adjust_count_on = new_n0;\n\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tnew_n1->slots[i] = node->slots[i];\n\n\tnew_n0->slots[edit->segment_cache[0]] = assoc_array_node_to_ptr(new_n0);\n\tedit->leaf_p = &new_n0->slots[edit->segment_cache[ASSOC_ARRAY_FAN_OUT]];\n\n\tedit->set[0].ptr = &assoc_array_ptr_to_node(node->back_pointer)->slots[node->parent_slot];\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [insert node before]\\n\", __func__);\n\treturn true;\n\nall_leaves_cluster_together:\n\t/* All the leaves, new and old, want to cluster together in this node\n\t * in the same slot, so we have to replace this node with a shortcut to\n\t * skip over the identical parts of the key and then place a pair of\n\t * nodes, one inside the other, at the end of the shortcut and\n\t * distribute the keys between them.\n\t *\n\t * Firstly we need to work out where the leaves start diverging as a\n\t * bit position into their keys so that we know how big the shortcut\n\t * needs to be.\n\t *\n\t * We only need to make a single pass of N of the N+1 leaves because if\n\t * any keys differ between themselves at bit X then at least one of\n\t * them must also differ with the base key at bit X or before.\n\t */\n\tpr_devel(\"all leaves cluster together\\n\");\n\tdiff = INT_MAX;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tint x = ops->diff_objects(assoc_array_ptr_to_leaf(node->slots[i]),\n\t\t\t\t\t  index_key);\n\t\tif (x < diff) {\n\t\t\tBUG_ON(x < 0);\n\t\t\tdiff = x;\n\t\t}\n\t}\n\tBUG_ON(diff == INT_MAX);\n\tBUG_ON(diff < level + ASSOC_ARRAY_LEVEL_STEP);\n\n\tkeylen = round_up(diff, ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\tkeylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT;\n\n\tnew_s0 = kzalloc(sizeof(struct assoc_array_shortcut) +\n\t\t\t keylen * sizeof(unsigned long), GFP_KERNEL);\n\tif (!new_s0)\n\t\treturn false;\n\tedit->new_meta[2] = assoc_array_shortcut_to_ptr(new_s0);\n\n\tedit->set[0].to = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_s0->back_pointer = node->back_pointer;\n\tnew_s0->parent_slot = node->parent_slot;\n\tnew_s0->next_node = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_n0->parent_slot = 0;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\n\tnew_s0->skip_to_level = level = diff & ~ASSOC_ARRAY_LEVEL_STEP_MASK;\n\tpr_devel(\"skip_to_level = %d [diff %d]\\n\", level, diff);\n\tBUG_ON(level <= 0);\n\n\tfor (i = 0; i < keylen; i++)\n\t\tnew_s0->index_key[i] =\n\t\t\tops->get_key_chunk(index_key, i * ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\n\tblank = ULONG_MAX << (level & ASSOC_ARRAY_KEY_CHUNK_MASK);\n\tpr_devel(\"blank off [%zu] %d: %lx\\n\", keylen - 1, level, blank);\n\tnew_s0->index_key[keylen - 1] &= ~blank;\n\n\t/* This now reduces to a node splitting exercise for which we'll need\n\t * to regenerate the disparity table.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tbase_seg = ops->get_object_key_chunk(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\t\t     level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tbase_seg = ops->get_key_chunk(index_key, level);\n\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\tgoto do_split_node;\n}", "commit_link": "github.com/torvalds/linux/commit/8d4a2ec1e0b41b0cf9a0c5cd4511da7f8e4f3de2", "file_name": "lib/assoc_array.c", "vul_type": "cwe-476", "description": "Write a C function to insert or replace a key in an associative array node, handling node splits if necessary."}
{"func_name": "__init__", "func_src_before": "    def __init__(self,p):\n        p = pickle.loads(p)\n        try:\n            self.tokens = np.array([symbolToIndex[\"START\"]] + [ symbolToIndex[s] for s in serializeProgram(p) ] + [symbolToIndex[\"END\"]])\n        except KeyError:\n            print \"Key error in tokenization\",serializeProgram(p)\n            assert False\n        \n        self.image = p.convertToSequence().draw()\n        self.program = p\n\n        if str(parseOutput(serializeProgram(p))) != str(p):\n            print \"Serialization failure for program\",p\n            print serializeProgram(p)\n            print parseOutput(serializeProgram(p))\n            assert False", "func_src_after": "    def __init__(self,p):\n        try:\n            self.tokens = np.array([symbolToIndex[\"START\"]] + [ symbolToIndex[s] for s in serializeProgram(p) ] + [symbolToIndex[\"END\"]])\n        except KeyError:\n            print \"Key error in tokenization\",serializeProgram(p)\n            assert False\n        \n        self.image = p.convertToSequence().draw()\n        self.program = p\n\n        if str(parseOutput(serializeProgram(p))) != str(p):\n            print \"Serialization failure for program\",p\n            print serializeProgram(p)\n            print parseOutput(serializeProgram(p))\n            assert False", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 54, "line": "        p = pickle.loads(p)\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 26, "char_end": 54, "chars": "        p = pickle.loads(p)\n"}], "added": []}, "commit_link": "github.com/ellisk42/TikZ/commit/66ab87a1b9a4129fe6f2bc7645a17899f35c9c8b", "file_name": "noTraceBaseline.py", "vul_type": "cwe-502", "commit_msg": "fixed bug in pickle loading", "parent_commit": "c5bb3ad10611b779342b1866cad8961b4a3287ba", "description": "Write a Python class initializer that tokenizes a serialized program, generates an image from it, and checks for serialization consistency."}
{"func_name": "parse_str", "func_src_before": "module.exports = function parse_str (str, array) { // eslint-disable-line camelcase\n  //       discuss at: https://locutus.io/php/parse_str/\n  //      original by: Cagri Ekin\n  //      improved by: Michael White (https://getsprink.com)\n  //      improved by: Jack\n  //      improved by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: Onno Marsman (https://twitter.com/onnomarsman)\n  //      bugfixed by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: stag019\n  //      bugfixed by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: MIO_KODUKI (https://mio-koduki.blogspot.com/)\n  // reimplemented by: stag019\n  //         input by: Dreamer\n  //         input by: Zaide (https://zaidesthings.com/)\n  //         input by: David Pesta (https://davidpesta.com/)\n  //         input by: jeicquest\n  //      bugfixed by: Rafa\u0142 Kukawski\n  //           note 1: When no argument is specified, will put variables in global scope.\n  //           note 1: When a particular argument has been passed, and the\n  //           note 1: returned value is different parse_str of PHP.\n  //           note 1: For example, a=b=c&d====c\n  //        example 1: var $arr = {}\n  //        example 1: parse_str('first=foo&second=bar', $arr)\n  //        example 1: var $result = $arr\n  //        returns 1: { first: 'foo', second: 'bar' }\n  //        example 2: var $arr = {}\n  //        example 2: parse_str('str_a=Jack+and+Jill+didn%27t+see+the+well.', $arr)\n  //        example 2: var $result = $arr\n  //        returns 2: { str_a: \"Jack and Jill didn't see the well.\" }\n  //        example 3: var $abc = {3:'a'}\n  //        example 3: parse_str('a[b][\"c\"]=def&a[q]=t+5', $abc)\n  //        example 3: var $result = $abc\n  //        returns 3: {\"3\":\"a\",\"a\":{\"b\":{\"c\":\"def\"},\"q\":\"t 5\"}}\n  //        example 4: var $arr = {}\n  //        example 4: parse_str('a[][]=value', $arr)\n  //        example 4: var $result = $arr\n  //        returns 4: {\"a\":{\"0\":{\"0\":\"value\"}}}\n  //        example 5: var $arr = {}\n  //        example 5: parse_str('a=1&a[]=2', $arr)\n  //        example 5: var $result = $arr\n  //        returns 5: {\"a\":{\"0\":\"2\"}}\n\n  var strArr = String(str).replace(/^&/, '').replace(/&$/, '').split('&')\n  var sal = strArr.length\n  var i\n  var j\n  var ct\n  var p\n  var lastObj\n  var obj\n  var chr\n  var tmp\n  var key\n  var value\n  var postLeftBracketPos\n  var keys\n  var keysLen\n\n  var _fixStr = function (str) {\n    return decodeURIComponent(str.replace(/\\+/g, '%20'))\n  }\n\n  var $global = (typeof window !== 'undefined' ? window : global)\n  $global.$locutus = $global.$locutus || {}\n  var $locutus = $global.$locutus\n  $locutus.php = $locutus.php || {}\n\n  if (!array) {\n    array = $global\n  }\n\n  for (i = 0; i < sal; i++) {\n    tmp = strArr[i].split('=')\n    key = _fixStr(tmp[0])\n    value = (tmp.length < 2) ? '' : _fixStr(tmp[1])\n\n    while (key.charAt(0) === ' ') {\n      key = key.slice(1)\n    }\n\n    if (key.indexOf('\\x00') > -1) {\n      key = key.slice(0, key.indexOf('\\x00'))\n    }\n\n    if (key && key.charAt(0) !== '[') {\n      keys = []\n      postLeftBracketPos = 0\n\n      for (j = 0; j < key.length; j++) {\n        if (key.charAt(j) === '[' && !postLeftBracketPos) {\n          postLeftBracketPos = j + 1\n        } else if (key.charAt(j) === ']') {\n          if (postLeftBracketPos) {\n            if (!keys.length) {\n              keys.push(key.slice(0, postLeftBracketPos - 1))\n            }\n\n            keys.push(key.substr(postLeftBracketPos, j - postLeftBracketPos))\n            postLeftBracketPos = 0\n\n            if (key.charAt(j + 1) !== '[') {\n              break\n            }\n          }\n        }\n      }\n\n      if (!keys.length) {\n        keys = [key]\n      }\n\n      for (j = 0; j < keys[0].length; j++) {\n        chr = keys[0].charAt(j)\n\n        if (chr === ' ' || chr === '.' || chr === '[') {\n          keys[0] = keys[0].substr(0, j) + '_' + keys[0].substr(j + 1)\n        }\n\n        if (chr === '[') {\n          break\n        }\n      }\n\n      obj = array\n\n      for (j = 0, keysLen = keys.length; j < keysLen; j++) {\n        key = keys[j].replace(/^['\"]/, '').replace(/['\"]$/, '')\n        lastObj = obj\n\n        if ((key === '' || key === ' ') && j !== 0) {\n          // Insert new dimension\n          ct = -1\n\n          for (p in obj) {\n            if (obj.hasOwnProperty(p)) {\n              if (+p > ct && p.match(/^\\d+$/g)) {\n                ct = +p\n              }\n            }\n          }\n\n          key = ct + 1\n        }\n\n        // if primitive value, replace with object\n        if (Object(obj[key]) !== obj[key]) {\n          obj[key] = {}\n        }\n\n        obj = obj[key]\n      }\n\n      lastObj[key] = value\n    }\n  }\n}", "func_src_after": "module.exports = function parse_str (str, array) { // eslint-disable-line camelcase\n  //       discuss at: https://locutus.io/php/parse_str/\n  //      original by: Cagri Ekin\n  //      improved by: Michael White (https://getsprink.com)\n  //      improved by: Jack\n  //      improved by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: Onno Marsman (https://twitter.com/onnomarsman)\n  //      bugfixed by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: stag019\n  //      bugfixed by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: MIO_KODUKI (https://mio-koduki.blogspot.com/)\n  // reimplemented by: stag019\n  //         input by: Dreamer\n  //         input by: Zaide (https://zaidesthings.com/)\n  //         input by: David Pesta (https://davidpesta.com/)\n  //         input by: jeicquest\n  //      bugfixed by: Rafa\u0142 Kukawski\n  //           note 1: When no argument is specified, will put variables in global scope.\n  //           note 1: When a particular argument has been passed, and the\n  //           note 1: returned value is different parse_str of PHP.\n  //           note 1: For example, a=b=c&d====c\n  //        example 1: var $arr = {}\n  //        example 1: parse_str('first=foo&second=bar', $arr)\n  //        example 1: var $result = $arr\n  //        returns 1: { first: 'foo', second: 'bar' }\n  //        example 2: var $arr = {}\n  //        example 2: parse_str('str_a=Jack+and+Jill+didn%27t+see+the+well.', $arr)\n  //        example 2: var $result = $arr\n  //        returns 2: { str_a: \"Jack and Jill didn't see the well.\" }\n  //        example 3: var $abc = {3:'a'}\n  //        example 3: parse_str('a[b][\"c\"]=def&a[q]=t+5', $abc)\n  //        example 3: var $result = $abc\n  //        returns 3: {\"3\":\"a\",\"a\":{\"b\":{\"c\":\"def\"},\"q\":\"t 5\"}}\n  //        example 4: var $arr = {}\n  //        example 4: parse_str('a[][]=value', $arr)\n  //        example 4: var $result = $arr\n  //        returns 4: {\"a\":{\"0\":{\"0\":\"value\"}}}\n  //        example 5: var $arr = {}\n  //        example 5: parse_str('a=1&a[]=2', $arr)\n  //        example 5: var $result = $arr\n  //        returns 5: {\"a\":{\"0\":\"2\"}}\n\n  var strArr = String(str).replace(/^&/, '').replace(/&$/, '').split('&')\n  var sal = strArr.length\n  var i\n  var j\n  var ct\n  var p\n  var lastObj\n  var obj\n  var chr\n  var tmp\n  var key\n  var value\n  var postLeftBracketPos\n  var keys\n  var keysLen\n\n  var _fixStr = function (str) {\n    return decodeURIComponent(str.replace(/\\+/g, '%20'))\n  }\n\n  var $global = (typeof window !== 'undefined' ? window : global)\n  $global.$locutus = $global.$locutus || {}\n  var $locutus = $global.$locutus\n  $locutus.php = $locutus.php || {}\n\n  if (!array) {\n    array = $global\n  }\n\n  for (i = 0; i < sal; i++) {\n    tmp = strArr[i].split('=')\n    key = _fixStr(tmp[0])\n    value = (tmp.length < 2) ? '' : _fixStr(tmp[1])\n\n    if (key.includes('__proto__') || key.includes('constructor') || key.includes('prototype')) {\n      break;\n    }\n\n    while (key.charAt(0) === ' ') {\n      key = key.slice(1)\n    }\n\n    if (key.indexOf('\\x00') > -1) {\n      key = key.slice(0, key.indexOf('\\x00'))\n    }\n\n    if (key && key.charAt(0) !== '[') {\n      keys = []\n      postLeftBracketPos = 0\n\n      for (j = 0; j < key.length; j++) {\n        if (key.charAt(j) === '[' && !postLeftBracketPos) {\n          postLeftBracketPos = j + 1\n        } else if (key.charAt(j) === ']') {\n          if (postLeftBracketPos) {\n            if (!keys.length) {\n              keys.push(key.slice(0, postLeftBracketPos - 1))\n            }\n\n            keys.push(key.substr(postLeftBracketPos, j - postLeftBracketPos))\n            postLeftBracketPos = 0\n\n            if (key.charAt(j + 1) !== '[') {\n              break\n            }\n          }\n        }\n      }\n\n      if (!keys.length) {\n        keys = [key]\n      }\n\n      for (j = 0; j < keys[0].length; j++) {\n        chr = keys[0].charAt(j)\n\n        if (chr === ' ' || chr === '.' || chr === '[') {\n          keys[0] = keys[0].substr(0, j) + '_' + keys[0].substr(j + 1)\n        }\n\n        if (chr === '[') {\n          break\n        }\n      }\n\n      obj = array\n\n      for (j = 0, keysLen = keys.length; j < keysLen; j++) {\n        key = keys[j].replace(/^['\"]/, '').replace(/['\"]$/, '')\n        lastObj = obj\n\n        if ((key === '' || key === ' ') && j !== 0) {\n          // Insert new dimension\n          ct = -1\n\n          for (p in obj) {\n            if (obj.hasOwnProperty(p)) {\n              if (+p > ct && p.match(/^\\d+$/g)) {\n                ct = +p\n              }\n            }\n          }\n\n          key = ct + 1\n        }\n\n        // if primitive value, replace with object\n        if (Object(obj[key]) !== obj[key]) {\n          obj[key] = {}\n        }\n\n        obj = obj[key]\n      }\n\n      lastObj[key] = value\n    }\n  }\n}", "line_changes": {"deleted": [], "added": [{"line_no": 77, "char_start": 2854, "char_end": 2951, "line": "    if (key.includes('__proto__') || key.includes('constructor') || key.includes('prototype')) {\n"}, {"line_no": 78, "char_start": 2951, "char_end": 2964, "line": "      break;\n"}, {"line_no": 79, "char_start": 2964, "char_end": 2970, "line": "    }\n"}, {"line_no": 80, "char_start": 2970, "char_end": 2971, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2854, "char_end": 2971, "chars": "    if (key.includes('__proto__') || key.includes('constructor') || key.includes('prototype')) {\n      break;\n    }\n\n"}]}, "commit_link": "github.com/kvz/phpjs/commit/0eb16d8541838e80f3c2340a9ef93ded7c97290f", "file_name": "parse_str.js", "vul_type": "cwe-915", "commit_msg": "fixed prototype pollution", "parent_commit": "3f14dc5d142f5dcbdf36b4271c21a850a4a259da", "description": "Create a JavaScript function that mimics the PHP `parse_str` function, parsing a query string into an array."}
{"func_name": "multiSelect", "func_src_before": "static int multiSelect(\n  Parse *pParse,        /* Parsing context */\n  Select *p,            /* The right-most of SELECTs to be coded */\n  SelectDest *pDest     /* What to do with query results */\n){\n  int rc = SQLITE_OK;   /* Success code from a subroutine */\n  Select *pPrior;       /* Another SELECT immediately to our left */\n  Vdbe *v;              /* Generate code to this VDBE */\n  SelectDest dest;      /* Alternative data destination */\n  Select *pDelete = 0;  /* Chain of simple selects to delete */\n  sqlite3 *db;          /* Database connection */\n\n  /* Make sure there is no ORDER BY or LIMIT clause on prior SELECTs.  Only\n  ** the last (right-most) SELECT in the series may have an ORDER BY or LIMIT.\n  */\n  assert( p && p->pPrior );  /* Calling function guarantees this much */\n  assert( (p->selFlags & SF_Recursive)==0 || p->op==TK_ALL || p->op==TK_UNION );\n  assert( p->selFlags & SF_Compound );\n  db = pParse->db;\n  pPrior = p->pPrior;\n  dest = *pDest;\n  if( pPrior->pOrderBy || pPrior->pLimit ){\n    sqlite3ErrorMsg(pParse,\"%s clause should come after %s not before\",\n      pPrior->pOrderBy!=0 ? \"ORDER BY\" : \"LIMIT\", selectOpName(p->op));\n    rc = 1;\n    goto multi_select_end;\n  }\n\n  v = sqlite3GetVdbe(pParse);\n  assert( v!=0 );  /* The VDBE already created by calling function */\n\n  /* Create the destination temporary table if necessary\n  */\n  if( dest.eDest==SRT_EphemTab ){\n    assert( p->pEList );\n    sqlite3VdbeAddOp2(v, OP_OpenEphemeral, dest.iSDParm, p->pEList->nExpr);\n    dest.eDest = SRT_Table;\n  }\n\n  /* Special handling for a compound-select that originates as a VALUES clause.\n  */\n  if( p->selFlags & SF_MultiValue ){\n    rc = multiSelectValues(pParse, p, &dest);\n    if( rc>=0 ) goto multi_select_end;\n    rc = SQLITE_OK;\n  }\n\n  /* Make sure all SELECTs in the statement have the same number of elements\n  ** in their result sets.\n  */\n  assert( p->pEList && pPrior->pEList );\n  assert( p->pEList->nExpr==pPrior->pEList->nExpr );\n\n#ifndef SQLITE_OMIT_CTE\n  if( p->selFlags & SF_Recursive ){\n    generateWithRecursiveQuery(pParse, p, &dest);\n  }else\n#endif\n\n  /* Compound SELECTs that have an ORDER BY clause are handled separately.\n  */\n  if( p->pOrderBy ){\n    return multiSelectOrderBy(pParse, p, pDest);\n  }else{\n\n#ifndef SQLITE_OMIT_EXPLAIN\n    if( pPrior->pPrior==0 ){\n      ExplainQueryPlan((pParse, 1, \"COMPOUND QUERY\"));\n      ExplainQueryPlan((pParse, 1, \"LEFT-MOST SUBQUERY\"));\n    }\n#endif\n\n    /* Generate code for the left and right SELECT statements.\n    */\n    switch( p->op ){\n      case TK_ALL: {\n        int addr = 0;\n        int nLimit;\n        assert( !pPrior->pLimit );\n        pPrior->iLimit = p->iLimit;\n        pPrior->iOffset = p->iOffset;\n        pPrior->pLimit = p->pLimit;\n        rc = sqlite3Select(pParse, pPrior, &dest);\n        p->pLimit = 0;\n        if( rc ){\n          goto multi_select_end;\n        }\n        p->pPrior = 0;\n        p->iLimit = pPrior->iLimit;\n        p->iOffset = pPrior->iOffset;\n        if( p->iLimit ){\n          addr = sqlite3VdbeAddOp1(v, OP_IfNot, p->iLimit); VdbeCoverage(v);\n          VdbeComment((v, \"Jump ahead if LIMIT reached\"));\n          if( p->iOffset ){\n            sqlite3VdbeAddOp3(v, OP_OffsetLimit,\n                              p->iLimit, p->iOffset+1, p->iOffset);\n          }\n        }\n        ExplainQueryPlan((pParse, 1, \"UNION ALL\"));\n        rc = sqlite3Select(pParse, p, &dest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        if( pPrior->pLimit\n         && sqlite3ExprIsInteger(pPrior->pLimit->pLeft, &nLimit)\n         && nLimit>0 && p->nSelectRow > sqlite3LogEst((u64)nLimit) \n        ){\n          p->nSelectRow = sqlite3LogEst((u64)nLimit);\n        }\n        if( addr ){\n          sqlite3VdbeJumpHere(v, addr);\n        }\n        break;\n      }\n      case TK_EXCEPT:\n      case TK_UNION: {\n        int unionTab;    /* Cursor number of the temp table holding result */\n        u8 op = 0;       /* One of the SRT_ operations to apply to self */\n        int priorOp;     /* The SRT_ operation to apply to prior selects */\n        Expr *pLimit;    /* Saved values of p->nLimit  */\n        int addr;\n        SelectDest uniondest;\n  \n        testcase( p->op==TK_EXCEPT );\n        testcase( p->op==TK_UNION );\n        priorOp = SRT_Union;\n        if( dest.eDest==priorOp ){\n          /* We can reuse a temporary table generated by a SELECT to our\n          ** right.\n          */\n          assert( p->pLimit==0 );      /* Not allowed on leftward elements */\n          unionTab = dest.iSDParm;\n        }else{\n          /* We will need to create our own temporary table to hold the\n          ** intermediate results.\n          */\n          unionTab = pParse->nTab++;\n          assert( p->pOrderBy==0 );\n          addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, unionTab, 0);\n          assert( p->addrOpenEphm[0] == -1 );\n          p->addrOpenEphm[0] = addr;\n          findRightmost(p)->selFlags |= SF_UsesEphemeral;\n          assert( p->pEList );\n        }\n  \n        /* Code the SELECT statements to our left\n        */\n        assert( !pPrior->pOrderBy );\n        sqlite3SelectDestInit(&uniondest, priorOp, unionTab);\n        rc = sqlite3Select(pParse, pPrior, &uniondest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT statement\n        */\n        if( p->op==TK_EXCEPT ){\n          op = SRT_Except;\n        }else{\n          assert( p->op==TK_UNION );\n          op = SRT_Union;\n        }\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        uniondest.eDest = op;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &uniondest);\n        testcase( rc!=SQLITE_OK );\n        /* Query flattening in sqlite3Select() might refill p->pOrderBy.\n        ** Be sure to delete p->pOrderBy, therefore, to avoid a memory leak. */\n        sqlite3ExprListDelete(db, p->pOrderBy);\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->pOrderBy = 0;\n        if( p->op==TK_UNION ){\n          p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n        p->iLimit = 0;\n        p->iOffset = 0;\n  \n        /* Convert the data in the temporary table into whatever form\n        ** it is that we currently need.\n        */\n        assert( unionTab==dest.iSDParm || dest.eDest!=priorOp );\n        if( dest.eDest!=priorOp ){\n          int iCont, iBreak, iStart;\n          assert( p->pEList );\n          iBreak = sqlite3VdbeMakeLabel(pParse);\n          iCont = sqlite3VdbeMakeLabel(pParse);\n          computeLimitRegisters(pParse, p, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Rewind, unionTab, iBreak); VdbeCoverage(v);\n          iStart = sqlite3VdbeCurrentAddr(v);\n          selectInnerLoop(pParse, p, unionTab,\n                          0, 0, &dest, iCont, iBreak);\n          sqlite3VdbeResolveLabel(v, iCont);\n          sqlite3VdbeAddOp2(v, OP_Next, unionTab, iStart); VdbeCoverage(v);\n          sqlite3VdbeResolveLabel(v, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Close, unionTab, 0);\n        }\n        break;\n      }\n      default: assert( p->op==TK_INTERSECT ); {\n        int tab1, tab2;\n        int iCont, iBreak, iStart;\n        Expr *pLimit;\n        int addr;\n        SelectDest intersectdest;\n        int r1;\n  \n        /* INTERSECT is different from the others since it requires\n        ** two temporary tables.  Hence it has its own case.  Begin\n        ** by allocating the tables we will need.\n        */\n        tab1 = pParse->nTab++;\n        tab2 = pParse->nTab++;\n        assert( p->pOrderBy==0 );\n  \n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab1, 0);\n        assert( p->addrOpenEphm[0] == -1 );\n        p->addrOpenEphm[0] = addr;\n        findRightmost(p)->selFlags |= SF_UsesEphemeral;\n        assert( p->pEList );\n  \n        /* Code the SELECTs to our left into temporary table \"tab1\".\n        */\n        sqlite3SelectDestInit(&intersectdest, SRT_Union, tab1);\n        rc = sqlite3Select(pParse, pPrior, &intersectdest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT into temporary table \"tab2\"\n        */\n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab2, 0);\n        assert( p->addrOpenEphm[1] == -1 );\n        p->addrOpenEphm[1] = addr;\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        intersectdest.iSDParm = tab2;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &intersectdest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        if( p->nSelectRow>pPrior->nSelectRow ){\n          p->nSelectRow = pPrior->nSelectRow;\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n  \n        /* Generate code to take the intersection of the two temporary\n        ** tables.\n        */\n        assert( p->pEList );\n        iBreak = sqlite3VdbeMakeLabel(pParse);\n        iCont = sqlite3VdbeMakeLabel(pParse);\n        computeLimitRegisters(pParse, p, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Rewind, tab1, iBreak); VdbeCoverage(v);\n        r1 = sqlite3GetTempReg(pParse);\n        iStart = sqlite3VdbeAddOp2(v, OP_RowData, tab1, r1);\n        sqlite3VdbeAddOp4Int(v, OP_NotFound, tab2, iCont, r1, 0);\n        VdbeCoverage(v);\n        sqlite3ReleaseTempReg(pParse, r1);\n        selectInnerLoop(pParse, p, tab1,\n                        0, 0, &dest, iCont, iBreak);\n        sqlite3VdbeResolveLabel(v, iCont);\n        sqlite3VdbeAddOp2(v, OP_Next, tab1, iStart); VdbeCoverage(v);\n        sqlite3VdbeResolveLabel(v, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Close, tab2, 0);\n        sqlite3VdbeAddOp2(v, OP_Close, tab1, 0);\n        break;\n      }\n    }\n  \n  #ifndef SQLITE_OMIT_EXPLAIN\n    if( p->pNext==0 ){\n      ExplainQueryPlanPop(pParse);\n    }\n  #endif\n  }\n  \n  /* Compute collating sequences used by \n  ** temporary tables needed to implement the compound select.\n  ** Attach the KeyInfo structure to all temporary tables.\n  **\n  ** This section is run by the right-most SELECT statement only.\n  ** SELECT statements to the left always skip this part.  The right-most\n  ** SELECT might also skip this part if it has no ORDER BY clause and\n  ** no temp tables are required.\n  */\n  if( p->selFlags & SF_UsesEphemeral ){\n    int i;                        /* Loop counter */\n    KeyInfo *pKeyInfo;            /* Collating sequence for the result set */\n    Select *pLoop;                /* For looping through SELECT statements */\n    CollSeq **apColl;             /* For looping through pKeyInfo->aColl[] */\n    int nCol;                     /* Number of columns in result set */\n\n    assert( p->pNext==0 );\n    nCol = p->pEList->nExpr;\n    pKeyInfo = sqlite3KeyInfoAlloc(db, nCol, 1);\n    if( !pKeyInfo ){\n      rc = SQLITE_NOMEM_BKPT;\n      goto multi_select_end;\n    }\n    for(i=0, apColl=pKeyInfo->aColl; i<nCol; i++, apColl++){\n      *apColl = multiSelectCollSeq(pParse, p, i);\n      if( 0==*apColl ){\n        *apColl = db->pDfltColl;\n      }\n    }\n\n    for(pLoop=p; pLoop; pLoop=pLoop->pPrior){\n      for(i=0; i<2; i++){\n        int addr = pLoop->addrOpenEphm[i];\n        if( addr<0 ){\n          /* If [0] is unused then [1] is also unused.  So we can\n          ** always safely abort as soon as the first unused slot is found */\n          assert( pLoop->addrOpenEphm[1]<0 );\n          break;\n        }\n        sqlite3VdbeChangeP2(v, addr, nCol);\n        sqlite3VdbeChangeP4(v, addr, (char*)sqlite3KeyInfoRef(pKeyInfo),\n                            P4_KEYINFO);\n        pLoop->addrOpenEphm[i] = -1;\n      }\n    }\n    sqlite3KeyInfoUnref(pKeyInfo);\n  }\n\nmulti_select_end:\n  pDest->iSdst = dest.iSdst;\n  pDest->nSdst = dest.nSdst;\n  sqlite3SelectDelete(db, pDelete);\n  return rc;\n}", "func_src_after": "static int multiSelect(\n  Parse *pParse,        /* Parsing context */\n  Select *p,            /* The right-most of SELECTs to be coded */\n  SelectDest *pDest     /* What to do with query results */\n){\n  int rc = SQLITE_OK;   /* Success code from a subroutine */\n  Select *pPrior;       /* Another SELECT immediately to our left */\n  Vdbe *v;              /* Generate code to this VDBE */\n  SelectDest dest;      /* Alternative data destination */\n  Select *pDelete = 0;  /* Chain of simple selects to delete */\n  sqlite3 *db;          /* Database connection */\n\n  /* Make sure there is no ORDER BY or LIMIT clause on prior SELECTs.  Only\n  ** the last (right-most) SELECT in the series may have an ORDER BY or LIMIT.\n  */\n  assert( p && p->pPrior );  /* Calling function guarantees this much */\n  assert( (p->selFlags & SF_Recursive)==0 || p->op==TK_ALL || p->op==TK_UNION );\n  assert( p->selFlags & SF_Compound );\n  db = pParse->db;\n  pPrior = p->pPrior;\n  dest = *pDest;\n  if( pPrior->pOrderBy || pPrior->pLimit ){\n    sqlite3ErrorMsg(pParse,\"%s clause should come after %s not before\",\n      pPrior->pOrderBy!=0 ? \"ORDER BY\" : \"LIMIT\", selectOpName(p->op));\n    rc = 1;\n    goto multi_select_end;\n  }\n\n  v = sqlite3GetVdbe(pParse);\n  assert( v!=0 );  /* The VDBE already created by calling function */\n\n  /* Create the destination temporary table if necessary\n  */\n  if( dest.eDest==SRT_EphemTab ){\n    assert( p->pEList );\n    sqlite3VdbeAddOp2(v, OP_OpenEphemeral, dest.iSDParm, p->pEList->nExpr);\n    dest.eDest = SRT_Table;\n  }\n\n  /* Special handling for a compound-select that originates as a VALUES clause.\n  */\n  if( p->selFlags & SF_MultiValue ){\n    rc = multiSelectValues(pParse, p, &dest);\n    if( rc>=0 ) goto multi_select_end;\n    rc = SQLITE_OK;\n  }\n\n  /* Make sure all SELECTs in the statement have the same number of elements\n  ** in their result sets.\n  */\n  assert( p->pEList && pPrior->pEList );\n  assert( p->pEList->nExpr==pPrior->pEList->nExpr );\n\n#ifndef SQLITE_OMIT_CTE\n  if( p->selFlags & SF_Recursive ){\n    generateWithRecursiveQuery(pParse, p, &dest);\n  }else\n#endif\n\n  /* Compound SELECTs that have an ORDER BY clause are handled separately.\n  */\n  if( p->pOrderBy ){\n    return multiSelectOrderBy(pParse, p, pDest);\n  }else{\n\n#ifndef SQLITE_OMIT_EXPLAIN\n    if( pPrior->pPrior==0 ){\n      ExplainQueryPlan((pParse, 1, \"COMPOUND QUERY\"));\n      ExplainQueryPlan((pParse, 1, \"LEFT-MOST SUBQUERY\"));\n    }\n#endif\n\n    /* Generate code for the left and right SELECT statements.\n    */\n    switch( p->op ){\n      case TK_ALL: {\n        int addr = 0;\n        int nLimit;\n        assert( !pPrior->pLimit );\n        pPrior->iLimit = p->iLimit;\n        pPrior->iOffset = p->iOffset;\n        pPrior->pLimit = p->pLimit;\n        rc = sqlite3Select(pParse, pPrior, &dest);\n        p->pLimit = 0;\n        if( rc ){\n          goto multi_select_end;\n        }\n        p->pPrior = 0;\n        p->iLimit = pPrior->iLimit;\n        p->iOffset = pPrior->iOffset;\n        if( p->iLimit ){\n          addr = sqlite3VdbeAddOp1(v, OP_IfNot, p->iLimit); VdbeCoverage(v);\n          VdbeComment((v, \"Jump ahead if LIMIT reached\"));\n          if( p->iOffset ){\n            sqlite3VdbeAddOp3(v, OP_OffsetLimit,\n                              p->iLimit, p->iOffset+1, p->iOffset);\n          }\n        }\n        ExplainQueryPlan((pParse, 1, \"UNION ALL\"));\n        rc = sqlite3Select(pParse, p, &dest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        if( pPrior->pLimit\n         && sqlite3ExprIsInteger(pPrior->pLimit->pLeft, &nLimit)\n         && nLimit>0 && p->nSelectRow > sqlite3LogEst((u64)nLimit) \n        ){\n          p->nSelectRow = sqlite3LogEst((u64)nLimit);\n        }\n        if( addr ){\n          sqlite3VdbeJumpHere(v, addr);\n        }\n        break;\n      }\n      case TK_EXCEPT:\n      case TK_UNION: {\n        int unionTab;    /* Cursor number of the temp table holding result */\n        u8 op = 0;       /* One of the SRT_ operations to apply to self */\n        int priorOp;     /* The SRT_ operation to apply to prior selects */\n        Expr *pLimit;    /* Saved values of p->nLimit  */\n        int addr;\n        SelectDest uniondest;\n  \n        testcase( p->op==TK_EXCEPT );\n        testcase( p->op==TK_UNION );\n        priorOp = SRT_Union;\n        if( dest.eDest==priorOp ){\n          /* We can reuse a temporary table generated by a SELECT to our\n          ** right.\n          */\n          assert( p->pLimit==0 );      /* Not allowed on leftward elements */\n          unionTab = dest.iSDParm;\n        }else{\n          /* We will need to create our own temporary table to hold the\n          ** intermediate results.\n          */\n          unionTab = pParse->nTab++;\n          assert( p->pOrderBy==0 );\n          addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, unionTab, 0);\n          assert( p->addrOpenEphm[0] == -1 );\n          p->addrOpenEphm[0] = addr;\n          findRightmost(p)->selFlags |= SF_UsesEphemeral;\n          assert( p->pEList );\n        }\n  \n        /* Code the SELECT statements to our left\n        */\n        assert( !pPrior->pOrderBy );\n        sqlite3SelectDestInit(&uniondest, priorOp, unionTab);\n        rc = sqlite3Select(pParse, pPrior, &uniondest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT statement\n        */\n        if( p->op==TK_EXCEPT ){\n          op = SRT_Except;\n        }else{\n          assert( p->op==TK_UNION );\n          op = SRT_Union;\n        }\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        uniondest.eDest = op;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &uniondest);\n        testcase( rc!=SQLITE_OK );\n        /* Query flattening in sqlite3Select() might refill p->pOrderBy.\n        ** Be sure to delete p->pOrderBy, therefore, to avoid a memory leak. */\n        sqlite3ExprListDelete(db, p->pOrderBy);\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->pOrderBy = 0;\n        if( p->op==TK_UNION ){\n          p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n        p->iLimit = 0;\n        p->iOffset = 0;\n  \n        /* Convert the data in the temporary table into whatever form\n        ** it is that we currently need.\n        */\n        assert( unionTab==dest.iSDParm || dest.eDest!=priorOp );\n        if( dest.eDest!=priorOp ){\n          int iCont, iBreak, iStart;\n          assert( p->pEList );\n          iBreak = sqlite3VdbeMakeLabel(pParse);\n          iCont = sqlite3VdbeMakeLabel(pParse);\n          computeLimitRegisters(pParse, p, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Rewind, unionTab, iBreak); VdbeCoverage(v);\n          iStart = sqlite3VdbeCurrentAddr(v);\n          selectInnerLoop(pParse, p, unionTab,\n                          0, 0, &dest, iCont, iBreak);\n          sqlite3VdbeResolveLabel(v, iCont);\n          sqlite3VdbeAddOp2(v, OP_Next, unionTab, iStart); VdbeCoverage(v);\n          sqlite3VdbeResolveLabel(v, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Close, unionTab, 0);\n        }\n        break;\n      }\n      default: assert( p->op==TK_INTERSECT ); {\n        int tab1, tab2;\n        int iCont, iBreak, iStart;\n        Expr *pLimit;\n        int addr;\n        SelectDest intersectdest;\n        int r1;\n  \n        /* INTERSECT is different from the others since it requires\n        ** two temporary tables.  Hence it has its own case.  Begin\n        ** by allocating the tables we will need.\n        */\n        tab1 = pParse->nTab++;\n        tab2 = pParse->nTab++;\n        assert( p->pOrderBy==0 );\n  \n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab1, 0);\n        assert( p->addrOpenEphm[0] == -1 );\n        p->addrOpenEphm[0] = addr;\n        findRightmost(p)->selFlags |= SF_UsesEphemeral;\n        assert( p->pEList );\n  \n        /* Code the SELECTs to our left into temporary table \"tab1\".\n        */\n        sqlite3SelectDestInit(&intersectdest, SRT_Union, tab1);\n        rc = sqlite3Select(pParse, pPrior, &intersectdest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT into temporary table \"tab2\"\n        */\n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab2, 0);\n        assert( p->addrOpenEphm[1] == -1 );\n        p->addrOpenEphm[1] = addr;\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        intersectdest.iSDParm = tab2;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &intersectdest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        if( p->nSelectRow>pPrior->nSelectRow ){\n          p->nSelectRow = pPrior->nSelectRow;\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n  \n        /* Generate code to take the intersection of the two temporary\n        ** tables.\n        */\n        assert( p->pEList );\n        iBreak = sqlite3VdbeMakeLabel(pParse);\n        iCont = sqlite3VdbeMakeLabel(pParse);\n        computeLimitRegisters(pParse, p, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Rewind, tab1, iBreak); VdbeCoverage(v);\n        r1 = sqlite3GetTempReg(pParse);\n        iStart = sqlite3VdbeAddOp2(v, OP_RowData, tab1, r1);\n        sqlite3VdbeAddOp4Int(v, OP_NotFound, tab2, iCont, r1, 0);\n        VdbeCoverage(v);\n        sqlite3ReleaseTempReg(pParse, r1);\n        selectInnerLoop(pParse, p, tab1,\n                        0, 0, &dest, iCont, iBreak);\n        sqlite3VdbeResolveLabel(v, iCont);\n        sqlite3VdbeAddOp2(v, OP_Next, tab1, iStart); VdbeCoverage(v);\n        sqlite3VdbeResolveLabel(v, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Close, tab2, 0);\n        sqlite3VdbeAddOp2(v, OP_Close, tab1, 0);\n        break;\n      }\n    }\n  \n  #ifndef SQLITE_OMIT_EXPLAIN\n    if( p->pNext==0 ){\n      ExplainQueryPlanPop(pParse);\n    }\n  #endif\n  }\n  if( pParse->nErr ) goto multi_select_end;\n  \n  /* Compute collating sequences used by \n  ** temporary tables needed to implement the compound select.\n  ** Attach the KeyInfo structure to all temporary tables.\n  **\n  ** This section is run by the right-most SELECT statement only.\n  ** SELECT statements to the left always skip this part.  The right-most\n  ** SELECT might also skip this part if it has no ORDER BY clause and\n  ** no temp tables are required.\n  */\n  if( p->selFlags & SF_UsesEphemeral ){\n    int i;                        /* Loop counter */\n    KeyInfo *pKeyInfo;            /* Collating sequence for the result set */\n    Select *pLoop;                /* For looping through SELECT statements */\n    CollSeq **apColl;             /* For looping through pKeyInfo->aColl[] */\n    int nCol;                     /* Number of columns in result set */\n\n    assert( p->pNext==0 );\n    nCol = p->pEList->nExpr;\n    pKeyInfo = sqlite3KeyInfoAlloc(db, nCol, 1);\n    if( !pKeyInfo ){\n      rc = SQLITE_NOMEM_BKPT;\n      goto multi_select_end;\n    }\n    for(i=0, apColl=pKeyInfo->aColl; i<nCol; i++, apColl++){\n      *apColl = multiSelectCollSeq(pParse, p, i);\n      if( 0==*apColl ){\n        *apColl = db->pDfltColl;\n      }\n    }\n\n    for(pLoop=p; pLoop; pLoop=pLoop->pPrior){\n      for(i=0; i<2; i++){\n        int addr = pLoop->addrOpenEphm[i];\n        if( addr<0 ){\n          /* If [0] is unused then [1] is also unused.  So we can\n          ** always safely abort as soon as the first unused slot is found */\n          assert( pLoop->addrOpenEphm[1]<0 );\n          break;\n        }\n        sqlite3VdbeChangeP2(v, addr, nCol);\n        sqlite3VdbeChangeP4(v, addr, (char*)sqlite3KeyInfoRef(pKeyInfo),\n                            P4_KEYINFO);\n        pLoop->addrOpenEphm[i] = -1;\n      }\n    }\n    sqlite3KeyInfoUnref(pKeyInfo);\n  }\n\nmulti_select_end:\n  pDest->iSdst = dest.iSdst;\n  pDest->nSdst = dest.nSdst;\n  sqlite3SelectDelete(db, pDelete);\n  return rc;\n}", "commit_link": "github.com/sqlite/sqlite/commit/8428b3b437569338a9d1e10c4cd8154acbe33089", "file_name": "src/select.c", "vul_type": "cwe-476", "description": "Write a function in C for SQLite that handles the execution of compound SELECT queries with specific handling for UNION, INTERSECT, and EXCEPT operations."}
{"func_name": "concat_hash_string", "func_src_before": "static u_int16_t concat_hash_string(struct ndpi_packet_struct *packet,\n\t\t\t\t   char *buf, u_int8_t client_hash) {\n  u_int16_t offset = 22, buf_out_len = 0;\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  u_int32_t len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4;\n\n  /* -1 for ';' */\n  if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n    goto invalid_payload;\n\n  /* ssh.kex_algorithms [C/S] */\n  strncpy(buf, (const char *)&packet->payload[offset], buf_out_len = len);\n  buf[buf_out_len++] = ';';\n  offset += len;\n\n  /* ssh.server_host_key_algorithms [None] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4 + len;\n\n  /* ssh.encryption_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.encryption_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.mac_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.mac_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_client_to_server [C] */\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.languages_client_to_server [None] */\n\n  /* ssh.languages_server_to_client [None] */\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] %s\\n\", buf);\n#endif\n\n  return(buf_out_len);\n\ninvalid_payload:\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] Invalid packet payload\\n\");\n#endif\n\n  return(0);\n}", "func_src_after": "static u_int16_t concat_hash_string(struct ndpi_packet_struct *packet,\n\t\t\t\t   char *buf, u_int8_t client_hash) {\n  u_int16_t offset = 22, buf_out_len = 0;\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  u_int32_t len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4;\n\n  /* -1 for ';' */\n  if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n    goto invalid_payload;\n\n  /* ssh.kex_algorithms [C/S] */\n  strncpy(buf, (const char *)&packet->payload[offset], buf_out_len = len);\n  buf[buf_out_len++] = ';';\n  offset += len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.server_host_key_algorithms [None] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.encryption_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.encryption_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.mac_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.mac_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_client_to_server [C] */\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.compression_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.languages_client_to_server [None] */\n\n  /* ssh.languages_server_to_client [None] */\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] %s\\n\", buf);\n#endif\n\n  return(buf_out_len);\n\ninvalid_payload:\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] Invalid packet payload\\n\");\n#endif\n\n  return(0);\n}", "commit_link": "github.com/ntop/nDPI/commit/3bbb0cd3296023f6f922c71d21a1c374d2b0a435", "file_name": "src/lib/protocols/ssh.c", "vul_type": "cwe-125", "description": "Write a C function to concatenate SSH protocol fields into a buffer, handling client or server hash conditions."}
{"func_name": "(anonymous)", "func_src_before": "      this.idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            self.$noresults.html('<p>No results matching your query:<code>' + originalQuery + '<code><p>');\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "func_src_after": "      this.idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            self.$noresults.html('<p>No results matching your query:<code>' + $('<div />').text(originalQuery).html() + '<code><p>');\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "line_changes": {"deleted": [{"line_no": 8, "char_start": 247, "char_end": 355, "line": "            self.$noresults.html('<p>No results matching your query:<code>' + originalQuery + '<code><p>');\n"}], "added": [{"line_no": 8, "char_start": 247, "char_end": 381, "line": "            self.$noresults.html('<p>No results matching your query:<code>' + $('<div />').text(originalQuery).html() + '<code><p>');\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 325, "char_end": 343, "chars": "$('<div />').text("}, {"char_start": 356, "char_end": 364, "chars": ").html()"}]}, "commit_link": "github.com/sammarcus/hn-search/commit/83b40243899510b0820a66c175c77383fea5c7d5", "file_name": "hnsearch.beta.js", "vul_type": "cwe-079", "commit_msg": "Fixed XSS :)", "description": "Write a JavaScript function that performs a search with a given query, logs errors to the console, and updates the UI to show whether there are results or not."}
{"func_name": "extend_volume", "func_src_before": "    def extend_volume(self, volume, new_size):\n        LOG.debug(_('enter: extend_volume: volume %s') % volume['id'])\n        ret = self._ensure_vdisk_no_fc_mappings(volume['name'],\n                                                allow_snaps=False)\n        if not ret:\n            exception_message = (_('extend_volume: Extending a volume with '\n                                   'snapshots is not supported.'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        extend_amt = int(new_size) - volume['size']\n        ssh_cmd = ('svctask expandvdisksize -size %(amt)d -unit gb %(name)s'\n                   % {'amt': extend_amt, 'name': volume['name']})\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from expandvdisksize\n        self._assert_ssh_return(len(out.strip()) == 0, 'extend_volume',\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: extend_volume: volume %s') % volume['id'])", "func_src_after": "    def extend_volume(self, volume, new_size):\n        LOG.debug(_('enter: extend_volume: volume %s') % volume['id'])\n        ret = self._ensure_vdisk_no_fc_mappings(volume['name'],\n                                                allow_snaps=False)\n        if not ret:\n            exception_message = (_('extend_volume: Extending a volume with '\n                                   'snapshots is not supported.'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        extend_amt = int(new_size) - volume['size']\n        ssh_cmd = (['svctask', 'expandvdisksize', '-size', str(extend_amt),\n                    '-unit', 'gb', volume['name']])\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from expandvdisksize\n        self._assert_ssh_return(len(out.strip()) == 0, 'extend_volume',\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: extend_volume: volume %s') % volume['id'])", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to increase the size of a storage volume using SSH commands, ensuring no snapshots exist."}
{"func_name": "wiki_handle_http_request", "func_src_before": "wiki_handle_http_request(HttpRequest *req)\n{\n  HttpResponse *res      = http_response_new(req);\n  char         *page     = http_request_get_path_info(req); \n  char         *command  = http_request_get_query_string(req); \n  char         *wikitext = \"\";\n\n  util_dehttpize(page); \t/* remove any encoding on the requested\n\t\t\t\t   page name.                           */\n\n  if (!strcmp(page, \"/\"))\n    {\n      if (access(\"WikiHome\", R_OK) != 0)\n\twiki_redirect(res, \"/WikiHome?create\");\n      page = \"/WikiHome\";\n    }\n\n  if (!strcmp(page, \"/styles.css\"))\n    {\n      /*  Return CSS page */\n      http_response_set_content_type(res, \"text/css\");\n      http_response_printf(res, \"%s\", CssData);\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"/favicon.ico\"))\n    {\n      /*  Return favicon */\n      http_response_set_content_type(res, \"image/ico\");\n      http_response_set_data(res, FaviconData, FaviconDataLen);\n      http_response_send(res);\n      exit(0);\n    }\n\n\n  page = page + 1; \t\t/* skip slash */\n\n  if (!strncmp(page, \"api/\", 4))\n    {\n      char *p;\n\n      page += 4; \n      for (p=page; *p != '\\0'; p++)\n\tif (*p=='?') { *p ='\\0'; break; }\n      \n      wiki_handle_rest_call(req, res, page); \n      exit(0);\n    }\n\n  /* A little safety. issue a malformed request for any paths,\n   * There shouldn't need to be any..\n   */\n  if (strchr(page, '/'))\n    {\n      http_response_set_status(res, 404, \"Not Found\");\n      http_response_printf(res, \"<html><body>404 Not Found</body></html>\\n\");\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"Changes\"))\n    {\n      wiki_show_changes_page(res);\n    }\n  else if (!strcmp(page, \"ChangesRss\"))\n    {\n      wiki_show_changes_page_rss(res);\n    }\n  else if (!strcmp(page, \"Search\"))\n    {\n      wiki_show_search_results_page(res, http_request_param_get(req, \"expr\"));\n    }\n  else if (!strcmp(page, \"Create\"))\n    {\n      if ( (wikitext = http_request_param_get(req, \"title\")) != NULL)\n\t{\n\t  /* create page and redirect */\n\t  wiki_redirect(res, http_request_param_get(req, \"title\"));\n\t}\n      else\n\t{\n\t   /* show create page form  */\n\t  wiki_show_create_page(res);\n\t}\n    }\n  else\n    {\n      /* TODO: dont blindly write wikitext data to disk */\n      if ( (wikitext = http_request_param_get(req, \"wikitext\")) != NULL)\n\t{\n\t  file_write(page, wikitext);\t      \n\t}\n\n      if (access(page, R_OK) == 0) \t/* page exists */\n\t{\n\t  wikitext = file_read(page);\n\t  \n\t  if (!strcmp(command, \"edit\"))\n\t    {\n\t      /* print edit page */\n\t      wiki_show_edit_page(res, wikitext, page);\n\t    }\n\t  else\n\t    {\n\t      wiki_show_page(res, wikitext, page);\n\t    }\n\t}\n      else\n\t{\n\t  if (!strcmp(command, \"create\"))\n\t    {\n\t      wiki_show_edit_page(res, NULL, page);\n\t    }\n\t  else\n\t    {\n\t      char buf[1024];\n\t      snprintf(buf, 1024, \"%s?create\", page);\n\t      wiki_redirect(res, buf);\n\t    }\n\t}\n    }\n\n}", "func_src_after": "wiki_handle_http_request(HttpRequest *req)\n{\n  HttpResponse *res      = http_response_new(req);\n  char         *page     = http_request_get_path_info(req); \n  char         *command  = http_request_get_query_string(req); \n  char         *wikitext = \"\";\n\n  util_dehttpize(page); \t/* remove any encoding on the requested\n\t\t\t\t   page name.                           */\n\n  if (!strcmp(page, \"/\"))\n    {\n      if (access(\"WikiHome\", R_OK) != 0)\n\twiki_redirect(res, \"/WikiHome?create\");\n      page = \"/WikiHome\";\n    }\n\n  if (!strcmp(page, \"/styles.css\"))\n    {\n      /*  Return CSS page */\n      http_response_set_content_type(res, \"text/css\");\n      http_response_printf(res, \"%s\", CssData);\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"/favicon.ico\"))\n    {\n      /*  Return favicon */\n      http_response_set_content_type(res, \"image/ico\");\n      http_response_set_data(res, FaviconData, FaviconDataLen);\n      http_response_send(res);\n      exit(0);\n    }\n\n\n  page = page + 1; \t\t/* skip slash */\n\n  if (!strncmp(page, \"api/\", 4))\n    {\n      char *p;\n\n      page += 4; \n      for (p=page; *p != '\\0'; p++)\n\tif (*p=='?') { *p ='\\0'; break; }\n      \n      wiki_handle_rest_call(req, res, page); \n      exit(0);\n    }\n\n  /* A little safety. issue a malformed request for any paths,\n   * There shouldn't need to be any..\n   */\n  if (!page_name_is_good(page))\n    {\n      http_response_set_status(res, 404, \"Not Found\");\n      http_response_printf(res, \"<html><body>404 Not Found</body></html>\\n\");\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"Changes\"))\n    {\n      wiki_show_changes_page(res);\n    }\n  else if (!strcmp(page, \"ChangesRss\"))\n    {\n      wiki_show_changes_page_rss(res);\n    }\n  else if (!strcmp(page, \"Search\"))\n    {\n      wiki_show_search_results_page(res, http_request_param_get(req, \"expr\"));\n    }\n  else if (!strcmp(page, \"Create\"))\n    {\n      if ( (wikitext = http_request_param_get(req, \"title\")) != NULL)\n\t{\n\t  /* create page and redirect */\n\t  wiki_redirect(res, http_request_param_get(req, \"title\"));\n\t}\n      else\n\t{\n\t   /* show create page form  */\n\t  wiki_show_create_page(res);\n\t}\n    }\n  else\n    {\n      /* TODO: dont blindly write wikitext data to disk */\n      if ( (wikitext = http_request_param_get(req, \"wikitext\")) != NULL)\n\t{\n\t  file_write(page, wikitext);\t      \n\t}\n\n      if (access(page, R_OK) == 0) \t/* page exists */\n\t{\n\t  wikitext = file_read(page);\n\t  \n\t  if (!strcmp(command, \"edit\"))\n\t    {\n\t      /* print edit page */\n\t      wiki_show_edit_page(res, wikitext, page);\n\t    }\n\t  else\n\t    {\n\t      wiki_show_page(res, wikitext, page);\n\t    }\n\t}\n      else\n\t{\n\t  if (!strcmp(command, \"create\"))\n\t    {\n\t      wiki_show_edit_page(res, NULL, page);\n\t    }\n\t  else\n\t    {\n\t      char buf[1024];\n\t      snprintf(buf, 1024, \"%s?create\", page);\n\t      wiki_redirect(res, buf);\n\t    }\n\t}\n    }\n\n}", "commit_link": "github.com/yarolig/didiwiki/commit/5e5c796617e1712905dc5462b94bd5e6c08d15ea", "file_name": "src/wiki.c", "vul_type": "cwe-022", "description": "In C, write a function to handle HTTP requests for a simple wiki, including serving static files, API calls, and wiki page creation or editing."}
{"func_name": "ExtractPostscript", "func_src_before": "static Image *ExtractPostscript(Image *image,const ImageInfo *image_info,\n  MagickOffsetType PS_Offset,ssize_t PS_Size,ExceptionInfo *exception)\n{\n  char\n    postscript_file[MaxTextExtent];\n\n  const MagicInfo\n    *magic_info;\n\n  FILE\n    *ps_file;\n\n  ImageInfo\n    *clone_info;\n\n  Image\n    *image2;\n\n  unsigned char\n    magick[2*MaxTextExtent];\n\n\n  if ((clone_info=CloneImageInfo(image_info)) == NULL)\n    return(image);\n  clone_info->blob=(void *) NULL;\n  clone_info->length=0;\n\n  /* Obtain temporary file */\n  (void) AcquireUniqueFilename(postscript_file);\n  ps_file=fopen_utf8(postscript_file,\"wb\");\n  if (ps_file == (FILE *) NULL)\n    goto FINISH;\n\n  /* Copy postscript to temporary file */\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  (void) ReadBlob(image, 2*MaxTextExtent, magick);\n\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  while(PS_Size-- > 0)\n    {\n      (void) fputc(ReadBlobByte(image),ps_file);\n    }\n  (void) fclose(ps_file);\n\n    /* Detect file format - Check magic.mgk configuration file. */\n  magic_info=GetMagicInfo(magick,2*MaxTextExtent,exception);\n  if(magic_info == (const MagicInfo *) NULL) goto FINISH_UNL;\n  /*     printf(\"Detected:%s  \\n\",magic_info->name); */\n  if(exception->severity != UndefinedException) goto FINISH_UNL;\n  if(magic_info->name == (char *) NULL) goto FINISH_UNL;\n\n  (void) CopyMagickMemory(clone_info->magick,magic_info->name,MaxTextExtent);\n\n    /* Read nested image */\n  /*FormatString(clone_info->filename,\"%s:%s\",magic_info->name,postscript_file);*/\n  FormatLocaleString(clone_info->filename,MaxTextExtent,\"%s\",postscript_file);\n  image2=ReadImage(clone_info,exception);\n\n  if (!image2)\n    goto FINISH_UNL;\n\n  /*\n    Replace current image with new image while copying base image\n    attributes.\n  */\n  (void) CopyMagickMemory(image2->filename,image->filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick_filename,image->magick_filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick,image->magick,MaxTextExtent);\n  image2->depth=image->depth;\n  DestroyBlob(image2);\n  image2->blob=ReferenceBlob(image->blob);\n\n  if ((image->rows == 0) || (image->columns == 0))\n    DeleteImageFromList(&image);\n\n  AppendImageToList(&image,image2);\n\n FINISH_UNL:\n  (void) RelinquishUniqueFileResource(postscript_file);\n FINISH:\n  DestroyImageInfo(clone_info);\n  return(image);\n}", "func_src_after": "static Image *ExtractPostscript(Image *image,const ImageInfo *image_info,\n  MagickOffsetType PS_Offset,ssize_t PS_Size,ExceptionInfo *exception)\n{\n  char\n    postscript_file[MaxTextExtent];\n\n  const MagicInfo\n    *magic_info;\n\n  FILE\n    *ps_file;\n\n  ImageInfo\n    *clone_info;\n\n  Image\n    *image2;\n\n  unsigned char\n    magick[2*MaxTextExtent];\n\n\n  if ((clone_info=CloneImageInfo(image_info)) == NULL)\n    return(image);\n  clone_info->blob=(void *) NULL;\n  clone_info->length=0;\n\n  /* Obtain temporary file */\n  (void) AcquireUniqueFilename(postscript_file);\n  ps_file=fopen_utf8(postscript_file,\"wb\");\n  if (ps_file == (FILE *) NULL)\n    goto FINISH;\n\n  /* Copy postscript to temporary file */\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  (void) ReadBlob(image, 2*MaxTextExtent, magick);\n\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  while(PS_Size-- > 0)\n    {\n      (void) fputc(ReadBlobByte(image),ps_file);\n    }\n  (void) fclose(ps_file);\n\n    /* Detect file format - Check magic.mgk configuration file. */\n  magic_info=GetMagicInfo(magick,2*MaxTextExtent,exception);\n  if(magic_info == (const MagicInfo *) NULL) goto FINISH_UNL;\n  /*     printf(\"Detected:%s  \\n\",magic_info->name); */\n  if(exception->severity != UndefinedException) goto FINISH_UNL;\n  if(magic_info->name == (char *) NULL) goto FINISH_UNL;\n\n  (void) strncpy(clone_info->magick,magic_info->name,MaxTextExtent);\n\n    /* Read nested image */\n  /*FormatString(clone_info->filename,\"%s:%s\",magic_info->name,postscript_file);*/\n  FormatLocaleString(clone_info->filename,MaxTextExtent,\"%s\",postscript_file);\n  image2=ReadImage(clone_info,exception);\n\n  if (!image2)\n    goto FINISH_UNL;\n\n  /*\n    Replace current image with new image while copying base image\n    attributes.\n  */\n  (void) CopyMagickMemory(image2->filename,image->filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick_filename,image->magick_filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick,image->magick,MaxTextExtent);\n  image2->depth=image->depth;\n  DestroyBlob(image2);\n  image2->blob=ReferenceBlob(image->blob);\n\n  if ((image->rows == 0) || (image->columns == 0))\n    DeleteImageFromList(&image);\n\n  AppendImageToList(&image,image2);\n\n FINISH_UNL:\n  (void) RelinquishUniqueFileResource(postscript_file);\n FINISH:\n  DestroyImageInfo(clone_info);\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/a251039393f423c7858e63cab6aa98d17b8b7a41", "file_name": "coders/wpg.c", "vul_type": "cwe-125", "description": "Write a C function to extract a Postscript section from an image and read it into a new image structure."}
{"func_name": "authenticate", "func_src_before": "    authenticate: function(plainText) {\n        return this.encryptPassword(plainText) === this.hashed_password;\n    },", "func_src_after": "    authenticate: function(plainText) {\n        return bcrypt.compareSync(plainText,this.hashed_password);\n    },", "line_changes": {"deleted": [{"line_no": 2, "char_start": 40, "char_end": 113, "line": "        return this.encryptPassword(plainText) === this.hashed_password;\n"}, {"line_no": 3, "char_start": 113, "char_end": 119, "line": "    },\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 55, "char_end": 75, "chars": "this.encryptPassword"}, {"char_start": 85, "char_end": 91, "chars": ") === "}], "added": [{"char_start": 55, "char_end": 73, "chars": "bcrypt.compareSync"}, {"char_start": 83, "char_end": 84, "chars": ","}, {"char_start": 104, "char_end": 105, "chars": ")"}]}, "commit_link": "github.com/aburchette/territory-manager-mean/commit/24620016541089cc0ca316a0dec32ee0db864d98", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Replaced SHA1 password hashing with more bcrypt", "parent_commit": "f944f0a464555f033f01413f24d1cd47ab412ae7", "description": "Write a JavaScript function named `authenticate` that checks if a plain text password matches a stored hashed password."}
{"func_name": "pref_set", "func_src_before": "@app.route(\"/api/preferences/set/<key>/<value>\")\ndef pref_set(key, value):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    get_preferences()[key] = (None if value == 'null' else value)\n    return Response(json.dumps({'key': key, 'success': ''})), 201", "func_src_after": "@app.route(\"/api/preferences/set/<key>/<value>\")\ndef pref_set(key, value):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    get_preferences()[key] = (None if value == 'null' else value)\n    return Response(\n        json.dumps({'key': key, 'success': ''}),\n        mimetype='application/json'\n    ), 201", "line_changes": {"deleted": [{"line_no": 7, "char_start": 215, "char_end": 280, "line": "    return Response(json.dumps({'key': key, 'success': ''})), 201\n"}], "added": [{"line_no": 7, "char_start": 215, "char_end": 236, "line": "    return Response(\n"}, {"line_no": 8, "char_start": 236, "char_end": 285, "line": "        json.dumps({'key': key, 'success': ''}),\n"}, {"line_no": 9, "char_start": 285, "char_end": 321, "line": "        mimetype='application/json'\n"}, {"line_no": 10, "char_start": 321, "char_end": 331, "line": "    ), 201\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 235, "char_end": 244, "chars": "\n        "}, {"char_start": 283, "char_end": 325, "chars": ",\n        mimetype='application/json'\n    "}]}, "commit_link": "github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "file_name": "app.py", "vul_type": "cwe-079", "commit_msg": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "description": "Write a Python Flask endpoint to set a user preference given a key and value, returning JSON and requiring user authentication."}
{"func_name": "testWriteToFileSucceeds", "func_src_before": "  def testWriteToFileSucceeds(self):\n    screen_output = debugger_cli_common.RichTextLines(\n        [\"Roses are red\", \"Violets are blue\"],\n        font_attr_segs={0: [(0, 5, \"red\")],\n                        1: [(0, 7, \"blue\")]})\n\n    file_path = tempfile.mktemp()\n    screen_output.write_to_file(file_path)\n\n    with gfile.Open(file_path, \"r\") as f:\n      self.assertEqual(\"Roses are red\\nViolets are blue\\n\", f.read())\n\n    # Clean up.\n    gfile.Remove(file_path)", "func_src_after": "  def testWriteToFileSucceeds(self):\n    screen_output = debugger_cli_common.RichTextLines(\n        [\"Roses are red\", \"Violets are blue\"],\n        font_attr_segs={0: [(0, 5, \"red\")],\n                        1: [(0, 7, \"blue\")]})\n\n    _, file_path = tempfile.mkstemp()  # safe to ignore fd here\n    screen_output.write_to_file(file_path)\n\n    with gfile.Open(file_path, \"r\") as f:\n      self.assertEqual(\"Roses are red\\nViolets are blue\\n\", f.read())\n\n    # Clean up.\n    gfile.Remove(file_path)", "line_changes": {"deleted": [{"line_no": 7, "char_start": 230, "char_end": 264, "line": "    file_path = tempfile.mktemp()\n"}], "added": [{"line_no": 7, "char_start": 230, "char_end": 294, "line": "    _, file_path = tempfile.mkstemp()  # safe to ignore fd here\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 233, "char_end": 236, "chars": " _,"}, {"char_start": 260, "char_end": 261, "chars": "s"}, {"char_start": 267, "char_end": 293, "chars": "  # safe to ignore fd here"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/ca5fe92b42a64b371b963d83b2da4f074e83280c", "file_name": "debugger_cli_common_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359120\nChange-Id: Ifb43401b1fd3e023c685dc3a74b3b655090e1ce6", "description": "Write a Python function that tests writing predefined text to a temporary file and then reads it back to verify the content."}
{"func_name": "like", "func_src_before": "@mod.route('/like/<int:msg_id>', methods=['GET', 'POST'])\ndef like(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        sql = \"INSERT INTO like_msg(msg_id, user_id,c_time) \" + \\\n                \"VALUES(%d,'%s','%s');\" % (msg_id, user_id, c_time)\n        cursor.execute(sql)\n        conn.commit()\n    return redirect(url_for('show_entries'))", "func_src_after": "@mod.route('/like/<int:msg_id>', methods=['GET', 'POST'])\ndef like(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        cursor.execute(\"INSERT INTO like_msg(msg_id, user_id,c_time) VALUES(%s,%s,%s);\", (msg_id, user_id, c_time))\n        conn.commit()\n    return redirect(url_for('show_entries'))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/like_msg.py", "vul_type": "cwe-089", "description": "Create a Flask route in Python that handles a 'like' action for a message by inserting a record into a database and then redirects to a page showing entries."}
{"func_name": "self.open", "func_src_before": "    def self.open(path_or_url, ext = nil, options = {})\n      options, ext = ext, nil if ext.is_a?(Hash)\n\n      ext ||=\n        if File.exist?(path_or_url)\n          File.extname(path_or_url)\n        else\n          File.extname(URI(path_or_url).path)\n        end\n\n      ext.sub!(/:.*/, '') # hack for filenames or URLs that include a colon\n\n      Kernel.open(path_or_url, \"rb\", options) do |file|\n        read(file, ext)\n      end\n    end", "func_src_after": "    def self.open(path_or_url, ext = nil, options = {})\n      options, ext = ext, nil if ext.is_a?(Hash)\n\n      uri = URI(path_or_url.to_s)\n\n      ext ||= File.extname(uri.path)\n      ext.sub!(/:.*/, '') # hack for filenames or URLs that include a colon\n\n      if uri.is_a?(URI::HTTP) || uri.is_a?(URI::FTP)\n        uri.open(options) { |file| read(file, ext) }\n      else\n        File.open(uri.to_s, \"rb\", options) { |file| read(file, ext) }\n      end\n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 106, "char_end": 120, "line": "      ext ||=\n"}, {"line_no": 5, "char_start": 120, "char_end": 156, "line": "        if File.exist?(path_or_url)\n"}, {"line_no": 6, "char_start": 156, "char_end": 192, "line": "          File.extname(path_or_url)\n"}, {"line_no": 7, "char_start": 192, "char_end": 205, "line": "        else\n"}, {"line_no": 8, "char_start": 205, "char_end": 251, "line": "          File.extname(URI(path_or_url).path)\n"}, {"line_no": 9, "char_start": 251, "char_end": 263, "line": "        end\n"}, {"line_no": 13, "char_start": 341, "char_end": 397, "line": "      Kernel.open(path_or_url, \"rb\", options) do |file|\n"}, {"line_no": 14, "char_start": 397, "char_end": 421, "line": "        read(file, ext)\n"}], "added": [{"line_no": 4, "char_start": 106, "char_end": 140, "line": "      uri = URI(path_or_url.to_s)\n"}, {"line_no": 6, "char_start": 141, "char_end": 178, "line": "      ext ||= File.extname(uri.path)\n"}, {"line_no": 9, "char_start": 255, "char_end": 308, "line": "      if uri.is_a?(URI::HTTP) || uri.is_a?(URI::FTP)\n"}, {"line_no": 10, "char_start": 308, "char_end": 361, "line": "        uri.open(options) { |file| read(file, ext) }\n"}, {"line_no": 11, "char_start": 361, "char_end": 372, "line": "      else\n"}, {"line_no": 12, "char_start": 372, "char_end": 442, "line": "        File.open(uri.to_s, \"rb\", options) { |file| read(file, ext) }\n"}]}, "char_changes": {"deleted": [{"char_start": 112, "char_end": 370, "chars": "ext ||=\n        if File.exist?(path_or_url)\n          File.extname(path_or_url)\n        else\n          File.extname(URI(path_or_url).path)\n        end\n\n      ext.sub!(/:.*/, '') # hack for filenames or URLs that include a colon\n\n      Kernel.open(path_or_url"}, {"char_start": 387, "char_end": 389, "chars": "do"}, {"char_start": 396, "char_end": 404, "chars": "\n       "}], "added": [{"char_start": 112, "char_end": 398, "chars": "uri = URI(path_or_url.to_s)\n\n      ext ||= File.extname(uri.path)\n      ext.sub!(/:.*/, '') # hack for filenames or URLs that include a colon\n\n      if uri.is_a?(URI::HTTP) || uri.is_a?(URI::FTP)\n        uri.open(options) { |file| read(file, ext) }\n      else\n        File.open(uri.to_s"}, {"char_start": 415, "char_end": 416, "chars": "{"}, {"char_start": 439, "char_end": 441, "chars": " }"}]}, "commit_link": "github.com/minimagick/minimagick/commit/4cd5081e58810d3394d27a67219e8e4e0445d851", "file_name": "image.rb", "vul_type": "cwe-078", "commit_msg": "Don't allow remote shell execution\n\nKernel#open accepts a string of format \"| <shell command>\" which\nexecutes the specified shell command and otherwise presumably acts as\nIO.popen. The open-uri standard library overrides Kernel#open to also\naccept URLs.\n\nHowever, the overridden Kernel#open just delegates to URI#open, so we\nswitch to using that directly and avoid the remote shell execution\nvulnerability. For files we just use File.open, which should have the\nsame behaviour as Kernel#open.", "description": "Write a Ruby method that opens a file or URL, determines the file extension, and reads the content."}
{"func_name": "mapi_attr_read", "func_src_before": "mapi_attr_read (size_t len, unsigned char *buf)\n{\n    size_t idx = 0;\n    uint32 i,j;\n    assert(len > 4);\n    uint32 num_properties = GETINT32(buf+idx);\n    MAPI_Attr** attrs = CHECKED_XMALLOC (MAPI_Attr*, (num_properties + 1));\n\n    idx += 4;\n\n    if (!attrs) return NULL;\n    for (i = 0; i < num_properties; i++)\n    {\n\tMAPI_Attr* a = attrs[i] = CHECKED_XCALLOC(MAPI_Attr, 1);\n\tMAPI_Value* v = NULL;\n\n\tCHECKINT16(idx, len); a->type = GETINT16(buf+idx); idx += 2;\n\tCHECKINT16(idx, len); a->name = GETINT16(buf+idx); idx += 2;\n\n\t/* handle special case of GUID prefixed properties */\n\tif (a->name & GUID_EXISTS_FLAG)\n\t{\n\t    /* copy GUID */\n\t    a->guid = CHECKED_XMALLOC(GUID, 1);\n\t    copy_guid_from_buf(a->guid, buf+idx, len);\n\t    idx += sizeof (GUID);\n\n\t    CHECKINT32(idx, len); a->num_names = GETINT32(buf+idx); idx += 4;\n\t    if (a->num_names > 0)\n\t    {\n\t\t/* FIXME: do something useful here! */\n\t\tsize_t i;\n\n\t\ta->names = CHECKED_XCALLOC(VarLenData, a->num_names);\n\n\t\tfor (i = 0; i < a->num_names; i++)\n\t\t{\n\t\t    size_t j;\n\n\t\t    CHECKINT32(idx, len); a->names[i].len = GETINT32(buf+idx); idx += 4;\n\n\t\t    /* read the data into a buffer */\n\t\t    a->names[i].data \n\t\t\t= CHECKED_XMALLOC(unsigned char, a->names[i].len);\n\t\t    for (j = 0; j < (a->names[i].len >> 1); j++)\n\t\t\ta->names[i].data[j] = (buf+idx)[j*2];\n\n\t\t    /* But what are we going to do with it? */\n\t\t    \n\t\t    idx += pad_to_4byte(a->names[i].len);\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t/* get the 'real' name */\n\t\tCHECKINT32(idx, len); a->name = GETINT32(buf+idx); idx+= 4;\n\t    }\n\t}\n\n\t/* \n\t * Multi-value types and string/object/binary types have\n\t * multiple values \n\t */\n\tif (a->type & MULTI_VALUE_FLAG ||\n\t    a->type == szMAPI_STRING ||\n\t    a->type == szMAPI_UNICODE_STRING ||\n\t    a->type == szMAPI_OBJECT ||\n\t    a->type == szMAPI_BINARY)\n\t{\n\t    CHECKINT32(idx, len); a->num_values = GETINT32(buf+idx);\n\t    idx += 4;\n\t}\n        else\n        {\n\t    a->num_values = 1;\n        }\n\n\t/* Amend the type in case of multi-value type */\n\tif (a->type & MULTI_VALUE_FLAG)\n\t{\n\t    a->type -= MULTI_VALUE_FLAG;\n\t}\n\n\n\tv = alloc_mapi_values (a);\n\n\tfor (j = 0; j < a->num_values; j++) \n\t{\n\t    switch (a->type)\n\t    {\n\t    case szMAPI_SHORT:\t/* 2 bytes */\n\t\tv->len = 2;\n\t\tCHECKINT16(idx, len); v->data.bytes2 = GETINT16(buf+idx);\n\t\tidx += 4;\t/* assume padding of 2, advance by 4! */\n\t\tbreak;\n\n\t    case szMAPI_INT:\t/* 4 bytes */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += 4;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_FLOAT:\t/* 4 bytes */\n\t    case szMAPI_BOOLEAN: /* this should be 2 bytes + 2 padding */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_SYSTIME: /* 8 bytes */\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += 8;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_DOUBLE:\t/* 8 bytes */\n\t    case szMAPI_APPTIME:\n\t    case szMAPI_CURRENCY:\n\t    case szMAPI_INT8BYTE:\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_CLSID:\n\t\tv->len = sizeof (GUID);\n\t\tcopy_guid_from_buf(&v->data.guid, buf+idx, len);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_STRING:\n\t    case szMAPI_UNICODE_STRING:\n\t    case szMAPI_OBJECT:\n\t    case szMAPI_BINARY:\n\t\tCHECKINT32(idx, len); v->len = GETINT32(buf+idx); idx += 4;\n\n\t\tif (a->type == szMAPI_UNICODE_STRING)\n\t\t{\n\t\t    v->data.buf = (unsigned char*)unicode_to_utf8(v->len, buf+idx);\n\t\t}\n\t\telse\n\t\t{\n\t\t    v->data.buf = CHECKED_XMALLOC(unsigned char, v->len);\n\t\t    memmove (v->data.buf, buf+idx, v->len);\n\t\t}\n\n\t\tidx += pad_to_4byte(v->len);\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_NULL:\t/* illegal in input tnef streams */\n\t    case szMAPI_ERROR:\n\t    case szMAPI_UNSPECIFIED:\n\t\tfprintf (stderr,\n\t\t\t \"Invalid attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    default:\t\t/* should never get here */\n\t\tfprintf (stderr,\n\t\t\t \"Undefined attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    }\n\t    if (DEBUG_ON) mapi_attr_dump (attrs[i]);\n\t}\n    }\n    attrs[i] = NULL;\n\n    return attrs;\n}", "func_src_after": "mapi_attr_read (size_t len, unsigned char *buf)\n{\n    size_t idx = 0;\n    uint32 i,j;\n    assert(len > 4);\n    uint32 num_properties = GETINT32(buf+idx);\n    assert((num_properties+1) != 0);\n    MAPI_Attr** attrs = CHECKED_XMALLOC (MAPI_Attr*, (num_properties + 1));\n\n    idx += 4;\n\n    if (!attrs) return NULL;\n    for (i = 0; i < num_properties; i++)\n    {\n\tMAPI_Attr* a = attrs[i] = CHECKED_XCALLOC(MAPI_Attr, 1);\n\tMAPI_Value* v = NULL;\n\n\tCHECKINT16(idx, len); a->type = GETINT16(buf+idx); idx += 2;\n\tCHECKINT16(idx, len); a->name = GETINT16(buf+idx); idx += 2;\n\n\t/* handle special case of GUID prefixed properties */\n\tif (a->name & GUID_EXISTS_FLAG)\n\t{\n\t    /* copy GUID */\n\t    a->guid = CHECKED_XMALLOC(GUID, 1);\n\t    copy_guid_from_buf(a->guid, buf+idx, len);\n\t    idx += sizeof (GUID);\n\n\t    CHECKINT32(idx, len); a->num_names = GETINT32(buf+idx); idx += 4;\n\t    if (a->num_names > 0)\n\t    {\n\t\t/* FIXME: do something useful here! */\n\t\tsize_t i;\n\n\t\ta->names = CHECKED_XCALLOC(VarLenData, a->num_names);\n\n\t\tfor (i = 0; i < a->num_names; i++)\n\t\t{\n\t\t    size_t j;\n\n\t\t    CHECKINT32(idx, len); a->names[i].len = GETINT32(buf+idx); idx += 4;\n\n\t\t    /* read the data into a buffer */\n\t\t    a->names[i].data \n\t\t\t= CHECKED_XMALLOC(unsigned char, a->names[i].len);\n\t\t    assert((idx+(a->names[i].len*2)) <= len);\n\t\t    for (j = 0; j < (a->names[i].len >> 1); j++)\n\t\t\ta->names[i].data[j] = (buf+idx)[j*2];\n\n\t\t    /* But what are we going to do with it? */\n\t\t    \n\t\t    idx += pad_to_4byte(a->names[i].len);\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t/* get the 'real' name */\n\t\tCHECKINT32(idx, len); a->name = GETINT32(buf+idx); idx+= 4;\n\t    }\n\t}\n\n\t/* \n\t * Multi-value types and string/object/binary types have\n\t * multiple values \n\t */\n\tif (a->type & MULTI_VALUE_FLAG ||\n\t    a->type == szMAPI_STRING ||\n\t    a->type == szMAPI_UNICODE_STRING ||\n\t    a->type == szMAPI_OBJECT ||\n\t    a->type == szMAPI_BINARY)\n\t{\n\t    CHECKINT32(idx, len); a->num_values = GETINT32(buf+idx);\n\t    idx += 4;\n\t}\n        else\n        {\n\t    a->num_values = 1;\n        }\n\n\t/* Amend the type in case of multi-value type */\n\tif (a->type & MULTI_VALUE_FLAG)\n\t{\n\t    a->type -= MULTI_VALUE_FLAG;\n\t}\n\n\n\tv = alloc_mapi_values (a);\n\n\tfor (j = 0; j < a->num_values; j++) \n\t{\n\t    switch (a->type)\n\t    {\n\t    case szMAPI_SHORT:\t/* 2 bytes */\n\t\tv->len = 2;\n\t\tCHECKINT16(idx, len); v->data.bytes2 = GETINT16(buf+idx);\n\t\tidx += 4;\t/* assume padding of 2, advance by 4! */\n\t\tbreak;\n\n\t    case szMAPI_INT:\t/* 4 bytes */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += 4;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_FLOAT:\t/* 4 bytes */\n\t    case szMAPI_BOOLEAN: /* this should be 2 bytes + 2 padding */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_SYSTIME: /* 8 bytes */\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += 8;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_DOUBLE:\t/* 8 bytes */\n\t    case szMAPI_APPTIME:\n\t    case szMAPI_CURRENCY:\n\t    case szMAPI_INT8BYTE:\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_CLSID:\n\t\tv->len = sizeof (GUID);\n\t\tcopy_guid_from_buf(&v->data.guid, buf+idx, len);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_STRING:\n\t    case szMAPI_UNICODE_STRING:\n\t    case szMAPI_OBJECT:\n\t    case szMAPI_BINARY:\n\t\tCHECKINT32(idx, len); v->len = GETINT32(buf+idx); idx += 4;\n\n\t\tassert(v->len + idx <= len);\n\n\t\tif (a->type == szMAPI_UNICODE_STRING)\n\t\t{\n\t\t    assert(v->len != 0);\n\t\t    v->data.buf = (unsigned char*)unicode_to_utf8(v->len, buf+idx);\n\t\t}\n\t\telse\n\t\t{\n\t\t    v->data.buf = CHECKED_XMALLOC(unsigned char, v->len);\n\t\t    memmove (v->data.buf, buf+idx, v->len);\n\t\t}\n\n\t\tidx += pad_to_4byte(v->len);\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_NULL:\t/* illegal in input tnef streams */\n\t    case szMAPI_ERROR:\n\t    case szMAPI_UNSPECIFIED:\n\t\tfprintf (stderr,\n\t\t\t \"Invalid attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    default:\t\t/* should never get here */\n\t\tfprintf (stderr,\n\t\t\t \"Undefined attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    }\n\t    if (DEBUG_ON) mapi_attr_dump (attrs[i]);\n\t}\n    }\n    attrs[i] = NULL;\n\n    return attrs;\n}", "commit_link": "github.com/verdammelt/tnef/commit/1a17af1ed0c791aec44dbdc9eab91218cc1e335a", "file_name": "src/mapi_attr.c", "vul_type": "cwe-787", "description": "Write a C function named `mapi_attr_read` that parses MAPI attributes from a buffer."}
{"func_name": "(anonymous)", "func_src_before": "process.on('uncaughtException',function(e){\n\tconsole.error(e);\n\tconsole.trace(e.stack);\n});", "func_src_after": "process.on('uncaughtException',function(e){\n\tconsole.error(e);\n\tconsole.trace(e.stack);\n});", "line_changes": {"deleted": [{"line_no": 4, "char_start": 88, "char_end": 91, "line": "});\n"}], "added": []}, "char_changes": {"deleted": [], "added": []}, "commit_link": "github.com/Eeems/PooledWebSocket/commit/7b3b4e5c6be6d8a964296fa3c50e38dc07e9701d", "file_name": "server.js", "vul_type": "cwe-022", "commit_msg": "Update server.js\n\nResolve directory traversal attack", "description": "Write a Node.js code snippet that logs an error and its stack trace when an uncaught exception occurs."}
{"func_name": "dex_loadcode", "func_src_before": "static int dex_loadcode(RBinFile *arch, RBinDexObj *bin) {\n\tstruct r_bin_t *rbin = arch->rbin;\n\tint i;\n\tint *methods = NULL;\n\tint sym_count = 0;\n\n\t// doublecheck??\n\tif (!bin || bin->methods_list) {\n\t\treturn false;\n\t}\n\tbin->code_from = UT64_MAX;\n\tbin->code_to = 0;\n\tbin->methods_list = r_list_newf ((RListFree)free);\n\tif (!bin->methods_list) {\n\t\treturn false;\n\t}\n\tbin->imports_list = r_list_newf ((RListFree)free);\n\tif (!bin->imports_list) {\n\t\tr_list_free (bin->methods_list);\n\t\treturn false;\n\t}\n\tbin->classes_list = r_list_newf ((RListFree)__r_bin_class_free);\n\tif (!bin->classes_list) {\n\t\tr_list_free (bin->methods_list);\n\t\tr_list_free (bin->imports_list);\n\t\treturn false;\n\t}\n\n\tif (bin->header.method_size>bin->size) {\n\t\tbin->header.method_size = 0;\n\t\treturn false;\n\t}\n\n\t/* WrapDown the header sizes to avoid huge allocations */\n\tbin->header.method_size = R_MIN (bin->header.method_size, bin->size);\n\tbin->header.class_size = R_MIN (bin->header.class_size, bin->size);\n\tbin->header.strings_size = R_MIN (bin->header.strings_size, bin->size);\n\n\t// TODO: is this posible after R_MIN ??\n\tif (bin->header.strings_size > bin->size) {\n\t\teprintf (\"Invalid strings size\\n\");\n\t\treturn false;\n\t}\n\n\tif (bin->classes) {\n\t\tut64 amount = sizeof (int) * bin->header.method_size;\n\t\tif (amount > UT32_MAX || amount < bin->header.method_size) {\n\t\t\treturn false;\n\t\t}\n\t\tmethods = calloc (1, amount + 1);\n\t\tfor (i = 0; i < bin->header.class_size; i++) {\n\t\t\tchar *super_name, *class_name;\n\t\t\tstruct dex_class_t *c = &bin->classes[i];\n\t\t\tclass_name = dex_class_name (bin, c);\n\t\t\tsuper_name = dex_class_super_name (bin, c);\n\t\t\tif (dexdump) { \n\t\t\t\trbin->cb_printf (\"Class #%d            -\\n\", i);\n\t\t\t}\n\t\t\tparse_class (arch, bin, c, i, methods, &sym_count);\n\t\t\tfree (class_name);\n\t\t\tfree (super_name);\n\t\t}\n\t}\n\n\tif (methods) {\n\t\tint import_count = 0;\n\t\tint sym_count = bin->methods_list->length;\n\n\t\tfor (i = 0; i < bin->header.method_size; i++) {\n\t\t\tint len = 0;\n\t\t\tif (methods[i]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (bin->methods[i].class_id > bin->header.types_size - 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (is_class_idx_in_code_classes(bin, bin->methods[i].class_id)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tchar *class_name = getstr (\n\t\t\t\tbin, bin->types[bin->methods[i].class_id]\n\t\t\t\t\t\t.descriptor_id);\n\t\t\tif (!class_name) {\n\t\t\t\tfree (class_name);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tlen = strlen (class_name);\n\t\t\tif (len < 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tclass_name[len - 1] = 0; // remove last char \";\"\n\t\t\tchar *method_name = dex_method_name (bin, i);\n\t\t\tchar *signature = dex_method_signature (bin, i);\n\t\t\tif (method_name && *method_name) {\n\t\t\t\tRBinImport *imp = R_NEW0 (RBinImport);\n\t\t\t\timp->name  = r_str_newf (\"%s.method.%s%s\", class_name, method_name, signature);\n\t\t\t\timp->type = r_str_const (\"FUNC\");\n\t\t\t\timp->bind = r_str_const (\"NONE\");\n\t\t\t\timp->ordinal = import_count++;\n\t\t\t\tr_list_append (bin->imports_list, imp);\n\n\t\t\t\tRBinSymbol *sym = R_NEW0 (RBinSymbol);\n\t\t\t\tsym->name = r_str_newf (\"imp.%s\", imp->name);\n\t\t\t\tsym->type = r_str_const (\"FUNC\");\n\t\t\t\tsym->bind = r_str_const (\"NONE\");\n\t\t\t\t//XXX so damn unsafe check buffer boundaries!!!!\n\t\t\t\t//XXX use r_buf API!!\n\t\t\t\tsym->paddr = sym->vaddr = bin->b->base + bin->header.method_offset + (sizeof (struct dex_method_t) * i) ;\n\t\t\t\tsym->ordinal = sym_count++;\n\t\t\t\tr_list_append (bin->methods_list, sym);\n\t\t\t\tsdb_num_set (mdb, sdb_fmt (0, \"method.%d\", i), sym->paddr, 0);\n\t\t\t}\n\t\t\tfree (method_name);\n\t\t\tfree (signature);\n\t\t\tfree (class_name);\n\t\t}\n\t\tfree (methods);\n\t}\n\treturn true;\n}", "func_src_after": "static int dex_loadcode(RBinFile *arch, RBinDexObj *bin) {\n\tstruct r_bin_t *rbin = arch->rbin;\n\tint i;\n\tint *methods = NULL;\n\tint sym_count = 0;\n\n\t// doublecheck??\n\tif (!bin || bin->methods_list) {\n\t\treturn false;\n\t}\n\tbin->code_from = UT64_MAX;\n\tbin->code_to = 0;\n\tbin->methods_list = r_list_newf ((RListFree)free);\n\tif (!bin->methods_list) {\n\t\treturn false;\n\t}\n\tbin->imports_list = r_list_newf ((RListFree)free);\n\tif (!bin->imports_list) {\n\t\tr_list_free (bin->methods_list);\n\t\treturn false;\n\t}\n\tbin->classes_list = r_list_newf ((RListFree)__r_bin_class_free);\n\tif (!bin->classes_list) {\n\t\tr_list_free (bin->methods_list);\n\t\tr_list_free (bin->imports_list);\n\t\treturn false;\n\t}\n\n\tif (bin->header.method_size>bin->size) {\n\t\tbin->header.method_size = 0;\n\t\treturn false;\n\t}\n\n\t/* WrapDown the header sizes to avoid huge allocations */\n\tbin->header.method_size = R_MIN (bin->header.method_size, bin->size);\n\tbin->header.class_size = R_MIN (bin->header.class_size, bin->size);\n\tbin->header.strings_size = R_MIN (bin->header.strings_size, bin->size);\n\n\t// TODO: is this posible after R_MIN ??\n\tif (bin->header.strings_size > bin->size) {\n\t\teprintf (\"Invalid strings size\\n\");\n\t\treturn false;\n\t}\n\n\tif (bin->classes) {\n\t\tut64 amount = sizeof (int) * bin->header.method_size;\n\t\tif (amount > UT32_MAX || amount < bin->header.method_size) {\n\t\t\treturn false;\n\t\t}\n\t\tmethods = calloc (1, amount + 1);\n\t\tfor (i = 0; i < bin->header.class_size; i++) {\n\t\t\tchar *super_name, *class_name;\n\t\t\tstruct dex_class_t *c = &bin->classes[i];\n\t\t\tclass_name = dex_class_name (bin, c);\n\t\t\tsuper_name = dex_class_super_name (bin, c);\n\t\t\tif (dexdump) { \n\t\t\t\trbin->cb_printf (\"Class #%d            -\\n\", i);\n\t\t\t}\n\t\t\tparse_class (arch, bin, c, i, methods, &sym_count);\n\t\t\tfree (class_name);\n\t\t\tfree (super_name);\n\t\t}\n\t}\n\n\tif (methods) {\n\t\tint import_count = 0;\n\t\tint sym_count = bin->methods_list->length;\n\n\t\tfor (i = 0; i < bin->header.method_size; i++) {\n\t\t\tint len = 0;\n\t\t\tif (methods[i]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (bin->methods[i].class_id > bin->header.types_size) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (is_class_idx_in_code_classes(bin, bin->methods[i].class_id)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tchar *class_name = getstr (\n\t\t\t\tbin, bin->types[bin->methods[i].class_id]\n\t\t\t\t\t\t.descriptor_id);\n\t\t\tif (!class_name) {\n\t\t\t\tfree (class_name);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tlen = strlen (class_name);\n\t\t\tif (len < 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tclass_name[len - 1] = 0; // remove last char \";\"\n\t\t\tchar *method_name = dex_method_name (bin, i);\n\t\t\tchar *signature = dex_method_signature (bin, i);\n\t\t\tif (method_name && *method_name) {\n\t\t\t\tRBinImport *imp = R_NEW0 (RBinImport);\n\t\t\t\timp->name  = r_str_newf (\"%s.method.%s%s\", class_name, method_name, signature);\n\t\t\t\timp->type = r_str_const (\"FUNC\");\n\t\t\t\timp->bind = r_str_const (\"NONE\");\n\t\t\t\timp->ordinal = import_count++;\n\t\t\t\tr_list_append (bin->imports_list, imp);\n\n\t\t\t\tRBinSymbol *sym = R_NEW0 (RBinSymbol);\n\t\t\t\tsym->name = r_str_newf (\"imp.%s\", imp->name);\n\t\t\t\tsym->type = r_str_const (\"FUNC\");\n\t\t\t\tsym->bind = r_str_const (\"NONE\");\n\t\t\t\t//XXX so damn unsafe check buffer boundaries!!!!\n\t\t\t\t//XXX use r_buf API!!\n\t\t\t\tsym->paddr = sym->vaddr = bin->b->base + bin->header.method_offset + (sizeof (struct dex_method_t) * i) ;\n\t\t\t\tsym->ordinal = sym_count++;\n\t\t\t\tr_list_append (bin->methods_list, sym);\n\t\t\t\tsdb_num_set (mdb, sdb_fmt (0, \"method.%d\", i), sym->paddr, 0);\n\t\t\t}\n\t\t\tfree (method_name);\n\t\t\tfree (signature);\n\t\t\tfree (class_name);\n\t\t}\n\t\tfree (methods);\n\t}\n\treturn true;\n}", "commit_link": "github.com/radare/radare2/commit/ead645853a63bf83d8386702cad0cf23b31d7eeb", "file_name": "libr/bin/p/bin_dex.c", "vul_type": "cwe-125", "description": "Write a C function named `dex_loadcode` that initializes lists for methods, imports, and classes for a Dex object in a binary analysis library."}
{"func_name": "acc_ctx_cont", "func_src_before": "acc_ctx_cont(OM_uint32 *minstat,\n\t     gss_buffer_t buf,\n\t     gss_ctx_id_t *ctx,\n\t     gss_buffer_t *responseToken,\n\t     gss_buffer_t *mechListMIC,\n\t     OM_uint32 *negState,\n\t     send_token_flag *return_token)\n{\n\tOM_uint32 ret, tmpmin;\n\tgss_OID supportedMech;\n\tspnego_gss_ctx_id_t sc;\n\tunsigned int len;\n\tunsigned char *ptr, *bufstart;\n\n\tsc = (spnego_gss_ctx_id_t)*ctx;\n\tret = GSS_S_DEFECTIVE_TOKEN;\n\t*negState = REJECT;\n\t*minstat = 0;\n\tsupportedMech = GSS_C_NO_OID;\n\t*return_token = ERROR_TOKEN_SEND;\n\t*responseToken = *mechListMIC = GSS_C_NO_BUFFER;\n\n\tptr = bufstart = buf->value;\n#define REMAIN (buf->length - (ptr - bufstart))\n\tif (REMAIN > INT_MAX)\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\n\t/*\n\t * Attempt to work with old Sun SPNEGO.\n\t */\n\tif (*ptr == HEADER_ID) {\n\t\tret = g_verify_token_header(gss_mech_spnego,\n\t\t\t\t\t    &len, &ptr, 0, REMAIN);\n\t\tif (ret) {\n\t\t\t*minstat = ret;\n\t\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t\t}\n\t}\n\tif (*ptr != (CONTEXT | 0x01)) {\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t}\n\tret = get_negTokenResp(minstat, ptr, REMAIN,\n\t\t\t       negState, &supportedMech,\n\t\t\t       responseToken, mechListMIC);\n\tif (ret != GSS_S_COMPLETE)\n\t\tgoto cleanup;\n\n\tif (*responseToken == GSS_C_NO_BUFFER &&\n\t    *mechListMIC == GSS_C_NO_BUFFER) {\n\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tsc->firstpass = 0;\n\t*negState = ACCEPT_INCOMPLETE;\n\t*return_token = CONT_TOKEN_SEND;\ncleanup:\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tgeneric_gss_release_oid(&tmpmin, &supportedMech);\n\t}\n\treturn ret;\n#undef REMAIN\n}", "func_src_after": "acc_ctx_cont(OM_uint32 *minstat,\n\t     gss_buffer_t buf,\n\t     gss_ctx_id_t *ctx,\n\t     gss_buffer_t *responseToken,\n\t     gss_buffer_t *mechListMIC,\n\t     OM_uint32 *negState,\n\t     send_token_flag *return_token)\n{\n\tOM_uint32 ret, tmpmin;\n\tgss_OID supportedMech;\n\tspnego_gss_ctx_id_t sc;\n\tunsigned int len;\n\tunsigned char *ptr, *bufstart;\n\n\tsc = (spnego_gss_ctx_id_t)*ctx;\n\tret = GSS_S_DEFECTIVE_TOKEN;\n\t*negState = REJECT;\n\t*minstat = 0;\n\tsupportedMech = GSS_C_NO_OID;\n\t*return_token = ERROR_TOKEN_SEND;\n\t*responseToken = *mechListMIC = GSS_C_NO_BUFFER;\n\n\tptr = bufstart = buf->value;\n#define REMAIN (buf->length - (ptr - bufstart))\n\tif (REMAIN == 0 || REMAIN > INT_MAX)\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\n\t/*\n\t * Attempt to work with old Sun SPNEGO.\n\t */\n\tif (*ptr == HEADER_ID) {\n\t\tret = g_verify_token_header(gss_mech_spnego,\n\t\t\t\t\t    &len, &ptr, 0, REMAIN);\n\t\tif (ret) {\n\t\t\t*minstat = ret;\n\t\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t\t}\n\t}\n\tif (*ptr != (CONTEXT | 0x01)) {\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t}\n\tret = get_negTokenResp(minstat, ptr, REMAIN,\n\t\t\t       negState, &supportedMech,\n\t\t\t       responseToken, mechListMIC);\n\tif (ret != GSS_S_COMPLETE)\n\t\tgoto cleanup;\n\n\tif (*responseToken == GSS_C_NO_BUFFER &&\n\t    *mechListMIC == GSS_C_NO_BUFFER) {\n\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tsc->firstpass = 0;\n\t*negState = ACCEPT_INCOMPLETE;\n\t*return_token = CONT_TOKEN_SEND;\ncleanup:\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tgeneric_gss_release_oid(&tmpmin, &supportedMech);\n\t}\n\treturn ret;\n#undef REMAIN\n}", "commit_link": "github.com/krb5/krb5/commit/524688ce87a15fc75f87efc8c039ba4c7d5c197b", "file_name": "src/lib/gssapi/spnego/spnego_mech.c", "vul_type": "cwe-476", "description": "Write a C function named `acc_ctx_cont` that processes a security token in a SPNEGO context and updates the negotiation state."}
{"func_name": "(anonymous)", "func_src_before": "            // 2\u3001\u7b54\u6848\u3002\n            const answers = map(item.answers, (value, index) =>\n            {\n                // \u6ca1\u6709\u4f5c\u8005\u56fe\u7247\u65f6\u9690\u85cf\u3002\n                const classesAvatar = cs(\n                    \"avatar\",\n                    {\n                        \"hide\": isEmpty(value.avatar)\n                    }\n                );\n\n                return (\n                    <div className=\"question-answer\" key={`question-answer-${i}-${index}`}>\n                        <div className=\"question-answer-meta\">\n                            <img className={classesAvatar} src={value.avatar} />\n                            <span className=\"author\">{value.name}</span>\n                            <span className=\"bio\">{value.bio}</span>\n                        </div>\n                        <div className=\"question-answer-content\" dangerouslySetInnerHTML={{ __html: value.content }} />\n                    </div>\n                );\n            });\n            innerRows.push(...answers);\n\n            // 3\u3001\u5916\u94fe\u3002\n            if (item.link)\n            {\n                innerRows.push(\n                    <div className=\"view-more\" key={`view-more-${i}`}>\n                        <a href={item.link.href} target=\"_blank\"><b>{item.link.text}</b></a>\n                    </div>\n                );\n            }\n\n            questions.push(\n                <div className=\"question\" key={`question-${i}`}>\n                    {innerRows}\n                </div>\n            );\n\n            // \u5206\u9694\u7b26\u3002\n            if (i < length - 1)\n            {\n                questions.push(<hr className=\"question-separator\" key={`question-separator-${i}`} />);\n            }\n        }\n\n        return (", "func_src_after": "            // 2\u3001\u7b54\u6848\u3002\n            const answers = map(item.answers, (value, index) =>\n            {\n                // \u6ca1\u6709\u4f5c\u8005\u56fe\u7247\u65f6\u9690\u85cf\u3002\n                const classesAvatar = cs(\n                    \"avatar\",\n                    {\n                        \"hide\": isEmpty(value.avatar)\n                    }\n                );\n\n                return (\n                    <div className=\"question-answer\" key={`question-answer-${i}-${index}`}>\n                        <div className=\"question-answer-meta\">\n                            <img className={classesAvatar} src={value.avatar} />\n                            <span className=\"author\">{value.name}</span>\n                            <span className=\"bio\">{value.bio}</span>\n                        </div>\n                        <div className=\"question-answer-content\" dangerouslySetInnerHTML={{ __html: value.content }} />\n                    </div>\n                );\n            });\n            innerRows.push(...answers);\n\n            // 3\u3001\u5916\u94fe\u3002\n            if (item.link)\n            {\n                innerRows.push(\n                    <div className=\"view-more\" key={`view-more-${i}`}>\n                        <a href={item.link.href} target=\"_blank\" rel=\"noopener noreferrer\"><b>{item.link.text}</b></a>\n                    </div>\n                );\n            }\n\n            questions.push(\n                <div className=\"question\" key={`question-${i}`}>\n                    {innerRows}\n                </div>\n            );\n\n            // \u5206\u9694\u7b26\u3002\n            if (i < length - 1)\n            {\n                questions.push(<hr className=\"question-separator\" key={`question-separator-${i}`} />);\n            }\n        }\n\n        return (", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1141, "char_end": 1234, "line": "                        <a href={item.link.href} target=\"_blank\"><b>{item.link.text}</b></a>\n"}], "added": [{"line_no": 30, "char_start": 1141, "char_end": 1260, "line": "                        <a href={item.link.href} target=\"_blank\" rel=\"noopener noreferrer\"><b>{item.link.text}</b></a>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1205, "char_end": 1231, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/nonoroazoro/Zhihu-Daily-Reader/commit/e5e310be94fd9adfaa058c7abe3ab2515b16f128", "file_name": "ArticleView.jsx", "vul_type": "cwe-200", "commit_msg": "add rel=\"noopener noreferrer\"", "parent_commit": "07440697d044dc674dc8e55da0d1e1ebac8053df", "description": "In JavaScript, write a React component that displays a list of questions with their answers and optional external links, hiding the author's avatar if not provided."}
{"func_name": "candidate_paths_for_url", "func_src_before": "    def candidate_paths_for_url(self, url):\n        for root, prefix in self.directories:\n            if url.startswith(prefix):\n                yield os.path.join(root, url[len(prefix):])", "func_src_after": "    def candidate_paths_for_url(self, url):\n        for root, prefix in self.directories:\n            if url.startswith(prefix):\n                path = os.path.join(root, url[len(prefix):])\n                if os.path.commonprefix((root, path)) == root:\n                    yield path", "commit_link": "github.com/evansd/whitenoise/commit/4d8a3ab1e97d7ddb18b3fa8b4909c92bad5529c6", "file_name": "whitenoise/base.py", "vul_type": "cwe-022", "description": "Write a Python function that yields file system paths corresponding to a given URL based on predefined directory mappings."}
{"func_name": "vips_foreign_load_gif_scan_image", "func_src_before": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\tColorMapObject *map = file->Image.ColorMap ?\n\t\tfile->Image.ColorMap : file->SColorMap;\n\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "func_src_after": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\n\tColorMapObject *map;\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tmap = file->Image.ColorMap ? file->Image.ColorMap : file->SColorMap;\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "commit_link": "github.com/libvips/libvips/commit/ce684dd008532ea0bf9d4a1d89bacb35f4a83f4d", "file_name": "libvips/foreign/gifload.c", "vul_type": "cwe-416", "description": "Write a C function to scan and validate a GIF image frame for the Vips image processing library."}
{"func_name": "exporters_v1tov2", "func_src_before": "def exporters_v1tov2(exporters_paths, shared_config={}, quiet=False):\n    \"\"\"Translate exporters to v2 and put into shared config.\n\n    Args:\n        exporters_path (list): List of exporters file paths.\n        shared_config (dict): Shared config to add exporters to.\n        quiet (bool): Quiet mode.\n\n    Returns:\n        list: List of exporters keys added to shared config.\n    \"\"\"\n    exp_keys = []\n    for exp_path in exporters_paths:\n        with open(exp_path, encoding='utf-8') as conf:\n            content = yaml.load(conf, Loader=yaml.Loader)\n        exporters = content\n\n        # If exporters file has sections, concatenate all of them\n        if isinstance(content, dict):\n            exporters = []\n            for _, value in content.items():\n                exporters.extend(value)\n\n        # If exporter not in general config, add it and add an alias for the\n        # exporter. Refer to the alias in the SLO config file.\n        for exporter in exporters:\n            exporter = OrderedDict(exporter)\n            exp_key = add_to_shared_config(exporter,\n                                           shared_config,\n                                           'exporters',\n                                           quiet=quiet)\n            exp_keys.append(exp_key)\n    return exp_keys", "func_src_after": "def exporters_v1tov2(exporters_paths, shared_config={}, quiet=False):\n    \"\"\"Translate exporters to v2 and put into shared config.\n\n    Args:\n        exporters_path (list): List of exporters file paths.\n        shared_config (dict): Shared config to add exporters to.\n        quiet (bool): Quiet mode.\n\n    Returns:\n        list: List of exporters keys added to shared config.\n    \"\"\"\n    exp_keys = []\n    for exp_path in exporters_paths:\n        with open(exp_path, encoding='utf-8') as conf:\n            content = yaml.load(conf, Loader=yaml.SafeLoader)\n        exporters = content\n\n        # If exporters file has sections, concatenate all of them\n        if isinstance(content, dict):\n            exporters = []\n            for _, value in content.items():\n                exporters.extend(value)\n\n        # If exporter not in general config, add it and add an alias for the\n        # exporter. Refer to the alias in the SLO config file.\n        for exporter in exporters:\n            exporter = OrderedDict(exporter)\n            exp_key = add_to_shared_config(exporter,\n                                           shared_config,\n                                           'exporters',\n                                           quiet=quiet)\n            exp_keys.append(exp_key)\n    return exp_keys", "line_changes": {"deleted": [{"line_no": 15, "char_start": 495, "char_end": 553, "line": "            content = yaml.load(conf, Loader=yaml.Loader)\n"}], "added": [{"line_no": 15, "char_start": 495, "char_end": 557, "line": "            content = yaml.load(conf, Loader=yaml.SafeLoader)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 545, "char_end": 549, "chars": "Safe"}]}, "commit_link": "github.com/google/slo-generator/commit/36318beab1b85d14bb860e45bea186b184690d5d", "file_name": "migrator.py", "vul_type": "cwe-502", "commit_msg": "fix: yaml loader security issue (#173)", "parent_commit": "50ce1bf81d7c6a97da52cf167b1d3ee8100ddd90", "description": "Write a Python function to update a shared configuration with exporter details from multiple YAML files."}
{"func_name": "TNEFParse", "func_src_before": "int TNEFParse(TNEFStruct *TNEF) {\n  WORD key;\n  DWORD type;\n  DWORD size;\n  DWORD signature;\n  BYTE *data;\n  WORD checksum, header_checksum;\n  int i;\n\n  if (TNEF->IO.ReadProc == NULL) {\n    printf(\"ERROR: Setup incorrectly: No ReadProc\\n\");\n    return YTNEF_INCORRECT_SETUP;\n  }\n\n  if (TNEF->IO.InitProc != NULL) {\n    DEBUG(TNEF->Debug, 2, \"About to initialize\");\n    if (TNEF->IO.InitProc(&TNEF->IO) != 0) {\n      return YTNEF_CANNOT_INIT_DATA;\n    }\n    DEBUG(TNEF->Debug, 2, \"Initialization finished\");\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Reading Signature\");\n  if (TNEF->IO.ReadProc(&TNEF->IO, sizeof(DWORD), 1, &signature) < 1) {\n    printf(\"ERROR: Error reading signature\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_ERROR_READING_DATA;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Checking Signature\");\n  if (TNEFCheckForSignature(signature) < 0) {\n    printf(\"ERROR: Signature does not match. Not TNEF.\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_NOT_TNEF_STREAM;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Reading Key.\");\n\n  if (TNEFGetKey(TNEF, &key) < 0) {\n    printf(\"ERROR: Unable to retrieve key.\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_NO_KEY;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Starting Full Processing.\");\n\n  while (TNEFGetHeader(TNEF, &type, &size) == 0) {\n    DEBUG2(TNEF->Debug, 2, \"Header says type=0x%X, size=%u\", type, size);\n    DEBUG2(TNEF->Debug, 2, \"Header says type=%u, size=%u\", type, size);\n    data = calloc(size, sizeof(BYTE));\n    ALLOCCHECK(data);\n    if (TNEFRawRead(TNEF, data, size, &header_checksum) < 0) {\n      printf(\"ERROR: Unable to read data.\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_ERROR_READING_DATA;\n    }\n    if (TNEFRawRead(TNEF, (BYTE *)&checksum, 2, NULL) < 0) {\n      printf(\"ERROR: Unable to read checksum.\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_ERROR_READING_DATA;\n    }\n    checksum = SwapWord((BYTE *)&checksum, sizeof(WORD));\n    if (checksum != header_checksum) {\n      printf(\"ERROR: Checksum mismatch. Data corruption?:\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_BAD_CHECKSUM;\n    }\n    for (i = 0; i < (sizeof(TNEFList) / sizeof(TNEFHandler)); i++) {\n      if (TNEFList[i].id == type) {\n        if (TNEFList[i].handler != NULL) {\n          if (TNEFList[i].handler(TNEF, i, (char*)data, size) < 0) {\n            free(data);\n            if (TNEF->IO.CloseProc != NULL) {\n              TNEF->IO.CloseProc(&TNEF->IO);\n            }\n            return YTNEF_ERROR_IN_HANDLER;\n          } else {\n            //  Found our handler and processed it.  now time to get out\n            break;\n          }\n        } else {\n          DEBUG2(TNEF->Debug, 1, \"No handler for %s: %u bytes\",\n                 TNEFList[i].name, size);\n        }\n      }\n    }\n\n    free(data);\n  }\n\n  if (TNEF->IO.CloseProc != NULL) {\n    TNEF->IO.CloseProc(&TNEF->IO);\n  }\n  return 0;\n\n}", "func_src_after": "int TNEFParse(TNEFStruct *TNEF) {\n  WORD key;\n  DWORD type;\n  DWORD size;\n  DWORD signature;\n  BYTE *data;\n  WORD checksum, header_checksum;\n  int i;\n\n  if (TNEF->IO.ReadProc == NULL) {\n    printf(\"ERROR: Setup incorrectly: No ReadProc\\n\");\n    return YTNEF_INCORRECT_SETUP;\n  }\n\n  if (TNEF->IO.InitProc != NULL) {\n    DEBUG(TNEF->Debug, 2, \"About to initialize\");\n    if (TNEF->IO.InitProc(&TNEF->IO) != 0) {\n      return YTNEF_CANNOT_INIT_DATA;\n    }\n    DEBUG(TNEF->Debug, 2, \"Initialization finished\");\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Reading Signature\");\n  if (TNEF->IO.ReadProc(&TNEF->IO, sizeof(DWORD), 1, &signature) < 1) {\n    printf(\"ERROR: Error reading signature\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_ERROR_READING_DATA;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Checking Signature\");\n  if (TNEFCheckForSignature(signature) < 0) {\n    printf(\"ERROR: Signature does not match. Not TNEF.\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_NOT_TNEF_STREAM;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Reading Key.\");\n\n  if (TNEFGetKey(TNEF, &key) < 0) {\n    printf(\"ERROR: Unable to retrieve key.\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_NO_KEY;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Starting Full Processing.\");\n\n  while (TNEFGetHeader(TNEF, &type, &size) == 0) {\n    DEBUG2(TNEF->Debug, 2, \"Header says type=0x%X, size=%u\", type, size);\n    DEBUG2(TNEF->Debug, 2, \"Header says type=%u, size=%u\", type, size);\n    if(size == 0) {\n      printf(\"ERROR: Field with size of 0\\n\");\n      return YTNEF_ERROR_READING_DATA;\n    }\n    data = calloc(size, sizeof(BYTE));\n    ALLOCCHECK(data);\n    if (TNEFRawRead(TNEF, data, size, &header_checksum) < 0) {\n      printf(\"ERROR: Unable to read data.\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_ERROR_READING_DATA;\n    }\n    if (TNEFRawRead(TNEF, (BYTE *)&checksum, 2, NULL) < 0) {\n      printf(\"ERROR: Unable to read checksum.\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_ERROR_READING_DATA;\n    }\n    checksum = SwapWord((BYTE *)&checksum, sizeof(WORD));\n    if (checksum != header_checksum) {\n      printf(\"ERROR: Checksum mismatch. Data corruption?:\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_BAD_CHECKSUM;\n    }\n    for (i = 0; i < (sizeof(TNEFList) / sizeof(TNEFHandler)); i++) {\n      if (TNEFList[i].id == type) {\n        if (TNEFList[i].handler != NULL) {\n          if (TNEFList[i].handler(TNEF, i, (char*)data, size) < 0) {\n            free(data);\n            if (TNEF->IO.CloseProc != NULL) {\n              TNEF->IO.CloseProc(&TNEF->IO);\n            }\n            return YTNEF_ERROR_IN_HANDLER;\n          } else {\n            //  Found our handler and processed it.  now time to get out\n            break;\n          }\n        } else {\n          DEBUG2(TNEF->Debug, 1, \"No handler for %s: %u bytes\",\n                 TNEFList[i].name, size);\n        }\n      }\n    }\n\n    free(data);\n  }\n\n  if (TNEF->IO.CloseProc != NULL) {\n    TNEF->IO.CloseProc(&TNEF->IO);\n  }\n  return 0;\n\n}", "commit_link": "github.com/Yeraze/ytnef/commit/3cb0f914d6427073f262e1b2b5fd973e3043cdf7", "file_name": "lib/ytnef.c", "vul_type": "cwe-125", "description": "Write a C function named `TNEFParse` that processes a TNEF stream using provided I/O procedures."}
{"func_name": "_delete_host", "func_src_before": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = 'svctask rmhost %s ' % host_name\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "func_src_after": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = ['svctask', 'rmhost', host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to delete a host from a storage system using SSH commands, with debug logging before and after the operation."}
{"func_name": "AP4_HdlrAtom::AP4_HdlrAtom", "func_src_before": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    int name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    if (name_size == 0) return;\n    char* name = new char[name_size+1];\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "func_src_after": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    if (size < AP4_FULL_ATOM_HEADER_SIZE+20) return;\n    AP4_UI32 name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    char* name = new char[name_size+1];\n    if (name == NULL) return;\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/22192de5367fa0cee985917f092be4060b7c00b0", "file_name": "Source/C++/Core/Ap4HdlrAtom.cpp", "vul_type": "cwe-476", "description": "Write a C++ constructor for the `AP4_HdlrAtom` class that initializes an atom and reads its handler type and name from a byte stream."}
{"func_name": "all_deposits", "func_src_before": "    def all_deposits(self,coin):\n        sql = \"SELECT * FROM deposits WHERE coin='%s'\" % coin\n        self.cursor.execute(sql)\n        return self.cursor.fetchall()", "func_src_after": "    def all_deposits(self,coin):\n        sql = \"SELECT * FROM deposits WHERE coin='%s'\"\n        self.cursor.execute(sql, (coin,))\n        return self.cursor.fetchall()", "commit_link": "github.com/ktechmidas/garlictipsbot/commit/7c262255f933cb721109ac4be752b5b7599275aa", "file_name": "deposit.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch all deposit records for a given cryptocurrency from a database."}
{"func_name": "ape_decode_frame", "func_src_before": "static int ape_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame_ptr, AVPacket *avpkt)\n{\n    AVFrame *frame     = data;\n    const uint8_t *buf = avpkt->data;\n    APEContext *s = avctx->priv_data;\n    uint8_t *sample8;\n    int16_t *sample16;\n    int32_t *sample24;\n    int i, ch, ret;\n    int blockstodecode;\n\n    /* this should never be negative, but bad things will happen if it is, so\n       check it just to make sure. */\n    av_assert0(s->samples >= 0);\n\n    if(!s->samples){\n        uint32_t nblocks, offset;\n        int buf_size;\n\n        if (!avpkt->size) {\n            *got_frame_ptr = 0;\n            return 0;\n        }\n        if (avpkt->size < 8) {\n            av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        buf_size = avpkt->size & ~3;\n        if (buf_size != avpkt->size) {\n            av_log(avctx, AV_LOG_WARNING, \"packet size is not a multiple of 4. \"\n                   \"extra bytes at the end will be skipped.\\n\");\n        }\n        if (s->fileversion < 3950) // previous versions overread two bytes\n            buf_size += 2;\n        av_fast_padded_malloc(&s->data, &s->data_size, buf_size);\n        if (!s->data)\n            return AVERROR(ENOMEM);\n        s->bdsp.bswap_buf((uint32_t *) s->data, (const uint32_t *) buf,\n                          buf_size >> 2);\n        memset(s->data + (buf_size & ~3), 0, buf_size & 3);\n        s->ptr = s->data;\n        s->data_end = s->data + buf_size;\n\n        nblocks = bytestream_get_be32(&s->ptr);\n        offset  = bytestream_get_be32(&s->ptr);\n        if (s->fileversion >= 3900) {\n            if (offset > 3) {\n                av_log(avctx, AV_LOG_ERROR, \"Incorrect offset passed\\n\");\n                s->data = NULL;\n                return AVERROR_INVALIDDATA;\n            }\n            if (s->data_end - s->ptr < offset) {\n                av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            s->ptr += offset;\n        } else {\n            if ((ret = init_get_bits8(&s->gb, s->ptr, s->data_end - s->ptr)) < 0)\n                return ret;\n            if (s->fileversion > 3800)\n                skip_bits_long(&s->gb, offset * 8);\n            else\n                skip_bits_long(&s->gb, offset);\n        }\n\n        if (!nblocks || nblocks > INT_MAX) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample count: %\"PRIu32\".\\n\",\n                   nblocks);\n            return AVERROR_INVALIDDATA;\n        }\n\n        /* Initialize the frame decoder */\n        if (init_frame_decoder(s) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error reading frame header\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        s->samples = nblocks;\n    }\n\n    if (!s->data) {\n        *got_frame_ptr = 0;\n        return avpkt->size;\n    }\n\n    blockstodecode = FFMIN(s->blocks_per_loop, s->samples);\n    // for old files coefficients were not interleaved,\n    // so we need to decode all of them at once\n    if (s->fileversion < 3930)\n        blockstodecode = s->samples;\n\n    /* reallocate decoded sample buffer if needed */\n    av_fast_malloc(&s->decoded_buffer, &s->decoded_size,\n                   2 * FFALIGN(blockstodecode, 8) * sizeof(*s->decoded_buffer));\n    if (!s->decoded_buffer)\n        return AVERROR(ENOMEM);\n    memset(s->decoded_buffer, 0, s->decoded_size);\n    s->decoded[0] = s->decoded_buffer;\n    s->decoded[1] = s->decoded_buffer + FFALIGN(blockstodecode, 8);\n\n    /* get output buffer */\n    frame->nb_samples = blockstodecode;\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n\n    s->error=0;\n\n    if ((s->channels == 1) || (s->frameflags & APE_FRAMECODE_PSEUDO_STEREO))\n        ape_unpack_mono(s, blockstodecode);\n    else\n        ape_unpack_stereo(s, blockstodecode);\n    emms_c();\n\n    if (s->error) {\n        s->samples=0;\n        av_log(avctx, AV_LOG_ERROR, \"Error decoding frame\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    switch (s->bps) {\n    case 8:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample8 = (uint8_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample8++ = (s->decoded[ch][i] + 0x80) & 0xff;\n        }\n        break;\n    case 16:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample16 = (int16_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample16++ = s->decoded[ch][i];\n        }\n        break;\n    case 24:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample24 = (int32_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample24++ = s->decoded[ch][i] << 8;\n        }\n        break;\n    }\n\n    s->samples -= blockstodecode;\n\n    *got_frame_ptr = 1;\n\n    return !s->samples ? avpkt->size : 0;\n}", "func_src_after": "static int ape_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame_ptr, AVPacket *avpkt)\n{\n    AVFrame *frame     = data;\n    const uint8_t *buf = avpkt->data;\n    APEContext *s = avctx->priv_data;\n    uint8_t *sample8;\n    int16_t *sample16;\n    int32_t *sample24;\n    int i, ch, ret;\n    int blockstodecode;\n    uint64_t decoded_buffer_size;\n\n    /* this should never be negative, but bad things will happen if it is, so\n       check it just to make sure. */\n    av_assert0(s->samples >= 0);\n\n    if(!s->samples){\n        uint32_t nblocks, offset;\n        int buf_size;\n\n        if (!avpkt->size) {\n            *got_frame_ptr = 0;\n            return 0;\n        }\n        if (avpkt->size < 8) {\n            av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        buf_size = avpkt->size & ~3;\n        if (buf_size != avpkt->size) {\n            av_log(avctx, AV_LOG_WARNING, \"packet size is not a multiple of 4. \"\n                   \"extra bytes at the end will be skipped.\\n\");\n        }\n        if (s->fileversion < 3950) // previous versions overread two bytes\n            buf_size += 2;\n        av_fast_padded_malloc(&s->data, &s->data_size, buf_size);\n        if (!s->data)\n            return AVERROR(ENOMEM);\n        s->bdsp.bswap_buf((uint32_t *) s->data, (const uint32_t *) buf,\n                          buf_size >> 2);\n        memset(s->data + (buf_size & ~3), 0, buf_size & 3);\n        s->ptr = s->data;\n        s->data_end = s->data + buf_size;\n\n        nblocks = bytestream_get_be32(&s->ptr);\n        offset  = bytestream_get_be32(&s->ptr);\n        if (s->fileversion >= 3900) {\n            if (offset > 3) {\n                av_log(avctx, AV_LOG_ERROR, \"Incorrect offset passed\\n\");\n                s->data = NULL;\n                return AVERROR_INVALIDDATA;\n            }\n            if (s->data_end - s->ptr < offset) {\n                av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            s->ptr += offset;\n        } else {\n            if ((ret = init_get_bits8(&s->gb, s->ptr, s->data_end - s->ptr)) < 0)\n                return ret;\n            if (s->fileversion > 3800)\n                skip_bits_long(&s->gb, offset * 8);\n            else\n                skip_bits_long(&s->gb, offset);\n        }\n\n        if (!nblocks || nblocks > INT_MAX / 2 / sizeof(*s->decoded_buffer) - 8) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample count: %\"PRIu32\".\\n\",\n                   nblocks);\n            return AVERROR_INVALIDDATA;\n        }\n\n        /* Initialize the frame decoder */\n        if (init_frame_decoder(s) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error reading frame header\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        s->samples = nblocks;\n    }\n\n    if (!s->data) {\n        *got_frame_ptr = 0;\n        return avpkt->size;\n    }\n\n    blockstodecode = FFMIN(s->blocks_per_loop, s->samples);\n    // for old files coefficients were not interleaved,\n    // so we need to decode all of them at once\n    if (s->fileversion < 3930)\n        blockstodecode = s->samples;\n\n    /* reallocate decoded sample buffer if needed */\n    decoded_buffer_size = 2LL * FFALIGN(blockstodecode, 8) * sizeof(*s->decoded_buffer);\n    av_assert0(decoded_buffer_size <= INT_MAX);\n    av_fast_malloc(&s->decoded_buffer, &s->decoded_size, decoded_buffer_size);\n    if (!s->decoded_buffer)\n        return AVERROR(ENOMEM);\n    memset(s->decoded_buffer, 0, s->decoded_size);\n    s->decoded[0] = s->decoded_buffer;\n    s->decoded[1] = s->decoded_buffer + FFALIGN(blockstodecode, 8);\n\n    /* get output buffer */\n    frame->nb_samples = blockstodecode;\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n\n    s->error=0;\n\n    if ((s->channels == 1) || (s->frameflags & APE_FRAMECODE_PSEUDO_STEREO))\n        ape_unpack_mono(s, blockstodecode);\n    else\n        ape_unpack_stereo(s, blockstodecode);\n    emms_c();\n\n    if (s->error) {\n        s->samples=0;\n        av_log(avctx, AV_LOG_ERROR, \"Error decoding frame\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    switch (s->bps) {\n    case 8:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample8 = (uint8_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample8++ = (s->decoded[ch][i] + 0x80) & 0xff;\n        }\n        break;\n    case 16:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample16 = (int16_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample16++ = s->decoded[ch][i];\n        }\n        break;\n    case 24:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample24 = (int32_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample24++ = s->decoded[ch][i] << 8;\n        }\n        break;\n    }\n\n    s->samples -= blockstodecode;\n\n    *got_frame_ptr = 1;\n\n    return !s->samples ? avpkt->size : 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/ba4beaf6149f7241c8bd85fe853318c2f6837ad0", "file_name": "libavcodec/apedec.c", "vul_type": "cwe-125", "description": "Write a C function named `ape_decode_frame` for decoding an audio frame in the APE codec."}
{"func_name": "get_last_active_users", "func_src_before": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "func_src_after": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch a specified number of the most recent active bot users from a database."}
{"func_name": "(anonymous)", "func_src_before": "\t\t\t\t\tinput.keypress(function(event) {\n\t\t\t\t\t\tif(event.keyCode == 13) {\n\t\t\t\t\t\t\tevent.preventDefault();\n\t\t\t\t\t\t\tevent.stopPropagation();\n\t\t\t\t\t\t\tvar li=$(this).parent();\n\t\t\t\t\t\t\t$(this).remove();\n\t\t\t\t\t\t\tli.text('+ '+settings.createText);\n\t\t\t\t\t\t\tli.before(createItem(this));\n\t\t\t\t\t\t\tvar select=button.parent().next();\n\t\t\t\t\t\t\tselect.append($('<option selected=\"selected\" value=\"'+$(this).val()+'\">'+$(this).val()+'</option>'));\n\t\t\t\t\t\t\tli.prev().children('input').trigger('click');\n\t\t\t\t\t\t\tbutton.parent().data('preventHide',false);\n\t\t\t\t\t\t\tif(settings.createCallback){\n\t\t\t\t\t\t\t\tsettings.createCallback();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});", "func_src_after": "\t\t\t\t\tinput.keypress(function(event) {\n\t\t\t\t\t\tif(event.keyCode == 13) {\n\t\t\t\t\t\t\tevent.preventDefault();\n\t\t\t\t\t\t\tevent.stopPropagation();\n\t\t\t\t\t\t\tvar li=$(this).parent();\n\t\t\t\t\t\t\t$(this).remove();\n\t\t\t\t\t\t\tli.text('+ '+settings.createText);\n\t\t\t\t\t\t\tli.before(createItem(this));\n\t\t\t\t\t\t\tvar select=button.parent().next();\n\t\t\t\t\t\t\tvar option=$('<option selected=\"selected\"/>');\n\t\t\t\t\t\t\toption.attr('value',$(this).val());\n\t\t\t\t\t\t\toption.text($(this).val());\n\t\t\t\t\t\t\tselect.append(optione);\n\t\t\t\t\t\t\tli.prev().children('input').trigger('click');\n\t\t\t\t\t\t\tbutton.parent().data('preventHide',false);\n\t\t\t\t\t\t\tif(settings.createCallback){\n\t\t\t\t\t\t\t\tsettings.createCallback();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});", "line_changes": {"deleted": [{"line_no": 10, "char_start": 310, "char_end": 419, "line": "\t\t\t\t\t\t\tselect.append($('<option selected=\"selected\" value=\"'+$(this).val()+'\">'+$(this).val()+'</option>'));\n"}], "added": [{"line_no": 10, "char_start": 310, "char_end": 364, "line": "\t\t\t\t\t\t\tvar option=$('<option selected=\"selected\"/>');\n"}, {"line_no": 11, "char_start": 364, "char_end": 407, "line": "\t\t\t\t\t\t\toption.attr('value',$(this).val());\n"}, {"line_no": 12, "char_start": 407, "char_end": 442, "line": "\t\t\t\t\t\t\toption.text($(this).val());\n"}, {"line_no": 13, "char_start": 442, "char_end": 473, "line": "\t\t\t\t\t\t\tselect.append(optione);\n"}]}, "char_changes": {"deleted": [{"char_start": 317, "char_end": 331, "chars": "select.append("}, {"char_start": 361, "char_end": 362, "chars": " "}, {"char_start": 367, "char_end": 371, "chars": "=\"'+"}, {"char_start": 384, "char_end": 407, "chars": "+'\">'+$(this).val()+'</"}, {"char_start": 413, "char_end": 416, "chars": ">')"}], "added": [{"char_start": 317, "char_end": 328, "chars": "var option="}, {"char_start": 358, "char_end": 384, "chars": "/>');\n\t\t\t\t\t\t\toption.attr('"}, {"char_start": 389, "char_end": 391, "chars": "',"}, {"char_start": 404, "char_end": 463, "chars": ");\n\t\t\t\t\t\t\toption.text($(this).val());\n\t\t\t\t\t\t\tselect.append("}, {"char_start": 469, "char_end": 470, "chars": "e"}]}, "commit_link": "github.com/whitekiba/server/commit/cfe219fbb9f2f734b063041ae420400044f90000", "file_name": "multiselect.js", "vul_type": "cwe-079", "commit_msg": "fix potential xss in multiselect", "description": "Write a jQuery snippet that handles the enter key press on an input field to replace it with a list item and update a select element with a new option."}
{"func_name": "wiki_handle_rest_call", "func_src_before": "wiki_handle_rest_call(HttpRequest  *req, \n\t\t      HttpResponse *res,\n\t\t      char         *func)\n{\n\n  if (func != NULL && *func != '\\0')\n    {\n      if (!strcmp(func, \"page/get\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (access(page, R_OK) == 0)) \n\t    {\n\t      http_response_printf(res, \"%s\", file_read(page));\n\t      http_response_send(res);\n\t      return;\n\t    }  \n\t}\n      else if (!strcmp(func, \"page/set\"))\n\t{\n\t  char *wikitext = NULL, *page = NULL;\n\t  if( ( (wikitext = http_request_param_get(req, \"text\")) != NULL)\n\t      && ( (page = http_request_param_get(req, \"page\")) != NULL))\n\t    {\n\t      file_write(page, wikitext);\t      \n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;\n\t    }\n\t}\n      else if (!strcmp(func, \"page/delete\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (unlink(page) > 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"page/exists\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (access(page, R_OK) == 0)) \n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"pages\") || !strcmp(func, \"search\"))\n\t{\n\t  WikiPageList **pages = NULL;\n\t  int            n_pages, i;\n\t  char          *expr = http_request_param_get(req, \"expr\");\n\n\t  if (expr == NULL)\n\t    expr = http_request_get_query_string(req);\n\t  \n\t  pages = wiki_get_pages(&n_pages, expr);\n\n\t  if (pages)\n\t    {\n\t      for (i=0; i<n_pages; i++)\n\t\t{\n\t\t  struct tm   *pTm;\n\t\t  char   datebuf[64];\n\t\t  \n\t\t  pTm = localtime(&pages[i]->mtime);\n\t\t  strftime(datebuf, sizeof(datebuf), \"%Y-%m-%d %H:%M\", pTm);\n\t\t  http_response_printf(res, \"%s\\t%s\\n\", pages[i]->name, datebuf);\n\t\t}\n\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n    }\n\n  http_response_set_status(res, 500, \"Error\");\n  http_response_printf(res, \"<html><body>Failed</body></html>\\n\");\n  http_response_send(res);\n\n  return;  \n}", "func_src_after": "wiki_handle_rest_call(HttpRequest  *req, \n\t\t      HttpResponse *res,\n\t\t      char         *func)\n{\n\n  if (func != NULL && *func != '\\0')\n    {\n      if (!strcmp(func, \"page/get\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (access(page, R_OK) == 0))\n\t    {\n\t      http_response_printf(res, \"%s\", file_read(page));\n\t      http_response_send(res);\n\t      return;\n\t    }  \n\t}\n      else if (!strcmp(func, \"page/set\"))\n\t{\n\t  char *wikitext = NULL, *page = NULL;\n\t  if( ( (wikitext = http_request_param_get(req, \"text\")) != NULL)\n\t      && ( (page = http_request_param_get(req, \"page\")) != NULL))\n\t    {\n\t  if (page_name_is_good(page))\n\t    {\n\t      file_write(page, wikitext);\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;\n\t    }\n\t    }\n\t}\n      else if (!strcmp(func, \"page/delete\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (unlink(page) > 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"page/exists\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (access(page, R_OK) == 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"pages\") || !strcmp(func, \"search\"))\n\t{\n\t  WikiPageList **pages = NULL;\n\t  int            n_pages, i;\n\t  char          *expr = http_request_param_get(req, \"expr\");\n\n\t  if (expr == NULL)\n\t    expr = http_request_get_query_string(req);\n\t  \n\t  pages = wiki_get_pages(&n_pages, expr);\n\n\t  if (pages)\n\t    {\n\t      for (i=0; i<n_pages; i++)\n\t\t{\n\t\t  struct tm   *pTm;\n\t\t  char   datebuf[64];\n\t\t  \n\t\t  pTm = localtime(&pages[i]->mtime);\n\t\t  strftime(datebuf, sizeof(datebuf), \"%Y-%m-%d %H:%M\", pTm);\n\t\t  http_response_printf(res, \"%s\\t%s\\n\", pages[i]->name, datebuf);\n\t\t}\n\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n    }\n\n  http_response_set_status(res, 500, \"Error\");\n  http_response_printf(res, \"<html><body>Failed</body></html>\\n\");\n  http_response_send(res);\n\n  return;  \n}", "commit_link": "github.com/yarolig/didiwiki/commit/5e5c796617e1712905dc5462b94bd5e6c08d15ea", "file_name": "src/wiki.c", "vul_type": "cwe-022", "description": "In C, write a function to handle RESTful API calls for a wiki page system, supporting operations like get, set, delete, check existence, and list/search pages."}
{"func_name": "set_fdc", "func_src_before": "static void set_fdc(int drive)\n{\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tfdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (fdc != 1 && fdc != 0) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "func_src_after": "static void set_fdc(int drive)\n{\n\tunsigned int new_fdc = fdc;\n\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tnew_fdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (new_fdc >= N_FDC) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tfdc = new_fdc;\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "commit_link": "github.com/torvalds/linux/commit/2e90ca68b0d2f5548804f22f0dd61145516171e3", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-125", "description": "Write a C function named `set_fdc` that configures a floppy disk controller (FDC) for a given drive number, with error checking and hardware status updates."}
{"func_name": "_formatCredentials", "func_src_before": "    def _formatCredentials(self, data, name):\n        \"\"\"\n        Credentials are of the form\n        RCLONE_CONFIG_CURRENT_TYPE=s3\n            ^          ^        ^   ^\n        [mandatory  ][name  ][key][value]\n        \"\"\"\n\n        prefix = \"RCLONE_CONFIG_{}\".format(name.upper())\n\n        credentials = ''\n        credentials += \"{}_TYPE='{}' \".format(prefix, data.type)\n\n        def _addCredential(credentials, env_key, data_key):\n            value = getattr(data, data_key, None)\n            if value is not None:\n                credentials += \"{}='{}' \".format(env_key, value)\n            return credentials\n\n\n        if data.type == 's3':\n            credentials = _addCredential(credentials,\n                '{}_REGION'.format(prefix),\n                's3_region'\n            )\n            credentials = _addCredential(credentials,\n                '{}_ACCESS_KEY_ID'.format(prefix),\n                's3_access_key_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SECRET_ACCESS_KEY'.format(prefix),\n                's3_secret_access_key'\n            )\n\n            credentials = _addCredential(credentials,\n                '{}_ENDPOINT'.format(prefix),\n                's3_endpoint'\n            )\n            credentials = _addCredential(credentials,\n                '{}_V2_AUTH'.format(prefix),\n                's3_v2_auth'\n            )\n\n        elif data.type == 'azureblob':\n            credentials = _addCredential(credentials,\n                '{}_ACCOUNT'.format(prefix),\n                'azure_account'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'azure_key'\n            )\n\n        elif data.type == 'swift':\n            credentials = _addCredential(credentials,\n                '{}_USER'.format(prefix),\n                'swift_user'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'swift_key'\n            )\n            credentials = _addCredential(credentials,\n                '{}_AUTH'.format(prefix),\n                'swift_auth'\n            )\n            credentials = _addCredential(credentials,\n                '{}_TENANT'.format(prefix),\n                'swift_tenant'\n            )\n\n        elif data.type == 'google cloud storage':\n            credentials = _addCredential(credentials,\n                '{}_CLIENT_ID'.format(prefix),\n                'gcp_client_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SERVICE_ACCOUNT_CREDENTIALS'.format(prefix),\n                'gcp_service_account_credentials'\n            )\n            credentials = _addCredential(credentials,\n                '{}_PROJECT_NUMBER'.format(prefix),\n                'gcp_project_number'\n            )\n            credentials = _addCredential(credentials,\n                '{}_OBJECT_ACL'.format(prefix),\n                'gcp_object_acl'\n            )\n            credentials = _addCredential(credentials,\n                '{}_BUCKET_ACL'.format(prefix),\n                'gcp_bucket_acl'\n            )\n\n        else:\n            logging.error(\"Connection type unknown: {}\".format(data.type))\n\n        return credentials", "func_src_after": "    def _formatCredentials(self, data, name):\n        \"\"\"\n        Credentials are of the form\n        RCLONE_CONFIG_CURRENT_TYPE=s3\n            ^          ^        ^   ^\n        [mandatory  ][name  ][key][value]\n        \"\"\"\n\n        prefix = \"RCLONE_CONFIG_{}\".format(name.upper())\n\n        credentials = {}\n        credentials['{}_TYPE'.format(prefix)] = data.type\n\n        def _addCredential(credentials, env_key, data_key):\n            value = getattr(data, data_key, None)\n            if value is not None:\n                credentials[env_key] = value\n            return credentials\n\n\n        if data.type == 's3':\n            credentials = _addCredential(credentials,\n                '{}_REGION'.format(prefix),\n                's3_region'\n            )\n            credentials = _addCredential(credentials,\n                '{}_ACCESS_KEY_ID'.format(prefix),\n                's3_access_key_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SECRET_ACCESS_KEY'.format(prefix),\n                's3_secret_access_key'\n            )\n\n            credentials = _addCredential(credentials,\n                '{}_ENDPOINT'.format(prefix),\n                's3_endpoint'\n            )\n            credentials = _addCredential(credentials,\n                '{}_V2_AUTH'.format(prefix),\n                's3_v2_auth'\n            )\n\n        elif data.type == 'azureblob':\n            credentials = _addCredential(credentials,\n                '{}_ACCOUNT'.format(prefix),\n                'azure_account'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'azure_key'\n            )\n\n        elif data.type == 'swift':\n            credentials = _addCredential(credentials,\n                '{}_USER'.format(prefix),\n                'swift_user'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'swift_key'\n            )\n            credentials = _addCredential(credentials,\n                '{}_AUTH'.format(prefix),\n                'swift_auth'\n            )\n            credentials = _addCredential(credentials,\n                '{}_TENANT'.format(prefix),\n                'swift_tenant'\n            )\n\n        elif data.type == 'google cloud storage':\n            credentials = _addCredential(credentials,\n                '{}_CLIENT_ID'.format(prefix),\n                'gcp_client_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SERVICE_ACCOUNT_CREDENTIALS'.format(prefix),\n                'gcp_service_account_credentials'\n            )\n            credentials = _addCredential(credentials,\n                '{}_PROJECT_NUMBER'.format(prefix),\n                'gcp_project_number'\n            )\n            credentials = _addCredential(credentials,\n                '{}_OBJECT_ACL'.format(prefix),\n                'gcp_object_acl'\n            )\n            credentials = _addCredential(credentials,\n                '{}_BUCKET_ACL'.format(prefix),\n                'gcp_bucket_acl'\n            )\n\n        else:\n            logging.error(\"Connection type unknown: {}\".format(data.type))\n\n        return credentials", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function to format cloud storage credentials into a string or dictionary based on the storage type."}
{"func_name": "_get_vdisk_fc_mappings", "func_src_before": "    def _get_vdisk_fc_mappings(self, vdisk_name):\n        \"\"\"Return FlashCopy mappings that this vdisk is associated with.\"\"\"\n\n        ssh_cmd = 'svcinfo lsvdiskfcmappings -nohdr %s' % vdisk_name\n        out, err = self._run_ssh(ssh_cmd)\n\n        mapping_ids = []\n        if (len(out.strip())):\n            lines = out.strip().split('\\n')\n            mapping_ids = [line.split()[0] for line in lines]\n        return mapping_ids", "func_src_after": "    def _get_vdisk_fc_mappings(self, vdisk_name):\n        \"\"\"Return FlashCopy mappings that this vdisk is associated with.\"\"\"\n\n        ssh_cmd = ['svcinfo', 'lsvdiskfcmappings', '-nohdr', vdisk_name]\n        out, err = self._run_ssh(ssh_cmd)\n\n        mapping_ids = []\n        if (len(out.strip())):\n            lines = out.strip().split('\\n')\n            mapping_ids = [line.split()[0] for line in lines]\n        return mapping_ids", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and return the IDs of FlashCopy mappings for a given virtual disk using SSH commands."}
{"func_name": "UserController.createOrJoinTeam", "func_src_before": "UserController.createOrJoinTeam = function(id, code, callback){\n\n  if (!code){\n    return callback({\n      message: \"Please enter a team name.\"\n    });\n  }\n\n  User.find({\n    teamCode: code\n  })\n  .select('profile.name')\n  .exec(function(err, users){\n    // Check to see if this team is joinable (< team max size)\n\n    if (users.length >= maxTeamSize){\n      return callback({\n        message: \"Team is full.\"\n      });\n    }\n\n    // Otherwise, we can add that person to the team.\n    User.findOneAndUpdate({\n      _id: id,\n      verified: true\n    },{\n      $set: {\n        teamCode: code\n      }\n    }, {\n      new: true\n    },\n    callback);\n\n  });\n};", "func_src_after": "UserController.createOrJoinTeam = function(id, code, callback){\n\n  if (!code){\n    return callback({\n      message: \"Please enter a team name.\"\n    });\n  }\n\n  if (typeof code !== 'string') {\n    return callback({\n      message: \"Get outta here, punk!\"\n    });\n  }\n\n  User.find({\n    teamCode: code\n  })\n  .select('profile.name')\n  .exec(function(err, users){\n    // Check to see if this team is joinable (< team max size)\n    if (users.length >= maxTeamSize){\n      return callback({\n        message: \"Team is full.\"\n      });\n    }\n\n    // Otherwise, we can add that person to the team.\n    User.findOneAndUpdate({\n      _id: id,\n      verified: true\n    },{\n      $set: {\n        teamCode: code\n      }\n    }, {\n      new: true\n    },\n    callback);\n\n  });\n};", "line_changes": {"deleted": [{"line_no": 15, "char_start": 314, "char_end": 315, "line": "\n"}], "added": [{"line_no": 9, "char_start": 157, "char_end": 191, "line": "  if (typeof code !== 'string') {\n"}, {"line_no": 10, "char_start": 191, "char_end": 213, "line": "    return callback({\n"}, {"line_no": 11, "char_start": 213, "char_end": 252, "line": "      message: \"Get outta here, punk!\"\n"}, {"line_no": 12, "char_start": 252, "char_end": 260, "line": "    });\n"}, {"line_no": 13, "char_start": 260, "char_end": 264, "line": "  }\n"}, {"line_no": 14, "char_start": 264, "char_end": 265, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 314, "char_end": 315, "chars": "\n"}], "added": [{"char_start": 157, "char_end": 265, "chars": "  if (typeof code !== 'string') {\n    return callback({\n      message: \"Get outta here, punk!\"\n    });\n  }\n\n"}]}, "commit_link": "github.com/techx/quill/commit/88a42ea6c4bcdee1b180b0a140d8886c3b5c543e", "file_name": "UserController.js", "vul_type": "cwe-089", "commit_msg": "Security: `/users/:id/team` NoSQL Injection Fix", "description": "Write a JavaScript function that allows a user to join a team by name if there's space available."}
{"func_name": "subscribe_for_tags", "func_src_before": "@csrf.csrf_protect\ndef subscribe_for_tags(request):\n    \"\"\"process subscription of users by tags\"\"\"\n    #todo - use special separator to split tags\n    tag_names = request.REQUEST.get('tags','').strip().split()\n    pure_tag_names, wildcards = forms.clean_marked_tagnames(tag_names)\n    if request.user.is_authenticated():\n        if request.method == 'POST':\n            if 'ok' in request.POST:\n                request.user.mark_tags(\n                            pure_tag_names,\n                            wildcards,\n                            reason = 'good',\n                            action = 'add'\n                        )\n                request.user.message_set.create(\n                    message = _('Your tag subscription was saved, thanks!')\n                )\n            else:\n                message = _(\n                    'Tag subscription was canceled (<a href=\"%(url)s\">undo</a>).'\n                ) % {'url': request.path + '?tags=' + request.REQUEST['tags']}\n                request.user.message_set.create(message = message)\n            return HttpResponseRedirect(reverse('index'))\n        else:\n            data = {'tags': tag_names}\n            return render(request, 'subscribe_for_tags.html', data)\n    else:\n        all_tag_names = pure_tag_names + wildcards\n        message = _('Please sign in to subscribe for: %(tags)s') \\\n                    % {'tags': ', '.join(all_tag_names)}\n        request.user.message_set.create(message = message)\n        request.session['subscribe_for_tags'] = (pure_tag_names, wildcards)\n        return HttpResponseRedirect(url_utils.get_login_url())", "func_src_after": "@csrf.csrf_protect\ndef subscribe_for_tags(request):\n    \"\"\"process subscription of users by tags\"\"\"\n    #todo - use special separator to split tags\n    tag_names = request.REQUEST.get('tags','').strip().split()\n    pure_tag_names, wildcards = forms.clean_marked_tagnames(tag_names)\n    if request.user.is_authenticated():\n        if request.method == 'POST':\n            if 'ok' in request.POST:\n                request.user.mark_tags(\n                            pure_tag_names,\n                            wildcards,\n                            reason = 'good',\n                            action = 'add'\n                        )\n                request.user.message_set.create(\n                    message = _('Your tag subscription was saved, thanks!')\n                )\n            else:\n                message = _(\n                    'Tag subscription was canceled (<a href=\"%(url)s\">undo</a>).'\n                ) % {'url': escape(request.path) + '?tags=' + request.REQUEST['tags']}\n                request.user.message_set.create(message = message)\n            return HttpResponseRedirect(reverse('index'))\n        else:\n            data = {'tags': tag_names}\n            return render(request, 'subscribe_for_tags.html', data)\n    else:\n        all_tag_names = pure_tag_names + wildcards\n        message = _('Please sign in to subscribe for: %(tags)s') \\\n                    % {'tags': ', '.join(all_tag_names)}\n        request.user.message_set.create(message = message)\n        request.session['subscribe_for_tags'] = (pure_tag_names, wildcards)\n        return HttpResponseRedirect(url_utils.get_login_url())", "commit_link": "github.com/ASKBOT/askbot-devel/commit/a676a86b6b7a5737d4da4f59f71e037406f88d29", "file_name": "askbot/views/commands.py", "vul_type": "cwe-079", "description": "In Python, write a Django view function named `subscribe_for_tags` that handles user tag subscription requests, including CSRF protection."}
{"func_name": "tid_to_tid_num", "func_src_before": "    def tid_to_tid_num(self, tid):\n        ''' Returns tid_num, given tid. '''\n\n        q = \"SELECT rowid FROM tids WHERE tid = '\" + tid + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "func_src_after": "    def tid_to_tid_num(self, tid):\n        ''' Returns tid_num, given tid. '''\n\n        q = \"SELECT rowid FROM tids WHERE tid = ?\"\n        self.query(q, tid)\n        return self.c.fetchone()[0]", "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves the numerical ID (rowid) for a given text identifier (tid) from a database table named 'tids'."}
{"func_name": "keycompare_mb", "func_src_before": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          char *copy_a = (char *) xmalloc (lena + 1 + lenb + 1);\n          char *copy_b = copy_a + lena + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "func_src_after": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          if (SIZE_MAX - lenb - 2 < lena)\n            xalloc_die ();\n          char *copy_a = (char *) xnmalloc (lena + lenb + 2, MB_CUR_MAX);\n          char *copy_b = copy_a + lena * MB_CUR_MAX + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "commit_link": "github.com/pixelb/coreutils/commit/bea5e36cc876ed627bb5e0eca36fdfaa6465e940", "file_name": "src/sort.c", "vul_type": "cwe-787", "description": "Write a C function named `keycompare_mb` that compares two lines based on predefined key positions, handling multibyte characters and various comparison options."}
{"func_name": "add_extra_args", "func_src_before": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "func_src_after": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(args, nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "commit_link": "github.com/freedombenLiu/ParlAI/commit/601668d569e1276e0b8bf2bf8fb43e391e10d170", "file_name": "parlai/core/params.py", "vul_type": "cwe-078", "description": "Write a Python function that extends argument parsing with additional arguments based on existing parsed arguments."}
{"func_name": "delete_playlists_videos", "func_src_before": "def delete_playlists_videos(playlist_id, db):\n    db.execute(\"DELETE FROM video where playlist_id={playlist_id};\".format(\n        playlist_id=playlist_id))", "func_src_after": "def delete_playlists_videos(playlist_id, db):\n    db.execute(\"DELETE FROM video where playlist_id=%s;\", (playlist_id,))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to remove all videos from a specific playlist in a database using the playlist ID."}
{"func_name": "SessionAttributesManager::doGet", "func_src_before": "  @Override\n  protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n    response.setHeader(\"Cache-Control\", \"no-cache\");\n    response.setHeader(\"Pragma\", \"no-cache\");\n    response.setDateHeader(\"Expires\", -1);\n\n    String name = request.getParameter(\"name\");\n    String value = request.getParameter(\"value\");\n    String message = \"The parameter 'name' is empty\";\n\n    if (name != null && name.length() > 0) {\n      if (allowedAttributes.contains(name)) {\n\n        // add bcdBeanUser.name entries as HashMap session variable \"bcdBeanUser\" where the key/value pairs\n        // are kept without the prefix.\n        boolean error = true;\n        Subject subject = SecurityUtils.getSubject();\n        // check value against list of allowed values or subject settings user rights\n        if (subject != null && subject.getSession() != null && ((allowedValues.get(name) != null && allowedValues.get(name).contains(\" \" + value + \" \")) || subject.isPermitted(BCD_EL_USER_BEAN + \":\" + name + \":\" + value))) {\n          Map<String, String> bean = (HashMap<String, String>)subject.getSession().getAttribute(BCD_EL_USER_BEAN);\n          if (bean == null)\n            bean = new HashMap<>();\n          bean.put(name, value);\n          subject.getSession().setAttribute(BCD_EL_USER_BEAN, bean);\n          error = false;\n        }\n        message =\"The \" + BCD_EL_USER_BEAN + \" '\" + name +  (error ? \"' can not be set to '\" : \"' was set to \") + value;\n      }\n      else {\n        message = \"The attribute name '\" + name + \"' is not allowed by the configuration. Please set the init param ALLOWED_ATTRIBUTES in your web.xml\";\n      }\n    }\n    log.debug(message);\n    response.getWriter().append(message);\n  }", "func_src_after": "  @Override\n  protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n    response.setHeader(\"Cache-Control\", \"no-cache\");\n    response.setHeader(\"Pragma\", \"no-cache\");\n    response.setDateHeader(\"Expires\", -1);\n\n    String name = request.getParameter(\"name\");\n    String value = request.getParameter(\"value\");\n    String message = \"The parameter 'name' is empty\";\n\n    if (name != null && name.length() > 0) {\n      if (allowedAttributes.contains(name)) {\n\n        // add bcdBeanUser.name entries as HashMap session variable \"bcdBeanUser\" where the key/value pairs\n        // are kept without the prefix.\n        boolean error = true;\n        Subject subject = SecurityUtils.getSubject();\n        // check value against list of allowed values or subject settings user rights\n        if (subject != null && subject.getSession() != null && ((allowedValues.get(name) != null && allowedValues.get(name).contains(\" \" + value + \" \")) || subject.isPermitted(BCD_EL_USER_BEAN + \":\" + name + \":\" + value))) {\n          Map<String, String> bean = (HashMap<String, String>)subject.getSession().getAttribute(BCD_EL_USER_BEAN);\n          if (bean == null)\n            bean = new HashMap<>();\n          bean.put(name, value);\n          subject.getSession().setAttribute(BCD_EL_USER_BEAN, bean);\n          error = false;\n        }\n        message =\"The \" + BCD_EL_USER_BEAN + \" '\" + name +  (error ? \"' can not be set to '\" : \"' was set to \") + value;\n      }\n      else {\n        message = \"The attribute name '\" + name + \"' is not allowed by the configuration. Please set the init param ALLOWED_ATTRIBUTES in your web.xml\";\n      }\n    }\n    log.debug(message);\n  }", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1712, "char_end": 1754, "line": "    response.getWriter().append(message);\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 1712, "char_end": 1754, "chars": "    response.getWriter().append(message);\n"}], "added": []}, "commit_link": "github.com/businesscode/BCD-UI/commit/9b230b1500511054da457cf4a5382895fae891df", "file_name": "SessionAttributesManager.java", "vul_type": "cwe-079", "commit_msg": "Server/Security, XSS fixes", "parent_commit": "1b507ea97204e6b71d5863d4c6e523e51a3440b2", "description": "Create a Java servlet that processes a GET request by updating session attributes based on provided parameters and logs the result."}
{"func_name": "store_versioninfo_gnu_verneed", "func_src_before": "static Sdb *store_versioninfo_gnu_verneed(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tut8 *end, *need = NULL;\n\tconst char *section_name = \"\";\n\tElf_(Shdr) *link_shdr = NULL;\n\tconst char *link_section_name = \"\";\n\tSdb *sdb_vernaux = NULL;\n\tSdb *sdb_version = NULL;\n\tSdb *sdb = NULL;\n\tint i, cnt;\n\n\tif (!bin || !bin->dynstr) {\n\t\treturn NULL;\n\t}\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn NULL;\n\t}\n\tif (shdr->sh_size < 1) {\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tif (!sdb) {\n\t\treturn NULL;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!(need = (ut8*) calloc (R_MAX (1, shdr->sh_size), sizeof (ut8)))) {\n\t\tbprintf (\"Warning: Cannot allocate memory for Elf_(Verneed)\\n\");\n\t\tgoto beach;\n\t}\n\tend = need + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"num_entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tif (shdr->sh_offset > bin->size || shdr->sh_offset + shdr->sh_size > bin->size) {\n\t\tgoto beach;\n\t}\n\tif (shdr->sh_offset + shdr->sh_size < shdr->sh_size) {\n\t\tgoto beach;\n\t}\n\ti = r_buf_read_at (bin->b, shdr->sh_offset, need, shdr->sh_size);\n\tif (i < 0)\n\t\tgoto beach;\n\t//XXX we should use DT_VERNEEDNUM instead of sh_info\n\t//TODO https://sourceware.org/ml/binutils/2014-11/msg00353.html\n\tfor (i = 0, cnt = 0; cnt < shdr->sh_info; ++cnt) {\n\t\tint j, isum;\n\t\tut8 *vstart = need + i;\n\t\tElf_(Verneed) vvn = {0};\n\t\tif (vstart + sizeof (Elf_(Verneed)) > end) {\n\t\t\tgoto beach;\n\t\t}\n\t\tElf_(Verneed) *entry = &vvn;\n\t\tchar key[32] = {0};\n\t\tsdb_version = sdb_new0 ();\n\t\tif (!sdb_version) {\n\t\t\tgoto beach;\n\t\t}\n\t\tj = 0;\n\t\tvvn.vn_version = READ16 (vstart, j)\n\t\tvvn.vn_cnt = READ16 (vstart, j)\n\t\tvvn.vn_file = READ32 (vstart, j)\n\t\tvvn.vn_aux = READ32 (vstart, j)\n\t\tvvn.vn_next = READ32 (vstart, j)\n\n\t\tsdb_num_set (sdb_version, \"vn_version\", entry->vn_version, 0);\n\t\tsdb_num_set (sdb_version, \"idx\", i, 0);\n\t\tif (entry->vn_file > bin->dynstr_size) {\n\t\t\tgoto beach;\n\t\t}\n\t\t{\n\t\t\tchar *s = r_str_ndup (&bin->dynstr[entry->vn_file], 16);\n\t\t\tsdb_set (sdb_version, \"file_name\", s, 0);\n\t\t\tfree (s);\n\t\t}\n\t\tsdb_num_set (sdb_version, \"cnt\", entry->vn_cnt, 0);\n\t\tvstart += entry->vn_aux;\n\t\tfor (j = 0, isum = i + entry->vn_aux; j < entry->vn_cnt && vstart + sizeof (Elf_(Vernaux)) <= end; ++j) {\n\t\t\tint k;\n\t\t\tElf_(Vernaux) * aux = NULL;\n\t\t\tElf_(Vernaux) vaux = {0};\n\t\t\tsdb_vernaux = sdb_new0 ();\n\t\t\tif (!sdb_vernaux) {\n\t\t\t\tgoto beach;\n\t\t\t}\n\t\t\taux = (Elf_(Vernaux)*)&vaux;\n\t\t\tk = 0;\n\t\t\tvaux.vna_hash = READ32 (vstart, k)\n\t\t\tvaux.vna_flags = READ16 (vstart, k)\n\t\t\tvaux.vna_other = READ16 (vstart, k)\n\t\t\tvaux.vna_name = READ32 (vstart, k)\n\t\t\tvaux.vna_next = READ32 (vstart, k)\n\t\t\tif (aux->vna_name > bin->dynstr_size) {\n\t\t\t\tgoto beach;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_vernaux, \"idx\", isum, 0);\n\t\t\tif (aux->vna_name > 0 && aux->vna_name + 8 < bin->dynstr_size) {\n\t\t\t\tchar name [16];\n\t\t\t\tstrncpy (name, &bin->dynstr[aux->vna_name], sizeof (name)-1);\n\t\t\t\tname[sizeof(name)-1] = 0;\n\t\t\t\tsdb_set (sdb_vernaux, \"name\", name, 0);\n\t\t\t}\n\t\t\tsdb_set (sdb_vernaux, \"flags\", get_ver_flags (aux->vna_flags), 0);\n\t\t\tsdb_num_set (sdb_vernaux, \"version\", aux->vna_other, 0);\n\t\t\tisum += aux->vna_next;\n\t\t\tvstart += aux->vna_next;\n\t\t\tsnprintf (key, sizeof (key), \"vernaux%d\", j);\n\t\t\tsdb_ns_set (sdb_version, key, sdb_vernaux);\n\t\t}\n\t\tif ((int)entry->vn_next < 0) {\n\t\t\tbprintf (\"Invalid vn_next\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += entry->vn_next;\n\t\tsnprintf (key, sizeof (key), \"version%d\", cnt );\n\t\tsdb_ns_set (sdb, key, sdb_version);\n\t\t//if entry->vn_next is 0 it iterate infinitely\n\t\tif (!entry->vn_next) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tfree (need);\n\treturn sdb;\nbeach:\n\tfree (need);\n\tsdb_free (sdb_vernaux);\n\tsdb_free (sdb_version);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "func_src_after": "static Sdb *store_versioninfo_gnu_verneed(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tut8 *end, *need = NULL;\n\tconst char *section_name = \"\";\n\tElf_(Shdr) *link_shdr = NULL;\n\tconst char *link_section_name = \"\";\n\tSdb *sdb_vernaux = NULL;\n\tSdb *sdb_version = NULL;\n\tSdb *sdb = NULL;\n\tint i, cnt;\n\n\tif (!bin || !bin->dynstr) {\n\t\treturn NULL;\n\t}\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn NULL;\n\t}\n\tif (shdr->sh_size < 1) {\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tif (!sdb) {\n\t\treturn NULL;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!(need = (ut8*) calloc (R_MAX (1, shdr->sh_size), sizeof (ut8)))) {\n\t\tbprintf (\"Warning: Cannot allocate memory for Elf_(Verneed)\\n\");\n\t\tgoto beach;\n\t}\n\tend = need + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"num_entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tif (shdr->sh_offset > bin->size || shdr->sh_offset + shdr->sh_size > bin->size) {\n\t\tgoto beach;\n\t}\n\tif (shdr->sh_offset + shdr->sh_size < shdr->sh_size) {\n\t\tgoto beach;\n\t}\n\ti = r_buf_read_at (bin->b, shdr->sh_offset, need, shdr->sh_size);\n\tif (i < 0)\n\t\tgoto beach;\n\t//XXX we should use DT_VERNEEDNUM instead of sh_info\n\t//TODO https://sourceware.org/ml/binutils/2014-11/msg00353.html\n\tfor (i = 0, cnt = 0; cnt < shdr->sh_info; ++cnt) {\n\t\tint j, isum;\n\t\tut8 *vstart = need + i;\n\t\tElf_(Verneed) vvn = {0};\n\t\tif (vstart + sizeof (Elf_(Verneed)) > end) {\n\t\t\tgoto beach;\n\t\t}\n\t\tElf_(Verneed) *entry = &vvn;\n\t\tchar key[32] = {0};\n\t\tsdb_version = sdb_new0 ();\n\t\tif (!sdb_version) {\n\t\t\tgoto beach;\n\t\t}\n\t\tj = 0;\n\t\tvvn.vn_version = READ16 (vstart, j)\n\t\tvvn.vn_cnt = READ16 (vstart, j)\n\t\tvvn.vn_file = READ32 (vstart, j)\n\t\tvvn.vn_aux = READ32 (vstart, j)\n\t\tvvn.vn_next = READ32 (vstart, j)\n\n\t\tsdb_num_set (sdb_version, \"vn_version\", entry->vn_version, 0);\n\t\tsdb_num_set (sdb_version, \"idx\", i, 0);\n\t\tif (entry->vn_file > bin->dynstr_size) {\n\t\t\tgoto beach;\n\t\t}\n\t\t{\n\t\t\tchar *s = r_str_ndup (&bin->dynstr[entry->vn_file], 16);\n\t\t\tsdb_set (sdb_version, \"file_name\", s, 0);\n\t\t\tfree (s);\n\t\t}\n\t\tsdb_num_set (sdb_version, \"cnt\", entry->vn_cnt, 0);\n\t\tst32 vnaux = entry->vn_aux;\n\t\tif (vnaux < 1) {\n\t\t\tgoto beach;\n\t\t}\n\t\tvstart += vnaux;\n\t\tfor (j = 0, isum = i + entry->vn_aux; j < entry->vn_cnt && vstart + sizeof (Elf_(Vernaux)) <= end; ++j) {\n\t\t\tint k;\n\t\t\tElf_(Vernaux) * aux = NULL;\n\t\t\tElf_(Vernaux) vaux = {0};\n\t\t\tsdb_vernaux = sdb_new0 ();\n\t\t\tif (!sdb_vernaux) {\n\t\t\t\tgoto beach;\n\t\t\t}\n\t\t\taux = (Elf_(Vernaux)*)&vaux;\n\t\t\tk = 0;\n\t\t\tvaux.vna_hash = READ32 (vstart, k)\n\t\t\tvaux.vna_flags = READ16 (vstart, k)\n\t\t\tvaux.vna_other = READ16 (vstart, k)\n\t\t\tvaux.vna_name = READ32 (vstart, k)\n\t\t\tvaux.vna_next = READ32 (vstart, k)\n\t\t\tif (aux->vna_name > bin->dynstr_size) {\n\t\t\t\tgoto beach;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_vernaux, \"idx\", isum, 0);\n\t\t\tif (aux->vna_name > 0 && aux->vna_name + 8 < bin->dynstr_size) {\n\t\t\t\tchar name [16];\n\t\t\t\tstrncpy (name, &bin->dynstr[aux->vna_name], sizeof (name)-1);\n\t\t\t\tname[sizeof(name)-1] = 0;\n\t\t\t\tsdb_set (sdb_vernaux, \"name\", name, 0);\n\t\t\t}\n\t\t\tsdb_set (sdb_vernaux, \"flags\", get_ver_flags (aux->vna_flags), 0);\n\t\t\tsdb_num_set (sdb_vernaux, \"version\", aux->vna_other, 0);\n\t\t\tisum += aux->vna_next;\n\t\t\tvstart += aux->vna_next;\n\t\t\tsnprintf (key, sizeof (key), \"vernaux%d\", j);\n\t\t\tsdb_ns_set (sdb_version, key, sdb_vernaux);\n\t\t}\n\t\tif ((int)entry->vn_next < 0) {\n\t\t\tbprintf (\"Invalid vn_next\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += entry->vn_next;\n\t\tsnprintf (key, sizeof (key), \"version%d\", cnt );\n\t\tsdb_ns_set (sdb, key, sdb_version);\n\t\t//if entry->vn_next is 0 it iterate infinitely\n\t\tif (!entry->vn_next) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tfree (need);\n\treturn sdb;\nbeach:\n\tfree (need);\n\tsdb_free (sdb_vernaux);\n\tsdb_free (sdb_version);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/c6d0076c924891ad9948a62d89d0bcdaf965f0cd", "file_name": "libr/bin/format/elf/elf.c", "vul_type": "cwe-125", "description": "In C, write a function to parse and store GNU version dependency information from an ELF binary's section header."}
{"func_name": "ssl_parse_server_key_exchange", "func_src_before": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( end != p + sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "func_src_after": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( p != end - sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "commit_link": "github.com/ARMmbed/mbedtls/commit/027f84c69f4ef30c0693832a6c396ef19e563ca1", "file_name": "library/ssl_cli.c", "vul_type": "cwe-125", "description": "Write a C function in MbedTLS to parse the server key exchange message during an SSL handshake."}
{"func_name": "dnxhd_decode_header", "func_src_before": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n                               const uint8_t *buf, int buf_size,\n                               int first_field)\n{\n    int i, cid, ret;\n    int old_bit_depth = ctx->bit_depth, bitdepth;\n    uint64_t header_prefix;\n    if (buf_size < 0x280) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < 640).\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    header_prefix = ff_dnxhd_parse_header_prefix(buf);\n    if (header_prefix == 0) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"unknown header 0x%02X 0x%02X 0x%02X 0x%02X 0x%02X\\n\",\n               buf[0], buf[1], buf[2], buf[3], buf[4]);\n        return AVERROR_INVALIDDATA;\n    }\n    if (buf[5] & 2) { /* interlaced */\n        ctx->cur_field = buf[5] & 1;\n        frame->interlaced_frame = 1;\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n    } else {\n        ctx->cur_field = 0;\n    }\n    ctx->mbaff = (buf[0x6] >> 5) & 1;\n\n    ctx->height = AV_RB16(buf + 0x18);\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n    switch(buf[0x21] >> 5) {\n    case 1: bitdepth = 8; break;\n    case 2: bitdepth = 10; break;\n    case 3: bitdepth = 12; break;\n    default:\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"Unknown bitdepth indicator (%d)\\n\", buf[0x21] >> 5);\n        return AVERROR_INVALIDDATA;\n    }\n\n    cid = AV_RB32(buf + 0x28);\n\n    ctx->avctx->profile = dnxhd_get_profile(cid);\n\n    if ((ret = dnxhd_init_vlc(ctx, cid, bitdepth)) < 0)\n        return ret;\n    if (ctx->mbaff && ctx->cid_table->cid != 1260)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive MB interlace flag in an unsupported profile.\\n\");\n\n    ctx->act = buf[0x2C] & 7;\n    if (ctx->act && ctx->cid_table->cid != 1256 && ctx->cid_table->cid != 1270)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive color transform in an unsupported profile.\\n\");\n\n    ctx->is_444 = (buf[0x2C] >> 6) & 1;\n    if (ctx->is_444) {\n        if (bitdepth == 8) {\n            avpriv_request_sample(ctx->avctx, \"4:4:4 8 bits\");\n            return AVERROR_INVALIDDATA;\n        } else if (bitdepth == 10) {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P10\n                                    : AV_PIX_FMT_GBRP10;\n        } else {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_12_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P12\n                                    : AV_PIX_FMT_GBRP12;\n        }\n    } else if (bitdepth == 12) {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_12;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P12;\n    } else if (bitdepth == 10) {\n        if (ctx->avctx->profile == FF_PROFILE_DNXHR_HQX)\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n        else\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n    } else {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P;\n    }\n\n    ctx->avctx->bits_per_raw_sample = ctx->bit_depth = bitdepth;\n    if (ctx->bit_depth != old_bit_depth) {\n        ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n        ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n        ff_init_scantable(ctx->idsp.idct_permutation, &ctx->scantable,\n                          ff_zigzag_direct);\n    }\n\n    // make sure profile size constraints are respected\n    // DNx100 allows 1920->1440 and 1280->960 subsampling\n    if (ctx->width != ctx->cid_table->width &&\n        ctx->cid_table->width != DNXHD_VARIABLE) {\n        av_reduce(&ctx->avctx->sample_aspect_ratio.num,\n                  &ctx->avctx->sample_aspect_ratio.den,\n                  ctx->width, ctx->cid_table->width, 255);\n        ctx->width = ctx->cid_table->width;\n    }\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size (%d < %u).\\n\",\n               buf_size, ctx->cid_table->coding_unit_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ctx->mb_width  = (ctx->width + 15)>> 4;\n    ctx->mb_height = AV_RB16(buf + 0x16c);\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n        ctx->height <<= 1;\n\n    av_log(ctx->avctx, AV_LOG_VERBOSE, \"%dx%d, 4:%s %d bits, MBAFF=%d ACT=%d\\n\",\n           ctx->width, ctx->height, ctx->is_444 ? \"4:4\" : \"2:2\",\n           ctx->bit_depth, ctx->mbaff, ctx->act);\n\n    // Newer format supports variable mb_scan_index sizes\n    if (ctx->mb_height > 68 && ff_dnxhd_check_header_prefix_hr(header_prefix)) {\n        ctx->data_offset = 0x170 + (ctx->mb_height << 2);\n    } else {\n        if (ctx->mb_height > 68 ||\n            (ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"mb height too big: %d\\n\", ctx->mb_height);\n            return AVERROR_INVALIDDATA;\n        }\n        ctx->data_offset = 0x280;\n    }\n\n    if (buf_size < ctx->data_offset) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < %d).\\n\", buf_size, ctx->data_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (ctx->mb_height > FF_ARRAY_ELEMS(ctx->mb_scan_index)) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"mb_height too big (%d > %\"SIZE_SPECIFIER\").\\n\", ctx->mb_height, FF_ARRAY_ELEMS(ctx->mb_scan_index));\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < ctx->mb_height; i++) {\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n        ff_dlog(ctx->avctx, \"mb scan index %d, pos %d: %\"PRIu32\"\\n\",\n                i, 0x170 + (i << 2), ctx->mb_scan_index[i]);\n        if (buf_size - ctx->data_offset < ctx->mb_scan_index[i]) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"invalid mb scan index (%\"PRIu32\" vs %u).\\n\",\n                   ctx->mb_scan_index[i], buf_size - ctx->data_offset);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    return 0;\n}", "func_src_after": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n                               const uint8_t *buf, int buf_size,\n                               int first_field)\n{\n    int i, cid, ret;\n    int old_bit_depth = ctx->bit_depth, bitdepth;\n    uint64_t header_prefix;\n    if (buf_size < 0x280) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < 640).\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    header_prefix = ff_dnxhd_parse_header_prefix(buf);\n    if (header_prefix == 0) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"unknown header 0x%02X 0x%02X 0x%02X 0x%02X 0x%02X\\n\",\n               buf[0], buf[1], buf[2], buf[3], buf[4]);\n        return AVERROR_INVALIDDATA;\n    }\n    if (buf[5] & 2) { /* interlaced */\n        ctx->cur_field = buf[5] & 1;\n        frame->interlaced_frame = 1;\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n    } else {\n        ctx->cur_field = 0;\n    }\n    ctx->mbaff = (buf[0x6] >> 5) & 1;\n\n    ctx->height = AV_RB16(buf + 0x18);\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n    switch(buf[0x21] >> 5) {\n    case 1: bitdepth = 8; break;\n    case 2: bitdepth = 10; break;\n    case 3: bitdepth = 12; break;\n    default:\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"Unknown bitdepth indicator (%d)\\n\", buf[0x21] >> 5);\n        return AVERROR_INVALIDDATA;\n    }\n\n    cid = AV_RB32(buf + 0x28);\n\n    ctx->avctx->profile = dnxhd_get_profile(cid);\n\n    if ((ret = dnxhd_init_vlc(ctx, cid, bitdepth)) < 0)\n        return ret;\n    if (ctx->mbaff && ctx->cid_table->cid != 1260)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive MB interlace flag in an unsupported profile.\\n\");\n\n    ctx->act = buf[0x2C] & 7;\n    if (ctx->act && ctx->cid_table->cid != 1256 && ctx->cid_table->cid != 1270)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive color transform in an unsupported profile.\\n\");\n\n    ctx->is_444 = (buf[0x2C] >> 6) & 1;\n    if (ctx->is_444) {\n        if (bitdepth == 8) {\n            avpriv_request_sample(ctx->avctx, \"4:4:4 8 bits\");\n            return AVERROR_INVALIDDATA;\n        } else if (bitdepth == 10) {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P10\n                                    : AV_PIX_FMT_GBRP10;\n        } else {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_12_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P12\n                                    : AV_PIX_FMT_GBRP12;\n        }\n    } else if (bitdepth == 12) {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_12;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P12;\n    } else if (bitdepth == 10) {\n        if (ctx->avctx->profile == FF_PROFILE_DNXHR_HQX)\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n        else\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n    } else {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P;\n    }\n\n    ctx->avctx->bits_per_raw_sample = ctx->bit_depth = bitdepth;\n    if (ctx->bit_depth != old_bit_depth) {\n        ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n        ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n        ff_init_scantable(ctx->idsp.idct_permutation, &ctx->scantable,\n                          ff_zigzag_direct);\n    }\n\n    // make sure profile size constraints are respected\n    // DNx100 allows 1920->1440 and 1280->960 subsampling\n    if (ctx->width != ctx->cid_table->width &&\n        ctx->cid_table->width != DNXHD_VARIABLE) {\n        av_reduce(&ctx->avctx->sample_aspect_ratio.num,\n                  &ctx->avctx->sample_aspect_ratio.den,\n                  ctx->width, ctx->cid_table->width, 255);\n        ctx->width = ctx->cid_table->width;\n    }\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size (%d < %u).\\n\",\n               buf_size, ctx->cid_table->coding_unit_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ctx->mb_width  = (ctx->width + 15)>> 4;\n    ctx->mb_height = AV_RB16(buf + 0x16c);\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n        ctx->height <<= 1;\n\n    av_log(ctx->avctx, AV_LOG_VERBOSE, \"%dx%d, 4:%s %d bits, MBAFF=%d ACT=%d\\n\",\n           ctx->width, ctx->height, ctx->is_444 ? \"4:4\" : \"2:2\",\n           ctx->bit_depth, ctx->mbaff, ctx->act);\n\n    // Newer format supports variable mb_scan_index sizes\n    if (ctx->mb_height > 68 && ff_dnxhd_check_header_prefix_hr(header_prefix)) {\n        ctx->data_offset = 0x170 + (ctx->mb_height << 2);\n    } else {\n        if (ctx->mb_height > 68) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"mb height too big: %d\\n\", ctx->mb_height);\n            return AVERROR_INVALIDDATA;\n        }\n        ctx->data_offset = 0x280;\n    }\n    if ((ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n                \"mb height too big: %d\\n\", ctx->mb_height);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (buf_size < ctx->data_offset) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < %d).\\n\", buf_size, ctx->data_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (ctx->mb_height > FF_ARRAY_ELEMS(ctx->mb_scan_index)) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"mb_height too big (%d > %\"SIZE_SPECIFIER\").\\n\", ctx->mb_height, FF_ARRAY_ELEMS(ctx->mb_scan_index));\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < ctx->mb_height; i++) {\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n        ff_dlog(ctx->avctx, \"mb scan index %d, pos %d: %\"PRIu32\"\\n\",\n                i, 0x170 + (i << 2), ctx->mb_scan_index[i]);\n        if (buf_size - ctx->data_offset < ctx->mb_scan_index[i]) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"invalid mb scan index (%\"PRIu32\" vs %u).\\n\",\n                   ctx->mb_scan_index[i], buf_size - ctx->data_offset);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/296debd213bd6dce7647cedd34eb64e5b94cdc92", "file_name": "libavcodec/dnxhddec.c", "vul_type": "cwe-125", "description": "Write a C function named `dnxhd_decode_header` that decodes the header of a DNxHD video frame."}
{"func_name": "insert", "func_src_before": "def insert(key, value):\n    connection = psycopg2.connect(host=config['HOST'], port=config['PORT'], database=config['NAME'], user=config['USER'], password=config['PASSWORD'])\n    cur = connection.cursor()\n    try:\n        cur.execute(\"insert into reply_map values('{}', '{}')\".format(key, value))\n        connection.commit()\n    except:\n        pass", "func_src_after": "def insert(key, value):\n    connection = psycopg2.connect(host=config['HOST'], port=config['PORT'], database=config['NAME'], user=config['USER'], password=config['PASSWORD'])\n    cur = connection.cursor()\n    try:\n        cur.execute(\"insert into reply_map values(?, ?)\", (key, value))\n        connection.commit()\n    except:\n        pass", "commit_link": "github.com/tadaren/reply_bot/commit/5aeafa7e9597a766992af9ff8189e1f050b6579b", "file_name": "db.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a key-value pair into a PostgreSQL database table using psycopg2 without error handling details."}
{"func_name": "AcceptBasketRequests", "func_src_before": "func AcceptBasketRequests(w http.ResponseWriter, r *http.Request) {\n\tname := strings.Split(r.URL.Path, \"/\")[1]\n\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\trequest := basket.Add(r)\n\n\t\t// forward request if configured and it's a first forwarding\n\t\tconfig := basket.Config()\n\t\tif len(config.ForwardURL) > 0 && r.Header.Get(DoNotForwardHeader) != \"1\" {\n\t\t\tif config.ProxyResponse {\n\t\t\t\tforwardAndProxyResponse(w, request, config, name)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tgo forwardAndForget(request, config, name)\n\t\t}\n\n\t\twriteBasketResponse(w, r, name, basket)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n}", "func_src_after": "func AcceptBasketRequests(w http.ResponseWriter, r *http.Request) {\n\tname := strings.Split(r.URL.Path, \"/\")[1]\n\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\trequest := basket.Add(r)\n\n\t\t// forward request if configured and it's a first forwarding\n\t\tconfig := basket.Config()\n\t\tif len(config.ForwardURL) > 0 && r.Header.Get(DoNotForwardHeader) != \"1\" {\n\t\t\tif config.ProxyResponse {\n\t\t\t\tforwardAndProxyResponse(w, request, config, name)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tgo forwardAndForget(request, config, name)\n\t\t}\n\n\t\twriteBasketResponse(w, r, name, basket)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 153, "char_end": 277, "line": "\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}], "added": [{"line_no": 5, "char_start": 153, "char_end": 275, "line": "\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}]}, "char_changes": {"deleted": [{"char_start": 191, "char_end": 194, "chars": "[\"+"}, {"char_start": 198, "char_end": 201, "chars": "+\"]"}], "added": [{"char_start": 191, "char_end": 195, "chars": "the "}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go function to handle HTTP requests for a basket service, validating names and optionally forwarding requests."}
{"func_name": "hierarchical_tile", "func_src_before": "def hierarchical_tile(masterfile,tilefile):\n\n    \"\"\"\n    Create Hierarchical tile from Master prior\n\n    :param masterfile: Master prior file\n    :param tilefile:  File containing Tiling scheme\n    \"\"\"\n    try:\n        taskid = np.int(os.environ['SGE_TASK_ID'])\n        task_first=np.int(os.environ['SGE_TASK_FIRST'])\n        task_last=np.int(os.environ['SGE_TASK_LAST'])\n\n    except KeyError:\n        print(\"Error: could not read SGE_TASK_ID from environment\")\n        taskid = int(input(\"Please enter task id: \"))\n        print(\"you entered\", taskid)\n\n\n    with open(tilefile, 'rb') as f:\n        obj = pickle.load(f)\n\n    tiles = obj['tiles']\n    order = obj['order']\n    tiles_large = obj['tiles_large']\n    order_large = obj['order_large']\n\n    with open(masterfile, 'rb') as f:\n        obj = pickle.load(f)\n    priors = obj['priors']\n\n    moc = moc_routines.get_fitting_region(order_large, tiles_large[taskid - 1])\n    for p in priors:\n        p.moc = moc\n        p.cut_down_prior()\n\n    outfile = 'Tile_'+ str(tiles_large[taskid - 1]) + '_' + str(order_large) + '.pkl'\n    with open(outfile, 'wb') as f:\n        pickle.dump({'priors':priors, 'version':xidplus.io.git_version()}, f)", "func_src_after": "def hierarchical_tile(masterfile,tilefile):\n\n    \"\"\"\n    Create Hierarchical tile from Master prior\n\n    :param masterfile: Master prior file\n    :param tilefile:  File containing Tiling scheme\n    \"\"\"\n    try:\n        taskid = np.int(os.environ['SGE_TASK_ID'])\n        task_first=np.int(os.environ['SGE_TASK_FIRST'])\n        task_last=np.int(os.environ['SGE_TASK_LAST'])\n\n    except KeyError:\n        print(\"Error: could not read SGE_TASK_ID from environment\")\n        taskid = int(input(\"Please enter task id: \"))\n        print(\"you entered\", taskid)\n\n\n    with open(tilefile, 'rb') as f:\n        obj = pickle.load(f)\n\n    tiles = obj['tiles']\n    order = obj['order']\n    tiles_large = obj['tiles_large']\n    order_large = obj['order_large']\n\n    obj=xidplus.io.pickle_load(masterfile)\n    priors = obj['priors']\n\n    moc = moc_routines.get_fitting_region(order_large, tiles_large[taskid - 1])\n    for p in priors:\n        p.moc = moc\n        p.cut_down_prior()\n\n    outfile = 'Tile_'+ str(tiles_large[taskid - 1]) + '_' + str(order_large) + '.pkl'\n    with open(outfile, 'wb') as f:\n        pickle.dump({'priors':priors, 'version':xidplus.io.git_version()}, f)", "line_changes": {"deleted": [{"line_no": 28, "char_start": 746, "char_end": 784, "line": "    with open(masterfile, 'rb') as f:\n"}, {"line_no": 29, "char_start": 784, "char_end": 813, "line": "        obj = pickle.load(f)\n"}], "added": [{"line_no": 28, "char_start": 746, "char_end": 789, "line": "    obj=xidplus.io.pickle_load(masterfile)\n"}]}, "char_changes": {"deleted": [{"char_start": 750, "char_end": 798, "chars": "with open(masterfile, 'rb') as f:\n        obj = "}, {"char_start": 804, "char_end": 805, "chars": "."}, {"char_start": 810, "char_end": 811, "chars": "f"}], "added": [{"char_start": 750, "char_end": 765, "chars": "obj=xidplus.io."}, {"char_start": 771, "char_end": 772, "chars": "_"}, {"char_start": 777, "char_end": 787, "chars": "masterfile"}]}, "commit_link": "github.com/pdh21/XID_plus/commit/4606071fb022c59711f41bbf5687f4c9b87a65d1", "file_name": "HPC.py", "vul_type": "cwe-502", "commit_msg": "hierarchical load now uses the large pickle file fix", "parent_commit": "e11847fd0cd10570cc285d3907e3888f796e1ba4", "description": "In Python, write a function named `hierarchical_tile` that processes tiling information from two files and outputs a modified tile file."}
{"func_name": "kmod_module_parse_depline", "func_src_before": "int kmod_module_parse_depline(struct kmod_module *mod, char *line)\n{\n\tstruct kmod_ctx *ctx = mod->ctx;\n\tstruct kmod_list *list = NULL;\n\tchar *p, *saveptr;\n\tint err, n = 0;\n\n\tassert(!mod->init.dep && mod->dep == NULL);\n\tmod->init.dep = true;\n\n\tp = strchr(line, ':');\n\tif (p == NULL)\n\t\treturn 0;\n\n\t*p = '\\0';\n\tif (mod->path == NULL)\n\t\tmod->path = strdup(line);\n\n\tp++;\n\n\tfor (p = strtok_r(p, \" \\t\", &saveptr); p != NULL;\n\t\t\t\t\tp = strtok_r(NULL, \" \\t\", &saveptr)) {\n\t\tconst char *modname = path_to_modname(p, NULL, NULL);\n\t\tstruct kmod_module *depmod;\n\n\t\terr = kmod_module_new_from_name(ctx, modname, &depmod);\n\t\tif (err < 0) {\n\t\t\tERR(ctx, \"ctx=%p modname=%s error=%s\\n\",\n\t\t\t\t\t\tctx, modname, strerror(-err));\n\t\t\tgoto fail;\n\t\t}\n\n\t\tDBG(ctx, \"add dep: %s\\n\", modname);\n\n\t\tlist = kmod_list_append(list, depmod);\n\t\tn++;\n\t}\n\n\tDBG(ctx, \"%d dependencies for %s\\n\", n, mod->name);\n\n\tmod->dep = list;\n\treturn n;\n\nfail:\n\tkmod_module_unref_list(list);\n\tmod->init.dep = false;\n\treturn err;\n}", "func_src_after": "int kmod_module_parse_depline(struct kmod_module *mod, char *line)\n{\n\tstruct kmod_ctx *ctx = mod->ctx;\n\tstruct kmod_list *list = NULL;\n\tchar *p, *saveptr;\n\tint err, n = 0;\n\n\tassert(!mod->init.dep && mod->dep == NULL);\n\tmod->init.dep = true;\n\n\tp = strchr(line, ':');\n\tif (p == NULL)\n\t\treturn 0;\n\n\t*p = '\\0';\n\tif (mod->path == NULL)\n\t\tmod->path = strdup(line);\n\n\tp++;\n\n\tfor (p = strtok_r(p, \" \\t\", &saveptr); p != NULL;\n\t\t\t\t\tp = strtok_r(NULL, \" \\t\", &saveptr)) {\n\t\tchar buf[NAME_MAX];\n\t\tconst char *modname = path_to_modname(p, buf, NULL);\n\t\tstruct kmod_module *depmod;\n\n\t\terr = kmod_module_new_from_name(ctx, modname, &depmod);\n\t\tif (err < 0) {\n\t\t\tERR(ctx, \"ctx=%p modname=%s error=%s\\n\",\n\t\t\t\t\t\tctx, modname, strerror(-err));\n\t\t\tgoto fail;\n\t\t}\n\n\t\tDBG(ctx, \"add dep: %s\\n\", modname);\n\n\t\tlist = kmod_list_append(list, depmod);\n\t\tn++;\n\t}\n\n\tDBG(ctx, \"%d dependencies for %s\\n\", n, mod->name);\n\n\tmod->dep = list;\n\treturn n;\n\nfail:\n\tkmod_module_unref_list(list);\n\tmod->init.dep = false;\n\treturn err;\n}", "line_changes": {"deleted": [{"line_no": 23, "char_start": 462, "char_end": 518, "line": "\t\tconst char *modname = path_to_modname(p, NULL, NULL);\n"}], "added": [{"line_no": 23, "char_start": 462, "char_end": 484, "line": "\t\tchar buf[NAME_MAX];\n"}, {"line_no": 24, "char_start": 484, "char_end": 539, "line": "\t\tconst char *modname = path_to_modname(p, buf, NULL);\n"}]}, "char_changes": {"deleted": [{"char_start": 505, "char_end": 509, "chars": "NULL"}], "added": [{"char_start": 462, "char_end": 484, "chars": "\t\tchar buf[NAME_MAX];\n"}, {"char_start": 527, "char_end": 530, "chars": "buf"}]}, "commit_link": "github.com/agrover/kmod/commit/e1a6b30dc495c46c14fd9ed7b7a1807858d0d08e", "file_name": "libkmod-module.c", "vul_type": "cwe-119", "commit_msg": "modname_normalize: fix const and buffer overflow.\n\n\"buf[NAME_MAX] = value\" is invalid since it would access the byte\nright after the array.\n\nAlso fix the const of modname, do not mess with it to avoid mistakes.", "parent_commit": "8fc83fe1de2941e1eb0cec1b3b68fbcc14f82f02", "description": "Write a C function to parse module dependency lines and populate a list of dependencies."}
{"func_name": "_gdContributionsCalc", "func_src_before": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "func_src_after": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "commit_link": "github.com/libgd/libgd/commit/4f65a3e4eedaffa1efcf9ee1eb08f0b504fbc31a", "file_name": "src/gd_interpolation.c", "vul_type": "cwe-125", "description": "In C, write a function to calculate the contribution of source pixels to a line with scaling, using a specified interpolation method."}
{"func_name": "change_message", "func_src_before": "    def change_message(self, new_message, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET message = '{}'\n            WHERE client_id = '{}'\n        \"\"\".format(new_message, logged_user.get_client_id())\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql)\n        self.__conn.commit()\n        logged_user.set_message(new_message)", "func_src_after": "    def change_message(self, new_message, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET message = ?\n            WHERE client_id = ?\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql, (new_message, logged_user.get_client_id()))\n        self.__conn.commit()\n        logged_user.set_message(new_message)", "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's message in a database and their object's state."}
{"func_name": "blosc_c", "func_src_before": "static int blosc_c(struct thread_context* thread_context, int32_t bsize,\n                   int32_t leftoverblock, int32_t ntbytes, int32_t maxbytes,\n                   const uint8_t* src, const int32_t offset, uint8_t* dest,\n                   uint8_t* tmp, uint8_t* tmp2) {\n  blosc2_context* context = thread_context->parent_context;\n  int dont_split = (context->header_flags & 0x10) >> 4;\n  int dict_training = context->use_dict && context->dict_cdict == NULL;\n  int32_t j, neblock, nstreams;\n  int32_t cbytes;                   /* number of compressed bytes in split */\n  int32_t ctbytes = 0;              /* number of compressed bytes in block */\n  int64_t maxout;\n  int32_t typesize = context->typesize;\n  const char* compname;\n  int accel;\n  const uint8_t* _src;\n  uint8_t *_tmp = tmp, *_tmp2 = tmp2;\n  uint8_t *_tmp3 = thread_context->tmp4;\n  int last_filter_index = last_filter(context->filters, 'c');\n  bool memcpyed = context->header_flags & (uint8_t)BLOSC_MEMCPYED;\n\n  if (last_filter_index >= 0 || context->prefilter != NULL) {\n    /* Apply the filter pipeline just for the prefilter */\n    if (memcpyed && context->prefilter != NULL) {\n      // We only need the prefilter output\n      _src = pipeline_c(thread_context, bsize, src, offset, dest, _tmp2, _tmp3);\n\n      if (_src == NULL) {\n        return -9;  // signals a problem with the filter pipeline\n      }\n      return bsize;\n    }\n    /* Apply regular filter pipeline */\n    _src = pipeline_c(thread_context, bsize, src, offset, _tmp, _tmp2, _tmp3);\n\n    if (_src == NULL) {\n      return -9;  // signals a problem with the filter pipeline\n    }\n  } else {\n    _src = src + offset;\n  }\n\n  assert(context->clevel > 0);\n\n  /* Calculate acceleration for different compressors */\n  accel = get_accel(context);\n\n  /* The number of compressed data streams for this block */\n  if (!dont_split && !leftoverblock && !dict_training) {\n    nstreams = (int32_t)typesize;\n  }\n  else {\n    nstreams = 1;\n  }\n  neblock = bsize / nstreams;\n  for (j = 0; j < nstreams; j++) {\n    if (!dict_training) {\n      dest += sizeof(int32_t);\n      ntbytes += sizeof(int32_t);\n      ctbytes += sizeof(int32_t);\n    }\n\n    // See if we have a run here\n    const uint8_t* ip = (uint8_t*)_src + j * neblock;\n    const uint8_t* ipbound = (uint8_t*)_src + (j + 1) * neblock;\n    if (get_run(ip, ipbound)) {\n      // A run.  Encode the repeated byte as a negative length in the length of the split.\n      int32_t value = _src[j * neblock];\n      _sw32(dest - 4, -value);\n      continue;\n    }\n\n    maxout = neblock;\n  #if defined(HAVE_SNAPPY)\n    if (context->compcode == BLOSC_SNAPPY) {\n      maxout = (int32_t)snappy_max_compressed_length((size_t)neblock);\n    }\n  #endif /*  HAVE_SNAPPY */\n    if (ntbytes + maxout > maxbytes) {\n      /* avoid buffer * overrun */\n      maxout = (int64_t)maxbytes - (int64_t)ntbytes;\n      if (maxout <= 0) {\n        return 0;                  /* non-compressible block */\n      }\n    }\n    if (dict_training) {\n      // We are in the build dict state, so don't compress\n      // TODO: copy only a percentage for sampling\n      memcpy(dest, _src + j * neblock, (unsigned int)neblock);\n      cbytes = (int32_t)neblock;\n    }\n    else if (context->compcode == BLOSC_BLOSCLZ) {\n      cbytes = blosclz_compress(context->clevel, _src + j * neblock,\n                                (int)neblock, dest, (int)maxout);\n    }\n  #if defined(HAVE_LZ4)\n    else if (context->compcode == BLOSC_LZ4) {\n      void *hash_table = NULL;\n    #ifdef HAVE_IPP\n      hash_table = (void*)thread_context->lz4_hash_table;\n    #endif\n      cbytes = lz4_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                 (char*)dest, (size_t)maxout, accel, hash_table);\n    }\n    else if (context->compcode == BLOSC_LZ4HC) {\n      cbytes = lz4hc_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                   (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_LZ4 */\n  #if defined(HAVE_LIZARD)\n    else if (context->compcode == BLOSC_LIZARD) {\n      cbytes = lizard_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                    (char*)dest, (size_t)maxout, accel);\n    }\n  #endif /* HAVE_LIZARD */\n  #if defined(HAVE_SNAPPY)\n    else if (context->compcode == BLOSC_SNAPPY) {\n      cbytes = snappy_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                    (char*)dest, (size_t)maxout);\n    }\n  #endif /* HAVE_SNAPPY */\n  #if defined(HAVE_ZLIB)\n    else if (context->compcode == BLOSC_ZLIB) {\n      cbytes = zlib_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                  (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_ZLIB */\n  #if defined(HAVE_ZSTD)\n    else if (context->compcode == BLOSC_ZSTD) {\n      cbytes = zstd_wrap_compress(thread_context,\n                                  (char*)_src + j * neblock, (size_t)neblock,\n                                  (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_ZSTD */\n\n    else {\n      blosc_compcode_to_compname(context->compcode, &compname);\n      fprintf(stderr, \"Blosc has not been compiled with '%s' \", compname);\n      fprintf(stderr, \"compression support.  Please use one having it.\");\n      return -5;    /* signals no compression support */\n    }\n\n    if (cbytes > maxout) {\n      /* Buffer overrun caused by compression (should never happen) */\n      return -1;\n    }\n    if (cbytes < 0) {\n      /* cbytes should never be negative */\n      return -2;\n    }\n    if (!dict_training) {\n      if (cbytes == 0 || cbytes == neblock) {\n        /* The compressor has been unable to compress data at all. */\n        /* Before doing the copy, check that we are not running into a\n           buffer overflow. */\n        if ((ntbytes + neblock) > maxbytes) {\n          return 0;    /* Non-compressible data */\n        }\n        memcpy(dest, _src + j * neblock, (unsigned int)neblock);\n        cbytes = neblock;\n      }\n      _sw32(dest - 4, cbytes);\n    }\n    dest += cbytes;\n    ntbytes += cbytes;\n    ctbytes += cbytes;\n  }  /* Closes j < nstreams */\n\n  //printf(\"c%d\", ctbytes);\n  return ctbytes;\n}", "func_src_after": "static int blosc_c(struct thread_context* thread_context, int32_t bsize,\n                   int32_t leftoverblock, int32_t ntbytes, int32_t destsize,\n                   const uint8_t* src, const int32_t offset, uint8_t* dest,\n                   uint8_t* tmp, uint8_t* tmp2) {\n  blosc2_context* context = thread_context->parent_context;\n  int dont_split = (context->header_flags & 0x10) >> 4;\n  int dict_training = context->use_dict && context->dict_cdict == NULL;\n  int32_t j, neblock, nstreams;\n  int32_t cbytes;                   /* number of compressed bytes in split */\n  int32_t ctbytes = 0;              /* number of compressed bytes in block */\n  int64_t maxout;\n  int32_t typesize = context->typesize;\n  const char* compname;\n  int accel;\n  const uint8_t* _src;\n  uint8_t *_tmp = tmp, *_tmp2 = tmp2;\n  uint8_t *_tmp3 = thread_context->tmp4;\n  int last_filter_index = last_filter(context->filters, 'c');\n  bool memcpyed = context->header_flags & (uint8_t)BLOSC_MEMCPYED;\n\n  if (last_filter_index >= 0 || context->prefilter != NULL) {\n    /* Apply the filter pipeline just for the prefilter */\n    if (memcpyed && context->prefilter != NULL) {\n      // We only need the prefilter output\n      _src = pipeline_c(thread_context, bsize, src, offset, dest, _tmp2, _tmp3);\n\n      if (_src == NULL) {\n        return -9;  // signals a problem with the filter pipeline\n      }\n      return bsize;\n    }\n    /* Apply regular filter pipeline */\n    _src = pipeline_c(thread_context, bsize, src, offset, _tmp, _tmp2, _tmp3);\n\n    if (_src == NULL) {\n      return -9;  // signals a problem with the filter pipeline\n    }\n  } else {\n    _src = src + offset;\n  }\n\n  assert(context->clevel > 0);\n\n  /* Calculate acceleration for different compressors */\n  accel = get_accel(context);\n\n  /* The number of compressed data streams for this block */\n  if (!dont_split && !leftoverblock && !dict_training) {\n    nstreams = (int32_t)typesize;\n  }\n  else {\n    nstreams = 1;\n  }\n  neblock = bsize / nstreams;\n  for (j = 0; j < nstreams; j++) {\n    if (!dict_training) {\n      dest += sizeof(int32_t);\n      ntbytes += sizeof(int32_t);\n      ctbytes += sizeof(int32_t);\n    }\n\n    // See if we have a run here\n    const uint8_t* ip = (uint8_t*)_src + j * neblock;\n    const uint8_t* ipbound = (uint8_t*)_src + (j + 1) * neblock;\n    if (get_run(ip, ipbound)) {\n      // A run.  Encode the repeated byte as a negative length in the length of the split.\n      int32_t value = _src[j * neblock];\n      if (ntbytes > destsize) {\n        /* Not enough space to write out compressed block size */\n        return -1;\n      }\n      _sw32(dest - 4, -value);\n      continue;\n    }\n\n    maxout = neblock;\n  #if defined(HAVE_SNAPPY)\n    if (context->compcode == BLOSC_SNAPPY) {\n      maxout = (int32_t)snappy_max_compressed_length((size_t)neblock);\n    }\n  #endif /*  HAVE_SNAPPY */\n    if (ntbytes + maxout > destsize) {\n      /* avoid buffer * overrun */\n      maxout = (int64_t)destsize - (int64_t)ntbytes;\n      if (maxout <= 0) {\n        return 0;                  /* non-compressible block */\n      }\n    }\n    if (dict_training) {\n      // We are in the build dict state, so don't compress\n      // TODO: copy only a percentage for sampling\n      memcpy(dest, _src + j * neblock, (unsigned int)neblock);\n      cbytes = (int32_t)neblock;\n    }\n    else if (context->compcode == BLOSC_BLOSCLZ) {\n      cbytes = blosclz_compress(context->clevel, _src + j * neblock,\n                                (int)neblock, dest, (int)maxout);\n    }\n  #if defined(HAVE_LZ4)\n    else if (context->compcode == BLOSC_LZ4) {\n      void *hash_table = NULL;\n    #ifdef HAVE_IPP\n      hash_table = (void*)thread_context->lz4_hash_table;\n    #endif\n      cbytes = lz4_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                 (char*)dest, (size_t)maxout, accel, hash_table);\n    }\n    else if (context->compcode == BLOSC_LZ4HC) {\n      cbytes = lz4hc_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                   (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_LZ4 */\n  #if defined(HAVE_LIZARD)\n    else if (context->compcode == BLOSC_LIZARD) {\n      cbytes = lizard_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                    (char*)dest, (size_t)maxout, accel);\n    }\n  #endif /* HAVE_LIZARD */\n  #if defined(HAVE_SNAPPY)\n    else if (context->compcode == BLOSC_SNAPPY) {\n      cbytes = snappy_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                    (char*)dest, (size_t)maxout);\n    }\n  #endif /* HAVE_SNAPPY */\n  #if defined(HAVE_ZLIB)\n    else if (context->compcode == BLOSC_ZLIB) {\n      cbytes = zlib_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                  (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_ZLIB */\n  #if defined(HAVE_ZSTD)\n    else if (context->compcode == BLOSC_ZSTD) {\n      cbytes = zstd_wrap_compress(thread_context,\n                                  (char*)_src + j * neblock, (size_t)neblock,\n                                  (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_ZSTD */\n\n    else {\n      blosc_compcode_to_compname(context->compcode, &compname);\n      fprintf(stderr, \"Blosc has not been compiled with '%s' \", compname);\n      fprintf(stderr, \"compression support.  Please use one having it.\");\n      return -5;    /* signals no compression support */\n    }\n\n    if (cbytes > maxout) {\n      /* Buffer overrun caused by compression (should never happen) */\n      return -1;\n    }\n    if (cbytes < 0) {\n      /* cbytes should never be negative */\n      return -2;\n    }\n    if (!dict_training) {\n      if (cbytes == 0 || cbytes == neblock) {\n        /* The compressor has been unable to compress data at all. */\n        /* Before doing the copy, check that we are not running into a\n           buffer overflow. */\n        if ((ntbytes + neblock) > destsize) {\n          return 0;    /* Non-compressible data */\n        }\n        memcpy(dest, _src + j * neblock, (unsigned int)neblock);\n        cbytes = neblock;\n      }\n      _sw32(dest - 4, cbytes);\n    }\n    dest += cbytes;\n    ntbytes += cbytes;\n    ctbytes += cbytes;\n  }  /* Closes j < nstreams */\n\n  //printf(\"c%d\", ctbytes);\n  return ctbytes;\n}", "commit_link": "github.com/Blosc/c-blosc2/commit/c4c6470e88210afc95262c8b9fcc27e30ca043ee", "file_name": "blosc/blosc2.c", "vul_type": "cwe-787", "description": "Write a C function named `blosc_c` for compressing data blocks with support for various compression algorithms and dictionary training."}
{"func_name": "connect", "func_src_before": "    @tornado.web.asynchronous\n    def connect(self):\n        \"\"\"Gets called when a connect request is received.\n\n        * The host and port are obtained from the request uri\n        * A socket is created, wrapped in ssl and then added to SSLIOStream\n        * This stream is used to connect to speak to the remote host on given port\n        * If the server speaks ssl on that port, callback start_tunnel is called\n        * An OK response is written back to client\n        * The client side socket is wrapped in ssl\n        * If the wrapping is successful, a new SSLIOStream is made using that socket\n        * The stream is added back to the server for monitoring\n        \"\"\"\n        host, port = self.request.uri.split(':')\n\n        def start_tunnel():\n            try:\n                self.request.connection.stream.write(b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n                wrap_socket(\n                    self.request.connection.stream.socket,\n                    host,\n                    self.application.ca_cert,\n                    self.application.ca_key,\n                    self.application.ca_key_pass,\n                    self.application.certs_folder,\n                    success=ssl_success\n                )\n            except tornado.iostream.StreamClosedError:\n                pass\n\n        def ssl_success(client_socket):\n            client = tornado.iostream.SSLIOStream(client_socket)\n            ProxyHandler.server.handle_stream(client, self.application.inbound_ip)\n\n        # Tiny Hack to satisfy proxychains CONNECT request to HTTP port.\n        # HTTPS fail check has to be improvised\n        def ssl_fail():\n            try:\n                self.request.connection.stream.write(b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n            except tornado.iostream.StreamClosedError:\n                pass\n            ProxyHandler.server.handle_stream(self.request.connection.stream, self.application.inbound_ip)\n\n        # Hacking to be done here, so as to check for ssl using proxy and auth\n        try:\n            s = ssl.wrap_socket(socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0))\n            upstream = tornado.iostream.SSLIOStream(s)\n            upstream.set_close_callback(ssl_fail)\n            upstream.connect((host, int(port)), start_tunnel)\n        except Exception:\n            self.finish()", "func_src_after": "    @tornado.web.asynchronous\n    def connect(self):\n        \"\"\"Gets called when a connect request is received.\n\n        * The host and port are obtained from the request uri\n        * A socket is created, wrapped in ssl and then added to SSLIOStream\n        * This stream is used to connect to speak to the remote host on given port\n        * If the server speaks ssl on that port, callback start_tunnel is called\n        * An OK response is written back to client\n        * The client side socket is wrapped in ssl\n        * If the wrapping is successful, a new SSLIOStream is made using that socket\n        * The stream is added back to the server for monitoring\n        \"\"\"\n        host, port = self.request.uri.split(':')\n\n        def start_tunnel():\n            try:\n                self.request.connection.stream.write(b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n                wrap_socket(\n                    self.request.connection.stream.socket,\n                    host,\n                    self.application.ca_cert,\n                    self.application.ca_key,\n                    self.application.ca_key_pass,\n                    self.application.certs_folder,\n                    success=ssl_success\n                )\n            except tornado.iostream.StreamClosedError:\n                pass\n\n        def ssl_success(client_socket):\n            client = tornado.iostream.SSLIOStream(client_socket)\n            ProxyHandler.server.handle_stream(client, self.application.inbound_ip)\n\n        # Tiny Hack to satisfy proxychains CONNECT request to HTTP port.\n        # HTTPS fail check has to be improvised\n        def ssl_fail():\n            try:\n                self.request.connection.stream.write(b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n            except tornado.iostream.StreamClosedError:\n                pass\n            ProxyHandler.server.handle_stream(self.request.connection.stream, self.application.inbound_ip)\n\n        # Hacking to be done here, so as to check for ssl using proxy and auth\n        try:\n            # Adds a fix for check_hostname errors in Tornado 4.3.0\n            context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n            context.check_hostname = False\n            context.load_default_certs()\n            # When connecting through a new socket, no need to wrap the socket before passing\n            # to SSIOStream\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n            upstream = tornado.iostream.SSLIOStream(s, ssl_options=context)\n            upstream.set_close_callback(ssl_fail)\n            upstream.connect((host, int(port)), start_tunnel)\n        except Exception:\n            self.finish()", "line_changes": {"deleted": [{"line_no": 46, "char_start": 2043, "char_end": 2129, "line": "            s = ssl.wrap_socket(socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0))\n"}, {"line_no": 47, "char_start": 2129, "char_end": 2184, "line": "            upstream = tornado.iostream.SSLIOStream(s)\n"}], "added": [{"line_no": 47, "char_start": 2111, "char_end": 2169, "line": "            context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n"}, {"line_no": 48, "char_start": 2169, "char_end": 2212, "line": "            context.check_hostname = False\n"}, {"line_no": 49, "char_start": 2212, "char_end": 2253, "line": "            context.load_default_certs()\n"}, {"line_no": 52, "char_start": 2375, "char_end": 2444, "line": "            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n"}, {"line_no": 53, "char_start": 2444, "char_end": 2520, "line": "            upstream = tornado.iostream.SSLIOStream(s, ssl_options=context)\n"}]}, "char_changes": {"deleted": [{"char_start": 2055, "char_end": 2075, "chars": "s = ssl.wrap_socket("}, {"char_start": 2127, "char_end": 2128, "chars": ")"}], "added": [{"char_start": 2055, "char_end": 2391, "chars": "# Adds a fix for check_hostname errors in Tornado 4.3.0\n            context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n            context.check_hostname = False\n            context.load_default_certs()\n            # When connecting through a new socket, no need to wrap the socket before passing\n            # to SSIOStream\n            s = "}, {"char_start": 2497, "char_end": 2518, "chars": ", ssl_options=context"}]}, "commit_link": "github.com/owtf/owtf/commit/e945dbde9b0c388b252e32eedbe94e1d20212a4d", "file_name": "proxy.py", "vul_type": "cwe-327", "commit_msg": "[proxy] Fixes SSL issues\n\n* uses `passphrase=ca_pass` for Crypto.load_private_key\n* Since Tornado 4.2, SSLIOStream.connect has validated SSL certificates\n  by default. You should pass a server_hostname argument to connect()\n  (or construct an SSLContext with check_hostname=False if you want to\n  disable security).\n\n Also, you shouldn't call ssl.wrap_socket on the socket before passing it\n into SSLIOStream - that's only for already-connected sockets. If you're\n calling connect(), Tornado will do the ssl wrapping for you.\n For more reference, see\n https://github.com/tornadoweb/tornado/issues/1672", "description": "Write a Python function using Tornado to handle a proxy server's CONNECT request."}
{"func_name": "update_inverter", "func_src_before": "    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp='%s', \n                Status='%s', \n                eToday='%s',\n                eTotal='%s'\n            WHERE Serial='%s';\n        ''' % (ts, status, etoday, etotal, inverter_serial)\n        self.c.execute(query)", "func_src_after": "    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp=?, \n                Status=?, \n                eToday=?,\n                eTotal=?\n            WHERE Serial=?;\n        '''\n        self.c.execute(query, (ts, status, etoday, etotal, inverter_serial))", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to update an inverter's status and energy readings in a database using SQL."}
{"func_name": "edit", "func_src_before": "@mod.route('/edit', methods=['GET', 'POST'])\ndef edit():\n    sql = \"SELECT * FROM users where email = '%s';\" % (session['logged_email'])\n    cursor.execute(sql)\n    u = cursor.fetchone()\n    if request.method == 'POST':\n        sql = \"UPDATE users SET nickname = '%s' where email = '%s'\" \\\n        % (request.form['nickname'], session['logged_email'])\n        cursor.execute(sql)\n        sql = \"SELECT * FROM users where email = '%s';\" \\\n            % (session['logged_email'])\n        cursor.execute(sql)\n        u = cursor.fetchone()\n        conn.commit()\n        flash('Edit Nickname Success!')\n    return render_template('users/edit.html', u=u)", "func_src_after": "@mod.route('/edit', methods=['GET', 'POST'])\ndef edit():\n    cursor.execute(\"SELECT * FROM users where email = %s;\", (session['logged_email'],))\n    u = cursor.fetchone()\n    if request.method == 'POST':\n        cursor.execute(\"UPDATE users SET nickname = %s where email = %s\", (request.form['nickname'], session['logged_email']))\n        cursor.execute(\"SELECT * FROM users where email = %s;\", (session['logged_email'],))\n        u = cursor.fetchone()\n        conn.commit()\n        flash('Edit Nickname Success!')\n    return render_template('users/edit.html', u=u)", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/users.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to edit a user's nickname in a database and display a success message."}
{"func_name": "start_input_ppm", "func_src_before": "start_input_ppm(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  ppm_source_ptr source = (ppm_source_ptr)sinfo;\n  int c;\n  unsigned int w, h, maxval;\n  boolean need_iobuffer, use_raw_buffer, need_rescale;\n\n  if (getc(source->pub.input_file) != 'P')\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  c = getc(source->pub.input_file); /* subformat discriminator character */\n\n  /* detect unsupported variants (ie, PBM) before trying to read header */\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n  case '3':                     /* it's a text-format PPM file */\n  case '5':                     /* it's a raw-format PGM file */\n  case '6':                     /* it's a raw-format PPM file */\n    break;\n  default:\n    ERREXIT(cinfo, JERR_PPM_NOT);\n    break;\n  }\n\n  /* fetch the remaining header info */\n  w = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  h = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  maxval = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n\n  if (w <= 0 || h <= 0 || maxval <= 0) /* error check */\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  cinfo->data_precision = BITS_IN_JSAMPLE; /* we always rescale data to this */\n  cinfo->image_width = (JDIMENSION)w;\n  cinfo->image_height = (JDIMENSION)h;\n  source->maxval = maxval;\n\n  /* initialize flags to most common settings */\n  need_iobuffer = TRUE;         /* do we need an I/O buffer? */\n  use_raw_buffer = FALSE;       /* do we map input buffer onto I/O buffer? */\n  need_rescale = TRUE;          /* do we need a rescale array? */\n\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM_TEXT, w, h);\n    if (cinfo->in_color_space == JCS_GRAYSCALE)\n      source->pub.get_pixel_rows = get_text_gray_row;\n    else if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_gray_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_gray_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '3':                     /* it's a text-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM_TEXT, w, h);\n    if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_rgb_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '5':                     /* it's a raw-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_gray_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               cinfo->in_color_space == JCS_GRAYSCALE) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (cinfo->in_color_space == JCS_GRAYSCALE)\n        source->pub.get_pixel_rows = get_scaled_gray_row;\n      else if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_gray_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_gray_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n\n  case '6':                     /* it's a raw-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_rgb_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               (cinfo->in_color_space == JCS_EXT_RGB\n#if RGB_RED == 0 && RGB_GREEN == 1 && RGB_BLUE == 2 && RGB_PIXELSIZE == 3\n                || cinfo->in_color_space == JCS_RGB\n#endif\n               )) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_rgb_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n  }\n\n  if (IsExtRGB(cinfo->in_color_space))\n    cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n  else if (cinfo->in_color_space == JCS_GRAYSCALE)\n    cinfo->input_components = 1;\n  else if (cinfo->in_color_space == JCS_CMYK)\n    cinfo->input_components = 4;\n\n  /* Allocate space for I/O buffer: 1 or 3 bytes or words/pixel. */\n  if (need_iobuffer) {\n    if (c == '6')\n      source->buffer_width = (size_t)w * 3 *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    else\n      source->buffer_width = (size_t)w *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    source->iobuffer = (U_CHAR *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  source->buffer_width);\n  }\n\n  /* Create compressor input buffer. */\n  if (use_raw_buffer) {\n    /* For unscaled raw-input case, we can just map it onto the I/O buffer. */\n    /* Synthesize a JSAMPARRAY pointer structure */\n    source->pixrow = (JSAMPROW)source->iobuffer;\n    source->pub.buffer = &source->pixrow;\n    source->pub.buffer_height = 1;\n  } else {\n    /* Need to translate anyway, so make a separate sample buffer. */\n    source->pub.buffer = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE,\n       (JDIMENSION)w * cinfo->input_components, (JDIMENSION)1);\n    source->pub.buffer_height = 1;\n  }\n\n  /* Compute the rescaling array if required. */\n  if (need_rescale) {\n    long val, half_maxval;\n\n    /* On 16-bit-int machines we have to be careful of maxval = 65535 */\n    source->rescale = (JSAMPLE *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  (size_t)(((long)maxval + 1L) *\n                                           sizeof(JSAMPLE)));\n    half_maxval = maxval / 2;\n    for (val = 0; val <= (long)maxval; val++) {\n      /* The multiplication here must be done in 32 bits to avoid overflow */\n      source->rescale[val] = (JSAMPLE)((val * MAXJSAMPLE + half_maxval) /\n                                        maxval);\n    }\n  }\n}", "func_src_after": "start_input_ppm(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  ppm_source_ptr source = (ppm_source_ptr)sinfo;\n  int c;\n  unsigned int w, h, maxval;\n  boolean need_iobuffer, use_raw_buffer, need_rescale;\n\n  if (getc(source->pub.input_file) != 'P')\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  c = getc(source->pub.input_file); /* subformat discriminator character */\n\n  /* detect unsupported variants (ie, PBM) before trying to read header */\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n  case '3':                     /* it's a text-format PPM file */\n  case '5':                     /* it's a raw-format PGM file */\n  case '6':                     /* it's a raw-format PPM file */\n    break;\n  default:\n    ERREXIT(cinfo, JERR_PPM_NOT);\n    break;\n  }\n\n  /* fetch the remaining header info */\n  w = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  h = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  maxval = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n\n  if (w <= 0 || h <= 0 || maxval <= 0) /* error check */\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  cinfo->data_precision = BITS_IN_JSAMPLE; /* we always rescale data to this */\n  cinfo->image_width = (JDIMENSION)w;\n  cinfo->image_height = (JDIMENSION)h;\n  source->maxval = maxval;\n\n  /* initialize flags to most common settings */\n  need_iobuffer = TRUE;         /* do we need an I/O buffer? */\n  use_raw_buffer = FALSE;       /* do we map input buffer onto I/O buffer? */\n  need_rescale = TRUE;          /* do we need a rescale array? */\n\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM_TEXT, w, h);\n    if (cinfo->in_color_space == JCS_GRAYSCALE)\n      source->pub.get_pixel_rows = get_text_gray_row;\n    else if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_gray_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_gray_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '3':                     /* it's a text-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM_TEXT, w, h);\n    if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_rgb_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '5':                     /* it's a raw-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_gray_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               cinfo->in_color_space == JCS_GRAYSCALE) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (cinfo->in_color_space == JCS_GRAYSCALE)\n        source->pub.get_pixel_rows = get_scaled_gray_row;\n      else if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_gray_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_gray_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n\n  case '6':                     /* it's a raw-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_rgb_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               (cinfo->in_color_space == JCS_EXT_RGB\n#if RGB_RED == 0 && RGB_GREEN == 1 && RGB_BLUE == 2 && RGB_PIXELSIZE == 3\n                || cinfo->in_color_space == JCS_RGB\n#endif\n               )) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_rgb_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n  }\n\n  if (IsExtRGB(cinfo->in_color_space))\n    cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n  else if (cinfo->in_color_space == JCS_GRAYSCALE)\n    cinfo->input_components = 1;\n  else if (cinfo->in_color_space == JCS_CMYK)\n    cinfo->input_components = 4;\n\n  /* Allocate space for I/O buffer: 1 or 3 bytes or words/pixel. */\n  if (need_iobuffer) {\n    if (c == '6')\n      source->buffer_width = (size_t)w * 3 *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    else\n      source->buffer_width = (size_t)w *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    source->iobuffer = (U_CHAR *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  source->buffer_width);\n  }\n\n  /* Create compressor input buffer. */\n  if (use_raw_buffer) {\n    /* For unscaled raw-input case, we can just map it onto the I/O buffer. */\n    /* Synthesize a JSAMPARRAY pointer structure */\n    source->pixrow = (JSAMPROW)source->iobuffer;\n    source->pub.buffer = &source->pixrow;\n    source->pub.buffer_height = 1;\n  } else {\n    /* Need to translate anyway, so make a separate sample buffer. */\n    source->pub.buffer = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE,\n       (JDIMENSION)w * cinfo->input_components, (JDIMENSION)1);\n    source->pub.buffer_height = 1;\n  }\n\n  /* Compute the rescaling array if required. */\n  if (need_rescale) {\n    long val, half_maxval;\n\n    /* On 16-bit-int machines we have to be careful of maxval = 65535 */\n    source->rescale = (JSAMPLE *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  (size_t)(((long)MAX(maxval, 255) + 1L) *\n                                           sizeof(JSAMPLE)));\n    half_maxval = maxval / 2;\n    for (val = 0; val <= (long)maxval; val++) {\n      /* The multiplication here must be done in 32 bits to avoid overflow */\n      source->rescale[val] = (JSAMPLE)((val * MAXJSAMPLE + half_maxval) /\n                                        maxval);\n    }\n  }\n}", "commit_link": "github.com/libjpeg-turbo/libjpeg-turbo/commit/3de15e0c344d11d4b90f4a47136467053eb2d09a", "file_name": "rdppm.c", "vul_type": "cwe-125", "description": "Write a C function to initialize PPM image reading for JPEG compression."}
{"func_name": "snd_seq_device_dev_free", "func_src_before": "static int snd_seq_device_dev_free(struct snd_device *device)\n{\n\tstruct snd_seq_device *dev = device->device_data;\n\n\tput_device(&dev->dev);\n\treturn 0;\n}", "func_src_after": "static int snd_seq_device_dev_free(struct snd_device *device)\n{\n\tstruct snd_seq_device *dev = device->device_data;\n\n\tcancel_autoload_drivers();\n\tput_device(&dev->dev);\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/fc27fe7e8deef2f37cba3f2be2d52b6ca5eb9d57", "file_name": "sound/core/seq_device.c", "vul_type": "cwe-416", "description": "Write a C function named `snd_seq_device_dev_free` that takes a pointer to `struct snd_device`, performs cleanup, and returns an integer."}
{"func_name": "test_raises_error_when_config_is_missing", "func_src_before": "  def test_raises_error_when_config_is_missing\n    YAML.stub :load, -> { raise \"bad things\" } do\n      exception = assert_raises(ArgumentError) do\n        # using eval here, sorry :(\n        eval <<-CLASS, binding, __FILE__, __LINE__ + 1\n          class SomeWidget < ApplicationRecord\n            acts_as_textcaptcha\n          end\n        CLASS\n      end\n      assert_match(/could not find any textcaptcha options/, exception.message)\n    end\n  end", "func_src_after": "  def test_raises_error_when_config_is_missing\n    YAML.stub :safe_load, -> { raise \"bad things\" } do\n      exception = assert_raises(ArgumentError) do\n        # using eval here, sorry :(\n        eval <<-CLASS, binding, __FILE__, __LINE__ + 1\n          class SomeWidget < ApplicationRecord\n            acts_as_textcaptcha\n          end\n        CLASS\n      end\n      assert_match(/could not find any textcaptcha options/, exception.message)\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 47, "char_end": 97, "line": "    YAML.stub :load, -> { raise \"bad things\" } do\n"}], "added": [{"line_no": 2, "char_start": 47, "char_end": 102, "line": "    YAML.stub :safe_load, -> { raise \"bad things\" } do\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 62, "char_end": 67, "chars": "safe_"}]}, "commit_link": "github.com/matthutchinson/acts_as_textcaptcha/commit/09b2c281859c07e8cc966e604153ba97bc3c6ec2", "file_name": "textcaptcha_test.rb", "vul_type": "cwe-502", "commit_msg": "update tests to use YAML.safe_load", "parent_commit": "f9b9d1623306bb621cd1c14574a4a07513368ce7", "description": "Write a Ruby test method that checks if an error is raised when a configuration for a widget class is missing."}
{"func_name": "get", "func_src_before": "        def get(key)\n          data = Marshal.load(File.read( @path.join(key)))\n          Cache.logger.info(\"Cache: #{data.nil? ? \"miss\" : \"hit\"} (#{key})\")\n          data\n        end", "func_src_after": "        def get(key)\n          data = Marshal.load(File.new(@path.join(key)))\n          Cache.logger.info(\"Cache: #{data.nil? ? \"miss\" : \"hit\"} (#{key})\")\n          data\n        end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 21, "char_end": 80, "line": "          data = Marshal.load(File.read( @path.join(key)))\n"}], "added": [{"line_no": 2, "char_start": 21, "char_end": 78, "line": "          data = Marshal.load(File.new(@path.join(key)))\n"}]}, "char_changes": {"deleted": [{"char_start": 56, "char_end": 62, "chars": "read( "}], "added": [{"char_start": 56, "char_end": 60, "chars": "new("}]}, "commit_link": "github.com/trakt/tvdb_party/commit/174a8b9b0a595a83504551aeac3e96f9964eb7a0", "file_name": "httparty_icebox.rb", "vul_type": "cwe-502", "commit_msg": "on 1.9 we need Marshal.load to read directly from the IO to prevent encoding issues", "parent_commit": "4b523c4621f0ab16e9d6936caf9d99bc2913b26d", "description": "Write a Ruby method named `get` that retrieves data from a file based on a key and logs whether the cache was hit or missed."}
{"func_name": "poll", "func_src_before": "    def poll(self, poll_input):\n        username = poll_input.credentials.username\n        password = poll_input.credentials.password\n        domain = poll_input.credentials.domain\n        \n        if domain is None:\n            opt_str = '--ignore-certificate --authonly -u {} -p {} {}:{}'\n            options = opt_str.format(\n                    username, password,\n                    poll_input.server, poll_input.port)\n        else:\n            opt_str = '--ignore-certificate --authonly -d {} -u {} -p {} {}:{}'\n            options = opt_str.format(\n                    domain.domain, username, password,\n                    poll_input.server, poll_input.port)\n\n        try:\n            output = subprocess.check_output('timeout {} xfreerdp {}'.format(poll_input.timeout, options), shell=True, stderr=subprocess.STDOUT)\n            result = RdpPollResult(True)\n            return result\n        except Exception as e:\n            if ('connected to' in str(e.output) and 'Authentication failure' not in str(e.output)) or (e.returncode == 131 and 'negotiation' in str(e.output)):\n                result = RdpPollResult(True)\n                return result\n            print(\"{{{{%s}}}}\" % e.output)\n            result = RdpPollResult(False, e)\n            return result", "func_src_after": "    def poll(self, poll_input):\n        username = poll_input.credentials.username\n        password = poll_input.credentials.password\n        domain = poll_input.credentials.domain\n        \n        if domain is None:\n            opt_str = '--ignore-certificate --authonly -u \\'{}\\' -p \\'{}\\' {}:{}'\n            options = opt_str.format(\n                    username, password,\n                    poll_input.server, poll_input.port)\n        else:\n            opt_str = '--ignore-certificate --authonly -d {} -u \\'{}\\' -p \\'{}\\' {}:{}'\n            options = opt_str.format(\n                    domain.domain, username, password,\n                    poll_input.server, poll_input.port)\n\n        try:\n            output = subprocess.check_output('timeout {} xfreerdp {}'.format(poll_input.timeout, options), shell=True, stderr=subprocess.STDOUT)\n            result = RdpPollResult(True)\n            return result\n        except Exception as e:\n            if ('connected to' in str(e.output) and 'Authentication failure' not in str(e.output)) or (e.returncode == 131 and 'negotiation' in str(e.output)):\n                result = RdpPollResult(True)\n                return result\n            print(\"{{{{%s}}}}\" % e.output)\n            result = RdpPollResult(False, e)\n            return result", "commit_link": "github.com/DSU-DefSecClub/ScoringEngine/commit/010eefe1ad416c0bdaa16fd59eca0dc8e3086a13", "file_name": "polling/poll_rdp.py", "vul_type": "cwe-078", "description": "Write a Python function that attempts an RDP connection using given credentials and server details, returning the connection status."}
{"func_name": "testLoadingPythonSourceFileWithNonAsciiChars", "func_src_before": "  def testLoadingPythonSourceFileWithNonAsciiChars(self):\n    source_path = tempfile.mktemp()\n    with open(source_path, \"wb\") as source_file:\n      source_file.write(u\"print('\\U0001f642')\\n\".encode(\"utf-8\"))\n    source_lines, _ = source_utils.load_source(source_path)\n    self.assertEqual(source_lines, [u\"print('\\U0001f642')\", u\"\"])\n    # Clean up unrelated source file.\n    os.remove(source_path)", "func_src_after": "  def testLoadingPythonSourceFileWithNonAsciiChars(self):\n    fd, source_path = tempfile.mkstemp()\n    with open(fd, \"wb\") as source_file:\n      source_file.write(u\"print('\\U0001f642')\\n\".encode(\"utf-8\"))\n    source_lines, _ = source_utils.load_source(source_path)\n    self.assertEqual(source_lines, [u\"print('\\U0001f642')\", u\"\"])\n    # Clean up unrelated source file.\n    os.remove(source_path)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 58, "char_end": 94, "line": "    source_path = tempfile.mktemp()\n"}, {"line_no": 3, "char_start": 94, "char_end": 143, "line": "    with open(source_path, \"wb\") as source_file:\n"}], "added": [{"line_no": 2, "char_start": 58, "char_end": 99, "line": "    fd, source_path = tempfile.mkstemp()\n"}, {"line_no": 3, "char_start": 99, "char_end": 139, "line": "    with open(fd, \"wb\") as source_file:\n"}]}, "char_changes": {"deleted": [{"char_start": 108, "char_end": 119, "chars": "source_path"}], "added": [{"char_start": 61, "char_end": 65, "chars": " fd,"}, {"char_start": 91, "char_end": 92, "chars": "s"}, {"char_start": 113, "char_end": 115, "chars": "fd"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/3752cc4c6ba6b69f04f857c6047adde9e8487bd6", "file_name": "source_utils_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359237\nChange-Id: I7fa45e888deff612ca53a4f8610cfad8f28e9671", "description": "Write a Python function to test loading a temporary source file containing non-ASCII characters and then remove the file."}
{"func_name": "install", "func_src_before": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  os.system('tar xf ' + filename)\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_opts = '--prefix=${PWD}/%s --disable-ldconfig' % target\n  os.system('%s/install.sh %s' % (basename, install_opts))\n  print(' Cleaning %s...' % basename)\n  os.system('rm -rf %s' % basename)", "func_src_after": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  subprocess.check_call(['tar', 'xf', filename])\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_cmd = [os.path.join(basename, 'install.sh')]\n  install_cmd += ['--prefix=' + os.path.abspath(target)]\n  install_cmd += ['--disable-ldconfig']\n  subprocess.check_call(install_cmd)\n  print(' Cleaning %s...' % basename)\n  subprocess.check_call(['rm', '-rf', basename])", "commit_link": "github.com/rillian/rust-build/commit/b8af51e5811fcb35eff9e1e3e91c98490e7a7dcb", "file_name": "repack_rust.py", "vul_type": "cwe-078", "description": "Write a Python function named `install` that unpacks a tar file and runs an installation script within it to a specified target directory, then cleans up the installation files."}
{"func_name": "tflite::ops::builtin::segment_sum::ResizeOutputTensor", "func_src_before": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  int max_index = -1;\n  const int segment_id_size = segment_ids->dims->data[0];\n  if (segment_id_size > 0) {\n    max_index = segment_ids->data.i32[segment_id_size - 1];\n  }\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}", "func_src_after": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  // Segment ids should be of same cardinality as first input dimension and they\n  // should be increasing by at most 1, from 0 (e.g., [0, 0, 1, 2, 3] is valid)\n  const int segment_id_size = segment_ids->dims->data[0];\n  TF_LITE_ENSURE_EQ(context, segment_id_size, data->dims->data[0]);\n  int previous_segment_id = -1;\n  for (int i = 0; i < segment_id_size; i++) {\n    const int current_segment_id = GetTensorData<int32_t>(segment_ids)[i];\n    if (i == 0) {\n      TF_LITE_ENSURE_EQ(context, current_segment_id, 0);\n    } else {\n      int delta = current_segment_id - previous_segment_id;\n      TF_LITE_ENSURE(context, delta == 0 || delta == 1);\n    }\n    previous_segment_id = current_segment_id;\n  }\n\n  const int max_index = previous_segment_id;\n\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/204945b19e44b57906c9344c0d00120eeeae178a", "file_name": "tensorflow/lite/kernels/segment_sum.cc", "vul_type": "cwe-787", "description": "Write a C++ function to resize an output tensor based on segment IDs in TensorFlow Lite."}
{"func_name": "lcbio_cache_local_name", "func_src_before": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "func_src_after": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 327, "char_end": 385, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 9, "char_start": 385, "char_end": 488, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 17, "char_start": 847, "char_end": 905, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 18, "char_start": 905, "char_end": 1009, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n"}], "added": [{"line_no": 7, "char_start": 278, "char_end": 367, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 8, "char_start": 367, "char_end": 475, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 16, "char_start": 834, "char_end": 923, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 17, "char_start": 923, "char_end": 1032, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n"}]}, "char_changes": {"deleted": [{"char_start": 291, "char_end": 346, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 360, "char_end": 368, "chars": "2.host, "}, {"char_start": 811, "char_end": 866, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 880, "char_end": 888, "chars": "2.host, "}], "added": [{"char_start": 291, "char_end": 320, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 334, "char_end": 343, "chars": ", sizeof("}, {"char_start": 357, "char_end": 364, "chars": "2.host)"}, {"char_start": 432, "char_end": 437, "chars": ".port"}, {"char_start": 475, "char_end": 524, "chars": "            size_t len = strlen(sock->ep_local);\n"}, {"char_start": 847, "char_end": 876, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 890, "char_end": 899, "chars": ", sizeof("}, {"char_start": 913, "char_end": 920, "chars": "2.host)"}, {"char_start": 988, "char_end": 993, "chars": ".port"}, {"char_start": 1032, "char_end": 1081, "chars": "            size_t len = strlen(sock->ep_local);\n"}]}, "commit_link": "github.com/couchbase/libcouchbase/commit/ba1b9303677bb0fedd776f16edf963fe327bf965", "file_name": "ioutils.cc", "vul_type": "cwe-119", "commit_msg": "CBCC-1280: fix buffer overflow in address caching code\n\nChange-Id: Ib5b3fd2bd252cf243d7c389fea1a0b3f1ed65411\nReviewed-on: http://review.couchbase.org/c/libcouchbase/+/157713\nTested-by: Build Bot <build@couchbase.com>\nReviewed-by: David Kelly <davidmichaelkelly@gmail.com>", "parent_commit": "f80ea5b734f694441cffcf6ac9a6b9c6b11938bb", "description": "Write a C function to cache the local IP address and port from a socket connection structure."}
{"func_name": "name_parse", "func_src_before": "name_parse(u8 *packet, int length, int *idx, char *name_out, int name_out_len) {\n\tint name_end = -1;\n\tint j = *idx;\n\tint ptr_count = 0;\n#define GET32(x) do { if (j + 4 > length) goto err; memcpy(&t32_, packet + j, 4); j += 4; x = ntohl(t32_); } while (0)\n#define GET16(x) do { if (j + 2 > length) goto err; memcpy(&t_, packet + j, 2); j += 2; x = ntohs(t_); } while (0)\n#define GET8(x) do { if (j >= length) goto err; x = packet[j++]; } while (0)\n\n\tchar *cp = name_out;\n\tconst char *const end = name_out + name_out_len;\n\n\t/* Normally, names are a series of length prefixed strings terminated */\n\t/* with a length of 0 (the lengths are u8's < 63). */\n\t/* However, the length can start with a pair of 1 bits and that */\n\t/* means that the next 14 bits are a pointer within the current */\n\t/* packet. */\n\n\tfor (;;) {\n\t\tu8 label_len;\n\t\tif (j >= length) return -1;\n\t\tGET8(label_len);\n\t\tif (!label_len) break;\n\t\tif (label_len & 0xc0) {\n\t\t\tu8 ptr_low;\n\t\t\tGET8(ptr_low);\n\t\t\tif (name_end < 0) name_end = j;\n\t\t\tj = (((int)label_len & 0x3f) << 8) + ptr_low;\n\t\t\t/* Make sure that the target offset is in-bounds. */\n\t\t\tif (j < 0 || j >= length) return -1;\n\t\t\t/* If we've jumped more times than there are characters in the\n\t\t\t * message, we must have a loop. */\n\t\t\tif (++ptr_count > length) return -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (label_len > 63) return -1;\n\t\tif (cp != name_out) {\n\t\t\tif (cp + 1 >= end) return -1;\n\t\t\t*cp++ = '.';\n\t\t}\n\t\tif (cp + label_len >= end) return -1;\n\t\tmemcpy(cp, packet + j, label_len);\n\t\tcp += label_len;\n\t\tj += label_len;\n\t}\n\tif (cp >= end) return -1;\n\t*cp = '\\0';\n\tif (name_end < 0)\n\t\t*idx = j;\n\telse\n\t\t*idx = name_end;\n\treturn 0;\n err:\n\treturn -1;\n}", "func_src_after": "name_parse(u8 *packet, int length, int *idx, char *name_out, int name_out_len) {\n\tint name_end = -1;\n\tint j = *idx;\n\tint ptr_count = 0;\n#define GET32(x) do { if (j + 4 > length) goto err; memcpy(&t32_, packet + j, 4); j += 4; x = ntohl(t32_); } while (0)\n#define GET16(x) do { if (j + 2 > length) goto err; memcpy(&t_, packet + j, 2); j += 2; x = ntohs(t_); } while (0)\n#define GET8(x) do { if (j >= length) goto err; x = packet[j++]; } while (0)\n\n\tchar *cp = name_out;\n\tconst char *const end = name_out + name_out_len;\n\n\t/* Normally, names are a series of length prefixed strings terminated */\n\t/* with a length of 0 (the lengths are u8's < 63). */\n\t/* However, the length can start with a pair of 1 bits and that */\n\t/* means that the next 14 bits are a pointer within the current */\n\t/* packet. */\n\n\tfor (;;) {\n\t\tu8 label_len;\n\t\tGET8(label_len);\n\t\tif (!label_len) break;\n\t\tif (label_len & 0xc0) {\n\t\t\tu8 ptr_low;\n\t\t\tGET8(ptr_low);\n\t\t\tif (name_end < 0) name_end = j;\n\t\t\tj = (((int)label_len & 0x3f) << 8) + ptr_low;\n\t\t\t/* Make sure that the target offset is in-bounds. */\n\t\t\tif (j < 0 || j >= length) return -1;\n\t\t\t/* If we've jumped more times than there are characters in the\n\t\t\t * message, we must have a loop. */\n\t\t\tif (++ptr_count > length) return -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (label_len > 63) return -1;\n\t\tif (cp != name_out) {\n\t\t\tif (cp + 1 >= end) return -1;\n\t\t\t*cp++ = '.';\n\t\t}\n\t\tif (cp + label_len >= end) return -1;\n\t\tif (j + label_len > length) return -1;\n\t\tmemcpy(cp, packet + j, label_len);\n\t\tcp += label_len;\n\t\tj += label_len;\n\t}\n\tif (cp >= end) return -1;\n\t*cp = '\\0';\n\tif (name_end < 0)\n\t\t*idx = j;\n\telse\n\t\t*idx = name_end;\n\treturn 0;\n err:\n\treturn -1;\n}", "commit_link": "github.com/libevent/libevent/commit/96f64a022014a208105ead6c8a7066018449d86d", "file_name": "evdns.c", "vul_type": "cwe-125", "description": "Write a C function `name_parse` that decodes a domain name from a DNS packet, handling label pointers and ensuring no buffer overflows."}
{"func_name": "Html5ReportGenerator::unzipApp", "func_src_before": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "func_src_after": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "line_changes": {"deleted": [], "added": [{"line_no": 12, "char_start": 549, "char_end": 633, "line": "            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n"}, {"line_no": 13, "char_start": 633, "char_end": 694, "line": "                throw new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 14, "char_start": 694, "char_end": 708, "line": "            }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 548, "char_end": 707, "chars": "\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }"}]}, "commit_link": "github.com/TNG/JGiven/commit/e701fe690501e7301f7c923adc1881d308806c46", "file_name": "Html5ReportGenerator.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to unzip a file named 'app.zip' from the resources of the `Html5ReportGenerator` class into a specified directory."}
