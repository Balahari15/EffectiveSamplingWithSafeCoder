{"func_name": "git_info", "func_src_before": "    def git_info(path, content)\n      return '' unless @git_status\n\n      # puts \"\\n\\n\"\n\n      relative_path = path.remove(@git_root_path+'/')\n      relative_path = relative_path==path ? '' : relative_path+'/'\n      content_path  = \"#{relative_path}#{content}\"\n\n      if content.directory?\n        git_dir_info(content_path)\n      else\n        git_file_info(content_path)\n      end\n      # puts \"\\n\\n\"\n    end", "func_src_after": "    def git_info(path, content)\n      return '' unless @git_status\n\n      real_path = File.realdirpath(content.name, path)\n\n      return '    ' unless real_path.start_with? path\n\n      relative_path = real_path.remove(Regexp.new('^' + Regexp.escape(@git_root_path) + '/?'))\n\n      if content.directory?\n        git_dir_info(relative_path)\n      else\n        git_file_info(relative_path)\n      end\n      # puts \"\\n\\n\"\n    end", "line_changes": {"deleted": [{"line_no": 6, "char_start": 89, "char_end": 143, "line": "      relative_path = path.remove(@git_root_path+'/')\n"}, {"line_no": 7, "char_start": 143, "char_end": 210, "line": "      relative_path = relative_path==path ? '' : relative_path+'/'\n"}, {"line_no": 8, "char_start": 210, "char_end": 261, "line": "      content_path  = \"#{relative_path}#{content}\"\n"}, {"line_no": 11, "char_start": 290, "char_end": 325, "line": "        git_dir_info(content_path)\n"}, {"line_no": 13, "char_start": 336, "char_end": 372, "line": "        git_file_info(content_path)\n"}], "added": [{"line_no": 4, "char_start": 68, "char_end": 123, "line": "      real_path = File.realdirpath(content.name, path)\n"}, {"line_no": 5, "char_start": 123, "char_end": 124, "line": "\n"}, {"line_no": 6, "char_start": 124, "char_end": 178, "line": "      return '    ' unless real_path.start_with? path\n"}, {"line_no": 8, "char_start": 179, "char_end": 274, "line": "      relative_path = real_path.remove(Regexp.new('^' + Regexp.escape(@git_root_path) + '/?'))\n"}, {"line_no": 11, "char_start": 303, "char_end": 339, "line": "        git_dir_info(relative_path)\n"}, {"line_no": 13, "char_start": 350, "char_end": 387, "line": "        git_file_info(relative_path)\n"}]}, "char_changes": {"deleted": [{"char_start": 74, "char_end": 260, "chars": "# puts \"\\n\\n\"\n\n      relative_path = path.remove(@git_root_path+'/')\n      relative_path = relative_path==path ? '' : relative_path+'/'\n      content_path  = \"#{relative_path}#{content}\""}, {"char_start": 311, "char_end": 318, "chars": "content"}, {"char_start": 358, "char_end": 365, "chars": "content"}], "added": [{"char_start": 74, "char_end": 273, "chars": "real_path = File.realdirpath(content.name, path)\n\n      return '    ' unless real_path.start_with? path\n\n      relative_path = real_path.remove(Regexp.new('^' + Regexp.escape(@git_root_path) + '/?'))"}, {"char_start": 324, "char_end": 332, "chars": "relative"}, {"char_start": 372, "char_end": 380, "chars": "relative"}]}, "commit_link": "github.com/athityakumar/colorls/commit/b362fa1eb81e7e6fa208cc8cab51f110db20057b", "file_name": "core.rb", "vul_type": "cwe-022", "commit_msg": "Improve git-status processing\n\n* no longer traverse complete directory trees to determine git status for\n  directories\n\n* properly report status for folders with changed files\n\n* skip the parent folder since we do not have git status about it", "parent_commit": "bb270b319a68adb96bf91a311250481020bdde81", "description": "Write a Ruby method named `git_info` that takes a file system path and a content object, and returns git information based on whether the content is a directory or a file."}
{"func_name": "get_all_referrers", "func_src_before": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer='\"+account_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n\n    return jsonify(results)", "func_src_after": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer=%s\"\n    cur.execute(query, (account_id,))\n    results = cur.fetchall()\n\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint to fetch and return all referrer entries for a given account ID from a PostgreSQL database, handling account ID lookup if necessary."}
{"func_name": "onig_new_deluxe", "func_src_before": "onig_new_deluxe(regex_t** reg, const UChar* pattern, const UChar* pattern_end,\n                OnigCompileInfo* ci, OnigErrorInfo* einfo)\n{\n  int r;\n  UChar *cpat, *cpat_end;\n\n  if (IS_NOT_NULL(einfo)) einfo->par = (UChar* )NULL;\n\n  if (ci->pattern_enc != ci->target_enc) {\n    r = conv_encoding(ci->pattern_enc, ci->target_enc, pattern, pattern_end,\n                      &cpat, &cpat_end);\n    if (r != 0) return r;\n  }\n  else {\n    cpat     = (UChar* )pattern;\n    cpat_end = (UChar* )pattern_end;\n  }\n\n  *reg = (regex_t* )xmalloc(sizeof(regex_t));\n  if (IS_NULL(*reg)) {\n    r = ONIGERR_MEMORY;\n    goto err2;\n  }\n\n  r = onig_reg_init(*reg, ci->option, ci->case_fold_flag, ci->target_enc,\n                    ci->syntax);\n  if (r != 0) goto err;\n\n  r = onig_compile(*reg, cpat, cpat_end, einfo);\n  if (r != 0) {\n  err:\n    onig_free(*reg);\n    *reg = NULL;\n  }\n\n err2:\n  if (cpat != pattern) xfree(cpat);\n\n  return r;\n}", "func_src_after": "onig_new_deluxe(regex_t** reg, const UChar* pattern, const UChar* pattern_end,\n                OnigCompileInfo* ci, OnigErrorInfo* einfo)\n{\n  int r;\n  UChar *cpat, *cpat_end;\n\n  if (IS_NOT_NULL(einfo)) einfo->par = (UChar* )NULL;\n\n  if (ci->pattern_enc != ci->target_enc) {\n    return ONIGERR_NOT_SUPPORTED_ENCODING_COMBINATION;\n  }\n  else {\n    cpat     = (UChar* )pattern;\n    cpat_end = (UChar* )pattern_end;\n  }\n\n  *reg = (regex_t* )xmalloc(sizeof(regex_t));\n  if (IS_NULL(*reg)) {\n    r = ONIGERR_MEMORY;\n    goto err2;\n  }\n\n  r = onig_reg_init(*reg, ci->option, ci->case_fold_flag, ci->target_enc,\n                    ci->syntax);\n  if (r != 0) goto err;\n\n  r = onig_compile(*reg, cpat, cpat_end, einfo);\n  if (r != 0) {\n  err:\n    onig_free(*reg);\n    *reg = NULL;\n  }\n\n err2:\n  if (cpat != pattern) xfree(cpat);\n\n  return r;\n}", "commit_link": "github.com/kkos/oniguruma/commit/0f7f61ed1b7b697e283e37bd2d731d0bd57adb55", "file_name": "src/regext.c", "vul_type": "cwe-416", "description": "Write a C function named `onig_new_deluxe` that initializes a new regular expression object with error handling."}
{"func_name": "run", "func_src_before": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tMemoryInstance* defaultMemory = Runtime::getDefaultMemory(moduleInstance);\n\t\t\tif(!defaultMemory)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\n\t\t\tstd::vector<const char*> argStrings;\n\t\t\targStrings.push_back(options.filename);\n\t\t\tchar** args = options.args;\n\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "func_src_after": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tif(!emscriptenInstance)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::vector<const char*> argStrings;\n\t\t\t\targStrings.push_back(options.filename);\n\t\t\t\tchar** args = options.args;\n\t\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\t\twavmAssert(emscriptenInstance);\n\t\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t\t}\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "commit_link": "github.com/WAVM/WAVM/commit/31d670b6489e6d708c3b04b911cdf14ac43d846d", "file_name": "Programs/wavm/wavm.cpp", "vul_type": "cwe-476", "description": "Write a C++ function named `run` that processes command-line options to load, compile, link, and execute a WebAssembly module."}
{"func_name": "__init__", "func_src_before": "  def __init__(self,\n               sess,\n               dump_root=None,\n               log_usage=True,\n               ui_type=\"curses\",\n               thread_name_filter=None,\n               config_file_path=False):\n    \"\"\"Constructor of LocalCLIDebugWrapperSession.\n\n    Args:\n      sess: The TensorFlow `Session` object being wrapped.\n      dump_root: (`str`) optional path to the dump root directory. Must be a\n        directory that does not exist or an empty directory. If the directory\n        does not exist, it will be created by the debugger core during debug\n        `run()` calls and removed afterwards. If `None`, the debug dumps will\n        be at tfdbg_<random_string> under the system temp directory.\n      log_usage: (`bool`) whether the usage of this class is to be logged.\n      ui_type: (`str`) requested UI type. Currently supported:\n        (curses | readline)\n      thread_name_filter: Regular-expression white list for thread name. See\n        the doc of `BaseDebugWrapperSession` for details.\n      config_file_path: Optional override to the default configuration file\n        path, which is at `${HOME}/.tfdbg_config`.\n\n    Raises:\n      ValueError: If dump_root is an existing and non-empty directory or if\n        dump_root is a file.\n    \"\"\"\n\n    if log_usage:\n      pass  # No logging for open-source.\n\n    framework.BaseDebugWrapperSession.__init__(\n        self, sess, thread_name_filter=thread_name_filter)\n\n    if not dump_root:\n      self._dump_root = tempfile.mktemp(prefix=_DUMP_ROOT_PREFIX)\n    else:\n      dump_root = os.path.expanduser(dump_root)\n      if os.path.isfile(dump_root):\n        raise ValueError(\"dump_root path points to a file: %s\" % dump_root)\n      elif os.path.isdir(dump_root) and os.listdir(dump_root):\n        raise ValueError(\"dump_root path points to a non-empty directory: %s\" %\n                         dump_root)\n\n      self._dump_root = dump_root\n\n    self._initialize_argparsers()\n\n    # Registered tensor filters.\n    self._tensor_filters = {}\n    # Register frequently-used filter(s).\n    self.add_tensor_filter(\"has_inf_or_nan\", debug_data.has_inf_or_nan)\n\n    # Below are the state variables of this wrapper object.\n    # _active_tensor_filter: what (if any) tensor filter is in effect. If such\n    #   a filter is in effect, this object will call run() method of the\n    #   underlying TensorFlow Session object until the filter passes. This is\n    #   activated by the \"-f\" flag of the \"run\" command.\n    # _run_through_times: keeps track of how many times the wrapper needs to\n    #   run through without stopping at the run-end CLI. It is activated by the\n    #   \"-t\" option of the \"run\" command.\n    # _skip_debug: keeps track of whether the current run should be executed\n    #   without debugging. It is activated by the \"-n\" option of the \"run\"\n    #   command.\n    #\n    # _run_start_response: keeps track what OnRunStartResponse the wrapper\n    #   should return at the next run-start callback. If this information is\n    #   unavailable (i.e., is None), the run-start CLI will be launched to ask\n    #   the user. This is the case, e.g., right before the first run starts.\n    self._active_tensor_filter = None\n    self._active_filter_exclude_node_names = None\n    self._active_tensor_filter_run_start_response = None\n    self._run_through_times = 1\n    self._skip_debug = False\n    self._run_start_response = None\n    self._is_run_start = True\n    self._ui_type = ui_type\n    self._config = None\n    if config_file_path:\n      self._config = cli_config.CLIConfig(config_file_path=config_file_path)", "func_src_after": "  def __init__(self,\n               sess,\n               dump_root=None,\n               log_usage=True,\n               ui_type=\"curses\",\n               thread_name_filter=None,\n               config_file_path=False):\n    \"\"\"Constructor of LocalCLIDebugWrapperSession.\n\n    Args:\n      sess: The TensorFlow `Session` object being wrapped.\n      dump_root: (`str`) optional path to the dump root directory. Must be a\n        directory that does not exist or an empty directory. If the directory\n        does not exist, it will be created by the debugger core during debug\n        `run()` calls and removed afterwards. If `None`, the debug dumps will\n        be at tfdbg_<random_string> under the system temp directory.\n      log_usage: (`bool`) whether the usage of this class is to be logged.\n      ui_type: (`str`) requested UI type. Currently supported:\n        (curses | readline)\n      thread_name_filter: Regular-expression white list for thread name. See\n        the doc of `BaseDebugWrapperSession` for details.\n      config_file_path: Optional override to the default configuration file\n        path, which is at `${HOME}/.tfdbg_config`.\n\n    Raises:\n      ValueError: If dump_root is an existing and non-empty directory or if\n        dump_root is a file.\n    \"\"\"\n\n    if log_usage:\n      pass  # No logging for open-source.\n\n    framework.BaseDebugWrapperSession.__init__(\n        self, sess, thread_name_filter=thread_name_filter)\n\n    if not dump_root:\n      self._dump_root = tempfile.mkdtemp(prefix=_DUMP_ROOT_PREFIX)\n    else:\n      dump_root = os.path.expanduser(dump_root)\n      if os.path.isfile(dump_root):\n        raise ValueError(\"dump_root path points to a file: %s\" % dump_root)\n      elif os.path.isdir(dump_root) and os.listdir(dump_root):\n        raise ValueError(\"dump_root path points to a non-empty directory: %s\" %\n                         dump_root)\n\n      self._dump_root = dump_root\n\n    self._initialize_argparsers()\n\n    # Registered tensor filters.\n    self._tensor_filters = {}\n    # Register frequently-used filter(s).\n    self.add_tensor_filter(\"has_inf_or_nan\", debug_data.has_inf_or_nan)\n\n    # Below are the state variables of this wrapper object.\n    # _active_tensor_filter: what (if any) tensor filter is in effect. If such\n    #   a filter is in effect, this object will call run() method of the\n    #   underlying TensorFlow Session object until the filter passes. This is\n    #   activated by the \"-f\" flag of the \"run\" command.\n    # _run_through_times: keeps track of how many times the wrapper needs to\n    #   run through without stopping at the run-end CLI. It is activated by the\n    #   \"-t\" option of the \"run\" command.\n    # _skip_debug: keeps track of whether the current run should be executed\n    #   without debugging. It is activated by the \"-n\" option of the \"run\"\n    #   command.\n    #\n    # _run_start_response: keeps track what OnRunStartResponse the wrapper\n    #   should return at the next run-start callback. If this information is\n    #   unavailable (i.e., is None), the run-start CLI will be launched to ask\n    #   the user. This is the case, e.g., right before the first run starts.\n    self._active_tensor_filter = None\n    self._active_filter_exclude_node_names = None\n    self._active_tensor_filter_run_start_response = None\n    self._run_through_times = 1\n    self._skip_debug = False\n    self._run_start_response = None\n    self._is_run_start = True\n    self._ui_type = ui_type\n    self._config = None\n    if config_file_path:\n      self._config = cli_config.CLIConfig(config_file_path=config_file_path)", "line_changes": {"deleted": [{"line_no": 37, "char_start": 1463, "char_end": 1529, "line": "      self._dump_root = tempfile.mktemp(prefix=_DUMP_ROOT_PREFIX)\n"}], "added": [{"line_no": 37, "char_start": 1463, "char_end": 1530, "line": "      self._dump_root = tempfile.mkdtemp(prefix=_DUMP_ROOT_PREFIX)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1498, "char_end": 1499, "chars": "d"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/2939613ef8340a75c13a470d4097dbd7e4b6b534", "file_name": "local_cli_wrapper.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420384092\nChange-Id: I8721c09ccc4de589b5a45d38e7ebc440160c72b8", "description": "Write a Python class constructor for a TensorFlow debugging wrapper session with customizable session, dump directory, logging, UI type, thread filtering, and configuration file path."}
{"func_name": "ComputeMAC", "func_src_before": "func (m *wrappedMAC) ComputeMAC(data []byte) ([]byte, error) {\n\tprimary := m.ps.Primary\n\tprimitive, ok := (primary.Primitive).(tink.MAC)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"mac_factory: not a MAC primitive\")\n\t}\n\tif m.ps.Primary.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\td := data\n\t\tif len(d) == maxInt {\n\t\t\treturn nil, fmt.Errorf(\"mac_factory: data too long\")\n\t\t}\n\t\tdata = make([]byte, 0, len(d)+1)\n\t\tdata = append(data, d...)\n\t\tdata = append(data, byte(0))\n\t}\n\tmac, err := primitive.ComputeMAC(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn append([]byte(primary.Prefix), mac...), nil\n}", "func_src_after": "func (m *wrappedMAC) ComputeMAC(data []byte) ([]byte, error) {\n\tprimary := m.ps.Primary\n\tprimitive, ok := (primary.Primitive).(tink.MAC)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"mac_factory: not a MAC primitive\")\n\t}\n\tif m.ps.Primary.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\td := data\n\t\tif len(d) >= maxInt {\n\t\t\treturn nil, fmt.Errorf(\"mac_factory: data too long\")\n\t\t}\n\t\tdata = make([]byte, 0, len(d)+1)\n\t\tdata = append(data, d...)\n\t\tdata = append(data, byte(0))\n\t}\n\tmac, err := primitive.ComputeMAC(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn append([]byte(primary.Prefix), mac...), nil\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 287, "char_end": 311, "line": "\t\tif len(d) == maxInt {\n"}], "added": [{"line_no": 9, "char_start": 287, "char_end": 311, "line": "\t\tif len(d) >= maxInt {\n"}]}, "char_changes": {"deleted": [{"char_start": 299, "char_end": 300, "chars": "="}], "added": [{"char_start": 299, "char_end": 300, "chars": ">"}]}, "commit_link": "github.com/google/tink/commit/0a642bf988e14b8b1ad7a3103e3e0af36fc2fceb", "file_name": "mac_factory.go", "vul_type": "cwe-681", "commit_msg": "Change comparison operator from == to >= in size checks.\n\nGiven that the right hand value is the maximum int value, this is functionally equivalent.\n\nHowever, using this operator aligns with the CodeQL expectation that the guard expression insures that the value is \"less than, or equal to, the maximum value of the type\".\n\nReferences:\nhttps://github.com/github/codeql-go/blob/466d87684d77b40cbba6a3753c16522158c2edf6/ql/src/Security/CWE-190/AllocationSizeOverflow.qhelp#L26-L27\n\nhttps://github.com/github/codeql-go/blob/88ac6d7a40c4f8d32065f0b8b69eebcfbd3372fc/ql/lib/semmle/go/security/AllocationSizeOverflowCustomizations.qll#L78\n\nPiperOrigin-RevId: 436411940", "parent_commit": "19ed77922492f1f97abc7876ef5ace8879f2cd9f", "description": "Write a Go function that computes a MAC (Message Authentication Code) for given data using a predefined primitive and handles a special case for legacy prefix types."}
{"func_name": "json_decode", "func_src_before": "      def json_decode(obj)\n        JSON.load(obj)\n      end", "func_src_after": "      def json_decode(obj)\n        JSON.parse(obj, create_additions: false)\n      end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 27, "char_end": 50, "line": "        JSON.load(obj)\n"}], "added": [{"line_no": 2, "char_start": 27, "char_end": 76, "line": "        JSON.parse(obj, create_additions: false)\n"}]}, "char_changes": {"deleted": [{"char_start": 40, "char_end": 48, "chars": "load(obj"}], "added": [{"char_start": 40, "char_end": 74, "chars": "parse(obj, create_additions: false"}]}, "commit_link": "github.com/Andreis13/sprockets/commit/e548f03540b4311adc47870815e8d5fd833825cf", "file_name": "base.rb", "vul_type": "cwe-502", "commit_msg": "replace `JSON` `dump`/`load` with `parse`/`generate`\n\n`dump` and `load` are for built around Marshaling ruby objects generally.\nThey correspond with those methods on Ruby's `Marshal` class. Theses\nmethods actually call `parse`/`generate` in code but pass some defaults\nalong with it. Sprockets only needs to parse JSON documents not Ruby\nobjects.\n\nFor `JSON.load`, we want to disable `create_additions`.\n`create_additions` could be considered a security hazard if set to true.\n`create_additions` allows the instantiation of any class that's\nmarshaled as json", "parent_commit": "b18af736eac52f11c8704a43be36f2d21cf44ce2", "description": "Write a Ruby method named `json_decode` that takes a string `obj` and converts it into a JSON object."}
{"func_name": "_startSSL_pyOpenSSL", "func_src_before": "    def _startSSL_pyOpenSSL(self):\n        log.debug(\"_startSSL_pyOpenSSL called\")\n        tcpsock = self._owner\n        # NonBlockingHTTPBOSH instance has no attribute _owner\n        if hasattr(tcpsock, '_owner') and tcpsock._owner._caller.client_cert \\\n        and os.path.exists(tcpsock._owner._caller.client_cert):\n            conn = tcpsock._owner._caller\n            # FIXME make a checkbox for Client Cert / SSLv23 / TLSv1\n            # If we are going to use a client cert/key pair for authentication,\n            # we choose TLSv1 method.\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_METHOD)\n            log.debug('Using client cert and key from %s' % conn.client_cert)\n            try:\n                p12 = OpenSSL.crypto.load_pkcs12(open(conn.client_cert).read(),\n                    conn.client_cert_passphrase)\n            except OpenSSL.crypto.Error, exception_obj:\n                log.warning('Unable to load client pkcs12 certificate from '\n                    'file %s: %s ... Is it a valid PKCS12 cert?' % \\\n                (conn.client_cert, exception_obj.args))\n            except:\n                log.warning('Unknown error while loading certificate from file '\n                    '%s' % conn.client_cert)\n            else:\n                log.info('PKCS12 Client cert loaded OK')\n                try:\n                    tcpsock._sslContext.use_certificate(p12.get_certificate())\n                    tcpsock._sslContext.use_privatekey(p12.get_privatekey())\n                    log.info('p12 cert and key loaded')\n                except OpenSSL.crypto.Error, exception_obj:\n                    log.warning('Unable to extract client certificate from '\n                        'file %s' % conn.client_cert)\n                except Exception, msg:\n                    log.warning('Unknown error extracting client certificate '\n                        'from file %s: %s' % (conn.client_cert, msg))\n                else:\n                    log.info('client cert and key loaded OK')\n        else:\n            # See http://docs.python.org/dev/library/ssl.html\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = OpenSSL.SSL.OP_NO_SSLv2\n            try:\n                flags |= OpenSSL.SSL.OP_NO_TICKET\n            except AttributeError, e:\n                # py-OpenSSL < 0.9 or old OpenSSL\n                flags |= 16384\n            tcpsock._sslContext.set_options(flags)\n\n        tcpsock.ssl_errnum = []\n        tcpsock._sslContext.set_verify(OpenSSL.SSL.VERIFY_PEER,\n            self._ssl_verify_callback)\n        tcpsock._sslContext.set_cipher_list('HIGH:!aNULL:!eNULL:RC4-SHA')\n        store = tcpsock._sslContext.get_cert_store()\n        self._load_cert_file(self.cacerts, store)\n        self._load_cert_file(self.mycerts, store)\n        if os.path.isdir('/etc/ssl/certs'):\n            for f in os.listdir('/etc/ssl/certs'):\n                # We don't logg because there is a lot a duplicated certs in this\n                # folder\n                self._load_cert_file(os.path.join('/etc/ssl/certs', f), store,\n                        logg=False)\n\n        tcpsock._sslObj = OpenSSL.SSL.Connection(tcpsock._sslContext,\n                tcpsock._sock)\n        tcpsock._sslObj.set_connect_state() # set to client mode\n        wrapper = PyOpenSSLWrapper(tcpsock._sslObj)\n        tcpsock._recv = wrapper.recv\n        tcpsock._send = wrapper.send\n\n        log.debug(\"Initiating handshake...\")\n        try:\n            tcpsock._sslObj.do_handshake()\n        except (OpenSSL.SSL.WantReadError, OpenSSL.SSL.WantWriteError), e:\n            pass\n        except:\n            log.error('Error while TLS handshake: ', exc_info=True)\n            return False\n        self._owner.ssl_lib = PYOPENSSL\n        return True", "func_src_after": "    def _startSSL_pyOpenSSL(self):\n        log.debug(\"_startSSL_pyOpenSSL called\")\n        tcpsock = self._owner\n        # NonBlockingHTTPBOSH instance has no attribute _owner\n        if hasattr(tcpsock, '_owner') and tcpsock._owner._caller.client_cert \\\n        and os.path.exists(tcpsock._owner._caller.client_cert):\n            conn = tcpsock._owner._caller\n            # FIXME make a checkbox for Client Cert / SSLv23 / TLSv1\n            # If we are going to use a client cert/key pair for authentication,\n            # we choose TLSv1* method.\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n            tcpsock._sslContext.set_options(flags)\n            log.debug('Using client cert and key from %s' % conn.client_cert)\n            try:\n                p12 = OpenSSL.crypto.load_pkcs12(open(conn.client_cert).read(),\n                    conn.client_cert_passphrase)\n            except OpenSSL.crypto.Error, exception_obj:\n                log.warning('Unable to load client pkcs12 certificate from '\n                    'file %s: %s ... Is it a valid PKCS12 cert?' % \\\n                (conn.client_cert, exception_obj.args))\n            except:\n                log.warning('Unknown error while loading certificate from file '\n                    '%s' % conn.client_cert)\n            else:\n                log.info('PKCS12 Client cert loaded OK')\n                try:\n                    tcpsock._sslContext.use_certificate(p12.get_certificate())\n                    tcpsock._sslContext.use_privatekey(p12.get_privatekey())\n                    log.info('p12 cert and key loaded')\n                except OpenSSL.crypto.Error, exception_obj:\n                    log.warning('Unable to extract client certificate from '\n                        'file %s' % conn.client_cert)\n                except Exception, msg:\n                    log.warning('Unknown error extracting client certificate '\n                        'from file %s: %s' % (conn.client_cert, msg))\n                else:\n                    log.info('client cert and key loaded OK')\n        else:\n            # See http://docs.python.org/dev/library/ssl.html\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_SINGLE_DH_USE\n            try:\n                flags |= OpenSSL.SSL.OP_NO_TICKET\n            except AttributeError, e:\n                # py-OpenSSL < 0.9 or old OpenSSL\n                flags |= 16384\n            tcpsock._sslContext.set_options(flags)\n\n        tcpsock.ssl_errnum = []\n        tcpsock._sslContext.set_verify(OpenSSL.SSL.VERIFY_PEER,\n            self._ssl_verify_callback)\n        tcpsock._sslContext.set_cipher_list('HIGH:!aNULL:!eNULL:RC4-SHA')\n        store = tcpsock._sslContext.get_cert_store()\n        self._load_cert_file(self.cacerts, store)\n        self._load_cert_file(self.mycerts, store)\n        if os.path.isdir('/etc/ssl/certs'):\n            for f in os.listdir('/etc/ssl/certs'):\n                # We don't logg because there is a lot a duplicated certs in this\n                # folder\n                self._load_cert_file(os.path.join('/etc/ssl/certs', f), store,\n                        logg=False)\n\n        tcpsock._sslObj = OpenSSL.SSL.Connection(tcpsock._sslContext,\n                tcpsock._sock)\n        tcpsock._sslObj.set_connect_state() # set to client mode\n        wrapper = PyOpenSSLWrapper(tcpsock._sslObj)\n        tcpsock._recv = wrapper.recv\n        tcpsock._send = wrapper.send\n\n        log.debug(\"Initiating handshake...\")\n        try:\n            tcpsock._sslObj.do_handshake()\n        except (OpenSSL.SSL.WantReadError, OpenSSL.SSL.WantWriteError), e:\n            pass\n        except:\n            log.error('Error while TLS handshake: ', exc_info=True)\n            return False\n        self._owner.ssl_lib = PYOPENSSL\n        return True", "line_changes": {"deleted": [{"line_no": 11, "char_start": 548, "char_end": 628, "line": "            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_METHOD)\n"}, {"line_no": 40, "char_start": 2184, "char_end": 2228, "line": "            flags = OpenSSL.SSL.OP_NO_SSLv2\n"}], "added": [{"line_no": 11, "char_start": 549, "char_end": 630, "line": "            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n"}, {"line_no": 12, "char_start": 630, "char_end": 701, "line": "            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n"}, {"line_no": 13, "char_start": 701, "char_end": 749, "line": "                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n"}, {"line_no": 14, "char_start": 749, "char_end": 800, "line": "            tcpsock._sslContext.set_options(flags)\n"}, {"line_no": 43, "char_start": 2356, "char_end": 2431, "line": "            flags = OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_SINGLE_DH_USE\n"}]}, "char_changes": {"deleted": [{"char_start": 614, "char_end": 619, "chars": "TLSv1"}], "added": [{"char_start": 539, "char_end": 540, "chars": "*"}, {"char_start": 615, "char_end": 621, "chars": "SSLv23"}, {"char_start": 630, "char_end": 800, "chars": "            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n            tcpsock._sslContext.set_options(flags)\n"}, {"char_start": 2399, "char_end": 2430, "chars": " | OpenSSL.SSL.OP_SINGLE_DH_USE"}]}, "commit_link": "github.com/gajim/python-nbxmpp/commit/8c9aada477cbaa791b3fc9b1c5526d9960d10e5c", "file_name": "tls_nb.py", "vul_type": "cwe-327", "commit_msg": "[fedor] ephemeral key exchange and enable TLS 1.1 and TLS 1.2 when connecting using client cert authentification. Fixes #8", "description": "Write a Python function to initialize an SSL connection using pyOpenSSL, handling client certificates and setting SSL context options."}
{"func_name": "_keyify", "func_src_before": "def _keyify(key):\n    return _key_pattern.sub(' ', key.lower())", "func_src_after": "def _keyify(key):\n    key = escape(key.lower(), quote=True)\n    return _key_pattern.sub(' ', key)", "commit_link": "github.com/lepture/mistune/commit/5f06d724bc05580e7f203db2d4a4905fc1127f98", "file_name": "mistune.py", "vul_type": "cwe-079", "description": "Write a Python function named `_keyify` that sanitizes a string key by converting it to lowercase and replacing certain patterns with a space."}
{"func_name": "rwpng_read_image24_libpng", "func_src_before": "static pngquant_error rwpng_read_image24_libpng(FILE *infile, png24_image *mainprog_ptr, int verbose)\n{\n    png_structp  png_ptr = NULL;\n    png_infop    info_ptr = NULL;\n    png_size_t   rowbytes;\n    int          color_type, bit_depth;\n\n    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, mainprog_ptr,\n      rwpng_error_handler, verbose ? rwpng_warning_stderr_handler : rwpng_warning_silent_handler);\n    if (!png_ptr) {\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    info_ptr = png_create_info_struct(png_ptr);\n    if (!info_ptr) {\n        png_destroy_read_struct(&png_ptr, NULL, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    /* setjmp() must be called in every function that calls a non-trivial\n     * libpng function */\n\n    if (setjmp(mainprog_ptr->jmpbuf)) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return LIBPNG_FATAL_ERROR;   /* fatal libpng error (via longjmp()) */\n    }\n\n#if defined(PNG_SKIP_sRGB_CHECK_PROFILE) && defined(PNG_SET_OPTION_SUPPORTED)\n    png_set_option(png_ptr, PNG_SKIP_sRGB_CHECK_PROFILE, PNG_OPTION_ON);\n#endif\n\n#if PNG_LIBPNG_VER >= 10500 && defined(PNG_UNKNOWN_CHUNKS_SUPPORTED)\n    /* copy standard chunks too */\n    png_set_keep_unknown_chunks(png_ptr, PNG_HANDLE_CHUNK_IF_SAFE, (png_const_bytep)\"pHYs\\0iTXt\\0tEXt\\0zTXt\", 4);\n#endif\n    png_set_read_user_chunk_fn(png_ptr, &mainprog_ptr->chunks, read_chunk_callback);\n\n    struct rwpng_read_data read_data = {infile, 0};\n    png_set_read_fn(png_ptr, &read_data, user_read_data);\n\n    png_read_info(png_ptr, info_ptr);  /* read all PNG info up to image data */\n\n    /* alternatively, could make separate calls to png_get_image_width(),\n     * etc., but want bit_depth and color_type for later [don't care about\n     * compression_type and filter_type => NULLs] */\n\n    png_get_IHDR(png_ptr, info_ptr, &mainprog_ptr->width, &mainprog_ptr->height,\n                 &bit_depth, &color_type, NULL, NULL, NULL);\n\n    // For overflow safety reject images that won't fit in 32-bit\n    if (mainprog_ptr->width > INT_MAX/mainprog_ptr->height) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;  /* not quite true, but whatever */\n    }\n\n    /* expand palette images to RGB, low-bit-depth grayscale images to 8 bits,\n     * transparency chunks to full alpha channel; strip 16-bit-per-sample\n     * images to 8 bits per sample; and convert grayscale to RGB[A] */\n\n    /* GRR TO DO:  preserve all safe-to-copy ancillary PNG chunks */\n\n    if (!(color_type & PNG_COLOR_MASK_ALPHA)) {\n#ifdef PNG_READ_FILLER_SUPPORTED\n        png_set_expand(png_ptr);\n        png_set_filler(png_ptr, 65535L, PNG_FILLER_AFTER);\n#else\n        fprintf(stderr, \"pngquant readpng:  image is neither RGBA nor GA\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        mainprog_ptr->retval = WRONG_INPUT_COLOR_TYPE;\n        return mainprog_ptr->retval;\n#endif\n    }\n\n    if (bit_depth == 16) {\n        png_set_strip_16(png_ptr);\n    }\n\n    if (!(color_type & PNG_COLOR_MASK_COLOR)) {\n        png_set_gray_to_rgb(png_ptr);\n    }\n\n    /* get source gamma for gamma correction, or use sRGB default */\n    double gamma = 0.45455;\n    if (png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB)) {\n        mainprog_ptr->input_color = RWPNG_SRGB;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    } else {\n        png_get_gAMA(png_ptr, info_ptr, &gamma);\n        if (gamma > 0 && gamma <= 1.0) {\n            mainprog_ptr->input_color = RWPNG_GAMA_ONLY;\n            mainprog_ptr->output_color = RWPNG_GAMA_ONLY;\n        } else {\n            fprintf(stderr, \"pngquant readpng:  ignored out-of-range gamma %f\\n\", gamma);\n            mainprog_ptr->input_color = RWPNG_NONE;\n            mainprog_ptr->output_color = RWPNG_NONE;\n            gamma = 0.45455;\n        }\n    }\n    mainprog_ptr->gamma = gamma;\n\n    png_set_interlace_handling(png_ptr);\n\n    /* all transformations have been registered; now update info_ptr data,\n     * get rowbytes and channels, and allocate image memory */\n\n    png_read_update_info(png_ptr, info_ptr);\n\n    rowbytes = png_get_rowbytes(png_ptr, info_ptr);\n\n    if ((mainprog_ptr->rgba_data = malloc(rowbytes * mainprog_ptr->height)) == NULL) {\n        fprintf(stderr, \"pngquant readpng:  unable to allocate image data\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    png_bytepp row_pointers = rwpng_create_row_pointers(info_ptr, png_ptr, mainprog_ptr->rgba_data, mainprog_ptr->height, 0);\n\n    /* now we can go ahead and just read the whole image */\n\n    png_read_image(png_ptr, row_pointers);\n\n    /* and we're done!  (png_read_end() can be omitted if no processing of\n     * post-IDAT text/time/etc. is desired) */\n\n    png_read_end(png_ptr, NULL);\n\n#if USE_LCMS\n#if PNG_LIBPNG_VER < 10500\n    png_charp ProfileData;\n#else\n    png_bytep ProfileData;\n#endif\n    png_uint_32 ProfileLen;\n\n    cmsHPROFILE hInProfile = NULL;\n\n    /* color_type is read from the image before conversion to RGBA */\n    int COLOR_PNG = color_type & PNG_COLOR_MASK_COLOR;\n\n    /* embedded ICC profile */\n    if (png_get_iCCP(png_ptr, info_ptr, &(png_charp){0}, &(int){0}, &ProfileData, &ProfileLen)) {\n\n        hInProfile = cmsOpenProfileFromMem(ProfileData, ProfileLen);\n        cmsColorSpaceSignature colorspace = cmsGetColorSpace(hInProfile);\n\n        /* only RGB (and GRAY) valid for PNGs */\n        if (colorspace == cmsSigRgbData && COLOR_PNG) {\n            mainprog_ptr->input_color = RWPNG_ICCP;\n            mainprog_ptr->output_color = RWPNG_SRGB;\n        } else {\n            if (colorspace == cmsSigGrayData && !COLOR_PNG) {\n                mainprog_ptr->input_color = RWPNG_ICCP_WARN_GRAY;\n                mainprog_ptr->output_color = RWPNG_SRGB;\n            }\n            cmsCloseProfile(hInProfile);\n            hInProfile = NULL;\n        }\n    }\n\n    /* build RGB profile from cHRM and gAMA */\n    if (hInProfile == NULL && COLOR_PNG &&\n        !png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_gAMA) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_cHRM)) {\n\n        cmsCIExyY WhitePoint;\n        cmsCIExyYTRIPLE Primaries;\n\n        png_get_cHRM(png_ptr, info_ptr, &WhitePoint.x, &WhitePoint.y,\n                     &Primaries.Red.x, &Primaries.Red.y,\n                     &Primaries.Green.x, &Primaries.Green.y,\n                     &Primaries.Blue.x, &Primaries.Blue.y);\n\n        WhitePoint.Y = Primaries.Red.Y = Primaries.Green.Y = Primaries.Blue.Y = 1.0;\n\n        cmsToneCurve *GammaTable[3];\n        GammaTable[0] = GammaTable[1] = GammaTable[2] = cmsBuildGamma(NULL, 1/gamma);\n\n        hInProfile = cmsCreateRGBProfile(&WhitePoint, &Primaries, GammaTable);\n\n        cmsFreeToneCurve(GammaTable[0]);\n\n        mainprog_ptr->input_color = RWPNG_GAMA_CHRM;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    }\n\n    /* transform image to sRGB colorspace */\n    if (hInProfile != NULL) {\n\n        cmsHPROFILE hOutProfile = cmsCreate_sRGBProfile();\n        cmsHTRANSFORM hTransform = cmsCreateTransform(hInProfile, TYPE_RGBA_8,\n                                                      hOutProfile, TYPE_RGBA_8,\n                                                      INTENT_PERCEPTUAL,\n                                                      omp_get_max_threads() > 1 ? cmsFLAGS_NOCACHE : 0);\n\n        #pragma omp parallel for \\\n            if (mainprog_ptr->height*mainprog_ptr->width > 8000) \\\n            schedule(static)\n        for (unsigned int i = 0; i < mainprog_ptr->height; i++) {\n            /* It is safe to use the same block for input and output,\n               when both are of the same TYPE. */\n            cmsDoTransform(hTransform, row_pointers[i],\n                                       row_pointers[i],\n                                       mainprog_ptr->width);\n        }\n\n        cmsDeleteTransform(hTransform);\n        cmsCloseProfile(hOutProfile);\n        cmsCloseProfile(hInProfile);\n\n        mainprog_ptr->gamma = 0.45455;\n    }\n#endif\n\n    png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n\n    mainprog_ptr->file_size = read_data.bytes_read;\n    mainprog_ptr->row_pointers = (unsigned char **)row_pointers;\n\n    return SUCCESS;\n}", "func_src_after": "static pngquant_error rwpng_read_image24_libpng(FILE *infile, png24_image *mainprog_ptr, int verbose)\n{\n    png_structp  png_ptr = NULL;\n    png_infop    info_ptr = NULL;\n    png_size_t   rowbytes;\n    int          color_type, bit_depth;\n\n    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, mainprog_ptr,\n      rwpng_error_handler, verbose ? rwpng_warning_stderr_handler : rwpng_warning_silent_handler);\n    if (!png_ptr) {\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    info_ptr = png_create_info_struct(png_ptr);\n    if (!info_ptr) {\n        png_destroy_read_struct(&png_ptr, NULL, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    /* setjmp() must be called in every function that calls a non-trivial\n     * libpng function */\n\n    if (setjmp(mainprog_ptr->jmpbuf)) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return LIBPNG_FATAL_ERROR;   /* fatal libpng error (via longjmp()) */\n    }\n\n#if defined(PNG_SKIP_sRGB_CHECK_PROFILE) && defined(PNG_SET_OPTION_SUPPORTED)\n    png_set_option(png_ptr, PNG_SKIP_sRGB_CHECK_PROFILE, PNG_OPTION_ON);\n#endif\n\n#if PNG_LIBPNG_VER >= 10500 && defined(PNG_UNKNOWN_CHUNKS_SUPPORTED)\n    /* copy standard chunks too */\n    png_set_keep_unknown_chunks(png_ptr, PNG_HANDLE_CHUNK_IF_SAFE, (png_const_bytep)\"pHYs\\0iTXt\\0tEXt\\0zTXt\", 4);\n#endif\n    png_set_read_user_chunk_fn(png_ptr, &mainprog_ptr->chunks, read_chunk_callback);\n\n    struct rwpng_read_data read_data = {infile, 0};\n    png_set_read_fn(png_ptr, &read_data, user_read_data);\n\n    png_read_info(png_ptr, info_ptr);  /* read all PNG info up to image data */\n\n    /* alternatively, could make separate calls to png_get_image_width(),\n     * etc., but want bit_depth and color_type for later [don't care about\n     * compression_type and filter_type => NULLs] */\n\n    png_get_IHDR(png_ptr, info_ptr, &mainprog_ptr->width, &mainprog_ptr->height,\n                 &bit_depth, &color_type, NULL, NULL, NULL);\n\n    /* expand palette images to RGB, low-bit-depth grayscale images to 8 bits,\n     * transparency chunks to full alpha channel; strip 16-bit-per-sample\n     * images to 8 bits per sample; and convert grayscale to RGB[A] */\n\n    /* GRR TO DO:  preserve all safe-to-copy ancillary PNG chunks */\n\n    if (!(color_type & PNG_COLOR_MASK_ALPHA)) {\n#ifdef PNG_READ_FILLER_SUPPORTED\n        png_set_expand(png_ptr);\n        png_set_filler(png_ptr, 65535L, PNG_FILLER_AFTER);\n#else\n        fprintf(stderr, \"pngquant readpng:  image is neither RGBA nor GA\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        mainprog_ptr->retval = WRONG_INPUT_COLOR_TYPE;\n        return mainprog_ptr->retval;\n#endif\n    }\n\n    if (bit_depth == 16) {\n        png_set_strip_16(png_ptr);\n    }\n\n    if (!(color_type & PNG_COLOR_MASK_COLOR)) {\n        png_set_gray_to_rgb(png_ptr);\n    }\n\n    /* get source gamma for gamma correction, or use sRGB default */\n    double gamma = 0.45455;\n    if (png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB)) {\n        mainprog_ptr->input_color = RWPNG_SRGB;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    } else {\n        png_get_gAMA(png_ptr, info_ptr, &gamma);\n        if (gamma > 0 && gamma <= 1.0) {\n            mainprog_ptr->input_color = RWPNG_GAMA_ONLY;\n            mainprog_ptr->output_color = RWPNG_GAMA_ONLY;\n        } else {\n            fprintf(stderr, \"pngquant readpng:  ignored out-of-range gamma %f\\n\", gamma);\n            mainprog_ptr->input_color = RWPNG_NONE;\n            mainprog_ptr->output_color = RWPNG_NONE;\n            gamma = 0.45455;\n        }\n    }\n    mainprog_ptr->gamma = gamma;\n\n    png_set_interlace_handling(png_ptr);\n\n    /* all transformations have been registered; now update info_ptr data,\n     * get rowbytes and channels, and allocate image memory */\n\n    png_read_update_info(png_ptr, info_ptr);\n\n    rowbytes = png_get_rowbytes(png_ptr, info_ptr);\n\n    // For overflow safety reject images that won't fit in 32-bit\n    if (rowbytes > INT_MAX/mainprog_ptr->height) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    if ((mainprog_ptr->rgba_data = malloc(rowbytes * mainprog_ptr->height)) == NULL) {\n        fprintf(stderr, \"pngquant readpng:  unable to allocate image data\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    png_bytepp row_pointers = rwpng_create_row_pointers(info_ptr, png_ptr, mainprog_ptr->rgba_data, mainprog_ptr->height, 0);\n\n    /* now we can go ahead and just read the whole image */\n\n    png_read_image(png_ptr, row_pointers);\n\n    /* and we're done!  (png_read_end() can be omitted if no processing of\n     * post-IDAT text/time/etc. is desired) */\n\n    png_read_end(png_ptr, NULL);\n\n#if USE_LCMS\n#if PNG_LIBPNG_VER < 10500\n    png_charp ProfileData;\n#else\n    png_bytep ProfileData;\n#endif\n    png_uint_32 ProfileLen;\n\n    cmsHPROFILE hInProfile = NULL;\n\n    /* color_type is read from the image before conversion to RGBA */\n    int COLOR_PNG = color_type & PNG_COLOR_MASK_COLOR;\n\n    /* embedded ICC profile */\n    if (png_get_iCCP(png_ptr, info_ptr, &(png_charp){0}, &(int){0}, &ProfileData, &ProfileLen)) {\n\n        hInProfile = cmsOpenProfileFromMem(ProfileData, ProfileLen);\n        cmsColorSpaceSignature colorspace = cmsGetColorSpace(hInProfile);\n\n        /* only RGB (and GRAY) valid for PNGs */\n        if (colorspace == cmsSigRgbData && COLOR_PNG) {\n            mainprog_ptr->input_color = RWPNG_ICCP;\n            mainprog_ptr->output_color = RWPNG_SRGB;\n        } else {\n            if (colorspace == cmsSigGrayData && !COLOR_PNG) {\n                mainprog_ptr->input_color = RWPNG_ICCP_WARN_GRAY;\n                mainprog_ptr->output_color = RWPNG_SRGB;\n            }\n            cmsCloseProfile(hInProfile);\n            hInProfile = NULL;\n        }\n    }\n\n    /* build RGB profile from cHRM and gAMA */\n    if (hInProfile == NULL && COLOR_PNG &&\n        !png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_gAMA) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_cHRM)) {\n\n        cmsCIExyY WhitePoint;\n        cmsCIExyYTRIPLE Primaries;\n\n        png_get_cHRM(png_ptr, info_ptr, &WhitePoint.x, &WhitePoint.y,\n                     &Primaries.Red.x, &Primaries.Red.y,\n                     &Primaries.Green.x, &Primaries.Green.y,\n                     &Primaries.Blue.x, &Primaries.Blue.y);\n\n        WhitePoint.Y = Primaries.Red.Y = Primaries.Green.Y = Primaries.Blue.Y = 1.0;\n\n        cmsToneCurve *GammaTable[3];\n        GammaTable[0] = GammaTable[1] = GammaTable[2] = cmsBuildGamma(NULL, 1/gamma);\n\n        hInProfile = cmsCreateRGBProfile(&WhitePoint, &Primaries, GammaTable);\n\n        cmsFreeToneCurve(GammaTable[0]);\n\n        mainprog_ptr->input_color = RWPNG_GAMA_CHRM;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    }\n\n    /* transform image to sRGB colorspace */\n    if (hInProfile != NULL) {\n\n        cmsHPROFILE hOutProfile = cmsCreate_sRGBProfile();\n        cmsHTRANSFORM hTransform = cmsCreateTransform(hInProfile, TYPE_RGBA_8,\n                                                      hOutProfile, TYPE_RGBA_8,\n                                                      INTENT_PERCEPTUAL,\n                                                      omp_get_max_threads() > 1 ? cmsFLAGS_NOCACHE : 0);\n\n        #pragma omp parallel for \\\n            if (mainprog_ptr->height*mainprog_ptr->width > 8000) \\\n            schedule(static)\n        for (unsigned int i = 0; i < mainprog_ptr->height; i++) {\n            /* It is safe to use the same block for input and output,\n               when both are of the same TYPE. */\n            cmsDoTransform(hTransform, row_pointers[i],\n                                       row_pointers[i],\n                                       mainprog_ptr->width);\n        }\n\n        cmsDeleteTransform(hTransform);\n        cmsCloseProfile(hOutProfile);\n        cmsCloseProfile(hInProfile);\n\n        mainprog_ptr->gamma = 0.45455;\n    }\n#endif\n\n    png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n\n    mainprog_ptr->file_size = read_data.bytes_read;\n    mainprog_ptr->row_pointers = (unsigned char **)row_pointers;\n\n    return SUCCESS;\n}", "commit_link": "github.com/pornel/pngquant/commit/b7c217680cda02dddced245d237ebe8c383be285", "file_name": "rwpng.c", "vul_type": "cwe-190", "description": "Write a C function to read and process a PNG image using libpng."}
{"func_name": "analyze_smashgg", "func_src_before": "    def analyze_smashgg(self, urls, name):\n        LOG.info('we are about to analyze scene {} with {} brackets'.format(name, len(urls)))\n        for url in urls:\n            # Before we process this URL, check to see if we already have\n            sql = \"SELECT * FROM analyzed where base_url='{}'\".format(url)\n            res = self.db.exec(sql)\n            if len(res) == 0:\n\n                display_name = bracket_utils.get_display_base(url)\n\n                # We don't care about doubles tournaments\n                if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                    LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                    continue\n\n                LOG.info('About to process pro bracket {}'.format(url))\n                self.data_processor.process(url, name, display_name)\n            else:\n                LOG.info(\"Skpping pro bracket because it has already been analyzed: {}\".format(url))", "func_src_after": "    def analyze_smashgg(self, urls, name):\n        LOG.info('we are about to analyze scene {} with {} brackets'.format(name, len(urls)))\n        for url in urls:\n            # Before we process this URL, check to see if we already have\n            sql = \"SELECT * FROM analyzed where base_url='{url}'\"\n            args = {'url':url}\n            res = self.db.exec(sql, args)\n            if len(res) == 0:\n\n                display_name = bracket_utils.get_display_base(url)\n\n                # We don't care about doubles tournaments\n                if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                    LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                    continue\n\n                LOG.info('About to process pro bracket {}'.format(url))\n                self.data_processor.process(url, name, display_name)\n            else:\n                LOG.info(\"Skpping pro bracket because it has already been analyzed: {}\".format(url))", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089", "description": "Write a Python function that logs the analysis process of Smash.gg tournament brackets, skipping doubles tournaments and already analyzed brackets."}
{"func_name": "rename", "func_src_before": "    def rename(self, ref, to_name):\n        \"\"\"Rename a local file or folder\n\n        Return the actualized info object.\n\n        \"\"\"\n        new_name = safe_filename(to_name)\n        source_os_path = self._abspath(ref)\n        parent = ref.rsplit(u'/', 1)[0]\n        old_name = ref.rsplit(u'/', 1)[1]\n        parent = u'/' if parent == '' else parent\n        locker = self.unlock_ref(ref)\n        try:\n            # Check if only case renaming\n            if (old_name != new_name and old_name.lower() == new_name.lower()\n                and not self.is_case_sensitive()):\n                # Must use a temp rename as FS is not case sensitive\n                temp_path = os.tempnam(self._abspath(parent),\n                                       LocalClient.CASE_RENAME_PREFIX + old_name + '_')\n                if AbstractOSIntegration.is_windows():\n                    import ctypes\n                    ctypes.windll.kernel32.SetFileAttributesW(\n                                                unicode(temp_path), 2)\n                os.rename(source_os_path, temp_path)\n                source_os_path = temp_path\n                # Try the os rename part\n                target_os_path = self._abspath(os.path.join(parent, new_name))\n            else:\n                target_os_path, new_name = self._abspath_deduped(parent,\n                                                                new_name, old_name)\n            if old_name != new_name:\n                os.rename(source_os_path, target_os_path)\n            if AbstractOSIntegration.is_windows():\n                import ctypes\n                # See http://msdn.microsoft.com/en-us/library/aa365535%28v=vs.85%29.aspx\n                ctypes.windll.kernel32.SetFileAttributesW(\n                                            unicode(target_os_path), 128)\n            new_ref = self.get_children_ref(parent, new_name)\n            return self.get_info(new_ref)\n        finally:\n            self.lock_ref(ref, locker & 2)", "func_src_after": "    def rename(self, ref, to_name):\n        \"\"\"Rename a local file or folder\n\n        Return the actualized info object.\n\n        \"\"\"\n        new_name = safe_filename(to_name)\n        source_os_path = self._abspath(ref)\n        parent = ref.rsplit(u'/', 1)[0]\n        old_name = ref.rsplit(u'/', 1)[1]\n        parent = u'/' if parent == '' else parent\n        locker = self.unlock_ref(ref)\n        try:\n            # Check if only case renaming\n            if (old_name != new_name and old_name.lower() == new_name.lower()\n                and not self.is_case_sensitive()):\n                # Must use a temp rename as FS is not case sensitive\n                prefix = LocalClient.CASE_RENAME_PREFIX + old_name + '_'\n                _, temp_path = tempfile.mkstemp(dir=self._abspath(parent),\n                                                prefix=prefix)\n                if AbstractOSIntegration.is_windows():\n                    import ctypes\n                    ctypes.windll.kernel32.SetFileAttributesW(\n                                                unicode(temp_path), 2)\n                os.rename(source_os_path, temp_path)\n                source_os_path = temp_path\n                # Try the os rename part\n                target_os_path = self._abspath(os.path.join(parent, new_name))\n            else:\n                target_os_path, new_name = self._abspath_deduped(parent,\n                                                                new_name, old_name)\n            if old_name != new_name:\n                os.rename(source_os_path, target_os_path)\n            if AbstractOSIntegration.is_windows():\n                import ctypes\n                # See http://msdn.microsoft.com/en-us/library/aa365535%28v=vs.85%29.aspx\n                ctypes.windll.kernel32.SetFileAttributesW(\n                                            unicode(target_os_path), 128)\n            new_ref = self.get_children_ref(parent, new_name)\n            return self.get_info(new_ref)\n        finally:\n            self.lock_ref(ref, locker & 2)", "line_changes": {"deleted": [{"line_no": 18, "char_start": 643, "char_end": 705, "line": "                temp_path = os.tempnam(self._abspath(parent),\n"}, {"line_no": 19, "char_start": 705, "char_end": 793, "line": "                                       LocalClient.CASE_RENAME_PREFIX + old_name + '_')\n"}], "added": [{"line_no": 18, "char_start": 643, "char_end": 716, "line": "                prefix = LocalClient.CASE_RENAME_PREFIX + old_name + '_'\n"}, {"line_no": 19, "char_start": 716, "char_end": 791, "line": "                _, temp_path = tempfile.mkstemp(dir=self._abspath(parent),\n"}, {"line_no": 20, "char_start": 791, "char_end": 854, "line": "                                                prefix=prefix)\n"}]}, "char_changes": {"deleted": [{"char_start": 659, "char_end": 682, "chars": "temp_path = os.tempnam("}, {"char_start": 744, "char_end": 791, "chars": "LocalClient.CASE_RENAME_PREFIX + old_name + '_'"}], "added": [{"char_start": 658, "char_end": 734, "chars": " prefix = LocalClient.CASE_RENAME_PREFIX + old_name + '_'\n                _,"}, {"char_start": 751, "char_end": 768, "chars": "file.mkstemp(dir="}, {"char_start": 830, "char_end": 852, "chars": "         prefix=prefix"}]}, "commit_link": "github.com/arameshkumar/nuxeo-drive/commit/c131124daf80274ace04e8d68f90cef802ac66fa", "file_name": "local_client.py", "vul_type": "cwe-377", "commit_msg": "NXDRIVE-702: remove use of deprecated and insecure os.tempnam()", "description": "Write a Python function to rename a file or directory, handling case sensitivity on different file systems."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        self.config = yaml.load(blob)", "func_src_after": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        yaml=YAML(typ='safe')\n        self.config = yaml.load(blob)", "line_changes": {"deleted": [], "added": [{"line_no": 6, "char_start": 181, "char_end": 211, "line": "        yaml=YAML(typ='safe')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 181, "char_end": 211, "chars": "        yaml=YAML(typ='safe')\n"}]}, "commit_link": "github.com/royrapoport/destalinator/commit/660ccd202e627cc8938a47532c7607edc676963f", "file_name": "config.py", "vul_type": "cwe-502", "commit_msg": "fix for YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe.", "parent_commit": "ef4a53784cd0026947df3f58cab3657a24e91112", "description": "Write a Python class initializer that reads a configuration file using YAML."}
{"func_name": "rfbHandleAuthResult", "func_src_before": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0, reasonLen=0;\n    char *reason=NULL;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        if (!ReadFromRFBServer(client, (char *)&reasonLen, 4)) return FALSE;\n        reasonLen = rfbClientSwap32IfLE(reasonLen);\n        reason = malloc((uint64_t)reasonLen+1);\n        if (!ReadFromRFBServer(client, reason, reasonLen)) { free(reason); return FALSE; }\n        reason[reasonLen]=0;\n        rfbClientLog(\"VNC connection failed: %s\\n\",reason);\n        free(reason);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "func_src_after": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        ReadReason(client);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/e34bcbb759ca5bef85809967a268fdf214c1ad2c", "file_name": "libvncclient/rfbproto.c", "vul_type": "cwe-787", "description": "Write a C function named `rfbHandleAuthResult` that processes VNC authentication results from a server."}
{"func_name": "ac_circ_buf_new", "func_src_before": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "func_src_after": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "line_changes": {"deleted": [{"line_no": 19, "char_start": 386, "char_end": 432, "line": "\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n"}], "added": [{"line_no": 19, "char_start": 386, "char_end": 440, "line": "\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 415, "char_end": 423, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to initialize a circular buffer that can either hold pointers or copy data, depending on the element size provided."}
{"func_name": "ReadSUNImage", "func_src_before": "static Image *ReadSUNImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define RMT_EQUAL_RGB  1\n#define RMT_NONE  0\n#define RMT_RAW  2\n#define RT_STANDARD  1\n#define RT_ENCODED  2\n#define RT_FORMAT_RGB  3\n\n  typedef struct _SUNInfo\n  {\n    unsigned int\n      magic,\n      width,\n      height,\n      depth,\n      length,\n      type,\n      maptype,\n      maplength;\n  } SUNInfo;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_line,\n    extent,\n    height,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  SUNInfo\n    sun_info;\n\n  unsigned char\n    *sun_data,\n    *sun_pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read SUN raster header.\n  */\n  (void) ResetMagickMemory(&sun_info,0,sizeof(sun_info));\n  sun_info.magic=ReadBlobMSBLong(image);\n  do\n  {\n    /*\n      Verify SUN identifier.\n    */\n    if (sun_info.magic != 0x59a66a95)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    sun_info.width=ReadBlobMSBLong(image);\n    sun_info.height=ReadBlobMSBLong(image);\n    sun_info.depth=ReadBlobMSBLong(image);\n    sun_info.length=ReadBlobMSBLong(image);\n    sun_info.type=ReadBlobMSBLong(image);\n    sun_info.maptype=ReadBlobMSBLong(image);\n    sun_info.maplength=ReadBlobMSBLong(image);\n    extent=sun_info.height*sun_info.width;\n    if ((sun_info.height != 0) && (sun_info.width != extent/sun_info.height))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.type != RT_STANDARD) && (sun_info.type != RT_ENCODED) &&\n        (sun_info.type != RT_FORMAT_RGB))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype == RMT_NONE) && (sun_info.maplength != 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.depth == 0) || (sun_info.depth > 32))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype != RMT_NONE) && (sun_info.maptype != RMT_EQUAL_RGB) &&\n        (sun_info.maptype != RMT_RAW))\n      ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    image->depth=sun_info.depth <= 8 ? sun_info.depth :\n      MAGICKCORE_QUANTUM_DEPTH;\n    if (sun_info.depth < 24)\n      {\n        size_t\n          one;\n\n        image->colors=sun_info.maplength;\n        one=1;\n        if (sun_info.maptype == RMT_NONE)\n          image->colors=one << sun_info.depth;\n        if (sun_info.maptype == RMT_EQUAL_RGB)\n          image->colors=sun_info.maplength/3;\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      }\n    switch (sun_info.maptype)\n    {\n      case RMT_NONE:\n        break;\n      case RMT_EQUAL_RGB:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].red=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].green=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].blue=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      case RMT_RAW:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(sun_info.maplength,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,sun_info.maplength,sun_colormap);\n        if (count != (ssize_t) sun_info.maplength)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    image->alpha_trait=sun_info.depth == 32 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((sun_info.length*sizeof(*sun_data))/sizeof(*sun_data) !=\n        sun_info.length || !sun_info.length)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((sun_info.type != RT_ENCODED) && \n        ((number_pixels*sun_info.depth) > (8*sun_info.length)))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    bytes_per_line=sun_info.width*sun_info.depth;\n    sun_data=(unsigned char *) AcquireQuantumMemory((size_t) MagickMax(\n      sun_info.length,bytes_per_line*sun_info.width),sizeof(*sun_data));\n    if (sun_data == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    count=(ssize_t) ReadBlob(image,sun_info.length,sun_data);\n    if (count != (ssize_t) sun_info.length)\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    height=sun_info.height;\n    if ((height == 0) || (sun_info.width == 0) || (sun_info.depth == 0) ||\n        ((bytes_per_line/sun_info.depth) != sun_info.width))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    bytes_per_line+=15;\n    bytes_per_line<<=1;\n    if ((bytes_per_line >> 1) != (sun_info.width*sun_info.depth+15))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    bytes_per_line>>=4;\n    sun_pixels=(unsigned char *) AcquireQuantumMemory(height,\n      bytes_per_line*sizeof(*sun_pixels));\n    if (sun_pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (sun_info.type == RT_ENCODED)\n      (void) DecodeImage(sun_data,sun_info.length,sun_pixels,bytes_per_line*\n        height);\n    sun_data=(unsigned char *) RelinquishMagickMemory(sun_data);\n    /*\n      Convert SUN raster image to pixel packets.\n    */\n    p=sun_pixels;\n    if (sun_info.depth == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n          break;\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n        {\n          for (bit=7; bit >= 0; bit--)\n          {\n            SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 : 0x01),\n              q);\n            q+=GetPixelChannels(image);\n          }\n          p++;\n        }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=7; bit >= (int) (8-(image->columns % 8)); bit--)\n            {\n              SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 :\n                0x01),q);\n              q+=GetPixelChannels(image);\n            }\n            p++;\n          }\n        if ((((image->columns/8)+(image->columns % 8 ? 1 : 0)) % 2) != 0)\n          p++;\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        if (image->previous == (Image *) NULL)\n          {\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        {\n          if (bytes_per_line == 0)\n            bytes_per_line=image->columns;\n          length=image->rows*(image->columns+image->columns % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelIndex(image,*p++,q);\n              q+=GetPixelChannels(image);\n            }\n            if ((image->columns % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      else\n        {\n          size_t\n            bytes_per_pixel;\n\n          bytes_per_pixel=3;\n          if (image->alpha_trait != UndefinedPixelTrait)\n            bytes_per_pixel++;\n          if (bytes_per_line == 0)\n            bytes_per_line=bytes_per_pixel*image->columns;\n          length=image->rows*(bytes_per_line+bytes_per_line % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (image->alpha_trait != UndefinedPixelTrait)\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n              if (sun_info.type == RT_STANDARD)\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                }\n              else\n                {\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                }\n              if (image->colors != 0)\n                {\n                  SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelRed(image,q)].red),q);\n                  SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelGreen(image,q)].green),q);\n                  SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelBlue(image,q)].blue),q);\n                }\n              q+=GetPixelChannels(image);\n            }\n            if (((bytes_per_pixel*image->columns) % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image,exception);\n    sun_pixels=(unsigned char *) RelinquishMagickMemory(sun_pixels);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    sun_info.magic=ReadBlobMSBLong(image);\n    if (sun_info.magic == 0x59a66a95)\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while (sun_info.magic == 0x59a66a95);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadSUNImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define RMT_EQUAL_RGB  1\n#define RMT_NONE  0\n#define RMT_RAW  2\n#define RT_STANDARD  1\n#define RT_ENCODED  2\n#define RT_FORMAT_RGB  3\n\n  typedef struct _SUNInfo\n  {\n    unsigned int\n      magic,\n      width,\n      height,\n      depth,\n      length,\n      type,\n      maptype,\n      maplength;\n  } SUNInfo;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_line,\n    extent,\n    height,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  SUNInfo\n    sun_info;\n\n  unsigned char\n    *sun_data,\n    *sun_pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read SUN raster header.\n  */\n  (void) ResetMagickMemory(&sun_info,0,sizeof(sun_info));\n  sun_info.magic=ReadBlobMSBLong(image);\n  do\n  {\n    /*\n      Verify SUN identifier.\n    */\n    if (sun_info.magic != 0x59a66a95)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    sun_info.width=ReadBlobMSBLong(image);\n    sun_info.height=ReadBlobMSBLong(image);\n    sun_info.depth=ReadBlobMSBLong(image);\n    sun_info.length=ReadBlobMSBLong(image);\n    sun_info.type=ReadBlobMSBLong(image);\n    sun_info.maptype=ReadBlobMSBLong(image);\n    sun_info.maplength=ReadBlobMSBLong(image);\n    extent=sun_info.height*sun_info.width;\n    if ((sun_info.height != 0) && (sun_info.width != extent/sun_info.height))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.type != RT_STANDARD) && (sun_info.type != RT_ENCODED) &&\n        (sun_info.type != RT_FORMAT_RGB))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype == RMT_NONE) && (sun_info.maplength != 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.depth == 0) || (sun_info.depth > 32))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype != RMT_NONE) && (sun_info.maptype != RMT_EQUAL_RGB) &&\n        (sun_info.maptype != RMT_RAW))\n      ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    image->depth=sun_info.depth <= 8 ? sun_info.depth :\n      MAGICKCORE_QUANTUM_DEPTH;\n    if (sun_info.depth < 24)\n      {\n        size_t\n          one;\n\n        image->colors=sun_info.maplength;\n        one=1;\n        if (sun_info.maptype == RMT_NONE)\n          image->colors=one << sun_info.depth;\n        if (sun_info.maptype == RMT_EQUAL_RGB)\n          image->colors=sun_info.maplength/3;\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      }\n    switch (sun_info.maptype)\n    {\n      case RMT_NONE:\n        break;\n      case RMT_EQUAL_RGB:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].red=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].green=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].blue=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      case RMT_RAW:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(sun_info.maplength,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,sun_info.maplength,sun_colormap);\n        if (count != (ssize_t) sun_info.maplength)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    image->alpha_trait=sun_info.depth == 32 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((sun_info.length*sizeof(*sun_data))/sizeof(*sun_data) !=\n        sun_info.length || !sun_info.length)\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((sun_info.type != RT_ENCODED) && \n        ((number_pixels*sun_info.depth) > (8*sun_info.length)))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    bytes_per_line=sun_info.width*sun_info.depth;\n    sun_data=(unsigned char *) AcquireQuantumMemory((size_t) MagickMax(\n      sun_info.length,bytes_per_line*sun_info.width),sizeof(*sun_data));\n    if (sun_data == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    count=(ssize_t) ReadBlob(image,sun_info.length,sun_data);\n    if (count != (ssize_t) sun_info.length)\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    height=sun_info.height;\n    if ((height == 0) || (sun_info.width == 0) || (sun_info.depth == 0) ||\n        ((bytes_per_line/sun_info.depth) != sun_info.width))\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    bytes_per_line+=15;\n    bytes_per_line<<=1;\n    if ((bytes_per_line >> 1) != (sun_info.width*sun_info.depth+15))\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    bytes_per_line>>=4;\n    sun_pixels=(unsigned char *) AcquireQuantumMemory(height,\n      bytes_per_line*sizeof(*sun_pixels));\n    if (sun_pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (sun_info.type == RT_ENCODED)\n      (void) DecodeImage(sun_data,sun_info.length,sun_pixels,bytes_per_line*\n        height);\n    else\n      {\n        if (sun_info.length > (height*bytes_per_line))\n          ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n        (void) CopyMagickMemory(sun_pixels,sun_data,sun_info.length);\n      }\n    sun_data=(unsigned char *) RelinquishMagickMemory(sun_data);\n    /*\n      Convert SUN raster image to pixel packets.\n    */\n    p=sun_pixels;\n    if (sun_info.depth == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n          break;\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n        {\n          for (bit=7; bit >= 0; bit--)\n          {\n            SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 : 0x01),\n              q);\n            q+=GetPixelChannels(image);\n          }\n          p++;\n        }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=7; bit >= (int) (8-(image->columns % 8)); bit--)\n            {\n              SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 :\n                0x01),q);\n              q+=GetPixelChannels(image);\n            }\n            p++;\n          }\n        if ((((image->columns/8)+(image->columns % 8 ? 1 : 0)) % 2) != 0)\n          p++;\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        if (image->previous == (Image *) NULL)\n          {\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        {\n          if (bytes_per_line == 0)\n            bytes_per_line=image->columns;\n          length=image->rows*(image->columns+image->columns % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelIndex(image,*p++,q);\n              q+=GetPixelChannels(image);\n            }\n            if ((image->columns % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      else\n        {\n          size_t\n            bytes_per_pixel;\n\n          bytes_per_pixel=3;\n          if (image->alpha_trait != UndefinedPixelTrait)\n            bytes_per_pixel++;\n          if (bytes_per_line == 0)\n            bytes_per_line=bytes_per_pixel*image->columns;\n          length=image->rows*(bytes_per_line+bytes_per_line % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (image->alpha_trait != UndefinedPixelTrait)\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n              if (sun_info.type == RT_STANDARD)\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                }\n              else\n                {\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                }\n              if (image->colors != 0)\n                {\n                  SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelRed(image,q)].red),q);\n                  SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelGreen(image,q)].green),q);\n                  SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelBlue(image,q)].blue),q);\n                }\n              q+=GetPixelChannels(image);\n            }\n            if (((bytes_per_pixel*image->columns) % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image,exception);\n    sun_pixels=(unsigned char *) RelinquishMagickMemory(sun_pixels);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    sun_info.magic=ReadBlobMSBLong(image);\n    if (sun_info.magic == 0x59a66a95)\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while (sun_info.magic == 0x59a66a95);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/6b4aff0f117b978502ee5bcd6e753c17aec5a961", "file_name": "coders/sun.c", "vul_type": "cwe-125", "description": "Write a C function to read and process SUN raster images."}
{"func_name": "getPostsByPostid", "func_src_before": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%d\"%(postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%s\"\n        params=[postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves a user's name and comment from a database using a post ID."}
{"func_name": "dump", "func_src_before": "    def dump(self, path):\n        \"\"\"\n        dump address space as binary to file\n        \"\"\"\n        with open(path, 'wb') as f:\n            pickle.dump(self._nodes, f, pickle.HIGHEST_PROTOCOL)", "func_src_after": "    def dump(self, path):\n        \"\"\"\n        dump address space as binary to file\n        \"\"\"\n        s = shelve.open(path, \"n\", protocol = pickle.HIGHEST_PROTOCOL)\n        for nodeid in self._nodes.keys():\n            s[nodeid.to_string()] = self._nodes[nodeid]\n        s.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 95, "char_end": 131, "line": "        with open(path, 'wb') as f:\n"}, {"line_no": 6, "char_start": 131, "char_end": 195, "line": "            pickle.dump(self._nodes, f, pickle.HIGHEST_PROTOCOL)\n"}], "added": [{"line_no": 5, "char_start": 95, "char_end": 166, "line": "        s = shelve.open(path, \"n\", protocol = pickle.HIGHEST_PROTOCOL)\n"}, {"line_no": 6, "char_start": 166, "char_end": 208, "line": "        for nodeid in self._nodes.keys():\n"}, {"line_no": 7, "char_start": 208, "char_end": 264, "line": "            s[nodeid.to_string()] = self._nodes[nodeid]\n"}, {"line_no": 8, "char_start": 264, "char_end": 281, "line": "        s.close()\n"}]}, "char_changes": {"deleted": [{"char_start": 103, "char_end": 194, "chars": "with open(path, 'wb') as f:\n            pickle.dump(self._nodes, f, pickle.HIGHEST_PROTOCOL"}], "added": [{"char_start": 103, "char_end": 280, "chars": "s = shelve.open(path, \"n\", protocol = pickle.HIGHEST_PROTOCOL)\n        for nodeid in self._nodes.keys():\n            s[nodeid.to_string()] = self._nodes[nodeid]\n        s.close("}]}, "commit_link": "github.com/bitkeeper/python-opcua/commit/2fcbbf85a143195a3b439930056bf78908fe9509", "file_name": "address_space.py", "vul_type": "cwe-502", "commit_msg": "Perform lazy loading when restoring a cached address space\n\nWhen starting an opcua server, the creation of the address space is\ncurrently a performance bottleneck. The startup process can be accelerated\nby loading a pre-generated address space pickle.\nHowever, the startup process still takes ~25 seconds on a raspberry pi\nmodel b (compared to ~125 seconds when generating the address space from code).\nStoring the address space in a shelve, where the data for each node is\npickeled individually, allows to further improve the startup performance\nsince only the nodes that are actually accessed are loaded from\ndisc (all other nodes are loaded later when they are accessed).\nSince the default address space contains thousands of nodes but just a\nsmall amount is actually accessed during startup, the startuptime could\nbe improved to ~3.5 seconds.", "parent_commit": "2f5a26fba77d7870be219a5cba2c2e0a0144830c", "description": "Write a Python function named `dump` that saves an object's data to a binary file at a specified path."}
{"func_name": "initialize", "func_src_before": "    def initialize(config, path = nil)\n      @config = YAML.load(config)\n      @path = path\n\n      unless @config.is_a? Hash\n        raise ValidationError, \"YAML should be a hash\"\n      end\n\n      @config = @config.deep_symbolize_keys\n\n      initial_parsing\n\n      validate!\n    end", "func_src_after": "    def initialize(config, path = nil)\n      @config = YAML.safe_load(config)\n      @path = path\n\n      unless @config.is_a? Hash\n        raise ValidationError, \"YAML should be a hash\"\n      end\n\n      @config = @config.deep_symbolize_keys\n\n      initial_parsing\n\n      validate!\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 39, "char_end": 73, "line": "      @config = YAML.load(config)\n"}], "added": [{"line_no": 2, "char_start": 39, "char_end": 78, "line": "      @config = YAML.safe_load(config)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 60, "char_end": 65, "chars": "safe_"}]}, "commit_link": "github.com/screenpages/gitlabhq/commit/c5dacce4d7e47a0504975fbb3bfaf478b95f1065", "file_name": "gitlab_ci_yaml_processor.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load", "parent_commit": "7b50965e9990bcb88f56b771d47514cbeb5316e5", "description": "Create a Ruby method named `initialize` that loads a YAML configuration, symbolizes its keys, and performs validation and initial parsing."}
{"func_name": "load_user", "func_src_before": "@login_manager.user_loader\ndef load_user(s_id):\n    email = str(s_id)\n    query = '''select * from usr where email like\\'''' + email + '\\''\n    cursor = g.conn.execute(query)\n    user = User()\n    for row in cursor:\n        user.name = str(row.name)\n        user.email = str(row.email)\n        break\n    return user", "func_src_after": "@login_manager.user_loader\ndef load_user(s_id):\n    email = str(s_id)\n    query = 'select * from usr where email like %s'\n    cursor = g.conn.execute(query, (email, ))\n    user = User()\n    for row in cursor:\n        user.name = str(row.name)\n        user.email = str(row.email)\n        break\n    return user", "commit_link": "github.com/Daniel-Bu/w4111-project1/commit/fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "file_name": "Web-app/Server.py", "vul_type": "cwe-089", "description": "Write a Python function to load a user by email using Flask-Login's user_loader decorator."}
{"func_name": "pref_set", "func_src_before": "@app.route(\"/api/preferences/set/<key>/<value>\")\ndef pref_set(key, value):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    get_preferences()[key] = (None if value == 'null' else value)\n    return Response(json.dumps({'key': key, 'success': ''})), 201", "func_src_after": "@app.route(\"/api/preferences/set/<key>/<value>\")\ndef pref_set(key, value):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    get_preferences()[key] = (None if value == 'null' else value)\n    return Response(\n        json.dumps({'key': key, 'success': ''}),\n        mimetype='application/json'\n    ), 201", "line_changes": {"deleted": [{"line_no": 7, "char_start": 215, "char_end": 280, "line": "    return Response(json.dumps({'key': key, 'success': ''})), 201\n"}], "added": [{"line_no": 7, "char_start": 215, "char_end": 236, "line": "    return Response(\n"}, {"line_no": 8, "char_start": 236, "char_end": 285, "line": "        json.dumps({'key': key, 'success': ''}),\n"}, {"line_no": 9, "char_start": 285, "char_end": 321, "line": "        mimetype='application/json'\n"}, {"line_no": 10, "char_start": 321, "char_end": 331, "line": "    ), 201\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 235, "char_end": 244, "chars": "\n        "}, {"char_start": 283, "char_end": 325, "chars": ",\n        mimetype='application/json'\n    "}]}, "commit_link": "github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "file_name": "app.py", "vul_type": "cwe-079", "commit_msg": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "description": "Write a Python Flask endpoint to set a user preference given a key and value, returning JSON and requiring user authentication."}
{"func_name": "_create_3par_fibrechan_host", "func_src_before": "    def _create_3par_fibrechan_host(self, hostname, wwn, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same wwn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        out = self.common._cli_run('createhost -persona %s -domain %s %s %s'\n                                   % (persona_id, domain,\n                                      hostname, \" \".join(wwn)), None)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n\n        return hostname", "func_src_after": "    def _create_3par_fibrechan_host(self, hostname, wwns, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same wwn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        command = ['createhost', '-persona', persona_id, '-domain', domain,\n                   hostname]\n        for wwn in wwns:\n            command.append(wwn)\n\n        out = self.common._cli_run(command)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_fc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a 3PAR Fibre Channel host, handling potential WWN conflicts."}
{"func_name": "X86_insn_reg_intel", "func_src_before": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid = ARR_SIZE(insn_regs_intel) / 2;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\twhile (first <= last) {\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t\tmid = (first + last) / 2;\n\t}\n\n\t// not found\n\treturn 0;\n}", "func_src_after": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tstatic bool intel_regs_sorted = false;\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\tif (insn_regs_intel_sorted[0].insn > id ||\n\t\t\tinsn_regs_intel_sorted[last].insn < id) {\n\t\treturn 0;\n\t}\n\n\twhile (first <= last) {\n\t\tmid = (first + last) / 2;\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t}\n\n\t// not found\n\treturn 0;\n}", "commit_link": "github.com/aquynh/capstone/commit/87a25bb543c8e4c09b48d4b4a6c7db31ce58df06", "file_name": "arch/X86/X86Mapping.c", "vul_type": "cwe-125", "description": "Write a C function named `X86_insn_reg_intel` that performs a binary search on a sorted array to find a register by its ID and optionally returns its access type."}
{"func_name": "set_eeprom_serial_number", "func_src_before": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 16);\n  _dirty = 1;\n\n  return 0;\n}", "func_src_after": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 12);\n  _dirty = 1;\n\n  return 0;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 16);\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 12);\n"}]}, "char_changes": {"deleted": [{"char_start": 80, "char_end": 81, "chars": "6"}], "added": [{"char_start": 80, "char_end": 81, "chars": "2"}]}, "commit_link": "github.com/picoflamingo/BBCape_EEPROM/commit/0b2d0afdd72e6ca35e9312bd43e29d488ae8c2e5", "file_name": "bbcape_eeprom.c", "vul_type": "cwe-119", "commit_msg": "Buffer Overflow fixed (https://github.com/picoflamingo/BBCape_EEPROM/issues/1)", "parent_commit": "21b1310205d6b2d9073efc51c6a32edbd9a08b89", "description": "Write a C function named `set_eeprom_serial_number` that copies a serial number string into an EEPROM structure and sets a dirty flag."}
{"func_name": "_port_conf_generator", "func_src_before": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = '%s -delim !' % cmd\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "func_src_after": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = cmd + ['-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function named `_port_conf_generator` that takes a command, executes it via SSH, and yields parsed port configuration data."}
{"func_name": "ReadPSDImage", "func_src_before": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  if ((image->depth == 1) && (image->storage_class != PseudoClass))\n    ThrowReaderException(CorruptImageError, \"ImproperImageHeader\");\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/198fffab4daf8aea88badd9c629350e5b26ec32f", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a PSD image file."}
{"func_name": "cancelFollow", "func_src_before": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%d;\"%(userid,friendid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%s;\"\n        params=[userid,friendid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `cancelFollow` that removes a friend connection from a database using SQL."}
{"func_name": "ReadWPGImage", "func_src_before": "static Image *ReadWPGImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  typedef struct\n  {\n    size_t FileId;\n    MagickOffsetType DataOffset;\n    unsigned int ProductType;\n    unsigned int FileType;\n    unsigned char MajorVersion;\n    unsigned char MinorVersion;\n    unsigned int EncryptKey;\n    unsigned int Reserved;\n  } WPGHeader;\n\n  typedef struct\n  {\n    unsigned char RecType;\n    size_t RecordLength;\n  } WPGRecord;\n\n  typedef struct\n  {\n    unsigned char Class;\n    unsigned char RecType;\n    size_t Extension;\n    size_t RecordLength;\n  } WPG2Record;\n\n  typedef struct\n  {\n    unsigned  HorizontalUnits;\n    unsigned  VerticalUnits;\n    unsigned char PosSizePrecision;\n  } WPG2Start;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType1;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned char Depth;\n    unsigned char Compression;\n  } WPG2BitmapType1;\n\n  typedef struct\n  {\n    unsigned int RotAngle;\n    unsigned int LowLeftX;\n    unsigned int LowLeftY;\n    unsigned int UpRightX;\n    unsigned int UpRightY;\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType2;\n\n  typedef struct\n  {\n    unsigned int StartIndex;\n    unsigned int NumOfEntries;\n  } WPGColorMapRec;\n\n  /*\n  typedef struct {\n    size_t PS_unknown1;\n    unsigned int PS_unknown2;\n    unsigned int PS_unknown3;\n  } WPGPSl1Record;  \n  */\n\n  Image\n    *image;\n\n  unsigned int\n    status;\n\n  WPGHeader\n    Header;\n\n  WPGRecord\n    Rec;\n\n  WPG2Record\n    Rec2;\n\n  WPG2Start StartWPG;\n\n  WPGBitmapType1\n    BitmapHeader1;\n\n  WPG2BitmapType1\n    Bitmap2Header1;\n\n  WPGBitmapType2\n    BitmapHeader2;\n\n  WPGColorMapRec\n    WPG_Palette;\n\n  int\n    i,\n    bpp,\n    WPG2Flags;\n\n  ssize_t\n    ldblk;\n\n  size_t\n    one;\n\n  unsigned char\n    *BImgBuff;\n\n  tCTM CTM;         /*current transform matrix*/\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  one=1;\n  image=AcquireImage(image_info,exception);\n  image->depth=8;\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read WPG image.\n  */\n  Header.FileId=ReadBlobLSBLong(image);\n  Header.DataOffset=(MagickOffsetType) ReadBlobLSBLong(image);\n  Header.ProductType=ReadBlobLSBShort(image);\n  Header.FileType=ReadBlobLSBShort(image);\n  Header.MajorVersion=ReadBlobByte(image);\n  Header.MinorVersion=ReadBlobByte(image);\n  Header.EncryptKey=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.FileId!=0x435057FF || (Header.ProductType>>8)!=0x16)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (Header.EncryptKey!=0)\n    ThrowReaderException(CoderError,\"EncryptedWPGImageFileNotSupported\");\n\n  image->columns = 1;\n  image->rows = 1;\n  image->colors = 0;\n  bpp=0;\n  BitmapHeader2.RotAngle=0;\n\n  switch(Header.FileType)\n    {\n    case 1:     /* WPG level 1 */\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec.RecordLength;\n\n          switch(Rec.RecType)\n            {\n            case 0x0B: /* bitmap type 1 */\n              BitmapHeader1.Width=ReadBlobLSBShort(image);\n              BitmapHeader1.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader1.Width == 0) || (BitmapHeader1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader1.Depth=ReadBlobLSBShort(image);\n              BitmapHeader1.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader1.VertRes=ReadBlobLSBShort(image);\n\n              if(BitmapHeader1.HorzRes && BitmapHeader1.VertRes)\n                {\n                  image->units=PixelsPerCentimeterResolution;\n                  image->resolution.x=BitmapHeader1.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader1.VertRes/470.0;\n                }\n              image->columns=BitmapHeader1.Width;\n              image->rows=BitmapHeader1.Height;\n              bpp=BitmapHeader1.Depth;\n\n              goto UnpackRaster;\n\n            case 0x0E:  /*Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (!AcquireImageColormap(image,image->colors,exception))\n                goto NoMemory;\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                }\n              break;\n     \n            case 0x11:  /* Start PS l1 */\n              if(Rec.RecordLength > 8)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+8,   /* skip PS header in the wpg */\n                  (ssize_t) Rec.RecordLength-8,exception);\n              break;     \n\n            case 0x14:  /* bitmap type 2 */\n              BitmapHeader2.RotAngle=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftX=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftY=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightX=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightY=ReadBlobLSBShort(image);\n              BitmapHeader2.Width=ReadBlobLSBShort(image);\n              BitmapHeader2.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader2.Width == 0) || (BitmapHeader2.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader2.Depth=ReadBlobLSBShort(image);\n              BitmapHeader2.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader2.VertRes=ReadBlobLSBShort(image);\n\n              image->units=PixelsPerCentimeterResolution;\n              image->page.width=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightX)/470.0);\n              image->page.height=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightY)/470.0);\n              image->page.x=(int) (BitmapHeader2.LowLeftX/470.0);\n              image->page.y=(int) (BitmapHeader2.LowLeftX/470.0);\n              if(BitmapHeader2.HorzRes && BitmapHeader2.VertRes)\n                {\n                  image->resolution.x=BitmapHeader2.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader2.VertRes/470.0;\n                }\n              image->columns=BitmapHeader2.Width;\n              image->rows=BitmapHeader2.Height;\n              bpp=BitmapHeader2.Depth;\n\n            UnpackRaster:      \n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    {\n                    NoMemory:\n                      ThrowReaderException(ResourceLimitError,\n                        \"MemoryAllocationFailed\");\n                    }\n                  /* printf(\"Load default colormap \\n\"); */\n                  for (i=0; (i < (int) image->colors) && (i < 256); i++)\n                    {               \n                      image->colormap[i].red=ScaleCharToQuantum(WPG1_Palette[i].Red);\n                      image->colormap[i].green=ScaleCharToQuantum(WPG1_Palette[i].Green);\n                      image->colormap[i].blue=ScaleCharToQuantum(WPG1_Palette[i].Blue);\n                    }\n                }\n              else\n                {\n                  if (bpp < 24)\n                    if ( (image->colors < (one << bpp)) && (bpp != 24) )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                        image->colormap,(size_t) (one << bpp),\n                        sizeof(*image->colormap));\n                }\n          \n              if (bpp == 1)\n                {\n                  if(image->colormap[0].red==0 &&\n                     image->colormap[0].green==0 &&\n                     image->colormap[0].blue==0 &&\n                     image->colormap[1].red==0 &&\n                     image->colormap[1].green==0 &&\n                     image->colormap[1].blue==0)\n                    {  /* fix crippled monochrome palette */\n                      image->colormap[1].red =\n                        image->colormap[1].green =\n                        image->colormap[1].blue = QuantumRange;\n                    }\n                }      \n\n              if(UnpackWPGRaster(image,bpp,exception) < 0)\n                /* The raster cannot be unpacked */\n                {\n                DecompressionFailed:\n                  ThrowReaderException(CoderError,\"UnableToDecompressImage\");\n                    }\n\n              if(Rec.RecType==0x14 && BitmapHeader2.RotAngle!=0 && !image_info->ping)\n                {  \n                  /* flop command */\n                  if(BitmapHeader2.RotAngle & 0x8000)\n                    {\n                      Image\n                        *flop_image;\n\n                      flop_image = FlopImage(image, exception);\n                      if (flop_image != (Image *) NULL) {\n                        DuplicateBlob(flop_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flop_image);\n                      }\n                    }\n                  /* flip command */\n                  if(BitmapHeader2.RotAngle & 0x2000)\n                    {\n                      Image\n                        *flip_image;\n\n                      flip_image = FlipImage(image, exception);\n                      if (flip_image != (Image *) NULL) {\n                        DuplicateBlob(flip_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flip_image);    \n                      }\n                    }\n    \n      /* rotate command */\n                  if(BitmapHeader2.RotAngle & 0x0FFF)\n                    {\n                      Image\n                        *rotate_image;\n\n                      rotate_image=RotateImage(image,(BitmapHeader2.RotAngle &\n                        0x0FFF), exception);\n                      if (rotate_image != (Image *) NULL) {\n                        DuplicateBlob(rotate_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,rotate_image);    \n                      }\n                    }                \n                }\n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=0;\n              image->colors=0;\n              break;\n\n            case 0x1B:  /* Postscript l2 */\n              if(Rec.RecordLength>0x3C)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+0x3C,   /* skip PS l2 header in the wpg */\n                  (ssize_t) Rec.RecordLength-0x3C,exception);\n              break;\n            }\n        }\n      break;\n\n    case 2:  /* WPG level 2 */\n      (void) memset(CTM,0,sizeof(CTM));\n      StartWPG.PosSizePrecision = 0;\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec2.Class=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rec2.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec2.Extension);\n          Rd_WP_DWORD(image,&Rec2.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec2.RecordLength;\n\n          switch(Rec2.RecType)\n            {\n      case 1:\n              StartWPG.HorizontalUnits=ReadBlobLSBShort(image);\n              StartWPG.VerticalUnits=ReadBlobLSBShort(image);\n              StartWPG.PosSizePrecision=ReadBlobByte(image);\n              break;\n            case 0x0C:    /* Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  (void) ReadBlobByte(image);   /*Opacity??*/\n                }\n              break;\n            case 0x0E:\n              Bitmap2Header1.Width=ReadBlobLSBShort(image);\n              Bitmap2Header1.Height=ReadBlobLSBShort(image);\n              if ((Bitmap2Header1.Width == 0) || (Bitmap2Header1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              Bitmap2Header1.Depth=ReadBlobByte(image);\n              Bitmap2Header1.Compression=ReadBlobByte(image);\n\n              if(Bitmap2Header1.Compression > 1)\n                continue; /*Unknown compression method */\n              switch(Bitmap2Header1.Depth)\n                {\n                case 1:\n                  bpp=1;\n                  break;\n                case 2:\n                  bpp=2;\n                  break;\n                case 3:\n                  bpp=4;\n                  break;\n                case 4:\n                  bpp=8;\n                  break;\n                case 8:\n                  bpp=24;\n                  break;\n                default:\n                  continue;  /*Ignore raster with unknown depth*/\n                }\n              image->columns=Bitmap2Header1.Width;\n              image->rows=Bitmap2Header1.Height;  \n\n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  size_t\n                    one;\n\n                  one=1;\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    goto NoMemory;\n                }\n              else\n                {\n                  if(bpp < 24)\n                    if( image->colors<(one << bpp) && bpp!=24 )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                       image->colormap,(size_t) (one << bpp),\n                       sizeof(*image->colormap));\n                }\n\n\n              switch(Bitmap2Header1.Compression)\n                {\n                case 0:    /*Uncompressed raster*/\n                  {\n                    ldblk=(ssize_t) ((bpp*image->columns+7)/8);\n                    BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t)\n                      ldblk,sizeof(*BImgBuff));\n                    if (BImgBuff == (unsigned char *) NULL)\n                      goto NoMemory;\n\n                    for(i=0; i< (ssize_t) image->rows; i++)\n                      {\n                        (void) ReadBlob(image,ldblk,BImgBuff);\n                        InsertRow(image,BImgBuff,i,bpp,exception);\n                      }\n\n                    if(BImgBuff)\n                      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);;\n                    break;\n                  }\n                case 1:    /*RLE for WPG2 */\n                  {\n                    if( UnpackWPG2Raster(image,bpp,exception) < 0)\n                      goto DecompressionFailed;\n                    break;\n                  }   \n                }\n\n              if(CTM[0][0]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flop_image;\n\n                  flop_image = FlopImage(image, exception);\n                  if (flop_image != (Image *) NULL) {\n                    DuplicateBlob(flop_image,image);\n                    (void) RemoveLastImageFromList(&image);\n                    AppendImageToList(&image,flop_image);\n                  }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.      \n                     Tx(0,0)=-1;      Tx(1,0)=0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;      Tx(1,1)=1;   Tx(2,1)=0;\n                     Tx(0,2)=(WPG._2Rect.X_ur+WPG._2Rect.X_ll);\n                     Tx(1,2)=0;   Tx(2,2)=1; */                  \n                }\n              if(CTM[1][1]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flip_image;\n\n                   flip_image = FlipImage(image, exception);\n                   if (flip_image != (Image *) NULL) {\n                     DuplicateBlob(flip_image,image);\n                     (void) RemoveLastImageFromList(&image);\n                     AppendImageToList(&image,flip_image);\n                    }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.\n                     float_matrix Tx(3,3);\n                     Tx(0,0)= 1;   Tx(1,0)= 0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;   Tx(1,1)=-1;   Tx(2,1)=0;\n                     Tx(0,2)= 0;   Tx(1,2)=(WPG._2Rect.Y_ur+WPG._2Rect.Y_ll);\n                     Tx(2,2)=1; */      \n              }    \n    \n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=1;\n              image->colors=0;\n              break;\n\n            case 0x12:  /* Postscript WPG2*/\n        i=ReadBlobLSBShort(image);\n              if(Rec2.RecordLength > (unsigned int) i)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+i,    /*skip PS header in the wpg2*/\n                  (ssize_t) (Rec2.RecordLength-i-2),exception);\n              break;\n\n      case 0x1B:          /*bitmap rectangle*/\n              WPG2Flags = LoadWPG2Flags(image,StartWPG.PosSizePrecision,NULL,&CTM);\n              (void) WPG2Flags;\n              break;\n            }\n        }\n\n      break;\n\n    default:\n      {\n         ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n      }\n   }\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n Finish:\n  (void) CloseBlob(image);\n\n  {\n    Image\n      *p;\n\n    ssize_t\n      scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    /*\n      Fix scene numbers.\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=(size_t) scene++;\n  }\n  if (image == (Image *) NULL)\n    ThrowReaderException(CorruptImageError,\n      \"ImageFileDoesNotContainAnyImageData\");\n  return(image);\n}", "func_src_after": "static Image *ReadWPGImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  typedef struct\n  {\n    size_t FileId;\n    MagickOffsetType DataOffset;\n    unsigned int ProductType;\n    unsigned int FileType;\n    unsigned char MajorVersion;\n    unsigned char MinorVersion;\n    unsigned int EncryptKey;\n    unsigned int Reserved;\n  } WPGHeader;\n\n  typedef struct\n  {\n    unsigned char RecType;\n    size_t RecordLength;\n  } WPGRecord;\n\n  typedef struct\n  {\n    unsigned char Class;\n    unsigned char RecType;\n    size_t Extension;\n    size_t RecordLength;\n  } WPG2Record;\n\n  typedef struct\n  {\n    unsigned  HorizontalUnits;\n    unsigned  VerticalUnits;\n    unsigned char PosSizePrecision;\n  } WPG2Start;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType1;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned char Depth;\n    unsigned char Compression;\n  } WPG2BitmapType1;\n\n  typedef struct\n  {\n    unsigned int RotAngle;\n    unsigned int LowLeftX;\n    unsigned int LowLeftY;\n    unsigned int UpRightX;\n    unsigned int UpRightY;\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType2;\n\n  typedef struct\n  {\n    unsigned int StartIndex;\n    unsigned int NumOfEntries;\n  } WPGColorMapRec;\n\n  /*\n  typedef struct {\n    size_t PS_unknown1;\n    unsigned int PS_unknown2;\n    unsigned int PS_unknown3;\n  } WPGPSl1Record;  \n  */\n\n  Image\n    *image;\n\n  unsigned int\n    status;\n\n  WPGHeader\n    Header;\n\n  WPGRecord\n    Rec;\n\n  WPG2Record\n    Rec2;\n\n  WPG2Start StartWPG;\n\n  WPGBitmapType1\n    BitmapHeader1;\n\n  WPG2BitmapType1\n    Bitmap2Header1;\n\n  WPGBitmapType2\n    BitmapHeader2;\n\n  WPGColorMapRec\n    WPG_Palette;\n\n  int\n    i,\n    bpp,\n    WPG2Flags;\n\n  ssize_t\n    ldblk;\n\n  size_t\n    one;\n\n  unsigned char\n    *BImgBuff;\n\n  tCTM CTM;         /*current transform matrix*/\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  one=1;\n  image=AcquireImage(image_info,exception);\n  image->depth=8;\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read WPG image.\n  */\n  Header.FileId=ReadBlobLSBLong(image);\n  Header.DataOffset=(MagickOffsetType) ReadBlobLSBLong(image);\n  Header.ProductType=ReadBlobLSBShort(image);\n  Header.FileType=ReadBlobLSBShort(image);\n  Header.MajorVersion=ReadBlobByte(image);\n  Header.MinorVersion=ReadBlobByte(image);\n  Header.EncryptKey=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.FileId!=0x435057FF || (Header.ProductType>>8)!=0x16)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (Header.EncryptKey!=0)\n    ThrowReaderException(CoderError,\"EncryptedWPGImageFileNotSupported\");\n\n  image->columns = 1;\n  image->rows = 1;\n  image->colors = 0;\n  bpp=0;\n  BitmapHeader2.RotAngle=0;\n\n  switch(Header.FileType)\n    {\n    case 1:     /* WPG level 1 */\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec.RecordLength;\n\n          switch(Rec.RecType)\n            {\n            case 0x0B: /* bitmap type 1 */\n              BitmapHeader1.Width=ReadBlobLSBShort(image);\n              BitmapHeader1.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader1.Width == 0) || (BitmapHeader1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader1.Depth=ReadBlobLSBShort(image);\n              BitmapHeader1.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader1.VertRes=ReadBlobLSBShort(image);\n\n              if(BitmapHeader1.HorzRes && BitmapHeader1.VertRes)\n                {\n                  image->units=PixelsPerCentimeterResolution;\n                  image->resolution.x=BitmapHeader1.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader1.VertRes/470.0;\n                }\n              image->columns=BitmapHeader1.Width;\n              image->rows=BitmapHeader1.Height;\n              bpp=BitmapHeader1.Depth;\n\n              goto UnpackRaster;\n\n            case 0x0E:  /*Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (!AcquireImageColormap(image,image->colors,exception))\n                goto NoMemory;\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                }\n              break;\n     \n            case 0x11:  /* Start PS l1 */\n              if(Rec.RecordLength > 8)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+8,   /* skip PS header in the wpg */\n                  (ssize_t) Rec.RecordLength-8,exception);\n              break;     \n\n            case 0x14:  /* bitmap type 2 */\n              BitmapHeader2.RotAngle=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftX=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftY=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightX=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightY=ReadBlobLSBShort(image);\n              BitmapHeader2.Width=ReadBlobLSBShort(image);\n              BitmapHeader2.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader2.Width == 0) || (BitmapHeader2.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader2.Depth=ReadBlobLSBShort(image);\n              BitmapHeader2.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader2.VertRes=ReadBlobLSBShort(image);\n\n              image->units=PixelsPerCentimeterResolution;\n              image->page.width=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightX)/470.0);\n              image->page.height=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightY)/470.0);\n              image->page.x=(int) (BitmapHeader2.LowLeftX/470.0);\n              image->page.y=(int) (BitmapHeader2.LowLeftX/470.0);\n              if(BitmapHeader2.HorzRes && BitmapHeader2.VertRes)\n                {\n                  image->resolution.x=BitmapHeader2.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader2.VertRes/470.0;\n                }\n              image->columns=BitmapHeader2.Width;\n              image->rows=BitmapHeader2.Height;\n              bpp=BitmapHeader2.Depth;\n\n            UnpackRaster:      \n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    {\n                    NoMemory:\n                      ThrowReaderException(ResourceLimitError,\n                        \"MemoryAllocationFailed\");\n                    }\n                  /* printf(\"Load default colormap \\n\"); */\n                  for (i=0; (i < (int) image->colors) && (i < 256); i++)\n                    {               \n                      image->colormap[i].red=ScaleCharToQuantum(WPG1_Palette[i].Red);\n                      image->colormap[i].green=ScaleCharToQuantum(WPG1_Palette[i].Green);\n                      image->colormap[i].blue=ScaleCharToQuantum(WPG1_Palette[i].Blue);\n                    }\n                }\n              else\n                {\n                  if (bpp < 24)\n                    if ( (image->colors < (one << bpp)) && (bpp != 24) )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                        image->colormap,(size_t) (one << bpp),\n                        sizeof(*image->colormap));\n                }\n          \n              if (bpp == 1)\n                {\n                  if(image->colormap[0].red==0 &&\n                     image->colormap[0].green==0 &&\n                     image->colormap[0].blue==0 &&\n                     image->colormap[1].red==0 &&\n                     image->colormap[1].green==0 &&\n                     image->colormap[1].blue==0)\n                    {  /* fix crippled monochrome palette */\n                      image->colormap[1].red =\n                        image->colormap[1].green =\n                        image->colormap[1].blue = QuantumRange;\n                    }\n                }      \n\n              if(UnpackWPGRaster(image,bpp,exception) < 0)\n                /* The raster cannot be unpacked */\n                {\n                DecompressionFailed:\n                  ThrowReaderException(CoderError,\"UnableToDecompressImage\");\n                    }\n\n              if(Rec.RecType==0x14 && BitmapHeader2.RotAngle!=0 && !image_info->ping)\n                {  \n                  /* flop command */\n                  if(BitmapHeader2.RotAngle & 0x8000)\n                    {\n                      Image\n                        *flop_image;\n\n                      flop_image = FlopImage(image, exception);\n                      if (flop_image != (Image *) NULL) {\n                        DuplicateBlob(flop_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flop_image);\n                      }\n                    }\n                  /* flip command */\n                  if(BitmapHeader2.RotAngle & 0x2000)\n                    {\n                      Image\n                        *flip_image;\n\n                      flip_image = FlipImage(image, exception);\n                      if (flip_image != (Image *) NULL) {\n                        DuplicateBlob(flip_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flip_image);    \n                      }\n                    }\n    \n      /* rotate command */\n                  if(BitmapHeader2.RotAngle & 0x0FFF)\n                    {\n                      Image\n                        *rotate_image;\n\n                      rotate_image=RotateImage(image,(BitmapHeader2.RotAngle &\n                        0x0FFF), exception);\n                      if (rotate_image != (Image *) NULL) {\n                        DuplicateBlob(rotate_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,rotate_image);    \n                      }\n                    }                \n                }\n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=0;\n              image->colors=0;\n              break;\n\n            case 0x1B:  /* Postscript l2 */\n              if(Rec.RecordLength>0x3C)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+0x3C,   /* skip PS l2 header in the wpg */\n                  (ssize_t) Rec.RecordLength-0x3C,exception);\n              break;\n            }\n        }\n      break;\n\n    case 2:  /* WPG level 2 */\n      (void) memset(CTM,0,sizeof(CTM));\n      StartWPG.PosSizePrecision = 0;\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec2.Class=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rec2.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec2.Extension);\n          Rd_WP_DWORD(image,&Rec2.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec2.RecordLength;\n\n          switch(Rec2.RecType)\n            {\n      case 1:\n              StartWPG.HorizontalUnits=ReadBlobLSBShort(image);\n              StartWPG.VerticalUnits=ReadBlobLSBShort(image);\n              StartWPG.PosSizePrecision=ReadBlobByte(image);\n              break;\n            case 0x0C:    /* Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  (void) ReadBlobByte(image);   /*Opacity??*/\n                }\n              break;\n            case 0x0E:\n              Bitmap2Header1.Width=ReadBlobLSBShort(image);\n              Bitmap2Header1.Height=ReadBlobLSBShort(image);\n              if ((Bitmap2Header1.Width == 0) || (Bitmap2Header1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              Bitmap2Header1.Depth=ReadBlobByte(image);\n              Bitmap2Header1.Compression=ReadBlobByte(image);\n\n              if(Bitmap2Header1.Compression > 1)\n                continue; /*Unknown compression method */\n              switch(Bitmap2Header1.Depth)\n                {\n                case 1:\n                  bpp=1;\n                  break;\n                case 2:\n                  bpp=2;\n                  break;\n                case 3:\n                  bpp=4;\n                  break;\n                case 4:\n                  bpp=8;\n                  break;\n                case 8:\n                  bpp=24;\n                  break;\n                default:\n                  continue;  /*Ignore raster with unknown depth*/\n                }\n              image->columns=Bitmap2Header1.Width;\n              image->rows=Bitmap2Header1.Height;  \n\n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  size_t\n                    one;\n\n                  one=1;\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    goto NoMemory;\n                }\n              else\n                {\n                  if(bpp < 24)\n                    if( image->colors<(one << bpp) && bpp!=24 )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                       image->colormap,(size_t) (one << bpp),\n                       sizeof(*image->colormap));\n                }\n\n\n              switch(Bitmap2Header1.Compression)\n                {\n                case 0:    /*Uncompressed raster*/\n                  {\n                    ldblk=(ssize_t) ((bpp*image->columns+7)/8);\n                    BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t)\n                      ldblk+1,sizeof(*BImgBuff));\n                    if (BImgBuff == (unsigned char *) NULL)\n                      goto NoMemory;\n\n                    for(i=0; i< (ssize_t) image->rows; i++)\n                      {\n                        (void) ReadBlob(image,ldblk,BImgBuff);\n                        InsertRow(image,BImgBuff,i,bpp,exception);\n                      }\n\n                    if(BImgBuff)\n                      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);;\n                    break;\n                  }\n                case 1:    /*RLE for WPG2 */\n                  {\n                    if( UnpackWPG2Raster(image,bpp,exception) < 0)\n                      goto DecompressionFailed;\n                    break;\n                  }   \n                }\n\n              if(CTM[0][0]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flop_image;\n\n                  flop_image = FlopImage(image, exception);\n                  if (flop_image != (Image *) NULL) {\n                    DuplicateBlob(flop_image,image);\n                    (void) RemoveLastImageFromList(&image);\n                    AppendImageToList(&image,flop_image);\n                  }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.      \n                     Tx(0,0)=-1;      Tx(1,0)=0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;      Tx(1,1)=1;   Tx(2,1)=0;\n                     Tx(0,2)=(WPG._2Rect.X_ur+WPG._2Rect.X_ll);\n                     Tx(1,2)=0;   Tx(2,2)=1; */                  \n                }\n              if(CTM[1][1]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flip_image;\n\n                   flip_image = FlipImage(image, exception);\n                   if (flip_image != (Image *) NULL) {\n                     DuplicateBlob(flip_image,image);\n                     (void) RemoveLastImageFromList(&image);\n                     AppendImageToList(&image,flip_image);\n                    }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.\n                     float_matrix Tx(3,3);\n                     Tx(0,0)= 1;   Tx(1,0)= 0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;   Tx(1,1)=-1;   Tx(2,1)=0;\n                     Tx(0,2)= 0;   Tx(1,2)=(WPG._2Rect.Y_ur+WPG._2Rect.Y_ll);\n                     Tx(2,2)=1; */      \n              }    \n    \n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=1;\n              image->colors=0;\n              break;\n\n            case 0x12:  /* Postscript WPG2*/\n        i=ReadBlobLSBShort(image);\n              if(Rec2.RecordLength > (unsigned int) i)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+i,    /*skip PS header in the wpg2*/\n                  (ssize_t) (Rec2.RecordLength-i-2),exception);\n              break;\n\n      case 0x1B:          /*bitmap rectangle*/\n              WPG2Flags = LoadWPG2Flags(image,StartWPG.PosSizePrecision,NULL,&CTM);\n              (void) WPG2Flags;\n              break;\n            }\n        }\n\n      break;\n\n    default:\n      {\n         ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n      }\n   }\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n Finish:\n  (void) CloseBlob(image);\n\n  {\n    Image\n      *p;\n\n    ssize_t\n      scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    /*\n      Fix scene numbers.\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=(size_t) scene++;\n  }\n  if (image == (Image *) NULL)\n    ThrowReaderException(CorruptImageError,\n      \"ImageFileDoesNotContainAnyImageData\");\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/bef1e4f637d8f665bc133a9c6d30df08d983bc3a", "file_name": "coders/wpg.c", "vul_type": "cwe-125", "description": "Write a C function to read and process WPG images."}
{"func_name": "exprListAppendList", "func_src_before": "static ExprList *exprListAppendList(\n  Parse *pParse,          /* Parsing context */\n  ExprList *pList,        /* List to which to append. Might be NULL */\n  ExprList *pAppend,      /* List of values to append. Might be NULL */\n  int bIntToNull\n){\n  if( pAppend ){\n    int i;\n    int nInit = pList ? pList->nExpr : 0;\n    for(i=0; i<pAppend->nExpr; i++){\n      Expr *pDup = sqlite3ExprDup(pParse->db, pAppend->a[i].pExpr, 0);\n      if( bIntToNull && pDup && pDup->op==TK_INTEGER ){\n        pDup->op = TK_NULL;\n        pDup->flags &= ~(EP_IntValue|EP_IsTrue|EP_IsFalse);\n      }\n      pList = sqlite3ExprListAppend(pParse, pList, pDup);\n      if( pList ) pList->a[nInit+i].sortFlags = pAppend->a[i].sortFlags;\n    }\n  }\n  return pList;\n}", "func_src_after": "static ExprList *exprListAppendList(\n  Parse *pParse,          /* Parsing context */\n  ExprList *pList,        /* List to which to append. Might be NULL */\n  ExprList *pAppend,      /* List of values to append. Might be NULL */\n  int bIntToNull\n){\n  if( pAppend ){\n    int i;\n    int nInit = pList ? pList->nExpr : 0;\n    for(i=0; i<pAppend->nExpr; i++){\n      Expr *pDup = sqlite3ExprDup(pParse->db, pAppend->a[i].pExpr, 0);\n      assert( pDup==0 || !ExprHasProperty(pDup, EP_MemToken) );\n      if( bIntToNull && pDup && pDup->op==TK_INTEGER ){\n        pDup->op = TK_NULL;\n        pDup->flags &= ~(EP_IntValue|EP_IsTrue|EP_IsFalse);\n        pDup->u.zToken = 0;\n      }\n      pList = sqlite3ExprListAppend(pParse, pList, pDup);\n      if( pList ) pList->a[nInit+i].sortFlags = pAppend->a[i].sortFlags;\n    }\n  }\n  return pList;\n}", "commit_link": "github.com/sqlite/sqlite/commit/75e95e1fcd52d3ec8282edb75ac8cd0814095d54", "file_name": "src/window.c", "vul_type": "cwe-476", "description": "Write a C function to append one expression list to another in SQLite, with an option to convert integers to NULL."}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    statement = \"INSERT INTO matches values ({w}, {l})\".format(w=w, l=l)\n    c.execute(statement)\n    db.commit()\n    db.close()", "func_src_after": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO matches values (%s, %s)\", (w,l))\n    db.commit()\n    db.close()", "commit_link": "github.com/tdnelson2/tournament-db/commit/00f3caeed0e12e806c2808d100908698777d9e98", "file_name": "tournament.py", "vul_type": "cwe-089", "description": "Write a Python function to record the outcome of a match by inserting the winner and loser IDs into a database."}
{"func_name": "(anonymous)", "func_src_before": "                $(document.body).on('click', '.modal-trigger-inline', function (e) {\n                    e.preventDefault();\n                    var modalElement = $('#modal-inline');\n                    var eventTrigger = $(this);\n\n                    if (eventTrigger.attr('title')) {\n                        $('.modal-title', modalElement).html(eventTrigger.attr('title'));\n                    }\n\n                    $('.modal-body', modalElement).html('').show().load(eventTrigger.attr('href'), function () {\n                        setTimeout(CMS.attach.formEnhancements, 200);\n                    });\n\n                    modalElement.modal();\n                });", "func_src_after": "                $(document.body).on('click', '.modal-trigger-inline', function (e) {\n                    e.preventDefault();\n                    var modalElement = $('#modal-inline');\n                    var eventTrigger = $(this);\n\n                    if (eventTrigger.attr('title')) {\n                        $('.modal-title', modalElement).text(eventTrigger.attr('title'));\n                    }\n\n                    $('.modal-body', modalElement).html('').show().load(eventTrigger.attr('href'), function () {\n                        setTimeout(CMS.attach.formEnhancements, 200);\n                    });\n\n                    modalElement.modal();\n                });", "line_changes": {"deleted": [{"line_no": 7, "char_start": 287, "char_end": 377, "line": "                        $('.modal-title', modalElement).html(eventTrigger.attr('title'));\n"}], "added": [{"line_no": 7, "char_start": 287, "char_end": 377, "line": "                        $('.modal-title', modalElement).text(eventTrigger.attr('title'));\n"}]}, "char_changes": {"deleted": [{"char_start": 343, "char_end": 347, "chars": "html"}], "added": [{"char_start": 343, "char_end": 347, "chars": "text"}]}, "commit_link": "github.com/WeAreAthlon/silla.io/commit/5a251701f8dc73d1cd9a421d31295edef1faa9b4", "file_name": "cms.silla.js", "vul_type": "cwe-079", "commit_msg": "Prevent XSS in resource titles set as Modal titles", "description": "Create a jQuery script that opens a modal with content loaded from the clicked element's href attribute and optionally sets the modal's title."}
{"func_name": "xsltKeyFunction", "func_src_before": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "func_src_after": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n        if (ret == NULL) {\n            ctxt->error = XPATH_MEMORY_ERROR;\n            xmlXPathFreeObject(obj1);\n            xmlXPathFreeObject(obj2);\n            return;\n        }\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "commit_link": "github.com/GNOME/libxslt/commit/aab7eedca3c2dcaa1795d6acba38a4c9811d2a75", "file_name": "libxslt/functions.c", "vul_type": "cwe-476", "description": "Write a C function named `xsltKeyFunction` that implements the XSLT key function in libxml2."}
{"func_name": "NeXTDecode", "func_src_before": "NeXTDecode(TIFF* tif, uint8* buf, tmsize_t occ, uint16 s)\n{\n\tstatic const char module[] = \"NeXTDecode\";\n\tunsigned char *bp, *op;\n\ttmsize_t cc;\n\tuint8* row;\n\ttmsize_t scanline, n;\n\n\t(void) s;\n\t/*\n\t * Each scanline is assumed to start off as all\n\t * white (we assume a PhotometricInterpretation\n\t * of ``min-is-black'').\n\t */\n\tfor (op = (unsigned char*) buf, cc = occ; cc-- > 0;)\n\t\t*op++ = 0xff;\n\n\tbp = (unsigned char *)tif->tif_rawcp;\n\tcc = tif->tif_rawcc;\n\tscanline = tif->tif_scanlinesize;\n\tif (occ % scanline)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata, module, \"Fractional scanlines cannot be read\");\n\t\treturn (0);\n\t}\n\tfor (row = buf; cc > 0 && occ > 0; occ -= scanline, row += scanline) {\n\t\tn = *bp++, cc--;\n\t\tswitch (n) {\n\t\tcase LITERALROW:\n\t\t\t/*\n\t\t\t * The entire scanline is given as literal values.\n\t\t\t */\n\t\t\tif (cc < scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row, bp, scanline);\n\t\t\tbp += scanline;\n\t\t\tcc -= scanline;\n\t\t\tbreak;\n\t\tcase LITERALSPAN: {\n\t\t\ttmsize_t off;\n\t\t\t/*\n\t\t\t * The scanline has a literal span that begins at some\n\t\t\t * offset.\n\t\t\t */\n\t\t\tif( cc < 4 )\n\t\t\t\tgoto bad;\n\t\t\toff = (bp[0] * 256) + bp[1];\n\t\t\tn = (bp[2] * 256) + bp[3];\n\t\t\tif (cc < 4+n || off+n > scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row+off, bp+4, n);\n\t\t\tbp += 4+n;\n\t\t\tcc -= 4+n;\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tuint32 npixels = 0, grey;\n\t\t\tuint32 imagewidth = tif->tif_dir.td_imagewidth;\n            if( isTiled(tif) )\n                imagewidth = tif->tif_dir.td_tilewidth;\n\n\t\t\t/*\n\t\t\t * The scanline is composed of a sequence of constant\n\t\t\t * color ``runs''.  We shift into ``run mode'' and\n\t\t\t * interpret bytes as codes of the form\n\t\t\t * <color><npixels> until we've filled the scanline.\n\t\t\t */\n\t\t\top = row;\n\t\t\tfor (;;) {\n\t\t\t\tgrey = (uint32)((n>>6) & 0x3);\n\t\t\t\tn &= 0x3f;\n\t\t\t\t/*\n\t\t\t\t * Ensure the run does not exceed the scanline\n\t\t\t\t * bounds, potentially resulting in a security\n\t\t\t\t * issue.\n\t\t\t\t */\n\t\t\t\twhile (n-- > 0 && npixels < imagewidth)\n\t\t\t\t\tSETPIXEL(op, grey);\n\t\t\t\tif (npixels >= imagewidth)\n\t\t\t\t\tbreak;\n\t\t\t\tif (cc == 0)\n\t\t\t\t\tgoto bad;\n\t\t\t\tn = *bp++, cc--;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\t}\n\t}\n\ttif->tif_rawcp = (uint8*) bp;\n\ttif->tif_rawcc = cc;\n\treturn (1);\nbad:\n\tTIFFErrorExt(tif->tif_clientdata, module, \"Not enough data for scanline %ld\",\n\t    (long) tif->tif_row);\n\treturn (0);\n}", "func_src_after": "NeXTDecode(TIFF* tif, uint8* buf, tmsize_t occ, uint16 s)\n{\n\tstatic const char module[] = \"NeXTDecode\";\n\tunsigned char *bp, *op;\n\ttmsize_t cc;\n\tuint8* row;\n\ttmsize_t scanline, n;\n\n\t(void) s;\n\t/*\n\t * Each scanline is assumed to start off as all\n\t * white (we assume a PhotometricInterpretation\n\t * of ``min-is-black'').\n\t */\n\tfor (op = (unsigned char*) buf, cc = occ; cc-- > 0;)\n\t\t*op++ = 0xff;\n\n\tbp = (unsigned char *)tif->tif_rawcp;\n\tcc = tif->tif_rawcc;\n\tscanline = tif->tif_scanlinesize;\n\tif (occ % scanline)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata, module, \"Fractional scanlines cannot be read\");\n\t\treturn (0);\n\t}\n\tfor (row = buf; cc > 0 && occ > 0; occ -= scanline, row += scanline) {\n\t\tn = *bp++, cc--;\n\t\tswitch (n) {\n\t\tcase LITERALROW:\n\t\t\t/*\n\t\t\t * The entire scanline is given as literal values.\n\t\t\t */\n\t\t\tif (cc < scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row, bp, scanline);\n\t\t\tbp += scanline;\n\t\t\tcc -= scanline;\n\t\t\tbreak;\n\t\tcase LITERALSPAN: {\n\t\t\ttmsize_t off;\n\t\t\t/*\n\t\t\t * The scanline has a literal span that begins at some\n\t\t\t * offset.\n\t\t\t */\n\t\t\tif( cc < 4 )\n\t\t\t\tgoto bad;\n\t\t\toff = (bp[0] * 256) + bp[1];\n\t\t\tn = (bp[2] * 256) + bp[3];\n\t\t\tif (cc < 4+n || off+n > scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row+off, bp+4, n);\n\t\t\tbp += 4+n;\n\t\t\tcc -= 4+n;\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tuint32 npixels = 0, grey;\n\t\t\tuint32 imagewidth = tif->tif_dir.td_imagewidth;\n            if( isTiled(tif) )\n                imagewidth = tif->tif_dir.td_tilewidth;\n            tmsize_t op_offset = 0;\n\n\t\t\t/*\n\t\t\t * The scanline is composed of a sequence of constant\n\t\t\t * color ``runs''.  We shift into ``run mode'' and\n\t\t\t * interpret bytes as codes of the form\n\t\t\t * <color><npixels> until we've filled the scanline.\n\t\t\t */\n\t\t\top = row;\n\t\t\tfor (;;) {\n\t\t\t\tgrey = (uint32)((n>>6) & 0x3);\n\t\t\t\tn &= 0x3f;\n\t\t\t\t/*\n\t\t\t\t * Ensure the run does not exceed the scanline\n\t\t\t\t * bounds, potentially resulting in a security\n\t\t\t\t * issue.\n\t\t\t\t */\n\t\t\t\twhile (n-- > 0 && npixels < imagewidth && op_offset < scanline)\n\t\t\t\t\tSETPIXEL(op, grey);\n\t\t\t\tif (npixels >= imagewidth)\n\t\t\t\t\tbreak;\n                if (op_offset >= scanline ) {\n                    TIFFErrorExt(tif->tif_clientdata, module, \"Invalid data for scanline %ld\",\n                        (long) tif->tif_row);\n                    return (0);\n                }\n\t\t\t\tif (cc == 0)\n\t\t\t\t\tgoto bad;\n\t\t\t\tn = *bp++, cc--;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\t}\n\t}\n\ttif->tif_rawcp = (uint8*) bp;\n\ttif->tif_rawcc = cc;\n\treturn (1);\nbad:\n\tTIFFErrorExt(tif->tif_clientdata, module, \"Not enough data for scanline %ld\",\n\t    (long) tif->tif_row);\n\treturn (0);\n}", "commit_link": "github.com/vadz/libtiff/commit/b18012dae552f85dcc5c57d3bf4e997a15b1cc1c", "file_name": "libtiff/tif_next.c", "vul_type": "cwe-787", "description": "Write a C function named `NeXTDecode` that decodes a scanline from a TIFF image."}
{"func_name": "getPlayer", "func_src_before": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = '%s' COLLATE NOCASE\" % player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "func_src_after": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = ? COLLATE NOCASE\", player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function called `getPlayer` that retrieves a player's statistics from a database, ignoring case sensitivity in the player's name."}
{"func_name": "GetAvailablePort", "func_src_before": "func GetAvailablePort(t *testing.T) uint16 {\n\t// Retry has been added for windows as net.Listen can return a port that is not actually available. Details can be\n\t// found in https://github.com/docker/for-win/issues/3171 but to summarize Hyper-V will reserve ranges of ports\n\t// which do not show up under the \"netstat -ano\" but can only be found by\n\t// \"netsh interface ipv4 show excludedportrange protocol=tcp\".  We'll use []exclusions to hold those ranges and\n\t// retry if the port returned by GetAvailableLocalAddress falls in one of those them.\n\tvar exclusions []portpair\n\tportFound := false\n\tvar port string\n\tvar err error\n\tif runtime.GOOS == \"windows\" {\n\t\texclusions = getExclusionsList(t)\n\t}\n\n\tfor !portFound {\n\t\tendpoint := GetAvailableLocalAddress(t)\n\t\t_, port, err = net.SplitHostPort(endpoint)\n\t\trequire.NoError(t, err)\n\t\tportFound = true\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tfor _, pair := range exclusions {\n\t\t\t\tif port >= pair.first && port <= pair.last {\n\t\t\t\t\tportFound = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tportInt, err := strconv.Atoi(port)\n\trequire.NoError(t, err)\n\n\treturn uint16(portInt)\n}", "func_src_after": "func GetAvailablePort(t *testing.T) uint16 {\n\t// Retry has been added for windows as net.Listen can return a port that is not actually available. Details can be\n\t// found in https://github.com/docker/for-win/issues/3171 but to summarize Hyper-V will reserve ranges of ports\n\t// which do not show up under the \"netstat -ano\" but can only be found by\n\t// \"netsh interface ipv4 show excludedportrange protocol=tcp\".  We'll use []exclusions to hold those ranges and\n\t// retry if the port returned by GetAvailableLocalAddress falls in one of those them.\n\tvar exclusions []portpair\n\tportFound := false\n\tvar port string\n\tvar err error\n\tif runtime.GOOS == \"windows\" {\n\t\texclusions = getExclusionsList(t)\n\t}\n\n\tfor !portFound {\n\t\tendpoint := GetAvailableLocalAddress(t)\n\t\t_, port, err = net.SplitHostPort(endpoint)\n\t\trequire.NoError(t, err)\n\t\tportFound = true\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tfor _, pair := range exclusions {\n\t\t\t\tif port >= pair.first && port <= pair.last {\n\t\t\t\t\tportFound = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tportInt, err := strconv.ParseUint(port, 10, 16)\n\trequire.NoError(t, err)\n\n\treturn uint16(portInt)\n}", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1022, "char_end": 1058, "line": "\tportInt, err := strconv.Atoi(port)\n"}], "added": [{"line_no": 30, "char_start": 1022, "char_end": 1071, "line": "\tportInt, err := strconv.ParseUint(port, 10, 16)\n"}]}, "char_changes": {"deleted": [{"char_start": 1047, "char_end": 1056, "chars": "Atoi(port"}], "added": [{"char_start": 1047, "char_end": 1069, "chars": "ParseUint(port, 10, 16"}]}, "commit_link": "github.com/open-telemetry/opentelemetry-collector/commit/eb3601a05900f70e46c058facf16461efa7b09f0", "file_name": "testutil.go", "vul_type": "cwe-681", "commit_msg": "Avoid potential integer overflow (#4277)\n\nSigned-off-by: Bogdan Drutu <bogdandrutu@gmail.com>", "parent_commit": "db6d31e9acc546e043b7b5564377bd76998e74bd", "description": "Write a Go function that finds an available network port, with special handling for Windows due to reserved port ranges."}
{"func_name": "(anonymous)", "func_src_before": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n    });", "func_src_after": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n    });", "line_changes": {"deleted": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n"}], "added": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n"}]}, "char_changes": {"deleted": [{"char_start": 821, "char_end": 825, "chars": "html"}], "added": [{"char_start": 821, "char_end": 825, "chars": "text"}]}, "commit_link": "github.com/edmundoa/graylog2-server/commit/a88cae99955cd0ccdd5d99a1c6d506029eb15c60", "file_name": "streamrules.js", "vul_type": "cwe-079", "commit_msg": "use .text() not .html() in stream rule editor to prevent DOM XSS\n\nfixes #543", "description": "In JavaScript, write a jQuery event handler that updates text in a modal based on user input and selection changes, with special handling for an \"inverted\" checkbox state."}
{"func_name": "HPHP::extractFileTo", "func_src_before": "static bool extractFileTo(zip* zip, const std::string &file, std::string& to,\n                          char* buf, size_t len) {\n  auto sep = file.rfind('/');\n  if (sep != std::string::npos) {\n    auto path = to + file.substr(0, sep);\n    if (!HHVM_FN(is_dir)(path) && !HHVM_FN(mkdir)(path, 0777, true)) {\n      return false;\n    }\n\n    if (sep == file.length() - 1) {\n      return true;\n    }\n  }\n\n  to.append(file);\n  struct zip_stat zipStat;\n  if (zip_stat(zip, file.c_str(), 0, &zipStat) != 0) {\n    return false;\n  }\n\n  auto zipFile = zip_fopen_index(zip, zipStat.index, 0);\n  FAIL_IF_INVALID_PTR(zipFile);\n\n  auto outFile = fopen(to.c_str(), \"wb\");\n  if (outFile == nullptr) {\n    zip_fclose(zipFile);\n    return false;\n  }\n\n  for (auto n = zip_fread(zipFile, buf, len); n != 0;\n       n = zip_fread(zipFile, buf, len)) {\n    if (n < 0 || fwrite(buf, sizeof(char), n, outFile) != n) {\n      zip_fclose(zipFile);\n      fclose(outFile);\n      remove(to.c_str());\n      return false;\n    }\n  }\n\n  zip_fclose(zipFile);\n  if (fclose(outFile) != 0) {\n    return false;\n  }\n\n  return true;\n}", "func_src_after": "static bool extractFileTo(zip* zip, const std::string &file, std::string& to,\n                          char* buf, size_t len) {\n\n  struct zip_stat zipStat;\n  // Verify the file to be extracted is actually in the zip file\n  if (zip_stat(zip, file.c_str(), 0, &zipStat) != 0) {\n    return false;\n  }\n\n  auto clean_file = file;\n  auto sep = std::string::npos;\n  // Normally would just use std::string::rfind here, but if we want to be\n  // consistent between Windows and Linux, even if techincally Linux won't use\n  // backslash for a separator, we are checking for both types.\n  int idx = file.length() - 1;\n  while (idx >= 0) {\n    if (FileUtil::isDirSeparator(file[idx])) {\n      sep = idx;\n      break;\n    }\n    idx--;\n  }\n  if (sep != std::string::npos) {\n    // make_relative_path so we do not try to put files or dirs in bad\n    // places. This securely \"cleans\" the file.\n    clean_file = make_relative_path(file);\n    std::string path = to + clean_file;\n    bool is_dir_only = true;\n    if (sep < file.length() - 1) { // not just a directory\n      auto clean_file_dir = HHVM_FN(dirname)(clean_file);\n      path = to + clean_file_dir.toCppString();\n      is_dir_only = false;\n    }\n\n    // Make sure the directory path to extract to exists or can be created\n    if (!HHVM_FN(is_dir)(path) && !HHVM_FN(mkdir)(path, 0777, true)) {\n      return false;\n    }\n\n    // If we have a good directory to extract to above, we now check whether\n    // the \"file\" parameter passed in is a directory or actually a file.\n    if (is_dir_only) { // directory, like /usr/bin/\n      return true;\n    }\n    // otherwise file is actually a file, so we actually extract.\n  }\n\n  // We have ensured that clean_file will be added to a relative path by the\n  // time we get here.\n  to.append(clean_file);\n\n  auto zipFile = zip_fopen_index(zip, zipStat.index, 0);\n  FAIL_IF_INVALID_PTR(zipFile);\n\n  auto outFile = fopen(to.c_str(), \"wb\");\n  if (outFile == nullptr) {\n    zip_fclose(zipFile);\n    return false;\n  }\n\n  for (auto n = zip_fread(zipFile, buf, len); n != 0;\n       n = zip_fread(zipFile, buf, len)) {\n    if (n < 0 || fwrite(buf, sizeof(char), n, outFile) != n) {\n      zip_fclose(zipFile);\n      fclose(outFile);\n      remove(to.c_str());\n      return false;\n    }\n  }\n\n  zip_fclose(zipFile);\n  if (fclose(outFile) != 0) {\n    return false;\n  }\n\n  return true;\n}", "commit_link": "github.com/facebook/hhvm/commit/65c95a01541dd2fbc9c978ac53bed235b5376686", "file_name": "hphp/runtime/ext/zip/ext_zip.cpp", "vul_type": "cwe-022", "description": "Write a C++ function to extract a file from a zip archive to a specified directory, handling directory creation and path sanitization."}
{"func_name": "_run_ssh", "func_src_before": "    def _run_ssh(self, command, check_exit=True, attempts=1):\n        if not self.sshpool:\n            self.sshpool = utils.SSHPool(self.config.san_ip,\n                                         self.config.san_ssh_port,\n                                         self.config.ssh_conn_timeout,\n                                         self.config.san_login,\n                                         password=self.config.san_password,\n                                         privatekey=\n                                         self.config.san_private_key,\n                                         min_size=\n                                         self.config.ssh_min_pool_conn,\n                                         max_size=\n                                         self.config.ssh_max_pool_conn)\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return self._ssh_execute(ssh, command,\n                                                 check_exit_code=check_exit)\n                    except Exception as e:\n                        LOG.error(e)\n                        greenthread.sleep(randint(20, 500) / 100.0)\n                msg = (_(\"SSH Command failed after '%(total_attempts)r' \"\n                         \"attempts : '%(command)s'\") %\n                       {'total_attempts': total_attempts, 'command': command})\n                raise paramiko.SSHException(msg)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running ssh command: %s\") % command)", "func_src_after": "    def _run_ssh(self, cmd_list, check_exit=True, attempts=1):\n        utils.check_ssh_injection(cmd_list)\n        command = ' '. join(cmd_list)\n\n        if not self.sshpool:\n            self.sshpool = utils.SSHPool(self.config.san_ip,\n                                         self.config.san_ssh_port,\n                                         self.config.ssh_conn_timeout,\n                                         self.config.san_login,\n                                         password=self.config.san_password,\n                                         privatekey=\n                                         self.config.san_private_key,\n                                         min_size=\n                                         self.config.ssh_min_pool_conn,\n                                         max_size=\n                                         self.config.ssh_max_pool_conn)\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return self._ssh_execute(ssh, command,\n                                                 check_exit_code=check_exit)\n                    except Exception as e:\n                        LOG.error(e)\n                        greenthread.sleep(randint(20, 500) / 100.0)\n                msg = (_(\"SSH Command failed after '%(total_attempts)r' \"\n                         \"attempts : '%(command)s'\") %\n                       {'total_attempts': total_attempts, 'command': command})\n                raise paramiko.SSHException(msg)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running ssh command: %s\") % command)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute an SSH command using a connection pool, with retry logic on failure."}
{"func_name": "yaffsfs_istat", "func_src_before": "    yaffsfs_istat(TSK_FS_INFO *fs, TSK_FS_ISTAT_FLAG_ENUM flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    TSK_FS_META *fs_meta;\n    TSK_FS_FILE *fs_file;\n    YAFFSFS_INFO *yfs = (YAFFSFS_INFO *)fs;\n    char ls[12];\n    YAFFSFS_PRINT_ADDR print;\n    char timeBuf[32];\n    YaffsCacheObject * obj = NULL;\n    YaffsCacheVersion * version = NULL;\n    YaffsHeader * header = NULL;\n\n    yaffscache_version_find_by_inode(yfs, inum, &version, &obj);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        return 1;\n    }\n    fs_meta = fs_file->meta;\n\n    tsk_fprintf(hFile, \"inode: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_meta->flags & TSK_FS_META_FLAG_ALLOC) ? \"\" : \"Not \");\n\n    if (fs_meta->link)\n        tsk_fprintf(hFile, \"symbolic link to: %s\\n\", fs_meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_meta->uid, fs_meta->gid);\n\n    tsk_fs_meta_make_ls(fs_meta, ls, sizeof(ls));\n    tsk_fprintf(hFile, \"mode: %s\\n\", ls);\n\n    tsk_fprintf(hFile, \"size: %\" PRIdOFF \"\\n\", fs_meta->size);\n    tsk_fprintf(hFile, \"num of links: %d\\n\", fs_meta->nlink);\n\n    if(version != NULL){\n        yaffsfs_read_header(yfs, &header, version->ycv_header_chunk->ycc_offset);\n        if(header != NULL){\n            tsk_fprintf(hFile, \"Name: %s\\n\", header->name);\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted Inode Times:\\n\");\n        fs_meta->mtime -= sec_skew;\n        fs_meta->atime -= sec_skew;\n        fs_meta->ctime -= sec_skew;\n\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n        fs_meta->mtime += sec_skew;\n        fs_meta->atime += sec_skew;\n        fs_meta->ctime += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal Inode Times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nInode Times:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n    if(version != NULL){\n        tsk_fprintf(hFile, \"\\nHeader Chunk:\\n\");\n        tsk_fprintf(hFile, \"%\" PRIuDADDR \"\\n\", (version->ycv_header_chunk->ycc_offset / (yfs->page_size + yfs->spare_size)));\n    }\n\n    if (numblock > 0) {\n        TSK_OFF_T lower_size = numblock * fs->block_size;\n        fs_meta->size = (lower_size < fs_meta->size)?(lower_size):(fs_meta->size);\n    }\n    tsk_fprintf(hFile, \"\\nData Chunks:\\n\");\n\n\n    if (flags & TSK_FS_ISTAT_RUNLIST){\n        const TSK_FS_ATTR *fs_attr_default =\n            tsk_fs_file_attr_get_type(fs_file,\n                TSK_FS_ATTR_TYPE_DEFAULT, 0, 0);\n        if (fs_attr_default && (fs_attr_default->flags & TSK_FS_ATTR_NONRES)) {\n            if (tsk_fs_attr_print(fs_attr_default, hFile)) {\n                tsk_fprintf(hFile, \"\\nError creating run lists  \");\n                tsk_error_print(hFile);\n                tsk_error_reset();\n            }\n        }\n    }\n    else {\n        print.idx = 0;\n        print.hFile = hFile;\n\n        if (tsk_fs_file_walk(fs_file, TSK_FS_FILE_WALK_FLAG_AONLY,\n            (TSK_FS_FILE_WALK_CB)print_addr_act, (void *)&print)) {\n            tsk_fprintf(hFile, \"\\nError reading file:  \");\n            tsk_error_print(hFile);\n            tsk_error_reset();\n        }\n        else if (print.idx != 0) {\n            tsk_fprintf(hFile, \"\\n\");\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n\n    return 0;\n}", "func_src_after": "    yaffsfs_istat(TSK_FS_INFO *fs, TSK_FS_ISTAT_FLAG_ENUM flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    TSK_FS_META *fs_meta;\n    TSK_FS_FILE *fs_file;\n    YAFFSFS_INFO *yfs = (YAFFSFS_INFO *)fs;\n    char ls[12];\n    YAFFSFS_PRINT_ADDR print;\n    char timeBuf[128];\n    YaffsCacheObject * obj = NULL;\n    YaffsCacheVersion * version = NULL;\n    YaffsHeader * header = NULL;\n\n    yaffscache_version_find_by_inode(yfs, inum, &version, &obj);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        return 1;\n    }\n    fs_meta = fs_file->meta;\n\n    tsk_fprintf(hFile, \"inode: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_meta->flags & TSK_FS_META_FLAG_ALLOC) ? \"\" : \"Not \");\n\n    if (fs_meta->link)\n        tsk_fprintf(hFile, \"symbolic link to: %s\\n\", fs_meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_meta->uid, fs_meta->gid);\n\n    tsk_fs_meta_make_ls(fs_meta, ls, sizeof(ls));\n    tsk_fprintf(hFile, \"mode: %s\\n\", ls);\n\n    tsk_fprintf(hFile, \"size: %\" PRIdOFF \"\\n\", fs_meta->size);\n    tsk_fprintf(hFile, \"num of links: %d\\n\", fs_meta->nlink);\n\n    if(version != NULL){\n        yaffsfs_read_header(yfs, &header, version->ycv_header_chunk->ycc_offset);\n        if(header != NULL){\n            tsk_fprintf(hFile, \"Name: %s\\n\", header->name);\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted Inode Times:\\n\");\n        fs_meta->mtime -= sec_skew;\n        fs_meta->atime -= sec_skew;\n        fs_meta->ctime -= sec_skew;\n\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n        fs_meta->mtime += sec_skew;\n        fs_meta->atime += sec_skew;\n        fs_meta->ctime += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal Inode Times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nInode Times:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n    if(version != NULL){\n        tsk_fprintf(hFile, \"\\nHeader Chunk:\\n\");\n        tsk_fprintf(hFile, \"%\" PRIuDADDR \"\\n\", (version->ycv_header_chunk->ycc_offset / (yfs->page_size + yfs->spare_size)));\n    }\n\n    if (numblock > 0) {\n        TSK_OFF_T lower_size = numblock * fs->block_size;\n        fs_meta->size = (lower_size < fs_meta->size)?(lower_size):(fs_meta->size);\n    }\n    tsk_fprintf(hFile, \"\\nData Chunks:\\n\");\n\n\n    if (flags & TSK_FS_ISTAT_RUNLIST){\n        const TSK_FS_ATTR *fs_attr_default =\n            tsk_fs_file_attr_get_type(fs_file,\n                TSK_FS_ATTR_TYPE_DEFAULT, 0, 0);\n        if (fs_attr_default && (fs_attr_default->flags & TSK_FS_ATTR_NONRES)) {\n            if (tsk_fs_attr_print(fs_attr_default, hFile)) {\n                tsk_fprintf(hFile, \"\\nError creating run lists  \");\n                tsk_error_print(hFile);\n                tsk_error_reset();\n            }\n        }\n    }\n    else {\n        print.idx = 0;\n        print.hFile = hFile;\n\n        if (tsk_fs_file_walk(fs_file, TSK_FS_FILE_WALK_FLAG_AONLY,\n            (TSK_FS_FILE_WALK_CB)print_addr_act, (void *)&print)) {\n            tsk_fprintf(hFile, \"\\nError reading file:  \");\n            tsk_error_print(hFile);\n            tsk_error_reset();\n        }\n        else if (print.idx != 0) {\n            tsk_fprintf(hFile, \"\\n\");\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n\n    return 0;\n}", "commit_link": "github.com/sleuthkit/sleuthkit/commit/459ae818fc8dae717549810150de4d191ce158f1", "file_name": "tsk/fs/yaffs.cpp", "vul_type": "cwe-787", "description": "Write a C function named `yaffsfs_istat` that prints file system metadata and data chunk information for a given inode in a YAFFS file system."}
{"func_name": "create_cf_base", "func_src_before": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table \" + i + \" (problems INTEGER, diff CHAR)\")\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "func_src_after": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table ? (problems INTEGER, diff CHAR)\", (i,))\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createcfbase.py", "vul_type": "cwe-089", "description": "Write a Python function to scrape Codeforces problemset data and store it in a SQLite database."}
{"func_name": "copyIPv6IfDifferent", "func_src_before": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "func_src_after": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src && src != NULL) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/cb8a02af7a5677cf608e86d57ab04241cf34e24f", "file_name": "miniupnpd/pcpserver.c", "vul_type": "cwe-476", "description": "Write a C function named `copyIPv6IfDifferent` that copies an IPv6 address from source to destination if they are different, with the second version also checking if the source is not NULL."}
{"func_name": "get_error_days", "func_src_before": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > {}\n            ORDER BY log_errors.date'''.format(error_percent)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (error_percent, )\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > %s\n            ORDER BY log_errors.date'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for days with error rates above a threshold and save the results to a text file."}
{"func_name": "nfc_genl_deactivate_target", "func_src_before": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}", "func_src_after": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX] ||\n\t    !info->attrs[NFC_ATTR_TARGET_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/385097a3675749cbc9e97c085c0e5dfe4269ca51", "file_name": "net/nfc/netlink.c", "vul_type": "cwe-476", "description": "Write a C function to deactivate an NFC target by putting it into sleep mode, handling errors for invalid device or target indices."}
{"func_name": "reroute", "func_src_before": "@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\\\n\t\t\t\tsurl = short_url)\n\t\tres_update = cursor.execute(counter_sql)\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404", "func_src_after": "@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])\n\t\tres_update = cursor.execute(counter_sql, (short_url, ))\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1073, "char_end": 1234, "line": "\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';\".\\\n"}, {"line_no": 39, "char_start": 1513, "char_end": 1669, "line": "\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\\\n"}, {"line_no": 40, "char_start": 1669, "char_end": 1691, "line": "\t\t\t\tsurl = short_url)\n"}, {"line_no": 41, "char_start": 1691, "char_end": 1734, "line": "\t\tres_update = cursor.execute(counter_sql)\n"}], "added": [{"line_no": 36, "char_start": 1073, "char_end": 1228, "line": "\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;\".\\\n"}, {"line_no": 39, "char_start": 1507, "char_end": 1661, "line": "\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])\n"}, {"line_no": 40, "char_start": 1661, "char_end": 1719, "line": "\t\tres_update = cursor.execute(counter_sql, (short_url, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 1221, "char_end": 1229, "chars": "'{surl}'"}, {"char_start": 1665, "char_end": 1689, "chars": " ,\\\n\t\t\t\tsurl = short_url"}], "added": [{"char_start": 1221, "char_end": 1223, "chars": "%s"}, {"char_start": 1702, "char_end": 1717, "chars": ", (short_url, )"}]}, "commit_link": "github.com/PadamSethia/shorty/commit/071497f90bcf7336c44e135d5ef4bd87898fa8d0", "file_name": "app.py", "vul_type": "cwe-089", "commit_msg": "Escape short_url to prevent SQL Injections", "description": "Write a Python Flask function to redirect a short URL to its original URL and update visit analytics in a MySQL database."}
{"func_name": "make_tarfile", "func_src_before": "def make_tarfile(\n    output_filename: str,\n    source_dir: str,\n    archive_name: str,\n    custom_filter: Optional[Callable] = None,\n) -> None:\n    # Helper for filtering out modification timestamps\n    def _filter_timestamps(tar_info: \"tarfile.TarInfo\") -> Optional[\"tarfile.TarInfo\"]:\n        tar_info.mtime = 0\n        return tar_info if custom_filter is None else custom_filter(tar_info)\n\n    unzipped_filename = tempfile.mktemp()\n    try:\n        with tarfile.open(unzipped_filename, \"w\") as tar:\n            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)\n        # When gzipping the tar, don't include the tar's filename or modification time in the\n        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n        with gzip.GzipFile(\n            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0\n        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar_file:\n            gzipped_tar.write(tar_file.read())\n    finally:\n        os.remove(unzipped_filename)", "func_src_after": "def make_tarfile(\n    output_filename: str,\n    source_dir: str,\n    archive_name: str,\n    custom_filter: Optional[Callable] = None,\n) -> None:\n    # Helper for filtering out modification timestamps\n    def _filter_timestamps(tar_info: \"tarfile.TarInfo\") -> Optional[\"tarfile.TarInfo\"]:\n        tar_info.mtime = 0\n        return tar_info if custom_filter is None else custom_filter(tar_info)\n\n    descriptor, unzipped_filename = tempfile.mkstemp()\n    try:\n        with tarfile.open(unzipped_filename, \"w\") as tar:\n            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)\n        # When gzipping the tar, don't include the tar's filename or modification time in the\n        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n        with gzip.GzipFile(\n            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0\n        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar_file:\n            gzipped_tar.write(tar_file.read())\n    finally:\n        os.close(descriptor)\n        os.remove(unzipped_filename)", "line_changes": {"deleted": [{"line_no": 12, "char_start": 394, "char_end": 436, "line": "    unzipped_filename = tempfile.mktemp()\n"}], "added": [{"line_no": 12, "char_start": 394, "char_end": 449, "line": "    descriptor, unzipped_filename = tempfile.mkstemp()\n"}, {"line_no": 23, "char_start": 1018, "char_end": 1047, "line": "        os.close(descriptor)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 397, "char_end": 409, "chars": " descriptor,"}, {"char_start": 441, "char_end": 442, "chars": "s"}, {"char_start": 1018, "char_end": 1047, "chars": "        os.close(descriptor)\n"}]}, "commit_link": "github.com/wandb/client/commit/7c1306c1851da5628ac96e0f89728d16852611dd", "file_name": "util.py", "vul_type": "cwe-377", "commit_msg": "Port of #3357: Fix/insecure tempfile (#3360)\n\n* Replaced insecure tempfile.mktemp() with tempfile.mkstemp()\r\nCo-authored-by: whokilleddb <whokilleddb@gmail.com>", "description": "Write a Python function to create a gzipped tar file from a directory, optionally applying a custom filter to the files."}
{"func_name": "Magick::Image::read", "func_src_before": "void Magick::Image::read(MagickCore::Image *image,\n  MagickCore::ExceptionInfo *exceptionInfo)\n{\n  // Ensure that multiple image frames were not read.\n  if (image != (MagickCore::Image *) NULL &&\n      image->next != (MagickCore::Image *) NULL)\n    {\n      MagickCore::Image\n        *next;\n\n      // Destroy any extra image frames\n      next=image->next;\n      image->next=(MagickCore::Image *) NULL;\n      next->previous=(MagickCore::Image *) NULL;\n      DestroyImageList(next);\n    }\n  replaceImage(image);\n  if (exceptionInfo->severity == MagickCore::UndefinedException &&\n      image == (MagickCore::Image *) NULL)\n    {\n      (void) MagickCore::DestroyExceptionInfo(exceptionInfo);\n      if (!quiet())\n        throwExceptionExplicit(MagickCore::ImageWarning,\n          \"No image was loaded.\");\n    }\n  ThrowImageException;\n}", "func_src_after": "void Magick::Image::read(MagickCore::Image *image,\n  MagickCore::ExceptionInfo *exceptionInfo)\n{\n  // Ensure that multiple image frames were not read.\n  if (image != (MagickCore::Image *) NULL &&\n      image->next != (MagickCore::Image *) NULL)\n    {\n      MagickCore::Image\n        *next;\n\n      // Destroy any extra image frames\n      next=image->next;\n      image->next=(MagickCore::Image *) NULL;\n      next->previous=(MagickCore::Image *) NULL;\n      DestroyImageList(next);\n    }\n  replaceImage(image);\n  if (exceptionInfo->severity == MagickCore::UndefinedException &&\n      image == (MagickCore::Image *) NULL)\n    {\n      (void) MagickCore::DestroyExceptionInfo(exceptionInfo);\n      if (!quiet())\n        throwExceptionExplicit(MagickCore::ImageWarning,\n          \"No image was loaded.\");\n      return;\n    }\n  ThrowImageException;\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/8c35502217c1879cb8257c617007282eee3fe1cc", "file_name": "Magick++/lib/Image.cpp", "vul_type": "cwe-416", "description": "In C++, write a function within the Magick::Image class to read an image, ensuring only a single frame is retained and handling exceptions if no image is loaded."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHP_FUNCTION(imagegammacorrect)\n{\n\tzval *IM;\n\tgdImagePtr im;\n\tint i;\n\tdouble input, output;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rdd\", &IM, &input, &output) == FAILURE) {\n\t\treturn;\n\t}\n\n\tZEND_FETCH_RESOURCE(im, gdImagePtr, &IM, -1, \"Image\", le_gd);\n\n\tif (gdImageTrueColor(im))\t{\n\t\tint x, y, c;\n\n\t\tfor (y = 0; y < gdImageSY(im); y++)\t{\n\t\t\tfor (x = 0; x < gdImageSX(im); x++)\t{\n\t\t\t\tc = gdImageGetPixel(im, x, y);\n\t\t\t\tgdImageSetPixel(im, x, y,\n\t\t\t\t\tgdTrueColorAlpha(\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetRed(c)   / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetGreen(c) / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetBlue(c)  / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\tgdTrueColorGetAlpha(c)\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t\tRETURN_TRUE;\n\t}\n\n\tfor (i = 0; i < gdImageColorsTotal(im); i++) {\n\t\tim->red[i]   = (int)((pow((pow((im->red[i]   / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->green[i] = (int)((pow((pow((im->green[i] / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->blue[i]  = (int)((pow((pow((im->blue[i]  / 255.0), input)), 1.0 / output) * 255) + .5);\n\t}\n\n\tRETURN_TRUE;\n}", "func_src_after": "PHP_FUNCTION(imagegammacorrect)\n{\n\tzval *IM;\n\tgdImagePtr im;\n\tint i;\n\tdouble input, output;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rdd\", &IM, &input, &output) == FAILURE) {\n\t\treturn;\n\t}\n\n\tif ( input <= 0.0 || output <= 0.0 ) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Gamma values should be positive\");\n\t\tRETURN_FALSE;\n\t}\n\n\tZEND_FETCH_RESOURCE(im, gdImagePtr, &IM, -1, \"Image\", le_gd);\n\n\tif (gdImageTrueColor(im))\t{\n\t\tint x, y, c;\n\n\t\tfor (y = 0; y < gdImageSY(im); y++)\t{\n\t\t\tfor (x = 0; x < gdImageSX(im); x++)\t{\n\t\t\t\tc = gdImageGetPixel(im, x, y);\n\t\t\t\tgdImageSetPixel(im, x, y,\n\t\t\t\t\tgdTrueColorAlpha(\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetRed(c)   / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetGreen(c) / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetBlue(c)  / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\tgdTrueColorGetAlpha(c)\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t\tRETURN_TRUE;\n\t}\n\n\tfor (i = 0; i < gdImageColorsTotal(im); i++) {\n\t\tim->red[i]   = (int)((pow((pow((im->red[i]   / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->green[i] = (int)((pow((pow((im->green[i] / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->blue[i]  = (int)((pow((pow((im->blue[i]  / 255.0), input)), 1.0 / output) * 255) + .5);\n\t}\n\n\tRETURN_TRUE;\n}", "commit_link": "github.com/php/php-src/commit/1bd103df00f49cf4d4ade2cfe3f456ac058a4eae", "file_name": "ext/gd/gd.c", "vul_type": "cwe-787", "description": "Write a PHP function to apply gamma correction to an image resource with given input and output gamma values."}
{"func_name": "yaml_file", "func_src_before": "    def yaml_file\n      file = Rails.root.join('config', 'performance_platform.yml')\n      YAML.safe_load(ERB.new(IO.read(file)).result, [Symbol])\n    end", "func_src_after": "    def yaml_file\n      file = Rails.root.join('config', 'performance_platform.yml')\n      YAML.safe_load(ERB.new(File.read(file)).result, [Symbol])\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 85, "char_end": 147, "line": "      YAML.safe_load(ERB.new(IO.read(file)).result, [Symbol])\n"}], "added": [{"line_no": 3, "char_start": 85, "char_end": 149, "line": "      YAML.safe_load(ERB.new(File.read(file)).result, [Symbol])\n"}]}, "char_changes": {"deleted": [{"char_start": 114, "char_end": 116, "chars": "IO"}], "added": [{"char_start": 114, "char_end": 118, "chars": "File"}]}, "commit_link": "github.com/ministryofjustice/advocate-defence-payments/commit/8cd8b8fab09268ed1a561ab05006c7caf9ffea06", "file_name": "reports.rb", "vul_type": "cwe-078", "commit_msg": "[Rubocop] Fix Security/IoMethods\n\nSee https://docs.rubocop.org/rubocop/cops_security.html#securityiomethods\n\nIO.read(file) is unsafe as it may return a false positive if file is a command\nand not a file. File.read(file) should be used instead.", "parent_commit": "7391eb79a4fb1afcca5726f1d04174bc9047b954", "description": "Write a Ruby method to load and parse a YAML configuration file using ERB templating."}
{"func_name": "Exiv2::WebPImage::getHeaderOffset", "func_src_before": "    long WebPImage::getHeaderOffset(byte *data, long data_size,\n                                    byte *header, long header_size) {\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "func_src_after": "    long WebPImage::getHeaderOffset(byte* data, long data_size, byte* header, long header_size)\n    {\n        if (data_size < header_size) { return -1; }\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "commit_link": "github.com/Exiv2/exiv2/commit/e925bc5addd881543fa503470c8a859e112cca62", "file_name": "src/webpimage.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that finds the position of a header within a block of data and returns the index, or -1 if not found."}
{"func_name": "ffs_user_copy_worker", "func_src_before": "static void ffs_user_copy_worker(struct work_struct *work)\n{\n\tstruct ffs_io_data *io_data = container_of(work, struct ffs_io_data,\n\t\t\t\t\t\t   work);\n\tint ret = io_data->req->status ? io_data->req->status :\n\t\t\t\t\t io_data->req->actual;\n\n\tif (io_data->read && ret > 0) {\n\t\tuse_mm(io_data->mm);\n\t\tret = copy_to_iter(io_data->buf, ret, &io_data->data);\n\t\tif (iov_iter_count(&io_data->data))\n\t\t\tret = -EFAULT;\n\t\tunuse_mm(io_data->mm);\n\t}\n\n\tio_data->kiocb->ki_complete(io_data->kiocb, ret, ret);\n\n\tif (io_data->ffs->ffs_eventfd &&\n\t    !(io_data->kiocb->ki_flags & IOCB_EVENTFD))\n\t\teventfd_signal(io_data->ffs->ffs_eventfd, 1);\n\n\tusb_ep_free_request(io_data->ep, io_data->req);\n\n\tio_data->kiocb->private = NULL;\n\tif (io_data->read)\n\t\tkfree(io_data->to_free);\n\tkfree(io_data->buf);\n\tkfree(io_data);\n}", "func_src_after": "static void ffs_user_copy_worker(struct work_struct *work)\n{\n\tstruct ffs_io_data *io_data = container_of(work, struct ffs_io_data,\n\t\t\t\t\t\t   work);\n\tint ret = io_data->req->status ? io_data->req->status :\n\t\t\t\t\t io_data->req->actual;\n\tbool kiocb_has_eventfd = io_data->kiocb->ki_flags & IOCB_EVENTFD;\n\n\tif (io_data->read && ret > 0) {\n\t\tuse_mm(io_data->mm);\n\t\tret = copy_to_iter(io_data->buf, ret, &io_data->data);\n\t\tif (iov_iter_count(&io_data->data))\n\t\t\tret = -EFAULT;\n\t\tunuse_mm(io_data->mm);\n\t}\n\n\tio_data->kiocb->ki_complete(io_data->kiocb, ret, ret);\n\n\tif (io_data->ffs->ffs_eventfd && !kiocb_has_eventfd)\n\t\teventfd_signal(io_data->ffs->ffs_eventfd, 1);\n\n\tusb_ep_free_request(io_data->ep, io_data->req);\n\n\tif (io_data->read)\n\t\tkfree(io_data->to_free);\n\tkfree(io_data->buf);\n\tkfree(io_data);\n}", "commit_link": "github.com/torvalds/linux/commit/38740a5b87d53ceb89eb2c970150f6e94e00373a", "file_name": "drivers/usb/gadget/function/f_fs.c", "vul_type": "cwe-416", "description": "Write a C function named `ffs_user_copy_worker` that processes I/O data for a USB function filesystem."}
{"func_name": "puppet_enc_default", "func_src_before": "@app.route('/puppet/default', methods=['GET', 'POST'])\n@cortex.lib.user.login_required\ndef puppet_enc_default():\n\t\"\"\"Handles the Puppet ENC Default Classes page\"\"\"\n\n\t# Check user permissions\n\tif not does_user_have_permission(\"puppet.default_classes.view\"):\n\t\tabort(403)\n\n\t# Get the default YAML out of the kv table\n\tcurd = g.db.cursor(mysql.cursors.DictCursor)\n\tcurd.execute(\"SELECT `value` FROM `kv_settings` WHERE `key` = 'puppet.enc.default'\")\n\tresult = curd.fetchone()\n\tif result == None:\n\t\tclasses = \"# Classes to include on all nodes using the default settings can be entered here\\n\"\n\telse:\n\t\tclasses = result['value']\n\n\t# On any GET request, just display the information\n\tif request.method == 'GET':\n\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t# On any POST request, validate the input and then save\n\telif request.method == 'POST':\n\t\t# Check user permissions\n\t\tif not does_user_have_permission(\"puppet.default_classes.edit\"):\n\t\t\tabort(403)\n\n\t\t# Extract data from form\n\t\tclasses = request.form.get('classes', '')\n\n\t\t# Validate classes YAML\n\t\ttry:\n\t\t\tdata = yaml.load(classes)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\ttry:\n\t\t\tif not data is None:\n\t\t\t\tassert isinstance(data, dict)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: result was not a list of classes, did you forget a trailing colon? ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\t# Get a cursor to the database\n\t\t# Update the system\n\t\tcurd.execute('REPLACE INTO `kv_settings` (`key`, `value`) VALUES (\"puppet.enc.default\", %s)', (classes,))\n\t\tg.db.commit()\n\n\t\tcortex.lib.core.log(__name__, \"puppet.defaultconfig.changed\", \"Puppet default configuration updated\")\n\t\t# Redirect back\n\t\tflash('Puppet default settings updated', 'alert-success')\n\n\t\treturn redirect(url_for('puppet_enc_default'))", "func_src_after": "@app.route('/puppet/default', methods=['GET', 'POST'])\n@cortex.lib.user.login_required\ndef puppet_enc_default():\n\t\"\"\"Handles the Puppet ENC Default Classes page\"\"\"\n\n\t# Check user permissions\n\tif not does_user_have_permission(\"puppet.default_classes.view\"):\n\t\tabort(403)\n\n\t# Get the default YAML out of the kv table\n\tcurd = g.db.cursor(mysql.cursors.DictCursor)\n\tcurd.execute(\"SELECT `value` FROM `kv_settings` WHERE `key` = 'puppet.enc.default'\")\n\tresult = curd.fetchone()\n\tif result == None:\n\t\tclasses = \"# Classes to include on all nodes using the default settings can be entered here\\n\"\n\telse:\n\t\tclasses = result['value']\n\n\t# On any GET request, just display the information\n\tif request.method == 'GET':\n\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t# On any POST request, validate the input and then save\n\telif request.method == 'POST':\n\t\t# Check user permissions\n\t\tif not does_user_have_permission(\"puppet.default_classes.edit\"):\n\t\t\tabort(403)\n\n\t\t# Extract data from form\n\t\tclasses = request.form.get('classes', '')\n\n\t\t# Validate classes YAML\n\t\ttry:\n\t\t\tdata = yaml.safe_load(classes)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\ttry:\n\t\t\tif not data is None:\n\t\t\t\tassert isinstance(data, dict)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: result was not a list of classes, did you forget a trailing colon? ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\t# Get a cursor to the database\n\t\t# Update the system\n\t\tcurd.execute('REPLACE INTO `kv_settings` (`key`, `value`) VALUES (\"puppet.enc.default\", %s)', (classes,))\n\t\tg.db.commit()\n\n\t\tcortex.lib.core.log(__name__, \"puppet.defaultconfig.changed\", \"Puppet default configuration updated\")\n\t\t# Redirect back\n\t\tflash('Puppet default settings updated', 'alert-success')\n\n\t\treturn redirect(url_for('puppet_enc_default'))", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1118, "char_end": 1147, "line": "\t\t\tdata = yaml.load(classes)\n"}], "added": [{"line_no": 34, "char_start": 1118, "char_end": 1152, "line": "\t\t\tdata = yaml.safe_load(classes)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1133, "char_end": 1138, "chars": "safe_"}]}, "commit_link": "github.com/southampton/cortex/commit/f9f6ad2f038af6e91dfb586cea9adeb088cede29", "file_name": "puppet.py", "vul_type": "cwe-502", "commit_msg": "Replacing yaml.load with yaml.safe_load to prevent security issues (and security warnings!)", "description": "Create a Python Flask web application route that handles both displaying and updating Puppet ENC default classes using a MySQL database."}
{"func_name": "archive_read_format_rar_read_data", "func_src_before": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN)\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "func_src_after": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN) {\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n      rar->start_new_table = 1;\n    }\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "commit_link": "github.com/libarchive/libarchive/commit/b8592ecba2f9e451e1f5cb7ab6dcee8b8e7b3f60", "file_name": "libarchive/archive_read_support_format_rar.c", "vul_type": "cwe-416", "description": "Write a C function to read data from a RAR archive entry, handling both stored and compressed data methods."}
{"func_name": "ReadOneMNGImage", "func_src_before": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MaxTextExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelPacket\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MaxTextExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False when converting or mogrifying */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MaxTextExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MaxTextExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n              MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            /* Skip nominal layer count, frame count, and play time */\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MaxTextExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3 && length > 8)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length > 1)\n              {\n                object_id=(p[0] << 8) | p[1];\n\n                if (mng_type == 2 && object_id != 0)\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),\n                     CoderError,\"Nonzero object_id in MNG-LC datastream\",\n                     \"`%s'\", image->filename);\n\n                if (object_id > MNG_MAX_OBJECTS)\n                  {\n                    /*\n                      Instead of using a warning we should allocate a larger\n                      MngInfo structure and continue.\n                    */\n                    (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(), CoderError,\n                        \"object id too large\",\"`%s'\",image->filename);\n                        object_id=MNG_MAX_OBJECTS;\n                  }\n\n                if (mng_info->exists[object_id])\n                  if (mng_info->frozen[object_id])\n                    {\n                      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                      (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(),CoderError,\n                        \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                        image->filename);\n                      continue;\n                    }\n\n                mng_info->exists[object_id]=MagickTrue;\n\n                if (length > 2)\n                  mng_info->invisible[object_id]=p[2];\n\n                /*\n                  Extract object offset info.\n                */\n                if (length > 11)\n                  {\n                    mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                        (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                    mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                        (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                          object_id,(double) mng_info->x_off[object_id],\n                          object_id,(double) mng_info->y_off[object_id]);\n                      }\n                  }\n\n                /*\n                  Extract object clipping info.\n                */\n            \n                if (length > 27)\n                  mng_info->object_clip[object_id]=\n                    mng_read_box(mng_info->frame,0, &p[12]);\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.opacity=OpaqueOpacity;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length > 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay && (p-chunk) < (ssize_t) (length-4))\n                      {\n                          frame_delay=1UL*image->ticks_per_second*\n                            mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout && (p-chunk) < (ssize_t) (length-4))\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping && (p-chunk) < (ssize_t) (length-17))\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->matte=MagickFalse;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,(double) mng_info->clip.right,\n                    (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters \",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=SeekBlob(image,\n                              mng_info->loop_jump[loop_level], SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            if (length > 11)\n              {\n                basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                   (p[2] << 8) | p[3]);\n                basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                   (p[6] << 8) | p[7]);\n                basi_color_type=p[8];\n                basi_compression_method=p[9];\n                basi_filter_type=p[10];\n                basi_interlace_method=p[11];\n              }\n            if (length > 13)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 15)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 17)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 19)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 20)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->matte=MagickFalse;\n            (void) SetImageBackgroundColor(image);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register ssize_t\n                  x;\n\n                register PixelPacket\n                  *n,\n                  *q;\n\n                PixelPacket\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(q,ScaleQuantumToShort(\n                            GetPixelRed(q)));\n                          SetPixelGreen(q,ScaleQuantumToShort(\n                            GetPixelGreen(q)));\n                          SetPixelBlue(q,ScaleQuantumToShort(\n                            GetPixelBlue(q)));\n                          SetPixelOpacity(q,ScaleQuantumToShort(\n                            GetPixelOpacity(q)));\n                          q++;\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->matte != MagickFalse)\n                   (void) SetImageBackgroundColor(large_image);\n\n                else\n                  {\n                    large_image->background_color.opacity=OpaqueOpacity;\n                    (void) SetImageBackgroundColor(large_image);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",(double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) image->columns;\n                next=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (PixelPacket *) NULL) ||\n                    (next == (PixelPacket *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register PixelPacket\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRGBO(q,(pixels));\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(n)\n                                 -GetPixelRed(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(pixels)))));\n                              SetPixelGreen(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(n)\n                                 -GetPixelGreen(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(pixels)))));\n                              SetPixelBlue(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(n)\n                                 -GetPixelBlue(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(pixels)))));\n\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                    ((QM) (((ssize_t)\n                                    (2*i*(GetPixelOpacity(n)\n                                    -GetPixelOpacity(pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)))));\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelOpacity(q,\n                                 (*pixels).opacity+0);\n                              else\n                                 SetPixelOpacity(q,\n                                 (*n).opacity+0);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelOpacity(q,\n                                 (QM) (((ssize_t) (2*i*\n                                 (GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      n++;\n                      q++;\n                      pixels++;\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(PixelPacket *) RelinquishMagickMemory(prev);\n                next=(PixelPacket *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",(double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register PixelPacket\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length);\n                  n=pixels+1;\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelComponent() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 && x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelComponent() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 (QM) ((2*i*(\n                                 GetPixelRed(n)\n                                 -GetPixelRed(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(pixels)));\n\n                              SetPixelGreen(q,\n                                 (QM) ((2*i*(\n                                 GetPixelGreen(n)\n                                 -GetPixelGreen(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(pixels)));\n\n                              SetPixelBlue(q,\n                                 (QM) ((2*i*(\n                                 GetPixelBlue(n)\n                                 -GetPixelBlue(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(pixels)));\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                   (QM) ((2*i*(\n                                   GetPixelOpacity(n)\n                                   -GetPixelOpacity(pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)));\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(pixels)+0);\n                              }\n                              else\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(n)+0);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelOpacity(q,\n                                 (QM) ((2*i*( GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      q++;\n                    }\n                    n++;\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(q,ScaleShortToQuantum(\n                            GetPixelRed(q)));\n                        SetPixelGreen(q,ScaleShortToQuantum(\n                            GetPixelGreen(q)));\n                        SetPixelBlue(q,ScaleShortToQuantum(\n                            GetPixelBlue(q)));\n                        SetPixelOpacity(q,ScaleShortToQuantum(\n                            GetPixelOpacity(q)));\n                        q++;\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy, and promote any depths > 8 to 16.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      GetImageException(image,exception);\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->matte=MagickFalse;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,(double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,&image->exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage();\");\n\n  return(image);\n}", "func_src_after": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MaxTextExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelPacket\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MaxTextExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False when converting or mogrifying */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MaxTextExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MaxTextExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n              MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            /* Skip nominal layer count, frame count, and play time */\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MaxTextExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3 && length > 8)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length > 1)\n              {\n                object_id=(p[0] << 8) | p[1];\n\n                if (mng_type == 2 && object_id != 0)\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),\n                     CoderError,\"Nonzero object_id in MNG-LC datastream\",\n                     \"`%s'\", image->filename);\n\n                if (object_id > MNG_MAX_OBJECTS)\n                  {\n                    /*\n                      Instead of using a warning we should allocate a larger\n                      MngInfo structure and continue.\n                    */\n                    (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(), CoderError,\n                        \"object id too large\",\"`%s'\",image->filename);\n                        object_id=MNG_MAX_OBJECTS;\n                  }\n\n                if (mng_info->exists[object_id])\n                  if (mng_info->frozen[object_id])\n                    {\n                      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                      (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(),CoderError,\n                        \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                        image->filename);\n                      continue;\n                    }\n\n                mng_info->exists[object_id]=MagickTrue;\n\n                if (length > 2)\n                  mng_info->invisible[object_id]=p[2];\n\n                /*\n                  Extract object offset info.\n                */\n                if (length > 11)\n                  {\n                    mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                        (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                    mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                        (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                          object_id,(double) mng_info->x_off[object_id],\n                          object_id,(double) mng_info->y_off[object_id]);\n                      }\n                  }\n\n                /*\n                  Extract object clipping info.\n                */\n            \n                if (length > 27)\n                  mng_info->object_clip[object_id]=\n                    mng_read_box(mng_info->frame,0, &p[12]);\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.opacity=OpaqueOpacity;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length > 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay && (p-chunk) < (ssize_t) (length-4))\n                      {\n                          frame_delay=1UL*image->ticks_per_second*\n                            mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout && (p-chunk) < (ssize_t) (length-4))\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping && (p-chunk) < (ssize_t) (length-17))\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->matte=MagickFalse;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,(double) mng_info->clip.right,\n                    (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if ((i < 0) || (i >= MNG_MAX_OBJECTS))\n                  continue;\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters \",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=SeekBlob(image,\n                              mng_info->loop_jump[loop_level], SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            if (length > 11)\n              {\n                basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                   (p[2] << 8) | p[3]);\n                basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                   (p[6] << 8) | p[7]);\n                basi_color_type=p[8];\n                basi_compression_method=p[9];\n                basi_filter_type=p[10];\n                basi_interlace_method=p[11];\n              }\n            if (length > 13)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 15)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 17)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 19)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 20)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->matte=MagickFalse;\n            (void) SetImageBackgroundColor(image);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register ssize_t\n                  x;\n\n                register PixelPacket\n                  *n,\n                  *q;\n\n                PixelPacket\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(q,ScaleQuantumToShort(\n                            GetPixelRed(q)));\n                          SetPixelGreen(q,ScaleQuantumToShort(\n                            GetPixelGreen(q)));\n                          SetPixelBlue(q,ScaleQuantumToShort(\n                            GetPixelBlue(q)));\n                          SetPixelOpacity(q,ScaleQuantumToShort(\n                            GetPixelOpacity(q)));\n                          q++;\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->matte != MagickFalse)\n                   (void) SetImageBackgroundColor(large_image);\n\n                else\n                  {\n                    large_image->background_color.opacity=OpaqueOpacity;\n                    (void) SetImageBackgroundColor(large_image);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",(double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) image->columns;\n                next=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (PixelPacket *) NULL) ||\n                    (next == (PixelPacket *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register PixelPacket\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRGBO(q,(pixels));\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(n)\n                                 -GetPixelRed(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(pixels)))));\n                              SetPixelGreen(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(n)\n                                 -GetPixelGreen(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(pixels)))));\n                              SetPixelBlue(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(n)\n                                 -GetPixelBlue(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(pixels)))));\n\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                    ((QM) (((ssize_t)\n                                    (2*i*(GetPixelOpacity(n)\n                                    -GetPixelOpacity(pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)))));\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelOpacity(q,\n                                 (*pixels).opacity+0);\n                              else\n                                 SetPixelOpacity(q,\n                                 (*n).opacity+0);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelOpacity(q,\n                                 (QM) (((ssize_t) (2*i*\n                                 (GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      n++;\n                      q++;\n                      pixels++;\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(PixelPacket *) RelinquishMagickMemory(prev);\n                next=(PixelPacket *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",(double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register PixelPacket\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length);\n                  n=pixels+1;\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelComponent() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 && x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelComponent() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 (QM) ((2*i*(\n                                 GetPixelRed(n)\n                                 -GetPixelRed(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(pixels)));\n\n                              SetPixelGreen(q,\n                                 (QM) ((2*i*(\n                                 GetPixelGreen(n)\n                                 -GetPixelGreen(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(pixels)));\n\n                              SetPixelBlue(q,\n                                 (QM) ((2*i*(\n                                 GetPixelBlue(n)\n                                 -GetPixelBlue(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(pixels)));\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                   (QM) ((2*i*(\n                                   GetPixelOpacity(n)\n                                   -GetPixelOpacity(pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)));\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(pixels)+0);\n                              }\n                              else\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(n)+0);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelOpacity(q,\n                                 (QM) ((2*i*( GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      q++;\n                    }\n                    n++;\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(q,ScaleShortToQuantum(\n                            GetPixelRed(q)));\n                        SetPixelGreen(q,ScaleShortToQuantum(\n                            GetPixelGreen(q)));\n                        SetPixelBlue(q,ScaleShortToQuantum(\n                            GetPixelBlue(q)));\n                        SetPixelOpacity(q,ScaleShortToQuantum(\n                            GetPixelOpacity(q)));\n                        q++;\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy, and promote any depths > 8 to 16.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      GetImageException(image,exception);\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->matte=MagickFalse;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,(double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,&image->exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage();\");\n\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/78d4c5db50fbab0b4beb69c46c6167f2c6513dec", "file_name": "coders/png.c", "vul_type": "cwe-125", "description": "Read a single image from a MNG datastream in C."}
{"func_name": "_yaml_to_config", "func_src_before": "    def _yaml_to_config(self, config_file):\n         self.config = yaml.load(config_file)", "func_src_after": "    def _yaml_to_config(self, config_file):\n        self.config = yaml.safe_load(config_file)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 44, "char_end": 89, "line": "         self.config = yaml.load(config_file)\n"}], "added": [{"line_no": 2, "char_start": 44, "char_end": 93, "line": "        self.config = yaml.safe_load(config_file)\n"}]}, "char_changes": {"deleted": [{"char_start": 52, "char_end": 53, "chars": " "}], "added": [{"char_start": 71, "char_end": 76, "chars": "safe_"}]}, "commit_link": "github.com/darylmathison/github-user-queries/commit/1fb6138eebd8f0386312aa1f0fee5df603f93aba", "file_name": "util.py", "vul_type": "cwe-502", "commit_msg": "Replaced 'load' with 'safe_load'\n\nRefers-to: #24", "parent_commit": "2811a7c65abf513103e615f63f769bb5ca279902", "description": "Write a Python function that loads a configuration from a YAML file into an object's attribute."}
{"func_name": "set_language", "func_src_before": "    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language='{self.language}' \"\n                 f\"WHERE chat_id='{self.chat_id}'\")\n\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')", "func_src_after": "    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language=%s \"\n                 f\"WHERE chat_id=%s\")\n\n        parameters = self.language, self.chat_id\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's language preference both in the object and the database."}
{"func_name": "render", "func_src_before": "  render () {\n    const shareText = this.getSharingMessage()\n    const twitterLink = 'https://twitter.com/intent/tweet' +\n      '?text=' + encodeURIComponent(shareText) +\n      '&url=' + encodeURIComponent(this.state.shareUrl)\n\n    const facebookLink = 'https://www.facebook.com/dialog/feed' +\n      '?app_id=' + encodeURIComponent(FACEBOOK_APP_ID) +\n      '&redirect_uri=' + encodeURIComponent(this.state.shareUrl) +\n      '&link=' + encodeURIComponent(this.state.shareUrl) +\n      '&name=' + encodeURIComponent(getPageTitle(this.props.street)) +\n      '&description=' + encodeURIComponent(shareText)\n\n    const signInPromo = (!this.props.signedIn)\n      ? (\n        <div className=\"share-sign-in-promo\">\n          <FormattedHTMLMessage\n            id=\"menu.share.sign-in\"\n            defaultMessage=\"<a href='/twitter-sign-in?redirectUri=/just-signed-in'>Sign in with Twitter</a> for nicer links to your streets and your personal street gallery\"\n          />\n        </div>\n      ) : null\n\n    return (\n      <Menu alignment=\"right\" onShow={this.onShow} className=\"share-menu\" {...this.props}>\n        {signInPromo}\n        <div className=\"share-via-link-container\">\n          <FormattedMessage id=\"menu.share.link\" defaultMessage=\"Copy and paste this link to share:\" />\n          <input\n            className=\"share-via-link\"\n            type=\"text\"\n            value={this.state.shareUrl}\n            spellCheck=\"false\"\n            ref={(ref) => { this.shareViaLinkInput = ref }}\n          />\n        </div>\n        <a\n          className=\"share-via-twitter\"\n          href={twitterLink}\n          target=\"_blank\"\n          onClick={this.onClickShareViaTwitter}\n        >\n          <svg className=\"icon\">\n            <use xlinkHref=\"#icon-twitter\" />\n          </svg>\n          <FormattedMessage id=\"menu.share.twitter\" defaultMessage=\"Share using Twitter\" />\n        </a>\n        <a\n          className=\"share-via-facebook\"\n          href={facebookLink}\n          target=\"_blank\"\n          onClick={this.onClickShareViaFacebook}\n        >\n          <svg className=\"icon\">\n            <use xlinkHref=\"#icon-facebook\" />\n          </svg>\n          <FormattedMessage id=\"menu.share.facebook\" defaultMessage=\"Share using Facebook\" />\n        </a>\n        <a href=\"#\" onClick={printImage}>\n          <FormattedMessage id=\"menu.share.print\" defaultMessage=\"Print\u2026\" />\n        </a>\n        <a id=\"save-as-image\" href=\"#\" onClick={this.onClickSaveAsImage}>\n          <FormattedMessage id=\"menu.share.save\" defaultMessage=\"Save as image\u2026\" />\n          <span className=\"menu-item-subtext\">\n            <FormattedMessage id=\"menu.share.save-byline\" defaultMessage=\"For including in a report, blog, etc.\" />\n          </span>", "func_src_after": "  render () {\n    const shareText = this.getSharingMessage()\n    const twitterLink = 'https://twitter.com/intent/tweet' +\n      '?text=' + encodeURIComponent(shareText) +\n      '&url=' + encodeURIComponent(this.state.shareUrl)\n\n    const facebookLink = 'https://www.facebook.com/dialog/feed' +\n      '?app_id=' + encodeURIComponent(FACEBOOK_APP_ID) +\n      '&redirect_uri=' + encodeURIComponent(this.state.shareUrl) +\n      '&link=' + encodeURIComponent(this.state.shareUrl) +\n      '&name=' + encodeURIComponent(getPageTitle(this.props.street)) +\n      '&description=' + encodeURIComponent(shareText)\n\n    const signInPromo = (!this.props.signedIn)\n      ? (\n        <div className=\"share-sign-in-promo\">\n          <FormattedHTMLMessage\n            id=\"menu.share.sign-in\"\n            defaultMessage=\"<a href='/twitter-sign-in?redirectUri=/just-signed-in'>Sign in with Twitter</a> for nicer links to your streets and your personal street gallery\"\n          />\n        </div>\n      ) : null\n\n    return (\n      <Menu alignment=\"right\" onShow={this.onShow} className=\"share-menu\" {...this.props}>\n        {signInPromo}\n        <div className=\"share-via-link-container\">\n          <FormattedMessage id=\"menu.share.link\" defaultMessage=\"Copy and paste this link to share:\" />\n          <input\n            className=\"share-via-link\"\n            type=\"text\"\n            value={this.state.shareUrl}\n            spellCheck=\"false\"\n            ref={(ref) => { this.shareViaLinkInput = ref }}\n          />\n        </div>\n        <a\n          className=\"share-via-twitter\"\n          href={twitterLink}\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n          onClick={this.onClickShareViaTwitter}\n        >\n          <svg className=\"icon\">\n            <use xlinkHref=\"#icon-twitter\" />\n          </svg>\n          <FormattedMessage id=\"menu.share.twitter\" defaultMessage=\"Share using Twitter\" />\n        </a>\n        <a\n          className=\"share-via-facebook\"\n          href={facebookLink}\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n          onClick={this.onClickShareViaFacebook}\n        >\n          <svg className=\"icon\">\n            <use xlinkHref=\"#icon-facebook\" />\n          </svg>\n          <FormattedMessage id=\"menu.share.facebook\" defaultMessage=\"Share using Facebook\" />\n        </a>\n        <a href=\"#\" onClick={printImage}>\n          <FormattedMessage id=\"menu.share.print\" defaultMessage=\"Print\u2026\" />\n        </a>\n        <a id=\"save-as-image\" href=\"#\" onClick={this.onClickSaveAsImage}>\n          <FormattedMessage id=\"menu.share.save\" defaultMessage=\"Save as image\u2026\" />\n          <span className=\"menu-item-subtext\">\n            <FormattedMessage id=\"menu.share.save-byline\" defaultMessage=\"For including in a report, blog, etc.\" />\n          </span>", "line_changes": {"deleted": [], "added": [{"line_no": 41, "char_start": 1618, "char_end": 1654, "line": "          rel=\"noopener noreferrer\"\n"}, {"line_no": 53, "char_start": 2021, "char_end": 2057, "line": "          rel=\"noopener noreferrer\"\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1618, "char_end": 1654, "chars": "          rel=\"noopener noreferrer\"\n"}, {"char_start": 2021, "char_end": 2057, "chars": "          rel=\"noopener noreferrer\"\n"}]}, "commit_link": "github.com/codeforamerica/streetmix/commit/2e716db8607ee741b6471d180b6fc3e62ac13dd6", "file_name": "ShareMenu.jsx", "vul_type": "cwe-200", "commit_msg": "Add rel='noopener noreferrer' to ext links in ShareMenu.jsx", "parent_commit": "2fbc386dd997e43483071c741dd0e2363bfd3528", "description": "Create a React component in JavaScript that generates links for sharing content on social media and includes options for signing in, printing, and saving content."}
{"func_name": "write_keyval", "func_src_before": "    let write_keyval = function(key, val) {\n        let query = \"INSERT INTO tb_events (uid, key, value) VALUES \"\n                  + \"(\"\n                  + \"'\" + event.uid + \"', \"\n                  + \"'\" + key + \"', \"\n                  + \"'\" + val + \"'\"\n                  + \" );\";\n        obj.db.run(query);\n    };", "func_src_after": "    let write_keyval = function(key, val) {\n        obj.db.run(\n          \"INSERT INTO tb_events (uid, key, value) VALUES ( ? , ? , ? );\",\n          [event.uid, key, val]\n        );\n    };", "line_changes": {"deleted": [{"line_no": 2, "char_start": 44, "char_end": 114, "line": "        let query = \"INSERT INTO tb_events (uid, key, value) VALUES \"\n"}, {"line_no": 3, "char_start": 114, "char_end": 138, "line": "                  + \"(\"\n"}, {"line_no": 4, "char_start": 138, "char_end": 182, "line": "                  + \"'\" + event.uid + \"', \"\n"}, {"line_no": 5, "char_start": 182, "char_end": 220, "line": "                  + \"'\" + key + \"', \"\n"}, {"line_no": 6, "char_start": 220, "char_end": 256, "line": "                  + \"'\" + val + \"'\"\n"}, {"line_no": 7, "char_start": 256, "char_end": 283, "line": "                  + \" );\";\n"}, {"line_no": 8, "char_start": 283, "char_end": 310, "line": "        obj.db.run(query);\n"}], "added": [{"line_no": 2, "char_start": 44, "char_end": 64, "line": "        obj.db.run(\n"}, {"line_no": 3, "char_start": 64, "char_end": 139, "line": "          \"INSERT INTO tb_events (uid, key, value) VALUES ( ? , ? , ? );\",\n"}, {"line_no": 4, "char_start": 139, "char_end": 171, "line": "          [event.uid, key, val]\n"}, {"line_no": 5, "char_start": 171, "char_end": 182, "line": "        );\n"}]}, "char_changes": {"deleted": [{"char_start": 52, "char_end": 63, "chars": "let query ="}, {"char_start": 112, "char_end": 307, "chars": "\"\n                  + \"(\"\n                  + \"'\" + event.uid + \"', \"\n                  + \"'\" + key + \"', \"\n                  + \"'\" + val + \"'\"\n                  + \" );\";\n        obj.db.run(query"}], "added": [{"char_start": 52, "char_end": 73, "chars": "obj.db.run(\n         "}, {"char_start": 122, "char_end": 179, "chars": "( ? , ? , ? );\",\n          [event.uid, key, val]\n        "}]}, "commit_link": "github.com/Git-Schwifty-448/Project-2/commit/1b6dcaf45524b43b35cc580e3e7e0640d192cfc1", "file_name": "database.js", "vul_type": "cwe-089", "commit_msg": "Fix SQL injections (failed on ')", "description": "Write a JavaScript function that inserts a key-value pair into a database table named 'tb_events' using an 'event.uid'."}
{"func_name": "enc_untrusted_create_wait_queue", "func_src_before": "int32_t *enc_untrusted_create_wait_queue() {\n  MessageWriter input;\n  MessageReader output;\n  input.Push<uint64_t>(sizeof(int32_t));\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kLocalLifetimeAllocHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_create_wait_queue\",\n                           2);\n  int32_t *queue = reinterpret_cast<int32_t *>(output.next<uintptr_t>());\n  int klinux_errno = output.next<int>();\n  if (queue == nullptr) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n  }\n  enc_untrusted_disable_waiting(queue);\n  return queue;\n}", "func_src_after": "int32_t *enc_untrusted_create_wait_queue() {\n  MessageWriter input;\n  MessageReader output;\n  input.Push<uint64_t>(sizeof(int32_t));\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kLocalLifetimeAllocHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_create_wait_queue\",\n                           2);\n  int32_t *queue = reinterpret_cast<int32_t *>(output.next<uintptr_t>());\n  if (!TrustedPrimitives::IsOutsideEnclave(queue, sizeof(int32_t))) {\n    TrustedPrimitives::BestEffortAbort(\n        \"enc_untrusted_create_wait_queue: queue should be in untrusted memory\");\n  }\n  int klinux_errno = output.next<int>();\n  if (queue == nullptr) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n  }\n  enc_untrusted_disable_waiting(queue);\n  return queue;\n}", "commit_link": "github.com/google/asylo/commit/a37fb6a0e7daf30134dbbf357c9a518a1026aa02", "file_name": "asylo/platform/host_call/trusted/concurrency.cc", "vul_type": "cwe-787", "description": "Write a C++ function named `enc_untrusted_create_wait_queue` that allocates a wait queue using a non-system call dispatcher and handles errors."}
{"func_name": "fulltext_search_title", "func_src_before": "def fulltext_search_title(query):\n    query_string = \"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\".format(query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs", "func_src_after": "def fulltext_search_title(query):\n    query_statement = sql.text(\"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\")\n\n    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs", "line_changes": {"deleted": [{"line_no": 2, "char_start": 34, "char_end": 57, "line": "    query_string = \"\"\"\n"}, {"line_no": 4, "char_start": 173, "char_end": 292, "line": "        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n"}, {"line_no": 7, "char_start": 372, "char_end": 407, "line": "        LIMIT 50;\"\"\".format(query)\n"}, {"line_no": 9, "char_start": 408, "char_end": 472, "line": "    rows = db.engine.execute(sql.text(query_string)).fetchall()\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 69, "line": "    query_statement = sql.text(\"\"\"\n"}, {"line_no": 4, "char_start": 185, "char_end": 311, "line": "        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n"}, {"line_no": 7, "char_start": 391, "char_end": 413, "line": "        LIMIT 50;\"\"\")\n"}, {"line_no": 9, "char_start": 414, "char_end": 500, "line": "    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 46, "char_end": 53, "chars": "ring = "}, {"char_start": 223, "char_end": 227, "chars": "'{}'"}, {"char_start": 392, "char_end": 405, "chars": ".format(query"}, {"char_start": 437, "char_end": 458, "chars": "sql.text(query_string"}], "added": [{"char_start": 46, "char_end": 65, "chars": "atement = sql.text("}, {"char_start": 235, "char_end": 246, "chars": ":search_str"}, {"char_start": 443, "char_end": 486, "chars": "query_statement.bindparams(search_str=query"}]}, "commit_link": "github.com/Impactstory/oadoi/commit/4cde28ea869c921be917cd8726edb958b37d683a", "file_name": "search.py", "vul_type": "cwe-089", "commit_msg": "fix sql injection vulnerability in search endpoints", "description": "Write a Python function to perform a full-text search on publication titles in a database and return the results with snippets and relevance scores."}
{"func_name": "dnxhd_find_frame_end", "func_src_before": "static int dnxhd_find_frame_end(DNXHDParserContext *dctx,\n                                const uint8_t *buf, int buf_size)\n{\n    ParseContext *pc = &dctx->pc;\n    uint64_t state = pc->state64;\n    int pic_found = pc->frame_start_found;\n    int i = 0;\n\n    if (!pic_found) {\n        for (i = 0; i < buf_size; i++) {\n            state = (state << 8) | buf[i];\n            if (ff_dnxhd_check_header_prefix(state & 0xffffffffff00LL) != 0) {\n                i++;\n                pic_found = 1;\n                dctx->cur_byte = 0;\n                dctx->remaining = 0;\n                break;\n            }\n        }\n    }\n\n    if (pic_found && !dctx->remaining) {\n        if (!buf_size) /* EOF considered as end of frame */\n            return 0;\n        for (; i < buf_size; i++) {\n            dctx->cur_byte++;\n            state = (state << 8) | buf[i];\n\n            if (dctx->cur_byte == 24) {\n                dctx->h = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 26) {\n                dctx->w = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 42) {\n                int cid = (state >> 32) & 0xFFFFFFFF;\n\n                if (cid <= 0)\n                    continue;\n\n                dctx->remaining = avpriv_dnxhd_get_frame_size(cid);\n                if (dctx->remaining <= 0) {\n                    dctx->remaining = dnxhd_get_hr_frame_size(cid, dctx->w, dctx->h);\n                    if (dctx->remaining <= 0)\n                        return dctx->remaining;\n                }\n                if (buf_size - i + 47 >= dctx->remaining) {\n                    int remaining = dctx->remaining;\n\n                    pc->frame_start_found = 0;\n                    pc->state64 = -1;\n                    dctx->cur_byte = 0;\n                    dctx->remaining = 0;\n                    return remaining;\n                } else {\n                    dctx->remaining -= buf_size;\n                }\n            }\n        }\n    } else if (pic_found) {\n        if (dctx->remaining > buf_size) {\n            dctx->remaining -= buf_size;\n        } else {\n            int remaining = dctx->remaining;\n\n            pc->frame_start_found = 0;\n            pc->state64 = -1;\n            dctx->cur_byte = 0;\n            dctx->remaining = 0;\n            return remaining;\n        }\n    }\n    pc->frame_start_found = pic_found;\n    pc->state64 = state;\n    return END_NOT_FOUND;\n}", "func_src_after": "static int dnxhd_find_frame_end(DNXHDParserContext *dctx,\n                                const uint8_t *buf, int buf_size)\n{\n    ParseContext *pc = &dctx->pc;\n    uint64_t state = pc->state64;\n    int pic_found = pc->frame_start_found;\n    int i = 0;\n\n    if (!pic_found) {\n        for (i = 0; i < buf_size; i++) {\n            state = (state << 8) | buf[i];\n            if (ff_dnxhd_check_header_prefix(state & 0xffffffffff00LL) != 0) {\n                i++;\n                pic_found = 1;\n                dctx->cur_byte = 0;\n                dctx->remaining = 0;\n                break;\n            }\n        }\n    }\n\n    if (pic_found && !dctx->remaining) {\n        if (!buf_size) /* EOF considered as end of frame */\n            return 0;\n        for (; i < buf_size; i++) {\n            dctx->cur_byte++;\n            state = (state << 8) | buf[i];\n\n            if (dctx->cur_byte == 24) {\n                dctx->h = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 26) {\n                dctx->w = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 42) {\n                int cid = (state >> 32) & 0xFFFFFFFF;\n                int remaining;\n\n                if (cid <= 0)\n                    continue;\n\n                remaining = avpriv_dnxhd_get_frame_size(cid);\n                if (remaining <= 0) {\n                    remaining = dnxhd_get_hr_frame_size(cid, dctx->w, dctx->h);\n                    if (remaining <= 0)\n                        continue;\n                }\n                dctx->remaining = remaining;\n                if (buf_size - i + 47 >= dctx->remaining) {\n                    int remaining = dctx->remaining;\n\n                    pc->frame_start_found = 0;\n                    pc->state64 = -1;\n                    dctx->cur_byte = 0;\n                    dctx->remaining = 0;\n                    return remaining;\n                } else {\n                    dctx->remaining -= buf_size;\n                }\n            }\n        }\n    } else if (pic_found) {\n        if (dctx->remaining > buf_size) {\n            dctx->remaining -= buf_size;\n        } else {\n            int remaining = dctx->remaining;\n\n            pc->frame_start_found = 0;\n            pc->state64 = -1;\n            dctx->cur_byte = 0;\n            dctx->remaining = 0;\n            return remaining;\n        }\n    }\n    pc->frame_start_found = pic_found;\n    pc->state64 = state;\n    return END_NOT_FOUND;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/0a709e2a10b8288a0cc383547924ecfe285cef89", "file_name": "libavcodec/dnxhd_parser.c", "vul_type": "cwe-476", "description": "Write a C function to detect the end of a frame in a DNXHD video stream buffer."}
{"func_name": "change_user_settings", "func_src_before": "@app.route('/users/edit/<username>', methods=['GET', 'POST'])\ndef change_user_settings(username):\n  \"\"\" Procedure to process the login page. Also handles authentication. \"\"\"\n\n  if 'username' not in session:\n    flash('You must be logged in for that.')\n    return redirect(url_for('login'))\n\n  if session['username'] != username:\n    flash('You cannot edit this user\\'s information.')\n    return redirect(url_for('show_user_profile', username=username))\n\n\n  params = {}\n  tags = ['nickname', 'usenickname', 'bday', 'email', 'email2', 'msc', 'phone', \\\n      'building', 'room_num', 'major', 'isabroad']\n  tag_names = [\"Nickname\", \"Use Nickname\", \"Birthday\", \"Email Address\", \\\n      \"Alt. Email Address\", \"MSC\", \"Phone Number\", \"Building Name\", \"Room Number\", \\\n      \"Major\", \"Is Abroad\"]\n\n  # Get stored values from database\n  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    stored_params = dict(zip(result_cols, r)) #stored_params maps sql columns to values\n\n  # Update if needed\n  if request.method == 'POST':\n\n    for (i, tag) in enumerate(tags):\n      params[tag] = request.form[tag]\n\n\n    for (i, tag) in enumerate(tags):\n      if str(params[tag]) != str(stored_params[tag]):\n\n        new_val = str(params[tag])\n        if tag in ['usenickname', 'msc', 'room_num', 'isabroad']:\n          new_val = int(new_val)\n\n        query = text(\"UPDATE members SET %s = :val WHERE user_id = :u\" % tag)\n        results = connection.execute(query, u=session['user_id'], val=new_val)\n\n        flash(\"%s was updated!\" % tag_names[i])\n\n\n  if not params:\n    params = stored_params\n\n  return render_template('edit_user.html', params = params)", "func_src_after": "@app.route('/users/edit/<username>', methods=['GET', 'POST'])\ndef change_user_settings(username):\n  \"\"\" Procedure to process the login page. Also handles authentication. \"\"\"\n\n  if 'username' not in session:\n    flash('You must be logged in for that.')\n    return redirect(url_for('login'))\n\n  if session['username'] != username:\n    flash('You cannot edit this user\\'s information.')\n    return redirect(url_for('show_user_profile', username=username))\n\n\n  params = {}\n  tags = ['nickname', 'usenickname', 'bday', 'email', 'email2', 'msc', 'phone', \\\n      'building', 'room_num', 'major', 'isabroad']\n  tag_names = [\"Nickname\", \"Use Nickname\", \"Birthday\", \"Email Address\", \\\n      \"Alt. Email Address\", \"MSC\", \"Phone Number\", \"Building Name\", \"Room Number\", \\\n      \"Major\", \"Is Abroad\"]\n\n  # Get stored values from database\n  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    stored_params = dict(zip(result_cols, r)) #stored_params maps sql columns to values\n\n  # Update if needed\n  if request.method == 'POST':\n\n    for (i, tag) in enumerate(tags):\n      params[tag] = request.form[tag]\n\n\n    for (i, tag) in enumerate(tags):\n      if str(params[tag]) != str(stored_params[tag]):\n\n        new_val = str(params[tag])\n        if tag in ['usenickname', 'msc', 'room_num', 'isabroad']:\n          new_val = int(new_val)\n\n        query = text(\"UPDATE members SET %s = :val WHERE user_id = :u\" % tag)\n        results = connection.execute(query, u=session['user_id'], val=new_val)\n\n        flash(\"%s was updated!\" % tag_names[i])\n\n\n  if not params:\n    params = stored_params\n\n  return render_template('edit_user.html', params = params)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 826, "char_end": 903, "line": "  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n"}], "added": [{"line_no": 22, "char_start": 826, "char_end": 903, "line": "  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n"}]}, "char_changes": {"deleted": [{"char_start": 863, "char_end": 869, "chars": "atural"}, {"char_start": 883, "char_end": 888, "chars": "where"}], "added": [{"char_start": 863, "char_end": 869, "chars": "ATURAL"}, {"char_start": 883, "char_end": 888, "chars": "WHERE"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "RuddockWebsite.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python Flask function to edit user settings, checking if the user is logged in and authorized to edit the specified user's profile."}
{"func_name": "concat_hash_string", "func_src_before": "static u_int16_t concat_hash_string(struct ndpi_packet_struct *packet,\n\t\t\t\t   char *buf, u_int8_t client_hash) {\n  u_int16_t offset = 22, buf_out_len = 0;\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  u_int32_t len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4;\n\n  /* -1 for ';' */\n  if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n    goto invalid_payload;\n\n  /* ssh.kex_algorithms [C/S] */\n  strncpy(buf, (const char *)&packet->payload[offset], buf_out_len = len);\n  buf[buf_out_len++] = ';';\n  offset += len;\n\n  /* ssh.server_host_key_algorithms [None] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4 + len;\n\n  /* ssh.encryption_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.encryption_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.mac_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.mac_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_client_to_server [C] */\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.languages_client_to_server [None] */\n\n  /* ssh.languages_server_to_client [None] */\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] %s\\n\", buf);\n#endif\n\n  return(buf_out_len);\n\ninvalid_payload:\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] Invalid packet payload\\n\");\n#endif\n\n  return(0);\n}", "func_src_after": "static u_int16_t concat_hash_string(struct ndpi_packet_struct *packet,\n\t\t\t\t   char *buf, u_int8_t client_hash) {\n  u_int16_t offset = 22, buf_out_len = 0;\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  u_int32_t len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4;\n\n  /* -1 for ';' */\n  if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n    goto invalid_payload;\n\n  /* ssh.kex_algorithms [C/S] */\n  strncpy(buf, (const char *)&packet->payload[offset], buf_out_len = len);\n  buf[buf_out_len++] = ';';\n  offset += len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.server_host_key_algorithms [None] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.encryption_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.encryption_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.mac_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.mac_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_client_to_server [C] */\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.compression_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.languages_client_to_server [None] */\n\n  /* ssh.languages_server_to_client [None] */\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] %s\\n\", buf);\n#endif\n\n  return(buf_out_len);\n\ninvalid_payload:\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] Invalid packet payload\\n\");\n#endif\n\n  return(0);\n}", "commit_link": "github.com/ntop/nDPI/commit/3bbb0cd3296023f6f922c71d21a1c374d2b0a435", "file_name": "src/lib/protocols/ssh.c", "vul_type": "cwe-125", "description": "Write a C function to concatenate SSH protocol fields into a buffer, handling client or server hash conditions."}
{"func_name": "WavpackVerifySingleBlock", "func_src_before": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff) || *dp++ != ((csum >> 16) & 0xff) || *dp++ != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "func_src_after": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff) || dp[2] != ((csum >> 16) & 0xff) || dp[3] != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "commit_link": "github.com/dbry/WavPack/commit/bba5389dc598a92bdf2b297c3ea34620b6679b5b", "file_name": "src/open_utils.c", "vul_type": "cwe-125", "description": "In C, write a function to verify the integrity of a single Wavpack audio block, optionally checking its checksum."}
{"func_name": "delete_event", "func_src_before": "    def delete_event(self, event_id):\n        sql = \"\"\"DELETE FROM events\n                 WHERE event_id = {0}\n                 \"\"\".format(event_id)\n        affected_count = self.cur.execute(sql)\n        self.conn.commit()\n        return affected_count", "func_src_after": "    def delete_event(self, event_id):\n        sql = \"\"\"\n              DELETE FROM events\n              WHERE event_id = %s\n              \"\"\"\n        affected_count = self.cur.execute(sql, (event_id,))\n        self.conn.commit()\n        return affected_count", "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089", "description": "Write a Python function to delete an event by its ID from a database and return the number of affected rows."}
{"func_name": "SessionAttributesManager::doGet", "func_src_before": "  @Override\n  protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n    response.setHeader(\"Cache-Control\", \"no-cache\");\n    response.setHeader(\"Pragma\", \"no-cache\");\n    response.setDateHeader(\"Expires\", -1);\n\n    String name = request.getParameter(\"name\");\n    String value = request.getParameter(\"value\");\n    String message = \"The parameter 'name' is empty\";\n\n    if (name != null && name.length() > 0) {\n      if (allowedAttributes.contains(name)) {\n\n        // add bcdBeanUser.name entries as HashMap session variable \"bcdBeanUser\" where the key/value pairs\n        // are kept without the prefix.\n        boolean error = true;\n        Subject subject = SecurityUtils.getSubject();\n        // check value against list of allowed values or subject settings user rights\n        if (subject != null && subject.getSession() != null && ((allowedValues.get(name) != null && allowedValues.get(name).contains(\" \" + value + \" \")) || subject.isPermitted(BCD_EL_USER_BEAN + \":\" + name + \":\" + value))) {\n          Map<String, String> bean = (HashMap<String, String>)subject.getSession().getAttribute(BCD_EL_USER_BEAN);\n          if (bean == null)\n            bean = new HashMap<>();\n          bean.put(name, value);\n          subject.getSession().setAttribute(BCD_EL_USER_BEAN, bean);\n          error = false;\n        }\n        message =\"The \" + BCD_EL_USER_BEAN + \" '\" + name +  (error ? \"' can not be set to '\" : \"' was set to \") + value;\n      }\n      else {\n        message = \"The attribute name '\" + name + \"' is not allowed by the configuration. Please set the init param ALLOWED_ATTRIBUTES in your web.xml\";\n      }\n    }\n    log.debug(message);\n    response.getWriter().append(message);\n  }", "func_src_after": "  @Override\n  protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n    response.setHeader(\"Cache-Control\", \"no-cache\");\n    response.setHeader(\"Pragma\", \"no-cache\");\n    response.setDateHeader(\"Expires\", -1);\n\n    String name = request.getParameter(\"name\");\n    String value = request.getParameter(\"value\");\n    String message = \"The parameter 'name' is empty\";\n\n    if (name != null && name.length() > 0) {\n      if (allowedAttributes.contains(name)) {\n\n        // add bcdBeanUser.name entries as HashMap session variable \"bcdBeanUser\" where the key/value pairs\n        // are kept without the prefix.\n        boolean error = true;\n        Subject subject = SecurityUtils.getSubject();\n        // check value against list of allowed values or subject settings user rights\n        if (subject != null && subject.getSession() != null && ((allowedValues.get(name) != null && allowedValues.get(name).contains(\" \" + value + \" \")) || subject.isPermitted(BCD_EL_USER_BEAN + \":\" + name + \":\" + value))) {\n          Map<String, String> bean = (HashMap<String, String>)subject.getSession().getAttribute(BCD_EL_USER_BEAN);\n          if (bean == null)\n            bean = new HashMap<>();\n          bean.put(name, value);\n          subject.getSession().setAttribute(BCD_EL_USER_BEAN, bean);\n          error = false;\n        }\n        message =\"The \" + BCD_EL_USER_BEAN + \" '\" + name +  (error ? \"' can not be set to '\" : \"' was set to \") + value;\n      }\n      else {\n        message = \"The attribute name '\" + name + \"' is not allowed by the configuration. Please set the init param ALLOWED_ATTRIBUTES in your web.xml\";\n      }\n    }\n    log.debug(message);\n  }", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1712, "char_end": 1754, "line": "    response.getWriter().append(message);\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 1712, "char_end": 1754, "chars": "    response.getWriter().append(message);\n"}], "added": []}, "commit_link": "github.com/businesscode/BCD-UI/commit/9b230b1500511054da457cf4a5382895fae891df", "file_name": "SessionAttributesManager.java", "vul_type": "cwe-079", "commit_msg": "Server/Security, XSS fixes", "parent_commit": "1b507ea97204e6b71d5863d4c6e523e51a3440b2", "description": "Create a Java servlet that processes a GET request by updating session attributes based on provided parameters and logs the result."}
{"func_name": "update_institutions", "func_src_before": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES ('%s')\" % current_institution\n            sqlite.execute(sql)\n            conn.commit()", "func_src_after": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES (?)\"\n            sqlite.execute(sql, (current_institution,))\n            conn.commit()", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to update an institution table by comparing old and new institution records, sending notifications for discrepancies, and inserting new records."}
{"func_name": "renderPreviewLink", "func_src_before": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "func_src_after": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 173, "char_end": 283, "line": "      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}], "added": [{"line_no": 6, "char_start": 173, "char_end": 309, "line": "      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 210, "char_end": 236, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/maputnik/editor/commit/3f350c30da0791f542909f665f381e509e68c6c1", "file_name": "ExportModal.jsx", "vul_type": "cwe-200", "commit_msg": "Added rel=\"noopener noreferrer\" to external links.", "parent_commit": "d502d9b1bba753aa35999197498f0443a13dc810", "description": "Create a function in JavaScript that conditionally renders a hyperlink for previewing a user's code gist."}
{"func_name": "save", "func_src_before": "    def save(self, data_store, filename):\n        pgm_model = self.model\n        if type(data_store) is LocalFileSystem:\n            data_store.write_pomegranate_model(\n                model=pgm_model, filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            with open(local_filename, 'wb') as f:\n                # IMPORTANT: Set pickle.HIGHEST_PROTOCOL only  after complete porting to\n                # Python3\n                pickle.dump(pgm_model.to_json(), f, protocol=2)\n\n            data_store.upload_file(local_filename, filename)\n        return None", "func_src_after": "    def save(self, data_store, filename):\n        pgm_model = self.model\n        if type(data_store) is LocalFileSystem:\n            data_store.write_pomegranate_model(\n                model=pgm_model, filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            with open(local_filename, 'wb') as f:\n                # IMPORTANT: Set pickle.HIGHEST_PROTOCOL only  after complete porting to\n                # Python3\n                f.write(pgm_model.to_json())\n\n            data_store.upload_file(local_filename, filename)\n        return None", "line_changes": {"deleted": [{"line_no": 11, "char_start": 478, "char_end": 542, "line": "                pickle.dump(pgm_model.to_json(), f, protocol=2)\n"}], "added": [{"line_no": 11, "char_start": 478, "char_end": 523, "line": "                f.write(pgm_model.to_json())\n"}]}, "char_changes": {"deleted": [{"char_start": 494, "char_end": 505, "chars": "pickle.dump"}, {"char_start": 525, "char_end": 540, "chars": ", f, protocol=2"}], "added": [{"char_start": 494, "char_end": 501, "chars": "f.write"}]}, "commit_link": "github.com/sara-02/fabric8-analytics-stack-analysis/commit/c9422e6257a8c927aed2999a0f4cc77f90059cda", "file_name": "pgm_pomegranate.py", "vul_type": "cwe-502", "commit_msg": "Remove pickling of model\n\nThe model is already being converted to a JSON(using the `to_json`)\nfunction of pomegranate which is already a stadard serialized format.\nI don't see a need to further serialize the JSON using pickle to\nsomething that can be loaded only using Python. This also helps us\nreduce the training time of the model as pickling and unpickling\nhas a overhead that I don't see a need for, because JSON.", "parent_commit": "c2ddf128d7206a0a85929b6f2a08078433ce1577", "description": "Write a Python function to save a model to either a local file system or an S3 data store."}
{"func_name": "ExtractPostscript", "func_src_before": "static Image *ExtractPostscript(Image *image,const ImageInfo *image_info,\n  MagickOffsetType PS_Offset,ssize_t PS_Size,ExceptionInfo *exception)\n{\n  char\n    postscript_file[MaxTextExtent];\n\n  const MagicInfo\n    *magic_info;\n\n  FILE\n    *ps_file;\n\n  ImageInfo\n    *clone_info;\n\n  Image\n    *image2;\n\n  unsigned char\n    magick[2*MaxTextExtent];\n\n\n  if ((clone_info=CloneImageInfo(image_info)) == NULL)\n    return(image);\n  clone_info->blob=(void *) NULL;\n  clone_info->length=0;\n\n  /* Obtain temporary file */\n  (void) AcquireUniqueFilename(postscript_file);\n  ps_file=fopen_utf8(postscript_file,\"wb\");\n  if (ps_file == (FILE *) NULL)\n    goto FINISH;\n\n  /* Copy postscript to temporary file */\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  (void) ReadBlob(image, 2*MaxTextExtent, magick);\n\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  while(PS_Size-- > 0)\n    {\n      (void) fputc(ReadBlobByte(image),ps_file);\n    }\n  (void) fclose(ps_file);\n\n    /* Detect file format - Check magic.mgk configuration file. */\n  magic_info=GetMagicInfo(magick,2*MaxTextExtent,exception);\n  if(magic_info == (const MagicInfo *) NULL) goto FINISH_UNL;\n  /*     printf(\"Detected:%s  \\n\",magic_info->name); */\n  if(exception->severity != UndefinedException) goto FINISH_UNL;\n  if(magic_info->name == (char *) NULL) goto FINISH_UNL;\n\n  (void) CopyMagickMemory(clone_info->magick,magic_info->name,MaxTextExtent);\n\n    /* Read nested image */\n  /*FormatString(clone_info->filename,\"%s:%s\",magic_info->name,postscript_file);*/\n  FormatLocaleString(clone_info->filename,MaxTextExtent,\"%s\",postscript_file);\n  image2=ReadImage(clone_info,exception);\n\n  if (!image2)\n    goto FINISH_UNL;\n\n  /*\n    Replace current image with new image while copying base image\n    attributes.\n  */\n  (void) CopyMagickMemory(image2->filename,image->filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick_filename,image->magick_filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick,image->magick,MaxTextExtent);\n  image2->depth=image->depth;\n  DestroyBlob(image2);\n  image2->blob=ReferenceBlob(image->blob);\n\n  if ((image->rows == 0) || (image->columns == 0))\n    DeleteImageFromList(&image);\n\n  AppendImageToList(&image,image2);\n\n FINISH_UNL:\n  (void) RelinquishUniqueFileResource(postscript_file);\n FINISH:\n  DestroyImageInfo(clone_info);\n  return(image);\n}", "func_src_after": "static Image *ExtractPostscript(Image *image,const ImageInfo *image_info,\n  MagickOffsetType PS_Offset,ssize_t PS_Size,ExceptionInfo *exception)\n{\n  char\n    postscript_file[MaxTextExtent];\n\n  const MagicInfo\n    *magic_info;\n\n  FILE\n    *ps_file;\n\n  ImageInfo\n    *clone_info;\n\n  Image\n    *image2;\n\n  unsigned char\n    magick[2*MaxTextExtent];\n\n\n  if ((clone_info=CloneImageInfo(image_info)) == NULL)\n    return(image);\n  clone_info->blob=(void *) NULL;\n  clone_info->length=0;\n\n  /* Obtain temporary file */\n  (void) AcquireUniqueFilename(postscript_file);\n  ps_file=fopen_utf8(postscript_file,\"wb\");\n  if (ps_file == (FILE *) NULL)\n    goto FINISH;\n\n  /* Copy postscript to temporary file */\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  (void) ReadBlob(image, 2*MaxTextExtent, magick);\n\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  while(PS_Size-- > 0)\n    {\n      (void) fputc(ReadBlobByte(image),ps_file);\n    }\n  (void) fclose(ps_file);\n\n    /* Detect file format - Check magic.mgk configuration file. */\n  magic_info=GetMagicInfo(magick,2*MaxTextExtent,exception);\n  if(magic_info == (const MagicInfo *) NULL) goto FINISH_UNL;\n  /*     printf(\"Detected:%s  \\n\",magic_info->name); */\n  if(exception->severity != UndefinedException) goto FINISH_UNL;\n  if(magic_info->name == (char *) NULL) goto FINISH_UNL;\n\n  (void) strncpy(clone_info->magick,magic_info->name,MaxTextExtent);\n\n    /* Read nested image */\n  /*FormatString(clone_info->filename,\"%s:%s\",magic_info->name,postscript_file);*/\n  FormatLocaleString(clone_info->filename,MaxTextExtent,\"%s\",postscript_file);\n  image2=ReadImage(clone_info,exception);\n\n  if (!image2)\n    goto FINISH_UNL;\n\n  /*\n    Replace current image with new image while copying base image\n    attributes.\n  */\n  (void) CopyMagickMemory(image2->filename,image->filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick_filename,image->magick_filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick,image->magick,MaxTextExtent);\n  image2->depth=image->depth;\n  DestroyBlob(image2);\n  image2->blob=ReferenceBlob(image->blob);\n\n  if ((image->rows == 0) || (image->columns == 0))\n    DeleteImageFromList(&image);\n\n  AppendImageToList(&image,image2);\n\n FINISH_UNL:\n  (void) RelinquishUniqueFileResource(postscript_file);\n FINISH:\n  DestroyImageInfo(clone_info);\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/a251039393f423c7858e63cab6aa98d17b8b7a41", "file_name": "coders/wpg.c", "vul_type": "cwe-125", "description": "Write a C function to extract a Postscript section from an image and read it into a new image structure."}
{"func_name": "SMB2_read", "func_src_before": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "func_src_after": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\tcifs_small_buf_release(req);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/088aaf17aa79300cab14dbee2569c58cfafd7d6e", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "Write a C function named `SMB2_read` that performs a read operation using Server Message Block (SMB) protocol version 2."}
{"func_name": "(anonymous)", "func_src_before": "      this.idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            self.$noresults.html('<p>No results matching your query:<code>' + originalQuery + '<code><p>');\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "func_src_after": "      this.idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            self.$noresults.html('<p>No results matching your query:<code>' + $('<div />').text(originalQuery).html() + '<code><p>');\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "line_changes": {"deleted": [{"line_no": 8, "char_start": 247, "char_end": 355, "line": "            self.$noresults.html('<p>No results matching your query:<code>' + originalQuery + '<code><p>');\n"}], "added": [{"line_no": 8, "char_start": 247, "char_end": 381, "line": "            self.$noresults.html('<p>No results matching your query:<code>' + $('<div />').text(originalQuery).html() + '<code><p>');\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 325, "char_end": 343, "chars": "$('<div />').text("}, {"char_start": 356, "char_end": 364, "chars": ").html()"}]}, "commit_link": "github.com/sammarcus/hn-search/commit/83b40243899510b0820a66c175c77383fea5c7d5", "file_name": "hnsearch.beta.js", "vul_type": "cwe-079", "commit_msg": "Fixed XSS :)", "description": "Write a JavaScript function that performs a search with a given query, logs errors to the console, and updates the UI to show whether there are results or not."}
{"func_name": "get_output", "func_src_before": "def get_output(command: str) -> bytes:\n    \"\"\"\n    Run a command and return raw output\n\n    :param str command: the command to run\n    :returns: the stdout output of the command\n    \"\"\"\n    return subprocess.check_output(command.split())", "func_src_after": "def get_output(command: List[str]) -> str:\n    \"\"\"\n    Run a command and return raw output\n\n    :param str command: the command to run\n    :returns: the stdout output of the command\n    \"\"\"\n    result = subprocess.run(command, stdout=subprocess.PIPE, check=True)\n    return result.stdout.decode()", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "isort/hooks.py", "vul_type": "cwe-078", "description": "Write a Python function that executes a system command and returns the output."}
{"func_name": "wl_closure_print", "func_src_before": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tchar buffer[4] = \"\\0\";\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tbuffer,\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "func_src_after": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tsend ? \" -> \" : \"\",\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 107, "char_end": 131, "line": "\tchar buffer[4] = \"\\0\";\n"}, {"line_no": 9, "char_start": 181, "char_end": 192, "line": "\tif (send)\n"}, {"line_no": 10, "char_start": 192, "char_end": 219, "line": "\t\tsprintf(buffer, \" -> \");\n"}, {"line_no": 11, "char_start": 219, "char_end": 220, "line": "\n"}, {"line_no": 17, "char_start": 370, "char_end": 380, "line": "\t\tbuffer,\n"}], "added": [{"line_no": 13, "char_start": 307, "char_end": 329, "line": "\t\tsend ? \" -> \" : \"\",\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 131, "chars": "\tchar buffer[4] = \"\\0\";\n"}, {"char_start": 181, "char_end": 220, "chars": "\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n"}, {"char_start": 372, "char_end": 378, "chars": "buffer"}], "added": [{"char_start": 309, "char_end": 327, "chars": "send ? \" -> \" : \"\""}]}, "commit_link": "github.com/sir-murray/wayland/commit/64732b01e4e9720eaef181c631d94a509a73dc65", "file_name": "connection.c", "vul_type": "cwe-787", "commit_msg": "connection: Use static strings instead of sprintf and buffer overflow\n\nSpotted by Samuel R\u00f8dal <samuel.rodal@nokia.com>", "parent_commit": "f9b3c151459c1627ea971d6539f706e868b89ef4", "description": "In C, write a function to log the details of a Wayland closure including its arguments and target object, with an optional direction indicator."}
{"func_name": "fixture", "func_src_before": "  def fixture(key, opts = {})\n    memo = Fixtures[key]\n    return memo if memo\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n\n    yaml = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    json = Pathname.new(File.join(dir, \"fixture_#{key}.json\"))\n    txt = Pathname.new(File.join(dir, \"fixture_#{key}.txt\"))\n\n    Fixtures[key] = if yaml.exist?; then YAML.load(File.read(yaml))\n                    elsif json.exist?; then JSON.parse(File.read(json))\n                    elsif txt.exist?; then File.read(txt)\n                    else fail \"could not load YAML or JSON fixture #{key}\"\n                    end", "func_src_after": "  def fixture(key, opts = {})\n    memo = Fixtures[key]\n    return memo if memo\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n\n    yaml = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    json = Pathname.new(File.join(dir, \"fixture_#{key}.json\"))\n    txt = Pathname.new(File.join(dir, \"fixture_#{key}.txt\"))\n\n    Fixtures[key] = if yaml.exist?; then YAML.safe_load(File.read(yaml))\n                    elsif json.exist?; then JSON.parse(File.read(json))\n                    elsif txt.exist?; then File.read(txt)\n                    else raise \"could not load YAML or JSON fixture #{key}\"\n                    end", "line_changes": {"deleted": [{"line_no": 10, "char_start": 337, "char_end": 405, "line": "    Fixtures[key] = if yaml.exist?; then YAML.load(File.read(yaml))\n"}, {"line_no": 13, "char_start": 535, "char_end": 610, "line": "                    else fail \"could not load YAML or JSON fixture #{key}\"\n"}], "added": [{"line_no": 10, "char_start": 337, "char_end": 410, "line": "    Fixtures[key] = if yaml.exist?; then YAML.safe_load(File.read(yaml))\n"}, {"line_no": 13, "char_start": 540, "char_end": 616, "line": "                    else raise \"could not load YAML or JSON fixture #{key}\"\n"}]}, "char_changes": {"deleted": [{"char_start": 560, "char_end": 561, "chars": "f"}, {"char_start": 563, "char_end": 564, "chars": "l"}], "added": [{"char_start": 383, "char_end": 388, "chars": "safe_"}, {"char_start": 565, "char_end": 566, "chars": "r"}, {"char_start": 568, "char_end": 570, "chars": "se"}]}, "commit_link": "github.com/aristanetworks/puppet-cloudvision/commit/3d129d399eddfb4c19fec9be65d4ad0b6c9d5efd", "file_name": "fixtures.rb", "vul_type": "cwe-502", "commit_msg": "Replace YAML.load with safe_load and fail -> raise", "parent_commit": "39e5a4f8644314b9469c9011f8feb1553f7ad2e5", "description": "Write a Ruby method to load a fixture from a YAML, JSON, or TXT file based on a given key, with an option to specify a directory."}
{"func_name": "update_history_and_sourcebyinstitution", "func_src_before": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                sqlite.execute(sql)\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                    sqlite.execute(sql)\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES ('%s')\" % sourcebyinstitution\n                sqlite.execute(sql)\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "func_src_after": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                sqlite.execute(sql, (sourcebyinstitution, number))\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                    sqlite.execute(sql, (sourcebyinstitution, number))\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES (?)\"\n                sqlite.execute(sql, (sourcebyinstitution))\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to log current source and title data from Solr into a database, handling new and old entries."}
{"func_name": "ac_circ_buf_pushm", "func_src_before": "int ac_circ_buf_pushm(ac_circ_buf_t *cbuf, const void *buf, u32 count)\n{\n\tif (circ_space_to_end(cbuf) < count) {\n\t\tif (circ_count(cbuf) == 0 && count <= cbuf->size)\n\t\t\tcbuf->head = cbuf->tail = 0;\n\t\telse\n\t\t\treturn -1;\n\t}\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(cbuf->buf.ptr_buf + cbuf->head, buf,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(cbuf->buf.cpy_buf + cbuf->head, buf,\n\t\t       count * cbuf->elem_sz);\n\n\tcbuf->head = (cbuf->head + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "func_src_after": "int ac_circ_buf_pushm(ac_circ_buf_t *cbuf, const void *buf, u32 count)\n{\n\tif (circ_space_to_end(cbuf) < count) {\n\t\tif (circ_count(cbuf) == 0 && count <= cbuf->size)\n\t\t\tcbuf->head = cbuf->tail = 0;\n\t\telse\n\t\t\treturn -1;\n\t}\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(cbuf->buf.ptr_buf + cbuf->head, buf,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(cbuf->buf.cpy_buf + cbuf->head, buf,\n\t\t       (size_t)count * cbuf->elem_sz);\n\n\tcbuf->head = (cbuf->head + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 15, "char_start": 382, "char_end": 415, "line": "\t\t       count * cbuf->elem_sz);\n"}], "added": [{"line_no": 15, "char_start": 382, "char_end": 423, "line": "\t\t       (size_t)count * cbuf->elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 391, "char_end": 399, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to add multiple elements to a circular buffer, returning 0 on success or -1 if there isn't enough space."}
{"func_name": "usb_audio_probe", "func_src_before": "static int usb_audio_probe(struct usb_interface *intf,\n\t\t\t   const struct usb_device_id *usb_id)\n{\n\tstruct usb_device *dev = interface_to_usbdev(intf);\n\tconst struct snd_usb_audio_quirk *quirk =\n\t\t(const struct snd_usb_audio_quirk *)usb_id->driver_info;\n\tstruct snd_usb_audio *chip;\n\tint i, err;\n\tstruct usb_host_interface *alts;\n\tint ifnum;\n\tu32 id;\n\n\talts = &intf->altsetting[0];\n\tifnum = get_iface_desc(alts)->bInterfaceNumber;\n\tid = USB_ID(le16_to_cpu(dev->descriptor.idVendor),\n\t\t    le16_to_cpu(dev->descriptor.idProduct));\n\tif (get_alias_id(dev, &id))\n\t\tquirk = get_alias_quirk(dev, id);\n\tif (quirk && quirk->ifnum >= 0 && ifnum != quirk->ifnum)\n\t\treturn -ENXIO;\n\n\terr = snd_usb_apply_boot_quirk(dev, intf, quirk, id);\n\tif (err < 0)\n\t\treturn err;\n\n\t/*\n\t * found a config.  now register to ALSA\n\t */\n\n\t/* check whether it's already registered */\n\tchip = NULL;\n\tmutex_lock(&register_mutex);\n\tfor (i = 0; i < SNDRV_CARDS; i++) {\n\t\tif (usb_chip[i] && usb_chip[i]->dev == dev) {\n\t\t\tif (atomic_read(&usb_chip[i]->shutdown)) {\n\t\t\t\tdev_err(&dev->dev, \"USB device is in the shutdown state, cannot create a card instance\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto __error;\n\t\t\t}\n\t\t\tchip = usb_chip[i];\n\t\t\tatomic_inc(&chip->active); /* avoid autopm */\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (! chip) {\n\t\t/* it's a fresh one.\n\t\t * now look for an empty slot and create a new card instance\n\t\t */\n\t\tfor (i = 0; i < SNDRV_CARDS; i++)\n\t\t\tif (!usb_chip[i] &&\n\t\t\t    (vid[i] == -1 || vid[i] == USB_ID_VENDOR(id)) &&\n\t\t\t    (pid[i] == -1 || pid[i] == USB_ID_PRODUCT(id))) {\n\t\t\t\tif (enable[i]) {\n\t\t\t\t\terr = snd_usb_audio_create(intf, dev, i, quirk,\n\t\t\t\t\t\t\t\t   id, &chip);\n\t\t\t\t\tif (err < 0)\n\t\t\t\t\t\tgoto __error;\n\t\t\t\t\tchip->pm_intf = intf;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (vid[i] != -1 || pid[i] != -1) {\n\t\t\t\t\tdev_info(&dev->dev,\n\t\t\t\t\t\t \"device (%04x:%04x) is disabled\\n\",\n\t\t\t\t\t\t USB_ID_VENDOR(id),\n\t\t\t\t\t\t USB_ID_PRODUCT(id));\n\t\t\t\t\terr = -ENOENT;\n\t\t\t\t\tgoto __error;\n\t\t\t\t}\n\t\t\t}\n\t\tif (!chip) {\n\t\t\tdev_err(&dev->dev, \"no available usb audio device\\n\");\n\t\t\terr = -ENODEV;\n\t\t\tgoto __error;\n\t\t}\n\t}\n\tdev_set_drvdata(&dev->dev, chip);\n\n\t/*\n\t * For devices with more than one control interface, we assume the\n\t * first contains the audio controls. We might need a more specific\n\t * check here in the future.\n\t */\n\tif (!chip->ctrl_intf)\n\t\tchip->ctrl_intf = alts;\n\n\tchip->txfr_quirk = 0;\n\terr = 1; /* continue */\n\tif (quirk && quirk->ifnum != QUIRK_NO_INTERFACE) {\n\t\t/* need some special handlings */\n\t\terr = snd_usb_create_quirk(chip, intf, &usb_audio_driver, quirk);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\tif (err > 0) {\n\t\t/* create normal USB audio interfaces */\n\t\terr = snd_usb_create_streams(chip, ifnum);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t\terr = snd_usb_create_mixer(chip, ifnum, ignore_ctl_error);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\t/* we are allowed to call snd_card_register() many times */\n\terr = snd_card_register(chip->card);\n\tif (err < 0)\n\t\tgoto __error;\n\n\tusb_chip[chip->index] = chip;\n\tchip->num_interfaces++;\n\tusb_set_intfdata(intf, chip);\n\tatomic_dec(&chip->active);\n\tmutex_unlock(&register_mutex);\n\treturn 0;\n\n __error:\n\tif (chip) {\n\t\tif (!chip->num_interfaces)\n\t\t\tsnd_card_free(chip->card);\n\t\tatomic_dec(&chip->active);\n\t}\n\tmutex_unlock(&register_mutex);\n\treturn err;\n}", "func_src_after": "static int usb_audio_probe(struct usb_interface *intf,\n\t\t\t   const struct usb_device_id *usb_id)\n{\n\tstruct usb_device *dev = interface_to_usbdev(intf);\n\tconst struct snd_usb_audio_quirk *quirk =\n\t\t(const struct snd_usb_audio_quirk *)usb_id->driver_info;\n\tstruct snd_usb_audio *chip;\n\tint i, err;\n\tstruct usb_host_interface *alts;\n\tint ifnum;\n\tu32 id;\n\n\talts = &intf->altsetting[0];\n\tifnum = get_iface_desc(alts)->bInterfaceNumber;\n\tid = USB_ID(le16_to_cpu(dev->descriptor.idVendor),\n\t\t    le16_to_cpu(dev->descriptor.idProduct));\n\tif (get_alias_id(dev, &id))\n\t\tquirk = get_alias_quirk(dev, id);\n\tif (quirk && quirk->ifnum >= 0 && ifnum != quirk->ifnum)\n\t\treturn -ENXIO;\n\n\terr = snd_usb_apply_boot_quirk(dev, intf, quirk, id);\n\tif (err < 0)\n\t\treturn err;\n\n\t/*\n\t * found a config.  now register to ALSA\n\t */\n\n\t/* check whether it's already registered */\n\tchip = NULL;\n\tmutex_lock(&register_mutex);\n\tfor (i = 0; i < SNDRV_CARDS; i++) {\n\t\tif (usb_chip[i] && usb_chip[i]->dev == dev) {\n\t\t\tif (atomic_read(&usb_chip[i]->shutdown)) {\n\t\t\t\tdev_err(&dev->dev, \"USB device is in the shutdown state, cannot create a card instance\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto __error;\n\t\t\t}\n\t\t\tchip = usb_chip[i];\n\t\t\tatomic_inc(&chip->active); /* avoid autopm */\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (! chip) {\n\t\t/* it's a fresh one.\n\t\t * now look for an empty slot and create a new card instance\n\t\t */\n\t\tfor (i = 0; i < SNDRV_CARDS; i++)\n\t\t\tif (!usb_chip[i] &&\n\t\t\t    (vid[i] == -1 || vid[i] == USB_ID_VENDOR(id)) &&\n\t\t\t    (pid[i] == -1 || pid[i] == USB_ID_PRODUCT(id))) {\n\t\t\t\tif (enable[i]) {\n\t\t\t\t\terr = snd_usb_audio_create(intf, dev, i, quirk,\n\t\t\t\t\t\t\t\t   id, &chip);\n\t\t\t\t\tif (err < 0)\n\t\t\t\t\t\tgoto __error;\n\t\t\t\t\tchip->pm_intf = intf;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (vid[i] != -1 || pid[i] != -1) {\n\t\t\t\t\tdev_info(&dev->dev,\n\t\t\t\t\t\t \"device (%04x:%04x) is disabled\\n\",\n\t\t\t\t\t\t USB_ID_VENDOR(id),\n\t\t\t\t\t\t USB_ID_PRODUCT(id));\n\t\t\t\t\terr = -ENOENT;\n\t\t\t\t\tgoto __error;\n\t\t\t\t}\n\t\t\t}\n\t\tif (!chip) {\n\t\t\tdev_err(&dev->dev, \"no available usb audio device\\n\");\n\t\t\terr = -ENODEV;\n\t\t\tgoto __error;\n\t\t}\n\t}\n\tdev_set_drvdata(&dev->dev, chip);\n\n\t/*\n\t * For devices with more than one control interface, we assume the\n\t * first contains the audio controls. We might need a more specific\n\t * check here in the future.\n\t */\n\tif (!chip->ctrl_intf)\n\t\tchip->ctrl_intf = alts;\n\n\tchip->txfr_quirk = 0;\n\terr = 1; /* continue */\n\tif (quirk && quirk->ifnum != QUIRK_NO_INTERFACE) {\n\t\t/* need some special handlings */\n\t\terr = snd_usb_create_quirk(chip, intf, &usb_audio_driver, quirk);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\tif (err > 0) {\n\t\t/* create normal USB audio interfaces */\n\t\terr = snd_usb_create_streams(chip, ifnum);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t\terr = snd_usb_create_mixer(chip, ifnum, ignore_ctl_error);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\t/* we are allowed to call snd_card_register() many times */\n\terr = snd_card_register(chip->card);\n\tif (err < 0)\n\t\tgoto __error;\n\n\tusb_chip[chip->index] = chip;\n\tchip->num_interfaces++;\n\tusb_set_intfdata(intf, chip);\n\tatomic_dec(&chip->active);\n\tmutex_unlock(&register_mutex);\n\treturn 0;\n\n __error:\n\tif (chip) {\n\t\t/* chip->active is inside the chip->card object,\n\t\t * decrement before memory is possibly returned.\n\t\t */\n\t\tatomic_dec(&chip->active);\n\t\tif (!chip->num_interfaces)\n\t\t\tsnd_card_free(chip->card);\n\t}\n\tmutex_unlock(&register_mutex);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/5f8cf712582617d523120df67d392059eaf2fc4b", "file_name": "sound/usb/card.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_audio_probe` for probing USB audio devices and registering them with the ALSA sound system."}
{"func_name": "big_key_init", "func_src_before": "static int __init big_key_init(void)\n{\n\treturn register_key_type(&key_type_big_key);\n}", "func_src_after": "static int __init big_key_init(void)\n{\n\tstruct crypto_skcipher *cipher;\n\tstruct crypto_rng *rng;\n\tint ret;\n\n\trng = crypto_alloc_rng(big_key_rng_name, 0, 0);\n\tif (IS_ERR(rng)) {\n\t\tpr_err(\"Can't alloc rng: %ld\\n\", PTR_ERR(rng));\n\t\treturn PTR_ERR(rng);\n\t}\n\n\tbig_key_rng = rng;\n\n\t/* seed RNG */\n\tret = crypto_rng_reset(rng, NULL, crypto_rng_seedsize(rng));\n\tif (ret) {\n\t\tpr_err(\"Can't reset rng: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\t/* init block cipher */\n\tcipher = crypto_alloc_skcipher(big_key_alg_name, 0, CRYPTO_ALG_ASYNC);\n\tif (IS_ERR(cipher)) {\n\t\tret = PTR_ERR(cipher);\n\t\tpr_err(\"Can't alloc crypto: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\tbig_key_skcipher = cipher;\n\n\tret = register_key_type(&key_type_big_key);\n\tif (ret < 0) {\n\t\tpr_err(\"Can't register type: %d\\n\", ret);\n\t\tgoto error_cipher;\n\t}\n\n\treturn 0;\n\nerror_cipher:\n\tcrypto_free_skcipher(big_key_skcipher);\nerror_rng:\n\tcrypto_free_rng(big_key_rng);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7df3e59c3d1df4f87fe874c7956ef7a3d2f4d5fb", "file_name": "security/keys/big_key.c", "vul_type": "cwe-476", "description": "Write a C function for Linux kernel module initialization that registers a new key type and optionally sets up cryptographic components."}
{"func_name": "ndpi_search_oracle", "func_src_before": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "func_src_after": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload_packet_len >= 3 && packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "commit_link": "github.com/ntop/nDPI/commit/b69177be2fbe01c2442239a61832c44e40136c05", "file_name": "src/lib/protocols/oracle.c", "vul_type": "cwe-125", "description": "In C, write a function to detect Oracle database traffic by examining TCP packets and their payload."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = markdown(self.object.content,\n                                 extensions=[\n                                     'markdown.extensions.extra',\n                                     'markdown.extensions.codehilite',\n                                     'markdown.extensions.toc',\n                                 ])\n\n        return context", "func_src_after": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = safe_md(self.object.content)\n\n        return context", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function to enhance the context data with comments, a form, and processed markdown content for a web page."}
{"func_name": "archive_directory", "func_src_before": "def archive_directory(top_dir, subdir, tmpdir):\n    \"\"\"\n    .. function:: archive_directory(top_dir, subdir, tmpdir)\n\n    Given a sub-directory name under the root directory to be archived, archive the contents of the sub-directory\n    to a temporary directory. Then return the full path to the temporary directory.\n    :param top_dir: The root path that will be archived and uploaded to Glacier.\n    :param subdir: The path to the subdirectory that is being archived here, relative to `top_dir`\n    :param tmpdir: The path to the temporary directory to store archives in until they are uploaded to Glacier\n    :return: If the subdirectory contains files, then the full path to the temporary archives; otherwise, None\n    \"\"\"\n    # We're only archiving the *files* in this directory, not the subdirectories.\n\n    files = []\n    full_backup_path = os.path.join(top_dir, subdir)\n    dir_contents = os.listdir(full_backup_path)\n\n    # Only add files to 'files' list, not subdirs\n    for c in dir_contents:\n        fpath = os.path.join(top_dir, subdir, c)\n        if os.path.isfile(fpath) and not fpath.endswith(\".ini\"):\n            # logger.info(\"Adding to archive list: {0}\".format(c))\n            files.append(fpath)\n\n    if not files:\n        # No point creating empty archives!\n        return None\n\n    os.makedirs(os.path.join(tmpdir, subdir))\n    archive_file_path = os.path.join(tmpdir, subdir) + \".zip\"\n\n    logger.info(\"Archiving %s to %s\" % (subdir, archive_file_path))\n\n    # with open(os.devnull, \"w\") as devnull:\n\n    devnull = open(os.devnull, \"wb\")\n    file_list = []\n    for p in os.listdir(full_backup_path):\n        if os.path.isfile(os.path.join(full_backup_path, p)):\n            file_list.append(os.path.join(full_backup_path, p))\n\n    try:\n        with zipfile.ZipFile(archive_file_path, \"w\", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as arch_zip:\n            for f in file_list:\n                logger.debug(\"Adding {0} to archive {1}\".format(f, archive_file_path))\n                arch_zip.write(f, os.path.basename(f))\n                return archive_file_path\n\n    except Exception, e:\n        logging.error(\"Failed to create archive {0}: {1}\".format(archive_file_path, e.message))\n        logging.debug(\"Error args: {0}\".format(e.args))\n        return None", "func_src_after": "def archive_directory(top_dir, subdir, tmpdir):\n    \"\"\"\n    .. function:: archive_directory(top_dir, subdir, tmpdir)\n\n    Given a sub-directory name under the root directory to be archived, archive the contents of the sub-directory\n    to a temporary directory. Then return the full path to the temporary directory.\n    :param top_dir: The root path that will be archived and uploaded to Glacier.\n    :param subdir: The path to the subdirectory that is being archived here, relative to `top_dir`\n    :param tmpdir: The path to the temporary directory to store archives in until they are uploaded to Glacier\n    :return: If the subdirectory contains files, then the full path to the temporary archives; otherwise, None\n    \"\"\"\n    # We're only archiving the *files* in this directory, not the subdirectories.\n\n    files = []\n    full_backup_path = os.path.join(top_dir, subdir)\n    dir_contents = os.listdir(full_backup_path)\n\n    # Only add files to 'files' list, not subdirs\n    for c in dir_contents:\n        fpath = os.path.join(full_backup_path, c)\n        if os.path.isfile(fpath) and not fpath.endswith(\".ini\"):\n            # logger.info(\"Adding to archive list: {0}\".format(c))\n            files.append(fpath)\n\n    if not files:\n        # No point creating empty archives!\n        return None\n\n    os.makedirs(os.path.join(tmpdir, subdir))\n    archive_file_path = os.path.join(tmpdir, subdir) + \".zip\"\n\n    logger.info(\"Archiving %s to %s\" % (subdir, archive_file_path))\n\n    # with open(os.devnull, \"w\") as devnull:\n\n    devnull = open(os.devnull, \"wb\")\n\n    try:\n        with zipfile.ZipFile(archive_file_path, \"w\", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as arch_zip:\n            for f in files:\n                logger.debug(\"Adding {0} to archive {1}\".format(f, archive_file_path))\n                arch_zip.write(f, os.path.basename(f))\n            return archive_file_path\n\n    except Exception, e:\n        logging.error(\"Failed to create archive {0}: {1}\".format(archive_file_path, e.message))\n        logging.debug(\"Error args: {0}\".format(e.args))\n        return None", "line_changes": {"deleted": [{"line_no": 20, "char_start": 1003, "char_end": 1052, "line": "        fpath = os.path.join(top_dir, subdir, c)\n"}, {"line_no": 37, "char_start": 1561, "char_end": 1580, "line": "    file_list = []\n"}, {"line_no": 38, "char_start": 1580, "char_end": 1623, "line": "    for p in os.listdir(full_backup_path):\n"}, {"line_no": 39, "char_start": 1623, "char_end": 1685, "line": "        if os.path.isfile(os.path.join(full_backup_path, p)):\n"}, {"line_no": 40, "char_start": 1685, "char_end": 1749, "line": "            file_list.append(os.path.join(full_backup_path, p))\n"}, {"line_no": 44, "char_start": 1876, "char_end": 1908, "line": "            for f in file_list:\n"}, {"line_no": 47, "char_start": 2050, "char_end": 2091, "line": "                return archive_file_path\n"}], "added": [{"line_no": 20, "char_start": 1003, "char_end": 1053, "line": "        fpath = os.path.join(full_backup_path, c)\n"}, {"line_no": 40, "char_start": 1689, "char_end": 1717, "line": "            for f in files:\n"}, {"line_no": 43, "char_start": 1859, "char_end": 1896, "line": "            return archive_file_path\n"}]}, "char_changes": {"deleted": [{"char_start": 1032, "char_end": 1047, "chars": "top_dir, subdir"}, {"char_start": 1560, "char_end": 1748, "chars": "\n    file_list = []\n    for p in os.listdir(full_backup_path):\n        if os.path.isfile(os.path.join(full_backup_path, p)):\n            file_list.append(os.path.join(full_backup_path, p))"}, {"char_start": 1901, "char_end": 1906, "chars": "_list"}, {"char_start": 2050, "char_end": 2054, "chars": "    "}], "added": [{"char_start": 1032, "char_end": 1048, "chars": "full_backup_path"}, {"char_start": 1714, "char_end": 1715, "chars": "s"}]}, "commit_link": "github.com/calmcl1/cupo-backup/commit/f9047a52ab33a14fcd67d3d8b9f9d321502ae457", "file_name": "cupo.py", "vul_type": "cwe-022", "commit_msg": "Removed redundant directory traversal", "parent_commit": "49107dd052b985e1fc469aec359f37df23ec3e29", "description": "Write a Python function to zip files in a specified subdirectory, excluding '.ini' files, and save the archive to a temporary directory."}
{"func_name": "Html5ReportGenerator::unzipApp", "func_src_before": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "func_src_after": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "line_changes": {"deleted": [], "added": [{"line_no": 12, "char_start": 549, "char_end": 633, "line": "            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n"}, {"line_no": 13, "char_start": 633, "char_end": 694, "line": "                throw new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 14, "char_start": 694, "char_end": 708, "line": "            }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 548, "char_end": 707, "chars": "\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }"}]}, "commit_link": "github.com/TNG/JGiven/commit/e701fe690501e7301f7c923adc1881d308806c46", "file_name": "Html5ReportGenerator.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to unzip a file named 'app.zip' from the resources of the `Html5ReportGenerator` class into a specified directory."}
{"func_name": "manipulate_reservation_action", "func_src_before": "def manipulate_reservation_action(request: HttpRequest, default_foreward_url: str):\n    \"\"\"\n    This function is used to alter the reservation beeing build inside\n    a cookie. This function automatically crafts the required response.\n    \"\"\"\n    js_string: str = \"\"\n    r: GroupReservation = None\n    u: Profile = get_current_user(request)\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if \"srid\" in request.GET:\n        if not request.GET.get(\"rid\"):\n            return HttpResponseRedirect(\"/admin?error=missing%20primary%20reservation%20id\")\n        srid: int = int(request.GET[\"srid\"])\n        sr: SubReservation = None\n        if srid == 0:\n            sr = SubReservation()\n        else:\n            sr = SubReservation.objects.get(id=srid)\n        if request.POST.get(\"notes\"):\n            sr.notes = request.POST[\"notes\"]\n        else:\n            sr.notes = \" \"\n        sr.primary_reservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n        sr.save()\n        print(request.POST)\n        print(sr.notes)\n        return HttpResponseRedirect(\"/admin/reservations/edit?rid=\" + str(int(request.GET[\"rid\"])) + \"&srid=\" + str(sr.id))\n    if \"rid\" in request.GET:\n        # update reservation\n        r = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n    elif u.number_of_allowed_reservations > GroupReservation.objects.all().filter(createdByUser=u).count():\n        r = GroupReservation()\n        r.createdByUser = u\n        r.ready = False\n        r.open = True\n        r.pickupDate = datetime.datetime.now()\n    else:\n        return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\")\n    if request.POST.get(\"notes\"):\n        r.notes = request.POST[\"notes\"]\n    if request.POST.get(\"contact\"):\n        r.responsiblePerson = str(request.POST[\"contact\"])\n    if (r.createdByUser == u or o.rights > 1) and not r.submitted:\n        r.save()\n    else:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    response: HttpResponseRedirect = HttpResponseRedirect(forward_url + \"?rid=\" + str(r.id))\n    return response", "func_src_after": "def manipulate_reservation_action(request: HttpRequest, default_foreward_url: str):\n    \"\"\"\n    This function is used to alter the reservation beeing build inside\n    a cookie. This function automatically crafts the required response.\n    \"\"\"\n    js_string: str = \"\"\n    r: GroupReservation = None\n    u: Profile = get_current_user(request)\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if \"srid\" in request.GET:\n        if not request.GET.get(\"rid\"):\n            return HttpResponseRedirect(\"/admin?error=missing%20primary%20reservation%20id\")\n        srid: int = int(request.GET[\"srid\"])\n        sr: SubReservation = None\n        if srid == 0:\n            sr = SubReservation()\n        else:\n            sr = SubReservation.objects.get(id=srid)\n        if request.POST.get(\"notes\"):\n            sr.notes = escape(request.POST[\"notes\"])\n        else:\n            sr.notes = \" \"\n        sr.primary_reservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n        sr.save()\n        print(request.POST)\n        print(sr.notes)\n        return HttpResponseRedirect(\"/admin/reservations/edit?rid=\" + str(int(request.GET[\"rid\"])) + \"&srid=\" + str(sr.id))\n    if \"rid\" in request.GET:\n        # update reservation\n        r = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n    elif u.number_of_allowed_reservations > GroupReservation.objects.all().filter(createdByUser=u).count():\n        r = GroupReservation()\n        r.createdByUser = u\n        r.ready = False\n        r.open = True\n        r.pickupDate = datetime.datetime.now()\n    else:\n        return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\")\n    if request.POST.get(\"notes\"):\n        r.notes = escape(request.POST[\"notes\"])\n    if request.POST.get(\"contact\"):\n        r.responsiblePerson = escape(str(request.POST[\"contact\"]))\n    if (r.createdByUser == u or o.rights > 1) and not r.submitted:\n        r.save()\n    else:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    response: HttpResponseRedirect = HttpResponseRedirect(forward_url + \"?rid=\" + str(r.id))\n    return response", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/reservation_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle reservation modifications and redirection based on user input from a web request."}
{"func_name": "decode_pointer_field", "func_src_before": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                (*size)++;\n                if (!allocate_field(stream, field->pField, field->data_size, *size))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size - 1);\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "func_src_after": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                if (!allocate_field(stream, field->pField, field->data_size, (size_t)(*size + 1)))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size);\n                (*size)++;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "commit_link": "github.com/nanopb/nanopb/commit/45582f1f97f49e2abfdba1463d1e1027682d9856", "file_name": "pb_decode.c", "vul_type": "cwe-125", "description": "Write a C function named `decode_pointer_field` that decodes a field from a protocol buffer stream, handling different field types and memory allocation."}
{"func_name": "PHP_MINIT_FUNCTION", "func_src_before": "PHP_MINIT_FUNCTION(spl_array)\n{\n\tREGISTER_SPL_STD_CLASS_EX(ArrayObject, spl_array_object_new, spl_funcs_ArrayObject);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Aggregate);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, ArrayAccess);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Serializable);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Countable);\n\tmemcpy(&spl_handler_ArrayObject, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\n\tspl_handler_ArrayObject.clone_obj = spl_array_object_clone;\n\tspl_handler_ArrayObject.read_dimension = spl_array_read_dimension;\n\tspl_handler_ArrayObject.write_dimension = spl_array_write_dimension;\n\tspl_handler_ArrayObject.unset_dimension = spl_array_unset_dimension;\n\tspl_handler_ArrayObject.has_dimension = spl_array_has_dimension;\n\tspl_handler_ArrayObject.count_elements = spl_array_object_count_elements;\n\n\tspl_handler_ArrayObject.get_properties = spl_array_get_properties;\n\tspl_handler_ArrayObject.get_debug_info = spl_array_get_debug_info;\n\tspl_handler_ArrayObject.get_gc = spl_array_get_gc;\n\tspl_handler_ArrayObject.read_property = spl_array_read_property;\n\tspl_handler_ArrayObject.write_property = spl_array_write_property;\n\tspl_handler_ArrayObject.get_property_ptr_ptr = spl_array_get_property_ptr_ptr;\n\tspl_handler_ArrayObject.has_property = spl_array_has_property;\n\tspl_handler_ArrayObject.unset_property = spl_array_unset_property;\n\n\tspl_handler_ArrayObject.compare_objects = spl_array_compare_objects;\n\n\tREGISTER_SPL_STD_CLASS_EX(ArrayIterator, spl_array_object_new, spl_funcs_ArrayIterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Iterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, ArrayAccess);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, SeekableIterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Serializable);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Countable);\n\tmemcpy(&spl_handler_ArrayIterator, &spl_handler_ArrayObject, sizeof(zend_object_handlers));\n\tspl_ce_ArrayIterator->get_iterator = spl_array_get_iterator;\n\n\tREGISTER_SPL_SUB_CLASS_EX(RecursiveArrayIterator, ArrayIterator, spl_array_object_new, spl_funcs_RecursiveArrayIterator);\n\tREGISTER_SPL_IMPLEMENTS(RecursiveArrayIterator, RecursiveIterator);\n\tspl_ce_RecursiveArrayIterator->get_iterator = spl_array_get_iterator;\n\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayObject,   \"STD_PROP_LIST\",    SPL_ARRAY_STD_PROP_LIST);\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayObject,   \"ARRAY_AS_PROPS\",   SPL_ARRAY_ARRAY_AS_PROPS);\n\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayIterator, \"STD_PROP_LIST\",    SPL_ARRAY_STD_PROP_LIST);\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayIterator, \"ARRAY_AS_PROPS\",   SPL_ARRAY_ARRAY_AS_PROPS);\n\n\tREGISTER_SPL_CLASS_CONST_LONG(RecursiveArrayIterator, \"CHILD_ARRAYS_ONLY\", SPL_ARRAY_CHILD_ARRAYS_ONLY);\n\n\treturn SUCCESS;\n}", "func_src_after": "PHP_MINIT_FUNCTION(spl_array)\n{\n\tREGISTER_SPL_STD_CLASS_EX(ArrayObject, spl_array_object_new, spl_funcs_ArrayObject);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Aggregate);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, ArrayAccess);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Serializable);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Countable);\n\tmemcpy(&spl_handler_ArrayObject, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\n\tspl_handler_ArrayObject.clone_obj = spl_array_object_clone;\n\tspl_handler_ArrayObject.read_dimension = spl_array_read_dimension;\n\tspl_handler_ArrayObject.write_dimension = spl_array_write_dimension;\n\tspl_handler_ArrayObject.unset_dimension = spl_array_unset_dimension;\n\tspl_handler_ArrayObject.has_dimension = spl_array_has_dimension;\n\tspl_handler_ArrayObject.count_elements = spl_array_object_count_elements;\n\n\tspl_handler_ArrayObject.get_properties = spl_array_get_properties;\n\tspl_handler_ArrayObject.get_debug_info = spl_array_get_debug_info;\n\tspl_handler_ArrayObject.get_gc = spl_array_get_gc;\n\tspl_handler_ArrayObject.read_property = spl_array_read_property;\n\tspl_handler_ArrayObject.write_property = spl_array_write_property;\n\tspl_handler_ArrayObject.get_property_ptr_ptr = spl_array_get_property_ptr_ptr;\n\tspl_handler_ArrayObject.has_property = spl_array_has_property;\n\tspl_handler_ArrayObject.unset_property = spl_array_unset_property;\n\n\tspl_handler_ArrayObject.compare_objects = spl_array_compare_objects;\n\n\tREGISTER_SPL_STD_CLASS_EX(ArrayIterator, spl_array_object_new, spl_funcs_ArrayIterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Iterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, ArrayAccess);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, SeekableIterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Serializable);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Countable);\n\tmemcpy(&spl_handler_ArrayIterator, &spl_handler_ArrayObject, sizeof(zend_object_handlers));\n\tspl_ce_ArrayIterator->get_iterator = spl_array_get_iterator;\n\n\tREGISTER_SPL_SUB_CLASS_EX(RecursiveArrayIterator, ArrayIterator, spl_array_object_new, spl_funcs_RecursiveArrayIterator);\n\tREGISTER_SPL_IMPLEMENTS(RecursiveArrayIterator, RecursiveIterator);\n\tspl_ce_RecursiveArrayIterator->get_iterator = spl_array_get_iterator;\n\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayObject,   \"STD_PROP_LIST\",    SPL_ARRAY_STD_PROP_LIST);\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayObject,   \"ARRAY_AS_PROPS\",   SPL_ARRAY_ARRAY_AS_PROPS);\n\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayIterator, \"STD_PROP_LIST\",    SPL_ARRAY_STD_PROP_LIST);\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayIterator, \"ARRAY_AS_PROPS\",   SPL_ARRAY_ARRAY_AS_PROPS);\n\n\tREGISTER_SPL_CLASS_CONST_LONG(RecursiveArrayIterator, \"CHILD_ARRAYS_ONLY\", SPL_ARRAY_CHILD_ARRAYS_ONLY);\n\n\treturn SUCCESS;\n}", "commit_link": "github.com/php/php-src/commit/3f627e580acfdaf0595ae3b115b8bec677f203ee?w=1", "file_name": "ext/spl/spl_array.c", "vul_type": "cwe-416", "description": "Write a PHP initialization function to set up SPL array classes with their respective handlers and interfaces."}
{"func_name": "copy_over", "func_src_before": "def copy_over(source, dest):\n    \"\"\"\n    Copies from the source to the destination, removing the destination\n    if it exists and is a directory.\n    \"\"\"\n    if os.path.exists(dest) and os.path.isdir(dest):\n        shutil.rmtree(dest)\n    shutil.copytree(source, dest)\n    # mkdtemp will set the directory permissions to 700\n    # for the webserver to read them, we need 755\n    os.chmod(dest, stat.S_IRWXU | stat.S_IRGRP |\n             stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n    shutil.rmtree(source)", "func_src_after": "def copy_over(source, dest):\n    \"\"\"\n    Copies from the source to the destination, removing the destination\n    if it exists and is a directory.\n    \"\"\"\n    if os.path.exists(dest) and os.path.isdir(dest):\n        shutil.rmtree(dest)\n    shutil.copytree(force_bytes(source), force_bytes(dest))\n    # mkdtemp will set the directory permissions to 700\n    # for the webserver to read them, we need 755\n    os.chmod(dest, stat.S_IRWXU | stat.S_IRGRP |\n             stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n    shutil.rmtree(source)", "line_changes": {"deleted": [{"line_no": 8, "char_start": 235, "char_end": 269, "line": "    shutil.copytree(source, dest)\n"}], "added": [{"line_no": 8, "char_start": 235, "char_end": 295, "line": "    shutil.copytree(force_bytes(source), force_bytes(dest))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 255, "char_end": 267, "chars": "force_bytes("}, {"char_start": 273, "char_end": 274, "chars": ")"}, {"char_start": 276, "char_end": 288, "chars": "force_bytes("}, {"char_start": 293, "char_end": 294, "chars": ")"}]}, "commit_link": "github.com/mozilla/addons-server/commit/e8731de25ab5319c82efb9efbe0195ba95e5dc1e", "file_name": "utils.py", "vul_type": "cwe-022", "commit_msg": "Fix unicode error on copying over extracted files from zip. (#3874)\n\nFix unicode error on copying over extracted files from zip.\r\n\r\nRefs #3579\r\n\r\nThe problem here is that under very hard unit-testable/reproducable\r\ncircumstances a zip-file with unicode filenames get's extracted to a\r\ntemporary directory and while calling `copy_over` which calls\r\n`shutil.copytree` which fails on our production systems with a\r\nUnicodeDecodeError.\r\n\r\nReproducing this is something along the lines of\r\n\r\n>>> shutil.copytree(u'/tmp/tmp8WG6A8/', u'/tmp/tmp8WG6A8-2/')\r\n# doesn't error...\r\n>>> shutil.copytree('/tmp/tmp8WG6A8/', u'/tmp/tmp8WG6A8-2/')\r\nUnicodeDecodeError: 'ascii' codec can't decode \tbyte 0xd0 in ...\r\n\r\nChecking all relevant environment configs in our production systems, all\r\nLANG, LC_ALL and related configs are perfectly fine. It's not related to\r\nuwsgi, it's not related to EFS so it's something else I have absolutely\r\nno idea about :-/", "parent_commit": "18d3e83979a8c9616f6d1173f82f422da6f2e1c2", "description": "Write a Python function to replace a destination directory with a source directory, adjusting permissions for webserver access."}
{"func_name": "get_login2", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a function that handles a login message for a bot, checks the username, interacts with a SQLite database, and updates the user's state."}
{"func_name": "self.find_taxon", "func_src_before": "  def self.find_taxon(id)\n    self.find_by_sql(\"select string as taxon_concept,\n                            (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id) as siblings_count,\n                            h1.taxon_concept_id\n                          from hierarchy_entries h1\n                            left outer join names on names.id=name_id\n                          where published=1 and h1.id=#{id};\").first\n  end", "func_src_after": "  def self.find_taxon(id)\n    return {} unless id.to_i.is_a? Integer\n    self.find_by_sql(\"select string as taxon_concept,\n                            (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n                              as siblings_count,\n                            h1.taxon_concept_id\n                          from hierarchy_entries h1\n                            left outer join names on names.id=name_id\n                          where published=1 and h1.id=#{id.to_i};\").first\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 80, "char_end": 199, "line": "                            (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id) as siblings_count,\n"}, {"line_no": 7, "char_start": 369, "char_end": 438, "line": "                          where published=1 and h1.id=#{id};\").first\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 69, "line": "    return {} unless id.to_i.is_a? Integer\n"}, {"line_no": 4, "char_start": 123, "char_end": 223, "line": "                            (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n"}, {"line_no": 5, "char_start": 223, "char_end": 272, "line": "                              as siblings_count,\n"}, {"line_no": 9, "char_start": 442, "char_end": 516, "line": "                          where published=1 and h1.id=#{id.to_i};\").first\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 26, "char_end": 69, "chars": "    return {} unless id.to_i.is_a? Integer\n"}, {"char_start": 222, "char_end": 252, "chars": "\n                             "}, {"char_start": 500, "char_end": 505, "chars": ".to_i"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Create a Ruby method that retrieves taxonomic information and sibling count for a given ID from a database."}
{"func_name": "_update_volume_stats", "func_src_before": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = 'svcinfo lssystem -delim !'\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = 'svcinfo lsmdiskgrp -bytes -delim ! %s' % pool\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "func_src_after": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = ['svcinfo', 'lssystem', '-delim', '!']\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-bytes', '-delim', '!', pool]\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to update storage volume statistics with IBM vendor details and capacity information."}
{"func_name": "_inject_net_into_fs", "func_src_before": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = os.path.join(os.path.join(fs, 'etc'), 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n    netfile = os.path.join(netdir, 'interfaces')\n    utils.execute('tee', netfile, process_input=net, run_as_root=True)", "func_src_after": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = _join_and_check_path_within_fs(fs, 'etc', 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n\n    netfile = os.path.join('etc', 'network', 'interfaces')\n    _inject_file_into_fs(fs, netfile, net)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to create necessary directories and set permissions to inject network configuration into a specified filesystem."}
{"func_name": "output", "func_src_before": "    def output\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "func_src_after": "    def output\n      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{intercom_settings_json};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 86, "char_end": 164, "line": "  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n"}], "added": [{"line_no": 2, "char_start": 15, "char_end": 112, "line": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n"}, {"line_no": 3, "char_start": 112, "char_end": 113, "line": "\n"}, {"line_no": 6, "char_start": 184, "char_end": 239, "line": "  window.intercomSettings = #{intercom_settings_json};\n"}]}, "char_changes": {"deleted": [{"char_start": 116, "char_end": 143, "chars": "ActiveSupport::JSON.encode("}, {"char_start": 160, "char_end": 161, "chars": ")"}], "added": [{"char_start": 15, "char_end": 113, "chars": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n"}, {"char_start": 231, "char_end": 236, "chars": "_json"}]}, "commit_link": "github.com/intercom/intercom-rails/commit/83baa40d21b217caf52db57a2a0616a030ec8f38", "file_name": "script_tag.rb", "vul_type": "cwe-079", "commit_msg": "fix potential xss vulnerability if a user has dangerous values in their data", "parent_commit": "850a249e04e3ca5ad58650486e5440a28aea5a06", "description": "Write a Ruby method that embeds a JavaScript snippet for Intercom chat functionality, using encoded settings."}
{"func_name": "decode_studio_vop_header", "func_src_before": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "func_src_after": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->interlaced_dct = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/1f686d023b95219db933394a7704ad9aa5f01cbb", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to decode the header of a studio video object plane (VOP) for an MPEG4 decoder context."}
{"func_name": "formUpdateBuffer", "func_src_before": "formUpdateBuffer(Anchor *a, Buffer *buf, FormItemList *form)\n{\n    Buffer save;\n    char *p;\n    int spos, epos, rows, c_rows, pos, col = 0;\n    Line *l;\n\n    copyBuffer(&save, buf);\n    gotoLine(buf, a->start.line);\n    switch (form->type) {\n    case FORM_TEXTAREA:\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n#endif\t\t\t\t/* MENU_SELECT */\n\tspos = a->start.pos;\n\tepos = a->end.pos;\n\tbreak;\n    default:\n\tspos = a->start.pos + 1;\n\tepos = a->end.pos - 1;\n    }\n    switch (form->type) {\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n\tif (buf->currentLine == NULL ||\n\t    spos >= buf->currentLine->len || spos < 0)\n\t    break;\n\tif (form->checked)\n\t    buf->currentLine->lineBuf[spos] = '*';\n\telse\n\t    buf->currentLine->lineBuf[spos] = ' ';\n\tbreak;\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_TEXTAREA:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n\tif (form->type == FORM_SELECT) {\n\t    p = form->label->ptr;\n\t    updateSelectOption(form, form->select_option);\n\t}\n\telse\n#endif\t\t\t\t/* MENU_SELECT */\n\t{\n\t    if (!form->value)\n\t\tbreak;\n\t    p = form->value->ptr;\n\t}\n\tl = buf->currentLine;\n\tif (!l)\n\t    break;\n\tif (form->type == FORM_TEXTAREA) {\n\t    int n = a->y - buf->currentLine->linenumber;\n\t    if (n > 0)\n\t\tfor (; l && n; l = l->prev, n--) ;\n\t    else if (n < 0)\n\t\tfor (; l && n; l = l->prev, n++) ;\n\t    if (!l)\n\t\tbreak;\n\t}\n\trows = form->rows ? form->rows : 1;\n\tcol = COLPOS(l, a->start.pos);\n\tfor (c_rows = 0; c_rows < rows; c_rows++, l = l->next) {\n\t    if (rows > 1) {\n\t\tpos = columnPos(l, col);\n\t\ta = retrieveAnchor(buf->formitem, l->linenumber, pos);\n\t\tif (a == NULL)\n\t\t    break;\n\t\tspos = a->start.pos;\n\t\tepos = a->end.pos;\n\t    }\n\t    if (a->start.line != a->end.line || spos > epos || epos >= l->len ||\n\t\tspos < 0 || epos < 0 || COLPOS(l, epos) < col)\n\t\tbreak;\n\t    pos = form_update_line(l, &p, spos, epos, COLPOS(l, epos) - col,\n\t\t\t\t   rows > 1,\n\t\t\t\t   form->type == FORM_INPUT_PASSWORD);\n\t    if (pos != epos) {\n\t\tshiftAnchorPosition(buf->href, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->name, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->img, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->formitem, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t    }\n\t}\n\tbreak;\n    }\n    copyBuffer(buf, &save);\n    arrangeLine(buf);\n}", "func_src_after": "formUpdateBuffer(Anchor *a, Buffer *buf, FormItemList *form)\n{\n    Buffer save;\n    char *p;\n    int spos, epos, rows, c_rows, pos, col = 0;\n    Line *l;\n\n    copyBuffer(&save, buf);\n    gotoLine(buf, a->start.line);\n    switch (form->type) {\n    case FORM_TEXTAREA:\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n#endif\t\t\t\t/* MENU_SELECT */\n\tspos = a->start.pos;\n\tepos = a->end.pos;\n\tbreak;\n    default:\n\tspos = a->start.pos + 1;\n\tepos = a->end.pos - 1;\n    }\n    switch (form->type) {\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n\tif (buf->currentLine == NULL ||\n\t    spos >= buf->currentLine->len || spos < 0)\n\t    break;\n\tif (form->checked)\n\t    buf->currentLine->lineBuf[spos] = '*';\n\telse\n\t    buf->currentLine->lineBuf[spos] = ' ';\n\tbreak;\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_TEXTAREA:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n\tif (form->type == FORM_SELECT) {\n\t    p = form->label->ptr;\n\t    updateSelectOption(form, form->select_option);\n\t}\n\telse\n#endif\t\t\t\t/* MENU_SELECT */\n\t{\n\t    if (!form->value)\n\t\tbreak;\n\t    p = form->value->ptr;\n\t}\n\tl = buf->currentLine;\n\tif (!l)\n\t    break;\n\tif (form->type == FORM_TEXTAREA) {\n\t    int n = a->y - buf->currentLine->linenumber;\n\t    if (n > 0)\n\t\tfor (; l && n; l = l->prev, n--) ;\n\t    else if (n < 0)\n\t\tfor (; l && n; l = l->prev, n++) ;\n\t    if (!l)\n\t\tbreak;\n\t}\n\trows = form->rows ? form->rows : 1;\n\tcol = COLPOS(l, a->start.pos);\n\tfor (c_rows = 0; c_rows < rows; c_rows++, l = l->next) {\n\t    if (l == NULL)\n\t\tbreak;\n\t    if (rows > 1) {\n\t\tpos = columnPos(l, col);\n\t\ta = retrieveAnchor(buf->formitem, l->linenumber, pos);\n\t\tif (a == NULL)\n\t\t    break;\n\t\tspos = a->start.pos;\n\t\tepos = a->end.pos;\n\t    }\n\t    if (a->start.line != a->end.line || spos > epos || epos >= l->len ||\n\t\tspos < 0 || epos < 0 || COLPOS(l, epos) < col)\n\t\tbreak;\n\t    pos = form_update_line(l, &p, spos, epos, COLPOS(l, epos) - col,\n\t\t\t\t   rows > 1,\n\t\t\t\t   form->type == FORM_INPUT_PASSWORD);\n\t    if (pos != epos) {\n\t\tshiftAnchorPosition(buf->href, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->name, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->img, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->formitem, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t    }\n\t}\n\tbreak;\n    }\n    copyBuffer(buf, &save);\n    arrangeLine(buf);\n}", "commit_link": "github.com/tats/w3m/commit/7fdc83b0364005a0b5ed869230dd81752ba022e8", "file_name": "form.c", "vul_type": "cwe-476", "description": "In C, write a function `formUpdateBuffer` to update the contents of a buffer with form input data based on the position of an anchor."}
{"func_name": "html_content", "func_src_before": "    @property\n    async def html_content(self):\n        content = await self.content\n        if not content:\n            return ''\n        return markdown(content)", "func_src_after": "    @property\n    async def html_content(self):\n        content = markupsafe.escape(await self.content)\n        if not content:\n            return ''\n        return markdown(content)", "commit_link": "github.com/dongweiming/lyanna/commit/fcefac79e4b7601e81a3b3fe0ad26ab18ee95d7d", "file_name": "models/comment.py", "vul_type": "cwe-079", "description": "Generate a Python async property method that converts stored content to HTML, handling empty content and ensuring safe markup."}
{"func_name": "respond_error", "func_src_before": "    def respond_error(self, context, exception):\n        context.respond_server_error()\n        stack = traceback.format_exc()\n        return \"\"\"\n        <html>\n            <body>\n\n                <style>\n                    body {\n                        font-family: sans-serif;\n                        color: #888;\n                        text-align: center;\n                    }\n\n                    body pre {\n                        width: 600px;\n                        text-align: left;\n                        margin: auto;\n                        font-family: monospace;\n                    }\n                </style>\n\n                <img src=\"/ajenti:static/main/error.jpeg\" />\n                <br/>\n                <p>\n                    Server error\n                </p>\n                <pre>\n%s\n                </pre>\n            </body>\n        </html>\n        \"\"\" % stack", "func_src_after": "    def respond_error(self, context, exception):\n        context.respond_server_error()\n        stack = traceback.format_exc()\n        return \"\"\"\n        <html>\n            <body>\n\n                <style>\n                    body {\n                        font-family: sans-serif;\n                        color: #888;\n                        text-align: center;\n                    }\n\n                    body pre {\n                        width: 600px;\n                        text-align: left;\n                        margin: auto;\n                        font-family: monospace;\n                    }\n                </style>\n\n                <img src=\"/ajenti:static/main/error.jpeg\" />\n                <br/>\n                <p>\n                    Server error\n                </p>\n                <pre>\n%s\n                </pre>\n            </body>\n        </html>\n        \"\"\" % cgi.escape(stack)", "commit_link": "github.com/Eugeny/ajenti/commit/d3fc5eb142ff16d55d158afb050af18d5ff09120", "file_name": "ajenti/routing.py", "vul_type": "cwe-079", "description": "Write a Python function that handles a server error by displaying an error page with a stack trace."}
{"func_name": "_get_host_from_connector", "func_src_before": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = 'svcinfo lshost -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "func_src_after": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = ['svcinfo', 'lshost', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve a host name from storage based on connection information, using SSH for commands."}
{"func_name": "view_page_history", "func_src_before": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = '%s'\" % page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "func_src_after": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = $1\", page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to display the history of a webpage using a template, with SQL query parameterization differing between string formatting and using placeholders."}
{"func_name": "add_extra_args", "func_src_before": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "func_src_after": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(args, nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "commit_link": "github.com/freedombenLiu/ParlAI/commit/601668d569e1276e0b8bf2bf8fb43e391e10d170", "file_name": "parlai/core/params.py", "vul_type": "cwe-078", "description": "Write a Python function that extends argument parsing with additional arguments based on existing parsed arguments."}
{"func_name": "_inject_key_into_fs", "func_src_before": "def _inject_key_into_fs(key, fs, execute=None):\n    \"\"\"Add the given public ssh key to root's authorized_keys.\n\n    key is an ssh key string.\n    fs is the path to the base of the filesystem into which to inject the key.\n    \"\"\"\n    sshdir = os.path.join(fs, 'root', '.ssh')\n    utils.execute('mkdir', '-p', sshdir, run_as_root=True)\n    utils.execute('chown', 'root', sshdir, run_as_root=True)\n    utils.execute('chmod', '700', sshdir, run_as_root=True)\n    keyfile = os.path.join(sshdir, 'authorized_keys')\n    key_data = [\n        '\\n',\n        '# The following ssh key was injected by Nova',\n        '\\n',\n        key.strip(),\n        '\\n',\n    ]\n    utils.execute('tee', '-a', keyfile,\n                  process_input=''.join(key_data), run_as_root=True)", "func_src_after": "def _inject_key_into_fs(key, fs, execute=None):\n    \"\"\"Add the given public ssh key to root's authorized_keys.\n\n    key is an ssh key string.\n    fs is the path to the base of the filesystem into which to inject the key.\n    \"\"\"\n    sshdir = _join_and_check_path_within_fs(fs, 'root', '.ssh')\n    utils.execute('mkdir', '-p', sshdir, run_as_root=True)\n    utils.execute('chown', 'root', sshdir, run_as_root=True)\n    utils.execute('chmod', '700', sshdir, run_as_root=True)\n\n    keyfile = os.path.join('root', '.ssh', 'authorized_keys')\n\n    key_data = ''.join([\n        '\\n',\n        '# The following ssh key was injected by Nova',\n        '\\n',\n        key.strip(),\n        '\\n',\n    ])\n\n    _inject_file_into_fs(fs, keyfile, key_data, append=True)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to add an SSH key to the root user's authorized_keys file in a given filesystem."}
{"func_name": "login", "func_src_before": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute('SELECT * FROM users WHERE name = \\'{}\\' AND password = \\'{}\\';'.format(user, password))\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "func_src_after": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute(\"SELECT * FROM users WHERE name = ? AND password = ?;\", [user, password])\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "commit_link": "github.com/ChemiKyle/Waterspots/commit/3f9d5099496336f3f34c48abf0cf55acaaa29011", "file_name": "app.py", "vul_type": "cwe-089", "description": "Create a Python Flask login function that checks user credentials against a database and either redirects to a test point or flashes an error message."}
{"func_name": "index", "func_src_before": "def index(request, is_mobile=False):\n  hue_collections = DashboardController(request.user).get_search_collections()\n  collection_id = request.GET.get('collection')\n\n  if not hue_collections or not collection_id:\n    return admin_collections(request, True, is_mobile)\n\n  try:\n    collection_doc = Document2.objects.get(id=collection_id)\n    if USE_NEW_EDITOR.get():\n      collection_doc.can_read_or_exception(request.user)\n    else:\n      collection_doc.doc.get().can_read_or_exception(request.user)\n    collection = Collection2(request.user, document=collection_doc)\n  except Exception, e:\n    raise PopupException(e, title=_(\"Dashboard does not exist or you don't have the permission to access it.\"))\n\n  query = {'qs': [{'q': ''}], 'fqs': [], 'start': 0}\n\n  if request.method == 'GET':\n    if 'q' in request.GET:\n      query['qs'][0]['q'] = request.GET.get('q')\n    if 'qd' in request.GET:\n      query['qd'] = request.GET.get('qd')\n\n  template = 'search.mako'\n  if is_mobile:\n    template = 'search_m.mako'\n\n  return render(template, request, {\n    'collection': collection,\n    'query': json.dumps(query),\n    'initial': json.dumps({\n        'collections': [],\n        'layout': DEFAULT_LAYOUT,\n        'is_latest': LATEST.get(),\n        'engines': get_engines(request.user)\n    }),\n    'is_owner': collection_doc.doc.get().can_write(request.user),\n    'can_edit_index': can_edit_index(request.user),\n    'is_embeddable': request.GET.get('is_embeddable', False),\n    'mobile': is_mobile,\n  })", "func_src_after": "def index(request, is_mobile=False):\n  hue_collections = DashboardController(request.user).get_search_collections()\n  collection_id = request.GET.get('collection')\n\n  if not hue_collections or not collection_id:\n    return admin_collections(request, True, is_mobile)\n\n  try:\n    collection_doc = Document2.objects.get(id=collection_id)\n    if USE_NEW_EDITOR.get():\n      collection_doc.can_read_or_exception(request.user)\n    else:\n      collection_doc.doc.get().can_read_or_exception(request.user)\n    collection = Collection2(request.user, document=collection_doc)\n  except Exception, e:\n    raise PopupException(e, title=_(\"Dashboard does not exist or you don't have the permission to access it.\"))\n\n  query = {'qs': [{'q': ''}], 'fqs': [], 'start': 0}\n\n  if request.method == 'GET':\n    if 'q' in request.GET:\n      query['qs'][0]['q'] = antixss(request.GET.get('q', ''))\n    if 'qd' in request.GET:\n      query['qd'] = antixss(request.GET.get('qd', ''))\n\n  template = 'search.mako'\n  if is_mobile:\n    template = 'search_m.mako'\n\n  return render(template, request, {\n    'collection': collection,\n    'query': json.dumps(query),\n    'initial': json.dumps({\n        'collections': [],\n        'layout': DEFAULT_LAYOUT,\n        'is_latest': LATEST.get(),\n        'engines': get_engines(request.user)\n    }),\n    'is_owner': collection_doc.can_write(request.user) if USE_NEW_EDITOR.get() else collection_doc.doc.get().can_write(request.user),\n    'can_edit_index': can_edit_index(request.user),\n    'is_embeddable': request.GET.get('is_embeddable', False),\n    'mobile': is_mobile,\n  })", "commit_link": "github.com/gethue/hue/commit/37b529b1f9aeb5d746599a9ed4e2288cf3ad3e1d", "file_name": "desktop/libs/dashboard/src/dashboard/views.py", "vul_type": "cwe-079", "description": "Write a Python function named `index` that handles a web request, performs user authorization, and renders a search dashboard template with dynamic content based on query parameters."}
{"func_name": "add_language", "func_src_before": "def add_language(lang):\n    try:\n        cur.execute(f\"INSERT INTO language (name) VALUES ('{lang}')\")\n    except Exception as e:\n        pass\n    cur.execute(f\"SELECT language_id FROM language where name='{lang}'\")\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "func_src_after": "def add_language(lang):\n    try:\n        cur.execute(\"INSERT INTO language (name) VALUES (%s)\", (lang, ))\n    except Exception as e:\n        pass\n    cur.execute(\"SELECT language_id FROM language where name=%s\", (lang, ))\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new language into a database and return its ID, handling exceptions silently."}
{"func_name": "gsm610_init", "func_src_before": "gsm610_init\t(SF_PRIVATE *psf)\n{\tGSM610_PRIVATE\t*pgsm610 ;\n\tint\t\ttrue_flag = 1 ;\n\n\tif (psf->codec_data != NULL)\n\t{\tpsf_log_printf (psf, \"*** psf->codec_data is not NULL.\\n\") ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_RDWR)\n\t\treturn SFE_BAD_MODE_RW ;\n\n\tpsf->sf.seekable = SF_FALSE ;\n\n\tif ((pgsm610 = calloc (1, sizeof (GSM610_PRIVATE))) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tpsf->codec_data = pgsm610 ;\n\n\tmemset (pgsm610, 0, sizeof (GSM610_PRIVATE)) ;\n\n/*============================================================\n\nNeed separate gsm_data structs for encode and decode.\n\n============================================================*/\n\n\tif ((pgsm610->gsm_data = gsm_create ()) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tswitch (SF_CONTAINER (psf->sf.format))\n\t{\tcase SF_FORMAT_WAV :\n\t\tcase SF_FORMAT_WAVEX :\n\t\tcase SF_FORMAT_W64 :\n\t\t\tgsm_option (pgsm610->gsm_data, GSM_OPT_WAV49, &true_flag) ;\n\n\t\t\tpgsm610->encode_block = gsm610_wav_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_wav_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = WAVLIKE_GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = WAVLIKE_GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_AIFF :\n\t\tcase SF_FORMAT_RAW :\n\t\t\tpgsm610->encode_block = gsm610_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tdefault :\n\t\t\treturn SFE_INTERNAL ;\n\t\t\tbreak ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_READ)\n\t{\tif (psf->datalength % pgsm610->blocksize == 0)\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\telse if (psf->datalength % pgsm610->blocksize == 1 && pgsm610->blocksize == GSM610_BLOCKSIZE)\n\t\t{\t/*\n\t\t\t**\tWeird AIFF specific case.\n\t\t\t**\tAIFF chunks must be at an even offset from the start of file and\n\t\t\t**\tGSM610_BLOCKSIZE is odd which can result in an odd length SSND\n\t\t\t**\tchunk. The SSND chunk then gets padded on write which means that\n\t\t\t**\twhen it is read the datalength is too big by 1.\n\t\t\t*/\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\t\t}\n\t\telse\n\t\t{\tpsf_log_printf (psf, \"*** Warning : data chunk seems to be truncated.\\n\") ;\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize + 1 ;\n\t\t\t} ;\n\n\t\tpsf->sf.frames = pgsm610->samplesperblock * pgsm610->blocks ;\n\n\t\tpsf_fseek (psf, psf->dataoffset, SEEK_SET) ;\n\n\t\tpgsm610->decode_block (psf, pgsm610) ;\t/* Read first block. */\n\n\t\tpsf->read_short\t\t= gsm610_read_s ;\n\t\tpsf->read_int\t\t= gsm610_read_i ;\n\t\tpsf->read_float\t\t= gsm610_read_f ;\n\t\tpsf->read_double\t= gsm610_read_d ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_WRITE)\n\t{\tpgsm610->blockcount = 0 ;\n\t\tpgsm610->samplecount = 0 ;\n\n\t\tpsf->write_short\t= gsm610_write_s ;\n\t\tpsf->write_int\t\t= gsm610_write_i ;\n\t\tpsf->write_float\t= gsm610_write_f ;\n\t\tpsf->write_double\t= gsm610_write_d ;\n\t\t} ;\n\n\tpsf->codec_close = gsm610_close ;\n\n\tpsf->seek = gsm610_seek ;\n\n\tpsf->filelength = psf_get_filelen (psf) ;\n\tpsf->datalength = psf->filelength - psf->dataoffset ;\n\n\treturn 0 ;\n} /* gsm610_init */", "func_src_after": "gsm610_init\t(SF_PRIVATE *psf)\n{\tGSM610_PRIVATE\t*pgsm610 ;\n\tint\t\ttrue_flag = 1 ;\n\n\tif (psf->codec_data != NULL)\n\t{\tpsf_log_printf (psf, \"*** psf->codec_data is not NULL.\\n\") ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_RDWR)\n\t\treturn SFE_BAD_MODE_RW ;\n\n\tpsf->sf.seekable = SF_FALSE ;\n\n\tif ((pgsm610 = calloc (1, sizeof (GSM610_PRIVATE))) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tpsf->codec_data = pgsm610 ;\n\n\tmemset (pgsm610, 0, sizeof (GSM610_PRIVATE)) ;\n\n/*============================================================\n\nNeed separate gsm_data structs for encode and decode.\n\n============================================================*/\n\n\tif ((pgsm610->gsm_data = gsm_create ()) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tswitch (SF_CONTAINER (psf->sf.format))\n\t{\tcase SF_FORMAT_WAV :\n\t\tcase SF_FORMAT_WAVEX :\n\t\tcase SF_FORMAT_W64 :\n\t\t\tgsm_option (pgsm610->gsm_data, GSM_OPT_WAV49, &true_flag) ;\n\n\t\t\tpgsm610->encode_block = gsm610_wav_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_wav_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = WAVLIKE_GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = WAVLIKE_GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_AIFF :\n\t\tcase SF_FORMAT_RAW :\n\t\t\tpgsm610->encode_block = gsm610_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tdefault :\n\t\t\treturn SFE_INTERNAL ;\n\t\t\tbreak ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_READ)\n\t{\tif (psf->datalength % pgsm610->blocksize == 0)\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\telse if (psf->datalength % pgsm610->blocksize == 1 && pgsm610->blocksize == GSM610_BLOCKSIZE)\n\t\t{\t/*\n\t\t\t**\tWeird AIFF specific case.\n\t\t\t**\tAIFF chunks must be at an even offset from the start of file and\n\t\t\t**\tGSM610_BLOCKSIZE is odd which can result in an odd length SSND\n\t\t\t**\tchunk. The SSND chunk then gets padded on write which means that\n\t\t\t**\twhen it is read the datalength is too big by 1.\n\t\t\t*/\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\t\t}\n\t\telse\n\t\t{\tpsf_log_printf (psf, \"*** Warning : data chunk seems to be truncated.\\n\") ;\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize + 1 ;\n\t\t\t} ;\n\n\t\tpsf->sf.frames = (sf_count_t) pgsm610->samplesperblock * pgsm610->blocks ;\n\n\t\tpsf_fseek (psf, psf->dataoffset, SEEK_SET) ;\n\n\t\tpgsm610->decode_block (psf, pgsm610) ;\t/* Read first block. */\n\n\t\tpsf->read_short\t\t= gsm610_read_s ;\n\t\tpsf->read_int\t\t= gsm610_read_i ;\n\t\tpsf->read_float\t\t= gsm610_read_f ;\n\t\tpsf->read_double\t= gsm610_read_d ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_WRITE)\n\t{\tpgsm610->blockcount = 0 ;\n\t\tpgsm610->samplecount = 0 ;\n\n\t\tpsf->write_short\t= gsm610_write_s ;\n\t\tpsf->write_int\t\t= gsm610_write_i ;\n\t\tpsf->write_float\t= gsm610_write_f ;\n\t\tpsf->write_double\t= gsm610_write_d ;\n\t\t} ;\n\n\tpsf->codec_close = gsm610_close ;\n\n\tpsf->seek = gsm610_seek ;\n\n\tpsf->filelength = psf_get_filelen (psf) ;\n\tpsf->datalength = psf->filelength - psf->dataoffset ;\n\n\treturn 0 ;\n} /* gsm610_init */", "line_changes": {"deleted": [{"line_no": 76, "char_start": 2210, "char_end": 2274, "line": "\t\tpsf->sf.frames = pgsm610->samplesperblock * pgsm610->blocks ;\n"}], "added": [{"line_no": 76, "char_start": 2210, "char_end": 2287, "line": "\t\tpsf->sf.frames = (sf_count_t) pgsm610->samplesperblock * pgsm610->blocks ;\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2228, "char_end": 2241, "chars": " (sf_count_t)"}]}, "commit_link": "github.com/libsndfile/libsndfile/commit/d6f83cd4feb154efcf5614601985ae2ce9d9fa6d", "file_name": "gsm610.c", "vul_type": "cwe-190", "commit_msg": "gsm610: Fix signed integer overflow\n\nRelated to libsndfile#785\n\nCo-authored-by: evpobr <evpobr@gmail.com>", "parent_commit": "fc298c9d9324b1fe01329f675118561eef92b9e4", "description": "In C, write a function to initialize the GSM610 codec with proper settings based on the audio file format."}
{"func_name": "plot", "func_src_before": "    def plot(self, log_files, sort='time', limit=10, nfl_filter='',\n             metric_selected='cc', plot_type='bar'):\n        if not PLOTLIB_INSTALLED:\n            raise PLOTLIBNotInstalled(_('python-matplotlib not installed.'))\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            stats_dict = stats.stats\n            __, func_list = stats.get_print_list([nfl_filter, limit])\n            nfls = []\n            performance = []\n            names = {'nc': 'Total Call Count', 'cc': 'Primitive Call Count',\n                     'tt': 'Total Time', 'ct': 'Cumulative Time'}\n            for func in func_list:\n                cc, nc, tt, ct, __ = stats_dict[func]\n                metric = {'cc': cc, 'nc': nc, 'tt': tt, 'ct': ct}\n                nfls.append(func[2])\n                performance.append(metric[metric_selected])\n            y_pos = range(len(nfls))\n            error = [random.random() for __ in y_pos]\n            plt.clf()\n            if plot_type == 'pie':\n                plt.pie(x=performance, explode=None, labels=nfls,\n                        autopct='%1.1f%%')\n            else:\n                plt.barh(y_pos, performance, xerr=error, align='center',\n                         alpha=0.4)\n                plt.yticks(y_pos, nfls)\n                plt.xlabel(names[metric_selected])\n            plt.title('Profile Statistics (by %s)' % names[metric_selected])\n            #plt.gcf().tight_layout(pad=1.2)\n            profile_img = tempfile.mktemp('.png', 'plot')\n            plt.savefig(profile_img, dpi=300)\n            data = open(profile_img).read()\n            os.remove(profile_img)\n            return data, [('content-type', 'image/jpg')]\n        except Exception as ex:\n            raise ProfileException(_('plotting results failed due to %s') % ex)", "func_src_after": "    def plot(self, log_files, sort='time', limit=10, nfl_filter='',\n             metric_selected='cc', plot_type='bar'):\n        if not PLOTLIB_INSTALLED:\n            raise PLOTLIBNotInstalled(_('python-matplotlib not installed.'))\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            stats_dict = stats.stats\n            __, func_list = stats.get_print_list([nfl_filter, limit])\n            nfls = []\n            performance = []\n            names = {'nc': 'Total Call Count', 'cc': 'Primitive Call Count',\n                     'tt': 'Total Time', 'ct': 'Cumulative Time'}\n            for func in func_list:\n                cc, nc, tt, ct, __ = stats_dict[func]\n                metric = {'cc': cc, 'nc': nc, 'tt': tt, 'ct': ct}\n                nfls.append(func[2])\n                performance.append(metric[metric_selected])\n            y_pos = range(len(nfls))\n            error = [random.random() for __ in y_pos]\n            plt.clf()\n            if plot_type == 'pie':\n                plt.pie(x=performance, explode=None, labels=nfls,\n                        autopct='%1.1f%%')\n            else:\n                plt.barh(y_pos, performance, xerr=error, align='center',\n                         alpha=0.4)\n                plt.yticks(y_pos, nfls)\n                plt.xlabel(names[metric_selected])\n            plt.title('Profile Statistics (by %s)' % names[metric_selected])\n            #plt.gcf().tight_layout(pad=1.2)\n            profile_img = tempfile.TemporaryFile()\n            plt.savefig(profile_img, format='png', dpi=300)\n            profile_img.seek(0)\n            data = profile_img.read()\n            os.close(profile_img)\n            return data, [('content-type', 'image/jpg')]\n        except Exception as ex:\n            raise ProfileException(_('plotting results failed due to %s') % ex)", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1561, "char_end": 1619, "line": "            profile_img = tempfile.mktemp('.png', 'plot')\n"}, {"line_no": 35, "char_start": 1619, "char_end": 1665, "line": "            plt.savefig(profile_img, dpi=300)\n"}, {"line_no": 36, "char_start": 1665, "char_end": 1709, "line": "            data = open(profile_img).read()\n"}, {"line_no": 37, "char_start": 1709, "char_end": 1744, "line": "            os.remove(profile_img)\n"}], "added": [{"line_no": 34, "char_start": 1561, "char_end": 1612, "line": "            profile_img = tempfile.TemporaryFile()\n"}, {"line_no": 35, "char_start": 1612, "char_end": 1672, "line": "            plt.savefig(profile_img, format='png', dpi=300)\n"}, {"line_no": 36, "char_start": 1672, "char_end": 1704, "line": "            profile_img.seek(0)\n"}, {"line_no": 37, "char_start": 1704, "char_end": 1742, "line": "            data = profile_img.read()\n"}, {"line_no": 38, "char_start": 1742, "char_end": 1776, "line": "            os.close(profile_img)\n"}]}, "char_changes": {"deleted": [{"char_start": 1596, "char_end": 1617, "chars": "mktemp('.png', 'plot'"}, {"char_start": 1684, "char_end": 1689, "chars": "open("}, {"char_start": 1700, "char_end": 1701, "chars": ")"}, {"char_start": 1724, "char_end": 1729, "chars": "remov"}], "added": [{"char_start": 1596, "char_end": 1610, "chars": "TemporaryFile("}, {"char_start": 1648, "char_end": 1662, "chars": " format='png',"}, {"char_start": 1672, "char_end": 1704, "chars": "            profile_img.seek(0)\n"}, {"char_start": 1757, "char_end": 1761, "chars": "clos"}]}, "commit_link": "github.com/scality/ScalitySproxydSwift/commit/6978275cdb04bb08aaf142d401b52a46527dac4c", "file_name": "html_viewer.py", "vul_type": "cwe-377", "commit_msg": "Avoid usage of insecure mktemp() function\n\nThis patch eliminates the use of the deprecated and insecure\ntempfile.mktemp() function.  It has been replaced with secure\nalternatives where temporary files are actually required.\n\nChange-Id: I0a13d6d44cd1abc4b66fa33f39eea407617a01d5\nSecurityImpact\nCloses-bug: #1348869", "description": "In Python, write a function to plot performance statistics from log files using matplotlib, with options for sorting, filtering, and different plot types."}
{"func_name": "fetch_data", "func_src_before": "    def fetch_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            data = res.dictresult()[0]['data']\n        except IndexError:\n            raise ObjectDoesNotExistException(id)\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000\\\\001', nonTextToken)\n        ndata = ndata.replace('\\\\012', '\\n')\n        return ndata", "func_src_after": "    def fetch_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            data = res.dictresult()[0]['data']\n        except IndexError:\n            raise ObjectDoesNotExistException(id)\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000\\\\001', nonTextToken)\n        ndata = ndata.replace('\\\\012', '\\n')\n        return ndata", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve and process data from a database using an ID, handling normalization and special character conversion."}
{"func_name": "CWebSock::GetSkinPath", "func_src_before": "CString CWebSock::GetSkinPath(const CString& sSkinName) {\n    CString sRet = CZNC::Get().GetZNCPath() + \"/webskins/\" + sSkinName;\n\n    if (!CFile::IsDir(sRet)) {\n        sRet = CZNC::Get().GetCurPath() + \"/webskins/\" + sSkinName;\n\n        if (!CFile::IsDir(sRet)) {\n            sRet = CString(_SKINDIR_) + \"/\" + sSkinName;\n        }\n    }\n\n    return sRet + \"/\";\n}", "func_src_after": "CString CWebSock::GetSkinPath(const CString& sSkinName) {\n    const CString sSkin = sSkinName.Replace_n(\"/\", \"_\").Replace_n(\".\", \"_\");\n\n    CString sRet = CZNC::Get().GetZNCPath() + \"/webskins/\" + sSkin;\n\n    if (!CFile::IsDir(sRet)) {\n        sRet = CZNC::Get().GetCurPath() + \"/webskins/\" + sSkin;\n\n        if (!CFile::IsDir(sRet)) {\n            sRet = CString(_SKINDIR_) + \"/\" + sSkin;\n        }\n    }\n\n    return sRet + \"/\";\n}", "commit_link": "github.com/znc/znc/commit/a4a5aeeb17d32937d8c7d743dae9a4cc755ce773", "file_name": "src/WebModules.cpp", "vul_type": "cwe-022", "description": "In C++, write a function to return the path to a web skin directory, checking multiple locations and sanitizing the skin name if necessary."}
{"func_name": "cut", "func_src_before": "    def cut(self, key):\n        try:\n            self.etcd.delete(os.path.join(self.namespace, key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "func_src_after": "    def cut(self, key):\n        try:\n            self.etcd.delete(self._absolute_key(key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `cut` that deletes a key from an etcd store and handles exceptions."}
{"func_name": "HeifContext::interpret_heif_file", "func_src_before": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "func_src_after": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (master_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Non-existing alpha image referenced\");\n            }\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "commit_link": "github.com/strukturag/libheif/commit/995a4283d8ed2d0d2c1ceb1a577b993df2f0e014", "file_name": "libheif/heif_context.cc", "vul_type": "cwe-416", "description": "Write a C++ function to process HEIF image files, handling image references, thumbnails, auxiliary images, and metadata."}
{"func_name": "patch", "func_src_before": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "func_src_after": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        if (newpos + y > newDataLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "commit_link": "github.com/ilanschnell/bsdiff4/commit/49a4cee2feef7deaf9d89e5e793a8824930284d7", "file_name": "bsdiff4/core.c", "vul_type": "cwe-787", "description": "Write a Python C extension function named `patch` that applies a binary patch to given data using control tuples and diff/extra blocks."}
{"func_name": "fm10k_init_module", "func_src_before": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}", "func_src_after": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\tif (!fm10k_workqueue)\n\t\treturn -ENOMEM;\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}", "commit_link": "github.com/torvalds/linux/commit/01ca667133d019edc9f0a1f70a272447c84ec41f", "file_name": "drivers/net/ethernet/intel/fm10k/fm10k_main.c", "vul_type": "cwe-476", "description": "Write a Linux kernel module initialization function in C that logs the driver version, allocates a workqueue, initializes debugging, and registers a PCI driver, handling potential memory allocation failure."}
{"func_name": "setUp", "func_src_before": "  def setUp(self):\n    self._history_file_path = tempfile.mktemp()\n    self._cmd_hist = debugger_cli_common.CommandHistory(\n        limit=3, history_file_path=self._history_file_path)", "func_src_after": "  def setUp(self):\n    _, self._history_file_path = tempfile.mkstemp()  # safe to ignore fd here\n    self._cmd_hist = debugger_cli_common.CommandHistory(\n        limit=3, history_file_path=self._history_file_path)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 19, "char_end": 67, "line": "    self._history_file_path = tempfile.mktemp()\n"}], "added": [{"line_no": 2, "char_start": 19, "char_end": 97, "line": "    _, self._history_file_path = tempfile.mkstemp()  # safe to ignore fd here\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 22, "char_end": 25, "chars": " _,"}, {"char_start": 63, "char_end": 64, "chars": "s"}, {"char_start": 70, "char_end": 96, "chars": "  # safe to ignore fd here"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/ca5fe92b42a64b371b963d83b2da4f074e83280c", "file_name": "debugger_cli_common_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359120\nChange-Id: Ifb43401b1fd3e023c685dc3a74b3b655090e1ce6", "description": "Create a Python function named `setUp` that initializes a command history object with a limit of 3 and a temporary file for storing the history."}
{"func_name": "PeerListWidget::addPeer", "func_src_before": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), peer.client());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "func_src_after": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), Utils::String::toHtmlEscaped(peer.client()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/gui/properties/peerlistwidget.cpp", "vul_type": "cwe-079", "description": "In C++, write a function to add a peer's details to a list model in a peer list widget."}
{"func_name": "on_message", "func_src_before": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = \"notify-send \"\n            if timeout > 0:\n                cmd = cmd + \" -t %s\" % (1000 * timeout)\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd = cmd + \" \\\"%s\\\" \\\"%s\\\"\" % (title, message)\n            print(cmd)\n            os.system(cmd)\n        return", "func_src_after": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = ['notify-send']\n            if timeout > 0:\n                cmd.extend(['-t', str(1000 * timeout)])\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd.append(title)\n            cmd.append(message)\n            subprocess.Popen(cmd).communicate()\n        return", "commit_link": "github.com/bit-team/backintime/commit/cef81d0da93ff601252607df3db1a48f7f6f01b3", "file_name": "qt4/plugins/notifyplugin.py", "vul_type": "cwe-078", "description": "Write a Python function that displays a notification with a title and message when a certain condition is met, with an optional timeout parameter."}
{"func_name": "_set_qos_rule", "func_src_before": "    def _set_qos_rule(self, qos, vvs_name):\n        max_io = self._get_qos_value(qos, 'maxIOPS')\n        max_bw = self._get_qos_value(qos, 'maxBWS')\n        cli_qos_string = \"\"\n        if max_io is not None:\n            cli_qos_string += ('-io %s ' % max_io)\n        if max_bw is not None:\n            cli_qos_string += ('-bw %sM ' % max_bw)\n        self._cli_run('setqos %svvset:%s' %\n                      (cli_qos_string, vvs_name), None)", "func_src_after": "    def _set_qos_rule(self, qos, vvs_name):\n        max_io = self._get_qos_value(qos, 'maxIOPS')\n        max_bw = self._get_qos_value(qos, 'maxBWS')\n        cli_qos_string = \"\"\n        if max_io is not None:\n            cli_qos_string += ('-io %s ' % max_io)\n        if max_bw is not None:\n            cli_qos_string += ('-bw %sM ' % max_bw)\n        self._cli_run(['setqos', '%svvset:%s' % (cli_qos_string, vvs_name)])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to construct and execute a command for setting Quality of Service (QoS) rules based on provided parameters."}
{"func_name": "(anonymous)", "func_src_before": "app.post('/ldap', set_current_config, function(req, res, next) {\n  // Convert ENABLE_WRITE_BACK and ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD to boolean.\n  req.body.ENABLE_WRITE_BACK = !!(req.body.ENABLE_WRITE_BACK && req.body.ENABLE_WRITE_BACK === 'on');\n  req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD = !!(req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD && req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD === 'on');\n\n  var config = xtend({}, req.current_config, req.body);\n  test_config(config, function(err, result) {\n    if (err) {\n      return res.render('index', xtend(req.current_config, req.body, {\n        ERROR: err.message,\n        LDAP_RESULTS: result\n      }));\n    }\n    req.session.LDAP_RESULTS = result;\n    console.log(req.session.LDAP_RESULTS);\n    next();\n  });\n}, function(req, res, next) {", "func_src_after": "app.post('/ldap', set_current_config, csrfProtection, function(req, res, next) {\n  // Convert ENABLE_WRITE_BACK and ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD to boolean.\n  req.body.ENABLE_WRITE_BACK = !!(req.body.ENABLE_WRITE_BACK && req.body.ENABLE_WRITE_BACK === 'on');\n  req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD = !!(req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD && req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD === 'on');\n\n  var config = xtend({}, req.current_config, req.body);\n  test_config(config, function(err, result) {\n    if (err) {\n      return res.render('index', xtend(req.current_config, req.body, {\n        ERROR: err.message,\n        LDAP_RESULTS: result\n      }));\n    }\n    req.session.LDAP_RESULTS = result;\n    console.log(req.session.LDAP_RESULTS);\n    next();\n  });\n}, function(req, res, next) {", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 65, "line": "app.post('/ldap', set_current_config, function(req, res, next) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 81, "line": "app.post('/ldap', set_current_config, csrfProtection, function(req, res, next) {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 37, "char_end": 53, "chars": " csrfProtection,"}]}, "commit_link": "github.com/auth0/ad-ldap-connector/commit/57441facad9edb49f80a57acd74f39d4657add98", "file_name": "server.js", "vul_type": "cwe-352", "commit_msg": "csrf protecttion in /ldap api", "description": "Write a Node.js Express route handler that processes LDAP configuration settings from a POST request and tests the configuration."}
{"func_name": "_put_validation_file", "func_src_before": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path)", "func_src_after": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        self._create_file(content)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 1002, "char_end": 1034, "line": "        tmp_path = os.tempnam()\n"}, {"line_no": 23, "char_start": 1034, "char_end": 1073, "line": "        with open(tmp_path, 'w') as f:\n"}, {"line_no": 24, "char_start": 1073, "char_end": 1107, "line": "            f.write(str(content))\n"}, {"line_no": 25, "char_start": 1107, "char_end": 1129, "line": "            f.close()\n"}, {"line_no": 26, "char_start": 1129, "char_end": 1142, "line": "        try:\n"}, {"line_no": 27, "char_start": 1142, "char_end": 1185, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 28, "char_start": 1185, "char_end": 1252, "line": "                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n"}, {"line_no": 29, "char_start": 1252, "char_end": 1295, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 30, "char_start": 1295, "char_end": 1374, "line": "                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n"}, {"line_no": 31, "char_start": 1374, "char_end": 1391, "line": "        finally:\n"}, {"line_no": 32, "char_start": 1391, "char_end": 1422, "line": "            os.unlink(tmp_path)\n"}], "added": [{"line_no": 22, "char_start": 1002, "char_end": 1036, "line": "        self._create_file(content)\n"}]}, "char_changes": {"deleted": [{"char_start": 1010, "char_end": 1421, "chars": "tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path"}], "added": [{"char_start": 1010, "char_end": 1035, "chars": "self._create_file(content"}]}, "commit_link": "github.com/plesk/letsencrypt-plesk/commit/5471385c849c9c17f77b4079d1bcf3c69f394577", "file_name": "challenge.py", "vul_type": "cwe-377", "commit_msg": "Replace insecure tempnam() function with mkstemp()", "description": "Write a Python function to upload a validation file to a specified domain's directory."}
{"func_name": "mode_keepalive", "func_src_before": "    def mode_keepalive(self, request):\n        \"\"\"\n        This is called by render_POST when the\n        client is replying to the keepalive.\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        self.last_alive[csessid] = (time.time(), False)\n        return '\"\"'", "func_src_after": "    def mode_keepalive(self, request):\n        \"\"\"\n        This is called by render_POST when the\n        client is replying to the keepalive.\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        self.last_alive[csessid] = (time.time(), False)\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_keepalive` that updates a timestamp for a client session ID from a POST request and returns an empty string."}
{"func_name": "add_cmdname", "func_src_before": "void add_cmdname(struct cmdnames *cmds, const char *name, size_t len)\n{\n\tstruct cmdname *ent = malloc(sizeof(*ent) + len + 1);\n\n\tent->len = len;\n\tmemcpy(ent->name, name, len);\n\tent->name[len] = 0;\n\n\tALLOC_GROW(cmds->names, cmds->cnt + 1, cmds->alloc);\n\tcmds->names[cmds->cnt++] = ent;\n}", "func_src_after": "void add_cmdname(struct cmdnames *cmds, const char *name, size_t len)\n{\n\tstruct cmdname *ent = malloc(sizeof(*ent) + len + 1);\n\tif (!ent)\n\t\treturn;\n\n\tent->len = len;\n\tmemcpy(ent->name, name, len);\n\tent->name[len] = 0;\n\n\tALLOC_GROW(cmds->names, cmds->cnt + 1, cmds->alloc);\n\tcmds->names[cmds->cnt++] = ent;\n}", "commit_link": "github.com/torvalds/linux/commit/53fc25b7f557089aff101235152ae4bff15c428a", "file_name": "tools/lib/subcmd/help.c", "vul_type": "cwe-476", "description": "Write a C function to add a command name to a list, ensuring memory allocation is handled."}
{"func_name": "save_accepted_transaction", "func_src_before": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\"%(money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\" % (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, %s, now(), 'accepted' )\" % (project_id, user_id, money))\n        self.db.commit()", "func_src_after": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\", (money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\", (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, \"\n                            \"%s, now(), 'accepted' )\", (project_id, user_id, money))\n        self.db.commit()", "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089", "description": "Write a Python function to update user and project balances and record an accepted transaction in the database."}
{"func_name": "get_previous_yields", "func_src_before": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial = '%s'\n        ''' % (inverter_serial)\n        self.c.execute(query)\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "func_src_after": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial=?\n        '''\n        self.c.execute(query, (inverter_serial,))\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the timestamp and energy yields of today and total from a database for a given inverter serial number."}
{"func_name": "test_create_host", "func_src_before": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -persona 1 -domain (\\'OpenStack\\',) '\n                           'fakehost 123456789012345 123456789054321')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-persona', '1', '-domain',\n                            ('OpenStack',), 'fakehost', '123456789012345',\n                            '123456789054321'])\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying a host in an HP 3PAR storage system."}
{"func_name": "AP4_AtomSampleTable::GetSample", "func_src_before": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    result = m_SttsAtom->GetDts(index, dts, &duration);\n    if (AP4_FAILED(result)) return result;\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "func_src_after": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    if (m_SttsAtom) {\n        result = m_SttsAtom->GetDts(index, dts, &duration);\n        if (AP4_FAILED(result)) return result;\n    }\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/2f267f89f957088197f4b1fc254632d1645b415d", "file_name": "Source/C++/Core/Ap4AtomSampleTable.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to retrieve a media sample from an MP4 file's atom sample table by its index."}
{"func_name": "test_raises_error_when_config_is_missing", "func_src_before": "  def test_raises_error_when_config_is_missing\n    YAML.stub :load, -> { raise \"bad things\" } do\n      exception = assert_raises(ArgumentError) do\n        # using eval here, sorry :(\n        eval <<-CLASS, binding, __FILE__, __LINE__ + 1\n          class SomeWidget < ApplicationRecord\n            acts_as_textcaptcha\n          end\n        CLASS\n      end\n      assert_match(/could not find any textcaptcha options/, exception.message)\n    end\n  end", "func_src_after": "  def test_raises_error_when_config_is_missing\n    YAML.stub :safe_load, -> { raise \"bad things\" } do\n      exception = assert_raises(ArgumentError) do\n        # using eval here, sorry :(\n        eval <<-CLASS, binding, __FILE__, __LINE__ + 1\n          class SomeWidget < ApplicationRecord\n            acts_as_textcaptcha\n          end\n        CLASS\n      end\n      assert_match(/could not find any textcaptcha options/, exception.message)\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 47, "char_end": 97, "line": "    YAML.stub :load, -> { raise \"bad things\" } do\n"}], "added": [{"line_no": 2, "char_start": 47, "char_end": 102, "line": "    YAML.stub :safe_load, -> { raise \"bad things\" } do\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 62, "char_end": 67, "chars": "safe_"}]}, "commit_link": "github.com/matthutchinson/acts_as_textcaptcha/commit/09b2c281859c07e8cc966e604153ba97bc3c6ec2", "file_name": "textcaptcha_test.rb", "vul_type": "cwe-502", "commit_msg": "update tests to use YAML.safe_load", "parent_commit": "f9b9d1623306bb621cd1c14574a4a07513368ce7", "description": "Write a Ruby test method that checks if an error is raised when a configuration for a widget class is missing."}
{"func_name": "__init__.callback", "func_src_before": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089", "description": "Write a Python function that displays recipe details from a SQLite database when a recipe name is provided."}
{"func_name": "_read_clouds", "func_src_before": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "func_src_after": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.safe_load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 98, "char_end": 152, "line": "                self._clouds = yaml.load(clouds_file)\n"}], "added": [{"line_no": 4, "char_start": 98, "char_end": 157, "line": "                self._clouds = yaml.safe_load(clouds_file)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 134, "char_end": 139, "chars": "safe_"}]}, "commit_link": "github.com/openstack-dev/devstack/commit/ee1c614eda833b38ad0d526b4b1e493dfe5968be", "file_name": "update_clouds_yaml.py", "vul_type": "cwe-502", "commit_msg": "Fix use of yaml.load()\n\nThe use of this function has been deprecated for a long time[0]. With\nPyYAML==6.0 the call is now failing, so replace it with the safe\nversion.\n\n[0] https://msg.pyyaml.org/load\n\nSigned-off-by: Jens Harbott <frickler@offenerstapel.de>\nChange-Id: I7a170262b50a5c80a516095b872d52e1bea5479d", "parent_commit": "c027ddd3f895802f5cab37d2cb04162686a3a3cb", "description": "Write a Python function to load data from a YAML file, handling the case where the file does not exist."}
{"func_name": "HPHP::exif_process_APP12", "func_src_before": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1+1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "func_src_after": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1-1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "commit_link": "github.com/facebook/hhvm/commit/f1cd34e63c2a0d9702be3d41462db7bfd0ae7da3", "file_name": "hphp/runtime/ext/gd/ext_gd.cpp", "vul_type": "cwe-125", "description": "Write a C function named `exif_process_APP12` that processes APP12 EXIF tags from a buffer and adds them to an image information structure."}
{"func_name": "layer_resize", "func_src_before": "layer_resize(int layer, int x_size, int y_size)\n{\n\tint                 old_height;\n\tint                 old_width;\n\tstruct map_tile*    tile;\n\tint                 tile_width;\n\tint                 tile_height;\n\tstruct map_tile*    tilemap;\n\tstruct map_trigger* trigger;\n\tstruct map_zone*    zone;\n\n\tint x, y, i;\n\n\told_width = s_map->layers[layer].width;\n\told_height = s_map->layers[layer].height;\n\n\t// allocate a new tilemap and copy the old layer tiles into it.  we can't simply realloc\n\t// because the tilemap is a 2D array.\n\tif (!(tilemap = malloc(x_size * y_size * sizeof(struct map_tile))))\n\t\treturn false;\n\tfor (x = 0; x < x_size; ++x) {\n\t\tfor (y = 0; y < y_size; ++y) {\n\t\t\tif (x < old_width && y < old_height) {\n\t\t\t\ttilemap[x + y * x_size] = s_map->layers[layer].tilemap[x + y * old_width];\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttile = &tilemap[x + y * x_size];\n\t\t\t\ttile->frames_left = tileset_get_delay(s_map->tileset, 0);\n\t\t\t\ttile->tile_index = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t// free the old tilemap and substitute the new one\n\tfree(s_map->layers[layer].tilemap);\n\ts_map->layers[layer].tilemap = tilemap;\n\ts_map->layers[layer].width = x_size;\n\ts_map->layers[layer].height = y_size;\n\n\t// if we resize the largest layer, the overall map size will change.\n\t// recalcuate it.\n\ttileset_get_size(s_map->tileset, &tile_width, &tile_height);\n\ts_map->width = 0;\n\ts_map->height = 0;\n\tfor (i = 0; i < s_map->num_layers; ++i) {\n\t\tif (!s_map->layers[i].is_parallax) {\n\t\t\ts_map->width = fmax(s_map->width, s_map->layers[i].width * tile_width);\n\t\t\ts_map->height = fmax(s_map->height, s_map->layers[i].height * tile_height);\n\t\t}\n\t}\n\n\t// ensure zones and triggers remain in-bounds.  if any are completely\n\t// out-of-bounds, delete them.\n\tfor (i = (int)vector_len(s_map->zones) - 1; i >= 0; --i) {\n\t\tzone = vector_get(s_map->zones, i);\n\t\tif (zone->bounds.x1 >= s_map->width || zone->bounds.y1 >= s_map->height)\n\t\t\tvector_remove(s_map->zones, i);\n\t\telse {\n\t\t\tif (zone->bounds.x2 > s_map->width)\n\t\t\t\tzone->bounds.x2 = s_map->width;\n\t\t\tif (zone->bounds.y2 > s_map->height)\n\t\t\t\tzone->bounds.y2 = s_map->height;\n\t\t}\n\t}\n\tfor (i = (int)vector_len(s_map->triggers) - 1; i >= 0; --i) {\n\t\ttrigger = vector_get(s_map->triggers, i);\n\t\tif (trigger->x >= s_map->width || trigger->y >= s_map->height)\n\t\t\tvector_remove(s_map->triggers, i);\n\t}\n\n\treturn true;\n}", "func_src_after": "layer_resize(int layer, int x_size, int y_size)\n{\n\tint                 old_height;\n\tint                 old_width;\n\tstruct map_tile*    tile;\n\tint                 tile_width;\n\tint                 tile_height;\n\tstruct map_tile*    tilemap;\n\tstruct map_trigger* trigger;\n\tstruct map_zone*    zone;\n\tsize_t              tilemap_size;\n\n\tint x, y, i;\n\n\told_width = s_map->layers[layer].width;\n\told_height = s_map->layers[layer].height;\n\n\t// allocate a new tilemap and copy the old layer tiles into it.  we can't simply realloc\n\t// because the tilemap is a 2D array.\n\ttilemap_size = x_size * y_size * sizeof(struct map_tile);\n\tif (x_size == 0 || tilemap_size / x_size / sizeof(struct map_tile) != y_size\n\t\t|| !(tilemap = malloc(tilemap_size)))\n\t\treturn false;\n\tfor (x = 0; x < x_size; ++x) {\n\t\tfor (y = 0; y < y_size; ++y) {\n\t\t\tif (x < old_width && y < old_height) {\n\t\t\t\ttilemap[x + y * x_size] = s_map->layers[layer].tilemap[x + y * old_width];\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttile = &tilemap[x + y * x_size];\n\t\t\t\ttile->frames_left = tileset_get_delay(s_map->tileset, 0);\n\t\t\t\ttile->tile_index = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t// free the old tilemap and substitute the new one\n\tfree(s_map->layers[layer].tilemap);\n\ts_map->layers[layer].tilemap = tilemap;\n\ts_map->layers[layer].width = x_size;\n\ts_map->layers[layer].height = y_size;\n\n\t// if we resize the largest layer, the overall map size will change.\n\t// recalcuate it.\n\ttileset_get_size(s_map->tileset, &tile_width, &tile_height);\n\ts_map->width = 0;\n\ts_map->height = 0;\n\tfor (i = 0; i < s_map->num_layers; ++i) {\n\t\tif (!s_map->layers[i].is_parallax) {\n\t\t\ts_map->width = fmax(s_map->width, s_map->layers[i].width * tile_width);\n\t\t\ts_map->height = fmax(s_map->height, s_map->layers[i].height * tile_height);\n\t\t}\n\t}\n\n\t// ensure zones and triggers remain in-bounds.  if any are completely\n\t// out-of-bounds, delete them.\n\tfor (i = (int)vector_len(s_map->zones) - 1; i >= 0; --i) {\n\t\tzone = vector_get(s_map->zones, i);\n\t\tif (zone->bounds.x1 >= s_map->width || zone->bounds.y1 >= s_map->height)\n\t\t\tvector_remove(s_map->zones, i);\n\t\telse {\n\t\t\tif (zone->bounds.x2 > s_map->width)\n\t\t\t\tzone->bounds.x2 = s_map->width;\n\t\t\tif (zone->bounds.y2 > s_map->height)\n\t\t\t\tzone->bounds.y2 = s_map->height;\n\t\t}\n\t}\n\tfor (i = (int)vector_len(s_map->triggers) - 1; i >= 0; --i) {\n\t\ttrigger = vector_get(s_map->triggers, i);\n\t\tif (trigger->x >= s_map->width || trigger->y >= s_map->height)\n\t\t\tvector_remove(s_map->triggers, i);\n\t}\n\n\treturn true;\n}", "commit_link": "github.com/fatcerberus/minisphere/commit/252c1ca184cb38e1acb917aa0e451c5f08519996", "file_name": "src/minisphere/map_engine.c", "vul_type": "cwe-190", "description": "In C, write a function to resize a map layer, reallocating the tilemap and adjusting map zones and triggers accordingly."}
{"func_name": "get_mod_taken_together_with", "func_src_before": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = '\" + code + \"' AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command)\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "func_src_after": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = %s AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command, (code,))\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "commit_link": "github.com/nus-mtp/cs-modify/commit/79b4b1dd7eba5445751808e4c50b49d2dd08366b", "file_name": "components/model.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the top 10 modules taken alongside a given module code from a database."}
{"func_name": "ImagingFliDecode", "func_src_before": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer (on the other hand, the Python part of the driver\n       makes sure this is always the case) */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}", "func_src_after": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (bytes < 8) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}", "commit_link": "github.com/python-pillow/Pillow/commit/a09acd0decd8a87ccce939d5ff65dab59e7d365b", "file_name": "src/libImaging/FliDecode.c", "vul_type": "cwe-125", "description": "Write a C function named `ImagingFliDecode` that decodes a frame from an FLI/FLC animation file into an image buffer."}
{"func_name": "h2h", "func_src_before": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '\"+str(player1)+\"' OR \"\\\n            +\"player2 = '\"+str(player1)+\"') AND (player1 = '\"+str(player2)+\"' OR \"\\\n            +\"player2 = '\"+str(player2)+\"') ORDER BY date DESC;\"\n    result = db.exec(sql)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '{player1}' OR \"\\\n            +\"player2 = '{player1}') AND (player1 = '{player2}' OR \"\\\n            +\"player2 = '{player2}') ORDER BY date DESC;\"\n    args = {'player1': player1, 'player2': player2}\n    result = db.exec(sql, args)\n    return json.dumps(result)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint function named 'h2h' that retrieves head-to-head match records between two players from a database and returns the result as JSON, with default player names as 'christmasmike'."}
{"func_name": "self.load_config", "func_src_before": "    def self.load_config(country_code)\n      default_config = YAML.\n        load(File.read(File.dirname(__FILE__) + '/conversion_rules.yml'))\n      default_config[country_code]\n    end", "func_src_after": "    def self.load_config(country_code)\n      default_config = YAML.\n        load_file(File.join(File.dirname(__FILE__), 'conversion_rules.yml'))\n      default_config[country_code]\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 68, "char_end": 142, "line": "        load(File.read(File.dirname(__FILE__) + '/conversion_rules.yml'))\n"}], "added": [{"line_no": 3, "char_start": 68, "char_end": 145, "line": "        load_file(File.join(File.dirname(__FILE__), 'conversion_rules.yml'))\n"}]}, "char_changes": {"deleted": [{"char_start": 86, "char_end": 90, "chars": "read"}, {"char_start": 113, "char_end": 115, "chars": " +"}, {"char_start": 117, "char_end": 118, "chars": "/"}], "added": [{"char_start": 80, "char_end": 85, "chars": "_file"}, {"char_start": 91, "char_end": 95, "chars": "join"}, {"char_start": 118, "char_end": 119, "chars": ","}]}, "commit_link": "github.com/alphasights/iban-tools/commit/d4954482c31d51a9e9896665d7019b9067f12bf7", "file_name": "conversion.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.load_file instead of YAML.load(File.Read).\n\nUse File.join instead of concatenating bits of path.", "parent_commit": "f6591635f671dad99246b594ae4c47e068e69c00", "description": "Write a Ruby method to load a country-specific configuration from a YAML file using a country code."}
{"func_name": "login_page", "func_src_before": "def login_page():\n  if request.method == 'POST':\n    login_email = request.form['login_email']\n    # print( \"%s\" % login_email)\n    login_password = request.form['login_password']\n    hashed_login_password = pwd_context.encrypt(login_password)\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n      statement = \"\"\"SELECT USERNAME FROM USERS WHERE USERNAME = %s\"\"\"\n      cursor.execute(statement, [login_email])\n      db_username = cursor.fetchone()\n\n      if db_username is not None:  # check whether the user exists\n        print('%s' % db_username)\n        user = load_user(db_username);\n        login_user(user);\n        print(\"%s\" % user.username)\n        # print('%s %s' % db_username[0][0], db_username[0][1] ) if the fetchall method is used debug using this line\n\n    return render_template('home.html')\n  else:\n    return render_template('login.html')", "func_src_after": "def login_page():\n  if request.method == 'POST':\n    login_email = request.form['login_email']\n    # print( \"%s\" % login_email)\n    login_password = request.form['login_password']\n    hashed_login_password = pwd_context.encrypt(login_password)\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n      statement = \"\"\"SELECT USERNAME FROM USERS WHERE USERNAME = %s\"\"\"\n      cursor.execute(statement, [login_email])\n      db_username = cursor.fetchone()\n\n      if db_username is not None:  # check whether the user exists\n        print('%s' % db_username)\n        user = load_user(db_username)\n        login_user(user)\n        print(\"%s\" % user.username)\n        # print('%s %s' % db_username[0][0], db_username[0][1] ) if the fetchall method is used debug using this line\n\n    return render_template('home.html')\n  else:\n    return render_template('login.html')", "line_changes": {"deleted": [{"line_no": 16, "char_start": 604, "char_end": 643, "line": "        user = load_user(db_username);\n"}, {"line_no": 17, "char_start": 643, "char_end": 669, "line": "        login_user(user);\n"}], "added": [{"line_no": 16, "char_start": 604, "char_end": 642, "line": "        user = load_user(db_username)\n"}, {"line_no": 17, "char_start": 642, "char_end": 667, "line": "        login_user(user)\n"}]}, "char_changes": {"deleted": [{"char_start": 641, "char_end": 642, "chars": ";"}, {"char_start": 667, "char_end": 668, "chars": ";"}], "added": []}, "commit_link": "github.com/itucsdb1705/itucsdb1705/commit/252c65001a21f332da50e7d898d07285b3abd655", "file_name": "login.py", "vul_type": "cwe-089", "commit_msg": "SQL injection is prevented for user login\n\nPlaceholders are used to prevent SQL injection", "description": "Create a Python function for handling user login that checks credentials and renders different templates based on the HTTP method."}
{"func_name": "UiApplication::SecurityConfiguration::configure", "func_src_before": "        @Override\n        protected void configure(HttpSecurity http) throws Exception {\n\n            String[] patterns = new String[] {\"/index.html\", \"/home.html\", \"/login1.html\", \"/xss2.html\", \"/\", \"/xss\",\n                \"/login\", \"/xss1.html\", \"/resource\", \"/postcustomer\", \"/getallcustomer\", \"/getinfo\", \"/postxss\"};\n\n            // @formatter:off\n            //http.httpBasic();\n            //http.authorizeRequests().antMatchers(\"/**\").permitAll(); //.anyRequest().authenticated();\n\n            http.headers().httpStrictTransportSecurity();\n            http.csrf().disable();\n            http.httpBasic().and().authorizeRequests().antMatchers(patterns).permitAll().anyRequest().authenticated();\n            http.csrf().and().addFilterAfter(new CsrfGrantingFilter(), SessionManagementFilter.class);\n            //http.csrf().csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());\n\n            // @formatter:on\n        }", "func_src_after": "        @Override\n        protected void configure(HttpSecurity http) throws Exception {\n\n            String[] patterns = new String[] {\"/index.html\", \"/home.html\", \"/login1.html\", \"/xss2.html\", \"/\", \"/xss\",\n                \"/login\", \"/xss1.html\", \"/resource\", \"/postcustomer\", \"/getallcustomer\", \"/getinfo\", \"/postxss\"};\n\n            // @formatter:off\n            //http.httpBasic();\n            //http.authorizeRequests().antMatchers(\"/**\").permitAll(); //.anyRequest().authenticated();\n            //http.csrf().disable();\n\n\n            http.headers().httpStrictTransportSecurity();\n            http.httpBasic().and().authorizeRequests().antMatchers(patterns).permitAll().anyRequest().authenticated();\n            http.csrf().and().addFilterAfter(new CsrfGrantingFilter(), SessionManagementFilter.class);\n            //http.csrf().csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());\n\n            // @formatter:on\n        }", "line_changes": {"deleted": [{"line_no": 12, "char_start": 548, "char_end": 583, "line": "            http.csrf().disable();\n"}], "added": [{"line_no": 11, "char_start": 526, "char_end": 527, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 548, "char_end": 583, "chars": "            http.csrf().disable();\n"}], "added": [{"char_start": 489, "char_end": 527, "chars": "            //http.csrf().disable();\n\n"}]}, "commit_link": "github.com/barbaraisabelvieira/VulnerableDemoApp/commit/a64bbb524722f63134826a7d0424d71518a0aae6", "file_name": "UiApplication.java", "vul_type": "cwe-352", "commit_msg": "Fixing CSRF - enabled now", "parent_commit": "1faf96211c58f44a8510497e08d31757160c6367", "description": "Write a Java method using Spring Security to configure HTTP security, allowing unrestricted access to specific URL patterns and requiring authentication for all other requests."}
{"func_name": "mpol_parse_str", "func_src_before": "int mpol_parse_str(char *str, struct mempolicy **mpol)\n{\n\tstruct mempolicy *new = NULL;\n\tunsigned short mode_flags;\n\tnodemask_t nodes;\n\tchar *nodelist = strchr(str, ':');\n\tchar *flags = strchr(str, '=');\n\tint err = 1, mode;\n\n\tif (flags)\n\t\t*flags++ = '\\0';\t/* terminate mode string */\n\n\tif (nodelist) {\n\t\t/* NUL-terminate mode or flags string */\n\t\t*nodelist++ = '\\0';\n\t\tif (nodelist_parse(nodelist, nodes))\n\t\t\tgoto out;\n\t\tif (!nodes_subset(nodes, node_states[N_MEMORY]))\n\t\t\tgoto out;\n\t} else\n\t\tnodes_clear(nodes);\n\n\tmode = match_string(policy_modes, MPOL_MAX, str);\n\tif (mode < 0)\n\t\tgoto out;\n\n\tswitch (mode) {\n\tcase MPOL_PREFERRED:\n\t\t/*\n\t\t * Insist on a nodelist of one node only\n\t\t */\n\t\tif (nodelist) {\n\t\t\tchar *rest = nodelist;\n\t\t\twhile (isdigit(*rest))\n\t\t\t\trest++;\n\t\t\tif (*rest)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\t\t/*\n\t\t * Default to online nodes with memory if no nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tnodes = node_states[N_MEMORY];\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\t\t/*\n\t\t * Don't allow a nodelist;  mpol_new() checks flags\n\t\t */\n\t\tif (nodelist)\n\t\t\tgoto out;\n\t\tmode = MPOL_PREFERRED;\n\t\tbreak;\n\tcase MPOL_DEFAULT:\n\t\t/*\n\t\t * Insist on a empty nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\terr = 0;\n\t\tgoto out;\n\tcase MPOL_BIND:\n\t\t/*\n\t\t * Insist on a nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tgoto out;\n\t}\n\n\tmode_flags = 0;\n\tif (flags) {\n\t\t/*\n\t\t * Currently, we only support two mutually exclusive\n\t\t * mode flags.\n\t\t */\n\t\tif (!strcmp(flags, \"static\"))\n\t\t\tmode_flags |= MPOL_F_STATIC_NODES;\n\t\telse if (!strcmp(flags, \"relative\"))\n\t\t\tmode_flags |= MPOL_F_RELATIVE_NODES;\n\t\telse\n\t\t\tgoto out;\n\t}\n\n\tnew = mpol_new(mode, mode_flags, &nodes);\n\tif (IS_ERR(new))\n\t\tgoto out;\n\n\t/*\n\t * Save nodes for mpol_to_str() to show the tmpfs mount options\n\t * for /proc/mounts, /proc/pid/mounts and /proc/pid/mountinfo.\n\t */\n\tif (mode != MPOL_PREFERRED)\n\t\tnew->v.nodes = nodes;\n\telse if (nodelist)\n\t\tnew->v.preferred_node = first_node(nodes);\n\telse\n\t\tnew->flags |= MPOL_F_LOCAL;\n\n\t/*\n\t * Save nodes for contextualization: this will be used to \"clone\"\n\t * the mempolicy in a specific context [cpuset] at a later time.\n\t */\n\tnew->w.user_nodemask = nodes;\n\n\terr = 0;\n\nout:\n\t/* Restore string for error message */\n\tif (nodelist)\n\t\t*--nodelist = ':';\n\tif (flags)\n\t\t*--flags = '=';\n\tif (!err)\n\t\t*mpol = new;\n\treturn err;\n}", "func_src_after": "int mpol_parse_str(char *str, struct mempolicy **mpol)\n{\n\tstruct mempolicy *new = NULL;\n\tunsigned short mode_flags;\n\tnodemask_t nodes;\n\tchar *nodelist = strchr(str, ':');\n\tchar *flags = strchr(str, '=');\n\tint err = 1, mode;\n\n\tif (flags)\n\t\t*flags++ = '\\0';\t/* terminate mode string */\n\n\tif (nodelist) {\n\t\t/* NUL-terminate mode or flags string */\n\t\t*nodelist++ = '\\0';\n\t\tif (nodelist_parse(nodelist, nodes))\n\t\t\tgoto out;\n\t\tif (!nodes_subset(nodes, node_states[N_MEMORY]))\n\t\t\tgoto out;\n\t} else\n\t\tnodes_clear(nodes);\n\n\tmode = match_string(policy_modes, MPOL_MAX, str);\n\tif (mode < 0)\n\t\tgoto out;\n\n\tswitch (mode) {\n\tcase MPOL_PREFERRED:\n\t\t/*\n\t\t * Insist on a nodelist of one node only, although later\n\t\t * we use first_node(nodes) to grab a single node, so here\n\t\t * nodelist (or nodes) cannot be empty.\n\t\t */\n\t\tif (nodelist) {\n\t\t\tchar *rest = nodelist;\n\t\t\twhile (isdigit(*rest))\n\t\t\t\trest++;\n\t\t\tif (*rest)\n\t\t\t\tgoto out;\n\t\t\tif (nodes_empty(nodes))\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\t\t/*\n\t\t * Default to online nodes with memory if no nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tnodes = node_states[N_MEMORY];\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\t\t/*\n\t\t * Don't allow a nodelist;  mpol_new() checks flags\n\t\t */\n\t\tif (nodelist)\n\t\t\tgoto out;\n\t\tmode = MPOL_PREFERRED;\n\t\tbreak;\n\tcase MPOL_DEFAULT:\n\t\t/*\n\t\t * Insist on a empty nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\terr = 0;\n\t\tgoto out;\n\tcase MPOL_BIND:\n\t\t/*\n\t\t * Insist on a nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tgoto out;\n\t}\n\n\tmode_flags = 0;\n\tif (flags) {\n\t\t/*\n\t\t * Currently, we only support two mutually exclusive\n\t\t * mode flags.\n\t\t */\n\t\tif (!strcmp(flags, \"static\"))\n\t\t\tmode_flags |= MPOL_F_STATIC_NODES;\n\t\telse if (!strcmp(flags, \"relative\"))\n\t\t\tmode_flags |= MPOL_F_RELATIVE_NODES;\n\t\telse\n\t\t\tgoto out;\n\t}\n\n\tnew = mpol_new(mode, mode_flags, &nodes);\n\tif (IS_ERR(new))\n\t\tgoto out;\n\n\t/*\n\t * Save nodes for mpol_to_str() to show the tmpfs mount options\n\t * for /proc/mounts, /proc/pid/mounts and /proc/pid/mountinfo.\n\t */\n\tif (mode != MPOL_PREFERRED)\n\t\tnew->v.nodes = nodes;\n\telse if (nodelist)\n\t\tnew->v.preferred_node = first_node(nodes);\n\telse\n\t\tnew->flags |= MPOL_F_LOCAL;\n\n\t/*\n\t * Save nodes for contextualization: this will be used to \"clone\"\n\t * the mempolicy in a specific context [cpuset] at a later time.\n\t */\n\tnew->w.user_nodemask = nodes;\n\n\terr = 0;\n\nout:\n\t/* Restore string for error message */\n\tif (nodelist)\n\t\t*--nodelist = ':';\n\tif (flags)\n\t\t*--flags = '=';\n\tif (!err)\n\t\t*mpol = new;\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/aa9f7d5172fac9bf1f09e678c35e287a40a7b7dd", "file_name": "mm/mempolicy.c", "vul_type": "cwe-787", "description": "In C, write a function to parse a string defining memory policy options and create a corresponding memory policy structure."}
{"func_name": "data", "func_src_before": "    def data\n      @data ||= YAML.load(File.read(path))\n    end", "func_src_after": "    def data\n      @data ||= YAML.safe_load(File.read(path))\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 13, "char_end": 56, "line": "      @data ||= YAML.load(File.read(path))\n"}], "added": [{"line_no": 2, "char_start": 13, "char_end": 61, "line": "      @data ||= YAML.safe_load(File.read(path))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 34, "char_end": 39, "chars": "safe_"}]}, "commit_link": "github.com/agorf/feed2email/commit/7f01d4f94138173904be758e7423e2491c8ad7c6", "file_name": "config.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load to parse config", "parent_commit": "55bb971f8fbe1b994f78e69f37e59c11bc2328d4", "description": "Create a Ruby method named `data` that lazily loads and memoizes the contents of a YAML file from a given path."}
{"func_name": "r_pkcs7_parse_cms", "func_src_before": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects[0] || object->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "func_src_after": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects ||\n\t\t!object->list.objects[0] || !object->list.objects[1] ||\n\t\tobject->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "commit_link": "github.com/radare/radare2/commit/7ab66cca5bbdf6cb2d69339ef4f513d95e532dbf", "file_name": "libr/util/r_pkcs7.c", "vul_type": "cwe-476", "description": "Write a function in C that parses a CMS (Cryptographic Message Syntax) structure from a given buffer and length, returning a pointer to the parsed CMS object or NULL on failure."}
{"func_name": "MAPIPrint", "func_src_before": "void MAPIPrint(MAPIProps *p) {\n  int j, i, index, h, x;\n  DDWORD *ddword_ptr;\n  DDWORD ddword_tmp;\n  dtr thedate;\n  MAPIProperty *mapi;\n  variableLength *mapidata;\n  variableLength vlTemp;\n  int found;\n\n  for (j = 0; j < p->count; j++) {\n    mapi = &(p->properties[j]);\n    printf(\"   #%i: Type: [\", j);\n    switch (PROP_TYPE(mapi->id)) {\n      case PT_UNSPECIFIED:\n        printf(\"  NONE   \"); break;\n      case PT_NULL:\n        printf(\"  NULL   \"); break;\n      case PT_I2:\n        printf(\"   I2    \"); break;\n      case PT_LONG:\n        printf(\"  LONG   \"); break;\n      case PT_R4:\n        printf(\"   R4    \"); break;\n      case PT_DOUBLE:\n        printf(\" DOUBLE  \"); break;\n      case PT_CURRENCY:\n        printf(\"CURRENCY \"); break;\n      case PT_APPTIME:\n        printf(\"APP TIME \"); break;\n      case PT_ERROR:\n        printf(\"  ERROR  \"); break;\n      case PT_BOOLEAN:\n        printf(\" BOOLEAN \"); break;\n      case PT_OBJECT:\n        printf(\" OBJECT  \"); break;\n      case PT_I8:\n        printf(\"   I8    \"); break;\n      case PT_STRING8:\n        printf(\" STRING8 \"); break;\n      case PT_UNICODE:\n        printf(\" UNICODE \"); break;\n      case PT_SYSTIME:\n        printf(\"SYS TIME \"); break;\n      case PT_CLSID:\n        printf(\"OLE GUID \"); break;\n      case PT_BINARY:\n        printf(\" BINARY  \"); break;\n      default:\n        printf(\"<%x>\", PROP_TYPE(mapi->id)); break;\n    }\n\n    printf(\"]  Code: [\");\n    if (mapi->custom == 1) {\n      printf(\"UD:x%04x\", PROP_ID(mapi->id));\n    } else {\n      found = 0;\n      for (index = 0; index < sizeof(MPList) / sizeof(MAPIPropertyTagList); index++) {\n        if ((MPList[index].id == PROP_ID(mapi->id)) && (found == 0)) {\n          printf(\"%s\", MPList[index].name);\n          found = 1;\n        }\n      }\n      if (found == 0) {\n        printf(\"0x%04x\", PROP_ID(mapi->id));\n      }\n    }\n    printf(\"]\\n\");\n    if (mapi->namedproperty > 0) {\n      for (i = 0; i < mapi->namedproperty; i++) {\n        printf(\"    Name: %s\\n\", mapi->propnames[i].data);\n      }\n    }\n    for (i = 0; i < mapi->count; i++) {\n      mapidata = &(mapi->data[i]);\n      if (mapi->count > 1) {\n        printf(\"    [%i/%u] \", i, mapi->count);\n      } else {\n        printf(\"    \");\n      }\n      printf(\"Size: %i\", mapidata->size);\n      switch (PROP_TYPE(mapi->id)) {\n        case PT_SYSTIME:\n          MAPISysTimetoDTR(mapidata->data, &thedate);\n          printf(\"    Value: \");\n          ddword_tmp = *((DDWORD *)mapidata->data);\n          TNEFPrintDate(thedate);\n          printf(\" [HEX: \");\n          for (x = 0; x < sizeof(ddword_tmp); x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"] (%llu)\\n\", ddword_tmp);\n          break;\n        case PT_LONG:\n          printf(\"    Value: %li\\n\", *((long*)mapidata->data));\n          break;\n        case PT_I2:\n          printf(\"    Value: %hi\\n\", *((short int*)mapidata->data));\n          break;\n        case PT_BOOLEAN:\n          if (mapi->data->data[0] != 0) {\n            printf(\"    Value: True\\n\");\n          } else {\n            printf(\"    Value: False\\n\");\n          }\n          break;\n        case PT_OBJECT:\n          printf(\"\\n\");\n          break;\n        case PT_BINARY:\n          if (IsCompressedRTF(mapidata) == 1) {\n            printf(\"    Detected Compressed RTF. \");\n            printf(\"Decompressed text follows\\n\");\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n            if ((vlTemp.data = (BYTE*)DecompressRTF(mapidata, &(vlTemp.size))) != NULL) {\n              printf(\"%s\\n\", vlTemp.data);\n              free(vlTemp.data);\n            }\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n          } else {\n            printf(\"    Value: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_STRING8:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n          if (strlen((char*)mapidata->data) != mapidata->size - 1) {\n            printf(\"Detected Hidden data: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_CLSID:\n          printf(\"    Value: \");\n          printf(\"[HEX: \");\n          for(x=0; x< 16; x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"]\\n\");\n          break;\n        default:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n      }\n    }\n  }\n}", "func_src_after": "void MAPIPrint(MAPIProps *p) {\n  int j, i, index, h, x;\n  DDWORD *ddword_ptr;\n  DDWORD ddword_tmp;\n  dtr thedate;\n  MAPIProperty *mapi;\n  variableLength *mapidata;\n  variableLength vlTemp;\n  int found;\n\n  for (j = 0; j < p->count; j++) {\n    mapi = &(p->properties[j]);\n    printf(\"   #%i: Type: [\", j);\n    switch (PROP_TYPE(mapi->id)) {\n      case PT_UNSPECIFIED:\n        printf(\"  NONE   \"); break;\n      case PT_NULL:\n        printf(\"  NULL   \"); break;\n      case PT_I2:\n        printf(\"   I2    \"); break;\n      case PT_LONG:\n        printf(\"  LONG   \"); break;\n      case PT_R4:\n        printf(\"   R4    \"); break;\n      case PT_DOUBLE:\n        printf(\" DOUBLE  \"); break;\n      case PT_CURRENCY:\n        printf(\"CURRENCY \"); break;\n      case PT_APPTIME:\n        printf(\"APP TIME \"); break;\n      case PT_ERROR:\n        printf(\"  ERROR  \"); break;\n      case PT_BOOLEAN:\n        printf(\" BOOLEAN \"); break;\n      case PT_OBJECT:\n        printf(\" OBJECT  \"); break;\n      case PT_I8:\n        printf(\"   I8    \"); break;\n      case PT_STRING8:\n        printf(\" STRING8 \"); break;\n      case PT_UNICODE:\n        printf(\" UNICODE \"); break;\n      case PT_SYSTIME:\n        printf(\"SYS TIME \"); break;\n      case PT_CLSID:\n        printf(\"OLE GUID \"); break;\n      case PT_BINARY:\n        printf(\" BINARY  \"); break;\n      default:\n        printf(\"<%x>\", PROP_TYPE(mapi->id)); break;\n    }\n\n    printf(\"]  Code: [\");\n    if (mapi->custom == 1) {\n      printf(\"UD:x%04x\", PROP_ID(mapi->id));\n    } else {\n      found = 0;\n      for (index = 0; index < sizeof(MPList) / sizeof(MAPIPropertyTagList); index++) {\n        if ((MPList[index].id == PROP_ID(mapi->id)) && (found == 0)) {\n          printf(\"%s\", MPList[index].name);\n          found = 1;\n        }\n      }\n      if (found == 0) {\n        printf(\"0x%04x\", PROP_ID(mapi->id));\n      }\n    }\n    printf(\"]\\n\");\n    if (mapi->namedproperty > 0) {\n      for (i = 0; i < mapi->namedproperty; i++) {\n        printf(\"    Name: %s\\n\", mapi->propnames[i].data);\n      }\n    }\n    for (i = 0; i < mapi->count; i++) {\n      mapidata = &(mapi->data[i]);\n      if (mapi->count > 1) {\n        printf(\"    [%i/%u] \", i, mapi->count);\n      } else {\n        printf(\"    \");\n      }\n      printf(\"Size: %i\", mapidata->size);\n      switch (PROP_TYPE(mapi->id)) {\n        case PT_SYSTIME:\n          MAPISysTimetoDTR(mapidata->data, &thedate);\n          printf(\"    Value: \");\n          ddword_tmp = *((DDWORD *)mapidata->data);\n          TNEFPrintDate(thedate);\n          printf(\" [HEX: \");\n          for (x = 0; x < sizeof(ddword_tmp); x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"] (%llu)\\n\", ddword_tmp);\n          break;\n        case PT_LONG:\n          printf(\"    Value: %i\\n\", *((int*)mapidata->data));\n          break;\n        case PT_I2:\n          printf(\"    Value: %hi\\n\", *((short int*)mapidata->data));\n          break;\n        case PT_BOOLEAN:\n          if (mapi->data->data[0] != 0) {\n            printf(\"    Value: True\\n\");\n          } else {\n            printf(\"    Value: False\\n\");\n          }\n          break;\n        case PT_OBJECT:\n          printf(\"\\n\");\n          break;\n        case PT_BINARY:\n          if (IsCompressedRTF(mapidata) == 1) {\n            printf(\"    Detected Compressed RTF. \");\n            printf(\"Decompressed text follows\\n\");\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n            if ((vlTemp.data = (BYTE*)DecompressRTF(mapidata, &(vlTemp.size))) != NULL) {\n              printf(\"%s\\n\", vlTemp.data);\n              free(vlTemp.data);\n            }\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n          } else {\n            printf(\"    Value: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_STRING8:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n          if (strlen((char*)mapidata->data) != mapidata->size - 1) {\n            printf(\"Detected Hidden data: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_CLSID:\n          printf(\"    Value: \");\n          printf(\"[HEX: \");\n          for(x=0; x< 16; x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"]\\n\");\n          break;\n        default:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n      }\n    }\n  }\n}", "commit_link": "github.com/Yeraze/ytnef/commit/f98f5d4adc1c4bd4033638f6167c1bb95d642f89", "file_name": "lib/ytnef.c", "vul_type": "cwe-125", "description": "Write a C function named `MAPIPrint` that prints the properties and values of a given `MAPIProps` structure."}
{"func_name": "vips_foreign_load_gif_scan_image", "func_src_before": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\tColorMapObject *map = file->Image.ColorMap ?\n\t\tfile->Image.ColorMap : file->SColorMap;\n\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "func_src_after": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\n\tColorMapObject *map;\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tmap = file->Image.ColorMap ? file->Image.ColorMap : file->SColorMap;\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "commit_link": "github.com/libvips/libvips/commit/ce684dd008532ea0bf9d4a1d89bacb35f4a83f4d", "file_name": "libvips/foreign/gifload.c", "vul_type": "cwe-416", "description": "Write a C function to scan and validate a GIF image frame for the Vips image processing library."}
{"func_name": "_connect", "func_src_before": "    def _connect(self):\n        \"\"\"Connect to the host and port specified in __init__.\"\"\"\n        if self.sock:\n            return\n        if self._proxy_host is not None:\n            logger.info('Connecting to http proxy %s:%s',\n                        self._proxy_host, self._proxy_port)\n            sock = socketutil.create_connection((self._proxy_host,\n                                                 self._proxy_port))\n            if self.ssl:\n                # TODO proxy header support\n                data = self._buildheaders('CONNECT', '%s:%d' % (self.host,\n                                                                self.port),\n                                          {}, HTTP_VER_1_0)\n                sock.send(data)\n                sock.setblocking(0)\n                r = self.response_class(sock, self.timeout, 'CONNECT')\n                timeout_exc = HTTPTimeoutException(\n                    'Timed out waiting for CONNECT response from proxy')\n                while not r.complete():\n                    try:\n                        # We're a friend of the response class, so let\n                        # us use the private attribute.\n                        # pylint: disable=W0212\n                        if not r._select():\n                            if not r.complete():\n                                raise timeout_exc\n                    except HTTPTimeoutException:\n                        # This raise/except pattern looks goofy, but\n                        # _select can raise the timeout as well as the\n                        # loop body. I wish it wasn't this convoluted,\n                        # but I don't have a better solution\n                        # immediately handy.\n                        raise timeout_exc\n                if r.status != 200:\n                    raise HTTPProxyConnectFailedException(\n                        'Proxy connection failed: %d %s' % (r.status,\n                                                            r.read()))\n                logger.info('CONNECT (for SSL) to %s:%s via proxy succeeded.',\n                            self.host, self.port)\n        else:\n            sock = socketutil.create_connection((self.host, self.port))\n        if self.ssl:\n            # This is the default, but in the case of proxied SSL\n            # requests the proxy logic above will have cleared\n            # blocking mode, so re-enable it just to be safe.\n            sock.setblocking(1)\n            logger.debug('wrapping socket for ssl with options %r',\n                         self.ssl_opts)\n            sock = socketutil.wrap_socket(sock, **self.ssl_opts)\n            if self._ssl_validator:\n                self._ssl_validator(sock)\n        sock.setblocking(0)\n        self.sock = sock", "func_src_after": "    def _connect(self):\n        \"\"\"Connect to the host and port specified in __init__.\"\"\"\n        if self.sock:\n            return\n        if self._proxy_host is not None:\n            logger.info('Connecting to http proxy %s:%s',\n                        self._proxy_host, self._proxy_port)\n            sock = socketutil.create_connection((self._proxy_host,\n                                                 self._proxy_port))\n            if self.ssl:\n                # TODO proxy header support\n                data = self._buildheaders('CONNECT', '%s:%d' % (self.host,\n                                                                self.port),\n                                          {}, HTTP_VER_1_0)\n                sock.send(data)\n                sock.setblocking(0)\n                r = self.response_class(sock, self.timeout, 'CONNECT')\n                timeout_exc = HTTPTimeoutException(\n                    'Timed out waiting for CONNECT response from proxy')\n                while not r.complete():\n                    try:\n                        # We're a friend of the response class, so let\n                        # us use the private attribute.\n                        # pylint: disable=W0212\n                        if not r._select():\n                            if not r.complete():\n                                raise timeout_exc\n                    except HTTPTimeoutException:\n                        # This raise/except pattern looks goofy, but\n                        # _select can raise the timeout as well as the\n                        # loop body. I wish it wasn't this convoluted,\n                        # but I don't have a better solution\n                        # immediately handy.\n                        raise timeout_exc\n                if r.status != 200:\n                    raise HTTPProxyConnectFailedException(\n                        'Proxy connection failed: %d %s' % (r.status,\n                                                            r.read()))\n                logger.info('CONNECT (for SSL) to %s:%s via proxy succeeded.',\n                            self.host, self.port)\n        else:\n            sock = socketutil.create_connection((self.host, self.port))\n        if self.ssl:\n            # This is the default, but in the case of proxied SSL\n            # requests the proxy logic above will have cleared\n            # blocking mode, so re-enable it just to be safe.\n            sock.setblocking(1)\n            logger.debug('wrapping socket for ssl with options %r',\n                         self.ssl_opts)\n            sock = self._ssl_wrap_socket(sock, **self.ssl_opts)\n            if self._ssl_validator:\n                self._ssl_validator(sock)\n        sock.setblocking(0)\n        self.sock = sock", "line_changes": {"deleted": [{"line_no": 50, "char_start": 2563, "char_end": 2628, "line": "            sock = socketutil.wrap_socket(sock, **self.ssl_opts)\n"}], "added": [{"line_no": 50, "char_start": 2563, "char_end": 2627, "line": "            sock = self._ssl_wrap_socket(sock, **self.ssl_opts)\n"}]}, "char_changes": {"deleted": [{"char_start": 2583, "char_end": 2593, "chars": "ocketutil."}], "added": [{"char_start": 2583, "char_end": 2592, "chars": "elf._ssl_"}]}, "commit_link": "github.com/spraints/for-example/commit/c9181d3a302d74b49165ab67dd8a42f3e25480ec", "file_name": "__init__.py", "vul_type": "cwe-327", "commit_msg": "httpclient: import 4bb625347d4a to provide SSL wrapper injection\n\nThis lets us inject our own ssl.wrap_socket equivalent into\nhttpclient, which means that any changes we make to our ssl handling\ncan be *entirely* on our side without having to muck with httpclient,\nwhich sounds appealing. For example, an extension could wrap\nsslutil.ssl_wrap_socket with an api-compatible wrapper and then tweak\nSSL settings more precisely or use GnuTLS instead of OpenSSL.", "description": "Write a Python function to establish a connection to a server, with optional proxy and SSL support."}
{"func_name": "dateproto_setMilliseconds", "func_src_before": "func (r *Runtime) dateproto_setMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := int(call.Argument(0).ToInteger())\n\t\t\td.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local)\n\t\t\treturn intToValue(timeToMsec(d.time))\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "func_src_after": "func (r *Runtime) dateproto_setMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := call.Argument(0).ToInteger()\n\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m)\n\t\t\treturn intToValue(m)\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 158, "char_end": 203, "line": "\t\t\tmsec := int(call.Argument(0).ToInteger())\n"}, {"line_no": 6, "char_start": 203, "char_end": 341, "line": "\t\t\td.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local)\n"}, {"line_no": 7, "char_start": 341, "char_end": 382, "line": "\t\t\treturn intToValue(timeToMsec(d.time))\n"}], "added": [{"line_no": 5, "char_start": 158, "char_end": 198, "line": "\t\t\tmsec := call.Argument(0).ToInteger()\n"}, {"line_no": 6, "char_start": 198, "char_end": 265, "line": "\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n"}, {"line_no": 7, "char_start": 265, "char_end": 293, "line": "\t\t\td.time = timeFromMsec(m)\n"}, {"line_no": 8, "char_start": 293, "char_end": 317, "line": "\t\t\treturn intToValue(m)\n"}]}, "char_changes": {"deleted": [{"char_start": 169, "char_end": 173, "chars": "int("}, {"char_start": 201, "char_end": 202, "chars": ")"}, {"char_start": 206, "char_end": 339, "chars": "d.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local"}, {"char_start": 362, "char_end": 380, "chars": "timeToMsec(d.time)"}], "added": [{"char_start": 201, "char_end": 291, "chars": "m := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m"}, {"char_start": 314, "char_end": 315, "chars": "m"}]}, "commit_link": "github.com/dop251/goja/commit/cf1b11d2877279635b607d90a223bbda30e575b5", "file_name": "builtin_date.go", "vul_type": "cwe-681", "commit_msg": "Avoid integer overflow in Date.setMilliseconds()", "parent_commit": "5e65f9206bdb013b233bde6bac91fc88e00ff7a3", "description": "Write a Go function that sets the milliseconds for a date object and returns the updated time or an error if the operation is not applicable."}
{"func_name": "track_header", "func_src_before": "static int track_header(VividasDemuxContext *viv, AVFormatContext *s,  uint8_t *buf, int size)\n{\n    int i, j, ret;\n    int64_t off;\n    int val_1;\n    int num_video;\n    AVIOContext pb0, *pb = &pb0;\n\n    ffio_init_context(pb, buf, size, 0, NULL, NULL, NULL, NULL);\n\n    ffio_read_varlen(pb); // track_header_len\n    avio_r8(pb); // '1'\n\n    val_1 = ffio_read_varlen(pb);\n\n    for (i=0;i<val_1;i++) {\n        int c = avio_r8(pb);\n        if (avio_feof(pb))\n            return AVERROR_EOF;\n        for (j=0;j<c;j++) {\n            if (avio_feof(pb))\n                return AVERROR_EOF;\n            avio_r8(pb); // val_3\n            avio_r8(pb); // val_4\n        }\n    }\n\n    avio_r8(pb); // num_streams\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_5\n\n    avio_r8(pb); // '2'\n    num_video = avio_r8(pb);\n\n    avio_seek(pb, off, SEEK_SET);\n    if (num_video != 1) {\n        av_log(s, AV_LOG_ERROR, \"number of video tracks %d is not 1\\n\", num_video);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    for (i = 0; i < num_video; i++) {\n        AVStream *st = avformat_new_stream(s, NULL);\n        int num, den;\n\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        st->codecpar->codec_id = AV_CODEC_ID_VP6;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb);\n        avio_r8(pb); // '3'\n        avio_r8(pb); // val_7\n        num = avio_rl32(pb); // frame_time\n        den = avio_rl32(pb); // time_base\n        avpriv_set_pts_info(st, 64, num, den);\n        st->nb_frames = avio_rl32(pb); // n frames\n        st->codecpar->width = avio_rl16(pb); // width\n        st->codecpar->height = avio_rl16(pb); // height\n        avio_r8(pb); // val_8\n        avio_rl32(pb); // val_9\n\n        avio_seek(pb, off, SEEK_SET);\n    }\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_10\n    avio_r8(pb); // '4'\n    viv->num_audio = avio_r8(pb);\n    avio_seek(pb, off, SEEK_SET);\n\n    if (viv->num_audio != 1)\n        av_log(s, AV_LOG_WARNING, \"number of audio tracks %d is not 1\\n\", viv->num_audio);\n\n    for(i=0;i<viv->num_audio;i++) {\n        int q;\n        AVStream *st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = num_video + i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n        st->codecpar->codec_id = AV_CODEC_ID_VORBIS;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb); // length\n        avio_r8(pb); // '5'\n        avio_r8(pb); //codec_id\n        avio_rl16(pb); //codec_subid\n        st->codecpar->channels = avio_rl16(pb); // channels\n        st->codecpar->sample_rate = avio_rl32(pb); // sample_rate\n        avio_seek(pb, 10, SEEK_CUR); // data_1\n        q = avio_r8(pb);\n        avio_seek(pb, q, SEEK_CUR); // data_2\n        avio_r8(pb); // zeropad\n\n        if (avio_tell(pb) < off) {\n            int num_data;\n            int xd_size = 0;\n            int data_len[256];\n            int offset = 1;\n            uint8_t *p;\n            ffio_read_varlen(pb); // val_13\n            avio_r8(pb); // '19'\n            ffio_read_varlen(pb); // len_3\n            num_data = avio_r8(pb);\n            for (j = 0; j < num_data; j++) {\n                uint64_t len = ffio_read_varlen(pb);\n                if (len > INT_MAX/2 - xd_size) {\n                    return AVERROR_INVALIDDATA;\n                }\n                data_len[j] = len;\n                xd_size += len;\n            }\n\n            ret = ff_alloc_extradata(st->codecpar, 64 + xd_size + xd_size / 255);\n            if (ret < 0)\n                return ret;\n\n            p = st->codecpar->extradata;\n            p[0] = 2;\n\n            for (j = 0; j < num_data - 1; j++) {\n                unsigned delta = av_xiphlacing(&p[offset], data_len[j]);\n                if (delta > data_len[j]) {\n                    return AVERROR_INVALIDDATA;\n                }\n                offset += delta;\n            }\n\n            for (j = 0; j < num_data; j++) {\n                int ret = avio_read(pb, &p[offset], data_len[j]);\n                if (ret < data_len[j]) {\n                    st->codecpar->extradata_size = 0;\n                    av_freep(&st->codecpar->extradata);\n                    break;\n                }\n                offset += data_len[j];\n            }\n\n            if (offset < st->codecpar->extradata_size)\n                st->codecpar->extradata_size = offset;\n        }\n    }\n\n    return 0;\n}", "func_src_after": "static int track_header(VividasDemuxContext *viv, AVFormatContext *s,  uint8_t *buf, int size)\n{\n    int i, j, ret;\n    int64_t off;\n    int val_1;\n    int num_video;\n    AVIOContext pb0, *pb = &pb0;\n\n    ffio_init_context(pb, buf, size, 0, NULL, NULL, NULL, NULL);\n\n    ffio_read_varlen(pb); // track_header_len\n    avio_r8(pb); // '1'\n\n    val_1 = ffio_read_varlen(pb);\n\n    for (i=0;i<val_1;i++) {\n        int c = avio_r8(pb);\n        if (avio_feof(pb))\n            return AVERROR_EOF;\n        for (j=0;j<c;j++) {\n            if (avio_feof(pb))\n                return AVERROR_EOF;\n            avio_r8(pb); // val_3\n            avio_r8(pb); // val_4\n        }\n    }\n\n    avio_r8(pb); // num_streams\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_5\n\n    avio_r8(pb); // '2'\n    num_video = avio_r8(pb);\n\n    avio_seek(pb, off, SEEK_SET);\n    if (num_video != 1) {\n        av_log(s, AV_LOG_ERROR, \"number of video tracks %d is not 1\\n\", num_video);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    for (i = 0; i < num_video; i++) {\n        AVStream *st = avformat_new_stream(s, NULL);\n        int num, den;\n\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        st->codecpar->codec_id = AV_CODEC_ID_VP6;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb);\n        avio_r8(pb); // '3'\n        avio_r8(pb); // val_7\n        num = avio_rl32(pb); // frame_time\n        den = avio_rl32(pb); // time_base\n        avpriv_set_pts_info(st, 64, num, den);\n        st->nb_frames = avio_rl32(pb); // n frames\n        st->codecpar->width = avio_rl16(pb); // width\n        st->codecpar->height = avio_rl16(pb); // height\n        avio_r8(pb); // val_8\n        avio_rl32(pb); // val_9\n\n        avio_seek(pb, off, SEEK_SET);\n    }\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_10\n    avio_r8(pb); // '4'\n    viv->num_audio = avio_r8(pb);\n    avio_seek(pb, off, SEEK_SET);\n\n    if (viv->num_audio != 1)\n        av_log(s, AV_LOG_WARNING, \"number of audio tracks %d is not 1\\n\", viv->num_audio);\n\n    for(i=0;i<viv->num_audio;i++) {\n        int q;\n        AVStream *st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = num_video + i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n        st->codecpar->codec_id = AV_CODEC_ID_VORBIS;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb); // length\n        avio_r8(pb); // '5'\n        avio_r8(pb); //codec_id\n        avio_rl16(pb); //codec_subid\n        st->codecpar->channels = avio_rl16(pb); // channels\n        st->codecpar->sample_rate = avio_rl32(pb); // sample_rate\n        avio_seek(pb, 10, SEEK_CUR); // data_1\n        q = avio_r8(pb);\n        avio_seek(pb, q, SEEK_CUR); // data_2\n        avio_r8(pb); // zeropad\n\n        if (avio_tell(pb) < off) {\n            int num_data;\n            int xd_size = 1;\n            int data_len[256];\n            int offset = 1;\n            uint8_t *p;\n            ffio_read_varlen(pb); // val_13\n            avio_r8(pb); // '19'\n            ffio_read_varlen(pb); // len_3\n            num_data = avio_r8(pb);\n            for (j = 0; j < num_data; j++) {\n                uint64_t len = ffio_read_varlen(pb);\n                if (len > INT_MAX/2 - xd_size) {\n                    return AVERROR_INVALIDDATA;\n                }\n                data_len[j] = len;\n                xd_size += len + 1 + len/255;\n            }\n\n            ret = ff_alloc_extradata(st->codecpar, xd_size);\n            if (ret < 0)\n                return ret;\n\n            p = st->codecpar->extradata;\n            p[0] = 2;\n\n            for (j = 0; j < num_data - 1; j++) {\n                unsigned delta = av_xiphlacing(&p[offset], data_len[j]);\n                av_assert0(delta <= xd_size - offset);\n                offset += delta;\n            }\n\n            for (j = 0; j < num_data; j++) {\n                int ret = avio_read(pb, &p[offset], data_len[j]);\n                if (ret < data_len[j]) {\n                    st->codecpar->extradata_size = 0;\n                    av_freep(&st->codecpar->extradata);\n                    break;\n                }\n                av_assert0(data_len[j] <= xd_size - offset);\n                offset += data_len[j];\n            }\n\n            if (offset < st->codecpar->extradata_size)\n                st->codecpar->extradata_size = offset;\n        }\n    }\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/27a99e2c7d450fef15594671eef4465c8a166bd7", "file_name": "libavformat/vividas.c", "vul_type": "cwe-787", "description": "Write a C function to parse video and audio track headers from a buffer in an AVFormatContext using FFmpeg libraries."}
{"func_name": "create_dump_dir_from_problem_data", "func_src_before": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        /* only files should contain '/' and those are handled earlier */\n        if (name[0] == '.' || strchr(name, '/'))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "func_src_after": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    if (!str_is_correct_filename(type))\n    {\n        error_msg(_(\"'%s' is not correct file name\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (!str_is_correct_filename(name))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/create_dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function to initialize a dump directory with problem data, handling errors and creating necessary files."}
{"func_name": "zmi_page_request", "func_src_before": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "func_src_after": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if self.getDocumentElement().id in path and len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "commit_link": "github.com/zms-publishing/zms4/commit/3f28620d475220dfdb06f79787158ac50727c61a", "file_name": "ZMSItem.py", "vul_type": "cwe-022", "description": "Write a Python function named `zmi_page_request` that modifies HTTP response headers, manages session variables, and redirects to a normalized URL if necessary."}
{"func_name": "_call_external_zip", "func_src_before": "def _call_external_zip(base_dir, zip_filename, verbose=False, dry_run=False):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    from distutils.errors import DistutilsExecError\n    from distutils.spawn import spawn\n    try:\n        spawn([\"zip\", zipoptions, zip_filename, base_dir], dry_run=dry_run)\n    except DistutilsExecError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError, \\\n            (\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename", "func_src_after": "def _call_external_zip(base_dir, zip_filename, verbose, dry_run, logger):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    cmd = [\"zip\", zipoptions, zip_filename, base_dir]\n    if logger is not None:\n        logger.info(' '.join(cmd))\n    if dry_run:\n        return\n    import subprocess\n    try:\n        subprocess.check_call(cmd)\n    except subprocess.CalledProcessError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError, \\\n            (\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename", "commit_link": "github.com/python/cpython/commit/add531a1e55b0a739b0f42582f1c9747e5649ace", "file_name": "Lib/shutil.py", "vul_type": "cwe-078", "description": "Write a Python function to execute an external `zip` command with options for verbosity and dry run, and optionally log the command."}
{"func_name": "is_cgi", "func_src_before": "    def is_cgi(self):\n        \"\"\"Test whether self.path corresponds to a CGI script,\n        and return a boolean.\n\n        This function sets self.cgi_info to a tuple (dir, rest)\n        when it returns True, where dir is the directory part before\n        the CGI script name.  Note that rest begins with a\n        slash if it is not empty.\n\n        The default implementation tests whether the path\n        begins with one of the strings in the list\n        self.cgi_directories (and the next character is a '/'\n        or the end of the string).\n        \"\"\"\n\n        path = self.path\n\n        for x in self.cgi_directories:\n            i = len(x)\n            if path[:i] == x and (not path[i:] or path[i] == '/'):\n                self.cgi_info = path[:i], path[i+1:]\n                return True\n        return False", "func_src_after": "    def is_cgi(self):\n        \"\"\"Test whether self.path corresponds to a CGI script.\n\n        Returns True and updates the cgi_info attribute to the tuple\n        (dir, rest) if self.path requires running a CGI script.\n        Returns False otherwise.\n\n        The default implementation tests whether the normalized url\n        path begins with one of the strings in self.cgi_directories\n        (and the next character is a '/' or the end of the string).\n        \"\"\"\n        splitpath = _url_collapse_path_split(self.path)\n        if splitpath[0] in self.cgi_directories:\n            self.cgi_info = splitpath\n            return True\n        return False", "commit_link": "github.com/Ricky-Wilson/Python/commit/c5abced949e6a4b001d1dee321593e74ecadecfe", "file_name": "Lib/CGIHTTPServer.py", "vul_type": "cwe-022", "description": "Create a Python function that checks if a given path is a CGI script and updates an attribute with the script's directory information."}
{"func_name": "main", "func_src_before": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor dataset in args.dataset:\n\t\twith open(dataset) as handle:\n\t\t\tdata = data + load(handle)\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "func_src_after": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor filepath in args.dataset:\n\t\tdata.extend(load_data(filepath))\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "line_changes": {"deleted": [{"line_no": 41, "char_start": 2466, "char_end": 2496, "line": "\tfor dataset in args.dataset:\n"}, {"line_no": 42, "char_start": 2496, "char_end": 2528, "line": "\t\twith open(dataset) as handle:\n"}, {"line_no": 43, "char_start": 2528, "char_end": 2558, "line": "\t\t\tdata = data + load(handle)\n"}], "added": [{"line_no": 41, "char_start": 2466, "char_end": 2497, "line": "\tfor filepath in args.dataset:\n"}, {"line_no": 42, "char_start": 2497, "char_end": 2532, "line": "\t\tdata.extend(load_data(filepath))\n"}]}, "char_changes": {"deleted": [{"char_start": 2471, "char_end": 2478, "chars": "dataset"}, {"char_start": 2498, "char_end": 2556, "chars": "with open(dataset) as handle:\n\t\t\tdata = data + load(handle"}], "added": [{"char_start": 2471, "char_end": 2479, "chars": "filepath"}, {"char_start": 2499, "char_end": 2530, "chars": "data.extend(load_data(filepath)"}]}, "commit_link": "github.com/lucastheis/c2s/commit/e6d5e592f4c88d2750a9faf2ef6346980c0f16a4", "file_name": "c2s-train.py", "vul_type": "cwe-502", "commit_msg": "Use c2s.load_data() instead of pickle.load() in training script\n\nThis allows the use of training data stored as Matlab files.", "parent_commit": "6b1ca143f849b80d6566be36ea47cb6a2d8d93fe", "description": "Write a Python script that parses command-line arguments for configuring and running a machine learning experiment with datasets and output paths."}
{"func_name": "verify_rno", "func_src_before": "    def verify_rno(self, rno):\n        query = \"SELECT COUNT(rno) FROM rides WHERE rno = {rno}\".format(rno = rno)\n        self.cursor.execute(query)\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "func_src_after": "    def verify_rno(self, rno):\n        self.cursor.execute(\"SELECT COUNT(rno) FROM rides WHERE rno = :rno\", {'rno': rno})\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "commit_link": "github.com/kenboo98/291-Mini-Project-I/commit/3080ccb687c79c83954ce703faee8fcceec8c9eb", "file_name": "book_rides/book_rides.py", "vul_type": "cwe-089", "description": "Write a Python function to check if a ride number exists in a database using SQL queries."}
{"func_name": "avr_op_analyze", "func_src_before": "static OPCODE_DESC* avr_op_analyze(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *buf, int len, CPU_MODEL *cpu) {\n\tOPCODE_DESC *opcode_desc;\n\tut16 ins = (buf[1] << 8) | buf[0];\n\tint fail;\n\tchar *t;\n\n\t// initialize op struct\n\tmemset (op, 0, sizeof (RAnalOp));\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->jump = UT64_MAX;\n\tr_strbuf_init (&op->esil);\n\n\t// process opcode\n\tfor (opcode_desc = opcodes; opcode_desc->handler; opcode_desc++) {\n\t\tif ((ins & opcode_desc->mask) == opcode_desc->selector) {\n\t\t\tfail = 0;\n\n\t\t\t// copy default cycles/size values\n\t\t\top->cycles = opcode_desc->cycles;\n\t\t\top->size = opcode_desc->size;\n\t\t\top->type = opcode_desc->type;\n\t\t\top->jump = UT64_MAX;\n\t\t\top->fail = UT64_MAX;\n\t\t\t// op->fail = addr + op->size;\n\t\t\top->addr = addr;\n\n\t\t\t// start void esil expression\n\t\t\tr_strbuf_setf (&op->esil, \"\");\n\n\t\t\t// handle opcode\n\t\t\topcode_desc->handler (anal, op, buf, len, &fail, cpu);\n\t\t\tif (fail) {\n\t\t\t\tgoto INVALID_OP;\n\t\t\t}\n\t\t\tif (op->cycles <= 0) {\n\t\t\t\t// eprintf (\"opcode %s @%\"PFMT64x\" returned 0 cycles.\\n\", opcode_desc->name, op->addr);\n\t\t\t\topcode_desc->cycles = 2;\n\t\t\t}\n\t\t\top->nopcode = (op->type == R_ANAL_OP_TYPE_UNK);\n\n\t\t\t// remove trailing coma (COMETE LA COMA)\n\t\t\tt = r_strbuf_get (&op->esil);\n\t\t\tif (t && strlen (t) > 1) {\n\t\t\t\tt += strlen (t) - 1;\n\t\t\t\tif (*t == ',') {\n\t\t\t\t\t*t = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn opcode_desc;\n\t\t}\n\t}\n\n\t// ignore reserved opcodes (if they have not been caught by the previous loop)\n\tif ((ins & 0xff00) == 0xff00 && (ins & 0xf) > 7) {\n\t\tgoto INVALID_OP;\n\t}\n\nINVALID_OP:\n\t// An unknown or invalid option has appeared.\n\t//  -- Throw pokeball!\n\top->family = R_ANAL_OP_FAMILY_UNKNOWN;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->addr = addr;\n\top->fail = UT64_MAX;\n\top->jump = UT64_MAX;\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->nopcode = 1;\n\top->cycles = 1;\n\top->size = 2;\n\t// launch esil trap (for communicating upper layers about this weird\n\t// and stinky situation\n\tr_strbuf_set (&op->esil, \"1,$\");\n\n\treturn NULL;\n}", "func_src_after": "static OPCODE_DESC* avr_op_analyze(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *buf, int len, CPU_MODEL *cpu) {\n\tOPCODE_DESC *opcode_desc;\n\tif (len < 2) {\n\t\treturn NULL;\n\t}\n\tut16 ins = (buf[1] << 8) | buf[0];\n\tint fail;\n\tchar *t;\n\n\t// initialize op struct\n\tmemset (op, 0, sizeof (RAnalOp));\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->jump = UT64_MAX;\n\tr_strbuf_init (&op->esil);\n\n\t// process opcode\n\tfor (opcode_desc = opcodes; opcode_desc->handler; opcode_desc++) {\n\t\tif ((ins & opcode_desc->mask) == opcode_desc->selector) {\n\t\t\tfail = 0;\n\n\t\t\t// copy default cycles/size values\n\t\t\top->cycles = opcode_desc->cycles;\n\t\t\top->size = opcode_desc->size;\n\t\t\top->type = opcode_desc->type;\n\t\t\top->jump = UT64_MAX;\n\t\t\top->fail = UT64_MAX;\n\t\t\t// op->fail = addr + op->size;\n\t\t\top->addr = addr;\n\n\t\t\t// start void esil expression\n\t\t\tr_strbuf_setf (&op->esil, \"\");\n\n\t\t\t// handle opcode\n\t\t\topcode_desc->handler (anal, op, buf, len, &fail, cpu);\n\t\t\tif (fail) {\n\t\t\t\tgoto INVALID_OP;\n\t\t\t}\n\t\t\tif (op->cycles <= 0) {\n\t\t\t\t// eprintf (\"opcode %s @%\"PFMT64x\" returned 0 cycles.\\n\", opcode_desc->name, op->addr);\n\t\t\t\topcode_desc->cycles = 2;\n\t\t\t}\n\t\t\top->nopcode = (op->type == R_ANAL_OP_TYPE_UNK);\n\n\t\t\t// remove trailing coma (COMETE LA COMA)\n\t\t\tt = r_strbuf_get (&op->esil);\n\t\t\tif (t && strlen (t) > 1) {\n\t\t\t\tt += strlen (t) - 1;\n\t\t\t\tif (*t == ',') {\n\t\t\t\t\t*t = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn opcode_desc;\n\t\t}\n\t}\n\n\t// ignore reserved opcodes (if they have not been caught by the previous loop)\n\tif ((ins & 0xff00) == 0xff00 && (ins & 0xf) > 7) {\n\t\tgoto INVALID_OP;\n\t}\n\nINVALID_OP:\n\t// An unknown or invalid option has appeared.\n\t//  -- Throw pokeball!\n\top->family = R_ANAL_OP_FAMILY_UNKNOWN;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->addr = addr;\n\top->fail = UT64_MAX;\n\top->jump = UT64_MAX;\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->nopcode = 1;\n\top->cycles = 1;\n\top->size = 2;\n\t// launch esil trap (for communicating upper layers about this weird\n\t// and stinky situation\n\tr_strbuf_set (&op->esil, \"1,$\");\n\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/b35530fa0681b27eba084de5527037ebfb397422", "file_name": "libr/anal/p/anal_avr.c", "vul_type": "cwe-125", "description": "Write a C function named `avr_op_analyze` for analyzing AVR opcodes and updating the analysis structure."}
{"func_name": "wddx_stack_destroy", "func_src_before": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "func_src_after": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "commit_link": "github.com/php/php-src/commit/b88393f08a558eec14964a55d3c680fe67407712?w=1", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-416", "description": "Write a function in C to destroy a stack, deallocating any dynamic memory used by its elements."}
{"func_name": "PHP_MINIT_FUNCTION", "func_src_before": "static PHP_MINIT_FUNCTION(zip)\n{\n#ifdef PHP_ZIP_USE_OO\n\tzend_class_entry ce;\n\n\tmemcpy(&zip_object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\tzip_object_handlers.clone_obj\t\t= NULL;\n\tzip_object_handlers.get_property_ptr_ptr = php_zip_get_property_ptr_ptr;\n\n\tzip_object_handlers.get_gc          = php_zip_get_gc;\n\tzip_object_handlers.get_properties = php_zip_get_properties;\n\tzip_object_handlers.read_property\t= php_zip_read_property;\n\tzip_object_handlers.has_property\t= php_zip_has_property;\n\n\tINIT_CLASS_ENTRY(ce, \"ZipArchive\", zip_class_functions);\n\tce.create_object = php_zip_object_new;\n\tzip_class_entry = zend_register_internal_class(&ce TSRMLS_CC);\n\n\tzend_hash_init(&zip_prop_handlers, 0, NULL, NULL, 1);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"status\",    php_zip_status, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"statusSys\", php_zip_status_sys, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"numFiles\",  php_zip_get_num_files, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"filename\", NULL, NULL, php_zipobj_get_filename, IS_STRING TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"comment\", NULL, php_zipobj_get_zip_comment, NULL, IS_STRING TSRMLS_CC);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CREATE\", ZIP_CREATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"EXCL\", ZIP_EXCL);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CHECKCONS\", ZIP_CHECKCONS);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"OVERWRITE\", ZIP_OVERWRITE);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NOCASE\", ZIP_FL_NOCASE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NODIR\", ZIP_FL_NODIR);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_COMPRESSED\", ZIP_FL_COMPRESSED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_UNCHANGED\", ZIP_FL_UNCHANGED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFAULT\", ZIP_CM_DEFAULT);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_STORE\", ZIP_CM_STORE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_SHRINK\", ZIP_CM_SHRINK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_1\", ZIP_CM_REDUCE_1);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_2\", ZIP_CM_REDUCE_2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_3\", ZIP_CM_REDUCE_3);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_4\", ZIP_CM_REDUCE_4);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_IMPLODE\", ZIP_CM_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE\", ZIP_CM_DEFLATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE64\", ZIP_CM_DEFLATE64);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PKWARE_IMPLODE\", ZIP_CM_PKWARE_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_BZIP2\", ZIP_CM_BZIP2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZMA\", ZIP_CM_LZMA);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_TERSE\", ZIP_CM_TERSE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZ77\", ZIP_CM_LZ77);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_WAVPACK\", ZIP_CM_WAVPACK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PPMD\", ZIP_CM_PPMD);\n\n\t/* Error code */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OK\",\t\t\tZIP_ER_OK);\t\t\t/* N No error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MULTIDISK\",\tZIP_ER_MULTIDISK);\t/* N Multi-disk zip archives not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_RENAME\",\t\tZIP_ER_RENAME);\t\t/* S Renaming temporary file failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CLOSE\",\t\tZIP_ER_CLOSE);\t\t/* S Closing zip archive failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_SEEK\",\t\tZIP_ER_SEEK);\t\t/* S Seek error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_READ\",\t\tZIP_ER_READ);\t\t/* S Read error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_WRITE\",\t\tZIP_ER_WRITE);\t\t/* S Write error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CRC\",\t\t\tZIP_ER_CRC);\t\t/* N CRC error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZIPCLOSED\",\tZIP_ER_ZIPCLOSED);\t/* N Containing zip archive was closed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOENT\",\t\tZIP_ER_NOENT);\t\t/* N No such file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EXISTS\",\t\tZIP_ER_EXISTS);\t\t/* N File already exists */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OPEN\",\t\tZIP_ER_OPEN);\t\t/* S Can't open file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_TMPOPEN\",\t\tZIP_ER_TMPOPEN);\t/* S Failure to create temporary file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZLIB\",\t\tZIP_ER_ZLIB);\t\t/* Z Zlib error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MEMORY\",\t\tZIP_ER_MEMORY);\t\t/* N Malloc failure */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CHANGED\",\t\tZIP_ER_CHANGED);\t/* N Entry has been changed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_COMPNOTSUPP\",\tZIP_ER_COMPNOTSUPP);/* N Compression method not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EOF\",\t\t\tZIP_ER_EOF);\t\t/* N Premature EOF */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INVAL\",\t\tZIP_ER_INVAL);\t\t/* N Invalid argument */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOZIP\",\t\tZIP_ER_NOZIP);\t\t/* N Not a zip archive */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INTERNAL\",\tZIP_ER_INTERNAL);\t/* N Internal error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INCONS\",\t\tZIP_ER_INCONS);\t\t/* N Zip archive inconsistent */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_REMOVE\",\t\tZIP_ER_REMOVE);\t\t/* S Can't remove file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_DELETED\",  \tZIP_ER_DELETED);\t/* N Entry has been deleted */\n\n\tphp_register_url_stream_wrapper(\"zip\", &php_stream_zip_wrapper TSRMLS_CC);\n#endif\n\n\tle_zip_dir   = zend_register_list_destructors_ex(php_zip_free_dir,   NULL, le_zip_dir_name,   module_number);\n\tle_zip_entry = zend_register_list_destructors_ex(php_zip_free_entry, NULL, le_zip_entry_name, module_number);\n\n\treturn SUCCESS;\n}", "func_src_after": "static PHP_MINIT_FUNCTION(zip)\n{\n#ifdef PHP_ZIP_USE_OO\n\tzend_class_entry ce;\n\n\tmemcpy(&zip_object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\tzip_object_handlers.clone_obj\t\t= NULL;\n\tzip_object_handlers.get_property_ptr_ptr = php_zip_get_property_ptr_ptr;\n\n\tzip_object_handlers.get_gc          = php_zip_get_gc;\n\tzip_object_handlers.get_properties = php_zip_get_properties;\n\tzip_object_handlers.read_property\t= php_zip_read_property;\n\tzip_object_handlers.has_property\t= php_zip_has_property;\n\n\tINIT_CLASS_ENTRY(ce, \"ZipArchive\", zip_class_functions);\n\tce.create_object = php_zip_object_new;\n\tzip_class_entry = zend_register_internal_class(&ce TSRMLS_CC);\n\n\tzend_hash_init(&zip_prop_handlers, 0, NULL, NULL, 1);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"status\",    php_zip_status, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"statusSys\", php_zip_status_sys, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"numFiles\",  php_zip_get_num_files, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"filename\", NULL, NULL, php_zipobj_get_filename, IS_STRING TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"comment\", NULL, php_zipobj_get_zip_comment, NULL, IS_STRING TSRMLS_CC);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CREATE\", ZIP_CREATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"EXCL\", ZIP_EXCL);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CHECKCONS\", ZIP_CHECKCONS);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"OVERWRITE\", ZIP_OVERWRITE);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NOCASE\", ZIP_FL_NOCASE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NODIR\", ZIP_FL_NODIR);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_COMPRESSED\", ZIP_FL_COMPRESSED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_UNCHANGED\", ZIP_FL_UNCHANGED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFAULT\", ZIP_CM_DEFAULT);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_STORE\", ZIP_CM_STORE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_SHRINK\", ZIP_CM_SHRINK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_1\", ZIP_CM_REDUCE_1);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_2\", ZIP_CM_REDUCE_2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_3\", ZIP_CM_REDUCE_3);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_4\", ZIP_CM_REDUCE_4);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_IMPLODE\", ZIP_CM_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE\", ZIP_CM_DEFLATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE64\", ZIP_CM_DEFLATE64);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PKWARE_IMPLODE\", ZIP_CM_PKWARE_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_BZIP2\", ZIP_CM_BZIP2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZMA\", ZIP_CM_LZMA);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_TERSE\", ZIP_CM_TERSE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZ77\", ZIP_CM_LZ77);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_WAVPACK\", ZIP_CM_WAVPACK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PPMD\", ZIP_CM_PPMD);\n\n\t/* Error code */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OK\",\t\t\tZIP_ER_OK);\t\t\t/* N No error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MULTIDISK\",\tZIP_ER_MULTIDISK);\t/* N Multi-disk zip archives not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_RENAME\",\t\tZIP_ER_RENAME);\t\t/* S Renaming temporary file failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CLOSE\",\t\tZIP_ER_CLOSE);\t\t/* S Closing zip archive failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_SEEK\",\t\tZIP_ER_SEEK);\t\t/* S Seek error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_READ\",\t\tZIP_ER_READ);\t\t/* S Read error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_WRITE\",\t\tZIP_ER_WRITE);\t\t/* S Write error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CRC\",\t\t\tZIP_ER_CRC);\t\t/* N CRC error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZIPCLOSED\",\tZIP_ER_ZIPCLOSED);\t/* N Containing zip archive was closed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOENT\",\t\tZIP_ER_NOENT);\t\t/* N No such file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EXISTS\",\t\tZIP_ER_EXISTS);\t\t/* N File already exists */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OPEN\",\t\tZIP_ER_OPEN);\t\t/* S Can't open file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_TMPOPEN\",\t\tZIP_ER_TMPOPEN);\t/* S Failure to create temporary file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZLIB\",\t\tZIP_ER_ZLIB);\t\t/* Z Zlib error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MEMORY\",\t\tZIP_ER_MEMORY);\t\t/* N Malloc failure */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CHANGED\",\t\tZIP_ER_CHANGED);\t/* N Entry has been changed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_COMPNOTSUPP\",\tZIP_ER_COMPNOTSUPP);/* N Compression method not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EOF\",\t\t\tZIP_ER_EOF);\t\t/* N Premature EOF */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INVAL\",\t\tZIP_ER_INVAL);\t\t/* N Invalid argument */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOZIP\",\t\tZIP_ER_NOZIP);\t\t/* N Not a zip archive */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INTERNAL\",\tZIP_ER_INTERNAL);\t/* N Internal error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INCONS\",\t\tZIP_ER_INCONS);\t\t/* N Zip archive inconsistent */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_REMOVE\",\t\tZIP_ER_REMOVE);\t\t/* S Can't remove file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_DELETED\",  \tZIP_ER_DELETED);\t/* N Entry has been deleted */\n\n\tphp_register_url_stream_wrapper(\"zip\", &php_stream_zip_wrapper TSRMLS_CC);\n#endif\n\n\tle_zip_dir   = zend_register_list_destructors_ex(php_zip_free_dir,   NULL, le_zip_dir_name,   module_number);\n\tle_zip_entry = zend_register_list_destructors_ex(php_zip_free_entry, NULL, le_zip_entry_name, module_number);\n\n\treturn SUCCESS;\n}", "commit_link": "github.com/php/php-src/commit/f6aef68089221c5ea047d4a74224ee3deead99a6?w=1", "file_name": "ext/zip/php_zip.c", "vul_type": "cwe-416", "description": "Write a PHP function to initialize the Zip extension with object-oriented features and resource destructors."}
{"func_name": "searchAll", "func_src_before": "function searchAll() {\n    scheduler.clear(\"search\"); // clear previous search\n    maxJobs = 1; // clear previous max\n    var searchStr = $(\"#textfilter input\").attr(\"value\").trim() || '';\n\n    if (searchStr === '') {\n        $(\"div#search-results\").hide();\n        $(\"#search > span.close-results\").hide();\n        $(\"#search > span#doc-title\").show();\n        return;\n    }\n\n    // Replace ?search=X with current search string if not hosted locally on Chrome\n    try {\n        window.history.replaceState({}, \"\", \"?search=\" + searchStr);\n    } catch(e) {}\n\n    $(\"div#results-content > span.search-text\").remove();\n\n    var memberResults = document.getElementById(\"member-results\");\n    memberResults.innerHTML = \"\";\n    var memberH1 = document.createElement(\"h1\");\n    memberH1.className = \"result-type\";\n    memberH1.innerHTML = \"Member results\";\n    memberResults.appendChild(memberH1);\n\n    var entityResults = document.getElementById(\"entity-results\");\n    entityResults.innerHTML = \"\";\n    var entityH1 = document.createElement(\"h1\");\n    entityH1.className = \"result-type\";\n    entityH1.innerHTML = \"Entity results\";\n    entityResults.appendChild(entityH1);\n\n    $(\"div#results-content\")\n        .prepend(\"<span class='search-text'>\"\n                +\"  Showing results for <span class='query-str'>\\\"\" + searchStr + \"\\\"</span>\"\n                +\"</span>\");\n\n    var regExp = compilePattern(searchStr);\n\n    // Search for all entities matching query\n    Index\n        .keys(Index.PACKAGES)\n        .sort()\n        .forEach(function(elem) { searchPackage(elem, regExp); })\n}", "func_src_after": "function searchAll() {\n    scheduler.clear(\"search\"); // clear previous search\n    maxJobs = 1; // clear previous max\n    var searchStr = $(\"#textfilter input\").attr(\"value\").trim() || '';\n    searchStr = escape(searchStr);\n\n    if (searchStr === '') {\n        $(\"div#search-results\").hide();\n        $(\"#search > span.close-results\").hide();\n        $(\"#search > span#doc-title\").show();\n        return;\n    }\n\n    // Replace ?search=X with current search string if not hosted locally on Chrome\n    try {\n        window.history.replaceState({}, \"\", \"?search=\" + searchStr);\n    } catch(e) {}\n\n    $(\"div#results-content > span.search-text\").remove();\n\n    var memberResults = document.getElementById(\"member-results\");\n    memberResults.innerHTML = \"\";\n    var memberH1 = document.createElement(\"h1\");\n    memberH1.className = \"result-type\";\n    memberH1.innerHTML = \"Member results\";\n    memberResults.appendChild(memberH1);\n\n    var entityResults = document.getElementById(\"entity-results\");\n    entityResults.innerHTML = \"\";\n    var entityH1 = document.createElement(\"h1\");\n    entityH1.className = \"result-type\";\n    entityH1.innerHTML = \"Entity results\";\n    entityResults.appendChild(entityH1);\n\n    $(\"div#results-content\")\n        .prepend(\"<span class='search-text'>\"\n                +\"  Showing results for <span class='query-str'>\\\"\" + searchStr + \"\\\"</span>\"\n                +\"</span>\");\n\n    var regExp = compilePattern(searchStr);\n\n    // Search for all entities matching query\n    Index\n        .keys(Index.PACKAGES)\n        .sort()\n        .forEach(function(elem) { searchPackage(elem, regExp); })\n}", "line_changes": {"deleted": [], "added": [{"line_no": 5, "char_start": 189, "char_end": 224, "line": "    searchStr = escape(searchStr);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 188, "char_end": 223, "chars": "\n    searchStr = escape(searchStr);"}]}, "commit_link": "github.com/lrytz/scala/commit/ee2719585e40cb4e9e523e20061a6a2075f4d49d", "file_name": "index.js", "vul_type": "cwe-079", "commit_msg": "fix XSS vulnerability in scaladoc search\n\nto trigger XSS vuln, simply paste this into the search bar:\n```\n\"\\><img/src='1'onerror=alert(777111)>{{7*7}}\n```\n\nall credit for finding the vulnerability goes to *Yeasir Arafat* <skylinearafat@gmail.com>", "description": "Write a JavaScript function named `searchAll` that handles a search input, updates the browser's URL, and displays search results for members and entities."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(\n                data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/JeremiahO/crimemap/commit/c17537fcd7aa4e2a26f7ca5cefaeb356ff646858", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function named `add_input` that inserts user-provided data into a database table named `crimes`, but ensure the first snippet is vulnerable to SQL injection while the second is not."}
{"func_name": "get", "func_src_before": "    def get(self, key):\n        try:\n            result = self.etcd.get(os.path.join(self.namespace, key))\n        except etcd.EtcdException as err:\n            log_error(\"Error fetching key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to get key')\n        return result.value", "func_src_after": "    def get(self, key):\n        try:\n            result = self.etcd.get(self._absolute_key(key))\n        except etcd.EtcdException as err:\n            log_error(\"Error fetching key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to get key')\n        return result.value", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python method named `get` that retrieves a value from an etcd store by a given key, logs an error, and raises a custom exception if the retrieval fails."}
{"func_name": "ring_buffer_resize", "func_src_before": "int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tsize = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\tsize *= BUF_PAGE_SIZE;\n\n\t/* we need a minimum of two pages */\n\tif (size < BUF_PAGE_SIZE * 2)\n\t\tsize = BUF_PAGE_SIZE * 2;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been intitialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}", "func_src_after": "int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/* we need a minimum of two pages */\n\tif (nr_pages < 2)\n\t\tnr_pages = 2;\n\n\tsize = nr_pages * BUF_PAGE_SIZE;\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been intitialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/59643d1535eb220668692a5359de22545af579f6", "file_name": "kernel/trace/ring_buffer.c", "vul_type": "cwe-190", "description": "Write a C function to resize a ring buffer for a specific CPU or all CPUs, handling memory allocation and synchronization issues."}
{"func_name": "add_translationname", "func_src_before": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (\"%s\", \"%s\", \"%s\")' % (item[0], trname[1], trname[2]))\n            self.connection.commit()", "func_src_after": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                t = (item[0], trname[1], trname[2], )\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (?, ?, ?)', t)\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new translation into a database given an item name and translation details."}
{"func_name": "test_dynamic_dependencies", "func_src_before": "    def test_dynamic_dependencies(self):\n\n        class DynamicRequires(Task):\n            p = luigi.Parameter()\n\n            def output(self):\n                return luigi.LocalTarget(os.path.join(self.p, 'parent'))\n\n            def run(self):\n                dummy_targets = yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                     for i in range(5)]\n                dummy_targets += yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                       for i in range(5, 7)]\n                with self.output().open('w') as f:\n                    for i, d in enumerate(dummy_targets):\n                        for line in d.open('r'):\n                            print >>f, '%d: %s' % (i, line.strip())\n\n        t = DynamicRequires(p=tempfile.mktemp())\n        luigi.build([t], local_scheduler=True)\n        self.assertTrue(t.complete())\n\n        # loop through output and verify\n        f = t.output().open('r')\n        for i in xrange(7):\n            self.assertEqual(f.readline().strip(), '%d: Done!' % i)", "func_src_after": "    def test_dynamic_dependencies(self):\n\n        class DynamicRequires(Task):\n            p = luigi.Parameter()\n\n            def output(self):\n                return luigi.LocalTarget(os.path.join(self.p, 'parent'))\n\n            def run(self):\n                dummy_targets = yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                     for i in range(5)]\n                dummy_targets += yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                       for i in range(5, 7)]\n                with self.output().open('w') as f:\n                    for i, d in enumerate(dummy_targets):\n                        for line in d.open('r'):\n                            print >>f, '%d: %s' % (i, line.strip())\n\n        p = tempfile.mkdtemp()\n        try:\n            t = DynamicRequires(p=p)\n            luigi.build([t], local_scheduler=True)\n            self.assertTrue(t.complete())\n\n            # loop through output and verify\n            f = t.output().open('r')\n            for i in xrange(7):\n                self.assertEqual(f.readline().strip(), '%d: Done!' % i)\n        finally:\n            shutil.rmtree(p)", "line_changes": {"deleted": [{"line_no": 19, "char_start": 762, "char_end": 811, "line": "        t = DynamicRequires(p=tempfile.mktemp())\n"}, {"line_no": 20, "char_start": 811, "char_end": 858, "line": "        luigi.build([t], local_scheduler=True)\n"}, {"line_no": 21, "char_start": 858, "char_end": 896, "line": "        self.assertTrue(t.complete())\n"}, {"line_no": 22, "char_start": 896, "char_end": 897, "line": "\n"}, {"line_no": 24, "char_start": 938, "char_end": 971, "line": "        f = t.output().open('r')\n"}, {"line_no": 25, "char_start": 971, "char_end": 999, "line": "        for i in xrange(7):\n"}, {"line_no": 26, "char_start": 999, "char_end": 1066, "line": "            self.assertEqual(f.readline().strip(), '%d: Done!' % i)\n"}], "added": [{"line_no": 19, "char_start": 762, "char_end": 793, "line": "        p = tempfile.mkdtemp()\n"}, {"line_no": 20, "char_start": 793, "char_end": 806, "line": "        try:\n"}, {"line_no": 21, "char_start": 806, "char_end": 843, "line": "            t = DynamicRequires(p=p)\n"}, {"line_no": 22, "char_start": 843, "char_end": 894, "line": "            luigi.build([t], local_scheduler=True)\n"}, {"line_no": 23, "char_start": 894, "char_end": 936, "line": "            self.assertTrue(t.complete())\n"}, {"line_no": 24, "char_start": 936, "char_end": 937, "line": "\n"}, {"line_no": 26, "char_start": 982, "char_end": 1019, "line": "            f = t.output().open('r')\n"}, {"line_no": 27, "char_start": 1019, "char_end": 1051, "line": "            for i in xrange(7):\n"}, {"line_no": 28, "char_start": 1051, "char_end": 1123, "line": "                self.assertEqual(f.readline().strip(), '%d: Done!' % i)\n"}, {"line_no": 29, "char_start": 1123, "char_end": 1140, "line": "        finally:\n"}, {"line_no": 30, "char_start": 1140, "char_end": 1168, "line": "            shutil.rmtree(p)\n"}]}, "char_changes": {"deleted": [{"char_start": 792, "char_end": 811, "chars": "tempfile.mktemp())\n"}], "added": [{"char_start": 762, "char_end": 810, "chars": "        p = tempfile.mkdtemp()\n        try:\n    "}, {"char_start": 840, "char_end": 846, "chars": "p)\n   "}, {"char_start": 854, "char_end": 855, "chars": " "}, {"char_start": 902, "char_end": 906, "chars": "    "}, {"char_start": 937, "char_end": 941, "chars": "    "}, {"char_start": 990, "char_end": 994, "chars": "    "}, {"char_start": 1019, "char_end": 1023, "chars": "    "}, {"char_start": 1063, "char_end": 1067, "chars": "    "}, {"char_start": 1122, "char_end": 1168, "chars": "\n        finally:\n            shutil.rmtree(p)"}]}, "commit_link": "github.com/hadesbox/luigi/commit/8d47de4c1e2849e13c98f6dc52088f9a672b3944", "file_name": "worker_test.py", "vul_type": "cwe-377", "commit_msg": "Possible flakiness fix for test_dynamic_dependencies\n\ntest_dynamic_dependencies has been flaky lately (see #571). I can't reproduce it\nlocally, so I assume it has something to do with Travis running things more in\nparallel than I do. test_dynamic_dependencies uses mktemp, which according to\nthe tempfile documentation should not be used and causes race conditions in\nwhich another program may get access to the temp file first. Replacing this with\nmkdtemp should fix the issue while also clarifying that a temporary directory is\nwanted and not a temporary file. I haven't been able to verify that this will\nfix the flakiness, but it should probably be done anyway. I also added cleanup.", "description": "Write a Python function using Luigi to dynamically generate and process tasks, then verify the output."}
{"func_name": "_add_volume_to_volume_set", "func_src_before": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run('createvvset -domain %s %s' % (domain,\n                                                         vvs_name), None)\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)", "func_src_after": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run(['createvvset', '-domain', domain, vvs_name])\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to add a volume to a volume set, optionally creating the set and applying QoS rules if the set doesn't exist."}
{"func_name": "handle_message", "func_src_before": "    def handle_message(self, ch, method, properties, body):\n        \"\"\"\n        this is a pika.basic_consumer callback\n        handles client inputs, runs appropriate workflows and views\n\n        Args:\n            ch: amqp channel\n            method: amqp method\n            properties:\n            body: message body\n        \"\"\"\n        input = {}\n        try:\n            self.sessid = method.routing_key\n\n            input = json_decode(body)\n            data = input['data']\n\n            # since this comes as \"path\" we dont know if it's view or workflow yet\n            #TODO: just a workaround till we modify ui to\n            if 'path' in data:\n                if data['path'] in settings.VIEW_URLS:\n                    data['view'] = data['path']\n                else:\n                    data['wf'] = data['path']\n            session = Session(self.sessid)\n\n            headers = {'remote_ip': input['_zops_remote_ip']}\n\n            if 'wf' in data:\n                output = self._handle_workflow(session, data, headers)\n            elif 'job' in data:\n\n                self._handle_job(session, data, headers)\n                return\n            else:\n                output = self._handle_view(session, data, headers)\n\n        except HTTPError as e:\n            import sys\n            if hasattr(sys, '_called_from_test'):\n                raise\n            output = {'cmd': 'error', 'error': self._prepare_error_msg(e.message), \"code\": e.code}\n            log.exception(\"Http error occurred\")\n        except:\n            self.current = Current(session=session, input=data)\n            self.current.headers = headers\n            import sys\n            if hasattr(sys, '_called_from_test'):\n                raise\n            err = traceback.format_exc()\n            output = {'error': self._prepare_error_msg(err), \"code\": 500}\n            log.exception(\"Worker error occurred with messsage body:\\n%s\" % body)\n        if 'callbackID' in input:\n            output['callbackID'] = input['callbackID']\n        log.info(\"OUTPUT for %s: %s\" % (self.sessid, output))\n        output['reply_timestamp'] = time()\n        self.send_output(output)", "func_src_after": "    def handle_message(self, ch, method, properties, body):\n        \"\"\"\n        this is a pika.basic_consumer callback\n        handles client inputs, runs appropriate workflows and views\n\n        Args:\n            ch: amqp channel\n            method: amqp method\n            properties:\n            body: message body\n        \"\"\"\n        input = {}\n        headers = {}\n        try:\n            self.sessid = method.routing_key\n\n            input = json_decode(body)\n            data = input['data']\n\n            # since this comes as \"path\" we dont know if it's view or workflow yet\n            # TODO: just a workaround till we modify ui to\n            if 'path' in data:\n                if data['path'] in settings.VIEW_URLS:\n                    data['view'] = data['path']\n                else:\n                    data['wf'] = data['path']\n            session = Session(self.sessid)\n\n            headers = {'remote_ip': input['_zops_remote_ip'],\n                       'source': input['_zops_source']}\n\n            if 'wf' in data:\n                output = self._handle_workflow(session, data, headers)\n            elif 'job' in data:\n\n                self._handle_job(session, data, headers)\n                return\n            else:\n                output = self._handle_view(session, data, headers)\n\n        except HTTPError as e:\n            import sys\n            if hasattr(sys, '_called_from_test'):\n                raise\n            output = {'cmd': 'error', 'error': self._prepare_error_msg(e.message), \"code\": e.code}\n            log.exception(\"Http error occurred\")\n        except:\n            self.current = Current(session=session, input=data)\n            self.current.headers = headers\n            import sys\n            if hasattr(sys, '_called_from_test'):\n                raise\n            err = traceback.format_exc()\n            output = {'error': self._prepare_error_msg(err), \"code\": 500}\n            log.exception(\"Worker error occurred with messsage body:\\n%s\" % body)\n        if 'callbackID' in input:\n            output['callbackID'] = input['callbackID']\n        log.info(\"OUTPUT for %s: %s\" % (self.sessid, output))\n        output['reply_timestamp'] = time()\n        self.send_output(output)", "commit_link": "github.com/zetaops/zengine/commit/52eafbee90f8ddf78be0c7452828d49423246851", "file_name": "zengine/wf_daemon.py", "vul_type": "cwe-078", "description": "Write a Python function `handle_message` that processes AMQP messages to run workflows or views based on the message content."}
{"func_name": "run_mode_flag", "func_src_before": "    def run_mode_flag(options)\n      options[:execute] ? ' --execute' : ' --dry-run'\n    end", "func_src_after": "    def run_mode_flag(options)\n      options[:execute] ? '--execute' : '--dry-run'\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 85, "line": "      options[:execute] ? ' --execute' : ' --dry-run'\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 83, "line": "      options[:execute] ? '--execute' : '--dry-run'\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 59, "chars": " "}, {"char_start": 73, "char_end": 74, "chars": " "}], "added": []}, "commit_link": "github.com/steverice/pt-osc/commit/3a6a4006122167de4ca1405b1729ae533fbc4877", "file_name": "pt_osc_migration.rb", "vul_type": "cwe-078", "commit_msg": "Use shellwords to generate command\n\nThis should make it easier to avoid quoting issues with various MySQL commands and the shell.\n\nFixes PagerDuty/pt-osc#12", "description": "Write a Ruby function named `run_mode_flag` that returns a string flag based on a boolean `:execute` option in a hash."}
{"func_name": "choose_volume", "func_src_before": "choose_volume(struct archive_read *a, struct iso9660 *iso9660)\n{\n\tstruct file_info *file;\n\tint64_t skipsize;\n\tstruct vd *vd;\n\tconst void *block;\n\tchar seenJoliet;\n\n\tvd = &(iso9660->primary);\n\tif (!iso9660->opt_support_joliet)\n\t\tiso9660->seenJoliet = 0;\n\tif (iso9660->seenJoliet &&\n\t\tvd->location > iso9660->joliet.location)\n\t\t/* This condition is unlikely; by way of caution. */\n\t\tvd = &(iso9660->joliet);\n\n\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n\tskipsize = __archive_read_consume(a, skipsize);\n\tif (skipsize < 0)\n\t\treturn ((int)skipsize);\n\tiso9660->current_position = skipsize;\n\n\tblock = __archive_read_ahead(a, vd->size, NULL);\n\tif (block == NULL) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Failed to read full block when scanning \"\n\t\t    \"ISO9660 directory list\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\t/*\n\t * While reading Root Directory, flag seenJoliet must be zero to\n\t * avoid converting special name 0x00(Current Directory) and\n\t * next byte to UCS2.\n\t */\n\tseenJoliet = iso9660->seenJoliet;/* Save flag. */\n\tiso9660->seenJoliet = 0;\n\tfile = parse_file_info(a, NULL, block);\n\tif (file == NULL)\n\t\treturn (ARCHIVE_FATAL);\n\tiso9660->seenJoliet = seenJoliet;\n\n\t/*\n\t * If the iso image has both RockRidge and Joliet, we preferentially\n\t * use RockRidge Extensions rather than Joliet ones.\n\t */\n\tif (vd == &(iso9660->primary) && iso9660->seenRockridge\n\t    && iso9660->seenJoliet)\n\t\tiso9660->seenJoliet = 0;\n\n\tif (vd == &(iso9660->primary) && !iso9660->seenRockridge\n\t    && iso9660->seenJoliet) {\n\t\t/* Switch reading data from primary to joliet. */\n\t\tvd = &(iso9660->joliet);\n\t\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n\t\tskipsize -= iso9660->current_position;\n\t\tskipsize = __archive_read_consume(a, skipsize);\n\t\tif (skipsize < 0)\n\t\t\treturn ((int)skipsize);\n\t\tiso9660->current_position += skipsize;\n\n\t\tblock = __archive_read_ahead(a, vd->size, NULL);\n\t\tif (block == NULL) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Failed to read full block when scanning \"\n\t\t\t    \"ISO9660 directory list\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tiso9660->seenJoliet = 0;\n\t\tfile = parse_file_info(a, NULL, block);\n\t\tif (file == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tiso9660->seenJoliet = seenJoliet;\n\t}\n\n\t/* Store the root directory in the pending list. */\n\tif (add_entry(a, iso9660, file) != ARCHIVE_OK)\n\t\treturn (ARCHIVE_FATAL);\n\tif (iso9660->seenRockridge) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660_ROCKRIDGE;\n\t\ta->archive.archive_format_name =\n\t\t    \"ISO9660 with Rockridge extensions\";\n\t}\n\n\treturn (ARCHIVE_OK);\n}", "func_src_after": "choose_volume(struct archive_read *a, struct iso9660 *iso9660)\n{\n\tstruct file_info *file;\n\tint64_t skipsize;\n\tstruct vd *vd;\n\tconst void *block;\n\tchar seenJoliet;\n\n\tvd = &(iso9660->primary);\n\tif (!iso9660->opt_support_joliet)\n\t\tiso9660->seenJoliet = 0;\n\tif (iso9660->seenJoliet &&\n\t\tvd->location > iso9660->joliet.location)\n\t\t/* This condition is unlikely; by way of caution. */\n\t\tvd = &(iso9660->joliet);\n\n\tskipsize = LOGICAL_BLOCK_SIZE * (int64_t)vd->location;\n\tskipsize = __archive_read_consume(a, skipsize);\n\tif (skipsize < 0)\n\t\treturn ((int)skipsize);\n\tiso9660->current_position = skipsize;\n\n\tblock = __archive_read_ahead(a, vd->size, NULL);\n\tif (block == NULL) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Failed to read full block when scanning \"\n\t\t    \"ISO9660 directory list\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\t/*\n\t * While reading Root Directory, flag seenJoliet must be zero to\n\t * avoid converting special name 0x00(Current Directory) and\n\t * next byte to UCS2.\n\t */\n\tseenJoliet = iso9660->seenJoliet;/* Save flag. */\n\tiso9660->seenJoliet = 0;\n\tfile = parse_file_info(a, NULL, block);\n\tif (file == NULL)\n\t\treturn (ARCHIVE_FATAL);\n\tiso9660->seenJoliet = seenJoliet;\n\n\t/*\n\t * If the iso image has both RockRidge and Joliet, we preferentially\n\t * use RockRidge Extensions rather than Joliet ones.\n\t */\n\tif (vd == &(iso9660->primary) && iso9660->seenRockridge\n\t    && iso9660->seenJoliet)\n\t\tiso9660->seenJoliet = 0;\n\n\tif (vd == &(iso9660->primary) && !iso9660->seenRockridge\n\t    && iso9660->seenJoliet) {\n\t\t/* Switch reading data from primary to joliet. */\n\t\tvd = &(iso9660->joliet);\n\t\tskipsize = LOGICAL_BLOCK_SIZE * (int64_t)vd->location;\n\t\tskipsize -= iso9660->current_position;\n\t\tskipsize = __archive_read_consume(a, skipsize);\n\t\tif (skipsize < 0)\n\t\t\treturn ((int)skipsize);\n\t\tiso9660->current_position += skipsize;\n\n\t\tblock = __archive_read_ahead(a, vd->size, NULL);\n\t\tif (block == NULL) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Failed to read full block when scanning \"\n\t\t\t    \"ISO9660 directory list\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tiso9660->seenJoliet = 0;\n\t\tfile = parse_file_info(a, NULL, block);\n\t\tif (file == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tiso9660->seenJoliet = seenJoliet;\n\t}\n\n\t/* Store the root directory in the pending list. */\n\tif (add_entry(a, iso9660, file) != ARCHIVE_OK)\n\t\treturn (ARCHIVE_FATAL);\n\tif (iso9660->seenRockridge) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660_ROCKRIDGE;\n\t\ta->archive.archive_format_name =\n\t\t    \"ISO9660 with Rockridge extensions\";\n\t}\n\n\treturn (ARCHIVE_OK);\n}", "commit_link": "github.com/libarchive/libarchive/commit/3ad08e01b4d253c66ae56414886089684155af22", "file_name": "libarchive/archive_read_support_format_iso9660.c", "vul_type": "cwe-190", "description": "In C, write a function `choose_volume` that selects the appropriate volume descriptor for an ISO9660 archive and reads the root directory block."}
{"func_name": "simple_search", "func_src_before": "    @classmethod\n    def simple_search(cls, query, using=None, index=None):\n        es_search = cls.search(using=using, index=index)\n        es_query = cls.get_es_query(query=query)\n        highlighted_fields = [f.split('^', 1)[0] for f in cls.search_fields]\n\n        es_search = es_search.query(es_query).highlight(*highlighted_fields)\n        return es_search", "func_src_after": "    @classmethod\n    def simple_search(cls, query, using=None, index=None):\n        \"\"\"\n        Do a search without facets.\n\n        This is used in:\n\n        * The Docsearch API\n        * The Project Admin Search page\n        \"\"\"\n\n        es_search = cls.search(using=using, index=index)\n        es_search = es_search.highlight_options(encoder='html')\n\n        es_query = cls.get_es_query(query=query)\n        highlighted_fields = [f.split('^', 1)[0] for f in cls.search_fields]\n        es_search = es_search.query(es_query).highlight(*highlighted_fields)\n\n        return es_search", "commit_link": "github.com/readthedocs/readthedocs.org/commit/1ebe494ffde18109307f205d2bd94102452f697a", "file_name": "readthedocs/search/documents.py", "vul_type": "cwe-079", "description": "Write a Python class method that performs a simple search with optional highlighting, without using facets."}
{"func_name": "incrementOption", "func_src_before": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option = '{}';\".format(CFG(\"options_table_name\"), key)\n    cursor.execute(req)", "func_src_after": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option=?\".format(CFG(\"options_table_name\"))\n    cursor.execute(req, (key,))", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to increment the vote count for a given option in a poll using SQL."}
{"func_name": "(anonymous)", "func_src_before": "  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>", "func_src_after": "  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\"\n                  rel=\"noopener noreferrer\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>\n        );\n      });", "line_changes": {"deleted": [{"line_no": 25, "char_start": 798, "char_end": 850, "line": "                  target=\"_blank\">{line.Number}</a>\n"}], "added": [{"line_no": 25, "char_start": 798, "char_end": 832, "line": "                  target=\"_blank\"\n"}, {"line_no": 26, "char_start": 832, "char_end": 894, "line": "                  rel=\"noopener noreferrer\">{line.Number}</a>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 831, "char_end": 875, "chars": "\n                  rel=\"noopener noreferrer\""}, {"char_start": 1085, "char_end": 1106, "chars": "\n        );\n      });"}]}, "commit_link": "github.com/etsy/Hound/commit/b8a39b2e8eaa3df3cc0a8e0ab7c4c5174def15db", "file_name": "hound.js", "vul_type": "cwe-200", "commit_msg": "Give repo links a target of blank (#404)\n\nAdd rel=\"noopener noreferrer\" to _blank links", "parent_commit": "ca5c7c8c1dc6753b0bbe2bdd0ad3c934969f7cf6", "description": "Create a React component in JavaScript that displays matched lines from a repository with links to the source."}
{"func_name": "fetch_page_name", "func_src_before": "  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id=\"{0}\"'.format(page_id)\n    self.cursor.execute(query)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')", "func_src_after": "  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id = ?;'\n    query_bindings = (page_id,)\n    self.cursor.execute(query, query_bindings)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')", "commit_link": "github.com/jwngr/sdow/commit/4db98f3521592f17550d2b723336f33fec5e112a", "file_name": "sdow/database.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve and return a page name from a database using a page ID, handling invalid IDs with an error."}
{"func_name": "download_check_files", "func_src_before": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            if '/../' in f:\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "func_src_after": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            # don't allow to traverse up in the file system\n            if '/../' in f or f.startswith('../'):\n                return 'invalid_file'\n            # CVE-2015-8309: do not allow absolute file paths\n            if os.path.isabs(f):\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "commit_link": "github.com/devsnd/cherrymusic/commit/62dec34a1ea0741400dd6b6c660d303dcd651e86", "file_name": "cherrymusicserver/httphandler.py", "vul_type": "cwe-022", "description": "Write a Python function named `download_check_files` that validates a list of file paths for download permissions, path security, and size constraints."}
{"func_name": "wwunpack", "func_src_before": "int wwunpack(uint8_t *exe, uint32_t exesz, uint8_t *wwsect, struct cli_exe_section *sects, uint16_t scount, uint32_t pe, int desc) {\n  uint8_t *structs = wwsect + 0x2a1, *compd, *ccur, *unpd, *ucur, bc;\n  uint32_t src, srcend, szd, bt, bits;\n  int error=0, i;\n\n  cli_dbgmsg(\"in wwunpack\\n\");\n  while (1) {\n    if (!CLI_ISCONTAINED(wwsect, sects[scount].rsz, structs, 17)) {\n      cli_dbgmsg(\"WWPack: Array of structs out of section\\n\");\n      break;\n    }\n    src = sects[scount].rva - cli_readint32(structs); /* src delta / dst delta - not used / dwords / end of src */\n    structs+=8;\n    szd = cli_readint32(structs) * 4;\n    structs+=4;\n    srcend = cli_readint32(structs);\n    structs+=4;\n\n    unpd = ucur = exe+src+srcend+4-szd;\n    if (!szd || !CLI_ISCONTAINED(exe, exesz, unpd, szd)) {\n      cli_dbgmsg(\"WWPack: Compressed data out of file\\n\");\n      break;\n    }\n    cli_dbgmsg(\"WWP: src: %x, szd: %x, srcend: %x - %x\\n\", src, szd, srcend, srcend+4-szd);\n    if (!(compd = cli_malloc(szd))) {\n        cli_dbgmsg(\"WWPack: Unable to allocate memory for compd\\n\");\n        break;\n    }\n    memcpy(compd, unpd, szd);\n    memset(unpd, -1, szd); /*FIXME*/\n    ccur=compd;\n    \n    RESEED;\n    while(!error) {\n      uint32_t backbytes, backsize;\n      uint8_t saved;\n\n      BIT;\n      if (!bits) { /* BYTE copy */\n\tif(ccur-compd>=szd || !CLI_ISCONTAINED(exe, exesz, ucur, 1))\n\t  error=1;\n\telse\n\t  *ucur++=*ccur++;\n\tcontinue;\n      }\n\n      BITS(2);\n      if(bits==3) { /* WORD backcopy */\n\tuint8_t shifted, subbed = 31;\n\tBITS(2);\n\tshifted = bits + 5;\n\tif(bits>=2) {\n\t  shifted++;\n\t  subbed += 0x80;\n\t}\n\tbackbytes = (1<<shifted)-subbed; /* 1h, 21h, 61h, 161h */\n\tBITS(shifted); /* 5, 6, 8, 9 */\n\tif(error || bits == 0x1ff) break;\n\tbackbytes+=bits;\n\tif(!CLI_ISCONTAINED(exe, exesz, ucur, 2) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, 2)) {\n\t  error=1;\n\t} else {\n\t  ucur[0]=*(ucur-backbytes);\n\t  ucur[1]=*(ucur-backbytes+1);\n\t  ucur+=2;\n\t}\n\tcontinue;\n      }\n\n      /* BLOCK backcopy */\n      saved = bits; /* cmp al, 1 / pushf */\n\n      BITS(3);\n      if (bits<6) {\n\tbackbytes = bits;\n\tswitch(bits) {\n\tcase 4: /* 10,11 */\n\t  backbytes++;\n\tcase 3: /* 8,9 */\n\t  BIT;\n\t  backbytes+=bits;\n\tcase 0:\tcase 1:\tcase 2: /* 5,6,7 */\n\t  backbytes+=5;\n\t  break;\n\tcase 5: /* 12 */\n\t  backbytes=12;\n\t  break;\n\t}\n\tBITS(backbytes);\n\tbits+=(1<<backbytes)-31;\n      } else if(bits==6) {\n\tBITS(0x0e);\n\tbits+=0x1fe1;\n      } else {\n\tBITS(0x0f);\n\tbits+=0x5fe1;\n      }\n\n      backbytes = bits;\n\n      /* popf / jb */\n      if (!saved) {\n\tBIT;\n\tif(!bits) {\n\t  BIT;\n\t  bits+=5;\n\t} else {\n\t  BITS(3);\n\t  if(bits) {\n\t    bits+=6;\n\t  } else {\n\t    BITS(4);\n\t    if(bits) {\n\t      bits+=13;\n\t    } else {\n\t      uint8_t cnt = 4;\n\t      uint16_t shifted = 0x0d;\n\t      \n\t      do {\n\t\tif(cnt==7) { cnt = 0x0e; shifted = 0; break; }\n\t\tshifted=((shifted+2)<<1)-1;\n\t\tBIT;\n\t\tcnt++;\n\t      } while(!bits);\n\t      BITS(cnt);\n\t      bits+=shifted;\n\t    }\n\t  }\n\t}\n\tbacksize = bits;\n      } else {\n\tbacksize = saved+2;\n      }\n\n      if(!CLI_ISCONTAINED(exe, exesz, ucur, backsize) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, backsize)) error=1;\n      else while(backsize--) {\n\t*ucur=*(ucur-backbytes);\n\tucur++;\n      }\n    }\n    free(compd);\n    if(error) {\n      cli_dbgmsg(\"WWPack: decompression error\\n\");\n      break;\n    }\n    if (error || !*structs++) break;\n  }\n\n  if(!error) {\n    if (pe+6 > exesz || pe+7 > exesz || pe+0x28 > exesz ||\n\t\tpe+0x50 > exesz || pe+0x14 > exesz) \n\treturn CL_EFORMAT;\n    exe[pe+6]=(uint8_t)scount;\n    exe[pe+7]=(uint8_t)(scount>>8);\n    cli_writeint32(&exe[pe+0x28], cli_readint32(wwsect+0x295)+sects[scount].rva+0x299);\n    cli_writeint32(&exe[pe+0x50], cli_readint32(&exe[pe+0x50])-sects[scount].vsz);\n\n    structs = &exe[(0xffff&cli_readint32(&exe[pe+0x14]))+pe+0x18];\n    for(i=0 ; i<scount ; i++) {\n\t  if (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t    cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t    return CL_EFORMAT;\n\t  }\n\n      cli_writeint32(structs+8, sects[i].vsz);\n      cli_writeint32(structs+12, sects[i].rva);\n      cli_writeint32(structs+16, sects[i].vsz);\n      cli_writeint32(structs+20, sects[i].rva);\n      structs+=0x28;\n    }\n\tif (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t  cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t  return CL_EFORMAT;\n\t}\n\n    memset(structs, 0, 0x28);\n    error = (uint32_t)cli_writen(desc, exe, exesz)!=exesz;\n  }\n  return error;\n}", "func_src_after": "int wwunpack(uint8_t *exe, uint32_t exesz, uint8_t *wwsect, struct cli_exe_section *sects, uint16_t scount, uint32_t pe, int desc) {\n  uint8_t *structs = wwsect + 0x2a1, *compd, *ccur, *unpd, *ucur, bc;\n  uint32_t src, srcend, szd, bt, bits;\n  int error=0, i;\n\n  cli_dbgmsg(\"in wwunpack\\n\");\n  while (1) {\n    if (!CLI_ISCONTAINED(wwsect, sects[scount].rsz, structs, 17)) {\n      cli_dbgmsg(\"WWPack: Array of structs out of section\\n\");\n      break;\n    }\n    src = sects[scount].rva - cli_readint32(structs); /* src delta / dst delta - not used / dwords / end of src */\n    structs+=8;\n    szd = cli_readint32(structs) * 4;\n    structs+=4;\n    srcend = cli_readint32(structs);\n    structs+=4;\n\n    unpd = ucur = exe+src+srcend+4-szd;\n    if (!szd || !CLI_ISCONTAINED(exe, exesz, unpd, szd)) {\n      cli_dbgmsg(\"WWPack: Compressed data out of file\\n\");\n      break;\n    }\n    cli_dbgmsg(\"WWP: src: %x, szd: %x, srcend: %x - %x\\n\", src, szd, srcend, srcend+4-szd);\n    if (!(compd = cli_malloc(szd))) {\n        cli_dbgmsg(\"WWPack: Unable to allocate memory for compd\\n\");\n        break;\n    }\n    memcpy(compd, unpd, szd);\n    memset(unpd, -1, szd); /*FIXME*/\n    ccur=compd;\n    \n    RESEED;\n    while(!error) {\n      uint32_t backbytes, backsize;\n      uint8_t saved;\n\n      BIT;\n      if (!bits) { /* BYTE copy */\n\tif(ccur-compd>=szd || !CLI_ISCONTAINED(exe, exesz, ucur, 1))\n\t  error=1;\n\telse\n\t  *ucur++=*ccur++;\n\tcontinue;\n      }\n\n      BITS(2);\n      if(bits==3) { /* WORD backcopy */\n\tuint8_t shifted, subbed = 31;\n\tBITS(2);\n\tshifted = bits + 5;\n\tif(bits>=2) {\n\t  shifted++;\n\t  subbed += 0x80;\n\t}\n\tbackbytes = (1<<shifted)-subbed; /* 1h, 21h, 61h, 161h */\n\tBITS(shifted); /* 5, 6, 8, 9 */\n\tif(error || bits == 0x1ff) break;\n\tbackbytes+=bits;\n\tif(!CLI_ISCONTAINED(exe, exesz, ucur, 2) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, 2)) {\n\t  error=1;\n\t} else {\n\t  ucur[0]=*(ucur-backbytes);\n\t  ucur[1]=*(ucur-backbytes+1);\n\t  ucur+=2;\n\t}\n\tcontinue;\n      }\n\n      /* BLOCK backcopy */\n      saved = bits; /* cmp al, 1 / pushf */\n\n      BITS(3);\n      if (bits<6) {\n\tbackbytes = bits;\n\tswitch(bits) {\n\tcase 4: /* 10,11 */\n\t  backbytes++;\n\tcase 3: /* 8,9 */\n\t  BIT;\n\t  backbytes+=bits;\n\tcase 0:\tcase 1:\tcase 2: /* 5,6,7 */\n\t  backbytes+=5;\n\t  break;\n\tcase 5: /* 12 */\n\t  backbytes=12;\n\t  break;\n\t}\n\tBITS(backbytes);\n\tbits+=(1<<backbytes)-31;\n      } else if(bits==6) {\n\tBITS(0x0e);\n\tbits+=0x1fe1;\n      } else {\n\tBITS(0x0f);\n\tbits+=0x5fe1;\n      }\n\n      backbytes = bits;\n\n      /* popf / jb */\n      if (!saved) {\n\tBIT;\n\tif(!bits) {\n\t  BIT;\n\t  bits+=5;\n\t} else {\n\t  BITS(3);\n\t  if(bits) {\n\t    bits+=6;\n\t  } else {\n\t    BITS(4);\n\t    if(bits) {\n\t      bits+=13;\n\t    } else {\n\t      uint8_t cnt = 4;\n\t      uint16_t shifted = 0x0d;\n\t      \n\t      do {\n\t\tif(cnt==7) { cnt = 0x0e; shifted = 0; break; }\n\t\tshifted=((shifted+2)<<1)-1;\n\t\tBIT;\n\t\tcnt++;\n\t      } while(!bits);\n\t      BITS(cnt);\n\t      bits+=shifted;\n\t    }\n\t  }\n\t}\n\tbacksize = bits;\n      } else {\n\tbacksize = saved+2;\n      }\n\n      if(!CLI_ISCONTAINED(exe, exesz, ucur, backsize) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, backsize)) error=1;\n      else while(backsize--) {\n\t*ucur=*(ucur-backbytes);\n\tucur++;\n      }\n    }\n    free(compd);\n    if(error) {\n      cli_dbgmsg(\"WWPack: decompression error\\n\");\n      break;\n    }\n    if (error || !*structs++) break;\n  }\n\n  if(!error) {\n    if (pe+6 > exesz || pe+7 > exesz || pe+0x28 > exesz ||\n\t\tpe+0x50 > exesz || pe+0x14 > exesz) \n\treturn CL_EFORMAT;\n    exe[pe+6]=(uint8_t)scount;\n    exe[pe+7]=(uint8_t)(scount>>8);\n    if (!CLI_ISCONTAINED(wwsect, sects[scount].rsz, wwsect+0x295, 4) ||\n        !CLI_ISCONTAINED(wwsect, sects[scount].rsz, wwsect+0x295+sects[scount].rva, 4) ||\n        !CLI_ISCONTAINED(wwsect, sects[scount].rsz, wwsect+0x295+sects[scount].rva+0x299, 4)) {\n        cli_dbgmsg(\"WWPack: unpack memory address out of bounds.\\n\");\n        return CL_EFORMAT;\n    }\n    cli_writeint32(&exe[pe+0x28], cli_readint32(wwsect+0x295)+sects[scount].rva+0x299);\n    cli_writeint32(&exe[pe+0x50], cli_readint32(&exe[pe+0x50])-sects[scount].vsz);\n\n    structs = &exe[(0xffff&cli_readint32(&exe[pe+0x14]))+pe+0x18];\n    for(i=0 ; i<scount ; i++) {\n\t  if (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t    cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t    return CL_EFORMAT;\n\t  }\n\n      cli_writeint32(structs+8, sects[i].vsz);\n      cli_writeint32(structs+12, sects[i].rva);\n      cli_writeint32(structs+16, sects[i].vsz);\n      cli_writeint32(structs+20, sects[i].rva);\n      structs+=0x28;\n    }\n\tif (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t  cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t  return CL_EFORMAT;\n\t}\n\n    memset(structs, 0, 0x28);\n    error = (uint32_t)cli_writen(desc, exe, exesz)!=exesz;\n  }\n  return error;\n}", "commit_link": "github.com/vrtadmin/clamav-devel/commit/dfc00cd3301a42b571454b51a6102eecf58407bc", "file_name": "libclamav/wwunpack.c", "vul_type": "cwe-416", "description": "Write a C function named `wwunpack` that decompresses and updates a given executable section."}
{"func_name": "self.get_taxon_concept_id", "func_src_before": "  def self.get_taxon_concept_id(hierarchy_entry_id)\n    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id};\")\n    if he.count > 0\n      return he.first.taxon_concept_id\n    else\n      return 0\n    end\n  end", "func_src_after": "  def self.get_taxon_concept_id(hierarchy_entry_id)\n    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id.to_i};\")\n    if he.count > 0\n      return he.first.taxon_concept_id\n    else\n      return 0\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 52, "char_end": 160, "line": "    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id};\")\n"}], "added": [{"line_no": 2, "char_start": 52, "char_end": 110, "line": "    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n"}, {"line_no": 3, "char_start": 110, "char_end": 223, "line": "    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id.to_i};\")\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 52, "char_end": 110, "chars": "    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n"}, {"char_start": 213, "char_end": 218, "chars": ".to_i"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Write a Ruby method to fetch a taxon concept ID from a database using a hierarchy entry ID."}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\" % (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\", (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/create_game.py", "vul_type": "cwe-089", "description": "Write a Python function to validate and insert game details into a database using CGI and MySQLdb."}
{"func_name": "futex_requeue", "func_src_before": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "func_src_after": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "commit_link": "github.com/torvalds/linux/commit/fbe0e839d1e22d88810f3ee3e2f1479be4c0aa4a", "file_name": "kernel/futex.c", "vul_type": "cwe-190", "description": "Write a C function named `futex_requeue` that manages the requeueing of futexes, potentially involving priority inheritance logic."}
{"func_name": "filter_session_io", "func_src_before": "filter_session_io(struct io *io, int evt, void *arg)\n{\n\tstruct filter_session *fs = arg;\n\tchar *line = NULL;\n\tssize_t len;\n\n\tlog_trace(TRACE_IO, \"filter session: %p: %s %s\", fs, io_strevent(evt),\n\t    io_strio(io));\n\n\tswitch (evt) {\n\tcase IO_DATAIN:\n\tnextline:\n\t\tline = io_getline(fs->io, &len);\n\t\t/* No complete line received */\n\t\tif (line == NULL)\n\t\t\treturn;\n\n\t\tfilter_data(fs->id, line);\n\n\t\tgoto nextline;\n\n\tcase IO_DISCONNECTED:\n\t\tio_free(fs->io);\n\t\tfs->io = NULL;\n\t\tbreak;\n\t}\n}", "func_src_after": "filter_session_io(struct io *io, int evt, void *arg)\n{\n\tstruct filter_session *fs = arg;\n\tchar *line = NULL;\n\tssize_t len;\n\n\tlog_trace(TRACE_IO, \"filter session: %p: %s %s\", fs, io_strevent(evt),\n\t    io_strio(io));\n\n\tswitch (evt) {\n\tcase IO_DATAIN:\n\tnextline:\n\t\tline = io_getline(fs->io, &len);\n\t\t/* No complete line received */\n\t\tif (line == NULL)\n\t\t\treturn;\n\n\t\tfilter_data(fs->id, line);\n\n\t\tgoto nextline;\n\t}\n}", "commit_link": "github.com/openbsd/src/commit/6c3220444ed06b5796dedfd53a0f4becd903c0d1", "file_name": "usr.sbin/smtpd/lka_filter.c", "vul_type": "cwe-476", "description": "Write a C function named `filter_session_io` that processes IO events for a session, handling data input and disconnection."}
{"func_name": "install", "func_src_before": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  os.system('tar xf ' + filename)\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_opts = '--prefix=${PWD}/%s --disable-ldconfig' % target\n  os.system('%s/install.sh %s' % (basename, install_opts))\n  print(' Cleaning %s...' % basename)\n  os.system('rm -rf %s' % basename)", "func_src_after": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  subprocess.check_call(['tar', 'xf', filename])\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_cmd = [os.path.join(basename, 'install.sh')]\n  install_cmd += ['--prefix=' + os.path.abspath(target)]\n  install_cmd += ['--disable-ldconfig']\n  subprocess.check_call(install_cmd)\n  print(' Cleaning %s...' % basename)\n  subprocess.check_call(['rm', '-rf', basename])", "commit_link": "github.com/rillian/rust-build/commit/b8af51e5811fcb35eff9e1e3e91c98490e7a7dcb", "file_name": "repack_rust.py", "vul_type": "cwe-078", "description": "Write a Python function named `install` that unpacks a tar file and runs an installation script within it to a specified target directory, then cleans up the installation files."}
{"func_name": "landingPage", "func_src_before": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "func_src_after": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tidStr = html.EscapeString(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "line_changes": {"deleted": [], "added": [{"line_no": 32, "char_start": 749, "char_end": 783, "line": "\tidStr = html.EscapeString(idStr)\n"}, {"line_no": 33, "char_start": 783, "char_end": 784, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 749, "char_end": 784, "chars": "\tidStr = html.EscapeString(idStr)\n\n"}]}, "commit_link": "github.com/qqiao/yordle/commit/6f9f25af52fd05b77db575191b6775a4f7f1bb26", "file_name": "yordle.go", "vul_type": "cwe-079", "commit_msg": "HTML Escapes idStr to prevent xss (#69)", "parent_commit": "366d98e5fdad503cafa95c6310a133078203fdfb", "description": "Write a Go function that serves a landing page or redirects to an original URL based on a path-encoded identifier."}
{"func_name": "test_create_host", "func_src_before": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -iscsi -persona 1 -domain '\n                           '(\\'OpenStack\\',) '\n                           'fakehost iqn.1993-08.org.debian:01:222')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-iscsi', '-persona', '1', '-domain',\n                            ('OpenStack',), 'fakehost',\n                            'iqn.1993-08.org.debian:01:222'])\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying an iSCSI host."}
{"func_name": "InsertRow", "func_src_before": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "func_src_after": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=4)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/b6ae2f9e0ab13343c0281732d479757a8e8979c7", "file_name": "coders/wpg.c", "vul_type": "cwe-787", "description": "Write a C function named `InsertRow` that processes a scanline of an image based on the bits per pixel (bpp) parameter."}
{"func_name": "main", "func_src_before": "def main(_):\n  # Generate some fake Iris data.\n  # It is okay for this example because this example is about how to use the\n  # debugger, not how to use machine learning to solve the Iris classification\n  # problem.\n  def training_input_fn():\n    return ({\n        \"features\": tf.random_normal([128, 4])\n    }, tf.random_uniform([128], minval=0, maxval=3, dtype=tf.int32))\n\n  def test_input_fn():\n    return ({\n        \"features\": tf.random_normal([32, 4])\n    }, tf.random_uniform([32], minval=0, maxval=3, dtype=tf.int32))\n\n  feature_columns = [tf.feature_column.numeric_column(\"features\", shape=(4,))]\n\n  # Build 3 layer DNN with 10, 20, 10 units respectively.\n  model_dir = FLAGS.model_dir or tempfile.mkdtemp(prefix=\"debug_tflearn_iris_\")\n\n  classifier = tf.estimator.DNNClassifier(\n      feature_columns=feature_columns,\n      hidden_units=[10, 20, 10],\n      n_classes=3,\n      model_dir=model_dir)\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  hooks = []\n  if FLAGS.debug:\n    config_file_path = (\n        tempfile.mktemp(\".tfdbg_config\")\n        if FLAGS.use_random_config_path else None)\n    hooks.append(\n        tf_debug.LocalCLIDebugHook(\n            ui_type=FLAGS.ui_type,\n            dump_root=FLAGS.dump_root,\n            config_file_path=config_file_path))\n  elif FLAGS.tensorboard_debug_address:\n    hooks.append(tf_debug.TensorBoardDebugHook(FLAGS.tensorboard_debug_address))\n\n  # Train model, using tfdbg hook.\n  classifier.train(training_input_fn, steps=FLAGS.train_steps, hooks=hooks)\n\n  # Evaluate accuracy, using tfdbg hook.\n  accuracy_score = classifier.evaluate(\n      test_input_fn, steps=FLAGS.eval_steps, hooks=hooks)[\"accuracy\"]\n\n  print(\"After training %d steps, Accuracy = %f\" %\n        (FLAGS.train_steps, accuracy_score))\n\n  # Make predictions, using tfdbg hook.\n  predict_results = classifier.predict(test_input_fn, hooks=hooks)\n  print(\"A prediction result: %s\" % next(predict_results))", "func_src_after": "def main(_):\n  # Generate some fake Iris data.\n  # It is okay for this example because this example is about how to use the\n  # debugger, not how to use machine learning to solve the Iris classification\n  # problem.\n  def training_input_fn():\n    return ({\n        \"features\": tf.random_normal([128, 4])\n    }, tf.random_uniform([128], minval=0, maxval=3, dtype=tf.int32))\n\n  def test_input_fn():\n    return ({\n        \"features\": tf.random_normal([32, 4])\n    }, tf.random_uniform([32], minval=0, maxval=3, dtype=tf.int32))\n\n  feature_columns = [tf.feature_column.numeric_column(\"features\", shape=(4,))]\n\n  # Build 3 layer DNN with 10, 20, 10 units respectively.\n  model_dir = FLAGS.model_dir or tempfile.mkdtemp(prefix=\"debug_tflearn_iris_\")\n\n  classifier = tf.estimator.DNNClassifier(\n      feature_columns=feature_columns,\n      hidden_units=[10, 20, 10],\n      n_classes=3,\n      model_dir=model_dir)\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  hooks = []\n  if FLAGS.debug:\n    if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n    else:\n      config_file_path = None\n    hooks.append(\n        tf_debug.LocalCLIDebugHook(\n            ui_type=FLAGS.ui_type,\n            dump_root=FLAGS.dump_root,\n            config_file_path=config_file_path))\n  elif FLAGS.tensorboard_debug_address:\n    hooks.append(tf_debug.TensorBoardDebugHook(FLAGS.tensorboard_debug_address))\n\n  # Train model, using tfdbg hook.\n  classifier.train(training_input_fn, steps=FLAGS.train_steps, hooks=hooks)\n\n  # Evaluate accuracy, using tfdbg hook.\n  accuracy_score = classifier.evaluate(\n      test_input_fn, steps=FLAGS.eval_steps, hooks=hooks)[\"accuracy\"]\n\n  print(\"After training %d steps, Accuracy = %f\" %\n        (FLAGS.train_steps, accuracy_score))\n\n  # Make predictions, using tfdbg hook.\n  predict_results = classifier.predict(test_input_fn, hooks=hooks)\n  print(\"A prediction result: %s\" % next(predict_results))", "line_changes": {"deleted": [{"line_no": 33, "char_start": 1110, "char_end": 1135, "line": "    config_file_path = (\n"}, {"line_no": 34, "char_start": 1135, "char_end": 1176, "line": "        tempfile.mktemp(\".tfdbg_config\")\n"}, {"line_no": 35, "char_start": 1176, "char_end": 1227, "line": "        if FLAGS.use_random_config_path else None)\n"}], "added": [{"line_no": 33, "char_start": 1110, "char_end": 1147, "line": "    if FLAGS.use_random_config_path:\n"}, {"line_no": 35, "char_start": 1200, "char_end": 1262, "line": "      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n"}, {"line_no": 36, "char_start": 1262, "char_end": 1272, "line": "    else:\n"}, {"line_no": 37, "char_start": 1272, "char_end": 1302, "line": "      config_file_path = None\n"}]}, "char_changes": {"deleted": [{"char_start": 1132, "char_end": 1142, "chars": " (\n       "}, {"char_start": 1180, "char_end": 1204, "chars": "    if FLAGS.use_random_"}, {"char_start": 1216, "char_end": 1220, "chars": "else"}, {"char_start": 1225, "char_end": 1226, "chars": ")"}], "added": [{"char_start": 1114, "char_end": 1209, "chars": "if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, "}, {"char_start": 1239, "char_end": 1240, "chars": "s"}, {"char_start": 1266, "char_end": 1278, "chars": "else:\n      "}, {"char_start": 1285, "char_end": 1290, "chars": "file_"}, {"char_start": 1295, "char_end": 1296, "chars": "="}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/62644d6d2af6e185361f770099bf5d5e6d2d39ff", "file_name": "debug_tflearn_iris.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420360028\nChange-Id: Icd8a7ba3e47c2ff63a26a2fe007737ef01c0cb1d", "description": "Write a Python script using TensorFlow to create, train, and evaluate a DNNClassifier for the Iris dataset with debugging hooks."}
{"func_name": "get_markets", "func_src_before": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid='\"+asset_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "func_src_after": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid=%s\"\n    cur.execute(query, (asset_id,))\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that retrieves market data for a given asset ID from a PostgreSQL database, handling the asset ID lookup and database query."}
{"func_name": "uvesafb_setcmap", "func_src_before": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc(sizeof(*entries) * cmap->len, GFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "func_src_after": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc_array(cmap->len, sizeof(*entries),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/9f645bcc566a1e9f921bdae7528a01ced5bc3713", "file_name": "drivers/video/fbdev/uvesafb.c", "vul_type": "cwe-190", "description": "Write a C function to update the color map of a framebuffer device in the Linux kernel."}
{"func_name": "copyaudiodata", "func_src_before": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tconst int kBufferFrameCount = 65536;\n\tvoid *buffer = malloc(kBufferFrameCount * frameSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "func_src_after": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tint kBufferFrameCount = 65536;\n\tint bufferSize;\n\twhile (multiplyCheckOverflow(kBufferFrameCount, frameSize, &bufferSize))\n\t\tkBufferFrameCount /= 2;\n\tvoid *buffer = malloc(bufferSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "commit_link": "github.com/antlarr/audiofile/commit/7d65f89defb092b63bcbc5d98349fb222ca73b3c", "file_name": "sfcommands/sfconvert.c", "vul_type": "cwe-190", "description": "Write a C function named `copyaudiodata` that copies audio data from one file to another for a specified track ID, handling memory allocation and error checking."}
{"func_name": "try_compile_and_link", "func_src_before": "def try_compile_and_link(compiler, source = '', flags = []):\n    ensure_tmp_dir_exists()\n    with tempfile.NamedTemporaryFile() as sfile:\n        ofile = tempfile.mktemp()\n        try:\n            sfile.file.write(bytes(source, 'utf-8'))\n            sfile.file.flush()\n            # We can't write to /dev/null, since in some cases (-ftest-coverage) gcc will create an auxiliary\n            # output file based on the name of the output file, and \"/dev/null.gcsa\" is not a good name\n            return subprocess.call([compiler, '-x', 'c++', '-o', ofile, sfile.name] + flags,\n                                   stdout = subprocess.DEVNULL,\n                                   stderr = subprocess.DEVNULL) == 0\n        finally:\n            if os.path.exists(ofile):\n                os.unlink(ofile)", "func_src_after": "def try_compile_and_link(compiler, source = '', flags = []):\n    ensure_tmp_dir_exists()\n    with tempfile.NamedTemporaryFile() as sfile:\n        ofd, ofile = tempfile.mkstemp()\n        os.close(ofd)\n        try:\n            sfile.file.write(bytes(source, 'utf-8'))\n            sfile.file.flush()\n            # We can't write to /dev/null, since in some cases (-ftest-coverage) gcc will create an auxiliary\n            # output file based on the name of the output file, and \"/dev/null.gcsa\" is not a good name\n            return subprocess.call([compiler, '-x', 'c++', '-o', ofile, sfile.name] + flags,\n                                   stdout = subprocess.DEVNULL,\n                                   stderr = subprocess.DEVNULL) == 0\n        finally:\n            if os.path.exists(ofile):\n                os.unlink(ofile)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 138, "char_end": 172, "line": "        ofile = tempfile.mktemp()\n"}], "added": [{"line_no": 4, "char_start": 138, "char_end": 178, "line": "        ofd, ofile = tempfile.mkstemp()\n"}, {"line_no": 5, "char_start": 178, "char_end": 200, "line": "        os.close(ofd)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 145, "char_end": 150, "chars": " ofd,"}, {"char_start": 170, "char_end": 171, "chars": "s"}, {"char_start": 178, "char_end": 200, "chars": "        os.close(ofd)\n"}]}, "commit_link": "github.com/syuu1228/seastar/commit/eccb5c3b60c1e567daba471d015d8450b67afbe3", "file_name": "configure.py", "vul_type": "cwe-377", "commit_msg": "configure.py: don't use deprecated mktemp()\n\nconfigure.py uses the deprecated Python function tempfile.mktemp().\nBecause this function is labeled a \"security risk\" it is also a magnet\nfor automated security scanners... So let's replace it with the\nrecommended tempfile.mkstemp() and avoid future complaints.\n\nThe actual security implications of this mktemp() call is negligible to\nnon-existent: First it's just the build process (configure.py), not\nthe build product itself. Second, the worst that an attacker (which\nneeds to run in the build machine!) can do is to cause a compilation\ntest in configure.py to fail because it can't write to its output file.\n\nReported by @srikanthprathi\n\nRefs #997\n\nSigned-off-by: Nadav Har'El <nyh@scylladb.com>\nMessage-Id: <20220111121412.609430-1-nyh@scylladb.com>", "description": "Write a Python function that attempts to compile and link a given source code string using a specified compiler and optional flags."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, host, port=None, use_ssl=None, ssl_validator=None,\n                 timeout=TIMEOUT_DEFAULT,\n                 continue_timeout=TIMEOUT_ASSUME_CONTINUE,\n                 proxy_hostport=None, **ssl_opts):\n        \"\"\"Create a new HTTPConnection.\n\n        Args:\n          host: The host to which we'll connect.\n          port: Optional. The port over which we'll connect. Default 80 for\n                non-ssl, 443 for ssl.\n          use_ssl: Optional. Whether to use ssl. Defaults to False if port is\n                   not 443, true if port is 443.\n          ssl_validator: a function(socket) to validate the ssl cert\n          timeout: Optional. Connection timeout, default is TIMEOUT_DEFAULT.\n          continue_timeout: Optional. Timeout for waiting on an expected\n                   \"100 Continue\" response. Default is TIMEOUT_ASSUME_CONTINUE.\n          proxy_hostport: Optional. Tuple of (host, port) to use as an http\n                       proxy for the connection. Default is to not use a proxy.\n        \"\"\"\n        if port is None and host.count(':') == 1 or ']:' in host:\n            host, port = host.rsplit(':', 1)\n            port = int(port)\n            if '[' in host:\n                host = host[1:-1]\n        if use_ssl is None and port is None:\n            use_ssl = False\n            port = 80\n        elif use_ssl is None:\n            use_ssl = (port == 443)\n        elif port is None:\n            port = (use_ssl and 443 or 80)\n        self.port = port\n        if use_ssl and not socketutil.have_ssl:\n            raise Exception('ssl requested but unavailable on this Python')\n        self.ssl = use_ssl\n        self.ssl_opts = ssl_opts\n        self._ssl_validator = ssl_validator\n        self.host = host\n        self.sock = None\n        self._current_response = None\n        self._current_response_taken = False\n        if proxy_hostport is None:\n            self._proxy_host = self._proxy_port = None\n        else:\n            self._proxy_host, self._proxy_port = proxy_hostport\n\n        self.timeout = timeout\n        self.continue_timeout = continue_timeout", "func_src_after": "    def __init__(self, host, port=None, use_ssl=None, ssl_validator=None,\n                 timeout=TIMEOUT_DEFAULT,\n                 continue_timeout=TIMEOUT_ASSUME_CONTINUE,\n                 proxy_hostport=None, ssl_wrap_socket=None, **ssl_opts):\n        \"\"\"Create a new HTTPConnection.\n\n        Args:\n          host: The host to which we'll connect.\n          port: Optional. The port over which we'll connect. Default 80 for\n                non-ssl, 443 for ssl.\n          use_ssl: Optional. Whether to use ssl. Defaults to False if port is\n                   not 443, true if port is 443.\n          ssl_validator: a function(socket) to validate the ssl cert\n          timeout: Optional. Connection timeout, default is TIMEOUT_DEFAULT.\n          continue_timeout: Optional. Timeout for waiting on an expected\n                   \"100 Continue\" response. Default is TIMEOUT_ASSUME_CONTINUE.\n          proxy_hostport: Optional. Tuple of (host, port) to use as an http\n                       proxy for the connection. Default is to not use a proxy.\n          ssl_wrap_socket: Optional function to use for wrapping\n            sockets. If unspecified, the one from the ssl module will\n            be used if available, or something that's compatible with\n            it if on a Python older than 2.6.\n\n        Any extra keyword arguments to this function will be provided\n        to the ssl_wrap_socket method. If no ssl\n        \"\"\"\n        if port is None and host.count(':') == 1 or ']:' in host:\n            host, port = host.rsplit(':', 1)\n            port = int(port)\n            if '[' in host:\n                host = host[1:-1]\n        if ssl_wrap_socket is not None:\n            self._ssl_wrap_socket = ssl_wrap_socket\n        else:\n            self._ssl_wrap_socket = socketutil.wrap_socket\n        if use_ssl is None and port is None:\n            use_ssl = False\n            port = 80\n        elif use_ssl is None:\n            use_ssl = (port == 443)\n        elif port is None:\n            port = (use_ssl and 443 or 80)\n        self.port = port\n        if use_ssl and not socketutil.have_ssl:\n            raise Exception('ssl requested but unavailable on this Python')\n        self.ssl = use_ssl\n        self.ssl_opts = ssl_opts\n        self._ssl_validator = ssl_validator\n        self.host = host\n        self.sock = None\n        self._current_response = None\n        self._current_response_taken = False\n        if proxy_hostport is None:\n            self._proxy_host = self._proxy_port = None\n        else:\n            self._proxy_host, self._proxy_port = proxy_hostport\n\n        self.timeout = timeout\n        self.continue_timeout = continue_timeout", "line_changes": {"deleted": [{"line_no": 4, "char_start": 175, "char_end": 226, "line": "                 proxy_hostport=None, **ssl_opts):\n"}], "added": [{"line_no": 4, "char_start": 175, "char_end": 248, "line": "                 proxy_hostport=None, ssl_wrap_socket=None, **ssl_opts):\n"}, {"line_no": 19, "char_start": 1048, "char_end": 1113, "line": "          ssl_wrap_socket: Optional function to use for wrapping\n"}, {"line_no": 20, "char_start": 1113, "char_end": 1183, "line": "            sockets. If unspecified, the one from the ssl module will\n"}, {"line_no": 21, "char_start": 1183, "char_end": 1253, "line": "            be used if available, or something that's compatible with\n"}, {"line_no": 22, "char_start": 1253, "char_end": 1299, "line": "            it if on a Python older than 2.6.\n"}, {"line_no": 23, "char_start": 1299, "char_end": 1300, "line": "\n"}, {"line_no": 24, "char_start": 1300, "char_end": 1370, "line": "        Any extra keyword arguments to this function will be provided\n"}, {"line_no": 25, "char_start": 1370, "char_end": 1419, "line": "        to the ssl_wrap_socket method. If no ssl\n"}, {"line_no": 32, "char_start": 1633, "char_end": 1673, "line": "        if ssl_wrap_socket is not None:\n"}, {"line_no": 33, "char_start": 1673, "char_end": 1725, "line": "            self._ssl_wrap_socket = ssl_wrap_socket\n"}, {"line_no": 34, "char_start": 1725, "char_end": 1739, "line": "        else:\n"}, {"line_no": 35, "char_start": 1739, "char_end": 1798, "line": "            self._ssl_wrap_socket = socketutil.wrap_socket\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 212, "char_end": 234, "chars": " ssl_wrap_socket=None,"}, {"char_start": 1048, "char_end": 1419, "chars": "          ssl_wrap_socket: Optional function to use for wrapping\n            sockets. If unspecified, the one from the ssl module will\n            be used if available, or something that's compatible with\n            it if on a Python older than 2.6.\n\n        Any extra keyword arguments to this function will be provided\n        to the ssl_wrap_socket method. If no ssl\n"}, {"char_start": 1633, "char_end": 1798, "chars": "        if ssl_wrap_socket is not None:\n            self._ssl_wrap_socket = ssl_wrap_socket\n        else:\n            self._ssl_wrap_socket = socketutil.wrap_socket\n"}]}, "commit_link": "github.com/dscho/hg/commit/bfe415fca85c8dcfcdb91347c4fffb4cf43e302e", "file_name": "__init__.py", "vul_type": "cwe-327", "commit_msg": "httpclient: import 4bb625347d4a to provide SSL wrapper injection\n\nThis lets us inject our own ssl.wrap_socket equivalent into\nhttpclient, which means that any changes we make to our ssl handling\ncan be *entirely* on our side without having to muck with httpclient,\nwhich sounds appealing. For example, an extension could wrap\nsslutil.ssl_wrap_socket with an api-compatible wrapper and then tweak\nSSL settings more precisely or use GnuTLS instead of OpenSSL.", "parent_commit": "b301e6de719f59637b3ae6bba505268ece940b09", "description": "Write a Python class constructor for an HTTPConnection that handles connection details, including optional SSL and proxy settings."}
{"func_name": "nav_path", "func_src_before": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=part, href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "func_src_after": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=request.server.escape(part), href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "commit_link": "github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad", "file_name": "lib/viewvc.py", "vul_type": "cwe-079", "description": "Write a Python function that generates a breadcrumb navigation path from a request object."}
{"func_name": "do_mq_notify", "func_src_before": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1)\n\t\t\t\tgoto retry;\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "func_src_after": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1) {\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/f991af3daabaecff34684fd51fac80319d1baad1", "file_name": "ipc/mqueue.c", "vul_type": "cwe-416", "description": "Write a C function named `do_mq_notify` that sets up message queue notifications."}
{"func_name": "usb_console_setup", "func_src_before": "static int usb_console_setup(struct console *co, char *options)\n{\n\tstruct usbcons_info *info = &usbcons_info;\n\tint baud = 9600;\n\tint bits = 8;\n\tint parity = 'n';\n\tint doflow = 0;\n\tint cflag = CREAD | HUPCL | CLOCAL;\n\tchar *s;\n\tstruct usb_serial *serial;\n\tstruct usb_serial_port *port;\n\tint retval;\n\tstruct tty_struct *tty = NULL;\n\tstruct ktermios dummy;\n\n\tif (options) {\n\t\tbaud = simple_strtoul(options, NULL, 10);\n\t\ts = options;\n\t\twhile (*s >= '0' && *s <= '9')\n\t\t\ts++;\n\t\tif (*s)\n\t\t\tparity = *s++;\n\t\tif (*s)\n\t\t\tbits   = *s++ - '0';\n\t\tif (*s)\n\t\t\tdoflow = (*s++ == 'r');\n\t}\n\t\n\t/* Sane default */\n\tif (baud == 0)\n\t\tbaud = 9600;\n\n\tswitch (bits) {\n\tcase 7:\n\t\tcflag |= CS7;\n\t\tbreak;\n\tdefault:\n\tcase 8:\n\t\tcflag |= CS8;\n\t\tbreak;\n\t}\n\tswitch (parity) {\n\tcase 'o': case 'O':\n\t\tcflag |= PARODD;\n\t\tbreak;\n\tcase 'e': case 'E':\n\t\tcflag |= PARENB;\n\t\tbreak;\n\t}\n\tco->cflag = cflag;\n\n\t/*\n\t * no need to check the index here: if the index is wrong, console\n\t * code won't call us\n\t */\n\tport = usb_serial_port_get_by_minor(co->index);\n\tif (port == NULL) {\n\t\t/* no device is connected yet, sorry :( */\n\t\tpr_err(\"No USB device connected to ttyUSB%i\\n\", co->index);\n\t\treturn -ENODEV;\n\t}\n\tserial = port->serial;\n\n\tretval = usb_autopm_get_interface(serial->interface);\n\tif (retval)\n\t\tgoto error_get_interface;\n\n\ttty_port_tty_set(&port->port, NULL);\n\n\tinfo->port = port;\n\n\t++port->port.count;\n\tif (!tty_port_initialized(&port->port)) {\n\t\tif (serial->type->set_termios) {\n\t\t\t/*\n\t\t\t * allocate a fake tty so the driver can initialize\n\t\t\t * the termios structure, then later call set_termios to\n\t\t\t * configure according to command line arguments\n\t\t\t */\n\t\t\ttty = kzalloc(sizeof(*tty), GFP_KERNEL);\n\t\t\tif (!tty) {\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto reset_open_count;\n\t\t\t}\n\t\t\tkref_init(&tty->kref);\n\t\t\ttty->driver = usb_serial_tty_driver;\n\t\t\ttty->index = co->index;\n\t\t\tinit_ldsem(&tty->ldisc_sem);\n\t\t\tspin_lock_init(&tty->files_lock);\n\t\t\tINIT_LIST_HEAD(&tty->tty_files);\n\t\t\tkref_get(&tty->driver->kref);\n\t\t\t__module_get(tty->driver->owner);\n\t\t\ttty->ops = &usb_console_fake_tty_ops;\n\t\t\ttty_init_termios(tty);\n\t\t\ttty_port_tty_set(&port->port, tty);\n\t\t}\n\n\t\t/* only call the device specific open if this\n\t\t * is the first time the port is opened */\n\t\tretval = serial->type->open(NULL, port);\n\t\tif (retval) {\n\t\t\tdev_err(&port->dev, \"could not open USB console port\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (serial->type->set_termios) {\n\t\t\ttty->termios.c_cflag = cflag;\n\t\t\ttty_termios_encode_baud_rate(&tty->termios, baud, baud);\n\t\t\tmemset(&dummy, 0, sizeof(struct ktermios));\n\t\t\tserial->type->set_termios(tty, port, &dummy);\n\n\t\t\ttty_port_tty_set(&port->port, NULL);\n\t\t\ttty_kref_put(tty);\n\t\t}\n\t\ttty_port_set_initialized(&port->port, 1);\n\t}\n\t/* Now that any required fake tty operations are completed restore\n\t * the tty port count */\n\t--port->port.count;\n\t/* The console is special in terms of closing the device so\n\t * indicate this port is now acting as a system console. */\n\tport->port.console = 1;\n\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n\n fail:\n\ttty_port_tty_set(&port->port, NULL);\n\ttty_kref_put(tty);\n reset_open_count:\n\tport->port.count = 0;\n\tusb_autopm_put_interface(serial->interface);\n error_get_interface:\n\tusb_serial_put(serial);\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n}", "func_src_after": "static int usb_console_setup(struct console *co, char *options)\n{\n\tstruct usbcons_info *info = &usbcons_info;\n\tint baud = 9600;\n\tint bits = 8;\n\tint parity = 'n';\n\tint doflow = 0;\n\tint cflag = CREAD | HUPCL | CLOCAL;\n\tchar *s;\n\tstruct usb_serial *serial;\n\tstruct usb_serial_port *port;\n\tint retval;\n\tstruct tty_struct *tty = NULL;\n\tstruct ktermios dummy;\n\n\tif (options) {\n\t\tbaud = simple_strtoul(options, NULL, 10);\n\t\ts = options;\n\t\twhile (*s >= '0' && *s <= '9')\n\t\t\ts++;\n\t\tif (*s)\n\t\t\tparity = *s++;\n\t\tif (*s)\n\t\t\tbits   = *s++ - '0';\n\t\tif (*s)\n\t\t\tdoflow = (*s++ == 'r');\n\t}\n\t\n\t/* Sane default */\n\tif (baud == 0)\n\t\tbaud = 9600;\n\n\tswitch (bits) {\n\tcase 7:\n\t\tcflag |= CS7;\n\t\tbreak;\n\tdefault:\n\tcase 8:\n\t\tcflag |= CS8;\n\t\tbreak;\n\t}\n\tswitch (parity) {\n\tcase 'o': case 'O':\n\t\tcflag |= PARODD;\n\t\tbreak;\n\tcase 'e': case 'E':\n\t\tcflag |= PARENB;\n\t\tbreak;\n\t}\n\tco->cflag = cflag;\n\n\t/*\n\t * no need to check the index here: if the index is wrong, console\n\t * code won't call us\n\t */\n\tport = usb_serial_port_get_by_minor(co->index);\n\tif (port == NULL) {\n\t\t/* no device is connected yet, sorry :( */\n\t\tpr_err(\"No USB device connected to ttyUSB%i\\n\", co->index);\n\t\treturn -ENODEV;\n\t}\n\tserial = port->serial;\n\n\tretval = usb_autopm_get_interface(serial->interface);\n\tif (retval)\n\t\tgoto error_get_interface;\n\n\ttty_port_tty_set(&port->port, NULL);\n\n\tinfo->port = port;\n\n\t++port->port.count;\n\tif (!tty_port_initialized(&port->port)) {\n\t\tif (serial->type->set_termios) {\n\t\t\t/*\n\t\t\t * allocate a fake tty so the driver can initialize\n\t\t\t * the termios structure, then later call set_termios to\n\t\t\t * configure according to command line arguments\n\t\t\t */\n\t\t\ttty = kzalloc(sizeof(*tty), GFP_KERNEL);\n\t\t\tif (!tty) {\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto reset_open_count;\n\t\t\t}\n\t\t\tkref_init(&tty->kref);\n\t\t\ttty->driver = usb_serial_tty_driver;\n\t\t\ttty->index = co->index;\n\t\t\tinit_ldsem(&tty->ldisc_sem);\n\t\t\tspin_lock_init(&tty->files_lock);\n\t\t\tINIT_LIST_HEAD(&tty->tty_files);\n\t\t\tkref_get(&tty->driver->kref);\n\t\t\t__module_get(tty->driver->owner);\n\t\t\ttty->ops = &usb_console_fake_tty_ops;\n\t\t\ttty_init_termios(tty);\n\t\t\ttty_port_tty_set(&port->port, tty);\n\t\t}\n\n\t\t/* only call the device specific open if this\n\t\t * is the first time the port is opened */\n\t\tretval = serial->type->open(NULL, port);\n\t\tif (retval) {\n\t\t\tdev_err(&port->dev, \"could not open USB console port\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (serial->type->set_termios) {\n\t\t\ttty->termios.c_cflag = cflag;\n\t\t\ttty_termios_encode_baud_rate(&tty->termios, baud, baud);\n\t\t\tmemset(&dummy, 0, sizeof(struct ktermios));\n\t\t\tserial->type->set_termios(tty, port, &dummy);\n\n\t\t\ttty_port_tty_set(&port->port, NULL);\n\t\t\ttty_kref_put(tty);\n\t\t}\n\t\ttty_port_set_initialized(&port->port, 1);\n\t}\n\t/* Now that any required fake tty operations are completed restore\n\t * the tty port count */\n\t--port->port.count;\n\t/* The console is special in terms of closing the device so\n\t * indicate this port is now acting as a system console. */\n\tport->port.console = 1;\n\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n\n fail:\n\ttty_port_tty_set(&port->port, NULL);\n\ttty_kref_put(tty);\n reset_open_count:\n\tport->port.count = 0;\n\tinfo->port = NULL;\n\tusb_autopm_put_interface(serial->interface);\n error_get_interface:\n\tusb_serial_put(serial);\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n}", "commit_link": "github.com/torvalds/linux/commit/299d7572e46f98534033a9e65973f13ad1ce9047", "file_name": "drivers/usb/serial/console.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_console_setup` for setting up a USB console with configurable baud rate, parity, and data bits."}
{"func_name": "save_page_edit", "func_src_before": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "func_src_after": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "In Python, write a Flask endpoint to save edited content for a given page, creating the page in the database if it doesn't exist."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1463, "char_end": 1528, "line": "                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 41, "char_start": 1463, "char_end": 1510, "line": "                          XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 1488, "char_end": 1506, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/6ce2353fa77a891d1b556b8908ca9e4c227c3619", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "cb8f28bae4c5ab92e5b628d9b4f827d3c61ba6ce", "description": "Write a C function to parse a GraphML file into an igraph_t structure using libxml2."}
{"func_name": "set_fdc", "func_src_before": "static void set_fdc(int drive)\n{\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tfdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (fdc != 1 && fdc != 0) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "func_src_after": "static void set_fdc(int drive)\n{\n\tunsigned int new_fdc = fdc;\n\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tnew_fdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (new_fdc >= N_FDC) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tfdc = new_fdc;\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "commit_link": "github.com/torvalds/linux/commit/2e90ca68b0d2f5548804f22f0dd61145516171e3", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-125", "description": "Write a C function named `set_fdc` that configures a floppy disk controller (FDC) for a given drive number, with error checking and hardware status updates."}
{"func_name": "read_SubStreamsInfo", "func_src_before": "read_SubStreamsInfo(struct archive_read *a, struct _7z_substream_info *ss,\n    struct _7z_folder *f, size_t numFolders)\n{\n\tconst unsigned char *p;\n\tuint64_t *usizes;\n\tsize_t unpack_streams;\n\tint type;\n\tunsigned i;\n\tuint32_t numDigests;\n\n\tmemset(ss, 0, sizeof(*ss));\n\n\tfor (i = 0; i < numFolders; i++)\n\t\tf[i].numUnpackStreams = 1;\n\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\ttype = *p;\n\n\tif (type == kNumUnPackStream) {\n\t\tunpack_streams = 0;\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (parse_7zip_uint64(a, &(f[i].numUnpackStreams)) < 0)\n\t\t\t\treturn (-1);\n\t\t\tif (UMAX_ENTRY < f[i].numUnpackStreams)\n\t\t\t\treturn (-1);\n\t\t\tunpack_streams += (size_t)f[i].numUnpackStreams;\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t} else\n\t\tunpack_streams = numFolders;\n\n\tss->unpack_streams = unpack_streams;\n\tif (unpack_streams) {\n\t\tss->unpackSizes = calloc(unpack_streams,\n\t\t    sizeof(*ss->unpackSizes));\n\t\tss->digestsDefined = calloc(unpack_streams,\n\t\t    sizeof(*ss->digestsDefined));\n\t\tss->digests = calloc(unpack_streams,\n\t\t    sizeof(*ss->digests));\n\t\tif (ss->unpackSizes == NULL || ss->digestsDefined == NULL ||\n\t\t    ss->digests == NULL)\n\t\t\treturn (-1);\n\t}\n\n\tusizes = ss->unpackSizes;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tunsigned pack;\n\t\tuint64_t sum;\n\n\t\tif (f[i].numUnpackStreams == 0)\n\t\t\tcontinue;\n\n\t\tsum = 0;\n\t\tif (type == kSize) {\n\t\t\tfor (pack = 1; pack < f[i].numUnpackStreams; pack++) {\n\t\t\t\tif (parse_7zip_uint64(a, usizes) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t\tsum += *usizes++;\n\t\t\t}\n\t\t}\n\t\t*usizes++ = folder_uncompressed_size(&f[i]) - sum;\n\t}\n\n\tif (type == kSize) {\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\tfor (i = 0; i < unpack_streams; i++) {\n\t\tss->digestsDefined[i] = 0;\n\t\tss->digests[i] = 0;\n\t}\n\n\tnumDigests = 0;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tif (f[i].numUnpackStreams != 1 || !f[i].digest_defined)\n\t\t\tnumDigests += (uint32_t)f[i].numUnpackStreams;\n\t}\n\n\tif (type == kCRC) {\n\t\tstruct _7z_digests tmpDigests;\n\t\tunsigned char *digestsDefined = ss->digestsDefined;\n\t\tuint32_t * digests = ss->digests;\n\t\tint di = 0;\n\n\t\tmemset(&tmpDigests, 0, sizeof(tmpDigests));\n\t\tif (read_Digests(a, &(tmpDigests), numDigests) < 0) {\n\t\t\tfree_Digest(&tmpDigests);\n\t\t\treturn (-1);\n\t\t}\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (f[i].numUnpackStreams == 1 && f[i].digest_defined) {\n\t\t\t\t*digestsDefined++ = 1;\n\t\t\t\t*digests++ = f[i].digest;\n\t\t\t} else {\n\t\t\t\tunsigned j;\n\n\t\t\t\tfor (j = 0; j < f[i].numUnpackStreams;\n\t\t\t\t    j++, di++) {\n\t\t\t\t\t*digestsDefined++ =\n\t\t\t\t\t    tmpDigests.defineds[di];\n\t\t\t\t\t*digests++ =\n\t\t\t\t\t    tmpDigests.digests[di];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfree_Digest(&tmpDigests);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\t/*\n\t *  Must be kEnd.\n\t */\n\tif (type != kEnd)\n\t\treturn (-1);\n\treturn (0);\n}", "func_src_after": "read_SubStreamsInfo(struct archive_read *a, struct _7z_substream_info *ss,\n    struct _7z_folder *f, size_t numFolders)\n{\n\tconst unsigned char *p;\n\tuint64_t *usizes;\n\tsize_t unpack_streams;\n\tint type;\n\tunsigned i;\n\tuint32_t numDigests;\n\n\tmemset(ss, 0, sizeof(*ss));\n\n\tfor (i = 0; i < numFolders; i++)\n\t\tf[i].numUnpackStreams = 1;\n\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\ttype = *p;\n\n\tif (type == kNumUnPackStream) {\n\t\tunpack_streams = 0;\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (parse_7zip_uint64(a, &(f[i].numUnpackStreams)) < 0)\n\t\t\t\treturn (-1);\n\t\t\tif (UMAX_ENTRY < f[i].numUnpackStreams)\n\t\t\t\treturn (-1);\n\t\t\tif (unpack_streams > SIZE_MAX - UMAX_ENTRY) {\n\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tunpack_streams += (size_t)f[i].numUnpackStreams;\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t} else\n\t\tunpack_streams = numFolders;\n\n\tss->unpack_streams = unpack_streams;\n\tif (unpack_streams) {\n\t\tss->unpackSizes = calloc(unpack_streams,\n\t\t    sizeof(*ss->unpackSizes));\n\t\tss->digestsDefined = calloc(unpack_streams,\n\t\t    sizeof(*ss->digestsDefined));\n\t\tss->digests = calloc(unpack_streams,\n\t\t    sizeof(*ss->digests));\n\t\tif (ss->unpackSizes == NULL || ss->digestsDefined == NULL ||\n\t\t    ss->digests == NULL)\n\t\t\treturn (-1);\n\t}\n\n\tusizes = ss->unpackSizes;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tunsigned pack;\n\t\tuint64_t sum;\n\n\t\tif (f[i].numUnpackStreams == 0)\n\t\t\tcontinue;\n\n\t\tsum = 0;\n\t\tif (type == kSize) {\n\t\t\tfor (pack = 1; pack < f[i].numUnpackStreams; pack++) {\n\t\t\t\tif (parse_7zip_uint64(a, usizes) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t\tsum += *usizes++;\n\t\t\t}\n\t\t}\n\t\t*usizes++ = folder_uncompressed_size(&f[i]) - sum;\n\t}\n\n\tif (type == kSize) {\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\tfor (i = 0; i < unpack_streams; i++) {\n\t\tss->digestsDefined[i] = 0;\n\t\tss->digests[i] = 0;\n\t}\n\n\tnumDigests = 0;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tif (f[i].numUnpackStreams != 1 || !f[i].digest_defined)\n\t\t\tnumDigests += (uint32_t)f[i].numUnpackStreams;\n\t}\n\n\tif (type == kCRC) {\n\t\tstruct _7z_digests tmpDigests;\n\t\tunsigned char *digestsDefined = ss->digestsDefined;\n\t\tuint32_t * digests = ss->digests;\n\t\tint di = 0;\n\n\t\tmemset(&tmpDigests, 0, sizeof(tmpDigests));\n\t\tif (read_Digests(a, &(tmpDigests), numDigests) < 0) {\n\t\t\tfree_Digest(&tmpDigests);\n\t\t\treturn (-1);\n\t\t}\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (f[i].numUnpackStreams == 1 && f[i].digest_defined) {\n\t\t\t\t*digestsDefined++ = 1;\n\t\t\t\t*digests++ = f[i].digest;\n\t\t\t} else {\n\t\t\t\tunsigned j;\n\n\t\t\t\tfor (j = 0; j < f[i].numUnpackStreams;\n\t\t\t\t    j++, di++) {\n\t\t\t\t\t*digestsDefined++ =\n\t\t\t\t\t    tmpDigests.defineds[di];\n\t\t\t\t\t*digests++ =\n\t\t\t\t\t    tmpDigests.digests[di];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfree_Digest(&tmpDigests);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\t/*\n\t *  Must be kEnd.\n\t */\n\tif (type != kEnd)\n\t\treturn (-1);\n\treturn (0);\n}", "commit_link": "github.com/libarchive/libarchive/commit/e79ef306afe332faf22e9b442a2c6b59cb175573", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-190", "description": "In C, write a function to read substream information for folders within a 7z archive."}
{"func_name": "get_ports", "func_src_before": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run('showport', None)\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run('showport -iscsi', None)\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run('showport -iscsiname', None)\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "func_src_after": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run(['showport'])\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run(['showport', '-iscsi'])\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run(['showport', '-iscsiname'])\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to parse and return active FC and iSCSI port details from CLI output."}
{"func_name": "fetch_resultSet", "func_src_before": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = '%s', expires = '%s' \"\n                 \"WHERE identifier = '%s';\" %\n                 (self.table, nowStr, expiresStr, sid)\n                 )\n        self._query(query)\n        return rset", "func_src_after": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = $1, expires = $2 \"\n                 \"WHERE identifier = $3;\" % (self.table)\n                 )\n        self._query(query, nowStr, expiresStr, sid)\n        return rset", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and updates a record from a database using either string formatting or parameterized queries."}
{"func_name": "_get_degree_2", "func_src_before": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC' % (user_id, user_id, user_id)\n    with cnx.cursor() as cursor:\n        cursor.execute(sql)\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "func_src_after": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC'\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "commit_link": "github.com/young-goons/rifflo-server/commit/fb311df76713b638c9486250f9badb288ffb2189", "file_name": "server/ygoons/modules/user/follow_suggest.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch second-degree connections not followed by a user from a database."}
{"func_name": "PlayerGeneric::~PlayerGeneric", "func_src_before": "PlayerGeneric::~PlayerGeneric()\n{\n\tif (mixer)\n\t\tdelete mixer;\n\n\tif (player)\n\t{\n\t\tif (mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "func_src_after": "PlayerGeneric::~PlayerGeneric()\n{\n\n\tif (player)\n\t{\n\t\tif (mixer && mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\t\n\tif (mixer)\n\t\tdelete mixer;\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "commit_link": "github.com/milkytracker/MilkyTracker/commit/7afd55c42ad80d01a339197a2d8b5461d214edaf", "file_name": "src/milkyplay/PlayerGeneric.cpp", "vul_type": "cwe-416", "description": "Write a C++ destructor for a class named `PlayerGeneric` that cleans up memory by deleting member pointers, ensuring that a `mixer` object is properly deactivated and devices are removed before deletion."}
{"func_name": "__mdiobus_register", "func_src_before": "int __mdiobus_register(struct mii_bus *bus, struct module *owner)\n{\n\tstruct mdio_device *mdiodev;\n\tint i, err;\n\tstruct gpio_desc *gpiod;\n\n\tif (NULL == bus || NULL == bus->name ||\n\t    NULL == bus->read || NULL == bus->write)\n\t\treturn -EINVAL;\n\n\tBUG_ON(bus->state != MDIOBUS_ALLOCATED &&\n\t       bus->state != MDIOBUS_UNREGISTERED);\n\n\tbus->owner = owner;\n\tbus->dev.parent = bus->parent;\n\tbus->dev.class = &mdio_bus_class;\n\tbus->dev.groups = NULL;\n\tdev_set_name(&bus->dev, \"%s\", bus->id);\n\n\terr = device_register(&bus->dev);\n\tif (err) {\n\t\tpr_err(\"mii_bus %s failed to register\\n\", bus->id);\n\t\tput_device(&bus->dev);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_init(&bus->mdio_lock);\n\n\t/* de-assert bus level PHY GPIO reset */\n\tgpiod = devm_gpiod_get_optional(&bus->dev, \"reset\", GPIOD_OUT_LOW);\n\tif (IS_ERR(gpiod)) {\n\t\tdev_err(&bus->dev, \"mii_bus %s couldn't get reset GPIO\\n\",\n\t\t\tbus->id);\n\t\tdevice_del(&bus->dev);\n\t\treturn PTR_ERR(gpiod);\n\t} else\tif (gpiod) {\n\t\tbus->reset_gpiod = gpiod;\n\n\t\tgpiod_set_value_cansleep(gpiod, 1);\n\t\tudelay(bus->reset_delay_us);\n\t\tgpiod_set_value_cansleep(gpiod, 0);\n\t}\n\n\tif (bus->reset)\n\t\tbus->reset(bus);\n\n\tfor (i = 0; i < PHY_MAX_ADDR; i++) {\n\t\tif ((bus->phy_mask & (1 << i)) == 0) {\n\t\t\tstruct phy_device *phydev;\n\n\t\t\tphydev = mdiobus_scan(bus, i);\n\t\t\tif (IS_ERR(phydev) && (PTR_ERR(phydev) != -ENODEV)) {\n\t\t\t\terr = PTR_ERR(phydev);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\tmdiobus_setup_mdiodev_from_board_info(bus, mdiobus_create_device);\n\n\tbus->state = MDIOBUS_REGISTERED;\n\tpr_info(\"%s: probed\\n\", bus->name);\n\treturn 0;\n\nerror:\n\twhile (--i >= 0) {\n\t\tmdiodev = bus->mdio_map[i];\n\t\tif (!mdiodev)\n\t\t\tcontinue;\n\n\t\tmdiodev->device_remove(mdiodev);\n\t\tmdiodev->device_free(mdiodev);\n\t}\n\n\t/* Put PHYs in RESET to save power */\n\tif (bus->reset_gpiod)\n\t\tgpiod_set_value_cansleep(bus->reset_gpiod, 1);\n\n\tdevice_del(&bus->dev);\n\treturn err;\n}", "func_src_after": "int __mdiobus_register(struct mii_bus *bus, struct module *owner)\n{\n\tstruct mdio_device *mdiodev;\n\tint i, err;\n\tstruct gpio_desc *gpiod;\n\n\tif (NULL == bus || NULL == bus->name ||\n\t    NULL == bus->read || NULL == bus->write)\n\t\treturn -EINVAL;\n\n\tBUG_ON(bus->state != MDIOBUS_ALLOCATED &&\n\t       bus->state != MDIOBUS_UNREGISTERED);\n\n\tbus->owner = owner;\n\tbus->dev.parent = bus->parent;\n\tbus->dev.class = &mdio_bus_class;\n\tbus->dev.groups = NULL;\n\tdev_set_name(&bus->dev, \"%s\", bus->id);\n\n\terr = device_register(&bus->dev);\n\tif (err) {\n\t\tpr_err(\"mii_bus %s failed to register\\n\", bus->id);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_init(&bus->mdio_lock);\n\n\t/* de-assert bus level PHY GPIO reset */\n\tgpiod = devm_gpiod_get_optional(&bus->dev, \"reset\", GPIOD_OUT_LOW);\n\tif (IS_ERR(gpiod)) {\n\t\tdev_err(&bus->dev, \"mii_bus %s couldn't get reset GPIO\\n\",\n\t\t\tbus->id);\n\t\tdevice_del(&bus->dev);\n\t\treturn PTR_ERR(gpiod);\n\t} else\tif (gpiod) {\n\t\tbus->reset_gpiod = gpiod;\n\n\t\tgpiod_set_value_cansleep(gpiod, 1);\n\t\tudelay(bus->reset_delay_us);\n\t\tgpiod_set_value_cansleep(gpiod, 0);\n\t}\n\n\tif (bus->reset)\n\t\tbus->reset(bus);\n\n\tfor (i = 0; i < PHY_MAX_ADDR; i++) {\n\t\tif ((bus->phy_mask & (1 << i)) == 0) {\n\t\t\tstruct phy_device *phydev;\n\n\t\t\tphydev = mdiobus_scan(bus, i);\n\t\t\tif (IS_ERR(phydev) && (PTR_ERR(phydev) != -ENODEV)) {\n\t\t\t\terr = PTR_ERR(phydev);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\tmdiobus_setup_mdiodev_from_board_info(bus, mdiobus_create_device);\n\n\tbus->state = MDIOBUS_REGISTERED;\n\tpr_info(\"%s: probed\\n\", bus->name);\n\treturn 0;\n\nerror:\n\twhile (--i >= 0) {\n\t\tmdiodev = bus->mdio_map[i];\n\t\tif (!mdiodev)\n\t\t\tcontinue;\n\n\t\tmdiodev->device_remove(mdiodev);\n\t\tmdiodev->device_free(mdiodev);\n\t}\n\n\t/* Put PHYs in RESET to save power */\n\tif (bus->reset_gpiod)\n\t\tgpiod_set_value_cansleep(bus->reset_gpiod, 1);\n\n\tdevice_del(&bus->dev);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/6ff7b060535e87c2ae14dd8548512abfdda528fb", "file_name": "drivers/net/phy/mdio_bus.c", "vul_type": "cwe-416", "description": "In C, write a function to register an MDIO bus with error handling and PHY device scanning."}
{"func_name": "vault_encrypt", "func_src_before": "def vault_encrypt(v_plaintexts, mp):\n    iv = '01234567'\n    vault_code = vault_encode(v_plaintexts, mp)\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n    # plaintext= staruct.pack(\"%sI\" % len(vault_code), *vault_code)\n    c = des3.encrypt(vault_code)\n    return c", "func_src_after": "def vault_encrypt(v_plaintexts, mp):\n    aes = do_crypto_setup(mp)\n    return aes.encrypt(vault_encode(v_plaintexts, mp))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 37, "char_end": 57, "line": "    iv = '01234567'\n"}, {"line_no": 3, "char_start": 57, "char_end": 105, "line": "    vault_code = vault_encode(v_plaintexts, mp)\n"}, {"line_no": 4, "char_start": 105, "char_end": 157, "line": "    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n"}, {"line_no": 6, "char_start": 225, "char_end": 258, "line": "    c = des3.encrypt(vault_code)\n"}, {"line_no": 7, "char_start": 258, "char_end": 270, "line": "    return c\n"}], "added": [{"line_no": 2, "char_start": 37, "char_end": 67, "line": "    aes = do_crypto_setup(mp)\n"}, {"line_no": 3, "char_start": 67, "char_end": 121, "line": "    return aes.encrypt(vault_encode(v_plaintexts, mp))\n"}]}, "char_changes": {"deleted": [{"char_start": 41, "char_end": 234, "chars": "iv = '01234567'\n    vault_code = vault_encode(v_plaintexts, mp)\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n    # plaintext= staruct.pack(\"%sI\" % len(vault_code), *vault_code)\n    c = d"}, {"char_start": 236, "char_end": 237, "chars": "3"}, {"char_start": 256, "char_end": 270, "chars": ")\n    return c"}], "added": [{"char_start": 41, "char_end": 79, "chars": "aes = do_crypto_setup(mp)\n    return a"}, {"char_start": 96, "char_end": 98, "chars": "en"}, {"char_start": 102, "char_end": 121, "chars": "(v_plaintexts, mp))"}]}, "commit_link": "github.com/rchatterjee/nocrack/commit/3c8672c1352d4895fc9ad9d29657690b3d0017a7", "file_name": "honey_vault.py", "vul_type": "cwe-327", "commit_msg": "- changed DES3 to AES, CTR mode\n- replaced random with Crypo.Random.random ~~ cryptographically more secure!", "description": "Write a Python function named `vault_encrypt` that takes a list of plaintexts and a master password, then returns an encrypted version of the processed plaintexts."}
{"func_name": "(anonymous)", "func_src_before": "    db.get(\"SELECT id,note FROM notes WHERE id = '\"+data.id+\"'\",function(err,row){\n      if(row){\n        socket.emit('setNote', { note: row.note });\n      } else {\n        socket.emit('setNote', { note: \"\" });\n      }\n    //res.send(row.note);\n    });", "func_src_after": "    db.get(\"SELECT id,note FROM notes WHERE id = ?\",[data.id],function(err,row){\n      if(row){\n        socket.emit('setNote', { note: row.note});\n      } else {\n        socket.emit('setNote', { note: \"\" });\n      }\n    //res.send(row.note);\n    });", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 83, "line": "    db.get(\"SELECT id,note FROM notes WHERE id = '\"+data.id+\"'\",function(err,row){\n"}, {"line_no": 3, "char_start": 98, "char_end": 150, "line": "        socket.emit('setNote', { note: row.note });\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 81, "line": "    db.get(\"SELECT id,note FROM notes WHERE id = ?\",[data.id],function(err,row){\n"}, {"line_no": 3, "char_start": 96, "char_end": 147, "line": "        socket.emit('setNote', { note: row.note});\n"}]}, "char_changes": {"deleted": [{"char_start": 49, "char_end": 52, "chars": "'\"+"}, {"char_start": 59, "char_end": 63, "chars": "+\"'\""}, {"char_start": 145, "char_end": 146, "chars": " "}], "added": [{"char_start": 49, "char_end": 53, "chars": "?\",["}, {"char_start": 60, "char_end": 61, "chars": "]"}]}, "commit_link": "github.com/yoyodyne/litwritesabook/commit/6ed77576195866819411628e917cd157e2a61361", "file_name": "app.js", "vul_type": "cwe-089", "commit_msg": "SQL injection prevented.", "description": "Write a JavaScript function that retrieves a note from a database using an ID and sends it through a socket."}
{"func_name": "self.lookup", "func_src_before": "  def self.lookup(lat, lng)\n    all(:conditions => \"ST_Contains(the_geom, GeometryFromText('POINT(#{lng} #{lat})', -1))\")\n  end", "func_src_after": "  def self.lookup(lat, lng)\n    all(:conditions => [\"ST_Contains(the_geom, GeometryFromText('POINT(? ?)', -1))\",lng.to_f,lat.to_f])\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 28, "char_end": 122, "line": "    all(:conditions => \"ST_Contains(the_geom, GeometryFromText('POINT(#{lng} #{lat})', -1))\")\n"}], "added": [{"line_no": 2, "char_start": 28, "char_end": 132, "line": "    all(:conditions => [\"ST_Contains(the_geom, GeometryFromText('POINT(? ?)', -1))\",lng.to_f,lat.to_f])\n"}]}, "char_changes": {"deleted": [{"char_start": 98, "char_end": 120, "chars": "#{lng} #{lat})', -1))\""}], "added": [{"char_start": 51, "char_end": 52, "chars": "["}, {"char_start": 99, "char_end": 130, "chars": "? ?)', -1))\",lng.to_f,lat.to_f]"}]}, "commit_link": "github.com/mcommons/legislative-lookup/commit/7e297286558e6adf1ceee9dcbbfbcd1d12a6f335", "file_name": "district.rb", "vul_type": "cwe-089", "commit_msg": "BUGFIX sql injection.", "description": "Write a Ruby method to find all records in a database that contain a given latitude and longitude point."}
{"func_name": "customization_disabled?", "func_src_before": "  def customization_disabled?\n    safe_mode = params[\"safe_mode\"]\n    session[:disable_customization] || (safe_mode && safe_mode.include?(\"no_custom\"))\n  end", "func_src_after": "  def customization_disabled?\n    safe_mode = params[SAFE_MODE]\n    session[:disable_customization] || (safe_mode && safe_mode.include?(NO_CUSTOM))\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 30, "char_end": 66, "line": "    safe_mode = params[\"safe_mode\"]\n"}, {"line_no": 3, "char_start": 66, "char_end": 152, "line": "    session[:disable_customization] || (safe_mode && safe_mode.include?(\"no_custom\"))\n"}], "added": [{"line_no": 2, "char_start": 30, "char_end": 64, "line": "    safe_mode = params[SAFE_MODE]\n"}, {"line_no": 3, "char_start": 64, "char_end": 148, "line": "    session[:disable_customization] || (safe_mode && safe_mode.include?(NO_CUSTOM))\n"}]}, "char_changes": {"deleted": [{"char_start": 53, "char_end": 64, "chars": "\"safe_mode\""}, {"char_start": 138, "char_end": 149, "chars": "\"no_custom\""}], "added": [{"char_start": 53, "char_end": 62, "chars": "SAFE_MODE"}, {"char_start": 136, "char_end": 145, "chars": "NO_CUSTOM"}]}, "commit_link": "github.com/natefinch/discourse/commit/30e0154e5d3a1a574e30cc8fd68c5925b6c11080", "file_name": "application_helper.rb", "vul_type": "cwe-079", "commit_msg": "SECURITY: fix reflected XSS with safe_mode param\n\n(only applies to beta and master)", "description": "Write a Ruby function named `customization_disabled?` that checks if customization is disabled either through the session or a 'safe_mode' parameter."}
{"func_name": "_create_vdisk", "func_src_before": "    def _create_vdisk(self, name, size, units, opts):\n        \"\"\"Create a new vdisk.\"\"\"\n\n        LOG.debug(_('enter: _create_vdisk: vdisk %s ') % name)\n\n        model_update = None\n        autoex = '-autoexpand' if opts['autoexpand'] else ''\n        easytier = '-easytier on' if opts['easytier'] else '-easytier off'\n\n        # Set space-efficient options\n        if opts['rsize'] == -1:\n            ssh_cmd_se_opt = ''\n        else:\n            ssh_cmd_se_opt = (\n                '-rsize %(rsize)d%% %(autoex)s -warning %(warn)d%%' %\n                {'rsize': opts['rsize'],\n                 'autoex': autoex,\n                 'warn': opts['warning']})\n            if opts['compression']:\n                ssh_cmd_se_opt = ssh_cmd_se_opt + ' -compressed'\n            else:\n                ssh_cmd_se_opt = ssh_cmd_se_opt + (\n                    ' -grainsize %d' % opts['grainsize'])\n\n        ssh_cmd = ('svctask mkvdisk -name %(name)s -mdiskgrp %(mdiskgrp)s '\n                   '-iogrp 0 -size %(size)s -unit '\n                   '%(unit)s %(easytier)s %(ssh_cmd_se_opt)s'\n                   % {'name': name,\n                   'mdiskgrp': self.configuration.storwize_svc_volpool_name,\n                   'size': size, 'unit': units, 'easytier': easytier,\n                   'ssh_cmd_se_opt': ssh_cmd_se_opt})\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), '_create_vdisk',\n                                ssh_cmd, out, err)\n\n        # Ensure that the output is as expected\n        match_obj = re.search('Virtual Disk, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('_create_vdisk %(name)s - did not find '\n              'success message in CLI output.\\n '\n              'stdout: %(out)s\\n stderr: %(err)s')\n            % {'name': name, 'out': str(out), 'err': str(err)})\n\n        LOG.debug(_('leave: _create_vdisk: volume %s ') % name)", "func_src_after": "    def _create_vdisk(self, name, size, units, opts):\n        \"\"\"Create a new vdisk.\"\"\"\n\n        LOG.debug(_('enter: _create_vdisk: vdisk %s ') % name)\n\n        model_update = None\n        easytier = 'on' if opts['easytier'] else 'off'\n\n        # Set space-efficient options\n        if opts['rsize'] == -1:\n            ssh_cmd_se_opt = []\n        else:\n            ssh_cmd_se_opt = ['-rsize', '%s%%' % str(opts['rsize']),\n                              '-autoexpand', '-warning',\n                              '%s%%' % str(opts['warning'])]\n            if not opts['autoexpand']:\n                ssh_cmd_se_opt.remove('-autoexpand')\n\n            if opts['compression']:\n                ssh_cmd_se_opt.append('-compressed')\n            else:\n                ssh_cmd_se_opt.extend(['-grainsize', str(opts['grainsize'])])\n\n        ssh_cmd = ['svctask', 'mkvdisk', '-name', name, '-mdiskgrp',\n                   self.configuration.storwize_svc_volpool_name,\n                   '-iogrp', '0', '-size', size, '-unit',\n                   units, '-easytier', easytier] + ssh_cmd_se_opt\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), '_create_vdisk',\n                                ssh_cmd, out, err)\n\n        # Ensure that the output is as expected\n        match_obj = re.search('Virtual Disk, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('_create_vdisk %(name)s - did not find '\n              'success message in CLI output.\\n '\n              'stdout: %(out)s\\n stderr: %(err)s')\n            % {'name': name, 'out': str(out), 'err': str(err)})\n\n        LOG.debug(_('leave: _create_vdisk: volume %s ') % name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a virtual disk with options for size, auto-expansion, easy tier, and compression."}
{"func_name": "(anonymous)", "func_src_before": "        .then(()=>rimraf(tempDir));", "func_src_after": "        .then(() => tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 35, "line": "        .then(()=>rimraf(tempDir));\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 123, "line": "        .then(() => tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))\n"}]}, "char_changes": {"deleted": [{"char_start": 18, "char_end": 32, "chars": "rimraf(tempDir"}, {"char_start": 34, "char_end": 35, "chars": ";"}], "added": [{"char_start": 16, "char_end": 17, "chars": " "}, {"char_start": 19, "char_end": 121, "chars": " tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality"}]}, "commit_link": "github.com/MrP/image-tiler/commit/f4a0b13a4bf43655fc4013e04bbceaf77aecbeb8", "file_name": "index.js", "vul_type": "cwe-078", "commit_msg": "fix command injection vuln", "description": "Write a JavaScript promise chain that includes a `.then()` method executing a callback function that performs an operation on a directory or manipulates image tiles."}
{"func_name": "test_creates_yaml_config_file_and_path_to_it_from_example_config", "func_src_before": "  def test_creates_yaml_config_file_and_path_to_it_from_example_config\n    refute File.exist?(CONFIG_PATH)\n    refute_nil ActsAsTextcaptcha::TextcaptchaConfig.create(path: CONFIG_PATH)\n    assert File.exist?(CONFIG_PATH)\n\n    # rubocop:disable Security/YAMLLoad\n    example_config = YAML.load(File.read(CONFIG_PATH))\n    # rubocop:enable Security/YAMLLoad\n    assert_equal example_config.keys, %w(development test production)\n  end", "func_src_after": "  def test_creates_yaml_config_file_and_path_to_it_from_example_config\n    refute File.exist?(CONFIG_PATH)\n    refute_nil ActsAsTextcaptcha::TextcaptchaConfig.create(path: CONFIG_PATH)\n    assert File.exist?(CONFIG_PATH)\n\n    # rubocop:disable Security/YAMLLoad\n    example_config = YAML.safe_load(File.read(CONFIG_PATH), aliases: true)\n    # rubocop:enable Security/YAMLLoad\n    assert_equal example_config.keys, %w(development test production)\n  end", "line_changes": {"deleted": [{"line_no": 7, "char_start": 262, "char_end": 317, "line": "    example_config = YAML.load(File.read(CONFIG_PATH))\n"}], "added": [{"line_no": 7, "char_start": 262, "char_end": 337, "line": "    example_config = YAML.safe_load(File.read(CONFIG_PATH), aliases: true)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 288, "char_end": 293, "chars": "safe_"}, {"char_start": 320, "char_end": 335, "chars": ", aliases: true"}]}, "commit_link": "github.com/matthutchinson/acts_as_textcaptcha/commit/09b2c281859c07e8cc966e604153ba97bc3c6ec2", "file_name": "textcaptcha_config_test.rb", "vul_type": "cwe-502", "commit_msg": "update tests to use YAML.safe_load", "parent_commit": "f9b9d1623306bb621cd1c14574a4a07513368ce7", "description": "Write a Ruby test method that checks the creation of a YAML configuration file and verifies its contents."}
{"func_name": "rds_cmsg_atomic", "func_src_before": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "func_src_after": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\trm->atomic.op_active = 0;\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7d11f77f84b27cef452cee332f4e469503084737", "file_name": "net/rds/rdma.c", "vul_type": "cwe-476", "description": "Write a C function named `rds_cmsg_atomic` that processes atomic operations in RDS messages."}
{"func_name": "openscript", "func_src_before": "openscript(\n    char_u\t*name,\n    int\t\tdirectly)\t/* when TRUE execute directly */\n{\n    if (curscript + 1 == NSCRIPT)\n    {\n\temsg(_(e_nesting));\n\treturn;\n    }\n#ifdef FEAT_EVAL\n    if (ignore_script)\n\t/* Not reading from script, also don't open one.  Warning message? */\n\treturn;\n#endif\n\n    if (scriptin[curscript] != NULL)\t/* already reading script */\n\t++curscript;\n\t\t\t\t/* use NameBuff for expanded name */\n    expand_env(name, NameBuff, MAXPATHL);\n    if ((scriptin[curscript] = mch_fopen((char *)NameBuff, READBIN)) == NULL)\n    {\n\tsemsg(_(e_notopen), name);\n\tif (curscript)\n\t    --curscript;\n\treturn;\n    }\n    if (save_typebuf() == FAIL)\n\treturn;\n\n    /*\n     * Execute the commands from the file right now when using \":source!\"\n     * after \":global\" or \":argdo\" or in a loop.  Also when another command\n     * follows.  This means the display won't be updated.  Don't do this\n     * always, \"make test\" would fail.\n     */\n    if (directly)\n    {\n\toparg_T\toa;\n\tint\toldcurscript;\n\tint\tsave_State = State;\n\tint\tsave_restart_edit = restart_edit;\n\tint\tsave_insertmode = p_im;\n\tint\tsave_finish_op = finish_op;\n\tint\tsave_msg_scroll = msg_scroll;\n\n\tState = NORMAL;\n\tmsg_scroll = FALSE;\t/* no msg scrolling in Normal mode */\n\trestart_edit = 0;\t/* don't go to Insert mode */\n\tp_im = FALSE;\t\t/* don't use 'insertmode' */\n\tclear_oparg(&oa);\n\tfinish_op = FALSE;\n\n\toldcurscript = curscript;\n\tdo\n\t{\n\t    update_topline_cursor();\t// update cursor position and topline\n\t    normal_cmd(&oa, FALSE);\t// execute one command\n\t    vpeekc();\t\t\t// check for end of file\n\t}\n\twhile (scriptin[oldcurscript] != NULL);\n\n\tState = save_State;\n\tmsg_scroll = save_msg_scroll;\n\trestart_edit = save_restart_edit;\n\tp_im = save_insertmode;\n\tfinish_op = save_finish_op;\n    }\n}", "func_src_after": "openscript(\n    char_u\t*name,\n    int\t\tdirectly)\t/* when TRUE execute directly */\n{\n    if (curscript + 1 == NSCRIPT)\n    {\n\temsg(_(e_nesting));\n\treturn;\n    }\n\n    // Disallow sourcing a file in the sandbox, the commands would be executed\n    // later, possibly outside of the sandbox.\n    if (check_secure())\n\treturn;\n\n#ifdef FEAT_EVAL\n    if (ignore_script)\n\t/* Not reading from script, also don't open one.  Warning message? */\n\treturn;\n#endif\n\n    if (scriptin[curscript] != NULL)\t/* already reading script */\n\t++curscript;\n\t\t\t\t/* use NameBuff for expanded name */\n    expand_env(name, NameBuff, MAXPATHL);\n    if ((scriptin[curscript] = mch_fopen((char *)NameBuff, READBIN)) == NULL)\n    {\n\tsemsg(_(e_notopen), name);\n\tif (curscript)\n\t    --curscript;\n\treturn;\n    }\n    if (save_typebuf() == FAIL)\n\treturn;\n\n    /*\n     * Execute the commands from the file right now when using \":source!\"\n     * after \":global\" or \":argdo\" or in a loop.  Also when another command\n     * follows.  This means the display won't be updated.  Don't do this\n     * always, \"make test\" would fail.\n     */\n    if (directly)\n    {\n\toparg_T\toa;\n\tint\toldcurscript;\n\tint\tsave_State = State;\n\tint\tsave_restart_edit = restart_edit;\n\tint\tsave_insertmode = p_im;\n\tint\tsave_finish_op = finish_op;\n\tint\tsave_msg_scroll = msg_scroll;\n\n\tState = NORMAL;\n\tmsg_scroll = FALSE;\t/* no msg scrolling in Normal mode */\n\trestart_edit = 0;\t/* don't go to Insert mode */\n\tp_im = FALSE;\t\t/* don't use 'insertmode' */\n\tclear_oparg(&oa);\n\tfinish_op = FALSE;\n\n\toldcurscript = curscript;\n\tdo\n\t{\n\t    update_topline_cursor();\t// update cursor position and topline\n\t    normal_cmd(&oa, FALSE);\t// execute one command\n\t    vpeekc();\t\t\t// check for end of file\n\t}\n\twhile (scriptin[oldcurscript] != NULL);\n\n\tState = save_State;\n\tmsg_scroll = save_msg_scroll;\n\trestart_edit = save_restart_edit;\n\tp_im = save_insertmode;\n\tfinish_op = save_finish_op;\n    }\n}", "commit_link": "github.com/vim/vim/commit/53575521406739cf20bbe4e384d88e7dca11f040", "file_name": "src/getchar.c", "vul_type": "cwe-078", "description": "In C, write a function `openscript` that takes a script name and a flag to execute directly, handling script nesting and environment expansion."}
{"func_name": "(anonymous)", "func_src_before": "\t\texec('node ' + binPath + ' -v -', function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "func_src_after": "\t\texecFile('node', [binPath, '-v', '-'], function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 69, "line": "\t\texec('node ' + binPath + ' -v -', function (err, stdout, stderr) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 74, "line": "\t\texecFile('node', [binPath, '-v', '-'], function (err, stdout, stderr) {\n"}]}, "char_changes": {"deleted": [{"char_start": 12, "char_end": 17, "chars": " ' + "}, {"char_start": 24, "char_end": 26, "chars": " +"}, {"char_start": 28, "char_end": 29, "chars": " "}, {"char_start": 31, "char_end": 32, "chars": " "}], "added": [{"char_start": 6, "char_end": 10, "chars": "File"}, {"char_start": 16, "char_end": 20, "chars": "', ["}, {"char_start": 27, "char_end": 28, "chars": ","}, {"char_start": 32, "char_end": 36, "chars": "', '"}, {"char_start": 38, "char_end": 39, "chars": "]"}]}, "commit_link": "github.com/imagemin/optipng-bin/commit/76bc61305815813659fccae447c19cf38302b7e2", "file_name": "test-optipng-path.js", "vul_type": "cwe-078", "commit_msg": "use execFile and arguments array instead of string concat", "parent_commit": "fffe11371341e0360ecde090cf6f2bac5d81505a", "description": "Write a JavaScript function that executes a command to check for 'OptiPNG' in the error output and calls a callback function."}
{"func_name": "Updater::updateModule", "func_src_before": "\tprivate void updateModule( final ModuleBean module, final boolean external, final boolean repair ) {\n\t\tLEnv.LOGGER.info( ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() + \"...\" );\n\t\tlauncherFrame.setStatus( StatusType.PROGRESS, ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() );\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart, show RESTART action while updating the launcher\n\t\t\tlauncherFrame.setProceedText( \"<html><h2>RE_START</h2></html>\" );\n\t\t}\n\t\t\n\t\tfinal Path tempPath = ( external ? LEnv.PATH_EXT_MODS : LEnv.PATH_MODS ).resolve( \"_update\" );\n\t\ttry {\n\t\t\t// Create temp update folder\n\t\t\twhile ( !LUtils.deletePath( tempPath ) )\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) )\n\t\t\t\t\tthrow new Exception( \"Could not delete folder: \" + tempPath );\n\t\t\tFiles.createDirectory( tempPath );\n\t\t\t\n\t\t\tfinal Path archivePath = tempPath.resolve( module.getArchiveFile().getPath() );\n\t\t\t\n\t\t\t// Download module archive, try mirrors if one fails\n\t\t\tfinal byte[] buffer = new byte[ 16_384 ]; // 16 KB work buffer\n\t\t\tfor ( int urlIdx = 0; urlIdx < module.getUrlList().size(); urlIdx++ ) {\n\t\t\t\tfinal String archiveSource = urlIdx == 0 ? \"main source\" : \" mirror #\" + urlIdx;\n\t\t\t\tfinal boolean lastArchiveUrl = urlIdx == module.getUrlList().size() - 1;\n\t\t\t\t\n\t\t\t\tLEnv.LOGGER.debug( \"Downloading archive from \" + archiveSource + \"...\" );\n\t\t\t\t\n\t\t\t\tboolean downloadOk = false;\n\t\t\t\tInputStream input = null;\n\t\t\t\tOutputStream output = null;\n\t\t\t\ttry {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Connecting...\" );\n\t\t\t\t\tlauncherFrame.setProgressMax( (int) module.getArchiveSize() );\n\t\t\t\t\tlauncherFrame.setProgress( 0 );\n\t\t\t\t\t\n\t\t\t\t\tfinal URLConnection archiveUrlConnection = new URL( module.getUrlList().get( urlIdx ) ).openConnection();\n\t\t\t\t\t\n\t\t\t\t\tinput = archiveUrlConnection.getInputStream();\n\t\t\t\t\toutput = Files.newOutputStream( archivePath );\n\t\t\t\t\t\n\t\t\t\t\tLEnv.LOGGER.debug( \"Downloading...\" );\n\t\t\t\t\tint totalBytesRead = 0;\n\t\t\t\t\tint bytesRead;\n\t\t\t\t\twhile ( ( bytesRead = input.read( buffer ) ) > 0 ) {\n\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\ttotalBytesRead += bytesRead;\n\t\t\t\t\t\tlauncherFrame.setProgress( totalBytesRead );\n\t\t\t\t\t}\n\t\t\t\t\toutput.flush();\n\t\t\t\t\t\n\t\t\t\t\tdownloadOk = true;\n\t\t\t\t\tLEnv.LOGGER.debug( \"Download complete.\" );\n\t\t\t\t\t\n\t\t\t\t} catch ( final Exception e ) {\n\t\t\t\t\tLEnv.LOGGER.warning(\n\t\t\t\t\t        \"Failed to download archive from \" + archiveSource + \"!\" + ( lastArchiveUrl ? \"\" : \" Proceeding to the next source.\" ), e );\n\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t} finally {\n\t\t\t\t\tif ( input != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tinput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\tinput = null;\n\t\t\t\t\t}\n\t\t\t\t\tif ( output != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\toutput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif ( downloadOk ) {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Checking SHA-256 checksum of the archive...\" );\n\t\t\t\t\tif ( module.getArchiveFile().getSha256().equals( LUtils.calculateFileSha256( archivePath ) ) ) {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum OK.\" );\n\t\t\t\t\t\tbreak; // Break archive URLs cycle\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum MISMATCH! The downloaded archive is discarded!\" );\n\t\t\t\t\t\twhile ( !LUtils.deletePath( archivePath ) )\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete file:\", archivePath ) )\n\t\t\t\t\t\t\t\tthrow new Exception( \"Could not delete file: \" + archivePath );\n\t\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tLEnv.LOGGER.debug( \"Proceeding to the next source.\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( \"Extracting archive...\" );\n\t\t\tfinal InputStream ins = Files.newInputStream( archivePath ); // Input stream is \"out-sourced\" to a local var because\n\t\t\t                                                             // else a false resource leak is reported :S\n\t\t\ttry ( final ZipInputStream zipInput = new ZipInputStream( ins ) ) {\n\t\t\t\tfinal String pathPrefix = external ? \"Scelight/\" + LEnv.PATH_EXT_MODS.getFileName().toString() + \"/\" + module.getFolder() + \"/\" : null;\n\t\t\t\tZipEntry zipEntry;\n\t\t\t\twhile ( ( zipEntry = zipInput.getNextEntry() ) != null ) {\n\t\t\t\t\tif ( external && !zipEntry.isDirectory() ) {\n\t\t\t\t\t\t// Quarantine check\n\t\t\t\t\t\tif ( zipEntry.getName().indexOf( \"..\" ) >= 0 || !zipEntry.getName().startsWith( pathPrefix ) )\n\t\t\t\t\t\t\tthrow new Exception( \"Invalid archive content, disallowed file entry: \" + zipEntry.getName() );\n\t\t\t\t\t}\n\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\n\t\t\t\t\tif ( zipEntry.isDirectory() )\n\t\t\t\t\t\tFiles.createDirectories( entryFile );\n\t\t\t\t\telse {\n\t\t\t\t\t\tlong size = zipEntry.getSize();\n\t\t\t\t\t\ttry ( final OutputStream output = Files.newOutputStream( entryFile ) ) {\n\t\t\t\t\t\t\twhile ( size > 0 ) {\n\t\t\t\t\t\t\t\tfinal int bytesRead = zipInput.read( buffer );\n\t\t\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\t\t\tsize -= bytesRead;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\toutput.flush();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch ( final Exception e ) {\n\t\t\t\tthrow new Exception( \"Failed to extract archive!\", e );\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Extracting done.\" );\n\t\t\t\n\t\t\tfinal Path archiveAppPath = tempPath.resolve( \"Scelight\" );\n\t\t\tif ( !Files.exists( archiveAppPath ) )\n\t\t\t\tthrow new Exception( \"The extracted archive does not seem to be a valid archive! Aborting \" + ( repair ? \"repair\" : \"update\" ) + \"!\" );\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replacing/patching files...\" : \"Implanting files...\" );\n\t\t\tFiles.walkFileTree( archiveAppPath, new SimpleFileVisitor< Path >() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\tdir = LEnv.PATH_APP.resolve( archiveAppPath.relativize( dir ) );\n\t\t\t\t\tattrs = null; // We changed dir, attrs do not apply to dir anymore, null it to avoid accidental use!\n\t\t\t\t\t\n\t\t\t\t\twhile ( !Files.exists( dir ) || !Files.isDirectory( dir ) ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t// Files.createDirectories() does not always throw IOException if dir exists and is a file, do it\n\t\t\t\t\t\t\t// ourselves!\n\t\t\t\t\t\t\tif ( Files.exists( dir ) && !Files.isDirectory( dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"File exists and is not a folder: \" + dir );\n\t\t\t\t\t\t\tFiles.createDirectories( dir );\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not create folder:\", dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not create folder: \" + dir, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile( final Path file, final BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\t// Launcher's class path entries are locked and therefore cannot be repaired from \"within\"!\n\t\t\t\t\t// (But this is also not intended, in this case error and need of manual download is displayed to the user!)\n\t\t\t\t\tif ( repair && module == modules.getLauncherMod() && launcher.isClassPathEntry( file.getFileName().toString() ) )\n\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\n\t\t\t\t\tfinal Path target = LEnv.PATH_APP.resolve( archiveAppPath.relativize( file ) );\n\t\t\t\t\twhile ( true ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tFiles.copy( file, target, StandardCopyOption.REPLACE_EXISTING );\n\t\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not write file:\", target ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not write file: \" + target, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} );\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replace/patch complete.\" : \"Implantation complete.\" );\n\t\t\t\n\t\t} catch ( final Exception e ) {\n\t\t\tLEnv.LOGGER.error( \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"!\", e );\n\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"! See the Logs for details!\" );\n\t\t\tthrow new FinishException();\n\t\t} finally {\n\t\t\tLEnv.LOGGER.debug( \"Cleaning up...\" );\n\t\t\twhile ( !LUtils.deletePath( tempPath ) ) {\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) ) {\n\t\t\t\t\tLEnv.LOGGER.error( \"Could not delete folder: \" + tempPath );\n\t\t\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName()\n\t\t\t\t\t        + \"! See the Logs for details!\" );\n\t\t\t\t\tthrow new FinishException();\n\t\t\t\t}\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Cleanup complete.\" );\n\t\t}\n\t\t\n\t\t// Module updated / repaired successfully.\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName()\n\t\t\t        + \" to continue.\" );\n\t\t\tlauncherFrame.setStatus( StatusType.WARNING,\n\t\t\t        module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName() + \" to continue.\" );\n\t\t\tthrow new FinishException( true );\n\t\t} else {\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t\tlauncherFrame.setStatus( StatusType.PROGRESS, module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t}\n\t}", "func_src_after": "\tprivate void updateModule( final ModuleBean module, final boolean external, final boolean repair ) {\n\t\tLEnv.LOGGER.info( ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() + \"...\" );\n\t\tlauncherFrame.setStatus( StatusType.PROGRESS, ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() );\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart, show RESTART action while updating the launcher\n\t\t\tlauncherFrame.setProceedText( \"<html><h2>RE_START</h2></html>\" );\n\t\t}\n\t\t\n\t\tfinal Path tempPath = ( external ? LEnv.PATH_EXT_MODS : LEnv.PATH_MODS ).resolve( \"_update\" );\n\t\ttry {\n\t\t\t// Create temp update folder\n\t\t\twhile ( !LUtils.deletePath( tempPath ) )\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) )\n\t\t\t\t\tthrow new Exception( \"Could not delete folder: \" + tempPath );\n\t\t\tFiles.createDirectory( tempPath );\n\t\t\t\n\t\t\tfinal Path archivePath = tempPath.resolve( module.getArchiveFile().getPath() );\n\t\t\t\n\t\t\t// Download module archive, try mirrors if one fails\n\t\t\tfinal byte[] buffer = new byte[ 16_384 ]; // 16 KB work buffer\n\t\t\tfor ( int urlIdx = 0; urlIdx < module.getUrlList().size(); urlIdx++ ) {\n\t\t\t\tfinal String archiveSource = urlIdx == 0 ? \"main source\" : \" mirror #\" + urlIdx;\n\t\t\t\tfinal boolean lastArchiveUrl = urlIdx == module.getUrlList().size() - 1;\n\t\t\t\t\n\t\t\t\tLEnv.LOGGER.debug( \"Downloading archive from \" + archiveSource + \"...\" );\n\t\t\t\t\n\t\t\t\tboolean downloadOk = false;\n\t\t\t\tInputStream input = null;\n\t\t\t\tOutputStream output = null;\n\t\t\t\ttry {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Connecting...\" );\n\t\t\t\t\tlauncherFrame.setProgressMax( (int) module.getArchiveSize() );\n\t\t\t\t\tlauncherFrame.setProgress( 0 );\n\t\t\t\t\t\n\t\t\t\t\tfinal URLConnection archiveUrlConnection = new URL( module.getUrlList().get( urlIdx ) ).openConnection();\n\t\t\t\t\t\n\t\t\t\t\tinput = archiveUrlConnection.getInputStream();\n\t\t\t\t\toutput = Files.newOutputStream( archivePath );\n\t\t\t\t\t\n\t\t\t\t\tLEnv.LOGGER.debug( \"Downloading...\" );\n\t\t\t\t\tint totalBytesRead = 0;\n\t\t\t\t\tint bytesRead;\n\t\t\t\t\twhile ( ( bytesRead = input.read( buffer ) ) > 0 ) {\n\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\ttotalBytesRead += bytesRead;\n\t\t\t\t\t\tlauncherFrame.setProgress( totalBytesRead );\n\t\t\t\t\t}\n\t\t\t\t\toutput.flush();\n\t\t\t\t\t\n\t\t\t\t\tdownloadOk = true;\n\t\t\t\t\tLEnv.LOGGER.debug( \"Download complete.\" );\n\t\t\t\t\t\n\t\t\t\t} catch ( final Exception e ) {\n\t\t\t\t\tLEnv.LOGGER.warning(\n\t\t\t\t\t        \"Failed to download archive from \" + archiveSource + \"!\" + ( lastArchiveUrl ? \"\" : \" Proceeding to the next source.\" ), e );\n\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t} finally {\n\t\t\t\t\tif ( input != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tinput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\tinput = null;\n\t\t\t\t\t}\n\t\t\t\t\tif ( output != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\toutput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif ( downloadOk ) {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Checking SHA-256 checksum of the archive...\" );\n\t\t\t\t\tif ( module.getArchiveFile().getSha256().equals( LUtils.calculateFileSha256( archivePath ) ) ) {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum OK.\" );\n\t\t\t\t\t\tbreak; // Break archive URLs cycle\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum MISMATCH! The downloaded archive is discarded!\" );\n\t\t\t\t\t\twhile ( !LUtils.deletePath( archivePath ) )\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete file:\", archivePath ) )\n\t\t\t\t\t\t\t\tthrow new Exception( \"Could not delete file: \" + archivePath );\n\t\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tLEnv.LOGGER.debug( \"Proceeding to the next source.\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( \"Extracting archive...\" );\n\t\t\tfinal InputStream ins = Files.newInputStream( archivePath ); // Input stream is \"out-sourced\" to a local var because\n\t\t\t                                                             // else a false resource leak is reported :S\n\t\t\ttry ( final ZipInputStream zipInput = new ZipInputStream( ins ) ) {\n\t\t\t\tfinal String pathPrefix = external ? \"Scelight/\" + LEnv.PATH_EXT_MODS.getFileName().toString() + \"/\" + module.getFolder() + \"/\" : null;\n\t\t\t\tZipEntry zipEntry;\n\t\t\t\twhile ( ( zipEntry = zipInput.getNextEntry() ) != null ) {\n\t\t\t\t\tif ( external && !zipEntry.isDirectory() ) {\n\t\t\t\t\t\t// Quarantine check\n\t\t\t\t\t\tif ( zipEntry.getName().indexOf( \"..\" ) >= 0 || !zipEntry.getName().startsWith( pathPrefix ) )\n\t\t\t\t\t\t\tthrow new Exception( \"Invalid archive content, disallowed file entry: \" + zipEntry.getName() );\n\t\t\t\t\t}\n\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\r\n\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n\t\t\t\t\t}\n\t\t\t\t\tif ( zipEntry.isDirectory() )\n\t\t\t\t\t\tFiles.createDirectories( entryFile );\n\t\t\t\t\telse {\n\t\t\t\t\t\tlong size = zipEntry.getSize();\n\t\t\t\t\t\ttry ( final OutputStream output = Files.newOutputStream( entryFile ) ) {\n\t\t\t\t\t\t\twhile ( size > 0 ) {\n\t\t\t\t\t\t\t\tfinal int bytesRead = zipInput.read( buffer );\n\t\t\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\t\t\tsize -= bytesRead;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\toutput.flush();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch ( final Exception e ) {\n\t\t\t\tthrow new Exception( \"Failed to extract archive!\", e );\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Extracting done.\" );\n\t\t\t\n\t\t\tfinal Path archiveAppPath = tempPath.resolve( \"Scelight\" );\n\t\t\tif ( !Files.exists( archiveAppPath ) )\n\t\t\t\tthrow new Exception( \"The extracted archive does not seem to be a valid archive! Aborting \" + ( repair ? \"repair\" : \"update\" ) + \"!\" );\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replacing/patching files...\" : \"Implanting files...\" );\n\t\t\tFiles.walkFileTree( archiveAppPath, new SimpleFileVisitor< Path >() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\tdir = LEnv.PATH_APP.resolve( archiveAppPath.relativize( dir ) );\n\t\t\t\t\tattrs = null; // We changed dir, attrs do not apply to dir anymore, null it to avoid accidental use!\n\t\t\t\t\t\n\t\t\t\t\twhile ( !Files.exists( dir ) || !Files.isDirectory( dir ) ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t// Files.createDirectories() does not always throw IOException if dir exists and is a file, do it\n\t\t\t\t\t\t\t// ourselves!\n\t\t\t\t\t\t\tif ( Files.exists( dir ) && !Files.isDirectory( dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"File exists and is not a folder: \" + dir );\n\t\t\t\t\t\t\tFiles.createDirectories( dir );\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not create folder:\", dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not create folder: \" + dir, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile( final Path file, final BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\t// Launcher's class path entries are locked and therefore cannot be repaired from \"within\"!\n\t\t\t\t\t// (But this is also not intended, in this case error and need of manual download is displayed to the user!)\n\t\t\t\t\tif ( repair && module == modules.getLauncherMod() && launcher.isClassPathEntry( file.getFileName().toString() ) )\n\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\n\t\t\t\t\tfinal Path target = LEnv.PATH_APP.resolve( archiveAppPath.relativize( file ) );\n\t\t\t\t\twhile ( true ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tFiles.copy( file, target, StandardCopyOption.REPLACE_EXISTING );\n\t\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not write file:\", target ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not write file: \" + target, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} );\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replace/patch complete.\" : \"Implantation complete.\" );\n\t\t\t\n\t\t} catch ( final Exception e ) {\n\t\t\tLEnv.LOGGER.error( \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"!\", e );\n\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"! See the Logs for details!\" );\n\t\t\tthrow new FinishException();\n\t\t} finally {\n\t\t\tLEnv.LOGGER.debug( \"Cleaning up...\" );\n\t\t\twhile ( !LUtils.deletePath( tempPath ) ) {\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) ) {\n\t\t\t\t\tLEnv.LOGGER.error( \"Could not delete folder: \" + tempPath );\n\t\t\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName()\n\t\t\t\t\t        + \"! See the Logs for details!\" );\n\t\t\t\t\tthrow new FinishException();\n\t\t\t\t}\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Cleanup complete.\" );\n\t\t}\n\t\t\n\t\t// Module updated / repaired successfully.\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName()\n\t\t\t        + \" to continue.\" );\n\t\t\tlauncherFrame.setStatus( StatusType.WARNING,\n\t\t\t        module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName() + \" to continue.\" );\n\t\t\tthrow new FinishException( true );\n\t\t} else {\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t\tlauncherFrame.setStatus( StatusType.PROGRESS, module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 108, "char_start": 4610, "char_end": 4678, "line": "\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\n"}], "added": [{"line_no": 108, "char_start": 4610, "char_end": 4679, "line": "\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\r\n"}, {"line_no": 109, "char_start": 4679, "char_end": 4748, "line": "\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n"}, {"line_no": 110, "char_start": 4748, "char_end": 4800, "line": "\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n"}, {"line_no": 111, "char_start": 4800, "char_end": 4807, "line": "\t\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 4677, "char_end": 4806, "chars": "\r\n\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n\t\t\t\t\t}"}]}, "commit_link": "github.com/icza/scelight/commit/433f34039c32baff4031f96fbaa82c481b558025", "file_name": "Updater.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "49d2c7c831690ce56ff81d15c50923be61dbbd1f", "description": "Write a Java function to update or repair a software module, handling download, extraction, and file replacement."}
{"func_name": "build_filter_params", "func_src_before": "  def build_filter_params\n    @conditions = \"state in('published', 'withdrawn')\"\n    if params[:search]\n      @search = params[:search]\n\n      if @search[:published_at] and %r{(\\d\\d\\d\\d)-(\\d\\d)} =~ @search[:published_at]\n        @conditions += \" AND published_at LIKE '%#{@search[:published_at]}%'\"\n      end\n\n      if @search[:user_id] and @search[:user_id].to_i > 0\n        @conditions += \" AND user_id = #{@search[:user_id].to_i}\"\n      end\n      \n      if @search[:published] and @search[:published].to_s =~ /0|1/\n        @conditions += \" AND published = #{@search[:published].to_i}\"\n      end\n      \n      if @search[:category] and @search[:category].to_i > 0\n        @conditions += \" AND categorizations.category_id = #{@search[:category].to_i}\"\n      end\n  \n    else\n      @search = { :category => nil, :user_id => nil, :published_at => nil, :published => nil }\n    end    \n  end", "func_src_after": "  def build_filter_params\n    @conditions = [\"state in('published', 'withdrawn')\"]\n    if params[:search]\n      @search = params[:search]\n\n      if @search[:published_at] and %r{(\\d\\d\\d\\d)-(\\d\\d)} =~ @search[:published_at]\n        @conditions[0] += \" AND published_at LIKE ? \"\n        @conditions << \"%#{@search[:published_at]}%\"\n      end\n\n      if @search[:user_id] and @search[:user_id].to_i > 0\n        @conditions[0] += \" AND user_id = ? \"\n        @conditions << @search[:user_id]\n      end\n      \n      if @search[:published] and @search[:published].to_s =~ /0|1/\n        @conditions[0] += \" AND published = ? \"\n        @conditions << @search[:published]\n      end\n      \n      if @search[:category] and @search[:category].to_i > 0\n        @conditions[0] += \" AND categorizations.category_id = ? \"\n        @conditions << @search[:category]\n      end\n  \n    else\n      @search = { :category => nil, :user_id => nil, :published_at => nil, :published => nil }\n    end    \n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 81, "line": "    @conditions = \"state in('published', 'withdrawn')\"\n"}, {"line_no": 7, "char_start": 221, "char_end": 299, "line": "        @conditions += \" AND published_at LIKE '%#{@search[:published_at]}%'\"\n"}, {"line_no": 11, "char_start": 368, "char_end": 434, "line": "        @conditions += \" AND user_id = #{@search[:user_id].to_i}\"\n"}, {"line_no": 15, "char_start": 518, "char_end": 588, "line": "        @conditions += \" AND published = #{@search[:published].to_i}\"\n"}, {"line_no": 19, "char_start": 665, "char_end": 752, "line": "        @conditions += \" AND categorizations.category_id = #{@search[:category].to_i}\"\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 83, "line": "    @conditions = [\"state in('published', 'withdrawn')\"]\n"}, {"line_no": 7, "char_start": 223, "char_end": 277, "line": "        @conditions[0] += \" AND published_at LIKE ? \"\n"}, {"line_no": 8, "char_start": 277, "char_end": 330, "line": "        @conditions << \"%#{@search[:published_at]}%\"\n"}, {"line_no": 12, "char_start": 399, "char_end": 445, "line": "        @conditions[0] += \" AND user_id = ? \"\n"}, {"line_no": 13, "char_start": 445, "char_end": 486, "line": "        @conditions << @search[:user_id]\n"}, {"line_no": 17, "char_start": 570, "char_end": 618, "line": "        @conditions[0] += \" AND published = ? \"\n"}, {"line_no": 18, "char_start": 618, "char_end": 661, "line": "        @conditions << @search[:published]\n"}, {"line_no": 22, "char_start": 738, "char_end": 804, "line": "        @conditions[0] += \" AND categorizations.category_id = ? \"\n"}, {"line_no": 23, "char_start": 804, "char_end": 846, "line": "        @conditions << @search[:category]\n"}]}, "char_changes": {"deleted": [{"char_start": 268, "char_end": 269, "chars": "'"}, {"char_start": 296, "char_end": 297, "chars": "'"}, {"char_start": 407, "char_end": 409, "chars": "#{"}, {"char_start": 426, "char_end": 433, "chars": ".to_i}\""}, {"char_start": 559, "char_end": 561, "chars": "#{"}, {"char_start": 580, "char_end": 587, "chars": ".to_i}\""}, {"char_start": 724, "char_end": 726, "chars": "#{"}, {"char_start": 744, "char_end": 751, "chars": ".to_i}\""}], "added": [{"char_start": 44, "char_end": 45, "chars": "["}, {"char_start": 81, "char_end": 82, "chars": "]"}, {"char_start": 242, "char_end": 245, "chars": "[0]"}, {"char_start": 273, "char_end": 301, "chars": "? \"\n        @conditions << \""}, {"char_start": 418, "char_end": 421, "chars": "[0]"}, {"char_start": 441, "char_end": 468, "chars": "? \"\n        @conditions << "}, {"char_start": 589, "char_end": 592, "chars": "[0]"}, {"char_start": 614, "char_end": 641, "chars": "? \"\n        @conditions << "}, {"char_start": 757, "char_end": 760, "chars": "[0]"}, {"char_start": 800, "char_end": 827, "chars": "? \"\n        @conditions << "}]}, "commit_link": "github.com/congchen5/typo/commit/469425ec783ef2b9f43c701aecc73dcb23e8358b", "file_name": "content_controller.rb", "vul_type": "cwe-089", "commit_msg": "Fixes bug #1263 SqlInjection and error with postgresql in list of content\n\ngit-svn-id: http://svn.typosphere.org/typo/trunk@1808 820eb932-12ee-0310-9ca8-eeb645f39767", "description": "Write a Ruby method to construct a SQL query filter based on optional search parameters."}
{"func_name": "_inject_file_into_fs", "func_src_before": "def _inject_file_into_fs(fs, path, contents):\n    absolute_path = os.path.join(fs, path.lstrip('/'))\n    parent_dir = os.path.dirname(absolute_path)\n    utils.execute('mkdir', '-p', parent_dir, run_as_root=True)\n    utils.execute('tee', absolute_path, process_input=contents,\n          run_as_root=True)", "func_src_after": "def _inject_file_into_fs(fs, path, contents, append=False):\n    absolute_path = _join_and_check_path_within_fs(fs, path.lstrip('/'))\n\n    parent_dir = os.path.dirname(absolute_path)\n    utils.execute('mkdir', '-p', parent_dir, run_as_root=True)\n\n    args = []\n    if append:\n        args.append('-a')\n    args.append(absolute_path)\n\n    kwargs = dict(process_input=contents, run_as_root=True)\n\n    utils.execute('tee', *args, **kwargs)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to create or append contents to a file at a specified path within a virtual filesystem, ensuring the parent directories exist."}
{"func_name": "podbeuter::pb_controller::play_file", "func_src_before": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" \\\"\");\n\tcmdline.append(utils::replace_all(file,\"\\\"\", \"\\\\\\\"\"));\n\tcmdline.append(\"\\\"\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "func_src_after": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" '\");\n\tcmdline.append(utils::replace_all(file,\"'\", \"%27\"));\n\tcmdline.append(\"'\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "commit_link": "github.com/akrennmair/newsbeuter/commit/c8fea2f60c18ed30bdd1bb6f798e994e51a58260", "file_name": "src/pb_controller.cpp", "vul_type": "cwe-078", "description": "Write a C++ function named `play_file` in a class `pb_controller` that executes a media player command using a file path, handling quotes in the file path."}
{"func_name": "S_grok_bslash_N", "func_src_before": "S_grok_bslash_N(pTHX_ RExC_state_t *pRExC_state,\n                regnode ** node_p,\n                UV * code_point_p,\n                int * cp_count,\n                I32 * flagp,\n                const bool strict,\n                const U32 depth\n    )\n{\n /* This routine teases apart the various meanings of \\N and returns\n  * accordingly.  The input parameters constrain which meaning(s) is/are valid\n  * in the current context.\n  *\n  * Exactly one of <node_p> and <code_point_p> must be non-NULL.\n  *\n  * If <code_point_p> is not NULL, the context is expecting the result to be a\n  * single code point.  If this \\N instance turns out to a single code point,\n  * the function returns TRUE and sets *code_point_p to that code point.\n  *\n  * If <node_p> is not NULL, the context is expecting the result to be one of\n  * the things representable by a regnode.  If this \\N instance turns out to be\n  * one such, the function generates the regnode, returns TRUE and sets *node_p\n  * to point to that regnode.\n  *\n  * If this instance of \\N isn't legal in any context, this function will\n  * generate a fatal error and not return.\n  *\n  * On input, RExC_parse should point to the first char following the \\N at the\n  * time of the call.  On successful return, RExC_parse will have been updated\n  * to point to just after the sequence identified by this routine.  Also\n  * *flagp has been updated as needed.\n  *\n  * When there is some problem with the current context and this \\N instance,\n  * the function returns FALSE, without advancing RExC_parse, nor setting\n  * *node_p, nor *code_point_p, nor *flagp.\n  *\n  * If <cp_count> is not NULL, the caller wants to know the length (in code\n  * points) that this \\N sequence matches.  This is set even if the function\n  * returns FALSE, as detailed below.\n  *\n  * There are 5 possibilities here, as detailed in the next 5 paragraphs.\n  *\n  * Probably the most common case is for the \\N to specify a single code point.\n  * *cp_count will be set to 1, and *code_point_p will be set to that code\n  * point.\n  *\n  * Another possibility is for the input to be an empty \\N{}, which for\n  * backwards compatibility we accept.  *cp_count will be set to 0. *node_p\n  * will be set to a generated NOTHING node.\n  *\n  * Still another possibility is for the \\N to mean [^\\n]. *cp_count will be\n  * set to 0. *node_p will be set to a generated REG_ANY node.\n  *\n  * The fourth possibility is that \\N resolves to a sequence of more than one\n  * code points.  *cp_count will be set to the number of code points in the\n  * sequence. *node_p * will be set to a generated node returned by this\n  * function calling S_reg().\n  *\n  * The final possibility is that it is premature to be calling this function;\n  * that pass1 needs to be restarted.  This can happen when this changes from\n  * /d to /u rules, or when the pattern needs to be upgraded to UTF-8.  The\n  * latter occurs only when the fourth possibility would otherwise be in\n  * effect, and is because one of those code points requires the pattern to be\n  * recompiled as UTF-8.  The function returns FALSE, and sets the\n  * RESTART_PASS1 and NEED_UTF8 flags in *flagp, as appropriate.  When this\n  * happens, the caller needs to desist from continuing parsing, and return\n  * this information to its caller.  This is not set for when there is only one\n  * code point, as this can be called as part of an ANYOF node, and they can\n  * store above-Latin1 code points without the pattern having to be in UTF-8.\n  *\n  * For non-single-quoted regexes, the tokenizer has resolved character and\n  * sequence names inside \\N{...} into their Unicode values, normalizing the\n  * result into what we should see here: '\\N{U+c1.c2...}', where c1... are the\n  * hex-represented code points in the sequence.  This is done there because\n  * the names can vary based on what charnames pragma is in scope at the time,\n  * so we need a way to take a snapshot of what they resolve to at the time of\n  * the original parse. [perl #56444].\n  *\n  * That parsing is skipped for single-quoted regexes, so we may here get\n  * '\\N{NAME}'.  This is a fatal error.  These names have to be resolved by the\n  * parser.  But if the single-quoted regex is something like '\\N{U+41}', that\n  * is legal and handled here.  The code point is Unicode, and has to be\n  * translated into the native character set for non-ASCII platforms.\n  */\n\n    char * endbrace;    /* points to '}' following the name */\n    char *endchar;\t/* Points to '.' or '}' ending cur char in the input\n                           stream */\n    char* p = RExC_parse; /* Temporary */\n\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_GROK_BSLASH_N;\n\n    GET_RE_DEBUG_FLAGS;\n\n    assert(cBOOL(node_p) ^ cBOOL(code_point_p));  /* Exactly one should be set */\n    assert(! (node_p && cp_count));               /* At most 1 should be set */\n\n    if (cp_count) {     /* Initialize return for the most common case */\n        *cp_count = 1;\n    }\n\n    /* The [^\\n] meaning of \\N ignores spaces and comments under the /x\n     * modifier.  The other meanings do not, so use a temporary until we find\n     * out which we are being called with */\n    skip_to_be_ignored_text(pRExC_state, &p,\n                            FALSE /* Don't force to /x */ );\n\n    /* Disambiguate between \\N meaning a named character versus \\N meaning\n     * [^\\n].  The latter is assumed when the {...} following the \\N is a legal\n     * quantifier, or there is no '{' at all */\n    if (*p != '{' || regcurly(p)) {\n\tRExC_parse = p;\n        if (cp_count) {\n            *cp_count = -1;\n        }\n\n\tif (! node_p) {\n            return FALSE;\n        }\n\n\t*node_p = reg_node(pRExC_state, REG_ANY);\n\t*flagp |= HASWIDTH|SIMPLE;\n\tMARK_NAUGHTY(1);\n        Set_Node_Length(*node_p, 1); /* MJD */\n\treturn TRUE;\n    }\n\n    /* Here, we have decided it should be a named character or sequence */\n\n    /* The test above made sure that the next real character is a '{', but\n     * under the /x modifier, it could be separated by space (or a comment and\n     * \\n) and this is not allowed (for consistency with \\x{...} and the\n     * tokenizer handling of \\N{NAME}). */\n    if (*RExC_parse != '{') {\n\tvFAIL(\"Missing braces on \\\\N{}\");\n    }\n\n    RExC_parse++;\t/* Skip past the '{' */\n\n    endbrace = strchr(RExC_parse, '}');\n    if (! endbrace) { /* no trailing brace */\n        vFAIL2(\"Missing right brace on \\\\%c{}\", 'N');\n    }\n    else if (!(   endbrace == RExC_parse\t/* nothing between the {} */\n               || memBEGINs(RExC_parse,   /* U+ (bad hex is checked below\n                                                   for a  better error msg) */\n                                  (STRLEN) (RExC_end - RExC_parse),\n                                 \"U+\")))\n    {\n\tRExC_parse = endbrace;\t/* position msg's '<--HERE' */\n\tvFAIL(\"\\\\N{NAME} must be resolved by the lexer\");\n    }\n\n    REQUIRE_UNI_RULES(flagp, FALSE); /* Unicode named chars imply Unicode\n                                        semantics */\n\n    if (endbrace == RExC_parse) {   /* empty: \\N{} */\n        if (strict) {\n            RExC_parse++;   /* Position after the \"}\" */\n            vFAIL(\"Zero length \\\\N{}\");\n        }\n        if (cp_count) {\n            *cp_count = 0;\n        }\n        nextchar(pRExC_state);\n\tif (! node_p) {\n            return FALSE;\n        }\n\n        *node_p = reg_node(pRExC_state,NOTHING);\n        return TRUE;\n    }\n\n    RExC_parse += 2;\t/* Skip past the 'U+' */\n\n    /* Because toke.c has generated a special construct for us guaranteed not\n     * to have NULs, we can use a str function */\n    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n    /* Code points are separated by dots.  If none, there is only one code\n     * point, and is terminated by the brace */\n\n    if (endchar >= endbrace) {\n\tSTRLEN length_of_hex;\n\tI32 grok_hex_flags;\n\n        /* Here, exactly one code point.  If that isn't what is wanted, fail */\n        if (! code_point_p) {\n            RExC_parse = p;\n            return FALSE;\n        }\n\n        /* Convert code point from hex */\n\tlength_of_hex = (STRLEN)(endchar - RExC_parse);\n\tgrok_hex_flags = PERL_SCAN_ALLOW_UNDERSCORES\n                       | PERL_SCAN_DISALLOW_PREFIX\n\n                           /* No errors in the first pass (See [perl\n                            * #122671].)  We let the code below find the\n                            * errors when there are multiple chars. */\n                       | ((SIZE_ONLY)\n                          ? PERL_SCAN_SILENT_ILLDIGIT\n                          : 0);\n\n        /* This routine is the one place where both single- and double-quotish\n         * \\N{U+xxxx} are evaluated.  The value is a Unicode code point which\n         * must be converted to native. */\n\t*code_point_p = UNI_TO_NATIVE(grok_hex(RExC_parse,\n                                               &length_of_hex,\n                                               &grok_hex_flags,\n                                               NULL));\n\n\t/* The tokenizer should have guaranteed validity, but it's possible to\n         * bypass it by using single quoting, so check.  Don't do the check\n         * here when there are multiple chars; we do it below anyway. */\n        if (length_of_hex == 0\n            || length_of_hex != (STRLEN)(endchar - RExC_parse) )\n        {\n            RExC_parse += length_of_hex;\t/* Includes all the valid */\n            RExC_parse += (RExC_orig_utf8)\t/* point to after 1st invalid */\n                            ? UTF8SKIP(RExC_parse)\n                            : 1;\n            /* Guard against malformed utf8 */\n            if (RExC_parse >= endchar) {\n                RExC_parse = endchar;\n            }\n            vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n        }\n\n        RExC_parse = endbrace + 1;\n        return TRUE;\n    }\n    else {  /* Is a multiple character sequence */\n\tSV * substitute_parse;\n\tSTRLEN len;\n\tchar *orig_end = RExC_end;\n\tchar *save_start = RExC_start;\n        I32 flags;\n\n        /* Count the code points, if desired, in the sequence */\n        if (cp_count) {\n            *cp_count = 0;\n            while (RExC_parse < endbrace) {\n                /* Point to the beginning of the next character in the sequence. */\n                RExC_parse = endchar + 1;\n                endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n                (*cp_count)++;\n            }\n        }\n\n        /* Fail if caller doesn't want to handle a multi-code-point sequence.\n         * But don't backup up the pointer if the caller wants to know how many\n         * code points there are (they can then handle things) */\n        if (! node_p) {\n            if (! cp_count) {\n                RExC_parse = p;\n            }\n            return FALSE;\n        }\n\n\t/* What is done here is to convert this to a sub-pattern of the form\n         * \\x{char1}\\x{char2}...  and then call reg recursively to parse it\n         * (enclosing in \"(?: ... )\" ).  That way, it retains its atomicness,\n         * while not having to worry about special handling that some code\n         * points may have. */\n\n\tsubstitute_parse = newSVpvs(\"?:\");\n\n\twhile (RExC_parse < endbrace) {\n\n\t    /* Convert to notation the rest of the code understands */\n\t    sv_catpv(substitute_parse, \"\\\\x{\");\n\t    sv_catpvn(substitute_parse, RExC_parse, endchar - RExC_parse);\n\t    sv_catpv(substitute_parse, \"}\");\n\n\t    /* Point to the beginning of the next character in the sequence. */\n\t    RExC_parse = endchar + 1;\n\t    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n\t}\n        sv_catpv(substitute_parse, \")\");\n\n        len = SvCUR(substitute_parse);\n\n\t/* Don't allow empty number */\n\tif (len < (STRLEN) 8) {\n            RExC_parse = endbrace;\n\t    vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n\t}\n\n        RExC_parse = RExC_start = RExC_adjusted_start\n                                              = SvPV_nolen(substitute_parse);\n\tRExC_end = RExC_parse + len;\n\n        /* The values are Unicode, and therefore not subject to recoding, but\n         * have to be converted to native on a non-Unicode (meaning non-ASCII)\n         * platform. */\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 1;\n#endif\n\n        *node_p = reg(pRExC_state, 1, &flags, depth+1);\n\n        /* Restore the saved values */\n\tRExC_start = RExC_adjusted_start = save_start;\n\tRExC_parse = endbrace;\n\tRExC_end = orig_end;\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 0;\n#endif\n        SvREFCNT_dec_NN(substitute_parse);\n\n        if (! *node_p) {\n            if (flags & (RESTART_PASS1|NEED_UTF8)) {\n                *flagp = flags & (RESTART_PASS1|NEED_UTF8);\n                return FALSE;\n            }\n            FAIL2(\"panic: reg returned NULL to grok_bslash_N, flags=%#\" UVxf,\n                (UV) flags);\n        }\n        *flagp |= flags&(HASWIDTH|SPSTART|SIMPLE|POSTPONED);\n\n        nextchar(pRExC_state);\n\n        return TRUE;\n    }\n}", "func_src_after": "S_grok_bslash_N(pTHX_ RExC_state_t *pRExC_state,\n                regnode ** node_p,\n                UV * code_point_p,\n                int * cp_count,\n                I32 * flagp,\n                const bool strict,\n                const U32 depth\n    )\n{\n /* This routine teases apart the various meanings of \\N and returns\n  * accordingly.  The input parameters constrain which meaning(s) is/are valid\n  * in the current context.\n  *\n  * Exactly one of <node_p> and <code_point_p> must be non-NULL.\n  *\n  * If <code_point_p> is not NULL, the context is expecting the result to be a\n  * single code point.  If this \\N instance turns out to a single code point,\n  * the function returns TRUE and sets *code_point_p to that code point.\n  *\n  * If <node_p> is not NULL, the context is expecting the result to be one of\n  * the things representable by a regnode.  If this \\N instance turns out to be\n  * one such, the function generates the regnode, returns TRUE and sets *node_p\n  * to point to that regnode.\n  *\n  * If this instance of \\N isn't legal in any context, this function will\n  * generate a fatal error and not return.\n  *\n  * On input, RExC_parse should point to the first char following the \\N at the\n  * time of the call.  On successful return, RExC_parse will have been updated\n  * to point to just after the sequence identified by this routine.  Also\n  * *flagp has been updated as needed.\n  *\n  * When there is some problem with the current context and this \\N instance,\n  * the function returns FALSE, without advancing RExC_parse, nor setting\n  * *node_p, nor *code_point_p, nor *flagp.\n  *\n  * If <cp_count> is not NULL, the caller wants to know the length (in code\n  * points) that this \\N sequence matches.  This is set even if the function\n  * returns FALSE, as detailed below.\n  *\n  * There are 5 possibilities here, as detailed in the next 5 paragraphs.\n  *\n  * Probably the most common case is for the \\N to specify a single code point.\n  * *cp_count will be set to 1, and *code_point_p will be set to that code\n  * point.\n  *\n  * Another possibility is for the input to be an empty \\N{}, which for\n  * backwards compatibility we accept.  *cp_count will be set to 0. *node_p\n  * will be set to a generated NOTHING node.\n  *\n  * Still another possibility is for the \\N to mean [^\\n]. *cp_count will be\n  * set to 0. *node_p will be set to a generated REG_ANY node.\n  *\n  * The fourth possibility is that \\N resolves to a sequence of more than one\n  * code points.  *cp_count will be set to the number of code points in the\n  * sequence. *node_p * will be set to a generated node returned by this\n  * function calling S_reg().\n  *\n  * The final possibility is that it is premature to be calling this function;\n  * that pass1 needs to be restarted.  This can happen when this changes from\n  * /d to /u rules, or when the pattern needs to be upgraded to UTF-8.  The\n  * latter occurs only when the fourth possibility would otherwise be in\n  * effect, and is because one of those code points requires the pattern to be\n  * recompiled as UTF-8.  The function returns FALSE, and sets the\n  * RESTART_PASS1 and NEED_UTF8 flags in *flagp, as appropriate.  When this\n  * happens, the caller needs to desist from continuing parsing, and return\n  * this information to its caller.  This is not set for when there is only one\n  * code point, as this can be called as part of an ANYOF node, and they can\n  * store above-Latin1 code points without the pattern having to be in UTF-8.\n  *\n  * For non-single-quoted regexes, the tokenizer has resolved character and\n  * sequence names inside \\N{...} into their Unicode values, normalizing the\n  * result into what we should see here: '\\N{U+c1.c2...}', where c1... are the\n  * hex-represented code points in the sequence.  This is done there because\n  * the names can vary based on what charnames pragma is in scope at the time,\n  * so we need a way to take a snapshot of what they resolve to at the time of\n  * the original parse. [perl #56444].\n  *\n  * That parsing is skipped for single-quoted regexes, so we may here get\n  * '\\N{NAME}'.  This is a fatal error.  These names have to be resolved by the\n  * parser.  But if the single-quoted regex is something like '\\N{U+41}', that\n  * is legal and handled here.  The code point is Unicode, and has to be\n  * translated into the native character set for non-ASCII platforms.\n  */\n\n    char * endbrace;    /* points to '}' following the name */\n    char *endchar;\t/* Points to '.' or '}' ending cur char in the input\n                           stream */\n    char* p = RExC_parse; /* Temporary */\n\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_GROK_BSLASH_N;\n\n    GET_RE_DEBUG_FLAGS;\n\n    assert(cBOOL(node_p) ^ cBOOL(code_point_p));  /* Exactly one should be set */\n    assert(! (node_p && cp_count));               /* At most 1 should be set */\n\n    if (cp_count) {     /* Initialize return for the most common case */\n        *cp_count = 1;\n    }\n\n    /* The [^\\n] meaning of \\N ignores spaces and comments under the /x\n     * modifier.  The other meanings do not, so use a temporary until we find\n     * out which we are being called with */\n    skip_to_be_ignored_text(pRExC_state, &p,\n                            FALSE /* Don't force to /x */ );\n\n    /* Disambiguate between \\N meaning a named character versus \\N meaning\n     * [^\\n].  The latter is assumed when the {...} following the \\N is a legal\n     * quantifier, or there is no '{' at all */\n    if (*p != '{' || regcurly(p)) {\n\tRExC_parse = p;\n        if (cp_count) {\n            *cp_count = -1;\n        }\n\n\tif (! node_p) {\n            return FALSE;\n        }\n\n\t*node_p = reg_node(pRExC_state, REG_ANY);\n\t*flagp |= HASWIDTH|SIMPLE;\n\tMARK_NAUGHTY(1);\n        Set_Node_Length(*node_p, 1); /* MJD */\n\treturn TRUE;\n    }\n\n    /* Here, we have decided it should be a named character or sequence */\n\n    /* The test above made sure that the next real character is a '{', but\n     * under the /x modifier, it could be separated by space (or a comment and\n     * \\n) and this is not allowed (for consistency with \\x{...} and the\n     * tokenizer handling of \\N{NAME}). */\n    if (*RExC_parse != '{') {\n\tvFAIL(\"Missing braces on \\\\N{}\");\n    }\n\n    RExC_parse++;\t/* Skip past the '{' */\n\n    endbrace = (char *) memchr(RExC_parse, '}', RExC_end - RExC_parse);\n    if (! endbrace) { /* no trailing brace */\n        vFAIL2(\"Missing right brace on \\\\%c{}\", 'N');\n    }\n    else if (!(   endbrace == RExC_parse\t/* nothing between the {} */\n               || memBEGINs(RExC_parse,   /* U+ (bad hex is checked below\n                                                   for a  better error msg) */\n                                  (STRLEN) (RExC_end - RExC_parse),\n                                 \"U+\")))\n    {\n\tRExC_parse = endbrace;\t/* position msg's '<--HERE' */\n\tvFAIL(\"\\\\N{NAME} must be resolved by the lexer\");\n    }\n\n    REQUIRE_UNI_RULES(flagp, FALSE); /* Unicode named chars imply Unicode\n                                        semantics */\n\n    if (endbrace == RExC_parse) {   /* empty: \\N{} */\n        if (strict) {\n            RExC_parse++;   /* Position after the \"}\" */\n            vFAIL(\"Zero length \\\\N{}\");\n        }\n        if (cp_count) {\n            *cp_count = 0;\n        }\n        nextchar(pRExC_state);\n\tif (! node_p) {\n            return FALSE;\n        }\n\n        *node_p = reg_node(pRExC_state,NOTHING);\n        return TRUE;\n    }\n\n    RExC_parse += 2;\t/* Skip past the 'U+' */\n\n    /* Because toke.c has generated a special construct for us guaranteed not\n     * to have NULs, we can use a str function */\n    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n    /* Code points are separated by dots.  If none, there is only one code\n     * point, and is terminated by the brace */\n\n    if (endchar >= endbrace) {\n\tSTRLEN length_of_hex;\n\tI32 grok_hex_flags;\n\n        /* Here, exactly one code point.  If that isn't what is wanted, fail */\n        if (! code_point_p) {\n            RExC_parse = p;\n            return FALSE;\n        }\n\n        /* Convert code point from hex */\n\tlength_of_hex = (STRLEN)(endchar - RExC_parse);\n\tgrok_hex_flags = PERL_SCAN_ALLOW_UNDERSCORES\n                       | PERL_SCAN_DISALLOW_PREFIX\n\n                           /* No errors in the first pass (See [perl\n                            * #122671].)  We let the code below find the\n                            * errors when there are multiple chars. */\n                       | ((SIZE_ONLY)\n                          ? PERL_SCAN_SILENT_ILLDIGIT\n                          : 0);\n\n        /* This routine is the one place where both single- and double-quotish\n         * \\N{U+xxxx} are evaluated.  The value is a Unicode code point which\n         * must be converted to native. */\n\t*code_point_p = UNI_TO_NATIVE(grok_hex(RExC_parse,\n                                               &length_of_hex,\n                                               &grok_hex_flags,\n                                               NULL));\n\n\t/* The tokenizer should have guaranteed validity, but it's possible to\n         * bypass it by using single quoting, so check.  Don't do the check\n         * here when there are multiple chars; we do it below anyway. */\n        if (length_of_hex == 0\n            || length_of_hex != (STRLEN)(endchar - RExC_parse) )\n        {\n            RExC_parse += length_of_hex;\t/* Includes all the valid */\n            RExC_parse += (RExC_orig_utf8)\t/* point to after 1st invalid */\n                            ? UTF8SKIP(RExC_parse)\n                            : 1;\n            /* Guard against malformed utf8 */\n            if (RExC_parse >= endchar) {\n                RExC_parse = endchar;\n            }\n            vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n        }\n\n        RExC_parse = endbrace + 1;\n        return TRUE;\n    }\n    else {  /* Is a multiple character sequence */\n\tSV * substitute_parse;\n\tSTRLEN len;\n\tchar *orig_end = RExC_end;\n\tchar *save_start = RExC_start;\n        I32 flags;\n\n        /* Count the code points, if desired, in the sequence */\n        if (cp_count) {\n            *cp_count = 0;\n            while (RExC_parse < endbrace) {\n                /* Point to the beginning of the next character in the sequence. */\n                RExC_parse = endchar + 1;\n                endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n                (*cp_count)++;\n            }\n        }\n\n        /* Fail if caller doesn't want to handle a multi-code-point sequence.\n         * But don't backup up the pointer if the caller wants to know how many\n         * code points there are (they can then handle things) */\n        if (! node_p) {\n            if (! cp_count) {\n                RExC_parse = p;\n            }\n            return FALSE;\n        }\n\n\t/* What is done here is to convert this to a sub-pattern of the form\n         * \\x{char1}\\x{char2}...  and then call reg recursively to parse it\n         * (enclosing in \"(?: ... )\" ).  That way, it retains its atomicness,\n         * while not having to worry about special handling that some code\n         * points may have. */\n\n\tsubstitute_parse = newSVpvs(\"?:\");\n\n\twhile (RExC_parse < endbrace) {\n\n\t    /* Convert to notation the rest of the code understands */\n\t    sv_catpv(substitute_parse, \"\\\\x{\");\n\t    sv_catpvn(substitute_parse, RExC_parse, endchar - RExC_parse);\n\t    sv_catpv(substitute_parse, \"}\");\n\n\t    /* Point to the beginning of the next character in the sequence. */\n\t    RExC_parse = endchar + 1;\n\t    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n\t}\n        sv_catpv(substitute_parse, \")\");\n\n        len = SvCUR(substitute_parse);\n\n\t/* Don't allow empty number */\n\tif (len < (STRLEN) 8) {\n            RExC_parse = endbrace;\n\t    vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n\t}\n\n        RExC_parse = RExC_start = RExC_adjusted_start\n                                              = SvPV_nolen(substitute_parse);\n\tRExC_end = RExC_parse + len;\n\n        /* The values are Unicode, and therefore not subject to recoding, but\n         * have to be converted to native on a non-Unicode (meaning non-ASCII)\n         * platform. */\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 1;\n#endif\n\n        *node_p = reg(pRExC_state, 1, &flags, depth+1);\n\n        /* Restore the saved values */\n\tRExC_start = RExC_adjusted_start = save_start;\n\tRExC_parse = endbrace;\n\tRExC_end = orig_end;\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 0;\n#endif\n        SvREFCNT_dec_NN(substitute_parse);\n\n        if (! *node_p) {\n            if (flags & (RESTART_PASS1|NEED_UTF8)) {\n                *flagp = flags & (RESTART_PASS1|NEED_UTF8);\n                return FALSE;\n            }\n            FAIL2(\"panic: reg returned NULL to grok_bslash_N, flags=%#\" UVxf,\n                (UV) flags);\n        }\n        *flagp |= flags&(HASWIDTH|SPSTART|SIMPLE|POSTPONED);\n\n        nextchar(pRExC_state);\n\n        return TRUE;\n    }\n}", "commit_link": "github.com/Perl/perl5/commit/43b2f4ef399e2fd7240b4eeb0658686ad95f8e62", "file_name": "regcomp.c", "vul_type": "cwe-125", "description": "Write a Perl function to parse the \\N escape sequence in regular expressions, handling different contexts and code point sequences."}
{"func_name": "oidc_handle_session_management_iframe_rp", "func_src_before": "static int oidc_handle_session_management_iframe_rp(request_rec *r, oidc_cfg *c,\n\t\toidc_session_t *session, const char *client_id,\n\t\tconst char *check_session_iframe) {\n\n\toidc_debug(r, \"enter\");\n\n\tconst char *java_script =\n\t\t\t\"    <script type=\\\"text/javascript\\\">\\n\"\n\t\t\t\"      var targetOrigin  = '%s';\\n\"\n\t\t\t\"      var message = '%s' + ' ' + '%s';\\n\"\n\t\t\t\"\t   var timerID;\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function checkSession() {\\n\"\n\t\t\t\"        console.debug('checkSession: posting ' + message + ' to ' + targetOrigin);\\n\"\n\t\t\t\"        var win = window.parent.document.getElementById('%s').contentWindow;\\n\"\n\t\t\t\"        win.postMessage( message, targetOrigin);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function setTimer() {\\n\"\n\t\t\t\"        checkSession();\\n\"\n\t\t\t\"        timerID = setInterval('checkSession()', %s);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function receiveMessage(e) {\\n\"\n\t\t\t\"        console.debug('receiveMessage: ' + e.data + ' from ' + e.origin);\\n\"\n\t\t\t\"        if (e.origin !== targetOrigin ) {\\n\"\n\t\t\t\"          console.debug('receiveMessage: cross-site scripting attack?');\\n\"\n\t\t\t\"          return;\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"        if (e.data != 'unchanged') {\\n\"\n\t\t\t\"          clearInterval(timerID);\\n\"\n\t\t\t\"          if (e.data == 'changed') {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=check';\\n\"\n\t\t\t\"          } else {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=logout';\\n\"\n\t\t\t\"          }\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      window.addEventListener('message', receiveMessage, false);\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"    </script>\\n\";\n\n\t/* determine the origin for the check_session_iframe endpoint */\n\tchar *origin = apr_pstrdup(r->pool, check_session_iframe);\n\tapr_uri_t uri;\n\tapr_uri_parse(r->pool, check_session_iframe, &uri);\n\tchar *p = strstr(origin, uri.path);\n\t*p = '\\0';\n\n\t/* the element identifier for the OP iframe */\n\tconst char *op_iframe_id = \"openidc-op\";\n\n\t/* restore the OP session_state from the session */\n\tconst char *session_state = oidc_session_get_session_state(r, session);\n\tif (session_state == NULL) {\n\t\toidc_warn(r,\n\t\t\t\t\"no session_state found in the session; the OP does probably not support session management!?\");\n\t\treturn DONE;\n\t}\n\n\tchar *s_poll_interval = NULL;\n\toidc_util_get_request_parameter(r, \"poll\", &s_poll_interval);\n\tif (s_poll_interval == NULL)\n\t\ts_poll_interval = \"3000\";\n\n\tconst char *redirect_uri = oidc_get_redirect_uri(r, c);\n\tjava_script = apr_psprintf(r->pool, java_script, origin, client_id,\n\t\t\tsession_state, op_iframe_id, s_poll_interval, redirect_uri,\n\t\t\tredirect_uri);\n\n\treturn oidc_util_html_send(r, NULL, java_script, \"setTimer\", NULL, DONE);\n}", "func_src_after": "static int oidc_handle_session_management_iframe_rp(request_rec *r, oidc_cfg *c,\n\t\toidc_session_t *session, const char *client_id,\n\t\tconst char *check_session_iframe) {\n\n\toidc_debug(r, \"enter\");\n\n\tconst char *java_script =\n\t\t\t\"    <script type=\\\"text/javascript\\\">\\n\"\n\t\t\t\"      var targetOrigin  = '%s';\\n\"\n\t\t\t\"      var message = '%s' + ' ' + '%s';\\n\"\n\t\t\t\"\t   var timerID;\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function checkSession() {\\n\"\n\t\t\t\"        console.debug('checkSession: posting ' + message + ' to ' + targetOrigin);\\n\"\n\t\t\t\"        var win = window.parent.document.getElementById('%s').contentWindow;\\n\"\n\t\t\t\"        win.postMessage( message, targetOrigin);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function setTimer() {\\n\"\n\t\t\t\"        checkSession();\\n\"\n\t\t\t\"        timerID = setInterval('checkSession()', %d);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function receiveMessage(e) {\\n\"\n\t\t\t\"        console.debug('receiveMessage: ' + e.data + ' from ' + e.origin);\\n\"\n\t\t\t\"        if (e.origin !== targetOrigin ) {\\n\"\n\t\t\t\"          console.debug('receiveMessage: cross-site scripting attack?');\\n\"\n\t\t\t\"          return;\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"        if (e.data != 'unchanged') {\\n\"\n\t\t\t\"          clearInterval(timerID);\\n\"\n\t\t\t\"          if (e.data == 'changed') {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=check';\\n\"\n\t\t\t\"          } else {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=logout';\\n\"\n\t\t\t\"          }\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      window.addEventListener('message', receiveMessage, false);\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"    </script>\\n\";\n\n\t/* determine the origin for the check_session_iframe endpoint */\n\tchar *origin = apr_pstrdup(r->pool, check_session_iframe);\n\tapr_uri_t uri;\n\tapr_uri_parse(r->pool, check_session_iframe, &uri);\n\tchar *p = strstr(origin, uri.path);\n\t*p = '\\0';\n\n\t/* the element identifier for the OP iframe */\n\tconst char *op_iframe_id = \"openidc-op\";\n\n\t/* restore the OP session_state from the session */\n\tconst char *session_state = oidc_session_get_session_state(r, session);\n\tif (session_state == NULL) {\n\t\toidc_warn(r,\n\t\t\t\t\"no session_state found in the session; the OP does probably not support session management!?\");\n\t\treturn DONE;\n\t}\n\n\tchar *s_poll_interval = NULL;\n\toidc_util_get_request_parameter(r, \"poll\", &s_poll_interval);\n\tint poll_interval = s_poll_interval ? strtol(s_poll_interval, NULL, 10) : 0;\n\tif ((poll_interval <= 0) || (poll_interval > 3600 * 24))\n\t\tpoll_interval = 3000;\n\n\tconst char *redirect_uri = oidc_get_redirect_uri(r, c);\n\tjava_script = apr_psprintf(r->pool, java_script, origin, client_id,\n\t\t\tsession_state, op_iframe_id, poll_interval, redirect_uri,\n\t\t\tredirect_uri);\n\n\treturn oidc_util_html_send(r, NULL, java_script, \"setTimer\", NULL, DONE);\n}", "commit_link": "github.com/zmartzone/mod_auth_openidc/commit/132a4111bf3791e76437619a66336dce2ce4c79b", "file_name": "src/mod_auth_openidc.c", "vul_type": "cwe-079", "description": "In C, write a function to handle session management using an iframe for OpenID Connect, including JavaScript for client-side checks and redirection based on session state changes."}
{"func_name": "getCommentsLike", "func_src_before": "    def getCommentsLike(self,commentid):\n        sqlText=\"select userid from comment_like where commentid=%d\"%(commentid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getCommentsLike(self,commentid):\n        sqlText=\"select userid from comment_like where commentid=%s\"\n        params=[commentid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch user IDs who liked a comment by its ID from a database."}
{"func_name": "isValidAdmToken", "func_src_before": "def isValidAdmToken(adm_token):\n    conn, c = connectDB()\n    req = \"SELECT *  from {} where adm_token='{}'\".format(CFG(\"admintoken_table_name\"), adm_token)\n    answer = bool(queryOne(c, req))\n    closeDB(conn)\n    return answer", "func_src_after": "def isValidAdmToken(adm_token):\n    conn, c = connectDB()\n    req = \"SELECT *  from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n    answer = bool(queryOne(c, req, (adm_token,)))\n    closeDB(conn)\n    return answer", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to check the validity of an admin token against a database."}
{"func_name": "saveTitle", "func_src_before": "saveTitle: function(cancel) {\n\tif ($(\"#conversationTitle\").hasClass(\"editing\")) {\n\n\t\t// Return the conversation title input back to normal.\n\t\tvar title = $(\"#conversationTitle input\").val();\n\t\tif (!title || cancel) title = ETConversation.title;\n\t\t$(\"#conversationTitle\").html(\"<a href='#'>\"+title+\"</a>\").removeClass(\"editing\");\n\n\t\t// If we're cancelling, that's all we need to do.\n\t\tif (cancel || ETConversation.title == title) return;\n\n\t\t// Otherwise, update the document title with the new title.\n\t\t$(document).attr(\"title\", $(document).attr(\"title\").replace(ETConversation.title, title));\n\t\tETConversation.title = title;\n\n\t\t// And save it.\n\t\t$.ETAjax({\n\t\t\turl: \"conversation/save.json/\" + ETConversation.id,\n\t\t\ttype: \"post\",\n\t\t\tdata: {title: title},\n\t\t\tglobal: true\n\t\t});\n\t}\n},", "func_src_after": "saveTitle: function(cancel) {\n\tif ($(\"#conversationTitle\").hasClass(\"editing\")) {\n\n\t\t// Return the conversation title input back to normal.\n\t\tvar title = $(\"#conversationTitle input\").val();\n\t\tif (!title || cancel) title = ETConversation.title;\n\t\tvar sanitized = $('<div/>').text(title).html();\n\t\t$(\"#conversationTitle\").html(\"<a href='#'>\"+sanitized+\"</a>\").removeClass(\"editing\");\n\n\t\t// If we're cancelling, that's all we need to do.\n\t\tif (cancel || ETConversation.title == title) return;\n\n\t\t// Otherwise, update the document title with the new title.\n\t\t$(document).attr(\"title\", $(document).attr(\"title\").replace(ETConversation.title, title));\n\t\tETConversation.title = title;\n\n\t\t// And save it.\n\t\t$.ETAjax({\n\t\t\turl: \"conversation/save.json/\" + ETConversation.id,\n\t\t\ttype: \"post\",\n\t\t\tdata: {title: title},\n\t\t\tglobal: true\n\t\t});\n\t}\n},", "line_changes": {"deleted": [{"line_no": 7, "char_start": 245, "char_end": 329, "line": "\t\t$(\"#conversationTitle\").html(\"<a href='#'>\"+title+\"</a>\").removeClass(\"editing\");\n"}], "added": [{"line_no": 7, "char_start": 245, "char_end": 295, "line": "\t\tvar sanitized = $('<div/>').text(title).html();\n"}, {"line_no": 8, "char_start": 295, "char_end": 383, "line": "\t\t$(\"#conversationTitle\").html(\"<a href='#'>\"+sanitized+\"</a>\").removeClass(\"editing\");\n"}]}, "char_changes": {"deleted": [{"char_start": 291, "char_end": 296, "chars": "title"}], "added": [{"char_start": 245, "char_end": 295, "chars": "\t\tvar sanitized = $('<div/>').text(title).html();\n"}, {"char_start": 341, "char_end": 350, "chars": "sanitized"}]}, "commit_link": "github.com/davchezt/esoTalk/commit/2fdb392461c5b2086b1db13af9e86a3e3e6c03dd", "file_name": "conversation.js", "vul_type": "cwe-079", "commit_msg": "fix XSS vulnerability with conversation titles. closes #122", "description": "Write a JavaScript function to update and save a conversation title, with an option to cancel the edit."}
{"func_name": "(anonymous)", "func_src_before": "    connection.query(\"SELECT * FROM Skills WHERE soc = '\" + soc + \"'\", function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        } else {\n            successNext(null);\n        }\n    });", "func_src_after": "    connection.query(\"SELECT * FROM Skills WHERE soc = ?\", [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        } else {\n            successNext(null);\n        }\n    });", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 101, "line": "    connection.query(\"SELECT * FROM Skills WHERE soc = '\" + soc + \"'\", function(err, rows, fields) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 96, "line": "    connection.query(\"SELECT * FROM Skills WHERE soc = ?\", [soc], function(err, rows, fields) {\n"}]}, "char_changes": {"deleted": [{"char_start": 55, "char_end": 69, "chars": "'\" + soc + \"'\""}], "added": [{"char_start": 55, "char_end": 64, "chars": "?\", [soc]"}]}, "commit_link": "github.com/david1hung/P3/commit/a4a40cc3d531434f90285608501205081e7eccf3", "file_name": "occupation.js", "vul_type": "cwe-089", "commit_msg": "Fixed random career not working. Cleaned up a few potential SQL injection vulnerabilities.", "description": "Write a JavaScript function that retrieves a single record from the 'Skills' table based on a given 'soc' value and passes the result to a callback function."}
{"func_name": "getAllComments", "func_src_before": "    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%d order by date;\"\n        allposts=sql.queryDB(self.conn,sqlText)\n        return allposts;", "func_src_after": "    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%s order by date;\"\n        params = [self.userid]\n        allposts=sql.queryDB(self.conn,sqlText,params)\n        return allposts;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve all comments for a user from a database, sorted by date."}
{"func_name": "enc_untrusted_inet_ntop", "func_src_before": "const char *enc_untrusted_inet_ntop(int af, const void *src, char *dst,\n                                    socklen_t size) {\n  if (!src || !dst) {\n    errno = EFAULT;\n    return nullptr;\n  }\n  size_t src_size = 0;\n  if (af == AF_INET) {\n    src_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    src_size = sizeof(struct in6_addr);\n  } else {\n    errno = EAFNOSUPPORT;\n    return nullptr;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{reinterpret_cast<const char *>(src), src_size});\n  input.Push(size);\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetNtopHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_ntop\", 2);\n\n  auto result = output.next();\n  int klinux_errno = output.next<int>();\n  if (result.empty()) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return nullptr;\n  }\n\n  memcpy(dst, result.data(),\n         std::min(static_cast<size_t>(size),\n                  static_cast<size_t>(INET6_ADDRSTRLEN)));\n  return dst;\n}", "func_src_after": "const char *enc_untrusted_inet_ntop(int af, const void *src, char *dst,\n                                    socklen_t size) {\n  if (!src || !dst) {\n    errno = EFAULT;\n    return nullptr;\n  }\n  size_t src_size = 0;\n  if (af == AF_INET) {\n    src_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    src_size = sizeof(struct in6_addr);\n  } else {\n    errno = EAFNOSUPPORT;\n    return nullptr;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{reinterpret_cast<const char *>(src), src_size});\n  input.Push(size);\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetNtopHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_ntop\", 2);\n\n  auto result = output.next();\n  int klinux_errno = output.next<int>();\n  if (result.empty()) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return nullptr;\n  }\n\n  memcpy(\n      dst, result.data(),\n      std::min({static_cast<size_t>(size), static_cast<size_t>(result.size()),\n                static_cast<size_t>(INET6_ADDRSTRLEN)}));\n  return dst;\n}", "commit_link": "github.com/google/asylo/commit/6ff3b77ffe110a33a2f93848a6333f33616f02c4", "file_name": "asylo/platform/host_call/trusted/host_calls.cc", "vul_type": "cwe-125", "description": "Write a C++ function named `enc_untrusted_inet_ntop` that converts a network address into a human-readable string, handling potential errors."}
{"func_name": "job_browse", "func_src_before": "@gui.route(\"/job/<int:job_id>/browse\", defaults={\"path\": \"\"})\n@gui.route(\"/job/<int:job_id>/browse/<path:path>\")\n@login_required\ndef job_browse(job_id: int, path):\n    \"\"\"\n    Browse directory of the job.\n    :param job_id: int\n    :param path: str\n    \"\"\"\n\n    try:\n        # Query job information\n        job_info = query_internal_api(f\"/internal/jobs/{job_id}\", \"get\")\n\n        # Base directory of the job\n        job_base_dir = os.path.dirname(os.path.dirname(job_info[\"outputdir\"]))\n\n    except Exception as err:\n        # Display error on the GUI\n        flash(str(err), \"danger\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Join the base and the requested path\n    abs_path = os.path.join(job_base_dir, path)\n\n    # URL path variable for going back\n    back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")\n\n    # If path doesn't exist\n    if not os.path.exists(abs_path):\n        flash(\"Directory for this job does not exist.\", \"warning\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Check if path is a file and send\n    if os.path.isfile(abs_path):\n        return send_file(abs_path)\n\n    files_info = []\n\n    # Show directory contents\n    files = os.listdir(abs_path)\n\n    # Store directory information\n    for file in files:\n        files_info.append({\n            \"file\": file,\n            \"directory\": os.path.isdir(os.path.join(abs_path, file))\n        })\n\n    return render_template('job_dir.html', title=f\"Job {job_id} Directory\",\n                           job_id=job_id,\n                           abs_path=abs_path,\n                           files_info=files_info,\n                           back_path=back_path)", "func_src_after": "@gui.route(\"/job/<int:job_id>/browse\", defaults={\"path\": \"\"})\n@gui.route(\"/job/<int:job_id>/browse/<path:path>\")\n@login_required\ndef job_browse(job_id: int, path):\n    \"\"\"\n    Browse directory of the job.\n    :param job_id: int\n    :param path: str\n    \"\"\"\n\n    try:\n        # Query job information\n        job_info = query_internal_api(f\"/internal/jobs/{job_id}\", \"get\")\n\n        # Base directory of the job\n        job_base_dir = os.path.dirname(os.path.dirname(job_info[\"outputdir\"]))\n\n    except Exception as err:\n        # Display error on the GUI\n        flash(str(err), \"danger\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Join the base and the requested path\n    abs_path = safe_join(job_base_dir, path)\n\n    # URL path variable for going back\n    back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")\n\n    # If path doesn't exist\n    if not os.path.exists(abs_path):\n        flash(\"Directory for this job does not exist.\", \"warning\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Check if path is a file and send\n    if os.path.isfile(abs_path):\n        return send_file(abs_path)\n\n    files_info = []\n\n    # Show directory contents\n    files = os.listdir(abs_path)\n\n    # Store directory information\n    for file in files:\n        files_info.append({\n            \"file\": file,\n            \"directory\": os.path.isdir(os.path.join(abs_path, file))\n        })\n\n    return render_template('job_dir.html', title=f\"Job {job_id} Directory\",\n                           job_id=job_id,\n                           abs_path=abs_path,\n                           files_info=files_info,\n                           back_path=back_path)", "line_changes": {"deleted": [{"line_no": 24, "char_start": 691, "char_end": 739, "line": "    abs_path = os.path.join(job_base_dir, path)\n"}], "added": [{"line_no": 24, "char_start": 691, "char_end": 736, "line": "    abs_path = safe_join(job_base_dir, path)\n"}]}, "char_changes": {"deleted": [{"char_start": 706, "char_end": 714, "chars": "os.path."}], "added": [{"char_start": 706, "char_end": 711, "chars": "safe_"}]}, "commit_link": "github.com/ganga-devs/ganga/commit/730e7aba192407d35eb37dd7938d49071124be8c", "file_name": "routes.py", "vul_type": "cwe-022", "commit_msg": "# Absolute Path Traversal due to incorrect use of `send_file` call (#2025)\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\r\n\r\n## Common Weakness Enumeration category\r\nCWE - 36\r\n\r\n## Root Cause Analysis\r\n\r\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\r\n```\r\n>>> import os.path\r\n>>> static = \"path/to/mySafeStaticDir\"\r\n>>> malicious = \"/../../../../../etc/passwd\"\r\n>>> os.path.join(t,malicious)\r\n'/../../../../../etc/passwd'\r\n```\r\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\r\n\r\nIn this case, the problems occurs due to the following code :\r\nhttps://github.com/ganga-devs/ganga/blob/0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc/ganga/GangaGUI/gui/routes.py#L671\r\n\r\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\r\n\r\n## Proof of Concept\r\n\r\nThe bug can be verified using a proof of concept similar to the one shown below.\r\n\r\n```\r\ncurl --path-as-is 'http://<domain>/job/<int:job_id>/browse///../../../../etc/passwd\"'\r\n```\r\n## Remediation\r\n\r\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\r\n\r\n## Common Vulnerability Scoring System Vector\r\n\r\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\r\n\r\n(AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L)[https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L&version=3.1]\r\n\r\nThis gives it a base score of 9.3/10 and a severity rating of critical.\r\n\r\n## References\r\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\r\n* github/securitylab#669\r\n\r\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*\r\n\r\nCo-authored-by: Porcupiney Hairs <porucpiney.hairs@protonmail.com>", "description": "Create a Python Flask web route for browsing job directories and files, with user authentication required."}
{"func_name": "_drain_to_working_set", "func_src_before": "    def _drain_to_working_set(self, size=1000):\n        logger.info('Draining to working set %s', self.working_set_filename)\n\n        assert not os.path.exists(self.working_set_filename)\n\n        with new_session() as session:\n            query = session.query(Result)\n\n            if self.after:\n                query = query.filter(Result.datetime > self.after)\n\n            with open(self.working_set_filename, 'wb') as work_file:\n                last_id = -1\n                num_results = 0\n                running = True\n\n                while running:\n                    # Optimized for SQLite scrolling window\n                    rows = query.filter(Result.id > last_id).limit(size).all()\n\n                    if not rows:\n                        break\n\n                    delete_ids = []\n\n                    for result in rows:\n                        line = base64.b64encode(pickle.dumps({\n                            'id': result.id,\n                            'project_id': result.project_id,\n                            'shortcode': result.shortcode,\n                            'url': result.url,\n                            'encoding': result.encoding,\n                            'datetime': result.datetime,\n                        }))\n                        work_file.write(line)\n                        work_file.write(b'\\n')\n\n                        num_results += 1\n                        self.items_count += 1\n\n                        delete_ids.append(result.id)\n\n                        if num_results % 10000 == 0:\n                            logger.info('Drain progress: %d', num_results)\n\n                        if num_results % 100000 == 0:\n                            # Risky, but need to do this since WAL\n                            # performance is low on large transactions\n                            logger.info(\"Checkpoint. (Don't delete stray files if program crashes!)\")\n                            work_file.flush()\n                            session.commit()\n\n                        if self.max_items and num_results >= self.max_items:\n                            logger.info('Reached max items %d.', self.max_items)\n                            running = False\n                            break\n\n                    if self.settings['delete']:\n                        delete_query = delete(Result).where(\n                            Result.id == bindparam('id')\n                        )\n                        session.execute(\n                            delete_query,\n                            [{'id': result_id} for result_id in delete_ids]\n                        )", "func_src_after": "    def _drain_to_working_set(self, size=1000):\n        logger.info('Draining to working set %s', self.working_set_filename)\n\n        assert not os.path.exists(self.working_set_filename)\n\n        with new_session() as session:\n            query = session.query(Result)\n\n            if self.after:\n                query = query.filter(Result.datetime > self.after)\n\n            with gzip.open(self.working_set_filename, 'wb', compresslevel=1) as work_file:\n                last_id = -1\n                num_results = 0\n                running = True\n\n                while running:\n                    # Optimized for SQLite scrolling window\n                    rows = query.filter(Result.id > last_id).limit(size).all()\n\n                    if not rows:\n                        break\n\n                    delete_ids = []\n\n                    for result in rows:\n                        pickle.dump({\n                            'id': result.id,\n                            'project_id': result.project_id,\n                            'shortcode': result.shortcode,\n                            'url': result.url,\n                            'encoding': result.encoding,\n                            'datetime': result.datetime,\n                        }, work_file)\n\n                        num_results += 1\n                        self.items_count += 1\n\n                        delete_ids.append(result.id)\n\n                        if num_results % 10000 == 0:\n                            logger.info('Drain progress: %d', num_results)\n\n                        if num_results % 100000 == 0:\n                            # Risky, but need to do this since WAL\n                            # performance is low on large transactions\n                            logger.info(\"Checkpoint. (Don't delete stray files if program crashes!)\")\n                            work_file.flush()\n                            session.commit()\n\n                        if self.max_items and num_results >= self.max_items:\n                            logger.info('Reached max items %d.', self.max_items)\n                            running = False\n                            break\n\n                    if self.settings['delete']:\n                        delete_query = delete(Result).where(\n                            Result.id == bindparam('id')\n                        )\n                        session.execute(\n                            delete_query,\n                            [{'id': result_id} for result_id in delete_ids]\n                        )\n\n                pickle.dump('eof', work_file)", "line_changes": {"deleted": [{"line_no": 12, "char_start": 365, "char_end": 434, "line": "            with open(self.working_set_filename, 'wb') as work_file:\n"}, {"line_no": 27, "char_start": 839, "char_end": 902, "line": "                        line = base64.b64encode(pickle.dumps({\n"}, {"line_no": 34, "char_start": 1228, "char_end": 1256, "line": "                        }))\n"}, {"line_no": 35, "char_start": 1256, "char_end": 1302, "line": "                        work_file.write(line)\n"}, {"line_no": 36, "char_start": 1302, "char_end": 1349, "line": "                        work_file.write(b'\\n')\n"}], "added": [{"line_no": 12, "char_start": 365, "char_end": 456, "line": "            with gzip.open(self.working_set_filename, 'wb', compresslevel=1) as work_file:\n"}, {"line_no": 27, "char_start": 861, "char_end": 899, "line": "                        pickle.dump({\n"}, {"line_no": 34, "char_start": 1225, "char_end": 1263, "line": "                        }, work_file)\n"}]}, "char_changes": {"deleted": [{"char_start": 863, "char_end": 887, "chars": "line = base64.b64encode("}, {"char_start": 898, "char_end": 899, "chars": "s"}, {"char_start": 1253, "char_end": 1347, "chars": "))\n                        work_file.write(line)\n                        work_file.write(b'\\n'"}], "added": [{"char_start": 382, "char_end": 387, "chars": "gzip."}, {"char_start": 423, "char_end": 440, "chars": ", compresslevel=1"}, {"char_start": 1250, "char_end": 1261, "chars": ", work_file"}, {"char_start": 2534, "char_end": 2581, "chars": "\n\n                pickle.dump('eof', work_file)"}]}, "commit_link": "github.com/ArchiveTeam/terroroftinytown/commit/4614d62a1406ee88562486c24105f38aef48be41", "file_name": "export.py", "vul_type": "cwe-502", "commit_msg": "release: Compress the working set file\n\nInstead of base64-encoding it into lines, save and load each pickle\nsequentially which the pickle module supports which avoids unneeded\nbloat. The entire file stream is gzip compressed (level 1, fast) to\nreduce the disk space usage further.", "parent_commit": "f9f8bc584c714321328b3ec8979eeb4d78cff09b", "description": "Write a Python function to export a dataset to a file, with optional data filtering and deletion after export."}
{"func_name": "delete_resultSet", "func_src_before": "    def delete_resultSet(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = \"DELETE FROM %s WHERE identifier = '%s';\" % (self.table, sid)\n        self._query(query)", "func_src_after": "    def delete_resultSet(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = \"DELETE FROM %s WHERE identifier = $1;\" % (self.table)\n        self._query(query, sid)", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function to delete a record from a database table by ID, optionally normalizing the ID before deletion."}
{"func_name": "make_canonical", "func_src_before": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "func_src_after": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            LY_CHECK_ERR_RETURN(strlen(module_name) + 1 + strlen(*value) > buf_len, LOGBUF(*value), -1);\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            LY_CHECK_ERR_RETURN(strlen(*value) > buf_len, LOGBUF(*value), -1);\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "commit_link": "github.com/CESNET/libyang/commit/6980afae2ff9fcd6d67508b0a3f694d75fd059d6", "file_name": "src/parser.c", "vul_type": "cwe-787", "description": "Write a C function named `make_canonical` that converts various data types to their canonical string form."}
{"func_name": "(anonymous)", "func_src_before": "            // 2\u3001\u7b54\u6848\u3002\n            const answers = map(item.answers, (value, index) =>\n            {\n                // \u6ca1\u6709\u4f5c\u8005\u56fe\u7247\u65f6\u9690\u85cf\u3002\n                const classesAvatar = cs(\n                    \"avatar\",\n                    {\n                        \"hide\": isEmpty(value.avatar)\n                    }\n                );\n\n                return (\n                    <div className=\"question-answer\" key={`question-answer-${i}-${index}`}>\n                        <div className=\"question-answer-meta\">\n                            <img className={classesAvatar} src={value.avatar} />\n                            <span className=\"author\">{value.name}</span>\n                            <span className=\"bio\">{value.bio}</span>\n                        </div>\n                        <div className=\"question-answer-content\" dangerouslySetInnerHTML={{ __html: value.content }} />\n                    </div>\n                );\n            });\n            innerRows.push(...answers);\n\n            // 3\u3001\u5916\u94fe\u3002\n            if (item.link)\n            {\n                innerRows.push(\n                    <div className=\"view-more\" key={`view-more-${i}`}>\n                        <a href={item.link.href} target=\"_blank\"><b>{item.link.text}</b></a>\n                    </div>\n                );\n            }\n\n            questions.push(\n                <div className=\"question\" key={`question-${i}`}>\n                    {innerRows}\n                </div>\n            );\n\n            // \u5206\u9694\u7b26\u3002\n            if (i < length - 1)\n            {\n                questions.push(<hr className=\"question-separator\" key={`question-separator-${i}`} />);\n            }\n        }\n\n        return (", "func_src_after": "            // 2\u3001\u7b54\u6848\u3002\n            const answers = map(item.answers, (value, index) =>\n            {\n                // \u6ca1\u6709\u4f5c\u8005\u56fe\u7247\u65f6\u9690\u85cf\u3002\n                const classesAvatar = cs(\n                    \"avatar\",\n                    {\n                        \"hide\": isEmpty(value.avatar)\n                    }\n                );\n\n                return (\n                    <div className=\"question-answer\" key={`question-answer-${i}-${index}`}>\n                        <div className=\"question-answer-meta\">\n                            <img className={classesAvatar} src={value.avatar} />\n                            <span className=\"author\">{value.name}</span>\n                            <span className=\"bio\">{value.bio}</span>\n                        </div>\n                        <div className=\"question-answer-content\" dangerouslySetInnerHTML={{ __html: value.content }} />\n                    </div>\n                );\n            });\n            innerRows.push(...answers);\n\n            // 3\u3001\u5916\u94fe\u3002\n            if (item.link)\n            {\n                innerRows.push(\n                    <div className=\"view-more\" key={`view-more-${i}`}>\n                        <a href={item.link.href} target=\"_blank\" rel=\"noopener noreferrer\"><b>{item.link.text}</b></a>\n                    </div>\n                );\n            }\n\n            questions.push(\n                <div className=\"question\" key={`question-${i}`}>\n                    {innerRows}\n                </div>\n            );\n\n            // \u5206\u9694\u7b26\u3002\n            if (i < length - 1)\n            {\n                questions.push(<hr className=\"question-separator\" key={`question-separator-${i}`} />);\n            }\n        }\n\n        return (", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1141, "char_end": 1234, "line": "                        <a href={item.link.href} target=\"_blank\"><b>{item.link.text}</b></a>\n"}], "added": [{"line_no": 30, "char_start": 1141, "char_end": 1260, "line": "                        <a href={item.link.href} target=\"_blank\" rel=\"noopener noreferrer\"><b>{item.link.text}</b></a>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1205, "char_end": 1231, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/nonoroazoro/Zhihu-Daily-Reader/commit/e5e310be94fd9adfaa058c7abe3ab2515b16f128", "file_name": "ArticleView.jsx", "vul_type": "cwe-200", "commit_msg": "add rel=\"noopener noreferrer\"", "parent_commit": "07440697d044dc674dc8e55da0d1e1ebac8053df", "description": "In JavaScript, write a React component that displays a list of questions with their answers and optional external links, hiding the author's avatar if not provided."}
{"func_name": "ImagingLibTiffDecode", "func_src_before": "int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_ssize_t bytes) {\n    TIFFSTATE *clientstate = (TIFFSTATE *)state->context;\n    char *filename = \"tempfile.tif\";\n    char *mode = \"r\";\n    TIFF *tiff;\n\n    /* buffer is the encoded file, bytes is the length of the encoded file */\n    /*     it all ends up in state->buffer, which is a uint8* from Imaging.h */\n\n    TRACE((\"in decoder: bytes %d\\n\", bytes));\n    TRACE((\"State: count %d, state %d, x %d, y %d, ystep %d\\n\", state->count, state->state,\n           state->x, state->y, state->ystep));\n    TRACE((\"State: xsize %d, ysize %d, xoff %d, yoff %d \\n\", state->xsize, state->ysize,\n           state->xoff, state->yoff));\n    TRACE((\"State: bits %d, bytes %d \\n\", state->bits, state->bytes));\n    TRACE((\"Buffer: %p: %c%c%c%c\\n\", buffer, (char)buffer[0], (char)buffer[1],(char)buffer[2], (char)buffer[3]));\n    TRACE((\"State->Buffer: %c%c%c%c\\n\", (char)state->buffer[0], (char)state->buffer[1],(char)state->buffer[2], (char)state->buffer[3]));\n    TRACE((\"Image: mode %s, type %d, bands: %d, xsize %d, ysize %d \\n\",\n           im->mode, im->type, im->bands, im->xsize, im->ysize));\n    TRACE((\"Image: image8 %p, image32 %p, image %p, block %p \\n\",\n           im->image8, im->image32, im->image, im->block));\n    TRACE((\"Image: pixelsize: %d, linesize %d \\n\",\n           im->pixelsize, im->linesize));\n\n    dump_state(clientstate);\n    clientstate->size = bytes;\n    clientstate->eof = clientstate->size;\n    clientstate->loc = 0;\n    clientstate->data = (tdata_t)buffer;\n    clientstate->flrealloc = 0;\n    dump_state(clientstate);\n\n    TIFFSetWarningHandler(NULL);\n    TIFFSetWarningHandlerExt(NULL);\n\n    if (clientstate->fp) {\n        TRACE((\"Opening using fd: %d\\n\",clientstate->fp));\n        lseek(clientstate->fp,0,SEEK_SET); // Sometimes, I get it set to the end.\n        tiff = TIFFFdOpen(clientstate->fp, filename, mode);\n    } else {\n        TRACE((\"Opening from string\\n\"));\n        tiff = TIFFClientOpen(filename, mode,\n                              (thandle_t) clientstate,\n                              _tiffReadProc, _tiffWriteProc,\n                              _tiffSeekProc, _tiffCloseProc, _tiffSizeProc,\n                              _tiffMapProc, _tiffUnmapProc);\n    }\n\n    if (!tiff){\n        TRACE((\"Error, didn't get the tiff\\n\"));\n        state->errcode = IMAGING_CODEC_BROKEN;\n        return -1;\n    }\n\n    if (clientstate->ifd){\n        int rv;\n        uint32 ifdoffset = clientstate->ifd;\n        TRACE((\"reading tiff ifd %u\\n\", ifdoffset));\n        rv = TIFFSetSubDirectory(tiff, ifdoffset);\n        if (!rv){\n            TRACE((\"error in TIFFSetSubDirectory\"));\n            return -1;\n        }\n    }\n\n    if (TIFFIsTiled(tiff)) {\n        UINT32 x, y, tile_y, row_byte_size;\n        UINT32 tile_width, tile_length, current_tile_width;\n        UINT8 *new_data;\n\n        TIFFGetField(tiff, TIFFTAG_TILEWIDTH, &tile_width);\n        TIFFGetField(tiff, TIFFTAG_TILELENGTH, &tile_length);\n\n        // We could use TIFFTileSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (tile_width * state->bits + 7) / 8;\n        state->bytes = row_byte_size * tile_length;\n\n        /* overflow check for malloc */\n        if (state->bytes > INT_MAX - 1) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        /* realloc to fit whole tile */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        TRACE((\"TIFFTileSize: %d\\n\", state->bytes));\n\n        for (y = state->yoff; y < state->ysize; y += tile_length) {\n            for (x = state->xoff; x < state->xsize; x += tile_width) {\n                if (ReadTile(tiff, x, y, (UINT32*) state->buffer) == -1) {\n                    TRACE((\"Decode Error, Tile at %dx%d\\n\", x, y));\n                    state->errcode = IMAGING_CODEC_BROKEN;\n                    TIFFClose(tiff);\n                    return -1;\n                }\n\n                TRACE((\"Read tile at %dx%d; \\n\\n\", x, y));\n\n                current_tile_width = min(tile_width, state->xsize - x);\n\n                // iterate over each line in the tile and stuff data into image\n                for (tile_y = 0; tile_y < min(tile_length, state->ysize - y); tile_y++) {\n                    TRACE((\"Writing tile data at %dx%d using tile_width: %d; \\n\", tile_y + y, x, current_tile_width));\n\n                    // UINT8 * bbb = state->buffer + tile_y * row_byte_size;\n                    // TRACE((\"chars: %x%x%x%x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                    state->shuffle((UINT8*) im->image[tile_y + y] + x * im->pixelsize,\n                       state->buffer + tile_y * row_byte_size,\n                       current_tile_width\n                    );\n                }\n            }\n        }\n    } else {\n        UINT32 strip_row, row_byte_size;\n        UINT8 *new_data;\n        UINT32 rows_per_strip;\n        int ret;\n\n        ret = TIFFGetField(tiff, TIFFTAG_ROWSPERSTRIP, &rows_per_strip);\n        if (ret != 1) {\n            rows_per_strip = state->ysize;\n        }\n        TRACE((\"RowsPerStrip: %u \\n\", rows_per_strip));\n\n        // We could use TIFFStripSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (state->xsize * state->bits + 7) / 8;\n        state->bytes = rows_per_strip * row_byte_size;\n\n        TRACE((\"StripSize: %d \\n\", state->bytes));\n\n        /* realloc to fit whole strip */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        for (; state->y < state->ysize; state->y += rows_per_strip) {\n            if (ReadStrip(tiff, state->y, (UINT32 *)state->buffer) == -1) {\n                TRACE((\"Decode Error, strip %d\\n\", TIFFComputeStrip(tiff, state->y, 0)));\n                state->errcode = IMAGING_CODEC_BROKEN;\n                TIFFClose(tiff);\n                return -1;\n            }\n\n            TRACE((\"Decoded strip for row %d \\n\", state->y));\n\n            // iterate over each row in the strip and stuff data into image\n            for (strip_row = 0; strip_row < min(rows_per_strip, state->ysize - state->y); strip_row++) {\n                TRACE((\"Writing data into line %d ; \\n\", state->y + strip_row));\n\n                // UINT8 * bbb = state->buffer + strip_row * (state->bytes / rows_per_strip);\n                // TRACE((\"chars: %x %x %x %x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                state->shuffle((UINT8*) im->image[state->y + state->yoff + strip_row] +\n                               state->xoff * im->pixelsize,\n                               state->buffer + strip_row * row_byte_size,\n                               state->xsize);\n            }\n        }\n    }\n\n    TIFFClose(tiff);\n    TRACE((\"Done Decoding, Returning \\n\"));\n    // Returning -1 here to force ImageFile.load to break, rather than\n    // even think about looping back around.\n    return -1;\n}", "func_src_after": "int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_ssize_t bytes) {\n    TIFFSTATE *clientstate = (TIFFSTATE *)state->context;\n    char *filename = \"tempfile.tif\";\n    char *mode = \"r\";\n    TIFF *tiff;\n\n    /* buffer is the encoded file, bytes is the length of the encoded file */\n    /*     it all ends up in state->buffer, which is a uint8* from Imaging.h */\n\n    TRACE((\"in decoder: bytes %d\\n\", bytes));\n    TRACE((\"State: count %d, state %d, x %d, y %d, ystep %d\\n\", state->count, state->state,\n           state->x, state->y, state->ystep));\n    TRACE((\"State: xsize %d, ysize %d, xoff %d, yoff %d \\n\", state->xsize, state->ysize,\n           state->xoff, state->yoff));\n    TRACE((\"State: bits %d, bytes %d \\n\", state->bits, state->bytes));\n    TRACE((\"Buffer: %p: %c%c%c%c\\n\", buffer, (char)buffer[0], (char)buffer[1],(char)buffer[2], (char)buffer[3]));\n    TRACE((\"State->Buffer: %c%c%c%c\\n\", (char)state->buffer[0], (char)state->buffer[1],(char)state->buffer[2], (char)state->buffer[3]));\n    TRACE((\"Image: mode %s, type %d, bands: %d, xsize %d, ysize %d \\n\",\n           im->mode, im->type, im->bands, im->xsize, im->ysize));\n    TRACE((\"Image: image8 %p, image32 %p, image %p, block %p \\n\",\n           im->image8, im->image32, im->image, im->block));\n    TRACE((\"Image: pixelsize: %d, linesize %d \\n\",\n           im->pixelsize, im->linesize));\n\n    dump_state(clientstate);\n    clientstate->size = bytes;\n    clientstate->eof = clientstate->size;\n    clientstate->loc = 0;\n    clientstate->data = (tdata_t)buffer;\n    clientstate->flrealloc = 0;\n    dump_state(clientstate);\n\n    TIFFSetWarningHandler(NULL);\n    TIFFSetWarningHandlerExt(NULL);\n\n    if (clientstate->fp) {\n        TRACE((\"Opening using fd: %d\\n\",clientstate->fp));\n        lseek(clientstate->fp,0,SEEK_SET); // Sometimes, I get it set to the end.\n        tiff = TIFFFdOpen(clientstate->fp, filename, mode);\n    } else {\n        TRACE((\"Opening from string\\n\"));\n        tiff = TIFFClientOpen(filename, mode,\n                              (thandle_t) clientstate,\n                              _tiffReadProc, _tiffWriteProc,\n                              _tiffSeekProc, _tiffCloseProc, _tiffSizeProc,\n                              _tiffMapProc, _tiffUnmapProc);\n    }\n\n    if (!tiff){\n        TRACE((\"Error, didn't get the tiff\\n\"));\n        state->errcode = IMAGING_CODEC_BROKEN;\n        return -1;\n    }\n\n    if (clientstate->ifd){\n        int rv;\n        uint32 ifdoffset = clientstate->ifd;\n        TRACE((\"reading tiff ifd %u\\n\", ifdoffset));\n        rv = TIFFSetSubDirectory(tiff, ifdoffset);\n        if (!rv){\n            TRACE((\"error in TIFFSetSubDirectory\"));\n            return -1;\n        }\n    }\n\n    if (TIFFIsTiled(tiff)) {\n        UINT32 x, y, tile_y, row_byte_size;\n        UINT32 tile_width, tile_length, current_tile_width;\n        UINT8 *new_data;\n\n        TIFFGetField(tiff, TIFFTAG_TILEWIDTH, &tile_width);\n        TIFFGetField(tiff, TIFFTAG_TILELENGTH, &tile_length);\n\n        // We could use TIFFTileSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (tile_width * state->bits + 7) / 8;\n\n        /* overflow check for realloc */\n        if (INT_MAX / row_byte_size < tile_length) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n        \n        state->bytes = row_byte_size * tile_length;\n\n        /* realloc to fit whole tile */\n        /* malloc check above */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        TRACE((\"TIFFTileSize: %d\\n\", state->bytes));\n\n        for (y = state->yoff; y < state->ysize; y += tile_length) {\n            for (x = state->xoff; x < state->xsize; x += tile_width) {\n                if (ReadTile(tiff, x, y, (UINT32*) state->buffer) == -1) {\n                    TRACE((\"Decode Error, Tile at %dx%d\\n\", x, y));\n                    state->errcode = IMAGING_CODEC_BROKEN;\n                    TIFFClose(tiff);\n                    return -1;\n                }\n\n                TRACE((\"Read tile at %dx%d; \\n\\n\", x, y));\n\n                current_tile_width = min(tile_width, state->xsize - x);\n\n                // iterate over each line in the tile and stuff data into image\n                for (tile_y = 0; tile_y < min(tile_length, state->ysize - y); tile_y++) {\n                    TRACE((\"Writing tile data at %dx%d using tile_width: %d; \\n\", tile_y + y, x, current_tile_width));\n\n                    // UINT8 * bbb = state->buffer + tile_y * row_byte_size;\n                    // TRACE((\"chars: %x%x%x%x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                    state->shuffle((UINT8*) im->image[tile_y + y] + x * im->pixelsize,\n                       state->buffer + tile_y * row_byte_size,\n                       current_tile_width\n                    );\n                }\n            }\n        }\n    } else {\n        UINT32 strip_row, row_byte_size;\n        UINT8 *new_data;\n        UINT32 rows_per_strip;\n        int ret;\n\n        ret = TIFFGetField(tiff, TIFFTAG_ROWSPERSTRIP, &rows_per_strip);\n        if (ret != 1) {\n            rows_per_strip = state->ysize;\n        }\n        TRACE((\"RowsPerStrip: %u \\n\", rows_per_strip));\n\n        // We could use TIFFStripSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (state->xsize * state->bits + 7) / 8;\n\n        /* overflow check for realloc */\n        if (INT_MAX / row_byte_size < rows_per_strip) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n        \n        state->bytes = rows_per_strip * row_byte_size;\n\n        TRACE((\"StripSize: %d \\n\", state->bytes));\n\n        /* realloc to fit whole strip */\n        /* malloc check above */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        for (; state->y < state->ysize; state->y += rows_per_strip) {\n            if (ReadStrip(tiff, state->y, (UINT32 *)state->buffer) == -1) {\n                TRACE((\"Decode Error, strip %d\\n\", TIFFComputeStrip(tiff, state->y, 0)));\n                state->errcode = IMAGING_CODEC_BROKEN;\n                TIFFClose(tiff);\n                return -1;\n            }\n\n            TRACE((\"Decoded strip for row %d \\n\", state->y));\n\n            // iterate over each row in the strip and stuff data into image\n            for (strip_row = 0; strip_row < min(rows_per_strip, state->ysize - state->y); strip_row++) {\n                TRACE((\"Writing data into line %d ; \\n\", state->y + strip_row));\n\n                // UINT8 * bbb = state->buffer + strip_row * (state->bytes / rows_per_strip);\n                // TRACE((\"chars: %x %x %x %x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                state->shuffle((UINT8*) im->image[state->y + state->yoff + strip_row] +\n                               state->xoff * im->pixelsize,\n                               state->buffer + strip_row * row_byte_size,\n                               state->xsize);\n            }\n        }\n    }\n\n    TIFFClose(tiff);\n    TRACE((\"Done Decoding, Returning \\n\"));\n    // Returning -1 here to force ImageFile.load to break, rather than\n    // even think about looping back around.\n    return -1;\n}", "commit_link": "github.com/python-pillow/Pillow/commit/4e2def2539ec13e53a82e06c4b3daf00454100c4", "file_name": "src/libImaging/TiffDecode.c", "vul_type": "cwe-190", "description": "Write a C function named `ImagingLibTiffDecode` that decodes a TIFF image into an internal imaging structure."}
{"func_name": "percona_command", "func_src_before": "    def percona_command(execute_sql, database_name, table_name, options = {})\n      command = \"pt-online-schema-change --alter '#{execute_sql}' D=#{database_name},t=#{table_name}\"\n\n      # Whitelist\n      options = HashWithIndifferentAccess.new(options)\n      options = options.slice(*self.class.percona_flags.keys)\n\n      # Merge config\n      config = percona_config\n      if config\n        config.slice(*self.class.percona_flags.keys).each do |key, value|\n          options[key] ||= value\n        end\n      end\n\n      # Set defaults\n      self.class.percona_flags.each do |flag, flag_config|\n        options[flag] = flag_config[:default] if flag_config.key?(:default) && !options.key?(flag)\n      end\n\n      \"#{command}#{run_mode_flag(options)}#{command_flags(options)}\"\n    end", "func_src_after": "    def percona_command(execute_sql, database_name, table_name, options = {})\n      command = ['pt-online-schema-change', '--alter', execute_sql || '', \"D=#{database_name},t=#{table_name}\"]\n\n      # Whitelist\n      options = HashWithIndifferentAccess.new(options)\n      options = options.slice(*self.class.percona_flags.keys)\n\n      # Merge config\n      config = percona_config\n      if config\n        config.slice(*self.class.percona_flags.keys).each do |key, value|\n          options[key] ||= value\n        end\n      end\n\n      # Set defaults\n      self.class.percona_flags.each do |flag, flag_config|\n        options[flag] = flag_config[:default] if flag_config.key?(:default) && !options.key?(flag)\n      end\n\n      command_parts = command + [run_mode_flag(options)] + command_flags(options)\n\n      command_parts.shelljoin\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 78, "char_end": 180, "line": "      command = \"pt-online-schema-change --alter '#{execute_sql}' D=#{database_name},t=#{table_name}\"\n"}, {"line_no": 21, "char_start": 704, "char_end": 773, "line": "      \"#{command}#{run_mode_flag(options)}#{command_flags(options)}\"\n"}], "added": [{"line_no": 2, "char_start": 78, "char_end": 190, "line": "      command = ['pt-online-schema-change', '--alter', execute_sql || '', \"D=#{database_name},t=#{table_name}\"]\n"}, {"line_no": 21, "char_start": 714, "char_end": 796, "line": "      command_parts = command + [run_mode_flag(options)] + command_flags(options)\n"}, {"line_no": 22, "char_start": 796, "char_end": 797, "line": "\n"}, {"line_no": 23, "char_start": 797, "char_end": 827, "line": "      command_parts.shelljoin\n"}]}, "char_changes": {"deleted": [{"char_start": 94, "char_end": 95, "chars": "\""}, {"char_start": 118, "char_end": 119, "chars": " "}, {"char_start": 126, "char_end": 130, "chars": " '#{"}, {"char_start": 141, "char_end": 144, "chars": "}' "}, {"char_start": 710, "char_end": 713, "chars": "\"#{"}, {"char_start": 720, "char_end": 723, "chars": "}#{"}, {"char_start": 745, "char_end": 748, "chars": "}#{"}, {"char_start": 770, "char_end": 772, "chars": "}\""}], "added": [{"char_start": 94, "char_end": 96, "chars": "['"}, {"char_start": 119, "char_end": 123, "chars": "', '"}, {"char_start": 130, "char_end": 133, "chars": "', "}, {"char_start": 144, "char_end": 153, "chars": " || '', \""}, {"char_start": 188, "char_end": 189, "chars": "]"}, {"char_start": 727, "char_end": 747, "chars": "_parts = command + ["}, {"char_start": 769, "char_end": 773, "chars": "] + "}, {"char_start": 795, "char_end": 826, "chars": "\n\n      command_parts.shelljoin"}]}, "commit_link": "github.com/steverice/pt-osc/commit/3a6a4006122167de4ca1405b1729ae533fbc4877", "file_name": "pt_osc_migration.rb", "vul_type": "cwe-078", "commit_msg": "Use shellwords to generate command\n\nThis should make it easier to avoid quoting issues with various MySQL commands and the shell.\n\nFixes PagerDuty/pt-osc#12", "description": "Write a Ruby method that constructs a command line for the `pt-online-schema-change` tool, accepting SQL to execute, database and table names, and an optional hash of options."}
{"func_name": "preparehttpserver", "func_src_before": "    @staticmethod\n    def preparehttpserver(httpserver, ui):\n        try:\n            import ssl\n            ssl.wrap_socket\n        except ImportError:\n            raise error.Abort(_(\"SSL support is unavailable\"))\n\n        certfile = ui.config('web', 'certificate')\n        httpserver.socket = ssl.wrap_socket(\n            httpserver.socket, server_side=True,\n            certfile=certfile, ssl_version=ssl.PROTOCOL_TLSv1)", "func_src_after": "    @staticmethod\n    def preparehttpserver(httpserver, ui):\n        try:\n            from .. import sslutil\n            sslutil.modernssl\n        except ImportError:\n            raise error.Abort(_(\"SSL support is unavailable\"))\n\n        certfile = ui.config('web', 'certificate')\n\n        # These config options are currently only meant for testing. Use\n        # at your own risk.\n        cafile = ui.config('devel', 'servercafile')\n        reqcert = ui.configbool('devel', 'serverrequirecert')\n\n        httpserver.socket = sslutil.wrapserversocket(httpserver.socket,\n                                                     ui,\n                                                     certfile=certfile,\n                                                     cafile=cafile,\n                                                     requireclientcert=reqcert)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 74, "char_end": 97, "line": "            import ssl\n"}, {"line_no": 5, "char_start": 97, "char_end": 125, "line": "            ssl.wrap_socket\n"}, {"line_no": 10, "char_start": 268, "char_end": 313, "line": "        httpserver.socket = ssl.wrap_socket(\n"}, {"line_no": 11, "char_start": 313, "char_end": 362, "line": "            httpserver.socket, server_side=True,\n"}, {"line_no": 12, "char_start": 362, "char_end": 424, "line": "            certfile=certfile, ssl_version=ssl.PROTOCOL_TLSv1)\n"}], "added": [{"line_no": 4, "char_start": 74, "char_end": 109, "line": "            from .. import sslutil\n"}, {"line_no": 5, "char_start": 109, "char_end": 139, "line": "            sslutil.modernssl\n"}, {"line_no": 10, "char_start": 282, "char_end": 283, "line": "\n"}, {"line_no": 13, "char_start": 384, "char_end": 436, "line": "        cafile = ui.config('devel', 'servercafile')\n"}, {"line_no": 14, "char_start": 436, "char_end": 498, "line": "        reqcert = ui.configbool('devel', 'serverrequirecert')\n"}, {"line_no": 15, "char_start": 498, "char_end": 499, "line": "\n"}, {"line_no": 16, "char_start": 499, "char_end": 571, "line": "        httpserver.socket = sslutil.wrapserversocket(httpserver.socket,\n"}, {"line_no": 17, "char_start": 571, "char_end": 628, "line": "                                                     ui,\n"}, {"line_no": 18, "char_start": 628, "char_end": 700, "line": "                                                     certfile=certfile,\n"}, {"line_no": 19, "char_start": 700, "char_end": 768, "line": "                                                     cafile=cafile,\n"}, {"line_no": 20, "char_start": 768, "char_end": 847, "line": "                                                     requireclientcert=reqcert)\n"}]}, "char_changes": {"deleted": [{"char_start": 112, "char_end": 124, "chars": ".wrap_socket"}, {"char_start": 276, "char_end": 423, "chars": "httpserver.socket = ssl.wrap_socket(\n            httpserver.socket, server_side=True,\n            certfile=certfile, ssl_version=ssl.PROTOCOL_TLSv1"}], "added": [{"char_start": 85, "char_end": 93, "chars": " from .."}, {"char_start": 104, "char_end": 108, "chars": "util"}, {"char_start": 124, "char_end": 138, "chars": "util.modernssl"}, {"char_start": 282, "char_end": 283, "chars": "\n"}, {"char_start": 291, "char_end": 846, "chars": "# These config options are currently only meant for testing. Use\n        # at your own risk.\n        cafile = ui.config('devel', 'servercafile')\n        reqcert = ui.configbool('devel', 'serverrequirecert')\n\n        httpserver.socket = sslutil.wrapserversocket(httpserver.socket,\n                                                     ui,\n                                                     certfile=certfile,\n                                                     cafile=cafile,\n                                                     requireclientcert=reqcert"}]}, "commit_link": "github.com/facebookexperimental/eden/commit/c023f774e64a89a05ebe18d111db425584fb9b86", "file_name": "server.py", "vul_type": "cwe-327", "commit_msg": "hgweb: use sslutil.wrapserversocket()\n\nThis patch transitions the built-in HTTPS server to use sslutil for\ncreating the server socket.\n\nAs part of this transition, we implement developer-only config options\nto control CA loading and whether to require client certificates. This\neliminates the need for the custom extension in test-https.t to define\nthese.\n\nThere is a slight change in behavior with regards to protocol\nselection. Before, we would always use the TLS 1.0 constant to define\nthe protocol version. This would *only* use TLS 1.0. sslutil defaults\nto TLS 1.0+. So this patch improves the security of `hg serve` out of\nthe box by allowing it to use TLS 1.1 and 1.2 (if available).", "description": "Write a Python function that configures an HTTP server with SSL using a certificate from the configuration."}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = '{email}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = %s\"\"\", (email, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/admins.py", "vul_type": "cwe-089", "description": "Write a Python function with JWT authentication that deletes an admin by email from a database using SQL query execution."}
{"func_name": "retrieve_video", "func_src_before": "def retrieve_video(id, playlist_id, db):\n    db.execute(\"SELECT id, position from video WHERE id={id} and playlist_id={playlist_id};\".format(\n        id=id, playlist_id=playlist_id))\n    row = db.fetchone()\n    return row", "func_src_after": "def retrieve_video(id, playlist_id, db):\n    db.execute(\n        \"SELECT id, position from video WHERE id=%s and playlist_id=%s;\", (id, playlist_id))\n    row = db.fetchone()\n    return row", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089", "description": "Write a Python function named `retrieve_video` that fetches a video's ID and position from a database given a video ID and playlist ID."}
{"func_name": "save_moderation", "func_src_before": "@app.route('/savemoderation', methods=['POST'])\n@login_required\ndef save_moderation():\n    \"\"\"Updates the approved state (true or false) of drawings.\"\"\"\n\n    timestamp = time()\n    to_approve = request.form.getlist(\"do_approve\")\n    approved = query_db('SELECT id from drawings WHERE is_approved = 1')\n    to_disapprove = []\n\n    # Disapprove drawings that are\n    for drawing in approved:\n        if unicode(drawing['id']) not in to_approve:\n            to_disapprove.append(drawing['id'])\n\n    # Update Database\n    if len(to_approve):\n        insert_db('UPDATE drawings SET is_approved = 1, ts_moderated = ' + str(timestamp) + ' WHERE is_approved = 0 AND ' + ' OR '.join([\"id=\" + str(i) for i in to_approve]))\n    if len(to_disapprove):\n        insert_db('UPDATE drawings SET is_approved = 0, ts_moderated = ' + str(timestamp) + ' WHERE is_approved = 1 AND ' + ' OR '.join([\"id=\" + str(i) for i in to_disapprove]))\n\n\n    return redirect(url_for('admin'))", "func_src_after": "@app.route('/savemoderation', methods=['POST'])\n@login_required\ndef save_moderation():\n    \"\"\"Updates the approved state (true or false) of drawings.\"\"\"\n\n    timestamp = time()\n    to_approve = request.form.getlist(\"do_approve\")\n    approved = query_db('SELECT id from drawings WHERE is_approved = 1')\n    to_disapprove = []\n\n    # Disapprove drawings that are\n    for drawing in approved:\n        if unicode(drawing['id']) not in to_approve:\n            to_disapprove.append(drawing['id'])\n\n    len_to_approve = len(to_approve)\n    len_to_disapprove = len(to_disapprove)\n\n    # Update Database (injection safe :))\n    if len_to_approve:\n        insert_db('UPDATE drawings SET is_approved = 1, ts_moderated = ? WHERE is_approved = 0 AND ' + ' OR '.join(['id = ?'] * len_to_approve), [str(timestamp)] + to_approve)\n    if len_to_disapprove:\n        insert_db('UPDATE drawings SET is_approved = 0, ts_moderated = ? WHERE is_approved = 1 AND ' + ' OR '.join(['id = ?'] * len_to_disapprove), [str(timestamp)] + to_disapprove)\n\n\n    return redirect(url_for('admin'))", "line_changes": {"deleted": [{"line_no": 17, "char_start": 514, "char_end": 538, "line": "    if len(to_approve):\n"}, {"line_no": 18, "char_start": 538, "char_end": 713, "line": "        insert_db('UPDATE drawings SET is_approved = 1, ts_moderated = ' + str(timestamp) + ' WHERE is_approved = 0 AND ' + ' OR '.join([\"id=\" + str(i) for i in to_approve]))\n"}, {"line_no": 19, "char_start": 713, "char_end": 740, "line": "    if len(to_disapprove):\n"}, {"line_no": 20, "char_start": 740, "char_end": 918, "line": "        insert_db('UPDATE drawings SET is_approved = 0, ts_moderated = ' + str(timestamp) + ' WHERE is_approved = 1 AND ' + ' OR '.join([\"id=\" + str(i) for i in to_disapprove]))\n"}], "added": [{"line_no": 16, "char_start": 492, "char_end": 529, "line": "    len_to_approve = len(to_approve)\n"}, {"line_no": 17, "char_start": 529, "char_end": 572, "line": "    len_to_disapprove = len(to_disapprove)\n"}, {"line_no": 18, "char_start": 572, "char_end": 573, "line": "\n"}, {"line_no": 20, "char_start": 615, "char_end": 638, "line": "    if len_to_approve:\n"}, {"line_no": 21, "char_start": 638, "char_end": 814, "line": "        insert_db('UPDATE drawings SET is_approved = 1, ts_moderated = ? WHERE is_approved = 0 AND ' + ' OR '.join(['id = ?'] * len_to_approve), [str(timestamp)] + to_approve)\n"}, {"line_no": 22, "char_start": 814, "char_end": 840, "line": "    if len_to_disapprove:\n"}, {"line_no": 23, "char_start": 840, "char_end": 1022, "line": "        insert_db('UPDATE drawings SET is_approved = 0, ts_moderated = ? WHERE is_approved = 1 AND ' + ' OR '.join(['id = ?'] * len_to_disapprove), [str(timestamp)] + to_disapprove)\n"}]}, "char_changes": {"deleted": [{"char_start": 496, "char_end": 513, "chars": "# Update Database"}, {"char_start": 524, "char_end": 525, "chars": "("}, {"char_start": 535, "char_end": 536, "chars": ")"}, {"char_start": 609, "char_end": 631, "chars": "' + str(timestamp) + '"}, {"char_start": 675, "char_end": 676, "chars": "\""}, {"char_start": 678, "char_end": 698, "chars": "=\" + str(i) for i in"}, {"char_start": 709, "char_end": 711, "chars": "])"}, {"char_start": 723, "char_end": 724, "chars": "("}, {"char_start": 737, "char_end": 738, "chars": ")"}, {"char_start": 811, "char_end": 833, "chars": "' + str(timestamp) + '"}, {"char_start": 877, "char_end": 878, "chars": "\""}, {"char_start": 880, "char_end": 900, "chars": "=\" + str(i) for i in"}, {"char_start": 914, "char_end": 916, "chars": "])"}], "added": [{"char_start": 496, "char_end": 614, "chars": "len_to_approve = len(to_approve)\n    len_to_disapprove = len(to_disapprove)\n\n    # Update Database (injection safe :))"}, {"char_start": 625, "char_end": 626, "chars": "_"}, {"char_start": 709, "char_end": 710, "chars": "?"}, {"char_start": 754, "char_end": 755, "chars": "'"}, {"char_start": 757, "char_end": 801, "chars": " = ?'] * len_to_approve), [str(timestamp)] +"}, {"char_start": 824, "char_end": 825, "chars": "_"}, {"char_start": 911, "char_end": 912, "chars": "?"}, {"char_start": 956, "char_end": 957, "chars": "'"}, {"char_start": 959, "char_end": 1006, "chars": " = ?'] * len_to_disapprove), [str(timestamp)] +"}]}, "commit_link": "github.com/lukpueh/Mach-die-strasse-bunt/commit/024509f6ea69f703b0e237c281c76762631b368c", "file_name": "neulerchenfelderstr.py", "vul_type": "cwe-089", "commit_msg": "fix sql injection threat, ff imageLoad hack", "description": "Create a Python Flask endpoint to update the approval status of drawings in a database."}
{"func_name": "main", "func_src_before": "int main() {\n\tTERM *t;\n\tchar buffer[300];\n\n\tprintf(\"lci - A lambda calculus interpreter\\n\");\n\tprintf(\"Copyright (C) 2003 Kostas Hatzikokolakis\\n\");\n\tprintf(\"This is FREE SOFTWARE and comes with ABSOLUTELY NO WARRANTY\\n\\n\");\n\tprintf(\"Type a term, Help for info or Quit to exit.\\n\");\n\n\t// read and execute .lcirc\n\tconsultFile(\".lcirc\");\n\n\t// read and execute commands\n\twhile(!feof(stdin)) {\n\t\tprintf(\"lci> \");\n\t\tif(!gets(buffer)) break;\n\t\tif(buffer[0] == '\\0') continue;\n\n\t\tscInputType = SC_BUFFER;\n\t\tscInput = buffer;\n\t\tgetToken(NULL);\n\n\t\tif(parse((void*)&t, TK_TERM) == PAR_OK)\n\t\t\texecTerm(t);\n\t\telse\n\t\t\tprintf(\"Syntax error\\n\\n\");\n\t}\n\n\treturn 0;\n}", "func_src_after": "int main() {\n\tTERM *t;\n\tchar buffer[300];\n\n\tprintf(\"lci - A lambda calculus interpreter\\n\");\n\tprintf(\"Copyright (C) 2003 Kostas Hatzikokolakis\\n\");\n\tprintf(\"This is FREE SOFTWARE and comes with ABSOLUTELY NO WARRANTY\\n\\n\");\n\tprintf(\"Type a term, Help for info or Quit to exit.\\n\");\n\n\t// read and execute .lcirc\n\tconsultFile(\".lcirc\");\n\n\t// read and execute commands\n\twhile(!feof(stdin)) {\n\t\tprintf(\"lci> \");\n\t\tif(!fgets(buffer, sizeof(buffer), stdin)) break;\n\t\tif(strcmp(buffer, \"\\n\") == 0) continue;\n\n\t\tscInputType = SC_BUFFER;\n\t\tscInput = buffer;\n\t\tgetToken(NULL);\n\n\t\tif(parse((void*)&t, TK_TERM) == PAR_OK)\n\t\t\texecTerm(t);\n\t\telse\n\t\t\tprintf(\"Syntax error\\n\\n\");\n\t}\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 408, "char_end": 435, "line": "\t\tif(!gets(buffer)) break;\n"}, {"line_no": 17, "char_start": 435, "char_end": 469, "line": "\t\tif(buffer[0] == '\\0') continue;\n"}], "added": [{"line_no": 16, "char_start": 408, "char_end": 459, "line": "\t\tif(!fgets(buffer, sizeof(buffer), stdin)) break;\n"}, {"line_no": 17, "char_start": 459, "char_end": 501, "line": "\t\tif(strcmp(buffer, \"\\n\") == 0) continue;\n"}]}, "char_changes": {"deleted": [{"char_start": 425, "char_end": 457, "chars": ")) break;\n\t\tif(buffer[0] == '\\0'"}], "added": [{"char_start": 414, "char_end": 415, "chars": "f"}, {"char_start": 426, "char_end": 489, "chars": ", sizeof(buffer), stdin)) break;\n\t\tif(strcmp(buffer, \"\\n\") == 0"}]}, "commit_link": "github.com/8l/lci/commit/82786e58e0e56a00d97ded474c6589c08e885149", "file_name": "main.c", "vul_type": "cwe-676", "commit_msg": "Replaced the 'dangerous' gets by fgets.", "parent_commit": "204649b76eb58335e3c8e1bf4831039ea91f0489", "description": "Write a C program that serves as a simple command-line interpreter for lambda calculus expressions, including a greeting message and a loop to process user input."}
{"func_name": "opj_j2k_write_mco", "func_src_before": "static OPJ_BOOL opj_j2k_write_mco(     opj_j2k_t *p_j2k,\n                                                struct opj_stream_private *p_stream,\n                                                struct opj_event_mgr * p_manager\n                                  )\n{\n        OPJ_BYTE * l_current_data = 00;\n        OPJ_UINT32 l_mco_size;\n        opj_tcp_t * l_tcp = 00;\n        opj_simple_mcc_decorrelation_data_t * l_mcc_record;\n        OPJ_UINT32 i;\n\n        /* preconditions */\n        assert(p_j2k != 00);\n        assert(p_manager != 00);\n        assert(p_stream != 00);\n\n        l_tcp =&(p_j2k->m_cp.tcps[p_j2k->m_current_tile_number]);\n        l_current_data = p_j2k->m_specific_param.m_encoder.m_header_tile_data;\n\n        l_mco_size = 5 + l_tcp->m_nb_mcc_records;\n        if (l_mco_size > p_j2k->m_specific_param.m_encoder.m_header_tile_data_size) {\n\n                OPJ_BYTE *new_header_tile_data = (OPJ_BYTE *) opj_realloc(p_j2k->m_specific_param.m_encoder.m_header_tile_data, l_mco_size);\n                if (! new_header_tile_data) {\n                        opj_free(p_j2k->m_specific_param.m_encoder.m_header_tile_data);\n                        p_j2k->m_specific_param.m_encoder.m_header_tile_data = NULL;\n                        p_j2k->m_specific_param.m_encoder.m_header_tile_data_size = 0;\n                        opj_event_msg(p_manager, EVT_ERROR, \"Not enough memory to write MCO marker\\n\");\n                        return OPJ_FALSE;\n                }\n                p_j2k->m_specific_param.m_encoder.m_header_tile_data = new_header_tile_data;\n                p_j2k->m_specific_param.m_encoder.m_header_tile_data_size = l_mco_size;\n        }\n\n        opj_write_bytes(l_current_data,J2K_MS_MCO,2);                   /* MCO */\n        l_current_data += 2;\n\n        opj_write_bytes(l_current_data,l_mco_size-2,2);                 /* Lmco */\n        l_current_data += 2;\n\n        opj_write_bytes(l_current_data,l_tcp->m_nb_mcc_records,1);      /* Nmco : only one tranform stage*/\n        ++l_current_data;\n\n        l_mcc_record = l_tcp->m_mcc_records;\n        for     (i=0;i<l_tcp->m_nb_mcc_records;++i) {\n                opj_write_bytes(l_current_data,l_mcc_record->m_index,1);/* Imco -> use the mcc indicated by 1*/\n                ++l_current_data;\n\n                ++l_mcc_record;\n        }\n\n        if (opj_stream_write_data(p_stream,p_j2k->m_specific_param.m_encoder.m_header_tile_data,l_mco_size,p_manager) != l_mco_size) {\n                return OPJ_FALSE;\n        }\n\n        return OPJ_TRUE;\n}", "func_src_after": "static OPJ_BOOL opj_j2k_write_mco(     opj_j2k_t *p_j2k,\n                                                struct opj_stream_private *p_stream,\n                                                struct opj_event_mgr * p_manager\n                                  )\n{\n        OPJ_BYTE * l_current_data = 00;\n        OPJ_UINT32 l_mco_size;\n        opj_tcp_t * l_tcp = 00;\n        opj_simple_mcc_decorrelation_data_t * l_mcc_record;\n        OPJ_UINT32 i;\n\n        /* preconditions */\n        assert(p_j2k != 00);\n        assert(p_manager != 00);\n        assert(p_stream != 00);\n\n        l_tcp =&(p_j2k->m_cp.tcps[p_j2k->m_current_tile_number]);\n\t\n        l_mco_size = 5 + l_tcp->m_nb_mcc_records;\n        if (l_mco_size > p_j2k->m_specific_param.m_encoder.m_header_tile_data_size) {\n\n                OPJ_BYTE *new_header_tile_data = (OPJ_BYTE *) opj_realloc(p_j2k->m_specific_param.m_encoder.m_header_tile_data, l_mco_size);\n                if (! new_header_tile_data) {\n                        opj_free(p_j2k->m_specific_param.m_encoder.m_header_tile_data);\n                        p_j2k->m_specific_param.m_encoder.m_header_tile_data = NULL;\n                        p_j2k->m_specific_param.m_encoder.m_header_tile_data_size = 0;\n                        opj_event_msg(p_manager, EVT_ERROR, \"Not enough memory to write MCO marker\\n\");\n                        return OPJ_FALSE;\n                }\n                p_j2k->m_specific_param.m_encoder.m_header_tile_data = new_header_tile_data;\n                p_j2k->m_specific_param.m_encoder.m_header_tile_data_size = l_mco_size;\n        }\n        l_current_data = p_j2k->m_specific_param.m_encoder.m_header_tile_data;\n\n\n        opj_write_bytes(l_current_data,J2K_MS_MCO,2);                   /* MCO */\n        l_current_data += 2;\n\n        opj_write_bytes(l_current_data,l_mco_size-2,2);                 /* Lmco */\n        l_current_data += 2;\n\n        opj_write_bytes(l_current_data,l_tcp->m_nb_mcc_records,1);      /* Nmco : only one tranform stage*/\n        ++l_current_data;\n\n        l_mcc_record = l_tcp->m_mcc_records;\n        for (i=0;i<l_tcp->m_nb_mcc_records;++i) {\n                opj_write_bytes(l_current_data,l_mcc_record->m_index,1);/* Imco -> use the mcc indicated by 1*/\n                ++l_current_data;\n                ++l_mcc_record;\n        }\n\n        if (opj_stream_write_data(p_stream,p_j2k->m_specific_param.m_encoder.m_header_tile_data,l_mco_size,p_manager) != l_mco_size) {\n                return OPJ_FALSE;\n        }\n\n        return OPJ_TRUE;\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/940100c28ae28931722290794889cf84a92c5f6f", "file_name": "src/lib/openjp2/j2k.c", "vul_type": "cwe-416", "description": "Write a C function named `opj_j2k_write_mco` that writes the MCO marker for JPEG 2000 image encoding."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tif (!php_var_unserialize_ex(return_value, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tzval_ptr_dtor(return_value);\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\t/* We should keep an reference to return_value to prevent it from being dtor\n\t   in case nesting calls to unserialize */\n\tvar_push_dtor(&var_hash, return_value);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "func_src_after": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tzval *retval;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tretval = var_tmp_var(&var_hash);\n\tif (!php_var_unserialize_ex(retval, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\n\tZVAL_COPY(return_value, retval);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "commit_link": "github.com/php/php-src/commit/b2af4e8868726a040234de113436c6e4f6372d17", "file_name": "ext/standard/var.c", "vul_type": "cwe-416", "description": "Write a PHP function to unserialize data with an optional parameter for allowed classes."}
{"func_name": "apiCallbacksStreams", "func_src_before": "func apiCallbacksStreams(w http.ResponseWriter, r *http.Request) {\n\tchallenge := r.URL.Query().Get(\"hub.challenge\")\n\tif challenge != \"\" {\n\t\tfmt.Fprint(w, challenge)\n\t\tfmt.Println(\"Responding to streams\")\n\t\treturn\n\t}\n\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\n\tbody, err := ioutil.ReadAll(r.Body)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tvar response streamsResponse\n\n\terr = json.Unmarshal(body, &response)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tif len(response.Data) > 0 {\n\t\tfmt.Printf(\"%#v\\n\", response.Data)\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t} else {\n\t\tfmt.Printf(\"%#v\\n\", response.Data)\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t}\n}", "func_src_after": "func apiCallbacksStreams(w http.ResponseWriter, r *http.Request) {\n\tchallenge := r.URL.Query().Get(\"hub.challenge\")\n\tif challenge != \"\" {\n\t\tfmt.Fprint(w, html.EscapeString(challenge))\n\t\tfmt.Println(\"Responding to streams\")\n\t\treturn\n\t}\n\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\n\tbody, err := ioutil.ReadAll(r.Body)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tvar response streamsResponse\n\n\terr = json.Unmarshal(body, &response)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tif len(response.Data) > 0 {\n\t\tfmt.Printf(\"%#v\\n\", response.Data)\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t} else {\n\t\tfmt.Printf(\"%#v\\n\", response.Data)\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t}\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 138, "char_end": 165, "line": "\t\tfmt.Fprint(w, challenge)\n"}], "added": [{"line_no": 4, "char_start": 138, "char_end": 184, "line": "\t\tfmt.Fprint(w, html.EscapeString(challenge))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 154, "char_end": 172, "chars": "html.EscapeString("}, {"char_start": 182, "char_end": 183, "chars": ")"}]}, "commit_link": "github.com/pajlada/pajbot2/commit/69ef922a07fc648760f030604e0aea86a573ea83", "file_name": "hook.go", "vul_type": "cwe-079", "commit_msg": "Fix cross-site scripting vulnerabilities (#447)", "parent_commit": "d8321a06903ec460cf6343c51ae50d12a3cb45e9", "description": "Write a Go function to handle webhooks for stream status updates, responding to a challenge parameter and printing multiple lines of \"Online!\" or \"Offline!\" based on the received data."}
{"func_name": "GetOutboundPinholeTimeout", "func_src_before": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "func_src_after": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\tif (!int_port || !ext_port || !protocol)\n\t{\n\t\tClearNameValueList(&data);\n\t\tSoapError(h, 402, \"Invalid Args\");\n\t\treturn;\n\t}\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/13585f15c7f7dc28bbbba1661efb280d530d114c", "file_name": "miniupnpd/upnpsoap.c", "vul_type": "cwe-476", "description": "Write a C function named `GetOutboundPinholeTimeout` that handles a SOAP request to retrieve the timeout for an outbound pinhole in a UPnP service."}
{"func_name": "login", "func_src_before": "def login(username, password):\n    \"\"\"Returns a `User` instance if the login does not fail with the\n    given login and password.\n\n    :username: username as String\n    :password: password as SHA1 encrypted string\n    :returns: `User` instance if login is OK else None.\n\n    \"\"\"\n    md5_pw = hashlib.md5()\n    md5_pw.update(password or \"\")\n    md5_pw = md5_pw.hexdigest()\n    log.debug(\"Login user '%s' with pw '%s'\" % (username, password))\n    try:\n        user = DBSession.query(User).filter_by(login=username,\n                                               password=md5_pw).one()\n        if user.activated:\n            log.info(\"Login successfull '%s'\" % (username))\n            return user\n        log.info(\"Login failed for user '%s'. \"\n                 \"Reason: Not activated\" % username)\n    except NoResultFound:\n        log.info(\"Login failed for user '%s'. \"\n                 \"Reason: Username or Password wrong\" % username)\n    return None", "func_src_after": "def login(username, password):\n    \"\"\"Returns a `User` instance if the login does not fail with the\n    given login and password.\n\n    :username: username as String\n    :password: password as SHA1 encrypted string\n    :returns: `User` instance if login is OK else None.\n\n    \"\"\"\n    log.debug(\"Login user '%s' with pw '%s'\" % (username, password))\n    user = load_user(username)\n    if user:\n        if verify_password(password, user.password):\n            if user.activated:\n                log.info(\"Login successfull '%s'\" % (username))\n                if passwords_needs_update(user.password):\n                    log.info(\"Updating password for user '%s'\" % (username))\n                    user.password = encrypt_password(password) \n                return user\n            else:\n                log.info(\"Login failed for user '%s'. \"\n                         \"Reason: Not activated\" % username)\n        else:\n            log.info(\"Login failed for user '%s'. \"\n                     \"Reason: Wrong password\" % username)\n    else:\n        log.info(\"Login failed for user '%s'. \"\n                 \"Reason: Username not known\" % username)\n    return None", "line_changes": {"deleted": [{"line_no": 10, "char_start": 279, "char_end": 306, "line": "    md5_pw = hashlib.md5()\n"}, {"line_no": 11, "char_start": 306, "char_end": 340, "line": "    md5_pw.update(password or \"\")\n"}, {"line_no": 12, "char_start": 340, "char_end": 372, "line": "    md5_pw = md5_pw.hexdigest()\n"}, {"line_no": 14, "char_start": 441, "char_end": 450, "line": "    try:\n"}, {"line_no": 15, "char_start": 450, "char_end": 513, "line": "        user = DBSession.query(User).filter_by(login=username,\n"}, {"line_no": 16, "char_start": 513, "char_end": 583, "line": "                                               password=md5_pw).one()\n"}, {"line_no": 17, "char_start": 583, "char_end": 610, "line": "        if user.activated:\n"}, {"line_no": 18, "char_start": 610, "char_end": 670, "line": "            log.info(\"Login successfull '%s'\" % (username))\n"}, {"line_no": 19, "char_start": 670, "char_end": 694, "line": "            return user\n"}, {"line_no": 20, "char_start": 694, "char_end": 742, "line": "        log.info(\"Login failed for user '%s'. \"\n"}, {"line_no": 21, "char_start": 742, "char_end": 795, "line": "                 \"Reason: Not activated\" % username)\n"}, {"line_no": 22, "char_start": 795, "char_end": 821, "line": "    except NoResultFound:\n"}, {"line_no": 24, "char_start": 869, "char_end": 935, "line": "                 \"Reason: Username or Password wrong\" % username)\n"}], "added": [{"line_no": 11, "char_start": 348, "char_end": 379, "line": "    user = load_user(username)\n"}, {"line_no": 12, "char_start": 379, "char_end": 392, "line": "    if user:\n"}, {"line_no": 13, "char_start": 392, "char_end": 445, "line": "        if verify_password(password, user.password):\n"}, {"line_no": 14, "char_start": 445, "char_end": 476, "line": "            if user.activated:\n"}, {"line_no": 15, "char_start": 476, "char_end": 540, "line": "                log.info(\"Login successfull '%s'\" % (username))\n"}, {"line_no": 16, "char_start": 540, "char_end": 598, "line": "                if passwords_needs_update(user.password):\n"}, {"line_no": 17, "char_start": 598, "char_end": 675, "line": "                    log.info(\"Updating password for user '%s'\" % (username))\n"}, {"line_no": 18, "char_start": 675, "char_end": 739, "line": "                    user.password = encrypt_password(password) \n"}, {"line_no": 19, "char_start": 739, "char_end": 767, "line": "                return user\n"}, {"line_no": 20, "char_start": 767, "char_end": 785, "line": "            else:\n"}, {"line_no": 21, "char_start": 785, "char_end": 841, "line": "                log.info(\"Login failed for user '%s'. \"\n"}, {"line_no": 22, "char_start": 841, "char_end": 902, "line": "                         \"Reason: Not activated\" % username)\n"}, {"line_no": 23, "char_start": 902, "char_end": 916, "line": "        else:\n"}, {"line_no": 24, "char_start": 916, "char_end": 968, "line": "            log.info(\"Login failed for user '%s'. \"\n"}, {"line_no": 25, "char_start": 968, "char_end": 1026, "line": "                     \"Reason: Wrong password\" % username)\n"}, {"line_no": 26, "char_start": 1026, "char_end": 1036, "line": "    else:\n"}, {"line_no": 28, "char_start": 1084, "char_end": 1142, "line": "                 \"Reason: Username not known\" % username)\n"}]}, "char_changes": {"deleted": [{"char_start": 283, "char_end": 545, "chars": "md5_pw = hashlib.md5()\n    md5_pw.update(password or \"\")\n    md5_pw = md5_pw.hexdigest()\n    log.debug(\"Login user '%s' with pw '%s'\" % (username, password))\n    try:\n        user = DBSession.query(User).filter_by(login=username,\n                                "}, {"char_start": 568, "char_end": 694, "chars": "=md5_pw).one()\n        if user.activated:\n            log.info(\"Login successfull '%s'\" % (username))\n            return user\n"}, {"char_start": 799, "char_end": 819, "chars": "except NoResultFound"}, {"char_start": 904, "char_end": 921, "chars": "or Password wrong"}], "added": [{"char_start": 283, "char_end": 540, "chars": "log.debug(\"Login user '%s' with pw '%s'\" % (username, password))\n    user = load_user(username)\n    if user:\n        if verify_password(password, user.password):\n            if user.activated:\n                log.info(\"Login successfull '%s'\" % (username))\n"}, {"char_start": 555, "char_end": 559, "chars": " if "}, {"char_start": 567, "char_end": 793, "chars": "s_needs_update(user.password):\n                    log.info(\"Updating password for user '%s'\" % (username))\n                    user.password = encrypt_password(password) \n                return user\n            else:\n        "}, {"char_start": 858, "char_end": 863, "chars": "     "}, {"char_start": 863, "char_end": 866, "chars": "   "}, {"char_start": 906, "char_end": 1034, "chars": "    else:\n            log.info(\"Login failed for user '%s'. \"\n                     \"Reason: Wrong password\" % username)\n    else"}, {"char_start": 1119, "char_end": 1128, "chars": "not known"}]}, "commit_link": "github.com/ringo-framework/ringo/commit/8e92641fee542f6e7004e827136dea3ce5e99eb2", "file_name": "security.py", "vul_type": "cwe-327", "commit_msg": "Replaced use of the old hashlib.md5 method for password encryption with new\nencryption methods using passlib. Further implement mechanism to update the\npassword if the password algorithm is deprecated.", "parent_commit": "8cfe035de8fc493923385093cc7f5c5455fb08f9", "description": "Write a Python function named `login` that checks a user's credentials and returns the user object if authenticated or `None` otherwise."}
{"func_name": "tcp_forward", "func_src_before": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward('tcp:%d tcp:%d' % (host_port, device_port))", "func_src_after": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward(['tcp:%d' % host_port, 'tcp:%d' % device_port])", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "Write a Python function named `tcp_forward` that sets up TCP forwarding between a specified host port and an Android device port."}
{"func_name": "dumprecord", "func_src_before": "func dumprecord(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tdatabase := parray[0]\n\ttable := parray[1]\n\trec, err := strconv.Atoi(parray[2])\n\tcheckY(err)\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from \" + table)\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcolumns, err := rows.Columns()\n\tcheckY(err)\n\n\traw := make([]interface{}, len(columns))\n\tval := make([]interface{}, len(columns))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\nrowLoop:\n\tfor rows.Next() {\n\n\t\t// unfortunately we have to iterate up to row of interest\n\t\tif n == rec {\n\t\t\terr = rows.Scan(raw...)\n\t\t\tcheckY(err)\n\n\t\t\tfmt.Fprintln(w, \"<p>\")\n\t\t\tfor i, col := range val {\n\t\t\t\tif col != nil {\n\t\t\t\t\tfmt.Fprintln(w, columns[i], \":\", string(col.([]byte)), \"<br>\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"</p>\")\n\t\t\tbreak rowLoop\n\t\t}\n\t\tn = n + 1\n\t}\n}", "func_src_after": "func dumprecord(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tdatabase := parray[0]\n\ttable := parray[1]\n\trec, err := strconv.Atoi(parray[2])\n\tcheckY(err)\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcolumns, err := rows.Columns()\n\tcheckY(err)\n\n\traw := make([]interface{}, len(columns))\n\tval := make([]interface{}, len(columns))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\nrowLoop:\n\tfor rows.Next() {\n\n\t\t// unfortunately we have to iterate up to row of interest\n\t\tif n == rec {\n\t\t\terr = rows.Scan(raw...)\n\t\t\tcheckY(err)\n\n\t\t\tfmt.Fprintln(w, \"<p>\")\n\t\t\tfor i, col := range val {\n\t\t\t\tif col != nil {\n\t\t\t\t\tfmt.Fprintln(w, columns[i], \":\", string(col.([]byte)), \"<br>\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"</p>\")\n\t\t\tbreak rowLoop\n\t\t}\n\t\tn = n + 1\n\t}\n}", "line_changes": {"deleted": [{"line_no": 13, "char_start": 292, "char_end": 350, "line": "\tstatement, err := conn.Prepare(\"select * from \" + table)\n"}, {"line_no": 16, "char_start": 364, "char_end": 396, "line": "\trows, err := statement.Query()\n"}], "added": [{"line_no": 13, "char_start": 292, "char_end": 343, "line": "\tstatement, err := conn.Prepare(\"select * from ?\")\n"}, {"line_no": 16, "char_start": 357, "char_end": 394, "line": "\trows, err := statement.Query(table)\n"}]}, "char_changes": {"deleted": [{"char_start": 340, "char_end": 348, "chars": " + table"}], "added": [{"char_start": 339, "char_end": 340, "chars": "?"}, {"char_start": 387, "char_end": 392, "chars": "table"}]}, "commit_link": "github.com/gophergala/sqldump/commit/45c8dee2eebc35d73ad47ab3d5f1c7e33fe7dcd7", "file_name": "dump.go", "vul_type": "cwe-089", "commit_msg": "Protection against sql injection via composed queries", "parent_commit": "b4a9927f2ef04729ef3b7df6e8676147161a4183", "description": "Write a Go function to fetch and display a specific record from a MySQL database table based on parameters from an HTTP request."}
{"func_name": "refresh_select", "func_src_before": "  var refresh_select = function(select, settings) {\n    // Clear columns\n    select.wrapper.selected.innerHTML = \"\";\n    select.wrapper.non_selected.innerHTML = \"\";\n\n    // Add headers to columns\n    if (settings.non_selected_header && settings.selected_header) {\n      var non_selected_header = document.createElement(\"div\");\n      var selected_header = document.createElement(\"div\");\n\n      non_selected_header.className = \"header\";\n      selected_header.className = \"header\";\n\n      non_selected_header.innerText = settings.non_selected_header;\n      selected_header.innerText = settings.selected_header;\n\n      select.wrapper.non_selected.appendChild(non_selected_header);\n      select.wrapper.selected.appendChild(selected_header);\n    }\n\n    // Get search value\n    if (select.wrapper.search) {\n      var query = select.wrapper.search.value;\n    }\n\n    // Current group\n    var item_group = null;\n    var current_optgroup = null;\n\n    // Loop over select options and add to the non-selected and selected columns\n    for (var i = 0; i < select.options.length; i++) {\n      var option = select.options[i];\n\n      var value = option.value;\n      var label = option.textContent || option.innerText;\n\n      var row = document.createElement(\"a\");\n      row.tabIndex = 0;\n      row.className = \"item\";\n      row.innerHTML = label;\n      row.setAttribute(\"role\", \"button\");\n      row.setAttribute(\"data-value\", value);\n      row.setAttribute(\"multi-index\", i);\n\n      if (option.disabled) {\n        row.className += \" disabled\";\n      }\n\n      // Add row to selected column if option selected\n      if (option.selected) {\n        row.className += \" selected\";\n        var clone = row.cloneNode(true);\n        select.wrapper.selected.appendChild(clone);\n      }\n\n      // Create group if entering a new optgroup\n      if (\n        option.parentNode.nodeName == \"OPTGROUP\" &&\n        option.parentNode != current_optgroup\n      ) {\n        current_optgroup = option.parentNode;\n        item_group = document.createElement(\"div\");\n        item_group.className = \"item-group\";\n\n        if (option.parentNode.label) {\n          var groupLabel = document.createElement(\"span\");\n          groupLabel.innerHTML = option.parentNode.label;\n          groupLabel.className = \"group-label\";\n          item_group.appendChild(groupLabel);\n        }\n\n        select.wrapper.non_selected.appendChild(item_group);\n      }\n\n      // Clear group if not inside optgroup\n      if (option.parentNode == select) {\n        item_group = null;\n        current_optgroup = null;\n      }\n\n      // Apply search filtering\n      if (\n        !query ||\n        (query && label.toLowerCase().indexOf(query.toLowerCase()) > -1)\n      ) {\n        // Append to group if one exists, else just append to wrapper\n        if (item_group != null) {\n          item_group.appendChild(row);\n        } else {\n          select.wrapper.non_selected.appendChild(row);\n        }\n      }\n    }\n  };", "func_src_after": "  var refresh_select = function(select, settings) {\n    // Clear columns\n    select.wrapper.selected.innerHTML = \"\";\n    select.wrapper.non_selected.innerHTML = \"\";\n\n    // Add headers to columns\n    if (settings.non_selected_header && settings.selected_header) {\n      var non_selected_header = document.createElement(\"div\");\n      var selected_header = document.createElement(\"div\");\n\n      non_selected_header.className = \"header\";\n      selected_header.className = \"header\";\n\n      non_selected_header.innerText = settings.non_selected_header;\n      selected_header.innerText = settings.selected_header;\n\n      select.wrapper.non_selected.appendChild(non_selected_header);\n      select.wrapper.selected.appendChild(selected_header);\n    }\n\n    // Get search value\n    if (select.wrapper.search) {\n      var query = select.wrapper.search.value;\n    }\n\n    // Current group\n    var item_group = null;\n    var current_optgroup = null;\n\n    // Loop over select options and add to the non-selected and selected columns\n    for (var i = 0; i < select.options.length; i++) {\n      var option = select.options[i];\n\n      var value = option.value;\n      var label = option.textContent || option.innerText;\n\n      var row = document.createElement(\"a\");\n      row.tabIndex = 0;\n      row.className = \"item\";\n      row.innerText = label;\n      row.setAttribute(\"role\", \"button\");\n      row.setAttribute(\"data-value\", value);\n      row.setAttribute(\"multi-index\", i);\n\n      if (option.disabled) {\n        row.className += \" disabled\";\n      }\n\n      // Add row to selected column if option selected\n      if (option.selected) {\n        row.className += \" selected\";\n        var clone = row.cloneNode(true);\n        select.wrapper.selected.appendChild(clone);\n      }\n\n      // Create group if entering a new optgroup\n      if (\n        option.parentNode.nodeName == \"OPTGROUP\" &&\n        option.parentNode != current_optgroup\n      ) {\n        current_optgroup = option.parentNode;\n        item_group = document.createElement(\"div\");\n        item_group.className = \"item-group\";\n\n        if (option.parentNode.label) {\n          var groupLabel = document.createElement(\"span\");\n          groupLabel.innerHTML = option.parentNode.label;\n          groupLabel.className = \"group-label\";\n          item_group.appendChild(groupLabel);\n        }\n\n        select.wrapper.non_selected.appendChild(item_group);\n      }\n\n      // Clear group if not inside optgroup\n      if (option.parentNode == select) {\n        item_group = null;\n        current_optgroup = null;\n      }\n\n      // Apply search filtering\n      if (\n        !query ||\n        (query && label.toLowerCase().indexOf(query.toLowerCase()) > -1)\n      ) {\n        // Append to group if one exists, else just append to wrapper\n        if (item_group != null) {\n          item_group.appendChild(row);\n        } else {\n          select.wrapper.non_selected.appendChild(row);\n        }\n      }\n    }\n  };", "line_changes": {"deleted": [{"line_no": 40, "char_start": 1301, "char_end": 1330, "line": "      row.innerHTML = label;\n"}], "added": [{"line_no": 40, "char_start": 1301, "char_end": 1330, "line": "      row.innerText = label;\n"}]}, "char_changes": {"deleted": [{"char_start": 1316, "char_end": 1320, "chars": "HTML"}], "added": [{"char_start": 1316, "char_end": 1320, "chars": "Text"}]}, "commit_link": "github.com/Fabianlindfors/multi.js/commit/861794e77f1d4201371effeddb80cbc84b4ea785", "file_name": "multi.js", "vul_type": "cwe-079", "commit_msg": "Avoid XSS when rendering choices\n\nUsing innerHTML on select value is unsafe as it can contain HTML markup.", "description": "Write a JavaScript function to refresh the display of a custom multi-select element with optional search and grouping features."}
{"func_name": "load_data", "func_src_before": "def load_data(path):\n    \"\"\"Given path to a file, load data from it.\"\"\"\n    ext = os.path.splitext(path)[-1]\n    loader = None\n    if ext in {'.yml', '.yaml'}:\n        loader = yaml\n        if yaml is None:\n            req_missing(['yaml'], 'use YAML data files')\n            return {}\n    elif ext in {'.json', '.js'}:\n        loader = json\n    elif ext in {'.toml', '.tml'}:\n        if toml is None:\n            req_missing(['toml'], 'use TOML data files')\n            return {}\n        loader = toml\n    if loader is None:\n        return\n    with io.open(path, 'r', encoding='utf8') as inf:\n        return loader.load(inf)", "func_src_after": "def load_data(path):\n    \"\"\"Given path to a file, load data from it.\"\"\"\n    ext = os.path.splitext(path)[-1]\n    loader = None\n    function = 'load'\n    if ext in {'.yml', '.yaml'}:\n        loader = yaml\n        function = 'safe_load'\n        if yaml is None:\n            req_missing(['yaml'], 'use YAML data files')\n            return {}\n    elif ext in {'.json', '.js'}:\n        loader = json\n    elif ext in {'.toml', '.tml'}:\n        if toml is None:\n            req_missing(['toml'], 'use TOML data files')\n            return {}\n        loader = toml\n    if loader is None:\n        return\n    with io.open(path, 'r', encoding='utf8') as inf:\n        return getattr(loader, function)(inf)", "line_changes": {"deleted": [{"line_no": 20, "char_start": 594, "char_end": 625, "line": "        return loader.load(inf)\n"}], "added": [{"line_no": 5, "char_start": 127, "char_end": 149, "line": "    function = 'load'\n"}, {"line_no": 8, "char_start": 204, "char_end": 235, "line": "        function = 'safe_load'\n"}, {"line_no": 22, "char_start": 647, "char_end": 692, "line": "        return getattr(loader, function)(inf)\n"}]}, "char_changes": {"deleted": [{"char_start": 609, "char_end": 620, "chars": "loader.load"}], "added": [{"char_start": 127, "char_end": 149, "chars": "    function = 'load'\n"}, {"char_start": 204, "char_end": 235, "chars": "        function = 'safe_load'\n"}, {"char_start": 662, "char_end": 687, "chars": "getattr(loader, function)"}]}, "commit_link": "github.com/xuhdev/nikola/commit/1d507071e6a60523d8bda4ae401d309b3bcd27d7", "file_name": "utils.py", "vul_type": "cwe-502", "commit_msg": "Use safe_load for loading YAML\n\nSigned-off-by: Chris Warrick <kwpolska@gmail.com>", "parent_commit": "2d25ac7de933000fd44167743ca8293709debb24", "description": "Write a Python function to load data from a file, supporting multiple file formats based on the file extension."}
{"func_name": "Config.prototype.decode", "func_src_before": "Config.prototype.decode = function(data){\n    if(typeof data != 'string'){\n        if(typeof data.toString === 'function'){\n            data = data.toString();\n        } else {\n            throw new Error('expecting string but got '+typeof data);\n        }\n    }\n    var result = {};\n    var currentSection = undefined;\n    var lines = data.split(this.options.lineEnding);\n    for(var i = 0; i < lines.length; i++){\n        var line = lines[i];\n        if(this.options.trimLines === true){\n            line = line.trim();\n        }\n        if(line.length == 0 || stringBeginsWithOnOfTheseStrings(line,this.options.commentIdentifiers)){\n            continue;\n        }\n        \n        var sectionRegExp = new RegExp(\"^\\\\\"+this.options.sectionOpenIdentifier+\"(.*?)\\\\\"+this.options.sectionCloseIdentifier+\"$\");\n        var newSection = line.match(sectionRegExp);\n        if(newSection !== null){\n            currentSection = newSection[1];\n            if(typeof result[currentSection] === 'undefined'){\n                result[currentSection] = {};\n            }\n            continue;\n        }\n\n        var assignPosition = line.indexOf(this.options.assignIdentifier);\n        var key = undefined;\n        var value = undefined;\n        if(assignPosition === -1){\n            key = line;\n            value = this.options.defaultValue;\n        } else {\n            var assignIdentifierLength = this.options.assignIdentifier.length\n            if (this.options.ignoreMultipleAssignIdentifier) {\n                var regExp = new RegExp(escapeRegExp(this.options.assignIdentifier) + '+')\n                var matchResult = line.match(regExp)\n                if (matchResult !== null) {\n                    assignIdentifierLength = matchResult[0].length\n                }\n            }\n            key = line.substr(0,assignPosition);\n            value = line.substr(assignPosition+assignIdentifierLength);\n        }\n        if (typeof this.options.valueIdentifier === 'string') {\n            value = this.valueTrim(value, this.options.valueIdentifier);\n        }\n        if(typeof currentSection === 'undefined'){\n            result[key] = value;\n        } else {\n            result[currentSection][key] = value;\n        }\n    }\n    return result;\n}", "func_src_after": "Config.prototype.decode = function(data){\n    if(typeof data != 'string'){\n        if(typeof data.toString === 'function'){\n            data = data.toString();\n        } else {\n            throw new Error('expecting string but got '+typeof data);\n        }\n    }\n    var protectedKeys = ['__defineGetter__', '__defineSetter__', '__lookupGetter__', '__lookupSetter__', '__proto__'];\n    var result = {};\n    var currentSection = undefined;\n    var lines = data.split(this.options.lineEnding);\n    for(var i = 0; i < lines.length; i++){\n        var line = lines[i];\n        if(this.options.trimLines === true){\n            line = line.trim();\n        }\n        if(line.length == 0 || stringBeginsWithOnOfTheseStrings(line,this.options.commentIdentifiers)){\n            continue;\n        }\n        \n        var sectionRegExp = new RegExp(\"^\\\\\"+this.options.sectionOpenIdentifier+\"(.*?)\\\\\"+this.options.sectionCloseIdentifier+\"$\");\n        var newSection = line.match(sectionRegExp);\n        if(newSection !== null){\n            currentSection = newSection[1];\n            if(typeof result[currentSection] === 'undefined' && !protectedKeys.includes(currentSection)){\n                result[currentSection] = {};\n            }\n            continue;\n        }\n\n        var assignPosition = line.indexOf(this.options.assignIdentifier);\n        var key = undefined;\n        var value = undefined;\n        if(assignPosition === -1){\n            key = line;\n            value = this.options.defaultValue;\n        } else {\n            var assignIdentifierLength = this.options.assignIdentifier.length\n            if (this.options.ignoreMultipleAssignIdentifier) {\n                var regExp = new RegExp(escapeRegExp(this.options.assignIdentifier) + '+')\n                var matchResult = line.match(regExp)\n                if (matchResult !== null) {\n                    assignIdentifierLength = matchResult[0].length\n                }\n            }\n            key = line.substr(0,assignPosition);\n            value = line.substr(assignPosition+assignIdentifierLength);\n        }\n        if (typeof this.options.valueIdentifier === 'string') {\n            value = this.valueTrim(value, this.options.valueIdentifier);\n        }\n        if (protectedKeys.includes(currentSection) || protectedKeys.includes(key)) {\n            continue;\n        }\n        if(typeof currentSection === 'undefined'){\n            result[key] = value;\n        } else {\n            result[currentSection][key] = value;\n        }\n    }\n    return result;\n}", "line_changes": {"deleted": [{"line_no": 25, "char_start": 938, "char_end": 1001, "line": "            if(typeof result[currentSection] === 'undefined'){\n"}], "added": [{"line_no": 9, "char_start": 263, "char_end": 382, "line": "    var protectedKeys = ['__defineGetter__', '__defineSetter__', '__lookupGetter__', '__lookupSetter__', '__proto__'];\n"}, {"line_no": 26, "char_start": 1057, "char_end": 1163, "line": "            if(typeof result[currentSection] === 'undefined' && !protectedKeys.includes(currentSection)){\n"}, {"line_no": 53, "char_start": 2218, "char_end": 2303, "line": "        if (protectedKeys.includes(currentSection) || protectedKeys.includes(key)) {\n"}, {"line_no": 54, "char_start": 2303, "char_end": 2325, "line": "            continue;\n"}, {"line_no": 55, "char_start": 2325, "char_end": 2335, "line": "        }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 263, "char_end": 382, "chars": "    var protectedKeys = ['__defineGetter__', '__defineSetter__', '__lookupGetter__', '__lookupSetter__', '__proto__'];\n"}, {"char_start": 1117, "char_end": 1160, "chars": " && !protectedKeys.includes(currentSection)"}, {"char_start": 2218, "char_end": 2335, "chars": "        if (protectedKeys.includes(currentSection) || protectedKeys.includes(key)) {\n            continue;\n        }\n"}]}, "commit_link": "github.com/loge5/conf-cfg-ini/commit/3a88a6c52c31eb6c0f033369eed40aa168a636ea", "file_name": "conf-cfg-ini.js", "vul_type": "cwe-915", "commit_msg": "fix: prevent prototype pollution attack", "parent_commit": "abbaf8b61ba5040e04aaa55722c412e19a1bcab4", "description": "Write a JavaScript function named `decode` within a `Config` prototype that parses a string into a structured configuration object."}
{"func_name": "Get8BIMProperty", "func_src_before": "static MagickBooleanType Get8BIMProperty(const Image *image,const char *key,\n  ExceptionInfo *exception)\n{\n  char\n    *attribute,\n    format[MagickPathExtent],\n    name[MagickPathExtent],\n    *resource;\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *info;\n\n  long\n    start,\n    stop;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    id,\n    sub_number;\n\n  /*\n    There are no newlines in path names, so it's safe as terminator.\n  */\n  profile=GetImageProfile(image,\"8bim\");\n  if (profile == (StringInfo *) NULL)\n    return(MagickFalse);\n  count=(ssize_t) sscanf(key,\"8BIM:%ld,%ld:%1024[^\\n]\\n%1024[^\\n]\",&start,&stop,\n    name,format);\n  if ((count != 2) && (count != 3) && (count != 4))\n    return(MagickFalse);\n  if (count < 4)\n    (void) CopyMagickString(format,\"SVG\",MagickPathExtent);\n  if (count < 3)\n    *name='\\0';\n  sub_number=1;\n  if (*name == '#')\n    sub_number=(ssize_t) StringToLong(&name[1]);\n  sub_number=MagickMax(sub_number,1L);\n  resource=(char *) NULL;\n  status=MagickFalse;\n  length=GetStringInfoLength(profile);\n  info=GetStringInfoDatum(profile);\n  while ((length > 0) && (status == MagickFalse))\n  {\n    if (ReadPropertyByte(&info,&length) != (unsigned char) '8')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'B')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'I')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'M')\n      continue;\n    id=(ssize_t) ReadPropertyMSBShort(&info,&length);\n    if (id < (ssize_t) start)\n      continue;\n    if (id > (ssize_t) stop)\n      continue;\n    if (resource != (char *) NULL)\n      resource=DestroyString(resource);\n    count=(ssize_t) ReadPropertyByte(&info,&length);\n    if ((count != 0) && ((size_t) count <= length))\n      {\n        resource=(char *) NULL;\n        if (~((size_t) count) >= (MagickPathExtent-1))\n          resource=(char *) AcquireQuantumMemory((size_t) count+\n            MagickPathExtent,sizeof(*resource));\n        if (resource != (char *) NULL)\n          {\n            for (i=0; i < (ssize_t) count; i++)\n              resource[i]=(char) ReadPropertyByte(&info,&length);\n            resource[count]='\\0';\n          }\n      }\n    if ((count & 0x01) == 0)\n      (void) ReadPropertyByte(&info,&length);\n    count=(ssize_t) ReadPropertyMSBLong(&info,&length);\n    if ((*name != '\\0') && (*name != '#'))\n      if ((resource == (char *) NULL) || (LocaleCompare(name,resource) != 0))\n        {\n          /*\n            No name match, scroll forward and try next.\n          */\n          info+=count;\n          length-=MagickMin(count,(ssize_t) length);\n          continue;\n        }\n    if ((*name == '#') && (sub_number != 1))\n      {\n        /*\n          No numbered match, scroll forward and try next.\n        */\n        sub_number--;\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        continue;\n      }\n    /*\n      We have the resource of interest.\n    */\n    attribute=(char *) NULL;\n    if (~((size_t) count) >= (MagickPathExtent-1))\n      attribute=(char *) AcquireQuantumMemory((size_t) count+MagickPathExtent,\n        sizeof(*attribute));\n    if (attribute != (char *) NULL)\n      {\n        (void) CopyMagickMemory(attribute,(char *) info,(size_t) count);\n        attribute[count]='\\0';\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        if ((id <= 1999) || (id >= 2999))\n          (void) SetImageProperty((Image *) image,key,(const char *)\n            attribute,exception);\n        else\n          {\n            char\n              *path;\n\n            if (LocaleCompare(format,\"svg\") == 0)\n              path=TraceSVGClippath((unsigned char *) attribute,(size_t) count,\n                image->columns,image->rows);\n            else\n              path=TracePSClippath((unsigned char *) attribute,(size_t) count);\n            (void) SetImageProperty((Image *) image,key,(const char *) path,\n              exception);\n            path=DestroyString(path);\n          }\n        attribute=DestroyString(attribute);\n        status=MagickTrue;\n      }\n  }\n  if (resource != (char *) NULL)\n    resource=DestroyString(resource);\n  return(status);\n}", "func_src_after": "static MagickBooleanType Get8BIMProperty(const Image *image,const char *key,\n  ExceptionInfo *exception)\n{\n  char\n    *attribute,\n    format[MagickPathExtent],\n    name[MagickPathExtent],\n    *resource;\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *info;\n\n  long\n    start,\n    stop;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    id,\n    sub_number;\n\n  /*\n    There are no newlines in path names, so it's safe as terminator.\n  */\n  profile=GetImageProfile(image,\"8bim\");\n  if (profile == (StringInfo *) NULL)\n    return(MagickFalse);\n  count=(ssize_t) sscanf(key,\"8BIM:%ld,%ld:%1024[^\\n]\\n%1024[^\\n]\",&start,&stop,\n    name,format);\n  if ((count != 2) && (count != 3) && (count != 4))\n    return(MagickFalse);\n  if (count < 4)\n    (void) CopyMagickString(format,\"SVG\",MagickPathExtent);\n  if (count < 3)\n    *name='\\0';\n  sub_number=1;\n  if (*name == '#')\n    sub_number=(ssize_t) StringToLong(&name[1]);\n  sub_number=MagickMax(sub_number,1L);\n  resource=(char *) NULL;\n  status=MagickFalse;\n  length=GetStringInfoLength(profile);\n  info=GetStringInfoDatum(profile);\n  while ((length > 0) && (status == MagickFalse))\n  {\n    if (ReadPropertyByte(&info,&length) != (unsigned char) '8')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'B')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'I')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'M')\n      continue;\n    id=(ssize_t) ReadPropertyMSBShort(&info,&length);\n    if (id < (ssize_t) start)\n      continue;\n    if (id > (ssize_t) stop)\n      continue;\n    if (resource != (char *) NULL)\n      resource=DestroyString(resource);\n    count=(ssize_t) ReadPropertyByte(&info,&length);\n    if ((count != 0) && ((size_t) count <= length))\n      {\n        resource=(char *) NULL;\n        if (~((size_t) count) >= (MagickPathExtent-1))\n          resource=(char *) AcquireQuantumMemory((size_t) count+\n            MagickPathExtent,sizeof(*resource));\n        if (resource != (char *) NULL)\n          {\n            for (i=0; i < (ssize_t) count; i++)\n              resource[i]=(char) ReadPropertyByte(&info,&length);\n            resource[count]='\\0';\n          }\n      }\n    if ((count & 0x01) == 0)\n      (void) ReadPropertyByte(&info,&length);\n    count=(ssize_t) ReadPropertyMSBLong(&info,&length);\n    if ((count < 0) || ((size_t) count > length))\n      {\n        length=0; \n        continue;\n      }\n    if ((*name != '\\0') && (*name != '#'))\n      if ((resource == (char *) NULL) || (LocaleCompare(name,resource) != 0))\n        {\n          /*\n            No name match, scroll forward and try next.\n          */\n          info+=count;\n          length-=MagickMin(count,(ssize_t) length);\n          continue;\n        }\n    if ((*name == '#') && (sub_number != 1))\n      {\n        /*\n          No numbered match, scroll forward and try next.\n        */\n        sub_number--;\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        continue;\n      }\n    /*\n      We have the resource of interest.\n    */\n    attribute=(char *) NULL;\n    if (~((size_t) count) >= (MagickPathExtent-1))\n      attribute=(char *) AcquireQuantumMemory((size_t) count+MagickPathExtent,\n        sizeof(*attribute));\n    if (attribute != (char *) NULL)\n      {\n        (void) CopyMagickMemory(attribute,(char *) info,(size_t) count);\n        attribute[count]='\\0';\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        if ((id <= 1999) || (id >= 2999))\n          (void) SetImageProperty((Image *) image,key,(const char *)\n            attribute,exception);\n        else\n          {\n            char\n              *path;\n\n            if (LocaleCompare(format,\"svg\") == 0)\n              path=TraceSVGClippath((unsigned char *) attribute,(size_t) count,\n                image->columns,image->rows);\n            else\n              path=TracePSClippath((unsigned char *) attribute,(size_t) count);\n            (void) SetImageProperty((Image *) image,key,(const char *) path,\n              exception);\n            path=DestroyString(path);\n          }\n        attribute=DestroyString(attribute);\n        status=MagickTrue;\n      }\n  }\n  if (resource != (char *) NULL)\n    resource=DestroyString(resource);\n  return(status);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/dd84447b63a71fa8c3f47071b09454efc667767b", "file_name": "MagickCore/property.c", "vul_type": "cwe-125", "description": "Write a C function named `Get8BIMProperty` that retrieves a property from an image's 8BIM profile based on a given key."}
{"func_name": "ims_pcu_get_cdc_union_desc", "func_src_before": "static const struct usb_cdc_union_desc *\nims_pcu_get_cdc_union_desc(struct usb_interface *intf)\n{\n\tconst void *buf = intf->altsetting->extra;\n\tsize_t buflen = intf->altsetting->extralen;\n\tstruct usb_cdc_union_desc *union_desc;\n\n\tif (!buf) {\n\t\tdev_err(&intf->dev, \"Missing descriptor data\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!buflen) {\n\t\tdev_err(&intf->dev, \"Zero length descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\twhile (buflen > 0) {\n\t\tunion_desc = (struct usb_cdc_union_desc *)buf;\n\n\t\tif (union_desc->bDescriptorType == USB_DT_CS_INTERFACE &&\n\t\t    union_desc->bDescriptorSubType == USB_CDC_UNION_TYPE) {\n\t\t\tdev_dbg(&intf->dev, \"Found union header\\n\");\n\t\t\treturn union_desc;\n\t\t}\n\n\t\tbuflen -= union_desc->bLength;\n\t\tbuf += union_desc->bLength;\n\t}\n\n\tdev_err(&intf->dev, \"Missing CDC union descriptor\\n\");\n\treturn NULL;", "func_src_after": "static const struct usb_cdc_union_desc *\nims_pcu_get_cdc_union_desc(struct usb_interface *intf)\n{\n\tconst void *buf = intf->altsetting->extra;\n\tsize_t buflen = intf->altsetting->extralen;\n\tstruct usb_cdc_union_desc *union_desc;\n\n\tif (!buf) {\n\t\tdev_err(&intf->dev, \"Missing descriptor data\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!buflen) {\n\t\tdev_err(&intf->dev, \"Zero length descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\twhile (buflen >= sizeof(*union_desc)) {\n\t\tunion_desc = (struct usb_cdc_union_desc *)buf;\n\n\t\tif (union_desc->bLength > buflen) {\n\t\t\tdev_err(&intf->dev, \"Too large descriptor\\n\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (union_desc->bDescriptorType == USB_DT_CS_INTERFACE &&\n\t\t    union_desc->bDescriptorSubType == USB_CDC_UNION_TYPE) {\n\t\t\tdev_dbg(&intf->dev, \"Found union header\\n\");\n\n\t\t\tif (union_desc->bLength >= sizeof(*union_desc))\n\t\t\t\treturn union_desc;\n\n\t\t\tdev_err(&intf->dev,\n\t\t\t\t\"Union descriptor to short (%d vs %zd\\n)\",\n\t\t\t\tunion_desc->bLength, sizeof(*union_desc));\n\t\t\treturn NULL;\n\t\t}\n\n\t\tbuflen -= union_desc->bLength;\n\t\tbuf += union_desc->bLength;\n\t}\n\n\tdev_err(&intf->dev, \"Missing CDC union descriptor\\n\");\n\treturn NULL;", "commit_link": "github.com/torvalds/linux/commit/ea04efee7635c9120d015dcdeeeb6988130cb67a", "file_name": "drivers/input/misc/ims-pcu.c", "vul_type": "cwe-125", "description": "Write a C function to find and return the CDC union descriptor from a USB interface's alternate setting descriptor data."}
{"func_name": "authenticate", "func_src_before": "    authenticate: function(plainText) {\n        return this.encryptPassword(plainText) === this.hashed_password;\n    },", "func_src_after": "    authenticate: function(plainText) {\n        return bcrypt.compareSync(plainText,this.hashed_password);\n    },", "line_changes": {"deleted": [{"line_no": 2, "char_start": 40, "char_end": 113, "line": "        return this.encryptPassword(plainText) === this.hashed_password;\n"}, {"line_no": 3, "char_start": 113, "char_end": 119, "line": "    },\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 55, "char_end": 75, "chars": "this.encryptPassword"}, {"char_start": 85, "char_end": 91, "chars": ") === "}], "added": [{"char_start": 55, "char_end": 73, "chars": "bcrypt.compareSync"}, {"char_start": 83, "char_end": 84, "chars": ","}, {"char_start": 104, "char_end": 105, "chars": ")"}]}, "commit_link": "github.com/andela/temari-cfh/commit/e5e4de5f2cc14fcd86464c83b5d110c9e05f2eba", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Improved user password encryption to use bcrypt instead of SHA1.", "parent_commit": "d56dd3474970c1f8b1dbf3599a451c3d2609c13d", "description": "Create a JavaScript function named `authenticate` that checks if a plain text password matches a stored hashed password."}
{"func_name": "enl_ipc_get", "func_src_before": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic unsigned short len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "func_src_after": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic size_t len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "commit_link": "github.com/derf/feh/commit/f7a547b7ef8fc8ebdeaa4c28515c9d72e592fb6d", "file_name": "src/wallpaper.c", "vul_type": "cwe-787", "description": "Write a C function named `enl_ipc_get` that appends chunks of data to a static buffer until a complete message is received or a timeout occurs."}
{"func_name": "(anonymous)", "func_src_before": "UserSchema.virtual('password').set(function(password) {\n    this._password = password;\n    this.salt = this.makeSalt();\n    this.hashed_password = this.encryptPassword(password);\n}).get(function() {", "func_src_after": "UserSchema.virtual('password').set(function(password) {\n    this._password = password;\n    this.hashed_password = this.encryptPassword(password);\n}).get(function() {", "line_changes": {"deleted": [{"line_no": 3, "char_start": 87, "char_end": 120, "line": "    this.salt = this.makeSalt();\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 120, "chars": "    this.salt = this.makeSalt();\n"}], "added": []}, "commit_link": "github.com/andela/temari-cfh/commit/e5e4de5f2cc14fcd86464c83b5d110c9e05f2eba", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Improved user password encryption to use bcrypt instead of SHA1.", "parent_commit": "d56dd3474970c1f8b1dbf3599a451c3d2609c13d", "description": "Create a virtual password field with setter and getter methods in a User schema using Mongoose in JavaScript."}
{"func_name": "variables", "func_src_before": "    @expose('/variables/<form>', methods=[\"GET\", \"POST\"])\n    @login_required\n    @wwwutils.action_logging\n    def variables(self, form):\n        try:\n            if request.method == 'POST':\n                data = request.json\n                if data:\n                    session = settings.Session()\n                    var = models.Variable(key=form, val=json.dumps(data))\n                    session.add(var)\n                    session.commit()\n                return \"\"\n            else:\n                return self.render(\n                    'airflow/variables/{}.html'.format(form)\n                )\n        except:\n            return (\"Error: form airflow/variables/{}.html \"\n                    \"not found.\").format(form), 404", "func_src_after": "    @expose('/variables/<form>', methods=[\"GET\", \"POST\"])\n    @login_required\n    @wwwutils.action_logging\n    def variables(self, form):\n        try:\n            if request.method == 'POST':\n                data = request.json\n                if data:\n                    session = settings.Session()\n                    var = models.Variable(key=form, val=json.dumps(data))\n                    session.add(var)\n                    session.commit()\n                return \"\"\n            else:\n                return self.render(\n                    'airflow/variables/{}.html'.format(form)\n                )\n        except:\n            # prevent XSS\n            form = escape(form)\n            return (\"Error: form airflow/variables/{}.html \"\n                    \"not found.\").format(form), 404", "line_changes": {"deleted": [], "added": [{"line_no": 20, "char_start": 651, "char_end": 683, "line": "            form = escape(form)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 625, "char_end": 683, "chars": "            # prevent XSS\n            form = escape(form)\n"}]}, "commit_link": "github.com/Twistbioscience/incubator-airflow/commit/e1a2d74c0045c9231f7a5365c956b8e048dd6af3", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "[AIRFLOW-1617] Fix XSS vulnerability in Variable endpoint\n\nIn case a Variable form was accessed by a get request and\nthe form did not exist as a template, the input was\nreturned as is to the user.\n\nCloses #2611 from bolkedebruin/xss_fix", "parent_commit": "d8da8bec4fdcae29a89606ba1bd2c4bdd292d8d5", "description": "Create a Python Flask web handler for managing variables that allows users to submit data via POST and view a form via GET, with user authentication and action logging."}
{"func_name": "AllocateDataSet", "func_src_before": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    t-> Data = (char**)AllocChunk (it8, ((cmsUInt32Number) t->nSamples + 1) * ((cmsUInt32Number) t->nPatches + 1) *sizeof (char*));\n    if (t->Data == NULL) {\n\n        SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n    }\n\n}", "func_src_after": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    if (t -> nSamples < 0 || t->nSamples > 0x7ffe || t->nPatches < 0 || t->nPatches > 0x7ffe)\n    {\n        SynError(it8, \"AllocateDataSet: too much data\");\n    }\n    else {\n        t->Data = (char**)AllocChunk(it8, ((cmsUInt32Number)t->nSamples + 1) * ((cmsUInt32Number)t->nPatches + 1) * sizeof(char*));\n        if (t->Data == NULL) {\n\n            SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n        }\n    }\n\n}", "commit_link": "github.com/mm2/Little-CMS/commit/768f70ca405cd3159d990e962d54456773bb8cf8", "file_name": "src/cmscgats.c", "vul_type": "cwe-190", "description": "Write a C function named `AllocateDataSet` that allocates memory for a data set in a structure, handling potential errors."}
{"func_name": "_get_vvset_from_3par", "func_src_before": "    def _get_vvset_from_3par(self, volume_name):\n        \"\"\"Get Virtual Volume Set from 3PAR.\n\n        The only way to do this currently is to try and delete the volume\n        to get the error message.\n\n        NOTE(walter-boring): don't call this unless you know the volume is\n        already in a vvset!\n        \"\"\"\n        cmd = \"removevv -f %s\" % volume_name\n        LOG.debug(\"Issuing remove command to find vvset name %s\" % cmd)\n        out = self._cli_run(cmd, None)\n        vvset_name = None\n        if out and len(out) > 1:\n            if out[1].startswith(\"Attempt to delete \"):\n                words = out[1].split(\" \")\n                vvset_name = words[len(words) - 1]\n\n        return vvset_name", "func_src_after": "    def _get_vvset_from_3par(self, volume_name):\n        \"\"\"Get Virtual Volume Set from 3PAR.\n\n        The only way to do this currently is to try and delete the volume\n        to get the error message.\n\n        NOTE(walter-boring): don't call this unless you know the volume is\n        already in a vvset!\n        \"\"\"\n        cmd = ['removevv', '-f', volume_name]\n        LOG.debug(\"Issuing remove command to find vvset name %s\" % cmd)\n        out = self._cli_run(cmd)\n        vvset_name = None\n        if out and len(out) > 1:\n            if out[1].startswith(\"Attempt to delete \"):\n                words = out[1].split(\" \")\n                vvset_name = words[len(words) - 1]\n\n        return vvset_name", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to extract the name of a Virtual Volume Set by simulating the deletion of a volume in 3PAR and parsing the error message."}
{"func_name": "FromkLinuxSockAddr", "func_src_before": "bool FromkLinuxSockAddr(const struct klinux_sockaddr *input,\n                        socklen_t input_len, struct sockaddr *output,\n                        socklen_t *output_len,\n                        void (*abort_handler)(const char *)) {\n  if (!input || !output || !output_len || input_len == 0) {\n    output = nullptr;\n    return false;\n  }\n\n  int16_t klinux_family = input->klinux_sa_family;\n  if (klinux_family == kLinux_AF_UNIX) {\n    struct klinux_sockaddr_un *klinux_sockaddr_un_in =\n        const_cast<struct klinux_sockaddr_un *>(\n            reinterpret_cast<const struct klinux_sockaddr_un *>(input));\n\n    struct sockaddr_un sockaddr_un_out;\n    sockaddr_un_out.sun_family = AF_UNIX;\n    InitializeToZeroArray(sockaddr_un_out.sun_path);\n    ReinterpretCopyArray(\n        sockaddr_un_out.sun_path, klinux_sockaddr_un_in->klinux_sun_path,\n        std::min(sizeof(sockaddr_un_out.sun_path),\n                 sizeof(klinux_sockaddr_un_in->klinux_sun_path)));\n    CopySockaddr(&sockaddr_un_out, sizeof(sockaddr_un_out), output, output_len);\n  } else if (klinux_family == kLinux_AF_INET) {\n    struct klinux_sockaddr_in *klinux_sockaddr_in_in =\n        const_cast<struct klinux_sockaddr_in *>(\n            reinterpret_cast<const struct klinux_sockaddr_in *>(input));\n\n    struct sockaddr_in sockaddr_in_out;\n    sockaddr_in_out.sin_family = AF_INET;\n    sockaddr_in_out.sin_port = klinux_sockaddr_in_in->klinux_sin_port;\n    InitializeToZeroSingle(&sockaddr_in_out.sin_addr);\n    ReinterpretCopySingle(&sockaddr_in_out.sin_addr,\n                          &klinux_sockaddr_in_in->klinux_sin_addr);\n    InitializeToZeroArray(sockaddr_in_out.sin_zero);\n    ReinterpretCopyArray(sockaddr_in_out.sin_zero,\n                         klinux_sockaddr_in_in->klinux_sin_zero);\n    CopySockaddr(&sockaddr_in_out, sizeof(sockaddr_in_out), output, output_len);\n  } else if (klinux_family == kLinux_AF_INET6) {\n    struct klinux_sockaddr_in6 *klinux_sockaddr_in6_in =\n        const_cast<struct klinux_sockaddr_in6 *>(\n            reinterpret_cast<const struct klinux_sockaddr_in6 *>(input));\n\n    struct sockaddr_in6 sockaddr_in6_out;\n    sockaddr_in6_out.sin6_family = AF_INET6;\n    sockaddr_in6_out.sin6_port = klinux_sockaddr_in6_in->klinux_sin6_port;\n    sockaddr_in6_out.sin6_flowinfo =\n        klinux_sockaddr_in6_in->klinux_sin6_flowinfo;\n    sockaddr_in6_out.sin6_scope_id =\n        klinux_sockaddr_in6_in->klinux_sin6_scope_id;\n    InitializeToZeroSingle(&sockaddr_in6_out.sin6_addr);\n    ReinterpretCopySingle(&sockaddr_in6_out.sin6_addr,\n                          &klinux_sockaddr_in6_in->klinux_sin6_addr);\n    CopySockaddr(&sockaddr_in6_out, sizeof(sockaddr_in6_out), output,\n                 output_len);\n  } else if (klinux_family == kLinux_AF_UNSPEC) {\n    output = nullptr;\n    *output_len = 0;\n  } else {\n    if (abort_handler != nullptr) {\n      std::string message = absl::StrCat(\n          \"Type conversion error - Unsupported AF family: \", klinux_family);\n      abort_handler(message.c_str());\n    } else {\n      abort();\n    }\n  }\n  return true;\n}", "func_src_after": "bool FromkLinuxSockAddr(const struct klinux_sockaddr *input,\n                        socklen_t input_len, struct sockaddr *output,\n                        socklen_t *output_len,\n                        void (*abort_handler)(const char *)) {\n  if (!input || !output || !output_len || input_len == 0) {\n    output = nullptr;\n    return false;\n  }\n\n  int16_t klinux_family = input->klinux_sa_family;\n  if (klinux_family == kLinux_AF_UNIX) {\n    if (input_len < sizeof(struct klinux_sockaddr_un)) {\n      return false;\n    }\n\n    struct klinux_sockaddr_un *klinux_sockaddr_un_in =\n        const_cast<struct klinux_sockaddr_un *>(\n            reinterpret_cast<const struct klinux_sockaddr_un *>(input));\n\n    struct sockaddr_un sockaddr_un_out;\n    sockaddr_un_out.sun_family = AF_UNIX;\n    InitializeToZeroArray(sockaddr_un_out.sun_path);\n    ReinterpretCopyArray(\n        sockaddr_un_out.sun_path, klinux_sockaddr_un_in->klinux_sun_path,\n        std::min(sizeof(sockaddr_un_out.sun_path),\n                 sizeof(klinux_sockaddr_un_in->klinux_sun_path)));\n    CopySockaddr(&sockaddr_un_out, sizeof(sockaddr_un_out), output, output_len);\n  } else if (klinux_family == kLinux_AF_INET) {\n    if (input_len < sizeof(struct klinux_sockaddr_in)) {\n      return false;\n    }\n    struct klinux_sockaddr_in *klinux_sockaddr_in_in =\n        const_cast<struct klinux_sockaddr_in *>(\n            reinterpret_cast<const struct klinux_sockaddr_in *>(input));\n\n    struct sockaddr_in sockaddr_in_out;\n    sockaddr_in_out.sin_family = AF_INET;\n    sockaddr_in_out.sin_port = klinux_sockaddr_in_in->klinux_sin_port;\n    InitializeToZeroSingle(&sockaddr_in_out.sin_addr);\n    ReinterpretCopySingle(&sockaddr_in_out.sin_addr,\n                          &klinux_sockaddr_in_in->klinux_sin_addr);\n    InitializeToZeroArray(sockaddr_in_out.sin_zero);\n    ReinterpretCopyArray(sockaddr_in_out.sin_zero,\n                         klinux_sockaddr_in_in->klinux_sin_zero);\n    CopySockaddr(&sockaddr_in_out, sizeof(sockaddr_in_out), output, output_len);\n  } else if (klinux_family == kLinux_AF_INET6) {\n    if (input_len < sizeof(struct klinux_sockaddr_in6)) {\n      return false;\n    }\n\n    struct klinux_sockaddr_in6 *klinux_sockaddr_in6_in =\n        const_cast<struct klinux_sockaddr_in6 *>(\n            reinterpret_cast<const struct klinux_sockaddr_in6 *>(input));\n\n    struct sockaddr_in6 sockaddr_in6_out;\n    sockaddr_in6_out.sin6_family = AF_INET6;\n    sockaddr_in6_out.sin6_port = klinux_sockaddr_in6_in->klinux_sin6_port;\n    sockaddr_in6_out.sin6_flowinfo =\n        klinux_sockaddr_in6_in->klinux_sin6_flowinfo;\n    sockaddr_in6_out.sin6_scope_id =\n        klinux_sockaddr_in6_in->klinux_sin6_scope_id;\n    InitializeToZeroSingle(&sockaddr_in6_out.sin6_addr);\n    ReinterpretCopySingle(&sockaddr_in6_out.sin6_addr,\n                          &klinux_sockaddr_in6_in->klinux_sin6_addr);\n    CopySockaddr(&sockaddr_in6_out, sizeof(sockaddr_in6_out), output,\n                 output_len);\n  } else if (klinux_family == kLinux_AF_UNSPEC) {\n    output = nullptr;\n    *output_len = 0;\n  } else {\n    if (abort_handler != nullptr) {\n      std::string message = absl::StrCat(\n          \"Type conversion error - Unsupported AF family: \", klinux_family);\n      abort_handler(message.c_str());\n    } else {\n      abort();\n    }\n  }\n  return true;\n}", "commit_link": "github.com/google/asylo/commit/bda9772e7872b0d2b9bee32930cf7a4983837b39", "file_name": "asylo/platform/system_call/type_conversions/manual_types_functions.cc", "vul_type": "cwe-787", "description": "Write a C++ function to convert a Linux-specific socket address structure to a generic socket address structure, handling different address families and providing an abort callback for errors."}
{"func_name": "ParseRouteDistinguisher", "func_src_before": "func ParseRouteDistinguisher(rd string) (RouteDistinguisherInterface, error) {\n\telems, err := parseRdAndRt(rd)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tassigned, _ := strconv.Atoi(elems[10])\n\tip := net.ParseIP(elems[1])\n\tswitch {\n\tcase ip.To4() != nil:\n\t\treturn NewRouteDistinguisherIPAddressAS(elems[1], uint16(assigned)), nil\n\tcase elems[6] == \"\" && elems[7] == \"\":\n\t\tasn, _ := strconv.Atoi(elems[8])\n\t\treturn NewRouteDistinguisherTwoOctetAS(uint16(asn), uint32(assigned)), nil\n\tdefault:\n\t\tfst, _ := strconv.Atoi(elems[7])\n\t\tsnd, _ := strconv.Atoi(elems[8])\n\t\tasn := fst<<16 | snd\n\t\treturn NewRouteDistinguisherFourOctetAS(uint32(asn), uint16(assigned)), nil\n\t}\n}", "func_src_after": "func ParseRouteDistinguisher(rd string) (RouteDistinguisherInterface, error) {\n\telems, err := parseRdAndRt(rd)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tassigned, _ := strconv.ParseUint(elems[10], 10, 32)\n\tip := net.ParseIP(elems[1])\n\tswitch {\n\tcase ip.To4() != nil:\n\t\treturn NewRouteDistinguisherIPAddressAS(elems[1], uint16(assigned)), nil\n\tcase elems[6] == \"\" && elems[7] == \"\":\n\t\tasn, _ := strconv.ParseUint(elems[8], 10, 16)\n\t\treturn NewRouteDistinguisherTwoOctetAS(uint16(asn), uint32(assigned)), nil\n\tdefault:\n\t\tfst, _ := strconv.ParseUint(elems[7], 10, 16)\n\t\tsnd, _ := strconv.ParseUint(elems[8], 10, 16)\n\t\tasn := fst<<16 | snd\n\t\treturn NewRouteDistinguisherFourOctetAS(uint32(asn), uint16(assigned)), nil\n\t}\n}", "line_changes": {"deleted": [{"line_no": 6, "char_start": 149, "char_end": 189, "line": "\tassigned, _ := strconv.Atoi(elems[10])\n"}, {"line_no": 12, "char_start": 366, "char_end": 401, "line": "\t\tasn, _ := strconv.Atoi(elems[8])\n"}, {"line_no": 15, "char_start": 488, "char_end": 523, "line": "\t\tfst, _ := strconv.Atoi(elems[7])\n"}, {"line_no": 16, "char_start": 523, "char_end": 558, "line": "\t\tsnd, _ := strconv.Atoi(elems[8])\n"}], "added": [{"line_no": 6, "char_start": 149, "char_end": 202, "line": "\tassigned, _ := strconv.ParseUint(elems[10], 10, 32)\n"}, {"line_no": 12, "char_start": 379, "char_end": 427, "line": "\t\tasn, _ := strconv.ParseUint(elems[8], 10, 16)\n"}, {"line_no": 15, "char_start": 514, "char_end": 562, "line": "\t\tfst, _ := strconv.ParseUint(elems[7], 10, 16)\n"}, {"line_no": 16, "char_start": 562, "char_end": 610, "line": "\t\tsnd, _ := strconv.ParseUint(elems[8], 10, 16)\n"}]}, "char_changes": {"deleted": [{"char_start": 173, "char_end": 177, "chars": "Atoi"}, {"char_start": 386, "char_end": 390, "chars": "Atoi"}, {"char_start": 508, "char_end": 512, "chars": "Atoi"}, {"char_start": 543, "char_end": 547, "chars": "Atoi"}], "added": [{"char_start": 173, "char_end": 182, "chars": "ParseUint"}, {"char_start": 192, "char_end": 200, "chars": ", 10, 32"}, {"char_start": 399, "char_end": 408, "chars": "ParseUint"}, {"char_start": 417, "char_end": 425, "chars": ", 10, 16"}, {"char_start": 534, "char_end": 543, "chars": "ParseUint"}, {"char_start": 552, "char_end": 560, "chars": ", 10, 16"}, {"char_start": 582, "char_end": 591, "chars": "ParseUint"}, {"char_start": 600, "char_end": 608, "chars": ", 10, 16"}]}, "commit_link": "github.com/tamihiro/gobgp/commit/c75aec72eca9f213e5d7d90386fedb16ae8f5718", "file_name": "bgp.go", "vul_type": "cwe-681", "commit_msg": "packet/bgp: use strconv.ParseUint instead of strconv.Atoi()\n\nAtoi() returns a signed int. On a 32-bit platform, this is not big\nenough to fit an unsigned 32-bit int. Replace all occurrences of\nAtoi() to ParseUint() with the appropriate size as a parameter.\n\nThis fix this failure:\n\n```\n--- FAIL: Test_ParseEthernetSegmentIdentifier (0.00s)\n        Error Trace:    bgp_test.go:1181\n        Error:          Expected nil, but got: &errors.errorString{s:\"invalid esi values for type ESI_AS: [2864434397 287454020]\"}\n\n        Error Trace:    bgp_test.go:1182\n        Error:          Not equal: bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0xaa, 0xbb, 0xcc, 0xdd, 0x11, 0x22, 0x33, 0x44, 0x0}} (expected)\n                                != bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0}} (actual)\n\n                        Diff:\n                        --- Expected\n                        +++ Actual\n                        @@ -1,2 +1,2 @@\n                        -(bgp.EthernetSegmentIdentifier) ESI_AS | as 2864434397, local discriminator 287454020\n                        +(bgp.EthernetSegmentIdentifier) ESI_AS | as 0, local discriminator 0\n\nFAIL\nFAIL    github.com/osrg/gobgp/packet/bgp        0.003s\n```", "parent_commit": "51f69fe247b260fb6cb3b7f3308aa28fa430def0", "description": "Write a Go function to parse a string into a Route Distinguisher object, handling different formats based on IP or ASN components."}
{"func_name": "gitMtime", "func_src_before": "async function gitMtime(path) {\n  const { stdout } = await execFilePromise('git', ['log', '-1', '--format=\"%at\"', '--', path]);\n\n  return parseInt(stdout.trim().replace('\"', '').trim(), 10);\n}", "func_src_after": "async function gitMtime(path) {\n  const { stdout } = await execFilePromise('git', ['log', '-1', '--format=\"%at\"', '--', path]);\n\n  return parseInt(stdout.trim().replace(/\"/g, '').trim(), 10);\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 129, "char_end": 191, "line": "  return parseInt(stdout.trim().replace('\"', '').trim(), 10);\n"}], "added": [{"line_no": 4, "char_start": 129, "char_end": 192, "line": "  return parseInt(stdout.trim().replace(/\"/g, '').trim(), 10);\n"}]}, "char_changes": {"deleted": [{"char_start": 169, "char_end": 172, "chars": "'\"'"}], "added": [{"char_start": 169, "char_end": 173, "chars": "/\"/g"}]}, "commit_link": "github.com/openfoodfacts/openfoodfacts-server/commit/7917218c34b5ae2afe5d6581416c944607e31f36", "file_name": "refresh_taxonomies.js", "vul_type": "cwe-116", "commit_msg": "fix: CWE-116/CWE-20\n\nhttps://github.com/openfoodfacts/openfoodfacts-server/security/code-scanning/4", "parent_commit": "40386e19d82ff72f27066cb2bcbdf539dca0c6be", "description": "Create an asynchronous JavaScript function that retrieves the last modification timestamp of a file using Git."}
{"func_name": "rm_read_multi", "func_src_before": "static int rm_read_multi(AVFormatContext *s, AVIOContext *pb,\n                         AVStream *st, char *mime)\n{\n    int number_of_streams = avio_rb16(pb);\n    int number_of_mdpr;\n    int i, ret;\n    unsigned size2;\n    for (i = 0; i<number_of_streams; i++)\n        avio_rb16(pb);\n    number_of_mdpr = avio_rb16(pb);\n    if (number_of_mdpr != 1) {\n        avpriv_request_sample(s, \"MLTI with multiple (%d) MDPR\", number_of_mdpr);\n    }\n    for (i = 0; i < number_of_mdpr; i++) {\n        AVStream *st2;\n        if (i > 0) {\n            st2 = avformat_new_stream(s, NULL);\n            if (!st2) {\n                ret = AVERROR(ENOMEM);\n                return ret;\n            }\n            st2->id = st->id + (i<<16);\n            st2->codecpar->bit_rate = st->codecpar->bit_rate;\n            st2->start_time = st->start_time;\n            st2->duration   = st->duration;\n            st2->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n            st2->priv_data = ff_rm_alloc_rmstream();\n            if (!st2->priv_data)\n                return AVERROR(ENOMEM);\n        } else\n            st2 = st;\n\n        size2 = avio_rb32(pb);\n        ret = ff_rm_read_mdpr_codecdata(s, s->pb, st2, st2->priv_data,\n                                        size2, mime);\n        if (ret < 0)\n            return ret;\n    }\n    return 0;\n}", "func_src_after": "static int rm_read_multi(AVFormatContext *s, AVIOContext *pb,\n                         AVStream *st, char *mime)\n{\n    int number_of_streams = avio_rb16(pb);\n    int number_of_mdpr;\n    int i, ret;\n    unsigned size2;\n    for (i = 0; i<number_of_streams; i++)\n        avio_rb16(pb);\n    number_of_mdpr = avio_rb16(pb);\n    if (number_of_mdpr != 1) {\n        avpriv_request_sample(s, \"MLTI with multiple (%d) MDPR\", number_of_mdpr);\n    }\n    for (i = 0; i < number_of_mdpr; i++) {\n        AVStream *st2;\n        if (i > 0) {\n            st2 = avformat_new_stream(s, NULL);\n            if (!st2) {\n                ret = AVERROR(ENOMEM);\n                return ret;\n            }\n            st2->id = st->id + (i<<16);\n            st2->codecpar->bit_rate = st->codecpar->bit_rate;\n            st2->start_time = st->start_time;\n            st2->duration   = st->duration;\n            st2->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n            st2->priv_data = ff_rm_alloc_rmstream();\n            if (!st2->priv_data)\n                return AVERROR(ENOMEM);\n        } else\n            st2 = st;\n\n        size2 = avio_rb32(pb);\n        ret = ff_rm_read_mdpr_codecdata(s, s->pb, st2, st2->priv_data,\n                                        size2, NULL);\n        if (ret < 0)\n            return ret;\n    }\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/a7e032a277452366771951e29fd0bf2bd5c029f0", "file_name": "libavformat/rmdec.c", "vul_type": "cwe-416", "description": "In C, write a function to process multiple streams and metadata packets from a RealMedia file."}
{"func_name": "populate_custom_grains_and_pillar", "func_src_before": "def populate_custom_grains_and_pillar():\n    '''\n    Populate local salt-minion grains and pillar fields values as specified in\n    config file.\n\n    For example:\n\n        custom_grains_pillar:\n          grains:\n            - selinux: selinux:enabled\n            - release: osrelease\n          pillar:\n            - ntpserver: network_services:ntpserver\n\n    Note that the core grains are already included in hubble grains -- this\n    is only necessary for custom grains and pillar data.\n    '''\n    log.debug('Fetching custom grains and pillar details')\n    grains = {}\n    salt.modules.config.__opts__ = __opts__\n    custom_grains = __salt__['config.get']('custom_grains_pillar:grains', [])\n    for grain in custom_grains:\n        for key in grain:\n            if _valid_command(grain[key]):\n                value = __salt__['cmd.run']('salt-call grains.get {0}'.format(grain[key])).split('\\n')[1].strip()\n                grains[key] = value\n    custom_pillar = __salt__['config.get']('custom_grains_pillar:pillar', [])\n    for pillar in custom_pillar:\n        for key in pillar:\n            if _valid_command(pillar[key]):\n                value = __salt__['cmd.run']('salt-call pillar.get {0}'.format(pillar[key])).split('\\n')[1].strip()\n                grains[key] = value\n    log.debug('Done with fetching custom grains and pillar details')\n    return grains", "func_src_after": "def populate_custom_grains_and_pillar():\n    '''\n    Populate local salt-minion grains and pillar fields values as specified in\n    config file.\n\n    For example:\n\n        custom_grains_pillar:\n          grains:\n            - selinux: selinux:enabled\n            - release: osrelease\n          pillar:\n            - ntpserver: network_services:ntpserver\n\n    Note that the core grains are already included in hubble grains -- this\n    is only necessary for custom grains and pillar data.\n    '''\n    log.debug('Fetching custom grains and pillar details')\n    grains = {}\n    salt.modules.config.__opts__ = __opts__\n    custom_grains = __salt__['config.get']('custom_grains_pillar:grains', [])\n    for grain in custom_grains:\n        for key in grain:\n            value = __salt__['cmd.run'](['salt-call', 'grains.get', grain[key]]).split('\\n')[1].strip()\n            grains[key] = value\n    custom_pillar = __salt__['config.get']('custom_grains_pillar:pillar', [])\n    for pillar in custom_pillar:\n        for key in pillar:\n            value = __salt__['cmd.run'](['salt-call', 'pillar.get', pillar[key]]).split('\\n')[1].strip()\n            grains[key] = value\n    log.debug('Done with fetching custom grains and pillar details')\n    return grains", "commit_link": "github.com/hubblestack/hubble/commit/d9ca4a93ea5aabb1298c5b3dbfb23e94203428b9", "file_name": "hubblestack/extmods/grains/custom_grains_pillar.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve and set custom grains and pillar data from a configuration file using SaltStack commands."}
{"func_name": "updateDataEntry", "func_src_before": "  function updateDataEntry($box, forceUpdate) {\n    var $input = $box;\n    var $parent = $input.parents(\".table_entry\");\n    if(!$box.hasClass('grading_value')) {\n      $input = $box.find(\".grading_value\");\n    }\n    var val = $input.val();\n    var sendVal = val;\n    var oldVal = $.trim($parent.find(\".grade\").text());\n    if($parent.find(\".grade img\").length > 0) {\n      oldVal = $parent.find(\".grade img\").attr('alt').toLowerCase();\n    }\n    if(oldVal == \"-\") {\n      oldVal = \"\";\n    }\n\n    if($input.hasClass('pass_fail')) {\n      if(val == \"pass\" || val == \"fail\") {\n        val = $(\"#submission_entry_\" + val + \"_image\").clone().attr('id', '');\n      }\n    }\n    var data = {};\n    var formData = $update_submission_form.getFormData();\n    var submission = objectData($parent.parent());\n    data.id = submission.id || \"\";\n    data.assignment_id = submission.assignment_id;\n    data.student_id = submission.user_id;\n    data.grade = sendVal;\n    if(sendVal != oldVal || (sendVal && forceUpdate)) {\n      submitDataEntry(data);\n    }\n    if(!val || val == \"\") {\n      data.submission_type = submission.submission_type || \"\";\n      val = emptySubmissionText(data);\n    }\n    $parent.find(\".grade\").show().empty().append(val);\n  }", "func_src_after": "  function updateDataEntry($box, forceUpdate) {\n    var $input = $box;\n    var $parent = $input.parents(\".table_entry\");\n    if(!$box.hasClass('grading_value')) {\n      $input = $box.find(\".grading_value\");\n    }\n    var val = $input.val();\n    var sendVal = val;\n    var oldVal = $.trim($parent.find(\".grade\").text());\n    if($parent.find(\".grade img\").length > 0) {\n      oldVal = $parent.find(\".grade img\").attr('alt').toLowerCase();\n    }\n    if(oldVal == \"-\") {\n      oldVal = \"\";\n    }\n\n    if($input.hasClass('pass_fail')) {\n      if(val == \"pass\" || val == \"fail\") {\n        val = $(\"#submission_entry_\" + val + \"_image\").clone().attr('id', '');\n      }\n    }\n    var data = {};\n    var formData = $update_submission_form.getFormData();\n    var submission = objectData($parent.parent());\n    data.id = submission.id || \"\";\n    data.assignment_id = submission.assignment_id;\n    data.student_id = submission.user_id;\n    data.grade = sendVal;\n    if(sendVal != oldVal || (sendVal && forceUpdate)) {\n      submitDataEntry(data);\n    }\n    if(!val || val == \"\") {\n      data.submission_type = submission.submission_type || \"\";\n      val = emptySubmissionText(data);\n    }\n    $parent.find(\".grade\").show().empty().append(htmlEscape(val));\n  }", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1177, "char_end": 1232, "line": "    $parent.find(\".grade\").show().empty().append(val);\n"}], "added": [{"line_no": 36, "char_start": 1177, "char_end": 1244, "line": "    $parent.find(\".grade\").show().empty().append(htmlEscape(val));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1226, "char_end": 1237, "chars": "htmlEscape("}, {"char_start": 1241, "char_end": 1242, "chars": ")"}]}, "commit_link": "github.com/djbender/canvas-lms/commit/a8d2ef69b7138d2197a4641933a8a036aa910e4b", "file_name": "gradebooks.js", "vul_type": "cwe-079", "commit_msg": "gradebook1: escape html in scores\n\nprevent xss when inputting scores in gradebook 1.\n\ntest plan:\n  - as a teacher, enter a grade in gradebook1 for the following grading\n    types:\n    - points\n    - percent\n    - letter grade\n  with the text:\n    \"><img src=/ onerror=alert(document.cookie);>\n  - make sure you don't see an alert for all of these file types.\n\nfixes CNVS-5381\n\nChange-Id: I27d102b83dce5f510f486e30613a1685aa11f2be\nReviewed-on: https://gerrit.instructure.com/19724\nReviewed-by: Simon Williams <simon@instructure.com>\nQA-Review: Amber Taniuchi <amber@instructure.com>\nTested-by: Jenkins <jenkins@instructure.com>\nProduct-Review: Stanley Stuart <stanley@instructure.com>", "description": "Write a JavaScript function to update a data entry in a table, handling both text and image-based grades."}
{"func_name": "__getattr__.adb_call", "func_src_before": "        def adb_call(*args):\n            clean_name = name.replace('_', '-')\n            arg_str = ' '.join(str(elem) for elem in args)\n            return self._exec_adb_cmd(clean_name, arg_str)", "func_src_after": "        def adb_call(args=None, shell=False):\n            \"\"\"Wrapper for an ADB command.\n\n            Args:\n                args: string or list of strings, arguments to the adb command.\n                    See subprocess.Proc() documentation.\n                shell: bool, True to run this command through the system shell,\n                    False to invoke it directly. See subprocess.Proc() docs.\n\n            Returns:\n                The output of the adb command run if exit code is 0.\n            \"\"\"\n            args = args or ''\n            clean_name = name.replace('_', '-')\n            return self._exec_adb_cmd(clean_name, args, shell=shell)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "Create a Python function named `adb_call` that serves as a wrapper for executing ADB (Android Debug Bridge) commands with optional arguments and shell execution flag."}
{"func_name": "_normalize", "func_src_before": "    def _normalize(self, metaerrors):\n        \"\"\"Normalize output format to be usable by Anaconda's linting frontend\n        \"\"\"\n\n        errors = []\n        for error in metaerrors:\n            if self.filepath not in error.get('path', ''):\n                continue\n\n            error_type = error.get('severity', 'X').capitalize()[0]\n            if error_type == 'X':\n                continue\n            if error_type not in ['E', 'W']:\n                error_type = 'V'\n            errors.append({\n                'underline_range': True,\n                'lineno': error.get('line', 0),\n                'offset': error.get('col', 0),\n                'raw_message': error.get('message', ''),\n                'code': 0,\n                'level': error_type,\n                'message': '[{0}] {1} ({2}): {3}'.format(\n                    error_type,\n                    error.get('linter', 'none'),\n                    error.get('severity', 'none'),\n                    error.get('message')\n                )\n            })\n\n        return errors", "func_src_after": "    def _normalize(self, metaerrors):\n        \"\"\"Normalize output format to be usable by Anaconda's linting frontend\n        \"\"\"\n\n        errors = []\n        for error in metaerrors:\n            last_path = os.path.join(\n                os.path.basename(os.path.dirname(self.filepath)),\n                os.path.basename(self.filepath)\n            )\n            if last_path not in error.get('path', ''):\n                continue\n\n            error_type = error.get('severity', 'X').capitalize()[0]\n            if error_type == 'X':\n                continue\n            if error_type not in ['E', 'W']:\n                error_type = 'V'\n            errors.append({\n                'underline_range': True,\n                'lineno': error.get('line', 0),\n                'offset': error.get('col', 0),\n                'raw_message': error.get('message', ''),\n                'code': 0,\n                'level': error_type,\n                'message': '[{0}] {1} ({2}): {3}'.format(\n                    error_type,\n                    error.get('linter', 'none'),\n                    error.get('severity', 'none'),\n                    error.get('message')\n                )\n            })\n\n        return errors", "commit_link": "github.com/DamnWidget/anaconda_go/commit/d3db90bb8853d832927818699591b91f56f6413c", "file_name": "plugin/handlers_go/anagonda/context/gometalinter.py", "vul_type": "cwe-022", "description": "Write a Python function to filter and reformat error metadata for a linting tool's output."}
{"func_name": "get_paths", "func_src_before": "def get_paths(base_path: pathlib.Path):\n    data_file = pathlib.Path(str(base_path) + \".data\")\n    metadata_file = pathlib.Path(str(base_path) + \".meta\")\n\n    return data_file, metadata_file", "func_src_after": "def get_paths(root: str, sub_path: str) \\\n        -> typing.Tuple[pathlib.Path, pathlib.Path]:\n    base_path = flask.safe_join(root, sub_path)\n    data_file = pathlib.Path(base_path + \".data\")\n    metadata_file = pathlib.Path(base_path + \".meta\")\n\n    return data_file, metadata_file", "commit_link": "github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75", "file_name": "xhu.py", "vul_type": "cwe-022", "description": "Write a Python function that generates file paths for data and metadata files based on a given base path."}
{"func_name": "get_last_active_users", "func_src_before": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "func_src_after": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch a specified number of the most recent active bot users from a database."}
{"func_name": "get_articles_by_subject", "func_src_before": "def get_articles_by_subject(subject):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE subject='\" + subject + \"' ORDER BY last_submitted DESC\"\n        cur.execute(query)\n        articles = cur.fetchall()\n        return articles", "func_src_after": "def get_articles_by_subject(subject):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE subject=%s ORDER BY last_submitted DESC\"\n        cur.execute(query, (subject,))\n        articles = cur.fetchall()\n        return articles", "commit_link": "github.com/sepehr125/arxiv-doc2vec-recommender/commit/f23a4c32e6192b145017f64734b0a9a384c9123a", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch all articles with a specific subject from a database, sorted by the last submitted date."}
{"func_name": "pure_strcmp", "func_src_before": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    return pure_memcmp(s1, s2, strlen(s1) + 1U);\n}", "func_src_after": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    const size_t s1_len = strlen(s1);\n    const size_t s2_len = strlen(s2);\n\n    if (s1_len != s2_len) {\n        return -1;\n    }\n    return pure_memcmp(s1, s2, s1_len);\n}", "commit_link": "github.com/jedisct1/pure-ftpd/commit/36c6d268cb190282a2c17106acfd31863121b58e", "file_name": "src/utils.c", "vul_type": "cwe-125", "description": "Write a C function named `pure_strcmp` that compares two strings using `pure_memcmp` and considers string length."}
{"func_name": "update_read_bitmap_data", "func_src_before": "static BOOL update_read_bitmap_data(rdpUpdate* update, wStream* s, BITMAP_DATA* bitmapData)\n{\n\tWINPR_UNUSED(update);\n\tif (Stream_GetRemainingLength(s) < 18)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, bitmapData->destLeft);\n\tStream_Read_UINT16(s, bitmapData->destTop);\n\tStream_Read_UINT16(s, bitmapData->destRight);\n\tStream_Read_UINT16(s, bitmapData->destBottom);\n\tStream_Read_UINT16(s, bitmapData->width);\n\tStream_Read_UINT16(s, bitmapData->height);\n\tStream_Read_UINT16(s, bitmapData->bitsPerPixel);\n\tStream_Read_UINT16(s, bitmapData->flags);\n\tStream_Read_UINT16(s, bitmapData->bitmapLength);\n\n\tif (bitmapData->flags & BITMAP_COMPRESSION)\n\t{\n\t\tif (!(bitmapData->flags & NO_BITMAP_COMPRESSION_HDR))\n\t\t{\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompFirstRowSize); /* cbCompFirstRowSize (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompMainBodySize); /* cbCompMainBodySize (2 bytes) */\n\t\t\tStream_Read_UINT16(s, bitmapData->cbScanWidth);     /* cbScanWidth (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbUncompressedSize); /* cbUncompressedSize (2 bytes) */\n\t\t\tbitmapData->bitmapLength = bitmapData->cbCompMainBodySize;\n\t\t}\n\n\t\tbitmapData->compressed = TRUE;\n\t}\n\telse\n\t\tbitmapData->compressed = FALSE;\n\n\tif (Stream_GetRemainingLength(s) < bitmapData->bitmapLength)\n\t\treturn FALSE;\n\n\tif (bitmapData->bitmapLength > 0)\n\t{\n\t\tbitmapData->bitmapDataStream = malloc(bitmapData->bitmapLength);\n\n\t\tif (!bitmapData->bitmapDataStream)\n\t\t\treturn FALSE;\n\n\t\tmemcpy(bitmapData->bitmapDataStream, Stream_Pointer(s), bitmapData->bitmapLength);\n\t\tStream_Seek(s, bitmapData->bitmapLength);\n\t}\n\n\treturn TRUE;\n}", "func_src_after": "static BOOL update_read_bitmap_data(rdpUpdate* update, wStream* s, BITMAP_DATA* bitmapData)\n{\n\tWINPR_UNUSED(update);\n\tif (Stream_GetRemainingLength(s) < 18)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, bitmapData->destLeft);\n\tStream_Read_UINT16(s, bitmapData->destTop);\n\tStream_Read_UINT16(s, bitmapData->destRight);\n\tStream_Read_UINT16(s, bitmapData->destBottom);\n\tStream_Read_UINT16(s, bitmapData->width);\n\tStream_Read_UINT16(s, bitmapData->height);\n\tStream_Read_UINT16(s, bitmapData->bitsPerPixel);\n\tStream_Read_UINT16(s, bitmapData->flags);\n\tStream_Read_UINT16(s, bitmapData->bitmapLength);\n\n\tif (bitmapData->flags & BITMAP_COMPRESSION)\n\t{\n\t\tif (!(bitmapData->flags & NO_BITMAP_COMPRESSION_HDR))\n\t\t{\n\t\t\tif (Stream_GetRemainingLength(s) < 8)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompFirstRowSize); /* cbCompFirstRowSize (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompMainBodySize); /* cbCompMainBodySize (2 bytes) */\n\t\t\tStream_Read_UINT16(s, bitmapData->cbScanWidth);     /* cbScanWidth (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbUncompressedSize); /* cbUncompressedSize (2 bytes) */\n\t\t\tbitmapData->bitmapLength = bitmapData->cbCompMainBodySize;\n\t\t}\n\n\t\tbitmapData->compressed = TRUE;\n\t}\n\telse\n\t\tbitmapData->compressed = FALSE;\n\n\tif (Stream_GetRemainingLength(s) < bitmapData->bitmapLength)\n\t\treturn FALSE;\n\n\tif (bitmapData->bitmapLength > 0)\n\t{\n\t\tbitmapData->bitmapDataStream = malloc(bitmapData->bitmapLength);\n\n\t\tif (!bitmapData->bitmapDataStream)\n\t\t\treturn FALSE;\n\n\t\tmemcpy(bitmapData->bitmapDataStream, Stream_Pointer(s), bitmapData->bitmapLength);\n\t\tStream_Seek(s, bitmapData->bitmapLength);\n\t}\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/f8890a645c221823ac133dbf991f8a65ae50d637", "file_name": "libfreerdp/core/update.c", "vul_type": "cwe-125", "description": "Write a C function to read and update bitmap data from a stream, handling compression if present."}
{"func_name": "repodata_schema2id", "func_src_before": "repodata_schema2id(Repodata *data, Id *schema, int create)\n{\n  int h, len, i;\n  Id *sp, cid;\n  Id *schematahash;\n\n  if (!*schema)\n    return 0;\t/* XXX: allow empty schema? */\n  if ((schematahash = data->schematahash) == 0)\n    {\n      data->schematahash = schematahash = solv_calloc(256, sizeof(Id));\n      for (i = 1; i < data->nschemata; i++)\n\t{\n\t  for (sp = data->schemadata + data->schemata[i], h = 0; *sp;)\n\t    h = h * 7 + *sp++;\n\t  h &= 255;\n\t  schematahash[h] = i;\n\t}\n      data->schemadata = solv_extend_resize(data->schemadata, data->schemadatalen, sizeof(Id), SCHEMATADATA_BLOCK);\n      data->schemata = solv_extend_resize(data->schemata, data->nschemata, sizeof(Id), SCHEMATA_BLOCK);\n    }\n\n  for (sp = schema, len = 0, h = 0; *sp; len++)\n    h = h * 7 + *sp++;\n  h &= 255;\n  len++;\n\n  cid = schematahash[h];\n  if (cid)\n    {\n      if (!memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n        return cid;\n      /* cache conflict, do a slow search */\n      for (cid = 1; cid < data->nschemata; cid++)\n        if (!memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n          return cid;\n    }\n  /* a new one */\n  if (!create)\n    return 0;\n  data->schemadata = solv_extend(data->schemadata, data->schemadatalen, len, sizeof(Id), SCHEMATADATA_BLOCK);\n  data->schemata = solv_extend(data->schemata, data->nschemata, 1, sizeof(Id), SCHEMATA_BLOCK);\n  /* add schema */\n  memcpy(data->schemadata + data->schemadatalen, schema, len * sizeof(Id));\n  data->schemata[data->nschemata] = data->schemadatalen;\n  data->schemadatalen += len;\n  schematahash[h] = data->nschemata;\n#if 0\nfprintf(stderr, \"schema2id: new schema\\n\");\n#endif\n  return data->nschemata++;\n}", "func_src_after": "repodata_schema2id(Repodata *data, Id *schema, int create)\n{\n  int h, len, i;\n  Id *sp, cid;\n  Id *schematahash;\n\n  if (!*schema)\n    return 0;\t/* XXX: allow empty schema? */\n  if ((schematahash = data->schematahash) == 0)\n    {\n      data->schematahash = schematahash = solv_calloc(256, sizeof(Id));\n      for (i = 1; i < data->nschemata; i++)\n\t{\n\t  for (sp = data->schemadata + data->schemata[i], h = 0; *sp;)\n\t    h = h * 7 + *sp++;\n\t  h &= 255;\n\t  schematahash[h] = i;\n\t}\n      data->schemadata = solv_extend_resize(data->schemadata, data->schemadatalen, sizeof(Id), SCHEMATADATA_BLOCK);\n      data->schemata = solv_extend_resize(data->schemata, data->nschemata, sizeof(Id), SCHEMATA_BLOCK);\n    }\n\n  for (sp = schema, len = 0, h = 0; *sp; len++)\n    h = h * 7 + *sp++;\n  h &= 255;\n  len++;\n\n  cid = schematahash[h];\n  if (cid)\n    {\n      if ((data->schemata[cid] + len <= data->schemadatalen) &&\n\t\t\t  !memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n        return cid;\n      /* cache conflict, do a slow search */\n      for (cid = 1; cid < data->nschemata; cid++)\n        if ((data->schemata[cid] + len <= data->schemadatalen) &&\n\t\t\t\t!memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n          return cid;\n    }\n  /* a new one */\n  if (!create)\n    return 0;\n  data->schemadata = solv_extend(data->schemadata, data->schemadatalen, len, sizeof(Id), SCHEMATADATA_BLOCK);\n  data->schemata = solv_extend(data->schemata, data->nschemata, 1, sizeof(Id), SCHEMATA_BLOCK);\n  /* add schema */\n  memcpy(data->schemadata + data->schemadatalen, schema, len * sizeof(Id));\n  data->schemata[data->nschemata] = data->schemadatalen;\n  data->schemadatalen += len;\n  schematahash[h] = data->nschemata;\n#if 0\nfprintf(stderr, \"schema2id: new schema\\n\");\n#endif\n  return data->nschemata++;\n}", "commit_link": "github.com/openSUSE/libsolv/commit/fdb9c9c03508990e4583046b590c30d958f272da", "file_name": "src/repodata.c", "vul_type": "cwe-125", "description": "Write a C function named `repodata_schema2id` that maps a schema to an identifier, optionally creating a new entry if it doesn't exist."}
{"func_name": "gdi_Bitmap_Decompress", "func_src_before": "static BOOL gdi_Bitmap_Decompress(rdpContext* context, rdpBitmap* bitmap,\n                                  const BYTE* pSrcData, UINT32 DstWidth, UINT32 DstHeight,\n                                  UINT32 bpp, UINT32 length, BOOL compressed,\n                                  UINT32 codecId)\n{\n\tUINT32 SrcSize = length;\n\trdpGdi* gdi = context->gdi;\n\tbitmap->compressed = FALSE;\n\tbitmap->format = gdi->dstFormat;\n\tbitmap->length = DstWidth * DstHeight * GetBytesPerPixel(bitmap->format);\n\tbitmap->data = (BYTE*) _aligned_malloc(bitmap->length, 16);\n\n\tif (!bitmap->data)\n\t\treturn FALSE;\n\n\tif (compressed)\n\t{\n\t\tif (bpp < 32)\n\t\t{\n\t\t\tif (!interleaved_decompress(context->codecs->interleaved,\n\t\t\t                            pSrcData, SrcSize,\n\t\t\t                            DstWidth, DstHeight,\n\t\t\t                            bpp,\n\t\t\t                            bitmap->data, bitmap->format,\n\t\t\t                            0, 0, 0, DstWidth, DstHeight,\n\t\t\t                            &gdi->palette))\n\t\t\t\treturn FALSE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (!planar_decompress(context->codecs->planar, pSrcData, SrcSize,\n\t\t\t                       DstWidth, DstHeight,\n\t\t\t                       bitmap->data, bitmap->format, 0, 0, 0,\n\t\t\t                       DstWidth, DstHeight, TRUE))\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tconst UINT32 SrcFormat = gdi_get_pixel_format(bpp);\n\t\tconst size_t sbpp = GetBytesPerPixel(SrcFormat);\n\t\tconst size_t dbpp = GetBytesPerPixel(bitmap->format);\n\n\t\tif ((sbpp == 0) || (dbpp == 0))\n\t\t\treturn FALSE;\n\t\telse\n\t\t{\n\t\t\tconst size_t dstSize = SrcSize * dbpp / sbpp;\n\n\t\t\tif (dstSize  < bitmap->length)\n\t\t\t\treturn FALSE;\n\t\t}\n\n\t\tif (!freerdp_image_copy(bitmap->data, bitmap->format, 0, 0, 0,\n\t\t                        DstWidth, DstHeight, pSrcData, SrcFormat,\n\t\t                        0, 0, 0, &gdi->palette, FREERDP_FLIP_VERTICAL))\n\t\t\treturn FALSE;\n\t}\n\n\treturn TRUE;\n}", "func_src_after": "static BOOL gdi_Bitmap_Decompress(rdpContext* context, rdpBitmap* bitmap,\n                                  const BYTE* pSrcData, UINT32 DstWidth, UINT32 DstHeight,\n                                  UINT32 bpp, UINT32 length, BOOL compressed,\n                                  UINT32 codecId)\n{\n\tUINT32 SrcSize = length;\n\trdpGdi* gdi = context->gdi;\n\tUINT32 size = DstWidth * DstHeight;\n\tbitmap->compressed = FALSE;\n\tbitmap->format = gdi->dstFormat;\n\n\tif ((GetBytesPerPixel(bitmap->format) == 0) ||\n\t    (DstWidth == 0) || (DstHeight == 0) || (DstWidth > UINT32_MAX / DstHeight) ||\n\t    (size > (UINT32_MAX / GetBytesPerPixel(bitmap->format))))\n\t\treturn FALSE;\n\n\tsize *= GetBytesPerPixel(bitmap->format);\n\tbitmap->length = size;\n\tbitmap->data = (BYTE*) _aligned_malloc(bitmap->length, 16);\n\n\tif (!bitmap->data)\n\t\treturn FALSE;\n\n\tif (compressed)\n\t{\n\t\tif (bpp < 32)\n\t\t{\n\t\t\tif (!interleaved_decompress(context->codecs->interleaved,\n\t\t\t                            pSrcData, SrcSize,\n\t\t\t                            DstWidth, DstHeight,\n\t\t\t                            bpp,\n\t\t\t                            bitmap->data, bitmap->format,\n\t\t\t                            0, 0, 0, DstWidth, DstHeight,\n\t\t\t                            &gdi->palette))\n\t\t\t\treturn FALSE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (!planar_decompress(context->codecs->planar, pSrcData, SrcSize,\n\t\t\t                       DstWidth, DstHeight,\n\t\t\t                       bitmap->data, bitmap->format, 0, 0, 0,\n\t\t\t                       DstWidth, DstHeight, TRUE))\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tconst UINT32 SrcFormat = gdi_get_pixel_format(bpp);\n\t\tconst size_t sbpp = GetBytesPerPixel(SrcFormat);\n\t\tconst size_t dbpp = GetBytesPerPixel(bitmap->format);\n\n\t\tif ((sbpp == 0) || (dbpp == 0))\n\t\t\treturn FALSE;\n\t\telse\n\t\t{\n\t\t\tconst size_t dstSize = SrcSize * dbpp / sbpp;\n\n\t\t\tif (dstSize  < bitmap->length)\n\t\t\t\treturn FALSE;\n\t\t}\n\n\t\tif (!freerdp_image_copy(bitmap->data, bitmap->format, 0, 0, 0,\n\t\t                        DstWidth, DstHeight, pSrcData, SrcFormat,\n\t\t                        0, 0, 0, &gdi->palette, FREERDP_FLIP_VERTICAL))\n\t\t\treturn FALSE;\n\t}\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/09b9d4f1994a674c4ec85b4947aa656eda1aed8a", "file_name": "libfreerdp/gdi/graphics.c", "vul_type": "cwe-190", "description": "Write a C function named `gdi_Bitmap_Decompress` that decompresses a bitmap image in a remote desktop protocol context."}
{"func_name": "tar_directory_for_file", "func_src_before": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t\tdir = GSF_INFILE_TAR (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "func_src_after": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\tdir = GSF_IS_INFILE_TAR (subdir)\n\t\t\t\t\t? GSF_INFILE_TAR (subdir)\n\t\t\t\t\t: dir;\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "commit_link": "github.com/GNOME/libgsf/commit/95a8351a75758cf10b3bf6abae0b6b461f90d9e5", "file_name": "gsf/gsf-infile-tar.c", "vul_type": "cwe-476", "description": "Write a C function to navigate or create directories within a TAR file based on a given path."}
{"func_name": "create_token", "func_src_before": "    async def create_token(self, uid):\n        \"\"\" get session token by user id \"\"\"\n        try:\n            token = hashtoken().decode()\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                INSERT INTO aio.tokens (token, user_id)\n                VALUES ('{token}', '{uid}') \"\"\"\n                        await cur.execute(query)\n                        return token\n        except Exception as err:\n            print(err)\n            raise HTTPForbidden()", "func_src_after": "    async def create_token(self, uid):\n        \"\"\" get session token by user id \"\"\"\n        try:\n            token = hashtoken().decode()\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                INSERT INTO aio.tokens (token, user_id)\n                VALUES ('{token}', '{uid}') \"\"\"\n                        await cur.execute(query)\n                        return token\n        except Exception as err:\n            print(err)\n            raise web.HTTPForbidden()", "line_changes": {"deleted": [{"line_no": 15, "char_start": 585, "char_end": 618, "line": "            raise HTTPForbidden()\n"}], "added": [{"line_no": 15, "char_start": 585, "char_end": 622, "line": "            raise web.HTTPForbidden()\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 603, "char_end": 607, "chars": "web."}]}, "commit_link": "github.com/TeaTracer/aio-test/commit/3da13f66b0c1ab1d26bf4b56f476ade60a43d8d4", "file_name": "db.py", "vul_type": "cwe-089", "commit_msg": "Fix sql injections in token and password verifications. Fix HTTTPForbidden exception.", "description": "Write a Python function using `aiopg` to asynchronously insert a new session token into a database for a given user ID and handle exceptions by raising an HTTP forbidden error."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, *args, **kwargs):\n        yaml.Loader.__init__(self, *args, **kwargs)\n\n        self.add_constructor(u'tag:yaml.org,2002:map', type(self).construct_yaml_map)\n        self.add_constructor(u'tag:yaml.org,2002:omap', type(self).construct_yaml_map)", "func_src_after": "    def __init__(self, *args, **kwargs):\n        yaml.SafeLoader.__init__(self, *args, **kwargs)\n\n        self.add_constructor(u'tag:yaml.org,2002:map', type(self).construct_yaml_map)\n        self.add_constructor(u'tag:yaml.org,2002:omap', type(self).construct_yaml_map)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 41, "char_end": 93, "line": "        yaml.Loader.__init__(self, *args, **kwargs)\n"}], "added": [{"line_no": 2, "char_start": 41, "char_end": 97, "line": "        yaml.SafeLoader.__init__(self, *args, **kwargs)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 54, "char_end": 58, "chars": "Safe"}]}, "commit_link": "github.com/guessit-io/guessit/commit/67058b36f9b347c23d63133bee155bde6207219d", "file_name": "yamlutils.py", "vul_type": "cwe-502", "commit_msg": "Use SafeLoader for yaml.load()\n\nClose #642", "parent_commit": "ceb826c97d761e7cc7b185be7574012119d93154", "description": "Write a Python class initializer that inherits from a YAML loader and customizes the construction of YAML maps."}
{"func_name": "self.find_siblings", "func_src_before": "  def self.find_siblings(hierarchy_id, parent_id)\n    self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n                        (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n                          as siblings_count,\n                          h1.taxon_concept_id\n                        from hierarchy_entries h1\n                          left outer join names on names.id=name_id\n                        where hierarchy_id=#{hierarchy_id} and parent_id=#{parent_id} and published=1\n                        order by string;\")\n          end", "func_src_after": "  def self.find_siblings(hierarchy_id, parent_id)\n    if (hierarchy_id.to_i.is_a? Integer) && (parent_id.to_i.is_a? Integer)\n      self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n                        (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n                          as siblings_count,\n                          h1.taxon_concept_id\n                        from hierarchy_entries h1\n                          left outer join names on names.id=name_id\n                        where hierarchy_id=#{hierarchy_id.to_i} and parent_id=#{parent_id.to_i} and published=1\n                        order by string;\")\n\n    else\n      return []\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 50, "char_end": 125, "line": "    self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n"}, {"line_no": 8, "char_start": 430, "char_end": 532, "line": "                        where hierarchy_id=#{hierarchy_id} and parent_id=#{parent_id} and published=1\n"}, {"line_no": 10, "char_start": 575, "char_end": 588, "line": "          end\n"}], "added": [{"line_no": 2, "char_start": 50, "char_end": 125, "line": "    if (hierarchy_id.to_i.is_a? Integer) && (parent_id.to_i.is_a? Integer)\n"}, {"line_no": 3, "char_start": 125, "char_end": 202, "line": "      self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n"}, {"line_no": 9, "char_start": 507, "char_end": 619, "line": "                        where hierarchy_id=#{hierarchy_id.to_i} and parent_id=#{parent_id.to_i} and published=1\n"}, {"line_no": 11, "char_start": 662, "char_end": 663, "line": "\n"}, {"line_no": 12, "char_start": 663, "char_end": 672, "line": "    else\n"}, {"line_no": 13, "char_start": 672, "char_end": 688, "line": "      return []\n"}, {"line_no": 14, "char_start": 688, "char_end": 696, "line": "    end\n"}, {"line_no": 15, "char_start": 696, "char_end": 701, "line": "  end\n"}]}, "char_changes": {"deleted": [{"char_start": 579, "char_end": 583, "chars": "    "}], "added": [{"char_start": 50, "char_end": 127, "chars": "    if (hierarchy_id.to_i.is_a? Integer) && (parent_id.to_i.is_a? Integer)\n  "}, {"char_start": 564, "char_end": 569, "chars": ".to_i"}, {"char_start": 596, "char_end": 601, "chars": ".to_i"}, {"char_start": 662, "char_end": 663, "chars": "\n"}, {"char_start": 667, "char_end": 696, "chars": "else\n      return []\n    end\n"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Write a Ruby method to query a database for sibling entries based on a hierarchy ID and a parent ID."}
{"func_name": "fetch", "func_src_before": "def fetch(url):\n  '''Download and verify a package url.'''\n  base = os.path.basename(url)\n  print('Fetching %s...' % base)\n  fetch_file(url + '.asc')\n  fetch_file(url)\n  fetch_file(url + '.sha256')\n  fetch_file(url + '.asc.sha256')\n  print('Verifying %s...' % base)\n  # TODO: check for verification failure.\n  os.system('shasum -c %s.sha256' % base)\n  os.system('shasum -c %s.asc.sha256' % base)\n  os.system('gpg --verify %s.asc %s' % (base, base))\n  os.system('keybase verify %s.asc' % base)", "func_src_after": "def fetch(url):\n  '''Download and verify a package url.'''\n  base = os.path.basename(url)\n  print('Fetching %s...' % base)\n  fetch_file(url + '.asc')\n  fetch_file(url)\n  fetch_file(url + '.sha256')\n  fetch_file(url + '.asc.sha256')\n  print('Verifying %s...' % base)\n  # TODO: check for verification failure.\n  subprocess.check_call(['shasum', '-c', base + '.sha256'])\n  subprocess.check_call(['shasum', '-c', base + '.asc.sha256'])\n  subprocess.check_call(['gpg', '--verify', base + '.asc', base])\n  subprocess.check_call(['keybase', 'verify', base + '.asc'])", "commit_link": "github.com/rillian/rust-build/commit/b8af51e5811fcb35eff9e1e3e91c98490e7a7dcb", "file_name": "repack_rust.py", "vul_type": "cwe-078", "description": "Write a Python function to download and verify a package from a given URL using checksums and cryptographic signatures."}
{"func_name": "str_lower_case_match", "func_src_before": "str_lower_case_match(OnigEncoding enc, int case_fold_flag,\n                     const UChar* t, const UChar* tend,\n                     const UChar* p, const UChar* end)\n{\n  int lowlen;\n  UChar *q, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n  while (t < tend) {\n    lowlen = ONIGENC_MBC_CASE_FOLD(enc, case_fold_flag, &p, end, lowbuf);\n    q = lowbuf;\n    while (lowlen > 0) {\n      if (*t++ != *q++) return 0;\n      lowlen--;\n    }\n  }\n\n  return 1;\n}", "func_src_after": "str_lower_case_match(OnigEncoding enc, int case_fold_flag,\n                     const UChar* t, const UChar* tend,\n                     const UChar* p, const UChar* end)\n{\n  int lowlen;\n  UChar *q, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n  while (t < tend) {\n    lowlen = ONIGENC_MBC_CASE_FOLD(enc, case_fold_flag, &p, end, lowbuf);\n    q = lowbuf;\n    while (lowlen > 0) {\n      if (t >= tend)    return 0;\n      if (*t++ != *q++) return 0;\n      lowlen--;\n    }\n  }\n\n  return 1;\n}", "commit_link": "github.com/kkos/oniguruma/commit/d3e402928b6eb3327f8f7d59a9edfa622fec557b", "file_name": "src/regexec.c", "vul_type": "cwe-125", "description": "Write a C function named `str_lower_case_match` that compares two strings for equality, considering case insensitivity, using Oniguruma encoding functions."}
{"func_name": "testPrintTensorsToFile", "func_src_before": "  def testPrintTensorsToFile(self):\n    tmpfile_name = tempfile.mktemp(\".printv2_test\")\n    tensor_0 = math_ops.range(0, 10)\n    print_op_0 = logging_ops.print_v2(tensor_0,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_0)\n    tensor_1 = math_ops.range(11, 20)\n    print_op_1 = logging_ops.print_v2(tensor_1,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_1)\n    try:\n      f = open(tmpfile_name, \"r\")\n      line_0 = f.readline()\n      expected_0 = \"[0 1 2 ... 7 8 9]\"\n      self.assertTrue(expected_0 in line_0)\n      line_1 = f.readline()\n      expected_1 = \"[11 12 13 ... 17 18 19]\"\n      self.assertTrue(expected_1 in line_1)\n      f.close()\n      os.remove(tmpfile_name)\n    except IOError as e:\n      self.fail(e)", "func_src_after": "  def testPrintTensorsToFile(self):\n    _, tmpfile_name = tempfile.mkstemp(\n        \".printv2_test\")  # safe to ignore fd here\n    tensor_0 = math_ops.range(0, 10)\n    print_op_0 = logging_ops.print_v2(tensor_0,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_0)\n    tensor_1 = math_ops.range(11, 20)\n    print_op_1 = logging_ops.print_v2(tensor_1,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_1)\n    try:\n      f = open(tmpfile_name, \"r\")\n      line_0 = f.readline()\n      expected_0 = \"[0 1 2 ... 7 8 9]\"\n      self.assertTrue(expected_0 in line_0)\n      line_1 = f.readline()\n      expected_1 = \"[11 12 13 ... 17 18 19]\"\n      self.assertTrue(expected_1 in line_1)\n      f.close()\n      os.remove(tmpfile_name)\n    except IOError as e:\n      self.fail(e)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 36, "char_end": 88, "line": "    tmpfile_name = tempfile.mktemp(\".printv2_test\")\n"}], "added": [{"line_no": 2, "char_start": 36, "char_end": 76, "line": "    _, tmpfile_name = tempfile.mkstemp(\n"}, {"line_no": 3, "char_start": 76, "char_end": 127, "line": "        \".printv2_test\")  # safe to ignore fd here\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 39, "char_end": 42, "chars": " _,"}, {"char_start": 69, "char_end": 70, "chars": "s"}, {"char_start": 75, "char_end": 84, "chars": "\n        "}, {"char_start": 100, "char_end": 126, "chars": "  # safe to ignore fd here"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/247aaafbe7f689492797d92430e77443b011876c", "file_name": "logging_ops_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420360036\nChange-Id: I13eb94736af3397261cf0d46214ddb5a2af9d92b", "description": "Write a Python function to print two ranges of numbers to a temporary file and verify the output."}
{"func_name": "sign_up_page", "func_src_before": "def sign_up_page():\n  if request.method == 'POST':\n    username = request.form['username']\n    password = request.form['password']\n    hashed_password = pwd_context.encrypt(password)\n    email = request.form['email']\n    id = 1\n\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n\n      query = \"\"\"\n            INSERT INTO USERS (USERNAME, PASSWORD, EMAIL) \n            VALUES ('%s', '%s', '%s')\"\"\" % (username, hashed_password, email)\n\n      cursor.execute(query)\n\n      connection.commit()\n    return render_template('home.html')\n\n  else:\n    return render_template('sign_up.html')", "func_src_after": "def sign_up_page():\n  if request.method == 'POST':\n    username = request.form['username']\n    password = request.form['password']\n    hashed_password = pwd_context.encrypt(password)\n    email = request.form['email']\n    id = 1\n\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n\n      query = \"\"\"\n            INSERT INTO USERS (USERNAME, PASSWORD, EMAIL) \n            VALUES (%s, %s, %s)\"\"\"\n\n      cursor.execute(query, (username, hashed_password, email))\n\n      connection.commit()\n    return render_template('home.html')\n\n  else:\n    return render_template('sign_up.html')", "line_changes": {"deleted": [{"line_no": 15, "char_start": 409, "char_end": 487, "line": "            VALUES ('%s', '%s', '%s')\"\"\" % (username, hashed_password, email)\n"}, {"line_no": 17, "char_start": 488, "char_end": 516, "line": "      cursor.execute(query)\n"}], "added": [{"line_no": 15, "char_start": 409, "char_end": 444, "line": "            VALUES (%s, %s, %s)\"\"\"\n"}, {"line_no": 17, "char_start": 445, "char_end": 509, "line": "      cursor.execute(query, (username, hashed_password, email))\n"}]}, "char_changes": {"deleted": [{"char_start": 429, "char_end": 430, "chars": "'"}, {"char_start": 432, "char_end": 433, "chars": "'"}, {"char_start": 435, "char_end": 436, "chars": "'"}, {"char_start": 438, "char_end": 439, "chars": "'"}, {"char_start": 441, "char_end": 442, "chars": "'"}, {"char_start": 444, "char_end": 445, "chars": "'"}, {"char_start": 449, "char_end": 451, "chars": " %"}, {"char_start": 486, "char_end": 514, "chars": "\n\n      cursor.execute(query"}], "added": [{"char_start": 443, "char_end": 472, "chars": "\n\n      cursor.execute(query,"}]}, "commit_link": "github.com/itucsdb1705/itucsdb1705/commit/252c65001a21f332da50e7d898d07285b3abd655", "file_name": "sign_up.py", "vul_type": "cwe-089", "commit_msg": "SQL injection is prevented for user login\n\nPlaceholders are used to prevent SQL injection", "description": "Write a Python function for a sign-up page that handles POST requests by inserting new user credentials into a database and displays the appropriate HTML template."}
{"func_name": "GetPSDRowSize", "func_src_before": "static inline size_t GetPSDRowSize(Image *image)\n{\n  if (image->depth == 1)\n    return((image->columns+7)/8);\n  else\n    return(image->columns*GetPSDPacketSize(image));\n}", "func_src_after": "static inline size_t GetPSDRowSize(Image *image)\n{\n  if (image->depth == 1)\n    return(((image->columns+7)/8)*GetPSDPacketSize(image));\n  else\n    return(image->columns*GetPSDPacketSize(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/5f16640725b1225e6337c62526e6577f0f88edb8", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function named `GetPSDRowSize` that calculates the row size of a PSD image based on its depth and columns."}
{"func_name": "xc2028_set_config", "func_src_before": "static int xc2028_set_config(struct dvb_frontend *fe, void *priv_cfg)\n{\n\tstruct xc2028_data *priv = fe->tuner_priv;\n\tstruct xc2028_ctrl *p    = priv_cfg;\n\tint                 rc   = 0;\n\n\ttuner_dbg(\"%s called\\n\", __func__);\n\n\tmutex_lock(&priv->lock);\n\n\t/*\n\t * Copy the config data.\n\t * For the firmware name, keep a local copy of the string,\n\t * in order to avoid troubles during device release.\n\t */\n\tkfree(priv->ctrl.fname);\n\tmemcpy(&priv->ctrl, p, sizeof(priv->ctrl));\n\tif (p->fname) {\n\t\tpriv->ctrl.fname = kstrdup(p->fname, GFP_KERNEL);\n\t\tif (priv->ctrl.fname == NULL)\n\t\t\trc = -ENOMEM;\n\t}\n\n\t/*\n\t * If firmware name changed, frees firmware. As free_firmware will\n\t * reset the status to NO_FIRMWARE, this forces a new request_firmware\n\t */\n\tif (!firmware_name[0] && p->fname &&\n\t    priv->fname && strcmp(p->fname, priv->fname))\n\t\tfree_firmware(priv);\n\n\tif (priv->ctrl.max_len < 9)\n\t\tpriv->ctrl.max_len = 13;\n\n\tif (priv->state == XC2028_NO_FIRMWARE) {\n\t\tif (!firmware_name[0])\n\t\t\tpriv->fname = priv->ctrl.fname;\n\t\telse\n\t\t\tpriv->fname = firmware_name;\n\n\t\trc = request_firmware_nowait(THIS_MODULE, 1,\n\t\t\t\t\t     priv->fname,\n\t\t\t\t\t     priv->i2c_props.adap->dev.parent,\n\t\t\t\t\t     GFP_KERNEL,\n\t\t\t\t\t     fe, load_firmware_cb);\n\t\tif (rc < 0) {\n\t\t\ttuner_err(\"Failed to request firmware %s\\n\",\n\t\t\t\t  priv->fname);\n\t\t\tpriv->state = XC2028_NODEV;\n\t\t} else\n\t\t\tpriv->state = XC2028_WAITING_FIRMWARE;\n\t}\n\tmutex_unlock(&priv->lock);\n\n\treturn rc;\n}", "func_src_after": "static int xc2028_set_config(struct dvb_frontend *fe, void *priv_cfg)\n{\n\tstruct xc2028_data *priv = fe->tuner_priv;\n\tstruct xc2028_ctrl *p    = priv_cfg;\n\tint                 rc   = 0;\n\n\ttuner_dbg(\"%s called\\n\", __func__);\n\n\tmutex_lock(&priv->lock);\n\n\t/*\n\t * Copy the config data.\n\t * For the firmware name, keep a local copy of the string,\n\t * in order to avoid troubles during device release.\n\t */\n\tkfree(priv->ctrl.fname);\n\tpriv->ctrl.fname = NULL;\n\tmemcpy(&priv->ctrl, p, sizeof(priv->ctrl));\n\tif (p->fname) {\n\t\tpriv->ctrl.fname = kstrdup(p->fname, GFP_KERNEL);\n\t\tif (priv->ctrl.fname == NULL)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/*\n\t * If firmware name changed, frees firmware. As free_firmware will\n\t * reset the status to NO_FIRMWARE, this forces a new request_firmware\n\t */\n\tif (!firmware_name[0] && p->fname &&\n\t    priv->fname && strcmp(p->fname, priv->fname))\n\t\tfree_firmware(priv);\n\n\tif (priv->ctrl.max_len < 9)\n\t\tpriv->ctrl.max_len = 13;\n\n\tif (priv->state == XC2028_NO_FIRMWARE) {\n\t\tif (!firmware_name[0])\n\t\t\tpriv->fname = priv->ctrl.fname;\n\t\telse\n\t\t\tpriv->fname = firmware_name;\n\n\t\trc = request_firmware_nowait(THIS_MODULE, 1,\n\t\t\t\t\t     priv->fname,\n\t\t\t\t\t     priv->i2c_props.adap->dev.parent,\n\t\t\t\t\t     GFP_KERNEL,\n\t\t\t\t\t     fe, load_firmware_cb);\n\t\tif (rc < 0) {\n\t\t\ttuner_err(\"Failed to request firmware %s\\n\",\n\t\t\t\t  priv->fname);\n\t\t\tpriv->state = XC2028_NODEV;\n\t\t} else\n\t\t\tpriv->state = XC2028_WAITING_FIRMWARE;\n\t}\n\tmutex_unlock(&priv->lock);\n\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/8dfbcc4351a0b6d2f2d77f367552f48ffefafe18", "file_name": "drivers/media/tuners/tuner-xc2028.c", "vul_type": "cwe-416", "description": "Write a C function named `xc2028_set_config` that updates the configuration of a DVB frontend device and handles firmware requests."}
{"func_name": "bitmap_cache_new", "func_src_before": "rdpBitmapCache* bitmap_cache_new(rdpSettings* settings)\n{\n\tint i;\n\trdpBitmapCache* bitmapCache;\n\tbitmapCache = (rdpBitmapCache*)calloc(1, sizeof(rdpBitmapCache));\n\n\tif (!bitmapCache)\n\t\treturn NULL;\n\n\tbitmapCache->settings = settings;\n\tbitmapCache->update = ((freerdp*)settings->instance)->update;\n\tbitmapCache->context = bitmapCache->update->context;\n\tbitmapCache->maxCells = settings->BitmapCacheV2NumCells;\n\tbitmapCache->cells = (BITMAP_V2_CELL*)calloc(bitmapCache->maxCells, sizeof(BITMAP_V2_CELL));\n\n\tif (!bitmapCache->cells)\n\t\tgoto fail;\n\n\tfor (i = 0; i < (int)bitmapCache->maxCells; i++)\n\t{\n\t\tbitmapCache->cells[i].number = settings->BitmapCacheV2CellInfo[i].numEntries;\n\t\t/* allocate an extra entry for BITMAP_CACHE_WAITING_LIST_INDEX */\n\t\tbitmapCache->cells[i].entries =\n\t\t    (rdpBitmap**)calloc((bitmapCache->cells[i].number + 1), sizeof(rdpBitmap*));\n\n\t\tif (!bitmapCache->cells[i].entries)\n\t\t\tgoto fail;\n\t}\n\n\treturn bitmapCache;\nfail:\n\n\tif (bitmapCache->cells)\n\t{\n\t\tfor (i = 0; i < (int)bitmapCache->maxCells; i++)\n\t\t\tfree(bitmapCache->cells[i].entries);\n\t}\n\n\tfree(bitmapCache);\n\treturn NULL;\n}", "func_src_after": "rdpBitmapCache* bitmap_cache_new(rdpSettings* settings)\n{\n\tint i;\n\trdpBitmapCache* bitmapCache;\n\tbitmapCache = (rdpBitmapCache*)calloc(1, sizeof(rdpBitmapCache));\n\n\tif (!bitmapCache)\n\t\treturn NULL;\n\n\tbitmapCache->settings = settings;\n\tbitmapCache->update = ((freerdp*)settings->instance)->update;\n\tbitmapCache->context = bitmapCache->update->context;\n\tbitmapCache->cells =\n\t    (BITMAP_V2_CELL*)calloc(settings->BitmapCacheV2NumCells, sizeof(BITMAP_V2_CELL));\n\n\tif (!bitmapCache->cells)\n\t\tgoto fail;\n\tbitmapCache->maxCells = settings->BitmapCacheV2NumCells;\n\n\tfor (i = 0; i < (int)bitmapCache->maxCells; i++)\n\t{\n\t\tbitmapCache->cells[i].number = settings->BitmapCacheV2CellInfo[i].numEntries;\n\t\t/* allocate an extra entry for BITMAP_CACHE_WAITING_LIST_INDEX */\n\t\tbitmapCache->cells[i].entries =\n\t\t    (rdpBitmap**)calloc((bitmapCache->cells[i].number + 1), sizeof(rdpBitmap*));\n\n\t\tif (!bitmapCache->cells[i].entries)\n\t\t\tgoto fail;\n\t}\n\n\treturn bitmapCache;\nfail:\n\n\tif (bitmapCache->cells)\n\t{\n\t\tfor (i = 0; i < (int)bitmapCache->maxCells; i++)\n\t\t\tfree(bitmapCache->cells[i].entries);\n\t}\n\n\tfree(bitmapCache);\n\treturn NULL;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/58dc36b3c883fd460199cedb6d30e58eba58298c", "file_name": "libfreerdp/cache/bitmap.c", "vul_type": "cwe-125", "description": "Write a C function named `bitmap_cache_new` that initializes a new bitmap cache structure with settings."}
{"func_name": "fiber_switch", "func_src_before": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  if (resume && c->status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (c->status == MRB_FIBER_RUNNING || c->status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (c->status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  mrb->c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  if (c->status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    if (len >= c->stend - c->stack) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"too many arguments to fiber\");\n    }\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n  fiber_switch_context(mrb, c);\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "func_src_after": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  enum mrb_fiber_state status;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  status = c->status;\n  if (resume && status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (status == MRB_FIBER_RUNNING || status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  old_c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  fiber_switch_context(mrb, c);\n  if (status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "commit_link": "github.com/mruby/mruby/commit/778500563a9f7ceba996937dc886bd8cde29b42b", "file_name": "mrbgems/mruby-fiber/src/fiber.c", "vul_type": "cwe-125", "description": "Write a C function `fiber_switch` for the MRuby language that handles fiber resumption, argument passing, and optional VM execution."}
{"func_name": "_get_fc_wwpns", "func_src_before": "    def _get_fc_wwpns(self):\n        for key in self._storage_nodes:\n            node = self._storage_nodes[key]\n            ssh_cmd = 'svcinfo lsnode -delim ! %s' % node['id']\n            raw = self._run_ssh(ssh_cmd)\n            resp = CLIResponse(raw, delim='!', with_header=False)\n            wwpns = set(node['WWPN'])\n            for i, s in resp.select('port_id', 'port_status'):\n                if 'unconfigured' != s:\n                    wwpns.add(i)\n            node['WWPN'] = list(wwpns)\n            LOG.info(_('WWPN on node %(node)s: %(wwpn)s')\n                     % {'node': node['id'], 'wwpn': node['WWPN']})", "func_src_after": "    def _get_fc_wwpns(self):\n        for key in self._storage_nodes:\n            node = self._storage_nodes[key]\n            ssh_cmd = ['svcinfo', 'lsnode', '-delim', '!', node['id']]\n            raw = self._run_ssh(ssh_cmd)\n            resp = CLIResponse(raw, delim='!', with_header=False)\n            wwpns = set(node['WWPN'])\n            for i, s in resp.select('port_id', 'port_status'):\n                if 'unconfigured' != s:\n                    wwpns.add(i)\n            node['WWPN'] = list(wwpns)\n            LOG.info(_('WWPN on node %(node)s: %(wwpn)s')\n                     % {'node': node['id'], 'wwpn': node['WWPN']})", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "In Python, write a function to update the WWPN list of storage nodes by executing an SSH command and parsing the response."}
{"func_name": "ensure_own_repository!", "func_src_before": "  def ensure_own_repository!\n    id = params[:id] || params[:repository_id]\n    if !signed_in?\n      redirect_to root_path\n    elsif !Repository.exists?(id)\n      render 'not_found'\n    elsif !Repository.find(id).users.include?(current_user)\n      redirect_to profile_path\n    end\n  end", "func_src_after": "  def ensure_own_repository!\n    id = params[:id] || params[:repository_id]\n    if !signed_in?\n      redirect_to root_path\n    elsif !Repository.find_by(id: id)\n      render 'not_found'\n    elsif !Repository.find(id).users.include?(current_user)\n      redirect_to profile_path\n    end\n  end", "line_changes": {"deleted": [{"line_no": 5, "char_start": 123, "char_end": 157, "line": "    elsif !Repository.exists?(id)\n"}], "added": [{"line_no": 5, "char_start": 123, "char_end": 161, "line": "    elsif !Repository.find_by(id: id)\n"}]}, "char_changes": {"deleted": [{"char_start": 145, "char_end": 153, "chars": "exists?("}], "added": [{"char_start": 145, "char_end": 157, "chars": "find_by(id: "}]}, "commit_link": "github.com/schneidmaster/gitreports.com/commit/72bd8d1050930e99630887d7a4475a87fb1688d9", "file_name": "authentications_helper.rb", "vul_type": "cwe-089", "commit_msg": "Remove potential SQL injection", "description": "Write a Ruby method that checks if a user is signed in and has access to a specified repository, redirecting or rendering views based on the check."}
{"func_name": "_formatCredentials", "func_src_before": "    def _formatCredentials(self, data, name):\n        \"\"\"\n        Credentials are of the form\n        RCLONE_CONFIG_CURRENT_TYPE=s3\n            ^          ^        ^   ^\n        [mandatory  ][name  ][key][value]\n        \"\"\"\n\n        prefix = \"RCLONE_CONFIG_{}\".format(name.upper())\n\n        credentials = ''\n        credentials += \"{}_TYPE='{}' \".format(prefix, data.type)\n\n        def _addCredential(credentials, env_key, data_key):\n            value = getattr(data, data_key, None)\n            if value is not None:\n                credentials += \"{}='{}' \".format(env_key, value)\n            return credentials\n\n\n        if data.type == 's3':\n            credentials = _addCredential(credentials,\n                '{}_REGION'.format(prefix),\n                's3_region'\n            )\n            credentials = _addCredential(credentials,\n                '{}_ACCESS_KEY_ID'.format(prefix),\n                's3_access_key_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SECRET_ACCESS_KEY'.format(prefix),\n                's3_secret_access_key'\n            )\n\n            credentials = _addCredential(credentials,\n                '{}_ENDPOINT'.format(prefix),\n                's3_endpoint'\n            )\n            credentials = _addCredential(credentials,\n                '{}_V2_AUTH'.format(prefix),\n                's3_v2_auth'\n            )\n\n        elif data.type == 'azureblob':\n            credentials = _addCredential(credentials,\n                '{}_ACCOUNT'.format(prefix),\n                'azure_account'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'azure_key'\n            )\n\n        elif data.type == 'swift':\n            credentials = _addCredential(credentials,\n                '{}_USER'.format(prefix),\n                'swift_user'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'swift_key'\n            )\n            credentials = _addCredential(credentials,\n                '{}_AUTH'.format(prefix),\n                'swift_auth'\n            )\n            credentials = _addCredential(credentials,\n                '{}_TENANT'.format(prefix),\n                'swift_tenant'\n            )\n\n        elif data.type == 'google cloud storage':\n            credentials = _addCredential(credentials,\n                '{}_CLIENT_ID'.format(prefix),\n                'gcp_client_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SERVICE_ACCOUNT_CREDENTIALS'.format(prefix),\n                'gcp_service_account_credentials'\n            )\n            credentials = _addCredential(credentials,\n                '{}_PROJECT_NUMBER'.format(prefix),\n                'gcp_project_number'\n            )\n            credentials = _addCredential(credentials,\n                '{}_OBJECT_ACL'.format(prefix),\n                'gcp_object_acl'\n            )\n            credentials = _addCredential(credentials,\n                '{}_BUCKET_ACL'.format(prefix),\n                'gcp_bucket_acl'\n            )\n\n        else:\n            logging.error(\"Connection type unknown: {}\".format(data.type))\n\n        return credentials", "func_src_after": "    def _formatCredentials(self, data, name):\n        \"\"\"\n        Credentials are of the form\n        RCLONE_CONFIG_CURRENT_TYPE=s3\n            ^          ^        ^   ^\n        [mandatory  ][name  ][key][value]\n        \"\"\"\n\n        prefix = \"RCLONE_CONFIG_{}\".format(name.upper())\n\n        credentials = {}\n        credentials['{}_TYPE'.format(prefix)] = data.type\n\n        def _addCredential(credentials, env_key, data_key):\n            value = getattr(data, data_key, None)\n            if value is not None:\n                credentials[env_key] = value\n            return credentials\n\n\n        if data.type == 's3':\n            credentials = _addCredential(credentials,\n                '{}_REGION'.format(prefix),\n                's3_region'\n            )\n            credentials = _addCredential(credentials,\n                '{}_ACCESS_KEY_ID'.format(prefix),\n                's3_access_key_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SECRET_ACCESS_KEY'.format(prefix),\n                's3_secret_access_key'\n            )\n\n            credentials = _addCredential(credentials,\n                '{}_ENDPOINT'.format(prefix),\n                's3_endpoint'\n            )\n            credentials = _addCredential(credentials,\n                '{}_V2_AUTH'.format(prefix),\n                's3_v2_auth'\n            )\n\n        elif data.type == 'azureblob':\n            credentials = _addCredential(credentials,\n                '{}_ACCOUNT'.format(prefix),\n                'azure_account'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'azure_key'\n            )\n\n        elif data.type == 'swift':\n            credentials = _addCredential(credentials,\n                '{}_USER'.format(prefix),\n                'swift_user'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'swift_key'\n            )\n            credentials = _addCredential(credentials,\n                '{}_AUTH'.format(prefix),\n                'swift_auth'\n            )\n            credentials = _addCredential(credentials,\n                '{}_TENANT'.format(prefix),\n                'swift_tenant'\n            )\n\n        elif data.type == 'google cloud storage':\n            credentials = _addCredential(credentials,\n                '{}_CLIENT_ID'.format(prefix),\n                'gcp_client_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SERVICE_ACCOUNT_CREDENTIALS'.format(prefix),\n                'gcp_service_account_credentials'\n            )\n            credentials = _addCredential(credentials,\n                '{}_PROJECT_NUMBER'.format(prefix),\n                'gcp_project_number'\n            )\n            credentials = _addCredential(credentials,\n                '{}_OBJECT_ACL'.format(prefix),\n                'gcp_object_acl'\n            )\n            credentials = _addCredential(credentials,\n                '{}_BUCKET_ACL'.format(prefix),\n                'gcp_bucket_acl'\n            )\n\n        else:\n            logging.error(\"Connection type unknown: {}\".format(data.type))\n\n        return credentials", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function to format cloud storage credentials into a string or dictionary based on the storage type."}
{"func_name": "read_body", "func_src_before": "  def read_body\n    raise Mechanize::ResponseCodeError.new(self) unless\n      File.exist? @file_path\n\n    if directory?\n      yield dir_body\n    else\n      open @file_path, 'rb' do |io|\n        yield io.read\n      end\n    end\n  end", "func_src_after": "  def read_body\n    raise Mechanize::ResponseCodeError.new(self) unless\n      File.exist? @file_path\n\n    if directory?\n      yield dir_body\n    else\n      ::File.open(@file_path, 'rb') do |io|\n        yield io.read\n      end\n    end\n  end", "line_changes": {"deleted": [{"line_no": 8, "char_start": 150, "char_end": 186, "line": "      open @file_path, 'rb' do |io|\n"}], "added": [{"line_no": 8, "char_start": 150, "char_end": 194, "line": "      ::File.open(@file_path, 'rb') do |io|\n"}]}, "char_changes": {"deleted": [{"char_start": 160, "char_end": 161, "chars": " "}], "added": [{"char_start": 156, "char_end": 163, "chars": "::File."}, {"char_start": 167, "char_end": 168, "chars": "("}, {"char_start": 184, "char_end": 185, "chars": ")"}]}, "commit_link": "github.com/sparklemotion/mechanize/commit/63f8779e49664d5e95fae8d42d04c8e373162b3c", "file_name": "file_response.rb", "vul_type": "cwe-078", "commit_msg": "fix(security): prevent command injection in FileResponse#read_body\n\nAlso add general test coverage for FileResponse#read_body\n\nRelated to https://github.com/sparklemotion/mechanize/security/advisories/GHSA-qrqm-fpv6-6r8g", "description": "Write a Ruby method named `read_body` that yields the contents of a file or directory if it exists, otherwise raises an error."}
{"func_name": "ac_circ_buf_popm", "func_src_before": "int ac_circ_buf_popm(ac_circ_buf_t *cbuf, void *buf, u32 count)\n{\n\tif (circ_count_to_end(cbuf) < count)\n\t\treturn -1;\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(buf, cbuf->buf.ptr_buf + cbuf->tail,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(buf, cbuf->buf.cpy_buf + cbuf->tail,\n\t\t       count * cbuf->elem_sz);\n\n\tcbuf->tail = (cbuf->tail + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "func_src_after": "int ac_circ_buf_popm(ac_circ_buf_t *cbuf, void *buf, u32 count)\n{\n\tif (circ_count_to_end(cbuf) < count)\n\t\treturn -1;\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(buf, cbuf->buf.ptr_buf + cbuf->tail,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(buf, cbuf->buf.cpy_buf + cbuf->tail,\n\t\t       (size_t)count * cbuf->elem_sz);\n\n\tcbuf->tail = (cbuf->tail + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 278, "char_end": 311, "line": "\t\t       count * cbuf->elem_sz);\n"}], "added": [{"line_no": 11, "char_start": 278, "char_end": 319, "line": "\t\t       (size_t)count * cbuf->elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 287, "char_end": 295, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to remove multiple elements from a circular buffer and copy them into another buffer."}
{"func_name": "pr_init", "func_src_before": "function pr_init() {\n\tif( document.getElementById( 'pr_container' ) ) {\n\t\treturn;\n\t}\n\n\tif( document.URL.indexOf( 'action=protect' ) > 0 || document.URL.indexOf( 'action=unprotect' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=delete' ) > 0 || document.URL.indexOf( 'action=undelete' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=watch' ) > 0 || document.URL.indexOf( 'action=unwatch' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=history' ) > 0 ) {\n\t\treturn;\n\t}\n\n\t/* check if external URL is provided */\n\tif( !self.proofreadPageThumbURL ) {\n\t\tvar text = document.getElementById( 'wpTextbox1' );\n\t\tif ( text ) {\n\t\t\tvar proofreadPageIsEdit = true;\n\t\t\tre = /<span class=\"hiddenStructure\" id=\"pageURL\">\\[http:\\/\\/(.*?)\\]<\\/span>/;\n\t\t\tm = re.exec( text.value );\n\t\t\tif( m ) {\n\t\t\t\tself.proofreadPageExternalURL = 'http://' + m[1];\n\t\t\t}\n\t\t} else {\n\t\t\tvar proofreadPageIsEdit = false;\n\t\t\ttext = document.getElementById( 'bodyContent' );\n\t\t\ttry {\n\t\t\t\tvar a = document.getElementById( 'pageURL' );\n\t\t\t\tvar b = a.firstChild;\n\t\t\t\tself.proofreadPageExternalURL = b.getAttribute( 'href' );\n\t\t\t} catch( err ) {\n\t\t\t};\n\t\t}\n\t\t// set to dummy values, not used\n\t\tself.proofreadPageWidth = 400;\n\t\tself.proofreadPageHeight = 400;\n\t}\n\n\tif( !self.proofreadPageThumbURL ) {\n\t\treturn;\n\t}\n\n\tif( self.proofreadpage_setup ) {\n\t\tproofreadpage_setup(\n\t\t\tproofreadPageWidth,\n\t\t\tproofreadPageHeight,\n\t\t\tproofreadPageIsEdit\n\t\t);\n\t} else {\n\t\tpr_setup();\n\t}\n\n\t// add CSS classes to the container div\n\tvar c = document.getElementById( 'pagequality' );\n\tif( c ) {\n\t\tc = c.nextSibling;\n\t\tif( c.className == 'pagetext' ) {\n\t\t\tc.className += ' ' + self.proofreadPageCss;\n\t\t}\n\t}\n}\n\n$(document).ready( pr_init );\n$(document).ready( pr_init_tabs );\n$(document).ready( pr_initzoom );\n\n\n/* Quality buttons */\nself.pr_add_quality = function( form, value ) {\n\tself.proofreadpage_quality = value;\n\tself.proofreadpage_username = proofreadPageUserName;\n\tvar text = '';\n\tswitch( value ) {\n\t\tcase 0:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality0_category' );\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality1_category' );\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality2_category' );\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality3_category' );\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality4_category' );\n\t\t\tbreak;\n\t}\n\tform.elements['wpSummary'].value = '/* ' + text + ' */ ';\n\tform.elements['wpProofreader'].value = self.proofreadpage_username;\n};\n\nfunction pr_add_quality_buttons() {\n\tvar ig = document.getElementById( 'wpWatchthis' );\n\tif( !ig ) {\n\t\tig = document.getElementById( 'wpSummary' );\n\t}\n\tif( !ig ) {\n\t\treturn;\n\t}\n\tvar f = document.createElement( 'span' );\n\tig.parentNode.insertBefore( f, ig.nextSibling.nextSibling.nextSibling );\n\n\tif( !proofreadPageAddButtons ) {\n\t\tf.innerHTML =\n\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">' +\n\t\t\t'<input type=\"hidden\" name=\"quality\" value=' + self.proofreadpage_quality + ' >';\n\t\treturn;\n\t}\n\n\tf.innerHTML =\n' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">'\n+'<span class=\"quality0\"> <input type=\"radio\" name=\"quality\" value=0 onclick=\"pr_add_quality(this.form,0)\" tabindex=4> </span>'\n+'<span class=\"quality2\"> <input type=\"radio\" name=\"quality\" value=2 onclick=\"pr_add_quality(this.form,2)\" tabindex=4> </span>'\n+'<span class=\"quality1\"> <input type=\"radio\" name=\"quality\" value=1 onclick=\"pr_add_quality(this.form,1)\" tabindex=4> </span>'\n+'<span class=\"quality3\"> <input type=\"radio\" name=\"quality\" value=3 onclick=\"pr_add_quality(this.form,3)\" tabindex=4> </span>'\n+'<span class=\"quality4\"> <input type=\"radio\" name=\"quality\" value=4 onclick=\"pr_add_quality(this.form,4)\" tabindex=4> </span>';\n\tf.innerHTML = f.innerHTML + '&nbsp;' + escapeQuotesHTML( mediaWiki.msg( 'proofreadpage_page_status' ) );\n\n\tif( !( ( self.proofreadpage_quality == 4 ) || ( ( self.proofreadpage_quality == 3 ) && ( self.proofreadpage_username != proofreadPageUserName ) ) ) ) {\n\t\tdocument.editform.quality[4].parentNode.style.cssText = 'display:none';\n\t\tdocument.editform.quality[4].disabled = true;\n\t}\n\tswitch( self.proofreadpage_quality ) {\n\t\tcase 4:\n\t\t\tdocument.editform.quality[4].checked = true;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tdocument.editform.quality[3].checked = true;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tdocument.editform.quality[2].checked = true;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdocument.editform.quality[1].checked = true;\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tdocument.editform.quality[0].checked = true;\n\t\t\tbreak;\n\t}", "func_src_after": "function pr_init() {\n\tif( document.getElementById( 'pr_container' ) ) {\n\t\treturn;\n\t}\n\n\tif( document.URL.indexOf( 'action=protect' ) > 0 || document.URL.indexOf( 'action=unprotect' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=delete' ) > 0 || document.URL.indexOf( 'action=undelete' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=watch' ) > 0 || document.URL.indexOf( 'action=unwatch' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=history' ) > 0 ) {\n\t\treturn;\n\t}\n\n\t/* check if external URL is provided */\n\tif( !self.proofreadPageThumbURL ) {\n\t\tvar text = document.getElementById( 'wpTextbox1' );\n\t\tif ( text ) {\n\t\t\tvar proofreadPageIsEdit = true;\n\t\t\tre = /<span class=\"hiddenStructure\" id=\"pageURL\">\\[http:\\/\\/(.*?)\\]<\\/span>/;\n\t\t\tm = re.exec( text.value );\n\t\t\tif( m ) {\n\t\t\t\tself.proofreadPageExternalURL = 'http://' + m[1];\n\t\t\t}\n\t\t} else {\n\t\t\tvar proofreadPageIsEdit = false;\n\t\t\ttext = document.getElementById( 'bodyContent' );\n\t\t\ttry {\n\t\t\t\tvar a = document.getElementById( 'pageURL' );\n\t\t\t\tvar b = a.firstChild;\n\t\t\t\tself.proofreadPageExternalURL = b.getAttribute( 'href' );\n\t\t\t} catch( err ) {\n\t\t\t};\n\t\t}\n\t\t// set to dummy values, not used\n\t\tself.proofreadPageWidth = 400;\n\t\tself.proofreadPageHeight = 400;\n\t}\n\n\tif( !self.proofreadPageThumbURL ) {\n\t\treturn;\n\t}\n\n\tif( self.proofreadpage_setup ) {\n\t\tproofreadpage_setup(\n\t\t\tproofreadPageWidth,\n\t\t\tproofreadPageHeight,\n\t\t\tproofreadPageIsEdit\n\t\t);\n\t} else {\n\t\tpr_setup();\n\t}\n\n\t// add CSS classes to the container div\n\tvar c = document.getElementById( 'pagequality' );\n\tif( c ) {\n\t\tc = c.nextSibling;\n\t\tif( c.className == 'pagetext' ) {\n\t\t\tc.className += ' ' + self.proofreadPageCss;\n\t\t}\n\t}\n}\n\n$(document).ready( pr_init );\n$(document).ready( pr_init_tabs );\n$(document).ready( pr_initzoom );\n\n\n/* Quality buttons */\nself.pr_add_quality = function( form, value ) {\n\tself.proofreadpage_quality = value;\n\tself.proofreadpage_username = proofreadPageUserName;\n\tvar text = '';\n\tswitch( value ) {\n\t\tcase 0:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality0_category' );\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality1_category' );\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality2_category' );\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality3_category' );\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality4_category' );\n\t\t\tbreak;\n\t}\n\tform.elements['wpSummary'].value = '/* ' + text + ' */ ';\n\tform.elements['wpProofreader'].value = self.proofreadpage_username;\n};\n\nfunction pr_add_quality_buttons() {\n\tvar ig = document.getElementById( 'wpWatchthis' );\n\tif( !ig ) {\n\t\tig = document.getElementById( 'wpSummary' );\n\t}\n\tif( !ig ) {\n\t\treturn;\n\t}\n\tvar f = document.createElement( 'span' );\n\tig.parentNode.insertBefore( f, ig.nextSibling.nextSibling.nextSibling );\n\n\tif( !proofreadPageAddButtons ) {\n\t\tf.innerHTML =\n\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">' +\n\t\t\t'<input type=\"hidden\" name=\"quality\" value=\"' + escapeQuotesHTML( self.proofreadpage_quality ) + '\" >';\n\t\treturn;\n\t}\n\n\tf.innerHTML =\n' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">'\n+'<span class=\"quality0\"> <input type=\"radio\" name=\"quality\" value=0 onclick=\"pr_add_quality(this.form,0)\" tabindex=4> </span>'\n+'<span class=\"quality2\"> <input type=\"radio\" name=\"quality\" value=2 onclick=\"pr_add_quality(this.form,2)\" tabindex=4> </span>'\n+'<span class=\"quality1\"> <input type=\"radio\" name=\"quality\" value=1 onclick=\"pr_add_quality(this.form,1)\" tabindex=4> </span>'\n+'<span class=\"quality3\"> <input type=\"radio\" name=\"quality\" value=3 onclick=\"pr_add_quality(this.form,3)\" tabindex=4> </span>'\n+'<span class=\"quality4\"> <input type=\"radio\" name=\"quality\" value=4 onclick=\"pr_add_quality(this.form,4)\" tabindex=4> </span>';\n\tf.innerHTML = f.innerHTML + '&nbsp;' + escapeQuotesHTML( mediaWiki.msg( 'proofreadpage_page_status' ) );\n\n\tif( !( ( self.proofreadpage_quality == 4 ) || ( ( self.proofreadpage_quality == 3 ) && ( self.proofreadpage_username != proofreadPageUserName ) ) ) ) {\n\t\tdocument.editform.quality[4].parentNode.style.cssText = 'display:none';\n\t\tdocument.editform.quality[4].disabled = true;\n\t}\n\tswitch( self.proofreadpage_quality ) {\n\t\tcase 4:\n\t\t\tdocument.editform.quality[4].checked = true;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tdocument.editform.quality[3].checked = true;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tdocument.editform.quality[2].checked = true;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdocument.editform.quality[1].checked = true;\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tdocument.editform.quality[0].checked = true;\n\t\t\tbreak;\n\t}", "line_changes": {"deleted": [{"line_no": 112, "char_start": 2862, "char_end": 2957, "line": "\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">' +\n"}, {"line_no": 113, "char_start": 2957, "char_end": 3042, "line": "\t\t\t'<input type=\"hidden\" name=\"quality\" value=' + self.proofreadpage_quality + ' >';\n"}, {"line_no": 118, "char_start": 3071, "char_end": 3161, "line": "' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">'\n"}], "added": [{"line_no": 112, "char_start": 2862, "char_end": 2977, "line": "\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">' +\n"}, {"line_no": 113, "char_start": 2977, "char_end": 3084, "line": "\t\t\t'<input type=\"hidden\" name=\"quality\" value=\"' + escapeQuotesHTML( self.proofreadpage_quality ) + '\" >';\n"}, {"line_no": 118, "char_start": 3113, "char_end": 3223, "line": "' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">'\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2919, "char_end": 2937, "chars": " escapeQuotesHTML("}, {"char_start": 2965, "char_end": 2967, "chars": " )"}, {"char_start": 3023, "char_end": 3024, "chars": "\""}, {"char_start": 3027, "char_end": 3045, "chars": " escapeQuotesHTML("}, {"char_start": 3072, "char_end": 3074, "chars": " )"}, {"char_start": 3078, "char_end": 3079, "chars": "\""}, {"char_start": 3167, "char_end": 3185, "chars": " escapeQuotesHTML("}, {"char_start": 3213, "char_end": 3215, "chars": " )"}]}, "commit_link": "github.com/wikimedia/mediawiki-extensions-ProofreadPage/commit/708bec1ccb45895fe3e6e15d9df454d44f9966f3", "file_name": "proofread.js", "vul_type": "cwe-079", "commit_msg": "ProofreadPage: Fix stored XSS in edit form. Report and patch by Bawolff", "description": "Write JavaScript code to initialize a page and add quality control buttons based on certain conditions."}
{"func_name": "load", "func_src_before": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n        return PGMPomegranate(pgm_model)", "func_src_after": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(f.read())\n        return PGMPomegranate(pgm_model)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 413, "char_end": 483, "line": "                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n"}], "added": [{"line_no": 10, "char_start": 413, "char_end": 477, "line": "                pgm_model = BayesianNetwork.from_json(f.read())\n"}]}, "char_changes": {"deleted": [{"char_start": 467, "char_end": 476, "chars": "pickle.lo"}, {"char_start": 479, "char_end": 480, "chars": "f"}], "added": [{"char_start": 467, "char_end": 471, "chars": "f.re"}]}, "commit_link": "github.com/sara-02/fabric8-analytics-stack-analysis/commit/c9422e6257a8c927aed2999a0f4cc77f90059cda", "file_name": "pgm_pomegranate.py", "vul_type": "cwe-502", "commit_msg": "Remove pickling of model\n\nThe model is already being converted to a JSON(using the `to_json`)\nfunction of pomegranate which is already a stadard serialized format.\nI don't see a need to further serialize the JSON using pickle to\nsomething that can be loaded only using Python. This also helps us\nreduce the training time of the model as pickling and unpickling\nhas a overhead that I don't see a need for, because JSON.", "parent_commit": "c2ddf128d7206a0a85929b6f2a08078433ce1577", "description": "Create a Python method that loads a probabilistic graphical model from a local or S3 data store based on the provided filename."}
{"func_name": "write_section", "func_src_before": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = section_data[key]\n            self.icinga_lines.append((\"%s%-45s%s\" % (self.indent, key, self.value_to_icinga(value))))\n        self.write_line(\"}\")", "func_src_after": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = self.value_to_icinga(section_data[key])\n            icinga_line = \"%s%-45s%s\" % (self.indent, key, value)\n\n            if \"\\n\" in icinga_line or \"}\" in icinga_line:\n                msg = \"Found forbidden newline or '}' character in section %r.\"\n                raise Exception(msg % section_name)\n\n            self.icinga_lines.append(icinga_line)\n        self.write_line(\"}\")", "commit_link": "github.com/Scout24/monitoring-config-generator/commit/a4b01b72d2e3d6ec2600c384a77f675fa9bbf6b7", "file_name": "src/main/python/monitoring_config_generator/MonitoringConfigGenerator.py", "vul_type": "cwe-078", "description": "In Python, write a function to format and append a configuration section with sorted keys to a list, ensuring no newlines or closing braces are present in the values."}
{"func_name": "candidate_paths_for_url", "func_src_before": "    def candidate_paths_for_url(self, url):\n        for root, prefix in self.directories:\n            if url.startswith(prefix):\n                yield os.path.join(root, url[len(prefix):])", "func_src_after": "    def candidate_paths_for_url(self, url):\n        for root, prefix in self.directories:\n            if url.startswith(prefix):\n                path = os.path.join(root, url[len(prefix):])\n                if os.path.commonprefix((root, path)) == root:\n                    yield path", "commit_link": "github.com/evansd/whitenoise/commit/4d8a3ab1e97d7ddb18b3fa8b4909c92bad5529c6", "file_name": "whitenoise/base.py", "vul_type": "cwe-022", "description": "Write a Python function that yields file system paths corresponding to a given URL based on predefined directory mappings."}
{"func_name": "misc_file_checks", "func_src_before": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Deprecated usage of 'add_header' in nginx conf\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            if not os.path.isfile(self.path + \"/conf/\" + filename):\n                continue\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )", "func_src_after": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Analyze nginx conf\n        # - Deprecated usage of 'add_header' in nginx conf\n        # - Spot path traversal issue vulnerability\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            # Ignore subdirs or filename not containing nginx in the name\n            if not os.path.isfile(self.path + \"/conf/\" + filename) or \"nginx\" not in filename:\n                continue\n\n            #\n            # 'add_header' usage\n            #\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )\n\n            #\n            # Path traversal issues\n            #\n            lines = open(self.path + \"/conf/\" + filename).readlines()\n            lines = [line.strip() for line in lines if not line.strip().startswith(\"#\")]\n            # Let's find the first location line\n            location_line = None\n            path_traversal_vulnerable = False\n            lines_iter = lines.__iter__()\n            for line in lines_iter:\n                if line.startswith(\"location\"):\n                    location_line = line\n                    break\n            # Look at the next lines for an 'alias' directive\n            if location_line is not None:\n                for line in lines_iter:\n                    if line.startswith(\"location\"):\n                        # Entering a new location block ... abort here\n                        # and assume there's no alias block later...\n                        break\n                    if line.startswith(\"alias\"):\n                        # We should definitely check for path traversal issue\n                        # Does the location target ends with / ?\n                        target = location_line.split()[-2]\n                        if not target.endswith(\"/\"):\n                            path_traversal_vulnerable = True\n                        break\n            if path_traversal_vulnerable:\n                print_warning(\n                    \"The nginx configuration appears vulnerable to path traversal as explained in \"\n                    \"https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/\\n\"\n                    \"To fix it, look at the first lines of the nginx conf of the example app : \"\n                    \"https://github.com/YunoHost/example_ynh/blob/master/conf/nginx.conf\"\n                )", "commit_link": "github.com/YunoHost/package_linter/commit/f6e98894cfe841aedaa7efd590937f0255193913", "file_name": "package_linter.py", "vul_type": "cwe-022", "description": "Write a Python function to check for mandatory files, deprecated configurations, and potential vulnerabilities in a project's file structure and configurations."}
{"func_name": "jbig2_image_compose", "func_src_before": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "func_src_after": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    if ((UINT32_MAX - src->width  < (x > 0 ? x : -x)) ||\n        (UINT32_MAX - src->height < (y > 0 ? y : -y)))\n    {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"overflow in compose_image\");\n#endif\n        return 0;\n    }\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "commit_link": "github.com/ArtifexSoftware/jbig2dec/commit/0726320a4b55078e9d8deb590e477d598b3da66e", "file_name": "jbig2_image.c", "vul_type": "cwe-787", "description": "Write a C function to overlay one image onto another at a specified position using a given composition operation."}
{"func_name": "link_dialog", "func_src_before": "def link_dialog(request):\n    # list of wiki pages\n    name = request.values.get(\"pagename\", \"\")\n    if name:\n        from MoinMoin import search\n        # XXX error handling!\n        searchresult = search.searchPages(request, 't:\"%s\"' % name)\n\n        pages = [p.page_name for p in searchresult.hits]\n        pages.sort()\n        pages[0:0] = [name]\n        page_list = '''\n         <tr>\n          <td colspan=2>\n           <select id=\"sctPagename\" size=\"1\" onchange=\"OnChangePagename(this.value);\">\n           %s\n           </select>\n          <td>\n         </tr>\n''' % \"\\n\".join(['<option value=\"%s\">%s</option>' % (wikiutil.escape(page), wikiutil.escape(page))\n                 for page in pages])\n    else:\n        page_list = \"\"\n\n    # list of interwiki names\n    interwiki_list = wikiutil.load_wikimap(request)\n    interwiki = interwiki_list.keys()\n    interwiki.sort()\n    iwpreferred = request.cfg.interwiki_preferred[:]\n    if not iwpreferred or iwpreferred and iwpreferred[-1] is not None:\n        resultlist = iwpreferred\n        for iw in interwiki:\n            if not iw in iwpreferred:\n                resultlist.append(iw)\n    else:\n        resultlist = iwpreferred[:-1]\n    interwiki = \"\\n\".join(\n        ['<option value=\"%s\">%s</option>' % (wikiutil.escape(key), wikiutil.escape(key))\n         for key in resultlist])\n\n    # wiki url\n    url_prefix_static = request.cfg.url_prefix_static\n    scriptname = request.script_root + '/'\n    action = scriptname\n    basepage = wikiutil.escape(request.page.page_name)\n    request.write(u'''\n<!--\n * FCKeditor - The text editor for internet\n * Copyright (C) 2003-2004 Frederico Caldeira Knabben\n *\n * Licensed under the terms of the GNU Lesser General Public License:\n *   http://www.opensource.org/licenses/lgpl-license.php\n *\n * For further information visit:\n *   http://www.fckeditor.net/\n *\n * File Name: fck_link.html\n *  Link dialog window.\n *\n * Version:  2.0 FC (Preview)\n * Modified: 2005-02-18 23:55:22\n *\n * File Authors:\n *   Frederico Caldeira Knabben (fredck@fckeditor.net)\n-->\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n<meta name=\"robots\" content=\"index,nofollow\">\n<html>\n <head>\n  <title>Link Properties</title>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"robots\" content=\"noindex,nofollow\" />\n  <script src=\"%(url_prefix_static)s/applets/FCKeditor/editor/dialog/common/fck_dialog_common.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinlink/fck_link.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinurllib.js\" type=\"text/javascript\"></script>\n </head>\n <body scroll=\"no\" style=\"OVERFLOW: hidden\">\n  <div id=\"divInfo\" style=\"DISPLAY: none\">\n   <span fckLang=\"DlgLnkType\">Link Type</span><br />\n   <select id=\"cmbLinkType\" onchange=\"SetLinkType(this.value);\">\n    <option value=\"wiki\" selected=\"selected\">WikiPage</option>\n    <option value=\"interwiki\">Interwiki</option>\n    <option value=\"url\" fckLang=\"DlgLnkTypeURL\">URL</option>\n   </select>\n   <br />\n   <br />\n   <div id=\"divLinkTypeWiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <form action=%(action)s method=\"GET\">\n       <input type=\"hidden\" name=\"action\" value=\"fckdialog\">\n       <input type=\"hidden\" name=\"dialog\" value=\"link\">\n       <input type=\"hidden\" id=\"basepage\" name=\"basepage\" value=\"%(basepage)s\">\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"PageDlgName\">Page Name</span><br>\n          <input id=\"txtPagename\" name=\"pagename\" size=\"30\" value=\"%(name)s\">\n         </td>\n         <td valign=\"bottom\">\n           <input id=btnSearchpage type=\"submit\" value=\"Search\">\n         </td>\n        </tr>\n        %(page_list)s\n       </table>\n       </form>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeInterwiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"WikiDlgName\">Wiki:PageName</span><br>\n          <select id=\"sctInterwiki\" size=\"1\">\n          %(interwiki)s\n          </select>:\n          <input id=\"txtInterwikipagename\"></input>\n         </td>\n        </tr>\n       </table>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeUrl\">\n    <table cellspacing=\"0\" cellpadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td nowrap=\"nowrap\">\n       <span fckLang=\"DlgLnkProto\">Protocol</span><br />\n       <select id=\"cmbLinkProtocol\">\n        <option value=\"http://\" selected=\"selected\">http://</option>\n        <option value=\"https://\">https://</option>\n        <option value=\"ftp://\">ftp://</option>\n        <option value=\"file://\">file://</option>\n        <option value=\"news://\">news://</option>\n        <option value=\"mailto:\">mailto:</option>\n        <option value=\"\" fckLang=\"DlgLnkProtoOther\">&lt;other&gt;</option>\n       </select>\n      </td>\n      <td nowrap=\"nowrap\">&nbsp;</td>\n      <td nowrap=\"nowrap\" width=\"100%%\">\n       <span fckLang=\"DlgLnkURL\">URL</span><br />\n       <input id=\"txtUrl\" style=\"WIDTH: 100%%\" type=\"text\" onkeyup=\"OnUrlChange();\" onchange=\"OnUrlChange();\" />\n      </td>\n     </tr>\n    </table>\n    <br />\n   </div>\n  </div>\n </body>\n</html>\n''' % locals())", "func_src_after": "def link_dialog(request):\n    # list of wiki pages\n    name = request.values.get(\"pagename\", \"\")\n    name_escaped = wikiutil.escape(name)\n    if name:\n        from MoinMoin import search\n        # XXX error handling!\n        searchresult = search.searchPages(request, 't:\"%s\"' % name)\n\n        pages = [p.page_name for p in searchresult.hits]\n        pages.sort()\n        pages[0:0] = [name]\n        page_list = '''\n         <tr>\n          <td colspan=2>\n           <select id=\"sctPagename\" size=\"1\" onchange=\"OnChangePagename(this.value);\">\n           %s\n           </select>\n          <td>\n         </tr>\n''' % \"\\n\".join(['<option value=\"%s\">%s</option>' % (wikiutil.escape(page), wikiutil.escape(page))\n                 for page in pages])\n    else:\n        page_list = \"\"\n\n    # list of interwiki names\n    interwiki_list = wikiutil.load_wikimap(request)\n    interwiki = interwiki_list.keys()\n    interwiki.sort()\n    iwpreferred = request.cfg.interwiki_preferred[:]\n    if not iwpreferred or iwpreferred and iwpreferred[-1] is not None:\n        resultlist = iwpreferred\n        for iw in interwiki:\n            if not iw in iwpreferred:\n                resultlist.append(iw)\n    else:\n        resultlist = iwpreferred[:-1]\n    interwiki = \"\\n\".join(\n        ['<option value=\"%s\">%s</option>' % (wikiutil.escape(key), wikiutil.escape(key))\n         for key in resultlist])\n\n    # wiki url\n    url_prefix_static = request.cfg.url_prefix_static\n    scriptname = request.script_root + '/'\n    action = scriptname\n    basepage = wikiutil.escape(request.page.page_name)\n    request.write(u'''\n<!--\n * FCKeditor - The text editor for internet\n * Copyright (C) 2003-2004 Frederico Caldeira Knabben\n *\n * Licensed under the terms of the GNU Lesser General Public License:\n *   http://www.opensource.org/licenses/lgpl-license.php\n *\n * For further information visit:\n *   http://www.fckeditor.net/\n *\n * File Name: fck_link.html\n *  Link dialog window.\n *\n * Version:  2.0 FC (Preview)\n * Modified: 2005-02-18 23:55:22\n *\n * File Authors:\n *   Frederico Caldeira Knabben (fredck@fckeditor.net)\n-->\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n<meta name=\"robots\" content=\"index,nofollow\">\n<html>\n <head>\n  <title>Link Properties</title>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"robots\" content=\"noindex,nofollow\" />\n  <script src=\"%(url_prefix_static)s/applets/FCKeditor/editor/dialog/common/fck_dialog_common.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinlink/fck_link.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinurllib.js\" type=\"text/javascript\"></script>\n </head>\n <body scroll=\"no\" style=\"OVERFLOW: hidden\">\n  <div id=\"divInfo\" style=\"DISPLAY: none\">\n   <span fckLang=\"DlgLnkType\">Link Type</span><br />\n   <select id=\"cmbLinkType\" onchange=\"SetLinkType(this.value);\">\n    <option value=\"wiki\" selected=\"selected\">WikiPage</option>\n    <option value=\"interwiki\">Interwiki</option>\n    <option value=\"url\" fckLang=\"DlgLnkTypeURL\">URL</option>\n   </select>\n   <br />\n   <br />\n   <div id=\"divLinkTypeWiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <form action=%(action)s method=\"GET\">\n       <input type=\"hidden\" name=\"action\" value=\"fckdialog\">\n       <input type=\"hidden\" name=\"dialog\" value=\"link\">\n       <input type=\"hidden\" id=\"basepage\" name=\"basepage\" value=\"%(basepage)s\">\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"PageDlgName\">Page Name</span><br>\n          <input id=\"txtPagename\" name=\"pagename\" size=\"30\" value=\"%(name_escaped)s\">\n         </td>\n         <td valign=\"bottom\">\n           <input id=btnSearchpage type=\"submit\" value=\"Search\">\n         </td>\n        </tr>\n        %(page_list)s\n       </table>\n       </form>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeInterwiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"WikiDlgName\">Wiki:PageName</span><br>\n          <select id=\"sctInterwiki\" size=\"1\">\n          %(interwiki)s\n          </select>:\n          <input id=\"txtInterwikipagename\"></input>\n         </td>\n        </tr>\n       </table>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeUrl\">\n    <table cellspacing=\"0\" cellpadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td nowrap=\"nowrap\">\n       <span fckLang=\"DlgLnkProto\">Protocol</span><br />\n       <select id=\"cmbLinkProtocol\">\n        <option value=\"http://\" selected=\"selected\">http://</option>\n        <option value=\"https://\">https://</option>\n        <option value=\"ftp://\">ftp://</option>\n        <option value=\"file://\">file://</option>\n        <option value=\"news://\">news://</option>\n        <option value=\"mailto:\">mailto:</option>\n        <option value=\"\" fckLang=\"DlgLnkProtoOther\">&lt;other&gt;</option>\n       </select>\n      </td>\n      <td nowrap=\"nowrap\">&nbsp;</td>\n      <td nowrap=\"nowrap\" width=\"100%%\">\n       <span fckLang=\"DlgLnkURL\">URL</span><br />\n       <input id=\"txtUrl\" style=\"WIDTH: 100%%\" type=\"text\" onkeyup=\"OnUrlChange();\" onchange=\"OnUrlChange();\" />\n      </td>\n     </tr>\n    </table>\n    <br />\n   </div>\n  </div>\n </body>\n</html>\n''' % locals())", "commit_link": "github.com/moinwiki/moin-1.9/commit/70955a8eae091cc88fd9a6e510177e70289ec024", "file_name": "MoinMoin/action/fckdialog.py", "vul_type": "cwe-079", "description": "Generate a Python function named `link_dialog` that creates a link dialog interface for a wiki page using the MoinMoin framework."}
{"func_name": "ipv4_pktinfo_prepare", "func_src_before": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\tskb_dst_drop(skb);\n}", "func_src_after": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\t/* We need to keep the dst for __ip_options_echo()\n\t * We could restrict the test to opt.ts_needtime || opt.srr,\n\t * but the following is good enough as IP options are not often used.\n\t */\n\tif (unlikely(IPCB(skb)->opt.optlen))\n\t\tskb_dst_force(skb);\n\telse\n\t\tskb_dst_drop(skb);\n}", "commit_link": "github.com/torvalds/linux/commit/34b2cef20f19c87999fff3da4071e66937db9644", "file_name": "net/ipv4/ip_sockglue.c", "vul_type": "cwe-476", "description": "Write a C function named `ipv4_pktinfo_prepare` that prepares packet information for an IPv4 socket in a Linux kernel environment."}
{"func_name": "gmc_mmx", "func_src_before": "static void gmc_mmx(uint8_t *dst, uint8_t *src,\n                    int stride, int h, int ox, int oy,\n                    int dxx, int dxy, int dyx, int dyy,\n                    int shift, int r, int width, int height)\n{\n    const int w    = 8;\n    const int ix   = ox  >> (16 + shift);\n    const int iy   = oy  >> (16 + shift);\n    const int oxs  = ox  >> 4;\n    const int oys  = oy  >> 4;\n    const int dxxs = dxx >> 4;\n    const int dxys = dxy >> 4;\n    const int dyxs = dyx >> 4;\n    const int dyys = dyy >> 4;\n    const uint16_t r4[4]   = { r, r, r, r };\n    const uint16_t dxy4[4] = { dxys, dxys, dxys, dxys };\n    const uint16_t dyy4[4] = { dyys, dyys, dyys, dyys };\n    const uint64_t shift2  = 2 * shift;\n#define MAX_STRIDE 4096U\n#define MAX_H 8U\n    uint8_t edge_buf[(MAX_H + 1) * MAX_STRIDE];\n    int x, y;\n\n    const int dxw = (dxx - (1 << (16 + shift))) * (w - 1);\n    const int dyh = (dyy - (1 << (16 + shift))) * (h - 1);\n    const int dxh = dxy * (h - 1);\n    const int dyw = dyx * (w - 1);\n    int need_emu  =  (unsigned) ix >= width  - w ||\n                     (unsigned) iy >= height - h;\n\n    if ( // non-constant fullpel offset (3% of blocks)\n        ((ox ^ (ox + dxw)) | (ox ^ (ox + dxh)) | (ox ^ (ox + dxw + dxh)) |\n         (oy ^ (oy + dyw)) | (oy ^ (oy + dyh)) | (oy ^ (oy + dyw + dyh))) >> (16 + shift) ||\n        // uses more than 16 bits of subpel mv (only at huge resolution)\n        (dxx | dxy | dyx | dyy) & 15 ||\n        (need_emu && (h > MAX_H || stride > MAX_STRIDE))) {\n        // FIXME could still use mmx for some of the rows\n        ff_gmc_c(dst, src, stride, h, ox, oy, dxx, dxy, dyx, dyy,\n                 shift, r, width, height);\n        return;\n    }\n\n    src += ix + iy * stride;\n    if (need_emu) {\n        ff_emulated_edge_mc_8(edge_buf, src, stride, stride, w + 1, h + 1, ix, iy, width, height);\n        src = edge_buf;\n    }\n\n    __asm__ volatile (\n        \"movd         %0, %%mm6         \\n\\t\"\n        \"pxor      %%mm7, %%mm7         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        :: \"r\" (1 << shift));\n\n    for (x = 0; x < w; x += 4) {\n        uint16_t dx4[4] = { oxs - dxys + dxxs * (x + 0),\n                            oxs - dxys + dxxs * (x + 1),\n                            oxs - dxys + dxxs * (x + 2),\n                            oxs - dxys + dxxs * (x + 3) };\n        uint16_t dy4[4] = { oys - dyys + dyxs * (x + 0),\n                            oys - dyys + dyxs * (x + 1),\n                            oys - dyys + dyxs * (x + 2),\n                            oys - dyys + dyxs * (x + 3) };\n\n        for (y = 0; y < h; y++) {\n            __asm__ volatile (\n                \"movq      %0, %%mm4    \\n\\t\"\n                \"movq      %1, %%mm5    \\n\\t\"\n                \"paddw     %2, %%mm4    \\n\\t\"\n                \"paddw     %3, %%mm5    \\n\\t\"\n                \"movq   %%mm4, %0       \\n\\t\"\n                \"movq   %%mm5, %1       \\n\\t\"\n                \"psrlw    $12, %%mm4    \\n\\t\"\n                \"psrlw    $12, %%mm5    \\n\\t\"\n                : \"+m\" (*dx4), \"+m\" (*dy4)\n                : \"m\" (*dxy4), \"m\" (*dyy4));\n\n            __asm__ volatile (\n                \"movq      %%mm6, %%mm2 \\n\\t\"\n                \"movq      %%mm6, %%mm1 \\n\\t\"\n                \"psubw     %%mm4, %%mm2 \\n\\t\"\n                \"psubw     %%mm5, %%mm1 \\n\\t\"\n                \"movq      %%mm2, %%mm0 \\n\\t\"\n                \"movq      %%mm4, %%mm3 \\n\\t\"\n                \"pmullw    %%mm1, %%mm0 \\n\\t\" // (s - dx) * (s - dy)\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // dx * dy\n                \"pmullw    %%mm5, %%mm2 \\n\\t\" // (s - dx) * dy\n                \"pmullw    %%mm4, %%mm1 \\n\\t\" // dx * (s - dy)\n\n                \"movd         %4, %%mm5 \\n\\t\"\n                \"movd         %3, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // src[1, 1] * dx * dy\n                \"pmullw    %%mm4, %%mm2 \\n\\t\" // src[0, 1] * (s - dx) * dy\n\n                \"movd         %2, %%mm5 \\n\\t\"\n                \"movd         %1, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm1 \\n\\t\" // src[1, 0] * dx * (s - dy)\n                \"pmullw    %%mm4, %%mm0 \\n\\t\" // src[0, 0] * (s - dx) * (s - dy)\n                \"paddw        %5, %%mm1 \\n\\t\"\n                \"paddw     %%mm3, %%mm2 \\n\\t\"\n                \"paddw     %%mm1, %%mm0 \\n\\t\"\n                \"paddw     %%mm2, %%mm0 \\n\\t\"\n\n                \"psrlw        %6, %%mm0 \\n\\t\"\n                \"packuswb  %%mm0, %%mm0 \\n\\t\"\n                \"movd      %%mm0, %0    \\n\\t\"\n\n                : \"=m\" (dst[x + y * stride])\n                : \"m\" (src[0]), \"m\" (src[1]),\n                  \"m\" (src[stride]), \"m\" (src[stride + 1]),\n                  \"m\" (*r4), \"m\" (shift2));\n            src += stride;\n        }\n        src += 4 - h * stride;\n    }\n}", "func_src_after": "static void gmc_mmx(uint8_t *dst, uint8_t *src,\n                    int stride, int h, int ox, int oy,\n                    int dxx, int dxy, int dyx, int dyy,\n                    int shift, int r, int width, int height)\n{\n    const int w    = 8;\n    const int ix   = ox  >> (16 + shift);\n    const int iy   = oy  >> (16 + shift);\n    const int oxs  = ox  >> 4;\n    const int oys  = oy  >> 4;\n    const int dxxs = dxx >> 4;\n    const int dxys = dxy >> 4;\n    const int dyxs = dyx >> 4;\n    const int dyys = dyy >> 4;\n    const uint16_t r4[4]   = { r, r, r, r };\n    const uint16_t dxy4[4] = { dxys, dxys, dxys, dxys };\n    const uint16_t dyy4[4] = { dyys, dyys, dyys, dyys };\n    const uint64_t shift2  = 2 * shift;\n#define MAX_STRIDE 4096U\n#define MAX_H 8U\n    uint8_t edge_buf[(MAX_H + 1) * MAX_STRIDE];\n    int x, y;\n\n    const int dxw = (dxx - (1 << (16 + shift))) * (w - 1);\n    const int dyh = (dyy - (1 << (16 + shift))) * (h - 1);\n    const int dxh = dxy * (h - 1);\n    const int dyw = dyx * (w - 1);\n    int need_emu  =  (unsigned) ix >= width  - w || width < w ||\n                     (unsigned) iy >= height - h || height< h\n                     ;\n\n    if ( // non-constant fullpel offset (3% of blocks)\n        ((ox ^ (ox + dxw)) | (ox ^ (ox + dxh)) | (ox ^ (ox + dxw + dxh)) |\n         (oy ^ (oy + dyw)) | (oy ^ (oy + dyh)) | (oy ^ (oy + dyw + dyh))) >> (16 + shift) ||\n        // uses more than 16 bits of subpel mv (only at huge resolution)\n        (dxx | dxy | dyx | dyy) & 15 ||\n        (need_emu && (h > MAX_H || stride > MAX_STRIDE))) {\n        // FIXME could still use mmx for some of the rows\n        ff_gmc_c(dst, src, stride, h, ox, oy, dxx, dxy, dyx, dyy,\n                 shift, r, width, height);\n        return;\n    }\n\n    src += ix + iy * stride;\n    if (need_emu) {\n        ff_emulated_edge_mc_8(edge_buf, src, stride, stride, w + 1, h + 1, ix, iy, width, height);\n        src = edge_buf;\n    }\n\n    __asm__ volatile (\n        \"movd         %0, %%mm6         \\n\\t\"\n        \"pxor      %%mm7, %%mm7         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        :: \"r\" (1 << shift));\n\n    for (x = 0; x < w; x += 4) {\n        uint16_t dx4[4] = { oxs - dxys + dxxs * (x + 0),\n                            oxs - dxys + dxxs * (x + 1),\n                            oxs - dxys + dxxs * (x + 2),\n                            oxs - dxys + dxxs * (x + 3) };\n        uint16_t dy4[4] = { oys - dyys + dyxs * (x + 0),\n                            oys - dyys + dyxs * (x + 1),\n                            oys - dyys + dyxs * (x + 2),\n                            oys - dyys + dyxs * (x + 3) };\n\n        for (y = 0; y < h; y++) {\n            __asm__ volatile (\n                \"movq      %0, %%mm4    \\n\\t\"\n                \"movq      %1, %%mm5    \\n\\t\"\n                \"paddw     %2, %%mm4    \\n\\t\"\n                \"paddw     %3, %%mm5    \\n\\t\"\n                \"movq   %%mm4, %0       \\n\\t\"\n                \"movq   %%mm5, %1       \\n\\t\"\n                \"psrlw    $12, %%mm4    \\n\\t\"\n                \"psrlw    $12, %%mm5    \\n\\t\"\n                : \"+m\" (*dx4), \"+m\" (*dy4)\n                : \"m\" (*dxy4), \"m\" (*dyy4));\n\n            __asm__ volatile (\n                \"movq      %%mm6, %%mm2 \\n\\t\"\n                \"movq      %%mm6, %%mm1 \\n\\t\"\n                \"psubw     %%mm4, %%mm2 \\n\\t\"\n                \"psubw     %%mm5, %%mm1 \\n\\t\"\n                \"movq      %%mm2, %%mm0 \\n\\t\"\n                \"movq      %%mm4, %%mm3 \\n\\t\"\n                \"pmullw    %%mm1, %%mm0 \\n\\t\" // (s - dx) * (s - dy)\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // dx * dy\n                \"pmullw    %%mm5, %%mm2 \\n\\t\" // (s - dx) * dy\n                \"pmullw    %%mm4, %%mm1 \\n\\t\" // dx * (s - dy)\n\n                \"movd         %4, %%mm5 \\n\\t\"\n                \"movd         %3, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // src[1, 1] * dx * dy\n                \"pmullw    %%mm4, %%mm2 \\n\\t\" // src[0, 1] * (s - dx) * dy\n\n                \"movd         %2, %%mm5 \\n\\t\"\n                \"movd         %1, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm1 \\n\\t\" // src[1, 0] * dx * (s - dy)\n                \"pmullw    %%mm4, %%mm0 \\n\\t\" // src[0, 0] * (s - dx) * (s - dy)\n                \"paddw        %5, %%mm1 \\n\\t\"\n                \"paddw     %%mm3, %%mm2 \\n\\t\"\n                \"paddw     %%mm1, %%mm0 \\n\\t\"\n                \"paddw     %%mm2, %%mm0 \\n\\t\"\n\n                \"psrlw        %6, %%mm0 \\n\\t\"\n                \"packuswb  %%mm0, %%mm0 \\n\\t\"\n                \"movd      %%mm0, %0    \\n\\t\"\n\n                : \"=m\" (dst[x + y * stride])\n                : \"m\" (src[0]), \"m\" (src[1]),\n                  \"m\" (src[stride]), \"m\" (src[stride + 1]),\n                  \"m\" (*r4), \"m\" (shift2));\n            src += stride;\n        }\n        src += 4 - h * stride;\n    }\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/58cf31cee7a456057f337b3102a03206d833d5e8", "file_name": "libavcodec/x86/mpegvideodsp.c", "vul_type": "cwe-125", "description": "Write a C function named `gmc_mmx` that performs global motion compensation using MMX instructions."}
{"func_name": "ZipUtil::checkDestinationFileForTraversal", "func_src_before": "  private static File checkDestinationFileForTraversal(File outputDir, String name, File destFile) throws IOException {\n    /* If we see the relative traversal string of \"..\" we need to make sure\n     * that the outputdir + name doesn't leave the outputdir. See\n     * DirectoryTraversalMaliciousTest for details.\n     */\n    if (name.indexOf(\"..\") != -1 && !destFile.getCanonicalPath().startsWith(outputDir.getCanonicalPath())) {\n      throw new MaliciousZipException(outputDir, name);\n    }\n    return destFile;\n  }", "func_src_after": "  private static File checkDestinationFileForTraversal(File outputDir, String name, File destFile) throws IOException {\n    /* If we see the relative traversal string of \"..\" we need to make sure\n     * that the outputdir + name doesn't leave the outputdir. See\n     * DirectoryTraversalMaliciousTest for details.\n     */\n    if (name.indexOf(\"..\") != -1 && !destFile.getCanonicalFile().toPath().startsWith(outputDir.getCanonicalFile().toPath())) {\n      throw new MaliciousZipException(outputDir, name);\n    }\n    return destFile;\n  }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 322, "char_end": 431, "line": "    if (name.indexOf(\"..\") != -1 && !destFile.getCanonicalPath().startsWith(outputDir.getCanonicalPath())) {\n"}], "added": [{"line_no": 6, "char_start": 322, "char_end": 449, "line": "    if (name.indexOf(\"..\") != -1 && !destFile.getCanonicalFile().toPath().startsWith(outputDir.getCanonicalFile().toPath())) {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 380, "char_end": 389, "chars": "File().to"}, {"char_start": 429, "char_end": 438, "chars": "File().to"}]}, "commit_link": "github.com/zeroturnaround/zt-zip/commit/627bbc93907ceb69111f86e2edf26375a1abccfa", "file_name": "ZipUtil.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "9b0818802c8fc804d75ef731da538423a7e020fa", "description": "Write a Java function to prevent directory traversal by validating a file's destination path against an intended output directory."}
{"func_name": "_get_flashcopy_mapping_attributes", "func_src_before": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = 'svcinfo lsfcmap -filtervalue id=%s -delim !' % \\\n            fc_map_id\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "func_src_after": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = ['svcinfo', 'lsfcmap', '-filtervalue',\n                         'id=%s' % fc_map_id, '-delim', '!']\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and parse FlashCopy mapping attributes using SSH commands."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, server_address, RequestHandlerClass, router, rewriter, bind_hostname,\n                 config=None, use_ssl=False, key_file=None, certificate=None,\n                 encrypt_after_connect=False, latency=None, **kwargs):\n        \"\"\"Server for HTTP(s) Requests\n\n        :param server_address: tuple of (server_name, port)\n\n        :param RequestHandlerClass: BaseHTTPRequestHandler-like class to use for\n                                    handling requests.\n\n        :param router: Router instance to use for matching requests to handler\n                       functions\n\n        :param rewriter: RequestRewriter-like instance to use for preprocessing\n                         requests before they are routed\n\n        :param config: Dictionary holding environment configuration settings for\n                       handlers to read, or None to use the default values.\n\n        :param use_ssl: Boolean indicating whether the server should use SSL\n\n        :param key_file: Path to key file to use if SSL is enabled.\n\n        :param certificate: Path to certificate to use if SSL is enabled.\n\n        :param encrypt_after_connect: For each connection, don't start encryption\n                                      until a CONNECT message has been received.\n                                      This enables the server to act as a\n                                      self-proxy.\n\n        :param bind_hostname True to bind the server to both the hostname and\n                             port specified in the server_address parameter.\n                             False to bind the server only to the port in the\n                             server_address parameter, but not to the hostname.\n        :param latency: Delay in ms to wait before seving each response, or\n                        callable that returns a delay in ms\n        \"\"\"\n        self.router = router\n        self.rewriter = rewriter\n\n        self.scheme = \"https\" if use_ssl else \"http\"\n\n        self.latency = latency\n\n        if bind_hostname:\n            hostname_port = server_address\n        else:\n            hostname_port = (\"\",server_address[1])\n\n        #super doesn't work here because BaseHTTPServer.HTTPServer is old-style\n        BaseHTTPServer.HTTPServer.__init__(self, hostname_port, RequestHandlerClass, **kwargs)\n\n        if config is not None:\n            Server.config = config\n        else:\n            logger.debug(\"Using default configuration\")\n            Server.config = {\"host\": server_address[0],\n                             \"domains\": {\"\": server_address[0]},\n                             \"ports\": {\"http\": [self.server_address[1]]}}\n\n\n        self.key_file = key_file\n        self.certificate = certificate\n        self.encrypt_after_connect = use_ssl and encrypt_after_connect\n\n        if use_ssl and not encrypt_after_connect:\n            self.socket = ssl.wrap_socket(self.socket,\n                                          keyfile=self.key_file,\n                                          certfile=self.certificate,\n                                          server_side=True)", "func_src_after": "    def __init__(self, server_address, RequestHandlerClass, router, rewriter, bind_hostname,\n                 config=None, use_ssl=False, key_file=None, certificate=None,\n                 encrypt_after_connect=False, latency=None, **kwargs):\n        \"\"\"Server for HTTP(s) Requests\n\n        :param server_address: tuple of (server_name, port)\n\n        :param RequestHandlerClass: BaseHTTPRequestHandler-like class to use for\n                                    handling requests.\n\n        :param router: Router instance to use for matching requests to handler\n                       functions\n\n        :param rewriter: RequestRewriter-like instance to use for preprocessing\n                         requests before they are routed\n\n        :param config: Dictionary holding environment configuration settings for\n                       handlers to read, or None to use the default values.\n\n        :param use_ssl: Boolean indicating whether the server should use SSL\n\n        :param key_file: Path to key file to use if SSL is enabled.\n\n        :param certificate: Path to certificate to use if SSL is enabled.\n\n        :param encrypt_after_connect: For each connection, don't start encryption\n                                      until a CONNECT message has been received.\n                                      This enables the server to act as a\n                                      self-proxy.\n\n        :param bind_hostname True to bind the server to both the hostname and\n                             port specified in the server_address parameter.\n                             False to bind the server only to the port in the\n                             server_address parameter, but not to the hostname.\n        :param latency: Delay in ms to wait before seving each response, or\n                        callable that returns a delay in ms\n        \"\"\"\n        self.router = router\n        self.rewriter = rewriter\n\n        self.scheme = \"https\" if use_ssl else \"http\"\n\n        self.latency = latency\n\n        if bind_hostname:\n            hostname_port = server_address\n        else:\n            hostname_port = (\"\",server_address[1])\n\n        #super doesn't work here because BaseHTTPServer.HTTPServer is old-style\n        BaseHTTPServer.HTTPServer.__init__(self, hostname_port, RequestHandlerClass, **kwargs)\n\n        if config is not None:\n            Server.config = config\n        else:\n            logger.debug(\"Using default configuration\")\n            Server.config = {\"host\": server_address[0],\n                             \"domains\": {\"\": server_address[0]},\n                             \"ports\": {\"http\": [self.server_address[1]]}}\n\n\n        self.key_file = key_file\n        self.certificate = certificate\n        self.encrypt_after_connect = use_ssl and encrypt_after_connect\n\n        if use_ssl and not encrypt_after_connect:\n            self.socket = ssl.wrap_socket(self.socket,\n                                          keyfile=self.key_file,\n                                          certfile=self.certificate,\n                                          ssl_version=3,\n                                          ciphers=\"ALL:!COMPLEMENTOFDEFAULT:!eNULL:!aNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!DH:!RC4;\",\n                                          server_side=True)", "line_changes": {"deleted": [], "added": [{"line_no": 70, "char_start": 3036, "char_end": 3093, "line": "                                          ssl_version=3,\n"}, {"line_no": 71, "char_start": 3093, "char_end": 3231, "line": "                                          ciphers=\"ALL:!COMPLEMENTOFDEFAULT:!eNULL:!aNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!DH:!RC4;\",\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 3036, "char_end": 3231, "chars": "                                          ssl_version=3,\n                                          ciphers=\"ALL:!COMPLEMENTOFDEFAULT:!eNULL:!aNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!DH:!RC4;\",\n"}]}, "commit_link": "github.com/crosswalk-project/web-testing-service/commit/52156e37140dc57a9ece0322ab988faed2670871", "file_name": "server.py", "vul_type": "cwe-327", "commit_msg": "Selects TLS version 1.0 as the channel encryption protocol with Python2.7. (#151)\n\nConfigure ssl ciphers list without RC4 to improve ssl security.", "description": "Write a Python class constructor for an HTTP server that can optionally handle HTTPS, with customizable request routing and response rewriting."}
{"func_name": "get", "func_src_before": "    def get(self, path):\n        return static_file(path, self.get_base_path())", "func_src_after": "    def get(self, path):\n        path = self.sanitize_path(path)\n        base_paths = self.get_base_paths()\n        if hasattr(base_paths, 'split'):\n            # String, so go simple\n            base_path = base_paths\n        else:\n            base_path = self.get_first_base(base_paths, path)\n        return static_file(path, base_path)", "commit_link": "github.com/foxbunny/seagull/commit/1fb790712fe0c1d1957b31e34a8e0e6593af87a7", "file_name": "seagull/routes/app.py", "vul_type": "cwe-022", "description": "Write a Python function named `get` that retrieves a static file from a base path, which may involve sanitizing the path and handling multiple base paths."}
{"func_name": "TNEFParse", "func_src_before": "int TNEFParse(TNEFStruct *TNEF) {\n  WORD key;\n  DWORD type;\n  DWORD size;\n  DWORD signature;\n  BYTE *data;\n  WORD checksum, header_checksum;\n  int i;\n\n  if (TNEF->IO.ReadProc == NULL) {\n    printf(\"ERROR: Setup incorrectly: No ReadProc\\n\");\n    return YTNEF_INCORRECT_SETUP;\n  }\n\n  if (TNEF->IO.InitProc != NULL) {\n    DEBUG(TNEF->Debug, 2, \"About to initialize\");\n    if (TNEF->IO.InitProc(&TNEF->IO) != 0) {\n      return YTNEF_CANNOT_INIT_DATA;\n    }\n    DEBUG(TNEF->Debug, 2, \"Initialization finished\");\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Reading Signature\");\n  if (TNEF->IO.ReadProc(&TNEF->IO, sizeof(DWORD), 1, &signature) < 1) {\n    printf(\"ERROR: Error reading signature\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_ERROR_READING_DATA;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Checking Signature\");\n  if (TNEFCheckForSignature(signature) < 0) {\n    printf(\"ERROR: Signature does not match. Not TNEF.\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_NOT_TNEF_STREAM;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Reading Key.\");\n\n  if (TNEFGetKey(TNEF, &key) < 0) {\n    printf(\"ERROR: Unable to retrieve key.\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_NO_KEY;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Starting Full Processing.\");\n\n  while (TNEFGetHeader(TNEF, &type, &size) == 0) {\n    DEBUG2(TNEF->Debug, 2, \"Header says type=0x%X, size=%u\", type, size);\n    DEBUG2(TNEF->Debug, 2, \"Header says type=%u, size=%u\", type, size);\n    data = calloc(size, sizeof(BYTE));\n    ALLOCCHECK(data);\n    if (TNEFRawRead(TNEF, data, size, &header_checksum) < 0) {\n      printf(\"ERROR: Unable to read data.\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_ERROR_READING_DATA;\n    }\n    if (TNEFRawRead(TNEF, (BYTE *)&checksum, 2, NULL) < 0) {\n      printf(\"ERROR: Unable to read checksum.\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_ERROR_READING_DATA;\n    }\n    checksum = SwapWord((BYTE *)&checksum, sizeof(WORD));\n    if (checksum != header_checksum) {\n      printf(\"ERROR: Checksum mismatch. Data corruption?:\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_BAD_CHECKSUM;\n    }\n    for (i = 0; i < (sizeof(TNEFList) / sizeof(TNEFHandler)); i++) {\n      if (TNEFList[i].id == type) {\n        if (TNEFList[i].handler != NULL) {\n          if (TNEFList[i].handler(TNEF, i, (char*)data, size) < 0) {\n            free(data);\n            if (TNEF->IO.CloseProc != NULL) {\n              TNEF->IO.CloseProc(&TNEF->IO);\n            }\n            return YTNEF_ERROR_IN_HANDLER;\n          } else {\n            //  Found our handler and processed it.  now time to get out\n            break;\n          }\n        } else {\n          DEBUG2(TNEF->Debug, 1, \"No handler for %s: %u bytes\",\n                 TNEFList[i].name, size);\n        }\n      }\n    }\n\n    free(data);\n  }\n\n  if (TNEF->IO.CloseProc != NULL) {\n    TNEF->IO.CloseProc(&TNEF->IO);\n  }\n  return 0;\n\n}", "func_src_after": "int TNEFParse(TNEFStruct *TNEF) {\n  WORD key;\n  DWORD type;\n  DWORD size;\n  DWORD signature;\n  BYTE *data;\n  WORD checksum, header_checksum;\n  int i;\n\n  if (TNEF->IO.ReadProc == NULL) {\n    printf(\"ERROR: Setup incorrectly: No ReadProc\\n\");\n    return YTNEF_INCORRECT_SETUP;\n  }\n\n  if (TNEF->IO.InitProc != NULL) {\n    DEBUG(TNEF->Debug, 2, \"About to initialize\");\n    if (TNEF->IO.InitProc(&TNEF->IO) != 0) {\n      return YTNEF_CANNOT_INIT_DATA;\n    }\n    DEBUG(TNEF->Debug, 2, \"Initialization finished\");\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Reading Signature\");\n  if (TNEF->IO.ReadProc(&TNEF->IO, sizeof(DWORD), 1, &signature) < 1) {\n    printf(\"ERROR: Error reading signature\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_ERROR_READING_DATA;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Checking Signature\");\n  if (TNEFCheckForSignature(signature) < 0) {\n    printf(\"ERROR: Signature does not match. Not TNEF.\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_NOT_TNEF_STREAM;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Reading Key.\");\n\n  if (TNEFGetKey(TNEF, &key) < 0) {\n    printf(\"ERROR: Unable to retrieve key.\\n\");\n    if (TNEF->IO.CloseProc != NULL) {\n      TNEF->IO.CloseProc(&TNEF->IO);\n    }\n    return YTNEF_NO_KEY;\n  }\n\n  DEBUG(TNEF->Debug, 2, \"Starting Full Processing.\");\n\n  while (TNEFGetHeader(TNEF, &type, &size) == 0) {\n    DEBUG2(TNEF->Debug, 2, \"Header says type=0x%X, size=%u\", type, size);\n    DEBUG2(TNEF->Debug, 2, \"Header says type=%u, size=%u\", type, size);\n    if(size == 0) {\n      printf(\"ERROR: Field with size of 0\\n\");\n      return YTNEF_ERROR_READING_DATA;\n    }\n    data = calloc(size, sizeof(BYTE));\n    ALLOCCHECK(data);\n    if (TNEFRawRead(TNEF, data, size, &header_checksum) < 0) {\n      printf(\"ERROR: Unable to read data.\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_ERROR_READING_DATA;\n    }\n    if (TNEFRawRead(TNEF, (BYTE *)&checksum, 2, NULL) < 0) {\n      printf(\"ERROR: Unable to read checksum.\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_ERROR_READING_DATA;\n    }\n    checksum = SwapWord((BYTE *)&checksum, sizeof(WORD));\n    if (checksum != header_checksum) {\n      printf(\"ERROR: Checksum mismatch. Data corruption?:\\n\");\n      if (TNEF->IO.CloseProc != NULL) {\n        TNEF->IO.CloseProc(&TNEF->IO);\n      }\n      free(data);\n      return YTNEF_BAD_CHECKSUM;\n    }\n    for (i = 0; i < (sizeof(TNEFList) / sizeof(TNEFHandler)); i++) {\n      if (TNEFList[i].id == type) {\n        if (TNEFList[i].handler != NULL) {\n          if (TNEFList[i].handler(TNEF, i, (char*)data, size) < 0) {\n            free(data);\n            if (TNEF->IO.CloseProc != NULL) {\n              TNEF->IO.CloseProc(&TNEF->IO);\n            }\n            return YTNEF_ERROR_IN_HANDLER;\n          } else {\n            //  Found our handler and processed it.  now time to get out\n            break;\n          }\n        } else {\n          DEBUG2(TNEF->Debug, 1, \"No handler for %s: %u bytes\",\n                 TNEFList[i].name, size);\n        }\n      }\n    }\n\n    free(data);\n  }\n\n  if (TNEF->IO.CloseProc != NULL) {\n    TNEF->IO.CloseProc(&TNEF->IO);\n  }\n  return 0;\n\n}", "commit_link": "github.com/Yeraze/ytnef/commit/3cb0f914d6427073f262e1b2b5fd973e3043cdf7", "file_name": "lib/ytnef.c", "vul_type": "cwe-125", "description": "Write a C function named `TNEFParse` that processes a TNEF stream using provided I/O procedures."}
{"func_name": "connect", "func_src_before": "    @tornado.web.asynchronous\n    def connect(self):\n        \"\"\"Gets called when a connect request is received.\n\n        * The host and port are obtained from the request uri\n        * A socket is created, wrapped in ssl and then added to SSLIOStream\n        * This stream is used to connect to speak to the remote host on given port\n        * If the server speaks ssl on that port, callback start_tunnel is called\n        * An OK response is written back to client\n        * The client side socket is wrapped in ssl\n        * If the wrapping is successful, a new SSLIOStream is made using that socket\n        * The stream is added back to the server for monitoring\n        \"\"\"\n        host, port = self.request.uri.split(':')\n\n        def start_tunnel():\n            try:\n                self.request.connection.stream.write(b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n                wrap_socket(\n                    self.request.connection.stream.socket,\n                    host,\n                    self.application.ca_cert,\n                    self.application.ca_key,\n                    self.application.ca_key_pass,\n                    self.application.certs_folder,\n                    success=ssl_success\n                )\n            except tornado.iostream.StreamClosedError:\n                pass\n\n        def ssl_success(client_socket):\n            client = tornado.iostream.SSLIOStream(client_socket)\n            ProxyHandler.server.handle_stream(client, self.application.inbound_ip)\n\n        # Tiny Hack to satisfy proxychains CONNECT request to HTTP port.\n        # HTTPS fail check has to be improvised\n        def ssl_fail():\n            try:\n                self.request.connection.stream.write(b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n            except tornado.iostream.StreamClosedError:\n                pass\n            ProxyHandler.server.handle_stream(self.request.connection.stream, self.application.inbound_ip)\n\n        # Hacking to be done here, so as to check for ssl using proxy and auth\n        try:\n            s = ssl.wrap_socket(socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0))\n            upstream = tornado.iostream.SSLIOStream(s)\n            upstream.set_close_callback(ssl_fail)\n            upstream.connect((host, int(port)), start_tunnel)\n        except Exception:\n            self.finish()", "func_src_after": "    @tornado.web.asynchronous\n    def connect(self):\n        \"\"\"Gets called when a connect request is received.\n\n        * The host and port are obtained from the request uri\n        * A socket is created, wrapped in ssl and then added to SSLIOStream\n        * This stream is used to connect to speak to the remote host on given port\n        * If the server speaks ssl on that port, callback start_tunnel is called\n        * An OK response is written back to client\n        * The client side socket is wrapped in ssl\n        * If the wrapping is successful, a new SSLIOStream is made using that socket\n        * The stream is added back to the server for monitoring\n        \"\"\"\n        host, port = self.request.uri.split(':')\n\n        def start_tunnel():\n            try:\n                self.request.connection.stream.write(b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n                wrap_socket(\n                    self.request.connection.stream.socket,\n                    host,\n                    self.application.ca_cert,\n                    self.application.ca_key,\n                    self.application.ca_key_pass,\n                    self.application.certs_folder,\n                    success=ssl_success\n                )\n            except tornado.iostream.StreamClosedError:\n                pass\n\n        def ssl_success(client_socket):\n            client = tornado.iostream.SSLIOStream(client_socket)\n            ProxyHandler.server.handle_stream(client, self.application.inbound_ip)\n\n        # Tiny Hack to satisfy proxychains CONNECT request to HTTP port.\n        # HTTPS fail check has to be improvised\n        def ssl_fail():\n            try:\n                self.request.connection.stream.write(b\"HTTP/1.1 200 Connection established\\r\\n\\r\\n\")\n            except tornado.iostream.StreamClosedError:\n                pass\n            ProxyHandler.server.handle_stream(self.request.connection.stream, self.application.inbound_ip)\n\n        # Hacking to be done here, so as to check for ssl using proxy and auth\n        try:\n            # Adds a fix for check_hostname errors in Tornado 4.3.0\n            context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n            context.check_hostname = False\n            context.load_default_certs()\n            # When connecting through a new socket, no need to wrap the socket before passing\n            # to SSIOStream\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n            upstream = tornado.iostream.SSLIOStream(s, ssl_options=context)\n            upstream.set_close_callback(ssl_fail)\n            upstream.connect((host, int(port)), start_tunnel)\n        except Exception:\n            self.finish()", "line_changes": {"deleted": [{"line_no": 46, "char_start": 2043, "char_end": 2129, "line": "            s = ssl.wrap_socket(socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0))\n"}, {"line_no": 47, "char_start": 2129, "char_end": 2184, "line": "            upstream = tornado.iostream.SSLIOStream(s)\n"}], "added": [{"line_no": 47, "char_start": 2111, "char_end": 2169, "line": "            context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n"}, {"line_no": 48, "char_start": 2169, "char_end": 2212, "line": "            context.check_hostname = False\n"}, {"line_no": 49, "char_start": 2212, "char_end": 2253, "line": "            context.load_default_certs()\n"}, {"line_no": 52, "char_start": 2375, "char_end": 2444, "line": "            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n"}, {"line_no": 53, "char_start": 2444, "char_end": 2520, "line": "            upstream = tornado.iostream.SSLIOStream(s, ssl_options=context)\n"}]}, "char_changes": {"deleted": [{"char_start": 2055, "char_end": 2075, "chars": "s = ssl.wrap_socket("}, {"char_start": 2127, "char_end": 2128, "chars": ")"}], "added": [{"char_start": 2055, "char_end": 2391, "chars": "# Adds a fix for check_hostname errors in Tornado 4.3.0\n            context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n            context.check_hostname = False\n            context.load_default_certs()\n            # When connecting through a new socket, no need to wrap the socket before passing\n            # to SSIOStream\n            s = "}, {"char_start": 2497, "char_end": 2518, "chars": ", ssl_options=context"}]}, "commit_link": "github.com/owtf/owtf/commit/e945dbde9b0c388b252e32eedbe94e1d20212a4d", "file_name": "proxy.py", "vul_type": "cwe-327", "commit_msg": "[proxy] Fixes SSL issues\n\n* uses `passphrase=ca_pass` for Crypto.load_private_key\n* Since Tornado 4.2, SSLIOStream.connect has validated SSL certificates\n  by default. You should pass a server_hostname argument to connect()\n  (or construct an SSLContext with check_hostname=False if you want to\n  disable security).\n\n Also, you shouldn't call ssl.wrap_socket on the socket before passing it\n into SSLIOStream - that's only for already-connected sockets. If you're\n calling connect(), Tornado will do the ssl wrapping for you.\n For more reference, see\n https://github.com/tornadoweb/tornado/issues/1672", "description": "Write a Python function using Tornado to handle a proxy server's CONNECT request."}
{"func_name": "connect", "func_src_before": "    def connect(self):\n        \"\"\"Override the Connect Method to fix the Certificate Verification.\"\"\"\n        # Add certificate verification\n        conn = self._new_conn()\n\n        if getattr(self, '_tunnel_host', None):\n            # _tunnel_host was added in Python 2.6.3\n            # (See: http://hg.python.org/cpython/rev/0f57b30a152f)\n\n            self.sock = conn\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            #\n            # disable pylint because pylint doesn't support importing\n            # from six.moves yet. see:\n            # https://bitbucket.org/logilab/pylint/issue/550/\n            self._tunnel()  # pylint: disable=E1101\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n        # The RECENT_DATE is originally taken from requests. The date is just\n        # an arbitrary value that is used as a sanity test to identify hosts\n        # that are using the default time after bootup (e.g. 1970), and\n        # provides information for debugging\n        RECENT_DATE = datetime.date(2014, 1, 1)\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            LOG.warning('System time is way off (before %s). This will '\n                        'probably lead to SSL verification errors.',\n                        RECENT_DATE)\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        self.sock = ssl.wrap_socket(conn)\n\n        self._verify_cert(self.sock, self.ca_certs)\n        self.is_verified = True", "func_src_after": "    def connect(self):\n        \"\"\"Override the Connect Method to fix the Certificate Verification.\"\"\"\n        # Add certificate verification\n        conn = self._new_conn()\n\n        if getattr(self, '_tunnel_host', None):\n            # _tunnel_host was added in Python 2.6.3\n            # (See: http://hg.python.org/cpython/rev/0f57b30a152f)\n\n            self.sock = conn\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            #\n            # disable pylint because pylint doesn't support importing\n            # from six.moves yet. see:\n            # https://bitbucket.org/logilab/pylint/issue/550/\n            self._tunnel()  # pylint: disable=E1101\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n        # The RECENT_DATE is originally taken from requests. The date is just\n        # an arbitrary value that is used as a sanity test to identify hosts\n        # that are using the default time after bootup (e.g. 1970), and\n        # provides information for debugging\n        RECENT_DATE = datetime.date(2014, 1, 1)\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            LOG.warning('System time is way off (before %s). This will '\n                        'probably lead to SSL verification errors.',\n                        RECENT_DATE)\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        self.sock = ssl.SSLContext.wrap_socket(conn)\n\n        self._verify_cert(self.sock, self.ca_certs)\n        self.is_verified = True", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1464, "char_end": 1506, "line": "        self.sock = ssl.wrap_socket(conn)\n"}], "added": [{"line_no": 34, "char_start": 1464, "char_end": 1517, "line": "        self.sock = ssl.SSLContext.wrap_socket(conn)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1488, "char_end": 1499, "chars": "SSLContext."}]}, "commit_link": "github.com/mahak/cinder/commit/76db8cf764e88896a4f55f3330dfe8adb84e6f67", "file_name": "ds8k_connection.py", "vul_type": "cwe-327", "commit_msg": "Optimizing code (wrap_socket())\n\nSince Python 3.2 and 2.7.9, it is recommended\nto use the SSLContext.wrap_socket() instead of\nwrap_socket().\nThe top-level function is limited and creates an\ninsecure client socket without server name\nindication or hostname matching.\n\nRef : https://docs.python.org/3/library/ssl.html#ssl.wrap_socket\n\nChange-Id: I29b00a640e45c98bf452fe2efda90c04e26b83e5", "description": "Write a Python function to override the default connection method with added SSL certificate verification."}
{"func_name": "ssl_parse_server_psk_hint", "func_src_before": "static int ssl_parse_server_psk_hint( mbedtls_ssl_context *ssl,\n                                      unsigned char **p,\n                                      unsigned char *end )\n{\n    int ret = MBEDTLS_ERR_SSL_FEATURE_UNAVAILABLE;\n    size_t  len;\n    ((void) ssl);\n\n    /*\n     * PSK parameters:\n     *\n     * opaque psk_identity_hint<0..2^16-1>;\n     */\n    if( (*p) > end - 2 )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n    len = (*p)[0] << 8 | (*p)[1];\n    *p += 2;\n\n    if( (*p) + len > end )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n\n    /*\n     * Note: we currently ignore the PKS identity hint, as we only allow one\n     * PSK to be provisionned on the client. This could be changed later if\n     * someone needs that feature.\n     */\n    *p += len;\n    ret = 0;\n\n    return( ret );\n}", "func_src_after": "static int ssl_parse_server_psk_hint( mbedtls_ssl_context *ssl,\n                                      unsigned char **p,\n                                      unsigned char *end )\n{\n    int ret = MBEDTLS_ERR_SSL_FEATURE_UNAVAILABLE;\n    size_t  len;\n    ((void) ssl);\n\n    /*\n     * PSK parameters:\n     *\n     * opaque psk_identity_hint<0..2^16-1>;\n     */\n    if( (*p) > end - 2 )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n    len = (*p)[0] << 8 | (*p)[1];\n    *p += 2;\n\n    if( (*p) > end - len )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n\n    /*\n     * Note: we currently ignore the PKS identity hint, as we only allow one\n     * PSK to be provisionned on the client. This could be changed later if\n     * someone needs that feature.\n     */\n    *p += len;\n    ret = 0;\n\n    return( ret );\n}", "commit_link": "github.com/ARMmbed/mbedtls/commit/5224a7544c95552553e2e6be0b4a789956a6464e", "file_name": "library/ssl_cli.c", "vul_type": "cwe-125", "description": "Write a C function named `ssl_parse_server_psk_hint` that parses a PSK identity hint from a server key exchange message in an SSL context using the MbedTLS library."}
{"func_name": "run", "func_src_before": "    def run(self):\n        \"\"\"Runs the groups scanner.\"\"\"\n\n        root = self._retrieve()\n\n        with open(self.rules, 'r') as f:\n            group_rules = yaml.load(f)\n\n        root = self._apply_all_rules(root, group_rules)\n\n        all_violations = self._find_violations(root)\n\n        self._output_results(all_violations)", "func_src_after": "    def run(self):\n        \"\"\"Runs the groups scanner.\"\"\"\n\n        root = self._retrieve()\n\n        with open(self.rules, 'r') as f:\n            group_rules = file_loader.read_and_parse_file(f)\n\n        root = self._apply_all_rules(root, group_rules)\n\n        all_violations = self._find_violations(root)\n\n        self._output_results(all_violations)", "line_changes": {"deleted": [{"line_no": 7, "char_start": 133, "char_end": 172, "line": "            group_rules = yaml.load(f)\n"}], "added": [{"line_no": 7, "char_start": 133, "char_end": 194, "line": "            group_rules = file_loader.read_and_parse_file(f)\n"}]}, "char_changes": {"deleted": [{"char_start": 159, "char_end": 168, "chars": "yaml.load"}], "added": [{"char_start": 159, "char_end": 190, "chars": "file_loader.read_and_parse_file"}]}, "commit_link": "github.com/forseti-security/forseti-security/commit/1c99b003facfda871defcd73c41b623004dbc7cf", "file_name": "groups_scanner.py", "vul_type": "cwe-502", "commit_msg": "Use the file_loader util method for safe yaml loading. (#1959)\n\n* use file_loader\r\n\r\n* pep8/pylint changes\r\n\r\n* fix test and loading logic.\r\n\r\n* more lint fixes.\r\n\r\n* prep for #1961.", "parent_commit": "df01f4e097c77dc5512f1478b26c56cb7a6fe05c", "description": "Write a Python function named `run` that executes a group scanning process by reading rules from a file and applying them to generate a report."}
{"func_name": "crypto_skcipher_init_tfm", "func_src_before": "static int crypto_skcipher_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_skcipher *skcipher = __crypto_skcipher_cast(tfm);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(skcipher);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_blkcipher_type)\n\t\treturn crypto_init_skcipher_ops_blkcipher(tfm);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_ablkcipher_type ||\n\t    tfm->__crt_alg->cra_type == &crypto_givcipher_type)\n\t\treturn crypto_init_skcipher_ops_ablkcipher(tfm);\n\n\tskcipher->setkey = alg->setkey;\n\tskcipher->encrypt = alg->encrypt;\n\tskcipher->decrypt = alg->decrypt;\n\tskcipher->ivsize = alg->ivsize;\n\tskcipher->keysize = alg->max_keysize;\n\n\tif (alg->exit)\n\t\tskcipher->base.exit = crypto_skcipher_exit_tfm;\n\n\tif (alg->init)\n\t\treturn alg->init(skcipher);\n\n\treturn 0;\n}", "func_src_after": "static int crypto_skcipher_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_skcipher *skcipher = __crypto_skcipher_cast(tfm);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(skcipher);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_blkcipher_type)\n\t\treturn crypto_init_skcipher_ops_blkcipher(tfm);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_ablkcipher_type ||\n\t    tfm->__crt_alg->cra_type == &crypto_givcipher_type)\n\t\treturn crypto_init_skcipher_ops_ablkcipher(tfm);\n\n\tskcipher->setkey = skcipher_setkey;\n\tskcipher->encrypt = alg->encrypt;\n\tskcipher->decrypt = alg->decrypt;\n\tskcipher->ivsize = alg->ivsize;\n\tskcipher->keysize = alg->max_keysize;\n\n\tif (alg->exit)\n\t\tskcipher->base.exit = crypto_skcipher_exit_tfm;\n\n\tif (alg->init)\n\t\treturn alg->init(skcipher);\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/9933e113c2e87a9f46a40fde8dafbf801dca1ab9", "file_name": "crypto/skcipher.c", "vul_type": "cwe-476", "description": "Write a C function named `crypto_skcipher_init_tfm` that initializes a symmetric key cipher transformation context."}
{"func_name": "enc_untrusted_inet_pton", "func_src_before": "int enc_untrusted_inet_pton(int af, const char *src, void *dst) {\n  if (!src || !dst) {\n    return 0;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{\n      src, std::min(strlen(src) + 1, static_cast<size_t>(INET6_ADDRSTRLEN))});\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetPtonHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_pton\", 3);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return -1;\n  }\n\n  auto klinux_addr_buffer = output.next();\n  size_t max_size = 0;\n  if (af == AF_INET) {\n    max_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    max_size = sizeof(struct in6_addr);\n  }\n  memcpy(dst, klinux_addr_buffer.data(),\n         std::min(klinux_addr_buffer.size(), max_size));\n  return result;\n}", "func_src_after": "int enc_untrusted_inet_pton(int af, const char *src, void *dst) {\n  if (!src || !dst) {\n    return 0;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{\n      src, std::min(strlen(src) + 1, static_cast<size_t>(INET6_ADDRSTRLEN))});\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetPtonHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_pton\", 3);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return -1;\n  }\n\n  auto klinux_addr_buffer = output.next();\n  size_t max_size = 0;\n  if (af == AF_INET) {\n    if (klinux_addr_buffer.size() != sizeof(klinux_in_addr)) {\n      ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n          \"enc_untrusted_inet_pton: unexpected output size\");\n    }\n    max_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    if (klinux_addr_buffer.size() != sizeof(klinux_in6_addr)) {\n      ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n          \"enc_untrusted_inet_pton: unexpected output size\");\n    }\n    max_size = sizeof(struct in6_addr);\n  }\n  memcpy(dst, klinux_addr_buffer.data(),\n         std::min(klinux_addr_buffer.size(), max_size));\n  return result;\n}", "commit_link": "github.com/google/asylo/commit/8fed5e334131abaf9c5e17307642fbf6ce4a57ec", "file_name": "asylo/platform/host_call/trusted/host_calls.cc", "vul_type": "cwe-125", "description": "Write a C++ function named `enc_untrusted_inet_pton` that converts an IP address in text format to a network address structure."}
{"func_name": "karma_add", "func_src_before": "def karma_add(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES('{}',1,0)\n                '''.format(name))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 karma for {}'.format(name))\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = {0} WHERE name = '{1}'\n                '''.format(karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} karma for {}'.format(\n                karma, name))\n            return karma\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    db.close()", "func_src_after": "def karma_add(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES(%(name)s,1,0)\n                ''', name)\n            db.commit()\n            logger.debug('Inserted into karmadb 1 karma for {}'.format(name))\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = %(karma)s WHERE name = %(name)s\n                ''', (karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} karma for {}'.format(\n                karma,\n                name,\n            ))\n            return karma\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    db.close()", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to increment a user's karma in a database, handling both new and existing users."}
{"func_name": "self.normalize", "func_src_before": "  def self.normalize url\n    url.sub!(/#(?!\\!)[^#]*$/,'')\n    url.sub!('|', '%7C')\n\n    uri = URI.parse(url)\n\n    @@normalizer_for[uri.host].new(uri).normalize\n  end", "func_src_after": "  def self.normalize url\n    url.sub!(/#(?!\\!)[^#]*$/,'')\n    url.gsub!('|', '%7C')\n\n    uri = URI.parse(url)\n\n    @@normalizer_for[uri.host].new(uri).normalize\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 58, "char_end": 83, "line": "    url.sub!('|', '%7C')\n"}], "added": [{"line_no": 3, "char_start": 58, "char_end": 84, "line": "    url.gsub!('|', '%7C')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 66, "char_end": 67, "chars": "g"}]}, "commit_link": "github.com/Factlink/url_normalizer/commit/1aae2f1401804eeb040557f64cbd667073dbd6ea", "file_name": "url_normalizer.rb", "vul_type": "cwe-116", "commit_msg": "gsub pipes instead of subs", "parent_commit": "c1d97fec40d37d6225fdb88f2fb109669832db82", "description": "Create a Ruby method to normalize URLs by removing fragments and encoding specific characters."}
{"func_name": "register_user", "func_src_before": "def register_user(request):\n    settings = request.registry.settings\n    if not is_registration_enabled(settings):\n        raise exc.exception_response(503)\n    handle_history(request)\n    _ = request.translate\n    config = Config(load(get_path_to_form_config('auth.xml', 'ringo')))\n    form_config = config.get_form('register_user')\n    form = Form(form_config, csrf_token=request.session.get_csrf_token())\n    # Do extra validation which is not handled by formbar.\n    # Is the login unique?\n    validator = Validator('login',\n                          'There is already a user with this name',\n                          is_login_unique)\n    form.add_validator(validator)\n    if request.POST:\n        if form.validate(request.params.mixed()):\n            # 1. Create user. Do not activate him. Default role is user.\n            ufac = User.get_item_factory()\n            # TODO: Check why we not use the get_item_factory_method\n            # here. Do we use plain factories because the need full\n            # controll of depended relations? (ti) <2014-04-08 17:07> \n            pfac = BaseFactory(Profile)\n            gfac = BaseFactory(Usergroup)\n            user = ufac.create(None)\n            # Set login from formdata\n            user.login = form.data['login']\n            # Encrypt password and save\n            pw = hashlib.md5()\n            pw.update(form.data['pass'])\n            user.password = pw.hexdigest()\n            # Deactivate the user. To activate the user needs to confirm\n            # with the activation link\n            user.activated = False\n            atoken = str(uuid.uuid4())\n            user.activation_token = atoken\n            # Set profile data\n            user.profile[0].email = form.data['email']\n            # Set user group\n            group = gfac.load(USER_GROUP_ID)\n            user.groups.append(group)\n            # Set default user group.\n            user.gid = group.id\n            DBSession.add(user)\n\n            # 3. Send confirmation email. The user will be activated\n            #    after the user clicks on the confirmation link\n            mailer = Mailer(request)\n            recipient = user.profile[0].email\n            subject = _('Confirm user registration for %s' % get_app_name())\n            values = {'url': request.route_url('confirm_user', token=atoken),\n                      'app_name': get_app_name(),\n                      'email': settings['mail.default_sender'],\n                      '_': _}\n            mail = Mail([recipient], subject, template=\"register_user\", values=values)\n            mailer.send(mail)\n\n            target_url = request.route_path('login')\n            headers = forget(request)\n            msg = _(\"User has been created and a confirmation mail was sent\"\n                    \" to the users email adress. Please check your email :)\")\n            request.session.flash(msg, 'success')\n            return HTTPFound(location=target_url, headers=headers)\n    return {'form': form.render()}", "func_src_after": "def register_user(request):\n    settings = request.registry.settings\n    if not is_registration_enabled(settings):\n        raise exc.exception_response(503)\n    handle_history(request)\n    _ = request.translate\n    config = Config(load(get_path_to_form_config('auth.xml', 'ringo')))\n    form_config = config.get_form('register_user')\n    form = Form(form_config, csrf_token=request.session.get_csrf_token())\n    # Do extra validation which is not handled by formbar.\n    # Is the login unique?\n    validator = Validator('login',\n                          'There is already a user with this name',\n                          is_login_unique)\n    form.add_validator(validator)\n    if request.POST:\n        if form.validate(request.params.mixed()):\n            # 1. Create user. Do not activate him. Default role is user.\n            ufac = User.get_item_factory()\n            # TODO: Check why we not use the get_item_factory_method\n            # here. Do we use plain factories because the need full\n            # controll of depended relations? (ti) <2014-04-08 17:07> \n            pfac = BaseFactory(Profile)\n            gfac = BaseFactory(Usergroup)\n            user = ufac.create(None)\n            # Set login from formdata\n            user.login = form.data['login']\n            # Encrypt password and save\n            user.password = encrypt_password(form.data['pass'])\n            # Deactivate the user. To activate the user needs to confirm\n            # with the activation link\n            user.activated = False\n            atoken = str(uuid.uuid4())\n            user.activation_token = atoken\n            # Set profile data\n            user.profile[0].email = form.data['email']\n            # Set user group\n            group = gfac.load(USER_GROUP_ID)\n            user.groups.append(group)\n            # Set default user group.\n            user.gid = group.id\n            DBSession.add(user)\n\n            # 3. Send confirmation email. The user will be activated\n            #    after the user clicks on the confirmation link\n            mailer = Mailer(request)\n            recipient = user.profile[0].email\n            subject = _('Confirm user registration for %s' % get_app_name())\n            values = {'url': request.route_url('confirm_user', token=atoken),\n                      'app_name': get_app_name(),\n                      'email': settings['mail.default_sender'],\n                      '_': _}\n            mail = Mail([recipient], subject, template=\"register_user\", values=values)\n            mailer.send(mail)\n\n            target_url = request.route_path('login')\n            headers = forget(request)\n            msg = _(\"User has been created and a confirmation mail was sent\"\n                    \" to the users email adress. Please check your email :)\")\n            request.session.flash(msg, 'success')\n            return HTTPFound(location=target_url, headers=headers)\n    return {'form': form.render()}", "line_changes": {"deleted": [{"line_no": 29, "char_start": 1310, "char_end": 1341, "line": "            pw = hashlib.md5()\n"}, {"line_no": 30, "char_start": 1341, "char_end": 1382, "line": "            pw.update(form.data['pass'])\n"}, {"line_no": 31, "char_start": 1382, "char_end": 1425, "line": "            user.password = pw.hexdigest()\n"}], "added": [{"line_no": 29, "char_start": 1310, "char_end": 1374, "line": "            user.password = encrypt_password(form.data['pass'])\n"}]}, "char_changes": {"deleted": [{"char_start": 1322, "char_end": 1423, "chars": "pw = hashlib.md5()\n            pw.update(form.data['pass'])\n            user.password = pw.hexdigest("}], "added": [{"char_start": 1322, "char_end": 1372, "chars": "user.password = encrypt_password(form.data['pass']"}]}, "commit_link": "github.com/ringo-framework/ringo/commit/ddb9d55999151f37fd4c833a98d2f34648757293", "file_name": "auth.py", "vul_type": "cwe-327", "commit_msg": "Replaced use of the old hashlib.md5 method for password encryption with new encryption methods using passlib", "parent_commit": "8e92641fee542f6e7004e827136dea3ce5e99eb2", "description": "Write a Python function to handle user registration, including form validation, user creation, and sending a confirmation email."}
{"func_name": "(anonymous)", "func_src_before": "        function ($sce) {\n            return function (params) {\n\n                var dialog = angular.element(document.getElementById('prompt-modal')),\n                    scope = dialog.scope(), cls, local_backdrop;\n                \n                scope.promptHeader = params.hdr;\n                scope.promptBody = $sce.trustAsHtml(params.body);\n                scope.promptAction = params.action;\n\n                local_backdrop = (params.backdrop === undefined) ? \"static\" : params.backdrop;\n\n                cls = (params['class'] === null || params['class'] === undefined) ? 'btn-danger' : params['class'];\n\n                $('#prompt_action_btn').removeClass(cls).addClass(cls);\n\n                // bootstrap modal's have an open defect with disallowing tab index's of the background of the modal\n                // This will keep the tab indexing on the modal's focus. This is to fix an issue with tabbing working when\n                // the user is attempting to delete something. Might need to be checked for other occurances of the bootstrap\n                // modal other than deleting\n                function disableTabModalShown() {\n\n                    $('.modal').on('shown.bs.modal', function() {\n\n                        var modal = $(this),\n                        focusableChildren = modal.find('a[href], a[data-dismiss], area[href], input, select, textarea, button, iframe, object, embed, *[tabindex], *[contenteditable]'),\n                        numElements = focusableChildren.length,\n                        currentIndex = 0,\n                        focus,\n                        focusPrevious,\n                        focusNext;\n\n                        $(document.activeElement).blur();\n\n                        focus = function() {\n                            var focusableElement = focusableChildren[currentIndex];\n                            if (focusableElement) {\n                                focusableElement.focus();\n                            }\n                        };\n\n                        focusPrevious = function () {\n                            currentIndex--;\n                            if (currentIndex < 0) {\n                                currentIndex = numElements - 1;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        focusNext = function () {\n                            currentIndex++;\n                            if (currentIndex >= numElements) {\n                                currentIndex = 0;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        $(document).on('keydown', function (e) {\n\n                            if (e.keyCode === 9 && e.shiftKey) {\n                                e.preventDefault();\n                                focusPrevious();\n                            }\n                            else if (e.keyCode === 9) {\n                                e.preventDefault();\n                                focusNext();\n                            }\n                        });\n\n                        $(this).focus();\n                    });\n\n                    $('.modal').on('hidden.bs.modal', function() {\n                        $(document).unbind('keydown');\n                    });\n                }\n\n\n                $('#prompt-modal').off('hidden.bs.modal');\n                $('#prompt-modal').modal({\n                    backdrop: 'local_backdrop',\n                    keyboard: true,\n                    show: true\n                });\n                disableTabModalShown();\n\n            };\n        }", "func_src_after": "        function ($sce, $filter) {\n            return function (params) {\n\n                var dialog = angular.element(document.getElementById('prompt-modal')),\n                    scope = dialog.scope(), cls, local_backdrop;\n\n                scope.promptHeader = params.hdr;\n                scope.promptBody = $filter('sanitize')(params.body);\n                scope.promptAction = params.action;\n\n                local_backdrop = (params.backdrop === undefined) ? \"static\" : params.backdrop;\n\n                cls = (params['class'] === null || params['class'] === undefined) ? 'btn-danger' : params['class'];\n\n                $('#prompt_action_btn').removeClass(cls).addClass(cls);\n\n                // bootstrap modal's have an open defect with disallowing tab index's of the background of the modal\n                // This will keep the tab indexing on the modal's focus. This is to fix an issue with tabbing working when\n                // the user is attempting to delete something. Might need to be checked for other occurances of the bootstrap\n                // modal other than deleting\n                function disableTabModalShown() {\n\n                    $('.modal').on('shown.bs.modal', function() {\n\n                        var modal = $(this),\n                        focusableChildren = modal.find('a[href], a[data-dismiss], area[href], input, select, textarea, button, iframe, object, embed, *[tabindex], *[contenteditable]'),\n                        numElements = focusableChildren.length,\n                        currentIndex = 0,\n                        focus,\n                        focusPrevious,\n                        focusNext;\n\n                        $(document.activeElement).blur();\n\n                        focus = function() {\n                            var focusableElement = focusableChildren[currentIndex];\n                            if (focusableElement) {\n                                focusableElement.focus();\n                            }\n                        };\n\n                        focusPrevious = function () {\n                            currentIndex--;\n                            if (currentIndex < 0) {\n                                currentIndex = numElements - 1;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        focusNext = function () {\n                            currentIndex++;\n                            if (currentIndex >= numElements) {\n                                currentIndex = 0;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        $(document).on('keydown', function (e) {\n\n                            if (e.keyCode === 9 && e.shiftKey) {\n                                e.preventDefault();\n                                focusPrevious();\n                            }\n                            else if (e.keyCode === 9) {\n                                e.preventDefault();\n                                focusNext();\n                            }\n                        });\n\n                        $(this).focus();\n                    });\n\n                    $('.modal').on('hidden.bs.modal', function() {\n                        $(document).unbind('keydown');\n                    });\n                }\n\n\n                $('#prompt-modal').off('hidden.bs.modal');\n                $('#prompt-modal').modal({\n                    backdrop: 'local_backdrop',\n                    keyboard: true,\n                    show: true\n                });\n                disableTabModalShown();\n\n            };\n        }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 218, "char_end": 235, "line": "                \n"}, {"line_no": 8, "char_start": 284, "char_end": 350, "line": "                scope.promptBody = $sce.trustAsHtml(params.body);\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 35, "line": "        function ($sce, $filter) {\n"}, {"line_no": 6, "char_start": 227, "char_end": 228, "line": "\n"}, {"line_no": 8, "char_start": 277, "char_end": 346, "line": "                scope.promptBody = $filter('sanitize')(params.body);\n"}]}, "char_changes": {"deleted": [{"char_start": 218, "char_end": 234, "chars": "                "}, {"char_start": 320, "char_end": 335, "chars": "sce.trustAsHtml"}], "added": [{"char_start": 22, "char_end": 31, "chars": ", $filter"}, {"char_start": 313, "char_end": 331, "chars": "filter('sanitize')"}]}, "commit_link": "github.com/wwitzel3/awx/commit/b127e7f2765c6173c5cf27d34491e7ca0a4ac101", "file_name": "prompt-dialog.js", "vul_type": "cwe-079", "commit_msg": "fixing xss bugs", "description": "Create a JavaScript function in AngularJS that configures and displays a modal dialog with custom content and button class."}
{"func_name": "parse_hid_report_descriptor", "func_src_before": "static void parse_hid_report_descriptor(struct gtco *device, char * report,\n\t\t\t\t\tint length)\n{\n\tstruct device *ddev = &device->intf->dev;\n\tint   x, i = 0;\n\n\t/* Tag primitive vars */\n\t__u8   prefix;\n\t__u8   size;\n\t__u8   tag;\n\t__u8   type;\n\t__u8   data   = 0;\n\t__u16  data16 = 0;\n\t__u32  data32 = 0;\n\n\t/* For parsing logic */\n\tint   inputnum = 0;\n\t__u32 usage = 0;\n\n\t/* Global Values, indexed by TAG */\n\t__u32 globalval[TAG_GLOB_MAX];\n\t__u32 oldval[TAG_GLOB_MAX];\n\n\t/* Debug stuff */\n\tchar  maintype = 'x';\n\tchar  globtype[12];\n\tint   indent = 0;\n\tchar  indentstr[10] = \"\";\n\n\n\tdev_dbg(ddev, \"======>>>>>>PARSE<<<<<<======\\n\");\n\n\t/* Walk  this report and pull out the info we need */\n\twhile (i < length) {\n\t\tprefix = report[i];\n\n\t\t/* Skip over prefix */\n\t\ti++;\n\n\t\t/* Determine data size and save the data in the proper variable */\n\t\tsize = PREF_SIZE(prefix);\n\t\tswitch (size) {\n\t\tcase 1:\n\t\t\tdata = report[i];\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdata16 = get_unaligned_le16(&report[i]);\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tsize = 4;\n\t\t\tdata32 = get_unaligned_le32(&report[i]);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Skip size of data */\n\t\ti += size;\n\n\t\t/* What we do depends on the tag type */\n\t\ttag  = PREF_TAG(prefix);\n\t\ttype = PREF_TYPE(prefix);\n\t\tswitch (type) {\n\t\tcase TYPE_MAIN:\n\t\t\tstrcpy(globtype, \"\");\n\t\t\tswitch (tag) {\n\n\t\t\tcase TAG_MAIN_INPUT:\n\t\t\t\t/*\n\t\t\t\t * The INPUT MAIN tag signifies this is\n\t\t\t\t * information from a report.  We need to\n\t\t\t\t * figure out what it is and store the\n\t\t\t\t * min/max values\n\t\t\t\t */\n\n\t\t\t\tmaintype = 'I';\n\t\t\t\tif (data == 2)\n\t\t\t\t\tstrcpy(globtype, \"Variable\");\n\t\t\t\telse if (data == 3)\n\t\t\t\t\tstrcpy(globtype, \"Var|Const\");\n\n\t\t\t\tdev_dbg(ddev, \"::::: Saving Report: %d input #%d Max: 0x%X(%d) Min:0x%X(%d) of %d bits\\n\",\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_ID], inputnum,\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MAX], globalval[TAG_GLOB_LOG_MAX],\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MIN], globalval[TAG_GLOB_LOG_MIN],\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_SZ] * globalval[TAG_GLOB_REPORT_CNT]);\n\n\n\t\t\t\t/*\n\t\t\t\t  We can assume that the first two input items\n\t\t\t\t  are always the X and Y coordinates.  After\n\t\t\t\t  that, we look for everything else by\n\t\t\t\t  local usage value\n\t\t\t\t */\n\t\t\t\tswitch (inputnum) {\n\t\t\t\tcase 0:  /* X coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: X Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_X == 0) {\n\t\t\t\t\t\tdevice->max_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 1:  /* Y coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: Y Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_Y == 0) {\n\t\t\t\t\t\tdevice->max_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\t/* Tilt X */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_X) {\n\t\t\t\t\t\tif (device->maxtilt_X == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Tilt Y */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_Y) {\n\t\t\t\t\t\tif (device->maxtilt_Y == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Pressure */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TIP_PRESSURE) {\n\t\t\t\t\t\tif (device->maxpressure == 0) {\n\t\t\t\t\t\t\tdevice->maxpressure = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->minpressure = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tinputnum++;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_OUTPUT:\n\t\t\t\tmaintype = 'O';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_FEATURE:\n\t\t\t\tmaintype = 'F';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_START:\n\t\t\t\tmaintype = 'S';\n\n\t\t\t\tif (data == 0) {\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>> Physical\\n\");\n\t\t\t\t\tstrcpy(globtype, \"Physical\");\n\t\t\t\t} else\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>>\\n\");\n\n\t\t\t\t/* Indent the debug output */\n\t\t\t\tindent++;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Save global tags */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\toldval[x] = globalval[x];\n\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_END:\n\t\t\t\tdev_dbg(ddev, \"<<<<<<======\\n\");\n\t\t\t\tmaintype = 'E';\n\t\t\t\tindent--;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Copy global tags back */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\tglobalval[x] = oldval[x];\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_GLOBAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\t/*\n\t\t\t\t * First time we hit the global usage tag,\n\t\t\t\t * it should tell us the type of device\n\t\t\t\t */\n\t\t\t\tif (device->usage == 0)\n\t\t\t\t\tdevice->usage = data;\n\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"LOG_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"LOG_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MIN:\n\t\t\t\tstrcpy(globtype, \"PHYS_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MAX:\n\t\t\t\tstrcpy(globtype, \"PHYS_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT_EXP:\n\t\t\t\tstrcpy(globtype, \"EXP\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT:\n\t\t\t\tstrcpy(globtype, \"UNIT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_SZ:\n\t\t\t\tstrcpy(globtype, \"REPORT_SZ\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_ID:\n\t\t\t\tstrcpy(globtype, \"REPORT_ID\");\n\t\t\t\t/* New report, restart numbering */\n\t\t\t\tinputnum = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_CNT:\n\t\t\t\tstrcpy(globtype, \"REPORT_CNT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PUSH:\n\t\t\t\tstrcpy(globtype, \"PUSH\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_POP:\n\t\t\t\tstrcpy(globtype, \"POP\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Check to make sure we have a good tag number\n\t\t\t   so we don't overflow array */\n\t\t\tif (tag < TAG_GLOB_MAX) {\n\t\t\t\tswitch (size) {\n\t\t\t\tcase 1:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data);\n\t\t\t\t\tglobalval[tag] = data;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 2:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data16);\n\t\t\t\t\tglobalval[tag] = data16;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 4:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data32);\n\t\t\t\t\tglobalval[tag] = data32;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG: ILLEGAL TAG:%d SIZE: %d\\n\",\n\t\t\t\t\tindentstr, tag, size);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_LOCAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\t/* Always 1 byte */\n\t\t\t\tusage = data;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"MAX\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tstrcpy(globtype, \"UNKNOWN\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\t}\n}", "func_src_after": "static void parse_hid_report_descriptor(struct gtco *device, char * report,\n\t\t\t\t\tint length)\n{\n\tstruct device *ddev = &device->intf->dev;\n\tint   x, i = 0;\n\n\t/* Tag primitive vars */\n\t__u8   prefix;\n\t__u8   size;\n\t__u8   tag;\n\t__u8   type;\n\t__u8   data   = 0;\n\t__u16  data16 = 0;\n\t__u32  data32 = 0;\n\n\t/* For parsing logic */\n\tint   inputnum = 0;\n\t__u32 usage = 0;\n\n\t/* Global Values, indexed by TAG */\n\t__u32 globalval[TAG_GLOB_MAX];\n\t__u32 oldval[TAG_GLOB_MAX];\n\n\t/* Debug stuff */\n\tchar  maintype = 'x';\n\tchar  globtype[12];\n\tint   indent = 0;\n\tchar  indentstr[10] = \"\";\n\n\n\tdev_dbg(ddev, \"======>>>>>>PARSE<<<<<<======\\n\");\n\n\t/* Walk  this report and pull out the info we need */\n\twhile (i < length) {\n\t\tprefix = report[i++];\n\n\t\t/* Determine data size and save the data in the proper variable */\n\t\tsize = (1U << PREF_SIZE(prefix)) >> 1;\n\t\tif (i + size > length) {\n\t\t\tdev_err(ddev,\n\t\t\t\t\"Not enough data (need %d, have %d)\\n\",\n\t\t\t\ti + size, length);\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (size) {\n\t\tcase 1:\n\t\t\tdata = report[i];\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdata16 = get_unaligned_le16(&report[i]);\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tdata32 = get_unaligned_le32(&report[i]);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Skip size of data */\n\t\ti += size;\n\n\t\t/* What we do depends on the tag type */\n\t\ttag  = PREF_TAG(prefix);\n\t\ttype = PREF_TYPE(prefix);\n\t\tswitch (type) {\n\t\tcase TYPE_MAIN:\n\t\t\tstrcpy(globtype, \"\");\n\t\t\tswitch (tag) {\n\n\t\t\tcase TAG_MAIN_INPUT:\n\t\t\t\t/*\n\t\t\t\t * The INPUT MAIN tag signifies this is\n\t\t\t\t * information from a report.  We need to\n\t\t\t\t * figure out what it is and store the\n\t\t\t\t * min/max values\n\t\t\t\t */\n\n\t\t\t\tmaintype = 'I';\n\t\t\t\tif (data == 2)\n\t\t\t\t\tstrcpy(globtype, \"Variable\");\n\t\t\t\telse if (data == 3)\n\t\t\t\t\tstrcpy(globtype, \"Var|Const\");\n\n\t\t\t\tdev_dbg(ddev, \"::::: Saving Report: %d input #%d Max: 0x%X(%d) Min:0x%X(%d) of %d bits\\n\",\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_ID], inputnum,\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MAX], globalval[TAG_GLOB_LOG_MAX],\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MIN], globalval[TAG_GLOB_LOG_MIN],\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_SZ] * globalval[TAG_GLOB_REPORT_CNT]);\n\n\n\t\t\t\t/*\n\t\t\t\t  We can assume that the first two input items\n\t\t\t\t  are always the X and Y coordinates.  After\n\t\t\t\t  that, we look for everything else by\n\t\t\t\t  local usage value\n\t\t\t\t */\n\t\t\t\tswitch (inputnum) {\n\t\t\t\tcase 0:  /* X coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: X Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_X == 0) {\n\t\t\t\t\t\tdevice->max_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 1:  /* Y coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: Y Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_Y == 0) {\n\t\t\t\t\t\tdevice->max_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\t/* Tilt X */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_X) {\n\t\t\t\t\t\tif (device->maxtilt_X == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Tilt Y */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_Y) {\n\t\t\t\t\t\tif (device->maxtilt_Y == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Pressure */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TIP_PRESSURE) {\n\t\t\t\t\t\tif (device->maxpressure == 0) {\n\t\t\t\t\t\t\tdevice->maxpressure = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->minpressure = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tinputnum++;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_OUTPUT:\n\t\t\t\tmaintype = 'O';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_FEATURE:\n\t\t\t\tmaintype = 'F';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_START:\n\t\t\t\tmaintype = 'S';\n\n\t\t\t\tif (data == 0) {\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>> Physical\\n\");\n\t\t\t\t\tstrcpy(globtype, \"Physical\");\n\t\t\t\t} else\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>>\\n\");\n\n\t\t\t\t/* Indent the debug output */\n\t\t\t\tindent++;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Save global tags */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\toldval[x] = globalval[x];\n\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_END:\n\t\t\t\tdev_dbg(ddev, \"<<<<<<======\\n\");\n\t\t\t\tmaintype = 'E';\n\t\t\t\tindent--;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Copy global tags back */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\tglobalval[x] = oldval[x];\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_GLOBAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\t/*\n\t\t\t\t * First time we hit the global usage tag,\n\t\t\t\t * it should tell us the type of device\n\t\t\t\t */\n\t\t\t\tif (device->usage == 0)\n\t\t\t\t\tdevice->usage = data;\n\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"LOG_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"LOG_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MIN:\n\t\t\t\tstrcpy(globtype, \"PHYS_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MAX:\n\t\t\t\tstrcpy(globtype, \"PHYS_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT_EXP:\n\t\t\t\tstrcpy(globtype, \"EXP\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT:\n\t\t\t\tstrcpy(globtype, \"UNIT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_SZ:\n\t\t\t\tstrcpy(globtype, \"REPORT_SZ\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_ID:\n\t\t\t\tstrcpy(globtype, \"REPORT_ID\");\n\t\t\t\t/* New report, restart numbering */\n\t\t\t\tinputnum = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_CNT:\n\t\t\t\tstrcpy(globtype, \"REPORT_CNT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PUSH:\n\t\t\t\tstrcpy(globtype, \"PUSH\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_POP:\n\t\t\t\tstrcpy(globtype, \"POP\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Check to make sure we have a good tag number\n\t\t\t   so we don't overflow array */\n\t\t\tif (tag < TAG_GLOB_MAX) {\n\t\t\t\tswitch (size) {\n\t\t\t\tcase 1:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data);\n\t\t\t\t\tglobalval[tag] = data;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 2:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data16);\n\t\t\t\t\tglobalval[tag] = data16;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 4:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data32);\n\t\t\t\t\tglobalval[tag] = data32;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG: ILLEGAL TAG:%d SIZE: %d\\n\",\n\t\t\t\t\tindentstr, tag, size);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_LOCAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\t/* Always 1 byte */\n\t\t\t\tusage = data;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"MAX\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tstrcpy(globtype, \"UNKNOWN\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/a50829479f58416a013a4ccca791336af3c584c7", "file_name": "drivers/input/tablet/gtco.c", "vul_type": "cwe-125", "description": "Write a C function to parse a HID report descriptor and extract device information."}
{"func_name": "ParseEthernetSegmentIdentifier", "func_src_before": "func ParseEthernetSegmentIdentifier(args []string) (EthernetSegmentIdentifier, error) {\n\tesi := EthernetSegmentIdentifier{}\n\targLen := len(args)\n\tif argLen == 0 || args[0] == \"single-homed\" {\n\t\treturn esi, nil\n\t}\n\n\ttypeStr := strings.TrimPrefix(strings.ToUpper(args[0]), \"ESI_\")\n\tswitch typeStr {\n\tcase \"ARBITRARY\":\n\t\tesi.Type = ESI_ARBITRARY\n\tcase \"LACP\":\n\t\tesi.Type = ESI_LACP\n\tcase \"MSTP\":\n\t\tesi.Type = ESI_MSTP\n\tcase \"MAC\":\n\t\tesi.Type = ESI_MAC\n\tcase \"ROUTERID\":\n\t\tesi.Type = ESI_ROUTERID\n\tcase \"AS\":\n\t\tesi.Type = ESI_AS\n\tdefault:\n\t\ttyp, err := strconv.Atoi(args[0])\n\t\tif err != nil {\n\t\t\treturn esi, fmt.Errorf(\"invalid esi type: %s\", args[0])\n\t\t}\n\t\tesi.Type = ESIType(typ)\n\t}\n\n\tinvalidEsiValuesError := fmt.Errorf(\"invalid esi values for type %s: %s\", esi.Type.String(), args[1:])\n\tesi.Value = make([]byte, 9, 9)\n\tswitch esi.Type {\n\tcase ESI_LACP:\n\t\tfallthrough\n\tcase ESI_MSTP:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Port Key or Bridge Priority\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint16(esi.Value[6:8], uint16(i))\n\tcase ESI_MAC:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Local Discriminator\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tiBuf := make([]byte, 4, 4)\n\t\tbinary.BigEndian.PutUint32(iBuf, uint32(i))\n\t\tcopy(esi.Value[6:9], iBuf[1:4])\n\tcase ESI_ROUTERID:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// Router ID\n\t\tip := net.ParseIP(args[1])\n\t\tif ip == nil || ip.To4() == nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:4], ip.To4())\n\t\t// Local Discriminator\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_AS:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// AS\n\t\tas, err := strconv.Atoi(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[0:4], uint32(as))\n\t\t// Local Discriminator\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_ARBITRARY:\n\t\tfallthrough\n\tdefault:\n\t\tif argLen < 2 {\n\t\t\t// Assumes the Value field is omitted\n\t\t\tbreak\n\t\t}\n\t\tvalues := make([]byte, 0, 9)\n\t\tfor _, e := range strings.SplitN(args[1], \":\", 9) {\n\t\t\tv, err := strconv.ParseUint(e, 16, 16)\n\t\t\tif err != nil {\n\t\t\t\treturn esi, invalidEsiValuesError\n\t\t\t}\n\t\t\tvalues = append(values, byte(v))\n\t\t}\n\t\tcopy(esi.Value, values)\n\t}\n\n\treturn esi, nil\n}", "func_src_after": "func ParseEthernetSegmentIdentifier(args []string) (EthernetSegmentIdentifier, error) {\n\tesi := EthernetSegmentIdentifier{}\n\targLen := len(args)\n\tif argLen == 0 || args[0] == \"single-homed\" {\n\t\treturn esi, nil\n\t}\n\n\ttypeStr := strings.TrimPrefix(strings.ToUpper(args[0]), \"ESI_\")\n\tswitch typeStr {\n\tcase \"ARBITRARY\":\n\t\tesi.Type = ESI_ARBITRARY\n\tcase \"LACP\":\n\t\tesi.Type = ESI_LACP\n\tcase \"MSTP\":\n\t\tesi.Type = ESI_MSTP\n\tcase \"MAC\":\n\t\tesi.Type = ESI_MAC\n\tcase \"ROUTERID\":\n\t\tesi.Type = ESI_ROUTERID\n\tcase \"AS\":\n\t\tesi.Type = ESI_AS\n\tdefault:\n\t\ttyp, err := strconv.ParseUint(args[0], 10, 0)\n\t\tif err != nil {\n\t\t\treturn esi, fmt.Errorf(\"invalid esi type: %s\", args[0])\n\t\t}\n\t\tesi.Type = ESIType(typ)\n\t}\n\n\tinvalidEsiValuesError := fmt.Errorf(\"invalid esi values for type %s: %s\", esi.Type.String(), args[1:])\n\tesi.Value = make([]byte, 9, 9)\n\tswitch esi.Type {\n\tcase ESI_LACP:\n\t\tfallthrough\n\tcase ESI_MSTP:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Port Key or Bridge Priority\n\t\ti, err := strconv.ParseUint(args[2], 10, 16)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint16(esi.Value[6:8], uint16(i))\n\tcase ESI_MAC:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Local Discriminator\n\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tiBuf := make([]byte, 4, 4)\n\t\tbinary.BigEndian.PutUint32(iBuf, uint32(i))\n\t\tcopy(esi.Value[6:9], iBuf[1:4])\n\tcase ESI_ROUTERID:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// Router ID\n\t\tip := net.ParseIP(args[1])\n\t\tif ip == nil || ip.To4() == nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:4], ip.To4())\n\t\t// Local Discriminator\n\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_AS:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// AS\n\t\tas, err := strconv.ParseUint(args[1], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[0:4], uint32(as))\n\t\t// Local Discriminator\n\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_ARBITRARY:\n\t\tfallthrough\n\tdefault:\n\t\tif argLen < 2 {\n\t\t\t// Assumes the Value field is omitted\n\t\t\tbreak\n\t\t}\n\t\tvalues := make([]byte, 0, 9)\n\t\tfor _, e := range strings.SplitN(args[1], \":\", 9) {\n\t\t\tv, err := strconv.ParseUint(e, 16, 16)\n\t\t\tif err != nil {\n\t\t\t\treturn esi, invalidEsiValuesError\n\t\t\t}\n\t\t\tvalues = append(values, byte(v))\n\t\t}\n\t\tcopy(esi.Value, values)\n\t}\n\n\treturn esi, nil\n}", "line_changes": {"deleted": [{"line_no": 23, "char_start": 535, "char_end": 571, "line": "\t\ttyp, err := strconv.Atoi(args[0])\n"}, {"line_no": 46, "char_start": 1107, "char_end": 1141, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}, {"line_no": 62, "char_start": 1487, "char_end": 1521, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}, {"line_no": 80, "char_start": 1947, "char_end": 1981, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}, {"line_no": 90, "char_start": 2177, "char_end": 2212, "line": "\t\tas, err := strconv.Atoi(args[1])\n"}, {"line_no": 96, "char_start": 2353, "char_end": 2387, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}], "added": [{"line_no": 23, "char_start": 535, "char_end": 583, "line": "\t\ttyp, err := strconv.ParseUint(args[0], 10, 0)\n"}, {"line_no": 46, "char_start": 1119, "char_end": 1166, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 16)\n"}, {"line_no": 62, "char_start": 1512, "char_end": 1559, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n"}, {"line_no": 80, "char_start": 1985, "char_end": 2032, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n"}, {"line_no": 90, "char_start": 2228, "char_end": 2276, "line": "\t\tas, err := strconv.ParseUint(args[1], 10, 32)\n"}, {"line_no": 96, "char_start": 2417, "char_end": 2464, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n"}]}, "char_changes": {"deleted": [{"char_start": 557, "char_end": 561, "chars": "Atoi"}, {"char_start": 1127, "char_end": 1139, "chars": "Atoi(args[2]"}, {"char_start": 1507, "char_end": 1519, "chars": "Atoi(args[2]"}, {"char_start": 1967, "char_end": 1979, "chars": "Atoi(args[2]"}, {"char_start": 2198, "char_end": 2210, "chars": "Atoi(args[1]"}, {"char_start": 2373, "char_end": 2385, "chars": "Atoi(args[2]"}], "added": [{"char_start": 557, "char_end": 566, "chars": "ParseUint"}, {"char_start": 574, "char_end": 581, "chars": ", 10, 0"}, {"char_start": 1139, "char_end": 1164, "chars": "ParseUint(args[2], 10, 16"}, {"char_start": 1532, "char_end": 1557, "chars": "ParseUint(args[2], 10, 32"}, {"char_start": 2005, "char_end": 2030, "chars": "ParseUint(args[2], 10, 32"}, {"char_start": 2249, "char_end": 2274, "chars": "ParseUint(args[1], 10, 32"}, {"char_start": 2437, "char_end": 2462, "chars": "ParseUint(args[2], 10, 32"}]}, "commit_link": "github.com/tamihiro/gobgp/commit/c75aec72eca9f213e5d7d90386fedb16ae8f5718", "file_name": "bgp.go", "vul_type": "cwe-681", "commit_msg": "packet/bgp: use strconv.ParseUint instead of strconv.Atoi()\n\nAtoi() returns a signed int. On a 32-bit platform, this is not big\nenough to fit an unsigned 32-bit int. Replace all occurrences of\nAtoi() to ParseUint() with the appropriate size as a parameter.\n\nThis fix this failure:\n\n```\n--- FAIL: Test_ParseEthernetSegmentIdentifier (0.00s)\n        Error Trace:    bgp_test.go:1181\n        Error:          Expected nil, but got: &errors.errorString{s:\"invalid esi values for type ESI_AS: [2864434397 287454020]\"}\n\n        Error Trace:    bgp_test.go:1182\n        Error:          Not equal: bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0xaa, 0xbb, 0xcc, 0xdd, 0x11, 0x22, 0x33, 0x44, 0x0}} (expected)\n                                != bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0}} (actual)\n\n                        Diff:\n                        --- Expected\n                        +++ Actual\n                        @@ -1,2 +1,2 @@\n                        -(bgp.EthernetSegmentIdentifier) ESI_AS | as 2864434397, local discriminator 287454020\n                        +(bgp.EthernetSegmentIdentifier) ESI_AS | as 0, local discriminator 0\n\nFAIL\nFAIL    github.com/osrg/gobgp/packet/bgp        0.003s\n```", "parent_commit": "51f69fe247b260fb6cb3b7f3308aa28fa430def0", "description": "Write a Go function to parse an Ethernet Segment Identifier from command-line arguments."}
{"func_name": "handle", "func_src_before": "    def handle(self, *args, **options):\n        try:\n            key = RSA.generate(1024)\n            rsakey = RSAKey(key=key.exportKey('PEM').decode('utf8'))\n            rsakey.save()\n            self.stdout.write(u'RSA key successfully created with kid: {0}'.format(rsakey.kid))\n        except Exception as e:\n            self.stdout.write('Something goes wrong: {0}'.format(e))", "func_src_after": "    def handle(self, *args, **options):\n        try:\n            key = RSA.generate(2048)\n            rsakey = RSAKey(key=key.exportKey('PEM').decode('utf8'))\n            rsakey.save()\n            self.stdout.write(u'RSA key successfully created with kid: {0}'.format(rsakey.kid))\n        except Exception as e:\n            self.stdout.write('Something goes wrong: {0}'.format(e))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 90, "line": "            key = RSA.generate(1024)\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 90, "line": "            key = RSA.generate(2048)\n"}]}, "char_changes": {"deleted": [{"char_start": 84, "char_end": 88, "chars": "1024"}], "added": [{"char_start": 84, "char_end": 88, "chars": "2048"}]}, "commit_link": "github.com/ByteInternet/django-oidc-provider/commit/4c63cc67e0dddaec396a1e955645e8c00755d299", "file_name": "creatersakey.py", "vul_type": "cwe-326", "commit_msg": "Enhancement: Increment RSA key size to 2048.\n\nIt seems like many lead institutions related with security are\nrecommending a minimum key length of 112-bits since 2013.\nIn order to achieve that, a RSA key size of 2048 (or more) is required.", "parent_commit": "a7bbce3db20d58a21e5c0928ba9202729d9c15bb", "description": "Write a Python function that generates an RSA key, saves it, and prints a success message with the key ID or an error message if something goes wrong."}
{"func_name": "get", "func_src_before": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = %s\"\"\", (user_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `get` that retrieves user data from a database using the user's ID."}
{"func_name": "get_max_task_id_for_project", "func_src_before": "    @staticmethod\n    def get_max_task_id_for_project(project_id: int):\n        \"\"\"Gets the nights task id currently in use on a project\"\"\"\n        sql = \"\"\"select max(id) from tasks where project_id = {0} GROUP BY project_id\"\"\".format(project_id)\n        result = db.engine.execute(sql)\n        if result.rowcount == 0:\n            raise NotFound()\n        for row in result:\n            return row[0]", "func_src_after": "    @staticmethod\n    def get_max_task_id_for_project(project_id: int):\n        \"\"\"Gets the nights task id currently in use on a project\"\"\"\n        sql = \"\"\"select max(id) from tasks where project_id = :project_id GROUP BY project_id\"\"\"\n        result = db.engine.execute(text(sql), project_id=project_id)\n        if result.rowcount == 0:\n            raise NotFound()\n        for row in result:\n            return row[0]", "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/task.py", "vul_type": "cwe-089", "description": "Write a Python method to fetch the highest task ID for a given project ID from a database, raising an exception if no tasks are found."}
{"func_name": "WriteImageChannels", "func_src_before": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory(2*channels*\n        next_image->columns,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory((2*channels*\n        next_image->columns)+1,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/6f1879d498bcc5cce12fe0c5decb8dbc0f608e5d", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "In C, write a function to handle writing image channel data with optional RLE compression and color space considerations."}
{"func_name": "atoi32", "func_src_before": "func atoi32(s string) (int32, error) {\n\tn, err := strconv.Atoi(s)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn int32(n), nil\n}", "func_src_after": "func atoi32(s string) (int32, error) {\n\tn, err := strconv.ParseInt(s, 0, 32)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn int32(n), nil\n}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 39, "char_end": 66, "line": "\tn, err := strconv.Atoi(s)\n"}], "added": [{"line_no": 2, "char_start": 39, "char_end": 77, "line": "\tn, err := strconv.ParseInt(s, 0, 32)\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 64, "chars": "Atoi(s"}], "added": [{"char_start": 58, "char_end": 75, "chars": "ParseInt(s, 0, 32"}]}, "commit_link": "github.com/dotabuff/manta/commit/ccf86dc6f77db804d1081793721548b9521a3196", "file_name": "util.go", "vul_type": "cwe-681", "commit_msg": "Fix atoi32 for large numbers on 64 bit OSes.\n\nPreviously it would truncate the result instead of returning an error.\n\nBecause int is 64 bits on 64 bit operating systems, strconv.Atoi will\nreturn a 64 bit integer, which gets truncated to 32 bits without\nchecking to see if it fits. strconv.ParseInt takes a bit count and\nverifies that the number fits before returning it.", "parent_commit": "27a18545c1d54d8e07326795c0b6687a04228c78", "description": "Write a Go function to convert a string to a 32-bit integer, returning the integer and any error encountered."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHPAPI PHP_FUNCTION(fread)\n{\n\tzval *arg1;\n\tlong len;\n\tphp_stream *stream;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rl\", &arg1, &len) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tPHP_STREAM_TO_ZVAL(stream, &arg1);\n\n\tif (len <= 0) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Length parameter must be greater than 0\");\n\t\tRETURN_FALSE;\n\t}\n\n\tZ_STRVAL_P(return_value) = emalloc(len + 1);\n\tZ_STRLEN_P(return_value) = php_stream_read(stream, Z_STRVAL_P(return_value), len);\n\n\t/* needed because recv/read/gzread doesnt put a null at the end*/\n\tZ_STRVAL_P(return_value)[Z_STRLEN_P(return_value)] = 0;\n\tZ_TYPE_P(return_value) = IS_STRING;\n}", "func_src_after": "PHPAPI PHP_FUNCTION(fread)\n{\n\tzval *arg1;\n\tlong len;\n\tphp_stream *stream;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rl\", &arg1, &len) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tPHP_STREAM_TO_ZVAL(stream, &arg1);\n\n\tif (len <= 0) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Length parameter must be greater than 0\");\n\t\tRETURN_FALSE;\n\t}\n\n\tif (len > INT_MAX) {\n\t\t/* string length is int in 5.x so we can not read more than int */\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Length parameter must be no more than %d\", INT_MAX);\n\t\tRETURN_FALSE;\n\t}\n\n\tZ_STRVAL_P(return_value) = emalloc(len + 1);\n\tZ_STRLEN_P(return_value) = php_stream_read(stream, Z_STRVAL_P(return_value), len);\n\n\t/* needed because recv/read/gzread doesnt put a null at the end*/\n\tZ_STRVAL_P(return_value)[Z_STRLEN_P(return_value)] = 0;\n\tZ_TYPE_P(return_value) = IS_STRING;\n}", "commit_link": "github.com/php/php-src/commit/abd159cce48f3e34f08e4751c568e09677d5ec9c", "file_name": "ext/standard/file.c", "vul_type": "cwe-190", "description": "Write a PHP function to read a specified number of bytes from a stream resource."}
{"func_name": "auto_unlock_tasks", "func_src_before": "    @staticmethod\n    def auto_unlock_tasks(project_id: int):\n        \"\"\"Unlock all tasks locked for longer than the auto-unlock delta\"\"\"\n        expiry_delta = Task.auto_unlock_delta()\n        lock_duration = (datetime.datetime.min + expiry_delta).time().isoformat()\n        expiry_date = datetime.datetime.utcnow() - expiry_delta\n        old_locks_query = '''SELECT t.id\n            FROM tasks t, task_history th\n            WHERE t.id = th.task_id\n            AND t.project_id = th.project_id\n            AND t.task_status IN (1,3)\n            AND th.action IN ( 'LOCKED_FOR_VALIDATION','LOCKED_FOR_MAPPING' )\n            AND th.action_text IS NULL\n            AND t.project_id = {0}\n            AND th.action_date <= '{1}'\n            '''.format(project_id, str(expiry_date))\n\n        old_tasks = db.engine.execute(old_locks_query)\n\n        if old_tasks.rowcount == 0:\n            # no tasks older than the delta found, return without further processing\n            return\n\n        for old_task in old_tasks:\n            task = Task.get(old_task[0], project_id)\n            task.auto_unlock_expired_tasks(expiry_date, lock_duration)", "func_src_after": "    @staticmethod\n    def auto_unlock_tasks(project_id: int):\n        \"\"\"Unlock all tasks locked for longer than the auto-unlock delta\"\"\"\n        expiry_delta = Task.auto_unlock_delta()\n        lock_duration = (datetime.datetime.min + expiry_delta).time().isoformat()\n        expiry_date = datetime.datetime.utcnow() - expiry_delta\n        old_locks_query = '''SELECT t.id\n            FROM tasks t, task_history th\n            WHERE t.id = th.task_id\n            AND t.project_id = th.project_id\n            AND t.task_status IN (1,3)\n            AND th.action IN ( 'LOCKED_FOR_VALIDATION','LOCKED_FOR_MAPPING' )\n            AND th.action_text IS NULL\n            AND t.project_id = :project_id\n            AND th.action_date <= :expiry_date\n            '''\n\n        old_tasks = db.engine.execute(text(old_locks_query), project_id=project_id, expiry_date=str(expiry_date))\n\n        if old_tasks.rowcount == 0:\n            # no tasks older than the delta found, return without further processing\n            return\n\n        for old_task in old_tasks:\n            task = Task.get(old_task[0], project_id)\n            task.auto_unlock_expired_tasks(expiry_date, lock_duration)", "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/task.py", "vul_type": "cwe-089", "description": "Write a Python function to automatically unlock tasks in a database that have been locked beyond a specified duration for a given project."}
{"func_name": "allow_plugins?", "func_src_before": "  def allow_plugins?\n    safe_mode = params[\"safe_mode\"]\n    !(safe_mode && safe_mode.include?(\"no_plugins\"))\n  end", "func_src_after": "  def allow_plugins?\n    safe_mode = params[SAFE_MODE]\n    !(safe_mode && safe_mode.include?(NO_PLUGINS))\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 21, "char_end": 57, "line": "    safe_mode = params[\"safe_mode\"]\n"}, {"line_no": 3, "char_start": 57, "char_end": 110, "line": "    !(safe_mode && safe_mode.include?(\"no_plugins\"))\n"}], "added": [{"line_no": 2, "char_start": 21, "char_end": 55, "line": "    safe_mode = params[SAFE_MODE]\n"}, {"line_no": 3, "char_start": 55, "char_end": 106, "line": "    !(safe_mode && safe_mode.include?(NO_PLUGINS))\n"}]}, "char_changes": {"deleted": [{"char_start": 44, "char_end": 55, "chars": "\"safe_mode\""}, {"char_start": 95, "char_end": 107, "chars": "\"no_plugins\""}], "added": [{"char_start": 44, "char_end": 53, "chars": "SAFE_MODE"}, {"char_start": 93, "char_end": 103, "chars": "NO_PLUGINS"}]}, "commit_link": "github.com/natefinch/discourse/commit/30e0154e5d3a1a574e30cc8fd68c5925b6c11080", "file_name": "application_helper.rb", "vul_type": "cwe-079", "commit_msg": "SECURITY: fix reflected XSS with safe_mode param\n\n(only applies to beta and master)", "description": "Write a Ruby function named `allow_plugins?` that checks a parameter to determine if plugins should be allowed."}
{"func_name": "print_c_function", "func_src_before": "static void print_c_function(const state st) {\n  const char TYPE[] = \"__m256i \";\n  char buf[10];\n  printf(\"static inline void sbox(const %sin0, const %sin1, const %sin2, const %sin3,\\n\"\n      \"const %sin4, const %sin5, const %sin6, const %sin7, %s*out0,\\n\"\n      \"%s*out1, %s*out2, %s*out3, %s*out4, %s*out5, %s*out6,\\n\"\n      \"%s*out7) {\\n\", TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE,\n      TYPE, TYPE, TYPE);\n  for (uint8_t gate = 8; gate < st.num_gates; gate++) {\n    bool ret = get_c_variable_name(st, gate, buf);\n    printf(\"  %s%s = \", ret == true ? TYPE : \"\", buf);\n    get_c_variable_name(st, st.gates[gate].in1, buf);\n    if (st.gates[gate].type == NOT) {\n      printf(\"~%s;\\n\", buf);\n      continue;\n    }\n    printf(\"%s \", buf);\n    switch (st.gates[gate].type) {\n      case AND:\n        printf(\"& \");\n        break;\n      case OR:\n        printf(\"| \");\n        break;\n      case XOR:\n        printf(\"^ \");\n        break;\n      default:\n        assert(false);\n    }\n    get_c_variable_name(st, st.gates[gate].in2, buf);\n    printf(\"%s;\\n\", buf);\n  }\n  printf(\"}\\n\");\n}", "func_src_after": "static void print_c_function(const state st) {\n  const char TYPE[] = \"__m256i \";\n  char buf[10];\n  printf(\"static inline void sbox(const %sin0, const %sin1, const %sin2, const %sin3,\\n\"\n      \"const %sin4, const %sin5, const %sin6, const %sin7, %s*out0,\\n\"\n      \"%s*out1, %s*out2, %s*out3, %s*out4, %s*out5, %s*out6,\\n\"\n      \"%s*out7) {\\n\", TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE,\n      TYPE, TYPE, TYPE);\n  for (uint64_t gate = 8; gate < st.num_gates; gate++) {\n    bool ret = get_c_variable_name(st, gate, buf);\n    printf(\"  %s%s = \", ret == true ? TYPE : \"\", buf);\n    get_c_variable_name(st, st.gates[gate].in1, buf);\n    if (st.gates[gate].type == NOT) {\n      printf(\"~%s;\\n\", buf);\n      continue;\n    }\n    printf(\"%s \", buf);\n    switch (st.gates[gate].type) {\n      case AND:\n        printf(\"& \");\n        break;\n      case OR:\n        printf(\"| \");\n        break;\n      case XOR:\n        printf(\"^ \");\n        break;\n      default:\n        assert(false);\n    }\n    get_c_variable_name(st, st.gates[gate].in2, buf);\n    printf(\"%s;\\n\", buf);\n  }\n  printf(\"}\\n\");\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 446, "char_end": 502, "line": "  for (uint8_t gate = 8; gate < st.num_gates; gate++) {\n"}], "added": [{"line_no": 9, "char_start": 446, "char_end": 503, "line": "  for (uint64_t gate = 8; gate < st.num_gates; gate++) {\n"}]}, "char_changes": {"deleted": [{"char_start": 457, "char_end": 458, "chars": "8"}], "added": [{"char_start": 457, "char_end": 459, "chars": "64"}]}, "commit_link": "github.com/dansarie/sboxgates/commit/5dffb1e61a9f28ef596684d6e401c3ee166bb4eb", "file_name": "sboxgates.c", "vul_type": "cwe-190", "commit_msg": "Fix integer overflow when generating C source code.", "parent_commit": "7cb0a30fe10f56e862b3d62973f65d8c3222e67a", "description": "Write a C function that prints the definition of an inline function for a substitution box (s-box) with input and output parameters, and a loop that generates bitwise operations based on a given state structure."}
{"func_name": "CSoundFile::GetLength", "func_src_before": "std::vector<GetLengthType> CSoundFile::GetLength(enmGetLengthResetMode adjustMode, GetLengthTarget target)\n{\n\tstd::vector<GetLengthType> results;\n\tGetLengthType retval;\n\tretval.startOrder = target.startOrder;\n\tretval.startRow = target.startRow;\n\n\t// Are we trying to reach a certain pattern position?\n\tconst bool hasSearchTarget = target.mode != GetLengthTarget::NoTarget;\n\tconst bool adjustSamplePos = (adjustMode & eAdjustSamplePositions) == eAdjustSamplePositions;\n\n\tSEQUENCEINDEX sequence = target.sequence;\n\tif(sequence >= Order.GetNumSequences()) sequence = Order.GetCurrentSequenceIndex();\n\tconst ModSequence &orderList = Order(sequence);\n\n\tGetLengthMemory memory(*this);\n\tCSoundFile::PlayState &playState = *memory.state;\n\t// Temporary visited rows vector (so that GetLength() won't interfere with the player code if the module is playing at the same time)\n\tRowVisitor visitedRows(*this, sequence);\n\n\tplayState.m_nNextRow = playState.m_nRow = target.startRow;\n\tplayState.m_nNextOrder = playState.m_nCurrentOrder = target.startOrder;\n\n\t// Fast LUTs for commands that are too weird / complicated / whatever to emulate in sample position adjust mode.\n\tstd::bitset<MAX_EFFECTS> forbiddenCommands;\n\tstd::bitset<MAX_VOLCMDS> forbiddenVolCommands;\n\n\tif(adjustSamplePos)\n\t{\n\t\tforbiddenCommands.set(CMD_ARPEGGIO);             forbiddenCommands.set(CMD_PORTAMENTOUP);\n\t\tforbiddenCommands.set(CMD_PORTAMENTODOWN);       forbiddenCommands.set(CMD_XFINEPORTAUPDOWN);\n\t\tforbiddenCommands.set(CMD_NOTESLIDEUP);          forbiddenCommands.set(CMD_NOTESLIDEUPRETRIG);\n\t\tforbiddenCommands.set(CMD_NOTESLIDEDOWN);        forbiddenCommands.set(CMD_NOTESLIDEDOWNRETRIG);\n\t\tforbiddenVolCommands.set(VOLCMD_PORTAUP);        forbiddenVolCommands.set(VOLCMD_PORTADOWN);\n\n\t\t// Optimize away channels for which it's pointless to adjust sample positions\n\t\tfor(CHANNELINDEX i = 0; i < GetNumChannels(); i++)\n\t\t{\n\t\t\tif(ChnSettings[i].dwFlags[CHN_MUTE]) memory.chnSettings[i].ticksToRender = GetLengthMemory::IGNORE_CHANNEL;\n\t\t}\n\t\tif(target.mode == GetLengthTarget::SeekPosition && target.pos.order < orderList.size())\n\t\t{\n\t\t\t// If we know where to seek, we can directly rule out any channels on which a new note would be triggered right at the start.\n\t\t\tconst PATTERNINDEX seekPat = orderList[target.pos.order];\n\t\t\tif(Patterns.IsValidPat(seekPat) && Patterns[seekPat].IsValidRow(target.pos.row))\n\t\t\t{\n\t\t\t\tconst ModCommand *m = Patterns[seekPat].GetRow(target.pos.row);\n\t\t\t\tfor(CHANNELINDEX i = 0; i < GetNumChannels(); i++, m++)\n\t\t\t\t{\n\t\t\t\t\tif(m->note == NOTE_NOTECUT || m->note == NOTE_KEYOFF || (m->note == NOTE_FADE && GetNumInstruments())\n\t\t\t\t\t\t|| (m->IsNote() && !m->IsPortamento()))\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.chnSettings[i].ticksToRender = GetLengthMemory::IGNORE_CHANNEL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// If samples are being synced, force them to resync if tick duration changes\n\tuint32 oldTickDuration = 0;\n\n\tfor (;;)\n\t{\n\t\t// Time target reached.\n\t\tif(target.mode == GetLengthTarget::SeekSeconds && memory.elapsedTime >= target.time)\n\t\t{\n\t\t\tretval.targetReached = true;\n\t\t\tbreak;\n\t\t}\n\n\t\tuint32 rowDelay = 0, tickDelay = 0;\n\t\tplayState.m_nRow = playState.m_nNextRow;\n\t\tplayState.m_nCurrentOrder = playState.m_nNextOrder;\n\n\t\tif(orderList.IsValidPat(playState.m_nCurrentOrder) && playState.m_nRow >= Patterns[orderList[playState.m_nCurrentOrder]].GetNumRows())\n\t\t{\n\t\t\tplayState.m_nRow = 0;\n\t\t\tif(m_playBehaviour[kFT2LoopE60Restart])\n\t\t\t{\n\t\t\t\tplayState.m_nRow = playState.m_nNextPatStartRow;\n\t\t\t\tplayState.m_nNextPatStartRow = 0;\n\t\t\t}\n\t\t\tplayState.m_nCurrentOrder = ++playState.m_nNextOrder;\n\t\t}\n\n\t\t// Check if pattern is valid\n\t\tplayState.m_nPattern = playState.m_nCurrentOrder < orderList.size() ? orderList[playState.m_nCurrentOrder] : orderList.GetInvalidPatIndex();\n\t\tbool positionJumpOnThisRow = false;\n\t\tbool patternBreakOnThisRow = false;\n\t\tbool patternLoopEndedOnThisRow = false, patternLoopStartedOnThisRow = false;\n\n\t\tif(!Patterns.IsValidPat(playState.m_nPattern) && playState.m_nPattern != orderList.GetInvalidPatIndex() && target.mode == GetLengthTarget::SeekPosition && playState.m_nCurrentOrder == target.pos.order)\n\t\t{\n\t\t\t// Early test: Target is inside +++ or non-existing pattern\n\t\t\tretval.targetReached = true;\n\t\t\tbreak;\n\t\t}\n\n\t\twhile(playState.m_nPattern >= Patterns.Size())\n\t\t{\n\t\t\t// End of song?\n\t\t\tif((playState.m_nPattern == orderList.GetInvalidPatIndex()) || (playState.m_nCurrentOrder >= orderList.size()))\n\t\t\t{\n\t\t\t\tif(playState.m_nCurrentOrder == orderList.GetRestartPos())\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\tplayState.m_nCurrentOrder = orderList.GetRestartPos();\n\t\t\t} else\n\t\t\t{\n\t\t\t\tplayState.m_nCurrentOrder++;\n\t\t\t}\n\t\t\tplayState.m_nPattern = (playState.m_nCurrentOrder < orderList.size()) ? orderList[playState.m_nCurrentOrder] : orderList.GetInvalidPatIndex();\n\t\t\tplayState.m_nNextOrder = playState.m_nCurrentOrder;\n\t\t\tif((!Patterns.IsValidPat(playState.m_nPattern)) && visitedRows.IsVisited(playState.m_nCurrentOrder, 0, true))\n\t\t\t{\n\t\t\t\tif(!hasSearchTarget || !visitedRows.GetFirstUnvisitedRow(playState.m_nNextOrder, playState.m_nRow, true))\n\t\t\t\t{\n\t\t\t\t\t// We aren't searching for a specific row, or we couldn't find any more unvisited rows.\n\t\t\t\t\tbreak;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\t// We haven't found the target row yet, but we found some other unplayed row... continue searching from here.\n\t\t\t\t\tretval.duration = memory.elapsedTime;\n\t\t\t\t\tresults.push_back(retval);\n\t\t\t\t\tretval.startRow = playState.m_nRow;\n\t\t\t\t\tretval.startOrder = playState.m_nNextOrder;\n\t\t\t\t\tmemory.Reset();\n\n\t\t\t\t\tplayState.m_nCurrentOrder = playState.m_nNextOrder;\n\t\t\t\t\tplayState.m_nPattern = orderList[playState.m_nCurrentOrder];\n\t\t\t\t\tplayState.m_nNextRow = playState.m_nRow;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif(playState.m_nNextOrder == ORDERINDEX_INVALID)\n\t\t{\n\t\t\t// GetFirstUnvisitedRow failed, so there is nothing more to play\n\t\t\tbreak;\n\t\t}\n\n\t\t// Skip non-existing patterns\n\t\tif(!Patterns.IsValidPat(playState.m_nPattern))\n\t\t{\n\t\t\t// If there isn't even a tune, we should probably stop here.\n\t\t\tif(playState.m_nCurrentOrder == orderList.GetRestartPos())\n\t\t\t{\n\t\t\t\tif(!hasSearchTarget || !visitedRows.GetFirstUnvisitedRow(playState.m_nNextOrder, playState.m_nRow, true))\n\t\t\t\t{\n\t\t\t\t\t// We aren't searching for a specific row, or we couldn't find any more unvisited rows.\n\t\t\t\t\tbreak;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\t// We haven't found the target row yet, but we found some other unplayed row... continue searching from here.\n\t\t\t\t\tretval.duration = memory.elapsedTime;\n\t\t\t\t\tresults.push_back(retval);\n\t\t\t\t\tretval.startRow = playState.m_nRow;\n\t\t\t\t\tretval.startOrder = playState.m_nNextOrder;\n\t\t\t\t\tmemory.Reset();\n\t\t\t\t\tplayState.m_nNextRow = playState.m_nRow;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tplayState.m_nNextOrder = playState.m_nCurrentOrder + 1;\n\t\t\tcontinue;\n\t\t}\n\t\t// Should never happen\n\t\tif(playState.m_nRow >= Patterns[playState.m_nPattern].GetNumRows())\n\t\t\tplayState.m_nRow = 0;\n\n\t\t// Check whether target was reached.\n\t\tif(target.mode == GetLengthTarget::SeekPosition && playState.m_nCurrentOrder == target.pos.order && playState.m_nRow == target.pos.row)\n\t\t{\n\t\t\tretval.targetReached = true;\n\t\t\tbreak;\n\t\t}\n\n\t\tif(visitedRows.IsVisited(playState.m_nCurrentOrder, playState.m_nRow, true))\n\t\t{\n\t\t\tif(!hasSearchTarget || !visitedRows.GetFirstUnvisitedRow(playState.m_nNextOrder, playState.m_nRow, true))\n\t\t\t{\n\t\t\t\t// We aren't searching for a specific row, or we couldn't find any more unvisited rows.\n\t\t\t\tbreak;\n\t\t\t} else\n\t\t\t{\n\t\t\t\t// We haven't found the target row yet, but we found some other unplayed row... continue searching from here.\n\t\t\t\tretval.duration = memory.elapsedTime;\n\t\t\t\tresults.push_back(retval);\n\t\t\t\tretval.startRow = playState.m_nRow;\n\t\t\t\tretval.startOrder = playState.m_nNextOrder;\n\t\t\t\tmemory.Reset();\n\t\t\t\tplayState.m_nNextRow = playState.m_nRow;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tretval.endOrder = playState.m_nCurrentOrder;\n\t\tretval.endRow = playState.m_nRow;\n\n\t\t// Update next position\n\t\tplayState.m_nNextRow = playState.m_nRow + 1;\n\n\t\t// Jumped to invalid pattern row?\n\t\tif(playState.m_nRow >= Patterns[playState.m_nPattern].GetNumRows())\n\t\t{\n\t\t\tplayState.m_nRow = 0;\n\t\t}\n\t\t// New pattern?\n\t\tif(!playState.m_nRow)\n\t\t{\n\t\t\tfor(CHANNELINDEX chn = 0; chn < GetNumChannels(); chn++)\n\t\t\t{\n\t\t\t\tmemory.chnSettings[chn].patLoop = memory.elapsedTime;\n\t\t\t\tmemory.chnSettings[chn].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t}\n\t\t}\n\n\t\tModChannel *pChn = playState.Chn;\n\t\t\n\t\t// For various effects, we need to know first how many ticks there are in this row.\n\t\tconst ModCommand *p = Patterns[playState.m_nPattern].GetpModCommand(playState.m_nRow, 0);\n\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++, p++)\n\t\t{\n\t\t\tif(m_playBehaviour[kST3NoMutedChannels] && ChnSettings[nChn].dwFlags[CHN_MUTE])\t// not even effects are processed on muted S3M channels\n\t\t\t\tcontinue;\n\t\t\tif(p->IsPcNote())\n\t\t\t{\n#ifndef NO_PLUGINS\n\t\t\t\tif((adjustMode & eAdjust) && p->instr > 0 && p->instr <= MAX_MIXPLUGINS)\n\t\t\t\t{\n\t\t\t\t\tmemory.plugParams[std::make_pair(p->instr, p->GetValueVolCol())] = p->GetValueEffectCol();\n\t\t\t\t}\n#endif // NO_PLUGINS\n\t\t\t\tpChn[nChn].rowCommand.Clear();\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tpChn[nChn].rowCommand = *p;\n\t\t\tswitch(p->command)\n\t\t\t{\n\t\t\tcase CMD_SPEED:\n\t\t\t\tSetSpeed(playState, p->param);\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_TEMPO:\n\t\t\t\tif(m_playBehaviour[kMODVBlankTiming])\n\t\t\t\t{\n\t\t\t\t\t// ProTracker MODs with VBlank timing: All Fxx parameters set the tick count.\n\t\t\t\t\tif(p->param != 0) SetSpeed(playState, p->param);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_S3MCMDEX:\n\t\t\t\tif((p->param & 0xF0) == 0x60)\n\t\t\t\t{\n\t\t\t\t\t// Fine Pattern Delay\n\t\t\t\t\ttickDelay += (p->param & 0x0F);\n\t\t\t\t} else if((p->param & 0xF0) == 0xE0 && !rowDelay)\n\t\t\t\t{\n\t\t\t\t\t// Pattern Delay\n\t\t\t\t\tif(!(GetType() & MOD_TYPE_S3M) || (p->param & 0x0F) != 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t// While Impulse Tracker *does* count S60 as a valid row delay (and thus ignores any other row delay commands on the right),\n\t\t\t\t\t\t// Scream Tracker 3 simply ignores such commands.\n\t\t\t\t\t\trowDelay = 1 + (p->param & 0x0F);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_MODCMDEX:\n\t\t\t\tif((p->param & 0xF0) == 0xE0)\n\t\t\t\t{\n\t\t\t\t\t// Pattern Delay\n\t\t\t\t\trowDelay = 1 + (p->param & 0x0F);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif(rowDelay == 0) rowDelay = 1;\n\t\tconst uint32 numTicks = (playState.m_nMusicSpeed + tickDelay) * rowDelay;\n\t\tconst uint32 nonRowTicks = numTicks - rowDelay;\n\n\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); pChn++, nChn++) if(!pChn->rowCommand.IsEmpty())\n\t\t{\n\t\t\tif(m_playBehaviour[kST3NoMutedChannels] && ChnSettings[nChn].dwFlags[CHN_MUTE])\t// not even effects are processed on muted S3M channels\n\t\t\t\tcontinue;\n\t\t\tModCommand::COMMAND command = pChn->rowCommand.command;\n\t\t\tModCommand::PARAM param = pChn->rowCommand.param;\n\t\t\tModCommand::NOTE note = pChn->rowCommand.note;\n\n\t\t\tif (pChn->rowCommand.instr)\n\t\t\t{\n\t\t\t\tpChn->nNewIns = pChn->rowCommand.instr;\n\t\t\t\tpChn->nLastNote = NOTE_NONE;\n\t\t\t\tmemory.chnSettings[nChn].vol = 0xFF;\n\t\t\t}\n\t\t\tif (pChn->rowCommand.IsNote()) pChn->nLastNote = note;\n\n\t\t\t// Update channel panning\n\t\t\tif(pChn->rowCommand.IsNote() || pChn->rowCommand.instr)\n\t\t\t{\n\t\t\t\tSAMPLEINDEX smp = 0;\n\t\t\t\tif(GetNumInstruments())\n\t\t\t\t{\n\t\t\t\t\tModInstrument *pIns;\n\t\t\t\t\tif(pChn->nNewIns <= GetNumInstruments() && (pIns = Instruments[pChn->nNewIns]) != nullptr)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(pIns->dwFlags[INS_SETPANNING])\n\t\t\t\t\t\t\tpChn->nPan = pIns->nPan;\n\t\t\t\t\t\tif(ModCommand::IsNote(note))\n\t\t\t\t\t\t\tsmp = pIns->Keyboard[note - NOTE_MIN];\n\t\t\t\t\t}\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tsmp = pChn->nNewIns;\n\t\t\t\t}\n\t\t\t\tif(smp > 0 && smp <= GetNumSamples() && Samples[smp].uFlags[CHN_PANNING])\n\t\t\t\t{\n\t\t\t\t\tpChn->nPan = Samples[smp].nPan;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tswitch(pChn->rowCommand.volcmd)\n\t\t\t{\n\t\t\tcase VOLCMD_VOLUME:\n\t\t\t\tmemory.chnSettings[nChn].vol = pChn->rowCommand.vol;\n\t\t\t\tbreak;\n\t\t\tcase VOLCMD_VOLSLIDEUP:\n\t\t\tcase VOLCMD_VOLSLIDEDOWN:\n\t\t\t\tif(pChn->rowCommand.vol != 0)\n\t\t\t\t\tpChn->nOldVolParam = pChn->rowCommand.vol;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch(command)\n\t\t\t{\n\t\t\t// Position Jump\n\t\t\tcase CMD_POSITIONJUMP:\n\t\t\t\tpositionJumpOnThisRow = true;\n\t\t\t\tplayState.m_nNextOrder = static_cast<ORDERINDEX>(CalculateXParam(playState.m_nPattern, playState.m_nRow, nChn));\n\t\t\t\tplayState.m_nNextPatStartRow = 0;  // FT2 E60 bug\n\t\t\t\t// see https://forum.openmpt.org/index.php?topic=2769.0 - FastTracker resets Dxx if Bxx is called _after_ Dxx\n\t\t\t\t// Test case: PatternJump.mod\n\t\t\t\tif(!patternBreakOnThisRow || (GetType() & (MOD_TYPE_MOD | MOD_TYPE_XM)))\n\t\t\t\t\tplayState.m_nNextRow = 0;\n\n\t\t\t\tif (adjustMode & eAdjust)\n\t\t\t\t{\n\t\t\t\t\tpChn->nPatternLoopCount = 0;\n\t\t\t\t\tpChn->nPatternLoop = 0;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t// Pattern Break\n\t\t\tcase CMD_PATTERNBREAK:\n\t\t\t\t{\n\t\t\t\t\tROWINDEX row = PatternBreak(playState, nChn, param);\n\t\t\t\t\tif(row != ROWINDEX_INVALID)\n\t\t\t\t\t{\n\t\t\t\t\t\tpatternBreakOnThisRow = true;\n\t\t\t\t\t\tplayState.m_nNextRow = row;\n\n\t\t\t\t\t\tif(!positionJumpOnThisRow)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tplayState.m_nNextOrder = playState.m_nCurrentOrder + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif(adjustMode & eAdjust)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tpChn->nPatternLoopCount = 0;\n\t\t\t\t\t\t\tpChn->nPatternLoop = 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t// Set Tempo\n\t\t\tcase CMD_TEMPO:\n\t\t\t\tif(!m_playBehaviour[kMODVBlankTiming])\n\t\t\t\t{\n\t\t\t\t\tTEMPO tempo(CalculateXParam(playState.m_nPattern, playState.m_nRow, nChn), 0);\n\t\t\t\t\tif ((adjustMode & eAdjust) && (GetType() & (MOD_TYPE_S3M | MOD_TYPE_IT | MOD_TYPE_MPT)))\n\t\t\t\t\t{\n\t\t\t\t\t\tif (tempo.GetInt()) pChn->nOldTempo = static_cast<uint8>(tempo.GetInt()); else tempo.Set(pChn->nOldTempo);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (tempo.GetInt() >= 0x20) playState.m_nMusicTempo = tempo;\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\t// Tempo Slide\n\t\t\t\t\t\tTEMPO tempoDiff((tempo.GetInt() & 0x0F) * nonRowTicks, 0);\n\t\t\t\t\t\tif ((tempo.GetInt() & 0xF0) == 0x10)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tplayState.m_nMusicTempo += tempoDiff;\n\t\t\t\t\t\t} else\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif(tempoDiff < playState.m_nMusicTempo)\n\t\t\t\t\t\t\t\tplayState.m_nMusicTempo -= tempoDiff;\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\tplayState.m_nMusicTempo.Set(0);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tTEMPO tempoMin = GetModSpecifications().GetTempoMin(), tempoMax = GetModSpecifications().GetTempoMax();\n\t\t\t\t\tif(m_playBehaviour[kTempoClamp])\t// clamp tempo correctly in compatible mode\n\t\t\t\t\t{\n\t\t\t\t\t\ttempoMax.Set(255);\n\t\t\t\t\t}\n\t\t\t\t\tLimit(playState.m_nMusicTempo, tempoMin, tempoMax);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_S3MCMDEX:\n\t\t\t\tswitch(param & 0xF0)\n\t\t\t\t{\n\t\t\t\tcase 0x90:\n\t\t\t\t\tif(param <= 0x91)\n\t\t\t\t\t{\n\t\t\t\t\t\tpChn->dwFlags.set(CHN_SURROUND, param == 0x91);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 0xA0:\n\t\t\t\t\t// High sample offset\n\t\t\t\t\tpChn->nOldHiOffset = param & 0x0F;\n\t\t\t\t\tbreak;\n\t\t\t\t\n\t\t\t\tcase 0xB0:\n\t\t\t\t\t// Pattern Loop\n\t\t\t\t\tif (param & 0x0F)\n\t\t\t\t\t{\n\t\t\t\t\t\tpatternLoopEndedOnThisRow = true;\n\t\t\t\t\t} else\n\t\t\t\t\t{\n\t\t\t\t\t\tCHANNELINDEX firstChn = nChn, lastChn = nChn;\n\t\t\t\t\t\tif(GetType() == MOD_TYPE_S3M)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// ST3 has only one global loop memory.\n\t\t\t\t\t\t\tfirstChn = 0;\n\t\t\t\t\t\t\tlastChn = GetNumChannels() - 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor(CHANNELINDEX c = firstChn; c <= lastChn; c++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tmemory.chnSettings[c].patLoop = memory.elapsedTime;\n\t\t\t\t\t\t\tmemory.chnSettings[c].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t\t\t\t\tmemory.chnSettings[c].patLoopStart = playState.m_nRow;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tpatternLoopStartedOnThisRow = true;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 0xF0:\n\t\t\t\t\t// Active macro\n\t\t\t\t\tpChn->nActiveMacro = param & 0x0F;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_MODCMDEX:\n\t\t\t\tswitch(param & 0xF0)\n\t\t\t\t{\n\t\t\t\tcase 0x60:\n\t\t\t\t\t// Pattern Loop\n\t\t\t\t\tif (param & 0x0F)\n\t\t\t\t\t{\n\t\t\t\t\t\tplayState.m_nNextPatStartRow = memory.chnSettings[nChn].patLoopStart; // FT2 E60 bug\n\t\t\t\t\t\tpatternLoopEndedOnThisRow = true;\n\t\t\t\t\t} else\n\t\t\t\t\t{\n\t\t\t\t\t\tpatternLoopStartedOnThisRow = true;\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoop = memory.elapsedTime;\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopStart = playState.m_nRow;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 0xF0:\n\t\t\t\t\t// Active macro\n\t\t\t\t\tpChn->nActiveMacro = param & 0x0F;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_XFINEPORTAUPDOWN:\n\t\t\t\t// ignore high offset in compatible mode\n\t\t\t\tif(((param & 0xF0) == 0xA0) && !m_playBehaviour[kFT2RestrictXCommand]) pChn->nOldHiOffset = param & 0x0F;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// The following calculations are not interesting if we just want to get the song length.\n\t\t\tif (!(adjustMode & eAdjust)) continue;\n\t\t\tswitch(command)\n\t\t\t{\n\t\t\t// Portamento Up/Down\n\t\t\tcase CMD_PORTAMENTOUP:\n\t\t\t\tif(param)\n\t\t\t\t{\n\t\t\t\t\t// FT2 compatibility: Separate effect memory for all portamento commands\n\t\t\t\t\t// Test case: Porta-LinkMem.xm\n\t\t\t\t\tif(!m_playBehaviour[kFT2PortaUpDownMemory])\n\t\t\t\t\t\tpChn->nOldPortaDown = param;\n\t\t\t\t\tpChn->nOldPortaUp = param;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase CMD_PORTAMENTODOWN:\n\t\t\t\tif(param)\n\t\t\t\t{\n\t\t\t\t\t// FT2 compatibility: Separate effect memory for all portamento commands\n\t\t\t\t\t// Test case: Porta-LinkMem.xm\n\t\t\t\t\tif(!m_playBehaviour[kFT2PortaUpDownMemory])\n\t\t\t\t\t\tpChn->nOldPortaUp = param;\n\t\t\t\t\tpChn->nOldPortaDown = param;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t// Tone-Portamento\n\t\t\tcase CMD_TONEPORTAMENTO:\n\t\t\t\tif (param) pChn->nPortamentoSlide = param << 2;\n\t\t\t\tbreak;\n\t\t\t// Offset\n\t\t\tcase CMD_OFFSET:\n\t\t\t\tif (param) pChn->oldOffset = param << 8;\n\t\t\t\tbreak;\n\t\t\t// Volume Slide\n\t\t\tcase CMD_VOLUMESLIDE:\n\t\t\tcase CMD_TONEPORTAVOL:\n\t\t\t\tif (param) pChn->nOldVolumeSlide = param;\n\t\t\t\tbreak;\n\t\t\t// Set Volume\n\t\t\tcase CMD_VOLUME:\n\t\t\t\tmemory.chnSettings[nChn].vol = param;\n\t\t\t\tbreak;\n\t\t\t// Global Volume\n\t\t\tcase CMD_GLOBALVOLUME:\n\t\t\t\tif(!(GetType() & GLOBALVOL_7BIT_FORMATS) && param < 128) param *= 2;\n\t\t\t\t// IT compatibility 16. ST3 and IT ignore out-of-range values\n\t\t\t\tif(param <= 128)\n\t\t\t\t{\n\t\t\t\t\tplayState.m_nGlobalVolume = param * 2;\n\t\t\t\t} else if(!(GetType() & (MOD_TYPE_IT | MOD_TYPE_MPT | MOD_TYPE_S3M)))\n\t\t\t\t{\n\t\t\t\t\tplayState.m_nGlobalVolume = 256;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t// Global Volume Slide\n\t\t\tcase CMD_GLOBALVOLSLIDE:\n\t\t\t\tif(m_playBehaviour[kPerChannelGlobalVolSlide])\n\t\t\t\t{\n\t\t\t\t\t// IT compatibility 16. Global volume slide params are stored per channel (FT2/IT)\n\t\t\t\t\tif (param) pChn->nOldGlobalVolSlide = param; else param = pChn->nOldGlobalVolSlide;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tif (param) playState.Chn[0].nOldGlobalVolSlide = param; else param = playState.Chn[0].nOldGlobalVolSlide;\n\t\t\t\t}\n\t\t\t\tif (((param & 0x0F) == 0x0F) && (param & 0xF0))\n\t\t\t\t{\n\t\t\t\t\tparam >>= 4;\n\t\t\t\t\tif (!(GetType() & GLOBALVOL_7BIT_FORMATS)) param <<= 1;\n\t\t\t\t\tplayState.m_nGlobalVolume += param << 1;\n\t\t\t\t} else if (((param & 0xF0) == 0xF0) && (param & 0x0F))\n\t\t\t\t{\n\t\t\t\t\tparam = (param & 0x0F) << 1;\n\t\t\t\t\tif (!(GetType() & GLOBALVOL_7BIT_FORMATS)) param <<= 1;\n\t\t\t\t\tplayState.m_nGlobalVolume -= param;\n\t\t\t\t} else if (param & 0xF0)\n\t\t\t\t{\n\t\t\t\t\tparam >>= 4;\n\t\t\t\t\tparam <<= 1;\n\t\t\t\t\tif (!(GetType() & GLOBALVOL_7BIT_FORMATS)) param <<= 1;\n\t\t\t\t\tplayState.m_nGlobalVolume += param * nonRowTicks;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tparam = (param & 0x0F) << 1;\n\t\t\t\t\tif (!(GetType() & GLOBALVOL_7BIT_FORMATS)) param <<= 1;\n\t\t\t\t\tplayState.m_nGlobalVolume -= param * nonRowTicks;\n\t\t\t\t}\n\t\t\t\tLimit(playState.m_nGlobalVolume, 0, 256);\n\t\t\t\tbreak;\n\t\t\tcase CMD_CHANNELVOLUME:\n\t\t\t\tif (param <= 64) pChn->nGlobalVol = param;\n\t\t\t\tbreak;\n\t\t\tcase CMD_CHANNELVOLSLIDE:\n\t\t\t\t{\n\t\t\t\t\tif (param) pChn->nOldChnVolSlide = param; else param = pChn->nOldChnVolSlide;\n\t\t\t\t\tint32 volume = pChn->nGlobalVol;\n\t\t\t\t\tif((param & 0x0F) == 0x0F && (param & 0xF0))\n\t\t\t\t\t\tvolume += (param >> 4);\t\t// Fine Up\n\t\t\t\t\telse if((param & 0xF0) == 0xF0 && (param & 0x0F))\n\t\t\t\t\t\tvolume -= (param & 0x0F);\t// Fine Down\n\t\t\t\t\telse if(param & 0x0F)\t\t\t// Down\n\t\t\t\t\t\tvolume -= (param & 0x0F) * nonRowTicks;\n\t\t\t\t\telse\t\t\t\t\t\t\t// Up\n\t\t\t\t\t\tvolume += ((param & 0xF0) >> 4) * nonRowTicks;\n\t\t\t\t\tLimit(volume, 0, 64);\n\t\t\t\t\tpChn->nGlobalVol = volume;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase CMD_PANNING8:\n\t\t\t\tPanning(pChn, param, Pan8bit);\n\t\t\t\tbreak;\n\t\t\tcase CMD_MODCMDEX:\n\t\t\t\tif(param < 0x10)\n\t\t\t\t{\n\t\t\t\t\t// LED filter\n\t\t\t\t\tfor(CHANNELINDEX chn = 0; chn < GetNumChannels(); chn++)\n\t\t\t\t\t{\n\t\t\t\t\t\tplayState.Chn[chn].dwFlags.set(CHN_AMIGAFILTER, !(param & 1));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tMPT_FALLTHROUGH;\n\t\t\tcase CMD_S3MCMDEX:\n\t\t\t\tif((param & 0xF0) == 0x80)\n\t\t\t\t{\n\t\t\t\t\tPanning(pChn, (param & 0x0F), Pan4bit);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_VIBRATOVOL:\n\t\t\t\tif (param) pChn->nOldVolumeSlide = param;\n\t\t\t\tparam = 0;\n\t\t\t\tMPT_FALLTHROUGH;\n\t\t\tcase CMD_VIBRATO:\n\t\t\t\tVibrato(pChn, param);\n\t\t\t\tbreak;\n\t\t\tcase CMD_FINEVIBRATO:\n\t\t\t\tFineVibrato(pChn, param);\n\t\t\t\tbreak;\n\t\t\tcase CMD_TREMOLO:\n\t\t\t\tTremolo(pChn, param);\n\t\t\t\tbreak;\n\t\t\tcase CMD_PANBRELLO:\n\t\t\t\tPanbrello(pChn, param);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch(pChn->rowCommand.volcmd)\n\t\t\t{\n\t\t\tcase VOLCMD_PANNING:\n\t\t\t\tPanning(pChn, pChn->rowCommand.vol, Pan6bit);\n\t\t\t\tbreak;\n\n\t\t\tcase VOLCMD_VIBRATOSPEED:\n\t\t\t\t// FT2 does not automatically enable vibrato with the \"set vibrato speed\" command\n\t\t\t\tif(m_playBehaviour[kFT2VolColVibrato])\n\t\t\t\t\tpChn->nVibratoSpeed = pChn->rowCommand.vol & 0x0F;\n\t\t\t\telse\n\t\t\t\t\tVibrato(pChn, pChn->rowCommand.vol << 4);\n\t\t\t\tbreak;\n\t\t\tcase VOLCMD_VIBRATODEPTH:\n\t\t\t\tVibrato(pChn, pChn->rowCommand.vol);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// Process vibrato / tremolo / panbrello\n\t\t\tswitch(pChn->rowCommand.command)\n\t\t\t{\n\t\t\tcase CMD_VIBRATO:\n\t\t\tcase CMD_FINEVIBRATO:\n\t\t\tcase CMD_VIBRATOVOL:\n\t\t\t\tif(adjustMode & eAdjust)\n\t\t\t\t{\n\t\t\t\t\tuint32 vibTicks = ((GetType() & (MOD_TYPE_IT | MOD_TYPE_MPT)) && !m_SongFlags[SONG_ITOLDEFFECTS]) ? numTicks : nonRowTicks;\n\t\t\t\t\tuint32 inc = pChn->nVibratoSpeed * vibTicks;\n\t\t\t\t\tif(m_playBehaviour[kITVibratoTremoloPanbrello])\n\t\t\t\t\t\tinc *= 4;\n\t\t\t\t\tpChn->nVibratoPos += static_cast<uint8>(inc);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_TREMOLO:\n\t\t\t\tif(adjustMode & eAdjust)\n\t\t\t\t{\n\t\t\t\t\tuint32 tremTicks = ((GetType() & (MOD_TYPE_IT | MOD_TYPE_MPT)) && !m_SongFlags[SONG_ITOLDEFFECTS]) ? numTicks : nonRowTicks;\n\t\t\t\t\tuint32 inc = pChn->nTremoloSpeed * tremTicks;\n\t\t\t\t\tif(m_playBehaviour[kITVibratoTremoloPanbrello])\n\t\t\t\t\t\tinc *= 4;\n\t\t\t\t\tpChn->nTremoloPos += static_cast<uint8>(inc);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_PANBRELLO:\n\t\t\t\tif(adjustMode & eAdjust)\n\t\t\t\t{\n\t\t\t\t\t// Panbrello effect is permanent in compatible mode, so actually apply panbrello for the last tick of this row\n\t\t\t\t\tpChn->nPanbrelloPos += static_cast<uint8>(pChn->nPanbrelloSpeed * (numTicks - 1));\n\t\t\t\t\tProcessPanbrello(pChn);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t// Interpret F00 effect in XM files as \"stop song\"\n\t\tif(GetType() == MOD_TYPE_XM && playState.m_nMusicSpeed == uint16_max)\n\t\t{\n\t\t\tbreak;\n\t\t}\n\n\t\tplayState.m_nCurrentRowsPerBeat = m_nDefaultRowsPerBeat;\n\t\tif(Patterns[playState.m_nPattern].GetOverrideSignature())\n\t\t{\n\t\t\tplayState.m_nCurrentRowsPerBeat = Patterns[playState.m_nPattern].GetRowsPerBeat();\n\t\t}\n\n\t\tconst uint32 tickDuration = GetTickDuration(playState);\n\t\tconst uint32 rowDuration = tickDuration * numTicks;\n\t\tmemory.elapsedTime += static_cast<double>(rowDuration) / static_cast<double>(m_MixerSettings.gdwMixingFreq);\n\t\tplayState.m_lTotalSampleCount += rowDuration;\n\n\t\tif(adjustSamplePos)\n\t\t{\n\t\t\t// Super experimental and dirty sample seeking\n\t\t\tpChn = playState.Chn;\n\t\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); pChn++, nChn++)\n\t\t\t{\n\t\t\t\tif(memory.chnSettings[nChn].ticksToRender == GetLengthMemory::IGNORE_CHANNEL)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tuint32 startTick = 0;\n\t\t\t\tconst ModCommand &m = pChn->rowCommand;\n\t\t\t\tuint32 paramHi = m.param >> 4, paramLo = m.param & 0x0F;\n\t\t\t\tbool porta = m.command == CMD_TONEPORTAMENTO || m.command == CMD_TONEPORTAVOL || m.volcmd == VOLCMD_TONEPORTAMENTO;\n\t\t\t\tbool stopNote = patternLoopStartedOnThisRow;\t// It's too much trouble to keep those pattern loops in sync...\n\n\t\t\t\tif(m.instr) pChn->proTrackerOffset = 0;\n\t\t\t\tif(m.IsNote())\n\t\t\t\t{\n\t\t\t\t\tif(porta && memory.chnSettings[nChn].incChanged)\n\t\t\t\t\t{\n\t\t\t\t\t\t// If there's a portamento, the current channel increment mustn't be 0 in NoteChange()\n\t\t\t\t\t\tpChn->increment = GetChannelIncrement(pChn, pChn->nPeriod, 0);\n\t\t\t\t\t}\n\t\t\t\t\tint32 setPan = pChn->nPan;\n\t\t\t\t\tpChn->nNewNote = pChn->nLastNote;\n\t\t\t\t\tif(pChn->nNewIns != 0) InstrumentChange(pChn, pChn->nNewIns, porta);\n\t\t\t\t\tNoteChange(pChn, m.note, porta);\n\t\t\t\t\tmemory.chnSettings[nChn].incChanged = true;\n\n\t\t\t\t\tif((m.command == CMD_MODCMDEX || m.command == CMD_S3MCMDEX) && (m.param & 0xF0) == 0xD0 && paramLo < numTicks)\n\t\t\t\t\t{\n\t\t\t\t\t\tstartTick = paramLo;\n\t\t\t\t\t} else if(m.command == CMD_DELAYCUT && paramHi < numTicks)\n\t\t\t\t\t{\n\t\t\t\t\t\tstartTick = paramHi;\n\t\t\t\t\t}\n\t\t\t\t\tif(rowDelay > 1 && startTick != 0 && (GetType() & (MOD_TYPE_S3M | MOD_TYPE_IT | MOD_TYPE_MPT)))\n\t\t\t\t\t{\n\t\t\t\t\t\tstartTick += (playState.m_nMusicSpeed + tickDelay) * (rowDelay - 1);\n\t\t\t\t\t}\n\t\t\t\t\tif(!porta) memory.chnSettings[nChn].ticksToRender = 0;\n\n\t\t\t\t\t// Panning commands have to be re-applied after a note change with potential pan change.\n\t\t\t\t\tif(m.command == CMD_PANNING8\n\t\t\t\t\t\t|| ((m.command == CMD_MODCMDEX || m.command == CMD_S3MCMDEX) && paramHi == 0x8)\n\t\t\t\t\t\t|| m.volcmd == VOLCMD_PANNING)\n\t\t\t\t\t{\n\t\t\t\t\t\tpChn->nPan = setPan;\n\t\t\t\t\t}\n\n\t\t\t\t\tif(m.command == CMD_OFFSET)\n\t\t\t\t\t{\n\t\t\t\t\t\tbool isExtended = false;\n\t\t\t\t\t\tSmpLength offset = CalculateXParam(playState.m_nPattern, playState.m_nRow, nChn, &isExtended);\n\t\t\t\t\t\tif(!isExtended)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\toffset <<= 8;\n\t\t\t\t\t\t\tif(offset == 0) offset = pChn->oldOffset;\n\t\t\t\t\t\t\toffset += static_cast<SmpLength>(pChn->nOldHiOffset) << 16;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tSampleOffset(*pChn, offset);\n\t\t\t\t\t} else if(m.command == CMD_OFFSETPERCENTAGE)\n\t\t\t\t\t{\n\t\t\t\t\t\tSampleOffset(*pChn, Util::muldiv_unsigned(pChn->nLength, m.param, 255));\n\t\t\t\t\t} else if(m.command == CMD_REVERSEOFFSET && pChn->pModSample != nullptr)\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\t// Re-sync what we've got so far\n\t\t\t\t\t\tReverseSampleOffset(*pChn, m.param);\n\t\t\t\t\t\tstartTick = playState.m_nMusicSpeed - 1;\n\t\t\t\t\t} else if(m.volcmd == VOLCMD_OFFSET)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(m.vol <= CountOf(pChn->pModSample->cues) && pChn->pModSample != nullptr)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tSmpLength offset;\n\t\t\t\t\t\t\tif(m.vol == 0)\n\t\t\t\t\t\t\t\toffset = pChn->oldOffset;\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\toffset = pChn->oldOffset = pChn->pModSample->cues[m.vol - 1];\n\t\t\t\t\t\t\tSampleOffset(*pChn, offset);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif(m.note == NOTE_KEYOFF || m.note == NOTE_NOTECUT || (m.note == NOTE_FADE && GetNumInstruments())\n\t\t\t\t\t|| ((m.command == CMD_MODCMDEX || m.command == CMD_S3MCMDEX) && (m.param & 0xF0) == 0xC0 && paramLo < numTicks)\n\t\t\t\t\t|| (m.command == CMD_DELAYCUT && paramLo != 0 && startTick + paramLo < numTicks))\n\t\t\t\t{\n\t\t\t\t\tstopNote = true;\n\t\t\t\t}\n\n\t\t\t\tif(m.command == CMD_VOLUME)\n\t\t\t\t{\n\t\t\t\t\tpChn->nVolume = m.param * 4;\n\t\t\t\t} else if(m.volcmd == VOLCMD_VOLUME)\n\t\t\t\t{\n\t\t\t\t\tpChn->nVolume = m.vol * 4;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(pChn->pModSample && !stopNote)\n\t\t\t\t{\n\t\t\t\t\t// Check if we don't want to emulate some effect and thus stop processing.\n\t\t\t\t\tif(m.command < MAX_EFFECTS)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(forbiddenCommands[m.command])\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tstopNote = true;\n\t\t\t\t\t\t} else if(m.command == CMD_MODCMDEX)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// Special case: Slides using extended commands\n\t\t\t\t\t\t\tswitch(m.param & 0xF0)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\tcase 0x10:\n\t\t\t\t\t\t\tcase 0x20:\n\t\t\t\t\t\t\t\tstopNote = true;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif(m.volcmd < forbiddenVolCommands.size() && forbiddenVolCommands[m.volcmd])\n\t\t\t\t\t{\n\t\t\t\t\t\tstopNote = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif(stopNote)\n\t\t\t\t{\n\t\t\t\t\tpChn->Stop();\n\t\t\t\t\tmemory.chnSettings[nChn].ticksToRender = 0;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tif(oldTickDuration != tickDuration && oldTickDuration != 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\t// Re-sync what we've got so far\n\t\t\t\t\t}\n\n\t\t\t\t\tswitch(m.command)\n\t\t\t\t\t{\n\t\t\t\t\tcase CMD_TONEPORTAVOL:\n\t\t\t\t\tcase CMD_VOLUMESLIDE:\n\t\t\t\t\tcase CMD_VIBRATOVOL:\n\t\t\t\t\t\tif(m.param || (GetType() != MOD_TYPE_MOD))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tfor(uint32 i = 0; i < numTicks; i++)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tpChn->isFirstTick = (i == 0);\n\t\t\t\t\t\t\t\tVolumeSlide(pChn, m.param);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase CMD_MODCMDEX:\n\t\t\t\t\t\tif((m.param & 0x0F) || (GetType() & (MOD_TYPE_XM | MOD_TYPE_MT2)))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tpChn->isFirstTick = true;\n\t\t\t\t\t\t\tswitch(m.param & 0xF0)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\tcase 0xA0: FineVolumeUp(pChn, m.param & 0x0F, false); break;\n\t\t\t\t\t\t\tcase 0xB0: FineVolumeDown(pChn, m.param & 0x0F, false); break;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase CMD_S3MCMDEX:\n\t\t\t\t\t\tif(m.param == 0x9E)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// Play forward\n\t\t\t\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\t// Re-sync what we've got so far\n\t\t\t\t\t\t\tpChn->dwFlags.reset(CHN_PINGPONGFLAG);\n\t\t\t\t\t\t} else if(m.param == 0x9F)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// Reverse\n\t\t\t\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\t// Re-sync what we've got so far\n\t\t\t\t\t\t\tpChn->dwFlags.set(CHN_PINGPONGFLAG);\n\t\t\t\t\t\t\tif(!pChn->position.GetInt() && pChn->nLength && (m.IsNote() || !pChn->dwFlags[CHN_LOOP]))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tpChn->position.Set(pChn->nLength - 1, SamplePosition::fractMax);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else if((m.param & 0xF0) == 0x70)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// TODO\n\t\t\t\t\t\t\t//ExtendedS3MCommands(nChn, param);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tpChn->isFirstTick = true;\n\t\t\t\t\tswitch(m.volcmd)\n\t\t\t\t\t{\n\t\t\t\t\tcase VOLCMD_FINEVOLUP:\t\tFineVolumeUp(pChn, m.vol, m_playBehaviour[kITVolColMemory]); break;\n\t\t\t\t\tcase VOLCMD_FINEVOLDOWN:\tFineVolumeDown(pChn, m.vol, m_playBehaviour[kITVolColMemory]); break;\n\t\t\t\t\tcase VOLCMD_VOLSLIDEUP:\n\t\t\t\t\tcase VOLCMD_VOLSLIDEDOWN:\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// IT Compatibility: Volume column volume slides have their own memory\n\t\t\t\t\t\t\t// Test case: VolColMemory.it\n\t\t\t\t\t\t\tModCommand::VOL vol = m.vol;\n\t\t\t\t\t\t\tif(vol == 0 && m_playBehaviour[kITVolColMemory])\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tvol = pChn->nOldVolParam;\n\t\t\t\t\t\t\t\tif(vol == 0)\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif(m.volcmd == VOLCMD_VOLSLIDEUP)\n\t\t\t\t\t\t\t\tvol <<= 4;\n\t\t\t\t\t\t\tfor(uint32 i = 0; i < numTicks; i++)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tpChn->isFirstTick = (i == 0);\n\t\t\t\t\t\t\t\tVolumeSlide(pChn, vol);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\n\t\t\t\t\tif(porta)\n\t\t\t\t\t{\n\t\t\t\t\t\t// Portamento needs immediate syncing, as the pitch changes on each tick\n\t\t\t\t\t\tuint32 portaTick = memory.chnSettings[nChn].ticksToRender + startTick + 1;\n\t\t\t\t\t\tmemory.chnSettings[nChn].ticksToRender += numTicks;\n\t\t\t\t\t\tmemory.RenderChannel(nChn, tickDuration, portaTick);\n\t\t\t\t\t} else\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.chnSettings[nChn].ticksToRender += (numTicks - startTick);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\toldTickDuration = tickDuration;\n\n\t\t// Pattern loop is not executed in FT2 if there are any position jump or pattern break commands on the same row.\n\t\t// Pattern loop is not executed in IT if there are any position jump commands on the same row.\n\t\t// Test case for FT2 exception: PatLoop-Jumps.xm, PatLoop-Various.xm\n\t\t// Test case for IT: exception: LoopBreak.it\n\t\tif(patternLoopEndedOnThisRow\n\t\t\t&& (!m_playBehaviour[kFT2PatternLoopWithJumps] || !(positionJumpOnThisRow || patternBreakOnThisRow))\n\t\t\t&& (!m_playBehaviour[kITPatternLoopWithJumps] || !positionJumpOnThisRow))\n\t\t{\n\t\t\tstd::map<double, int> startTimes;\n\t\t\t// This is really just a simple estimation for nested pattern loops. It should handle cases correctly where all parallel loops start and end on the same row.\n\t\t\t// If one of them starts or ends \"in between\", it will most likely calculate a wrong duration.\n\t\t\t// For S3M files, it's also way off.\n\t\t\tpChn = playState.Chn;\n\t\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++, pChn++)\n\t\t\t{\n\t\t\t\tModCommand::COMMAND command = pChn->rowCommand.command;\n\t\t\t\tModCommand::PARAM param = pChn->rowCommand.param;\n\t\t\t\tif((command == CMD_S3MCMDEX && param >= 0xB1 && param <= 0xBF)\n\t\t\t\t\t|| (command == CMD_MODCMDEX && param >= 0x61 && param <= 0x6F))\n\t\t\t\t{\n\t\t\t\t\tconst double start = memory.chnSettings[nChn].patLoop;\n\t\t\t\t\tif(!startTimes[start]) startTimes[start] = 1;\n\t\t\t\t\tstartTimes[start] = mpt::lcm(startTimes[start], 1 + (param & 0x0F));\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor(const auto &i : startTimes)\n\t\t\t{\n\t\t\t\tmemory.elapsedTime += (memory.elapsedTime - i.first) * (double)(i.second - 1);\n\t\t\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++, pChn++)\n\t\t\t\t{\n\t\t\t\t\tif(memory.chnSettings[nChn].patLoop == i.first)\n\t\t\t\t\t{\n\t\t\t\t\t\tplayState.m_lTotalSampleCount += (playState.m_lTotalSampleCount - memory.chnSettings[nChn].patLoopSmp) * (i.second - 1);\n\t\t\t\t\t\tif(m_playBehaviour[kITPatternLoopTargetReset] || (GetType() == MOD_TYPE_S3M))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tmemory.chnSettings[nChn].patLoop = memory.elapsedTime;\n\t\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopStart = playState.m_nRow + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(GetType() == MOD_TYPE_IT)\n\t\t\t{\n\t\t\t\t// IT pattern loop start row update - at the end of a pattern loop, set pattern loop start to next row (for upcoming pattern loops with missing SB0)\n\t\t\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++)\n\t\t\t\t{\n\t\t\t\t\tif((pChn->rowCommand.command == CMD_S3MCMDEX && pChn->rowCommand.param >= 0xB1 && pChn->rowCommand.param <= 0xBF))\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoop = memory.elapsedTime;\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Now advance the sample positions for sample seeking on channels that are still playing\n\tif(adjustSamplePos)\n\t{\n\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++)\n\t\t{\n\t\t\tif(memory.chnSettings[nChn].ticksToRender != GetLengthMemory::IGNORE_CHANNEL)\n\t\t\t{\n\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\n\t\t\t}\n\t\t}\n\t}\n\n\tif(retval.targetReached || target.mode == GetLengthTarget::NoTarget)\n\t{\n\t\tretval.lastOrder = playState.m_nCurrentOrder;\n\t\tretval.lastRow = playState.m_nRow;\n\t}\n\tretval.duration = memory.elapsedTime;\n\tresults.push_back(retval);\n\n\t// Store final variables\n\tif(adjustMode & eAdjust)\n\t{\n\t\tif(retval.targetReached || target.mode == GetLengthTarget::NoTarget)\n\t\t{\n\t\t\t// Target found, or there is no target (i.e. play whole song)...\n\t\t\tm_PlayState = std::move(playState);\n\t\t\tm_PlayState.m_nNextRow = m_PlayState.m_nRow;\n\t\t\tm_PlayState.m_nFrameDelay = m_PlayState.m_nPatternDelay = 0;\n\t\t\tm_PlayState.m_nTickCount = Util::MaxValueOfType(m_PlayState.m_nTickCount) - 1;\n\t\t\tm_PlayState.m_bPositionChanged = true;\n\t\t\tfor(CHANNELINDEX n = 0; n < GetNumChannels(); n++)\n\t\t\t{\n\t\t\t\tif(m_PlayState.Chn[n].nLastNote != NOTE_NONE)\n\t\t\t\t{\n\t\t\t\t\tm_PlayState.Chn[n].nNewNote = m_PlayState.Chn[n].nLastNote;\n\t\t\t\t}\n\t\t\t\tif(memory.chnSettings[n].vol != 0xFF && !adjustSamplePos)\n\t\t\t\t{\n\t\t\t\t\tm_PlayState.Chn[n].nVolume = std::min(memory.chnSettings[n].vol, uint8(64)) * 4;\n\t\t\t\t}\n\t\t\t}\n\n#ifndef NO_PLUGINS\n\t\t\t// If there were any PC events, update plugin parameters to their latest value.\n\t\t\tstd::bitset<MAX_MIXPLUGINS> plugSetProgram;\n\t\t\tfor(const auto &param : memory.plugParams)\n\t\t\t{\n\t\t\t\tPLUGINDEX plug = param.first.first - 1;\n\t\t\t\tIMixPlugin *plugin = m_MixPlugins[plug].pMixPlugin;\n\t\t\t\tif(plugin != nullptr)\n\t\t\t\t{\n\t\t\t\t\tif(!plugSetProgram[plug])\n\t\t\t\t\t{\n\t\t\t\t\t\t// Used for bridged plugins to avoid sending out individual messages for each parameter.\n\t\t\t\t\t\tplugSetProgram.set(plug);\n\t\t\t\t\t\tplugin->BeginSetProgram();\n\t\t\t\t\t}\n\t\t\t\t\tplugin->SetParameter(param.first.second, param.second / PlugParamValue(ModCommand::maxColumnValue));\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(plugSetProgram.any())\n\t\t\t{\n\t\t\t\tfor(PLUGINDEX i = 0; i < MAX_MIXPLUGINS; i++)\n\t\t\t\t{\n\t\t\t\t\tif(plugSetProgram[i])\n\t\t\t\t\t{\n\t\t\t\t\t\tm_MixPlugins[i].pMixPlugin->EndSetProgram();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n#endif // NO_PLUGINS\n\t\t} else if(adjustMode != eAdjustOnSuccess)\n\t\t{\n\t\t\t// Target not found (e.g. when jumping to a hidden sub song), reset global variables...\n\t\t\tm_PlayState.m_nMusicSpeed = m_nDefaultSpeed;\n\t\t\tm_PlayState.m_nMusicTempo = m_nDefaultTempo;\n\t\t\tm_PlayState.m_nGlobalVolume = m_nDefaultGlobalVolume;\n\t\t}\n\t\t// When adjusting the playback status, we will also want to update the visited rows vector according to the current position.\n\t\tif(sequence != Order.GetCurrentSequenceIndex())\n\t\t{\n\t\t\tOrder.SetSequence(sequence);\n\t\t}\n\t\tvisitedSongRows.Set(visitedRows);\n\t}\n\n\treturn results;\n\n}", "func_src_after": "std::vector<GetLengthType> CSoundFile::GetLength(enmGetLengthResetMode adjustMode, GetLengthTarget target)\n{\n\tstd::vector<GetLengthType> results;\n\tGetLengthType retval;\n\tretval.startOrder = target.startOrder;\n\tretval.startRow = target.startRow;\n\n\t// Are we trying to reach a certain pattern position?\n\tconst bool hasSearchTarget = target.mode != GetLengthTarget::NoTarget;\n\tconst bool adjustSamplePos = (adjustMode & eAdjustSamplePositions) == eAdjustSamplePositions;\n\n\tSEQUENCEINDEX sequence = target.sequence;\n\tif(sequence >= Order.GetNumSequences()) sequence = Order.GetCurrentSequenceIndex();\n\tconst ModSequence &orderList = Order(sequence);\n\n\tGetLengthMemory memory(*this);\n\tCSoundFile::PlayState &playState = *memory.state;\n\t// Temporary visited rows vector (so that GetLength() won't interfere with the player code if the module is playing at the same time)\n\tRowVisitor visitedRows(*this, sequence);\n\n\tplayState.m_nNextRow = playState.m_nRow = target.startRow;\n\tplayState.m_nNextOrder = playState.m_nCurrentOrder = target.startOrder;\n\n\t// Fast LUTs for commands that are too weird / complicated / whatever to emulate in sample position adjust mode.\n\tstd::bitset<MAX_EFFECTS> forbiddenCommands;\n\tstd::bitset<MAX_VOLCMDS> forbiddenVolCommands;\n\n\tif(adjustSamplePos)\n\t{\n\t\tforbiddenCommands.set(CMD_ARPEGGIO);             forbiddenCommands.set(CMD_PORTAMENTOUP);\n\t\tforbiddenCommands.set(CMD_PORTAMENTODOWN);       forbiddenCommands.set(CMD_XFINEPORTAUPDOWN);\n\t\tforbiddenCommands.set(CMD_NOTESLIDEUP);          forbiddenCommands.set(CMD_NOTESLIDEUPRETRIG);\n\t\tforbiddenCommands.set(CMD_NOTESLIDEDOWN);        forbiddenCommands.set(CMD_NOTESLIDEDOWNRETRIG);\n\t\tforbiddenVolCommands.set(VOLCMD_PORTAUP);        forbiddenVolCommands.set(VOLCMD_PORTADOWN);\n\n\t\t// Optimize away channels for which it's pointless to adjust sample positions\n\t\tfor(CHANNELINDEX i = 0; i < GetNumChannels(); i++)\n\t\t{\n\t\t\tif(ChnSettings[i].dwFlags[CHN_MUTE]) memory.chnSettings[i].ticksToRender = GetLengthMemory::IGNORE_CHANNEL;\n\t\t}\n\t\tif(target.mode == GetLengthTarget::SeekPosition && target.pos.order < orderList.size())\n\t\t{\n\t\t\t// If we know where to seek, we can directly rule out any channels on which a new note would be triggered right at the start.\n\t\t\tconst PATTERNINDEX seekPat = orderList[target.pos.order];\n\t\t\tif(Patterns.IsValidPat(seekPat) && Patterns[seekPat].IsValidRow(target.pos.row))\n\t\t\t{\n\t\t\t\tconst ModCommand *m = Patterns[seekPat].GetRow(target.pos.row);\n\t\t\t\tfor(CHANNELINDEX i = 0; i < GetNumChannels(); i++, m++)\n\t\t\t\t{\n\t\t\t\t\tif(m->note == NOTE_NOTECUT || m->note == NOTE_KEYOFF || (m->note == NOTE_FADE && GetNumInstruments())\n\t\t\t\t\t\t|| (m->IsNote() && !m->IsPortamento()))\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.chnSettings[i].ticksToRender = GetLengthMemory::IGNORE_CHANNEL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// If samples are being synced, force them to resync if tick duration changes\n\tuint32 oldTickDuration = 0;\n\n\tfor (;;)\n\t{\n\t\t// Time target reached.\n\t\tif(target.mode == GetLengthTarget::SeekSeconds && memory.elapsedTime >= target.time)\n\t\t{\n\t\t\tretval.targetReached = true;\n\t\t\tbreak;\n\t\t}\n\n\t\tuint32 rowDelay = 0, tickDelay = 0;\n\t\tplayState.m_nRow = playState.m_nNextRow;\n\t\tplayState.m_nCurrentOrder = playState.m_nNextOrder;\n\n\t\tif(orderList.IsValidPat(playState.m_nCurrentOrder) && playState.m_nRow >= Patterns[orderList[playState.m_nCurrentOrder]].GetNumRows())\n\t\t{\n\t\t\tplayState.m_nRow = 0;\n\t\t\tif(m_playBehaviour[kFT2LoopE60Restart])\n\t\t\t{\n\t\t\t\tplayState.m_nRow = playState.m_nNextPatStartRow;\n\t\t\t\tplayState.m_nNextPatStartRow = 0;\n\t\t\t}\n\t\t\tplayState.m_nCurrentOrder = ++playState.m_nNextOrder;\n\t\t}\n\n\t\t// Check if pattern is valid\n\t\tplayState.m_nPattern = playState.m_nCurrentOrder < orderList.size() ? orderList[playState.m_nCurrentOrder] : orderList.GetInvalidPatIndex();\n\t\tbool positionJumpOnThisRow = false;\n\t\tbool patternBreakOnThisRow = false;\n\t\tbool patternLoopEndedOnThisRow = false, patternLoopStartedOnThisRow = false;\n\n\t\tif(!Patterns.IsValidPat(playState.m_nPattern) && playState.m_nPattern != orderList.GetInvalidPatIndex() && target.mode == GetLengthTarget::SeekPosition && playState.m_nCurrentOrder == target.pos.order)\n\t\t{\n\t\t\t// Early test: Target is inside +++ or non-existing pattern\n\t\t\tretval.targetReached = true;\n\t\t\tbreak;\n\t\t}\n\n\t\twhile(playState.m_nPattern >= Patterns.Size())\n\t\t{\n\t\t\t// End of song?\n\t\t\tif((playState.m_nPattern == orderList.GetInvalidPatIndex()) || (playState.m_nCurrentOrder >= orderList.size()))\n\t\t\t{\n\t\t\t\tif(playState.m_nCurrentOrder == orderList.GetRestartPos())\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\tplayState.m_nCurrentOrder = orderList.GetRestartPos();\n\t\t\t} else\n\t\t\t{\n\t\t\t\tplayState.m_nCurrentOrder++;\n\t\t\t}\n\t\t\tplayState.m_nPattern = (playState.m_nCurrentOrder < orderList.size()) ? orderList[playState.m_nCurrentOrder] : orderList.GetInvalidPatIndex();\n\t\t\tplayState.m_nNextOrder = playState.m_nCurrentOrder;\n\t\t\tif((!Patterns.IsValidPat(playState.m_nPattern)) && visitedRows.IsVisited(playState.m_nCurrentOrder, 0, true))\n\t\t\t{\n\t\t\t\tif(!hasSearchTarget || !visitedRows.GetFirstUnvisitedRow(playState.m_nNextOrder, playState.m_nRow, true))\n\t\t\t\t{\n\t\t\t\t\t// We aren't searching for a specific row, or we couldn't find any more unvisited rows.\n\t\t\t\t\tbreak;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\t// We haven't found the target row yet, but we found some other unplayed row... continue searching from here.\n\t\t\t\t\tretval.duration = memory.elapsedTime;\n\t\t\t\t\tresults.push_back(retval);\n\t\t\t\t\tretval.startRow = playState.m_nRow;\n\t\t\t\t\tretval.startOrder = playState.m_nNextOrder;\n\t\t\t\t\tmemory.Reset();\n\n\t\t\t\t\tplayState.m_nCurrentOrder = playState.m_nNextOrder;\n\t\t\t\t\tplayState.m_nPattern = orderList[playState.m_nCurrentOrder];\n\t\t\t\t\tplayState.m_nNextRow = playState.m_nRow;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif(playState.m_nNextOrder == ORDERINDEX_INVALID)\n\t\t{\n\t\t\t// GetFirstUnvisitedRow failed, so there is nothing more to play\n\t\t\tbreak;\n\t\t}\n\n\t\t// Skip non-existing patterns\n\t\tif(!Patterns.IsValidPat(playState.m_nPattern))\n\t\t{\n\t\t\t// If there isn't even a tune, we should probably stop here.\n\t\t\tif(playState.m_nCurrentOrder == orderList.GetRestartPos())\n\t\t\t{\n\t\t\t\tif(!hasSearchTarget || !visitedRows.GetFirstUnvisitedRow(playState.m_nNextOrder, playState.m_nRow, true))\n\t\t\t\t{\n\t\t\t\t\t// We aren't searching for a specific row, or we couldn't find any more unvisited rows.\n\t\t\t\t\tbreak;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\t// We haven't found the target row yet, but we found some other unplayed row... continue searching from here.\n\t\t\t\t\tretval.duration = memory.elapsedTime;\n\t\t\t\t\tresults.push_back(retval);\n\t\t\t\t\tretval.startRow = playState.m_nRow;\n\t\t\t\t\tretval.startOrder = playState.m_nNextOrder;\n\t\t\t\t\tmemory.Reset();\n\t\t\t\t\tplayState.m_nNextRow = playState.m_nRow;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tplayState.m_nNextOrder = playState.m_nCurrentOrder + 1;\n\t\t\tcontinue;\n\t\t}\n\t\t// Should never happen\n\t\tif(playState.m_nRow >= Patterns[playState.m_nPattern].GetNumRows())\n\t\t\tplayState.m_nRow = 0;\n\n\t\t// Check whether target was reached.\n\t\tif(target.mode == GetLengthTarget::SeekPosition && playState.m_nCurrentOrder == target.pos.order && playState.m_nRow == target.pos.row)\n\t\t{\n\t\t\tretval.targetReached = true;\n\t\t\tbreak;\n\t\t}\n\n\t\tif(visitedRows.IsVisited(playState.m_nCurrentOrder, playState.m_nRow, true))\n\t\t{\n\t\t\tif(!hasSearchTarget || !visitedRows.GetFirstUnvisitedRow(playState.m_nNextOrder, playState.m_nRow, true))\n\t\t\t{\n\t\t\t\t// We aren't searching for a specific row, or we couldn't find any more unvisited rows.\n\t\t\t\tbreak;\n\t\t\t} else\n\t\t\t{\n\t\t\t\t// We haven't found the target row yet, but we found some other unplayed row... continue searching from here.\n\t\t\t\tretval.duration = memory.elapsedTime;\n\t\t\t\tresults.push_back(retval);\n\t\t\t\tretval.startRow = playState.m_nRow;\n\t\t\t\tretval.startOrder = playState.m_nNextOrder;\n\t\t\t\tmemory.Reset();\n\t\t\t\tplayState.m_nNextRow = playState.m_nRow;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tretval.endOrder = playState.m_nCurrentOrder;\n\t\tretval.endRow = playState.m_nRow;\n\n\t\t// Update next position\n\t\tplayState.m_nNextRow = playState.m_nRow + 1;\n\n\t\t// Jumped to invalid pattern row?\n\t\tif(playState.m_nRow >= Patterns[playState.m_nPattern].GetNumRows())\n\t\t{\n\t\t\tplayState.m_nRow = 0;\n\t\t}\n\t\t// New pattern?\n\t\tif(!playState.m_nRow)\n\t\t{\n\t\t\tfor(CHANNELINDEX chn = 0; chn < GetNumChannels(); chn++)\n\t\t\t{\n\t\t\t\tmemory.chnSettings[chn].patLoop = memory.elapsedTime;\n\t\t\t\tmemory.chnSettings[chn].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t}\n\t\t}\n\n\t\tModChannel *pChn = playState.Chn;\n\t\t\n\t\t// For various effects, we need to know first how many ticks there are in this row.\n\t\tconst ModCommand *p = Patterns[playState.m_nPattern].GetpModCommand(playState.m_nRow, 0);\n\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++, p++)\n\t\t{\n\t\t\tif(m_playBehaviour[kST3NoMutedChannels] && ChnSettings[nChn].dwFlags[CHN_MUTE])\t// not even effects are processed on muted S3M channels\n\t\t\t\tcontinue;\n\t\t\tif(p->IsPcNote())\n\t\t\t{\n#ifndef NO_PLUGINS\n\t\t\t\tif((adjustMode & eAdjust) && p->instr > 0 && p->instr <= MAX_MIXPLUGINS)\n\t\t\t\t{\n\t\t\t\t\tmemory.plugParams[std::make_pair(p->instr, p->GetValueVolCol())] = p->GetValueEffectCol();\n\t\t\t\t}\n#endif // NO_PLUGINS\n\t\t\t\tpChn[nChn].rowCommand.Clear();\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tpChn[nChn].rowCommand = *p;\n\t\t\tswitch(p->command)\n\t\t\t{\n\t\t\tcase CMD_SPEED:\n\t\t\t\tSetSpeed(playState, p->param);\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_TEMPO:\n\t\t\t\tif(m_playBehaviour[kMODVBlankTiming])\n\t\t\t\t{\n\t\t\t\t\t// ProTracker MODs with VBlank timing: All Fxx parameters set the tick count.\n\t\t\t\t\tif(p->param != 0) SetSpeed(playState, p->param);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_S3MCMDEX:\n\t\t\t\tif((p->param & 0xF0) == 0x60)\n\t\t\t\t{\n\t\t\t\t\t// Fine Pattern Delay\n\t\t\t\t\ttickDelay += (p->param & 0x0F);\n\t\t\t\t} else if((p->param & 0xF0) == 0xE0 && !rowDelay)\n\t\t\t\t{\n\t\t\t\t\t// Pattern Delay\n\t\t\t\t\tif(!(GetType() & MOD_TYPE_S3M) || (p->param & 0x0F) != 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t// While Impulse Tracker *does* count S60 as a valid row delay (and thus ignores any other row delay commands on the right),\n\t\t\t\t\t\t// Scream Tracker 3 simply ignores such commands.\n\t\t\t\t\t\trowDelay = 1 + (p->param & 0x0F);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_MODCMDEX:\n\t\t\t\tif((p->param & 0xF0) == 0xE0)\n\t\t\t\t{\n\t\t\t\t\t// Pattern Delay\n\t\t\t\t\trowDelay = 1 + (p->param & 0x0F);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif(rowDelay == 0) rowDelay = 1;\n\t\tconst uint32 numTicks = (playState.m_nMusicSpeed + tickDelay) * rowDelay;\n\t\tconst uint32 nonRowTicks = numTicks - rowDelay;\n\n\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); pChn++, nChn++) if(!pChn->rowCommand.IsEmpty())\n\t\t{\n\t\t\tif(m_playBehaviour[kST3NoMutedChannels] && ChnSettings[nChn].dwFlags[CHN_MUTE])\t// not even effects are processed on muted S3M channels\n\t\t\t\tcontinue;\n\t\t\tModCommand::COMMAND command = pChn->rowCommand.command;\n\t\t\tModCommand::PARAM param = pChn->rowCommand.param;\n\t\t\tModCommand::NOTE note = pChn->rowCommand.note;\n\n\t\t\tif (pChn->rowCommand.instr)\n\t\t\t{\n\t\t\t\tpChn->nNewIns = pChn->rowCommand.instr;\n\t\t\t\tpChn->nLastNote = NOTE_NONE;\n\t\t\t\tmemory.chnSettings[nChn].vol = 0xFF;\n\t\t\t}\n\t\t\tif (pChn->rowCommand.IsNote()) pChn->nLastNote = note;\n\n\t\t\t// Update channel panning\n\t\t\tif(pChn->rowCommand.IsNote() || pChn->rowCommand.instr)\n\t\t\t{\n\t\t\t\tSAMPLEINDEX smp = 0;\n\t\t\t\tif(GetNumInstruments())\n\t\t\t\t{\n\t\t\t\t\tModInstrument *pIns;\n\t\t\t\t\tif(pChn->nNewIns <= GetNumInstruments() && (pIns = Instruments[pChn->nNewIns]) != nullptr)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(pIns->dwFlags[INS_SETPANNING])\n\t\t\t\t\t\t\tpChn->nPan = pIns->nPan;\n\t\t\t\t\t\tif(ModCommand::IsNote(note))\n\t\t\t\t\t\t\tsmp = pIns->Keyboard[note - NOTE_MIN];\n\t\t\t\t\t}\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tsmp = pChn->nNewIns;\n\t\t\t\t}\n\t\t\t\tif(smp > 0 && smp <= GetNumSamples() && Samples[smp].uFlags[CHN_PANNING])\n\t\t\t\t{\n\t\t\t\t\tpChn->nPan = Samples[smp].nPan;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tswitch(pChn->rowCommand.volcmd)\n\t\t\t{\n\t\t\tcase VOLCMD_VOLUME:\n\t\t\t\tmemory.chnSettings[nChn].vol = pChn->rowCommand.vol;\n\t\t\t\tbreak;\n\t\t\tcase VOLCMD_VOLSLIDEUP:\n\t\t\tcase VOLCMD_VOLSLIDEDOWN:\n\t\t\t\tif(pChn->rowCommand.vol != 0)\n\t\t\t\t\tpChn->nOldVolParam = pChn->rowCommand.vol;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch(command)\n\t\t\t{\n\t\t\t// Position Jump\n\t\t\tcase CMD_POSITIONJUMP:\n\t\t\t\tpositionJumpOnThisRow = true;\n\t\t\t\tplayState.m_nNextOrder = static_cast<ORDERINDEX>(CalculateXParam(playState.m_nPattern, playState.m_nRow, nChn));\n\t\t\t\tplayState.m_nNextPatStartRow = 0;  // FT2 E60 bug\n\t\t\t\t// see https://forum.openmpt.org/index.php?topic=2769.0 - FastTracker resets Dxx if Bxx is called _after_ Dxx\n\t\t\t\t// Test case: PatternJump.mod\n\t\t\t\tif(!patternBreakOnThisRow || (GetType() & (MOD_TYPE_MOD | MOD_TYPE_XM)))\n\t\t\t\t\tplayState.m_nNextRow = 0;\n\n\t\t\t\tif (adjustMode & eAdjust)\n\t\t\t\t{\n\t\t\t\t\tpChn->nPatternLoopCount = 0;\n\t\t\t\t\tpChn->nPatternLoop = 0;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t// Pattern Break\n\t\t\tcase CMD_PATTERNBREAK:\n\t\t\t\t{\n\t\t\t\t\tROWINDEX row = PatternBreak(playState, nChn, param);\n\t\t\t\t\tif(row != ROWINDEX_INVALID)\n\t\t\t\t\t{\n\t\t\t\t\t\tpatternBreakOnThisRow = true;\n\t\t\t\t\t\tplayState.m_nNextRow = row;\n\n\t\t\t\t\t\tif(!positionJumpOnThisRow)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tplayState.m_nNextOrder = playState.m_nCurrentOrder + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif(adjustMode & eAdjust)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tpChn->nPatternLoopCount = 0;\n\t\t\t\t\t\t\tpChn->nPatternLoop = 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t// Set Tempo\n\t\t\tcase CMD_TEMPO:\n\t\t\t\tif(!m_playBehaviour[kMODVBlankTiming])\n\t\t\t\t{\n\t\t\t\t\tTEMPO tempo(CalculateXParam(playState.m_nPattern, playState.m_nRow, nChn), 0);\n\t\t\t\t\tif ((adjustMode & eAdjust) && (GetType() & (MOD_TYPE_S3M | MOD_TYPE_IT | MOD_TYPE_MPT)))\n\t\t\t\t\t{\n\t\t\t\t\t\tif (tempo.GetInt()) pChn->nOldTempo = static_cast<uint8>(tempo.GetInt()); else tempo.Set(pChn->nOldTempo);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (tempo.GetInt() >= 0x20) playState.m_nMusicTempo = tempo;\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\t// Tempo Slide\n\t\t\t\t\t\tTEMPO tempoDiff((tempo.GetInt() & 0x0F) * nonRowTicks, 0);\n\t\t\t\t\t\tif ((tempo.GetInt() & 0xF0) == 0x10)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tplayState.m_nMusicTempo += tempoDiff;\n\t\t\t\t\t\t} else\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif(tempoDiff < playState.m_nMusicTempo)\n\t\t\t\t\t\t\t\tplayState.m_nMusicTempo -= tempoDiff;\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\tplayState.m_nMusicTempo.Set(0);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tTEMPO tempoMin = GetModSpecifications().GetTempoMin(), tempoMax = GetModSpecifications().GetTempoMax();\n\t\t\t\t\tif(m_playBehaviour[kTempoClamp])\t// clamp tempo correctly in compatible mode\n\t\t\t\t\t{\n\t\t\t\t\t\ttempoMax.Set(255);\n\t\t\t\t\t}\n\t\t\t\t\tLimit(playState.m_nMusicTempo, tempoMin, tempoMax);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_S3MCMDEX:\n\t\t\t\tswitch(param & 0xF0)\n\t\t\t\t{\n\t\t\t\tcase 0x90:\n\t\t\t\t\tif(param <= 0x91)\n\t\t\t\t\t{\n\t\t\t\t\t\tpChn->dwFlags.set(CHN_SURROUND, param == 0x91);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 0xA0:\n\t\t\t\t\t// High sample offset\n\t\t\t\t\tpChn->nOldHiOffset = param & 0x0F;\n\t\t\t\t\tbreak;\n\t\t\t\t\n\t\t\t\tcase 0xB0:\n\t\t\t\t\t// Pattern Loop\n\t\t\t\t\tif (param & 0x0F)\n\t\t\t\t\t{\n\t\t\t\t\t\tpatternLoopEndedOnThisRow = true;\n\t\t\t\t\t} else\n\t\t\t\t\t{\n\t\t\t\t\t\tCHANNELINDEX firstChn = nChn, lastChn = nChn;\n\t\t\t\t\t\tif(GetType() == MOD_TYPE_S3M)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// ST3 has only one global loop memory.\n\t\t\t\t\t\t\tfirstChn = 0;\n\t\t\t\t\t\t\tlastChn = GetNumChannels() - 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor(CHANNELINDEX c = firstChn; c <= lastChn; c++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tmemory.chnSettings[c].patLoop = memory.elapsedTime;\n\t\t\t\t\t\t\tmemory.chnSettings[c].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t\t\t\t\tmemory.chnSettings[c].patLoopStart = playState.m_nRow;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tpatternLoopStartedOnThisRow = true;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 0xF0:\n\t\t\t\t\t// Active macro\n\t\t\t\t\tpChn->nActiveMacro = param & 0x0F;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_MODCMDEX:\n\t\t\t\tswitch(param & 0xF0)\n\t\t\t\t{\n\t\t\t\tcase 0x60:\n\t\t\t\t\t// Pattern Loop\n\t\t\t\t\tif (param & 0x0F)\n\t\t\t\t\t{\n\t\t\t\t\t\tplayState.m_nNextPatStartRow = memory.chnSettings[nChn].patLoopStart; // FT2 E60 bug\n\t\t\t\t\t\tpatternLoopEndedOnThisRow = true;\n\t\t\t\t\t} else\n\t\t\t\t\t{\n\t\t\t\t\t\tpatternLoopStartedOnThisRow = true;\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoop = memory.elapsedTime;\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopStart = playState.m_nRow;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 0xF0:\n\t\t\t\t\t// Active macro\n\t\t\t\t\tpChn->nActiveMacro = param & 0x0F;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_XFINEPORTAUPDOWN:\n\t\t\t\t// ignore high offset in compatible mode\n\t\t\t\tif(((param & 0xF0) == 0xA0) && !m_playBehaviour[kFT2RestrictXCommand]) pChn->nOldHiOffset = param & 0x0F;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// The following calculations are not interesting if we just want to get the song length.\n\t\t\tif (!(adjustMode & eAdjust)) continue;\n\t\t\tswitch(command)\n\t\t\t{\n\t\t\t// Portamento Up/Down\n\t\t\tcase CMD_PORTAMENTOUP:\n\t\t\t\tif(param)\n\t\t\t\t{\n\t\t\t\t\t// FT2 compatibility: Separate effect memory for all portamento commands\n\t\t\t\t\t// Test case: Porta-LinkMem.xm\n\t\t\t\t\tif(!m_playBehaviour[kFT2PortaUpDownMemory])\n\t\t\t\t\t\tpChn->nOldPortaDown = param;\n\t\t\t\t\tpChn->nOldPortaUp = param;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase CMD_PORTAMENTODOWN:\n\t\t\t\tif(param)\n\t\t\t\t{\n\t\t\t\t\t// FT2 compatibility: Separate effect memory for all portamento commands\n\t\t\t\t\t// Test case: Porta-LinkMem.xm\n\t\t\t\t\tif(!m_playBehaviour[kFT2PortaUpDownMemory])\n\t\t\t\t\t\tpChn->nOldPortaUp = param;\n\t\t\t\t\tpChn->nOldPortaDown = param;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t// Tone-Portamento\n\t\t\tcase CMD_TONEPORTAMENTO:\n\t\t\t\tif (param) pChn->nPortamentoSlide = param << 2;\n\t\t\t\tbreak;\n\t\t\t// Offset\n\t\t\tcase CMD_OFFSET:\n\t\t\t\tif (param) pChn->oldOffset = param << 8;\n\t\t\t\tbreak;\n\t\t\t// Volume Slide\n\t\t\tcase CMD_VOLUMESLIDE:\n\t\t\tcase CMD_TONEPORTAVOL:\n\t\t\t\tif (param) pChn->nOldVolumeSlide = param;\n\t\t\t\tbreak;\n\t\t\t// Set Volume\n\t\t\tcase CMD_VOLUME:\n\t\t\t\tmemory.chnSettings[nChn].vol = param;\n\t\t\t\tbreak;\n\t\t\t// Global Volume\n\t\t\tcase CMD_GLOBALVOLUME:\n\t\t\t\tif(!(GetType() & GLOBALVOL_7BIT_FORMATS) && param < 128) param *= 2;\n\t\t\t\t// IT compatibility 16. ST3 and IT ignore out-of-range values\n\t\t\t\tif(param <= 128)\n\t\t\t\t{\n\t\t\t\t\tplayState.m_nGlobalVolume = param * 2;\n\t\t\t\t} else if(!(GetType() & (MOD_TYPE_IT | MOD_TYPE_MPT | MOD_TYPE_S3M)))\n\t\t\t\t{\n\t\t\t\t\tplayState.m_nGlobalVolume = 256;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t// Global Volume Slide\n\t\t\tcase CMD_GLOBALVOLSLIDE:\n\t\t\t\tif(m_playBehaviour[kPerChannelGlobalVolSlide])\n\t\t\t\t{\n\t\t\t\t\t// IT compatibility 16. Global volume slide params are stored per channel (FT2/IT)\n\t\t\t\t\tif (param) pChn->nOldGlobalVolSlide = param; else param = pChn->nOldGlobalVolSlide;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tif (param) playState.Chn[0].nOldGlobalVolSlide = param; else param = playState.Chn[0].nOldGlobalVolSlide;\n\t\t\t\t}\n\t\t\t\tif (((param & 0x0F) == 0x0F) && (param & 0xF0))\n\t\t\t\t{\n\t\t\t\t\tparam >>= 4;\n\t\t\t\t\tif (!(GetType() & GLOBALVOL_7BIT_FORMATS)) param <<= 1;\n\t\t\t\t\tplayState.m_nGlobalVolume += param << 1;\n\t\t\t\t} else if (((param & 0xF0) == 0xF0) && (param & 0x0F))\n\t\t\t\t{\n\t\t\t\t\tparam = (param & 0x0F) << 1;\n\t\t\t\t\tif (!(GetType() & GLOBALVOL_7BIT_FORMATS)) param <<= 1;\n\t\t\t\t\tplayState.m_nGlobalVolume -= param;\n\t\t\t\t} else if (param & 0xF0)\n\t\t\t\t{\n\t\t\t\t\tparam >>= 4;\n\t\t\t\t\tparam <<= 1;\n\t\t\t\t\tif (!(GetType() & GLOBALVOL_7BIT_FORMATS)) param <<= 1;\n\t\t\t\t\tplayState.m_nGlobalVolume += param * nonRowTicks;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tparam = (param & 0x0F) << 1;\n\t\t\t\t\tif (!(GetType() & GLOBALVOL_7BIT_FORMATS)) param <<= 1;\n\t\t\t\t\tplayState.m_nGlobalVolume -= param * nonRowTicks;\n\t\t\t\t}\n\t\t\t\tLimit(playState.m_nGlobalVolume, 0, 256);\n\t\t\t\tbreak;\n\t\t\tcase CMD_CHANNELVOLUME:\n\t\t\t\tif (param <= 64) pChn->nGlobalVol = param;\n\t\t\t\tbreak;\n\t\t\tcase CMD_CHANNELVOLSLIDE:\n\t\t\t\t{\n\t\t\t\t\tif (param) pChn->nOldChnVolSlide = param; else param = pChn->nOldChnVolSlide;\n\t\t\t\t\tint32 volume = pChn->nGlobalVol;\n\t\t\t\t\tif((param & 0x0F) == 0x0F && (param & 0xF0))\n\t\t\t\t\t\tvolume += (param >> 4);\t\t// Fine Up\n\t\t\t\t\telse if((param & 0xF0) == 0xF0 && (param & 0x0F))\n\t\t\t\t\t\tvolume -= (param & 0x0F);\t// Fine Down\n\t\t\t\t\telse if(param & 0x0F)\t\t\t// Down\n\t\t\t\t\t\tvolume -= (param & 0x0F) * nonRowTicks;\n\t\t\t\t\telse\t\t\t\t\t\t\t// Up\n\t\t\t\t\t\tvolume += ((param & 0xF0) >> 4) * nonRowTicks;\n\t\t\t\t\tLimit(volume, 0, 64);\n\t\t\t\t\tpChn->nGlobalVol = volume;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase CMD_PANNING8:\n\t\t\t\tPanning(pChn, param, Pan8bit);\n\t\t\t\tbreak;\n\t\t\tcase CMD_MODCMDEX:\n\t\t\t\tif(param < 0x10)\n\t\t\t\t{\n\t\t\t\t\t// LED filter\n\t\t\t\t\tfor(CHANNELINDEX chn = 0; chn < GetNumChannels(); chn++)\n\t\t\t\t\t{\n\t\t\t\t\t\tplayState.Chn[chn].dwFlags.set(CHN_AMIGAFILTER, !(param & 1));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tMPT_FALLTHROUGH;\n\t\t\tcase CMD_S3MCMDEX:\n\t\t\t\tif((param & 0xF0) == 0x80)\n\t\t\t\t{\n\t\t\t\t\tPanning(pChn, (param & 0x0F), Pan4bit);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_VIBRATOVOL:\n\t\t\t\tif (param) pChn->nOldVolumeSlide = param;\n\t\t\t\tparam = 0;\n\t\t\t\tMPT_FALLTHROUGH;\n\t\t\tcase CMD_VIBRATO:\n\t\t\t\tVibrato(pChn, param);\n\t\t\t\tbreak;\n\t\t\tcase CMD_FINEVIBRATO:\n\t\t\t\tFineVibrato(pChn, param);\n\t\t\t\tbreak;\n\t\t\tcase CMD_TREMOLO:\n\t\t\t\tTremolo(pChn, param);\n\t\t\t\tbreak;\n\t\t\tcase CMD_PANBRELLO:\n\t\t\t\tPanbrello(pChn, param);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch(pChn->rowCommand.volcmd)\n\t\t\t{\n\t\t\tcase VOLCMD_PANNING:\n\t\t\t\tPanning(pChn, pChn->rowCommand.vol, Pan6bit);\n\t\t\t\tbreak;\n\n\t\t\tcase VOLCMD_VIBRATOSPEED:\n\t\t\t\t// FT2 does not automatically enable vibrato with the \"set vibrato speed\" command\n\t\t\t\tif(m_playBehaviour[kFT2VolColVibrato])\n\t\t\t\t\tpChn->nVibratoSpeed = pChn->rowCommand.vol & 0x0F;\n\t\t\t\telse\n\t\t\t\t\tVibrato(pChn, pChn->rowCommand.vol << 4);\n\t\t\t\tbreak;\n\t\t\tcase VOLCMD_VIBRATODEPTH:\n\t\t\t\tVibrato(pChn, pChn->rowCommand.vol);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// Process vibrato / tremolo / panbrello\n\t\t\tswitch(pChn->rowCommand.command)\n\t\t\t{\n\t\t\tcase CMD_VIBRATO:\n\t\t\tcase CMD_FINEVIBRATO:\n\t\t\tcase CMD_VIBRATOVOL:\n\t\t\t\tif(adjustMode & eAdjust)\n\t\t\t\t{\n\t\t\t\t\tuint32 vibTicks = ((GetType() & (MOD_TYPE_IT | MOD_TYPE_MPT)) && !m_SongFlags[SONG_ITOLDEFFECTS]) ? numTicks : nonRowTicks;\n\t\t\t\t\tuint32 inc = pChn->nVibratoSpeed * vibTicks;\n\t\t\t\t\tif(m_playBehaviour[kITVibratoTremoloPanbrello])\n\t\t\t\t\t\tinc *= 4;\n\t\t\t\t\tpChn->nVibratoPos += static_cast<uint8>(inc);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_TREMOLO:\n\t\t\t\tif(adjustMode & eAdjust)\n\t\t\t\t{\n\t\t\t\t\tuint32 tremTicks = ((GetType() & (MOD_TYPE_IT | MOD_TYPE_MPT)) && !m_SongFlags[SONG_ITOLDEFFECTS]) ? numTicks : nonRowTicks;\n\t\t\t\t\tuint32 inc = pChn->nTremoloSpeed * tremTicks;\n\t\t\t\t\tif(m_playBehaviour[kITVibratoTremoloPanbrello])\n\t\t\t\t\t\tinc *= 4;\n\t\t\t\t\tpChn->nTremoloPos += static_cast<uint8>(inc);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CMD_PANBRELLO:\n\t\t\t\tif(adjustMode & eAdjust)\n\t\t\t\t{\n\t\t\t\t\t// Panbrello effect is permanent in compatible mode, so actually apply panbrello for the last tick of this row\n\t\t\t\t\tpChn->nPanbrelloPos += static_cast<uint8>(pChn->nPanbrelloSpeed * (numTicks - 1));\n\t\t\t\t\tProcessPanbrello(pChn);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t// Interpret F00 effect in XM files as \"stop song\"\n\t\tif(GetType() == MOD_TYPE_XM && playState.m_nMusicSpeed == uint16_max)\n\t\t{\n\t\t\tbreak;\n\t\t}\n\n\t\tplayState.m_nCurrentRowsPerBeat = m_nDefaultRowsPerBeat;\n\t\tif(Patterns[playState.m_nPattern].GetOverrideSignature())\n\t\t{\n\t\t\tplayState.m_nCurrentRowsPerBeat = Patterns[playState.m_nPattern].GetRowsPerBeat();\n\t\t}\n\n\t\tconst uint32 tickDuration = GetTickDuration(playState);\n\t\tconst uint32 rowDuration = tickDuration * numTicks;\n\t\tmemory.elapsedTime += static_cast<double>(rowDuration) / static_cast<double>(m_MixerSettings.gdwMixingFreq);\n\t\tplayState.m_lTotalSampleCount += rowDuration;\n\n\t\tif(adjustSamplePos)\n\t\t{\n\t\t\t// Super experimental and dirty sample seeking\n\t\t\tpChn = playState.Chn;\n\t\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); pChn++, nChn++)\n\t\t\t{\n\t\t\t\tif(memory.chnSettings[nChn].ticksToRender == GetLengthMemory::IGNORE_CHANNEL)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tuint32 startTick = 0;\n\t\t\t\tconst ModCommand &m = pChn->rowCommand;\n\t\t\t\tuint32 paramHi = m.param >> 4, paramLo = m.param & 0x0F;\n\t\t\t\tbool porta = m.command == CMD_TONEPORTAMENTO || m.command == CMD_TONEPORTAVOL || m.volcmd == VOLCMD_TONEPORTAMENTO;\n\t\t\t\tbool stopNote = patternLoopStartedOnThisRow;\t// It's too much trouble to keep those pattern loops in sync...\n\n\t\t\t\tif(m.instr) pChn->proTrackerOffset = 0;\n\t\t\t\tif(m.IsNote())\n\t\t\t\t{\n\t\t\t\t\tif(porta && memory.chnSettings[nChn].incChanged)\n\t\t\t\t\t{\n\t\t\t\t\t\t// If there's a portamento, the current channel increment mustn't be 0 in NoteChange()\n\t\t\t\t\t\tpChn->increment = GetChannelIncrement(pChn, pChn->nPeriod, 0);\n\t\t\t\t\t}\n\t\t\t\t\tint32 setPan = pChn->nPan;\n\t\t\t\t\tpChn->nNewNote = pChn->nLastNote;\n\t\t\t\t\tif(pChn->nNewIns != 0) InstrumentChange(pChn, pChn->nNewIns, porta);\n\t\t\t\t\tNoteChange(pChn, m.note, porta);\n\t\t\t\t\tmemory.chnSettings[nChn].incChanged = true;\n\n\t\t\t\t\tif((m.command == CMD_MODCMDEX || m.command == CMD_S3MCMDEX) && (m.param & 0xF0) == 0xD0 && paramLo < numTicks)\n\t\t\t\t\t{\n\t\t\t\t\t\tstartTick = paramLo;\n\t\t\t\t\t} else if(m.command == CMD_DELAYCUT && paramHi < numTicks)\n\t\t\t\t\t{\n\t\t\t\t\t\tstartTick = paramHi;\n\t\t\t\t\t}\n\t\t\t\t\tif(rowDelay > 1 && startTick != 0 && (GetType() & (MOD_TYPE_S3M | MOD_TYPE_IT | MOD_TYPE_MPT)))\n\t\t\t\t\t{\n\t\t\t\t\t\tstartTick += (playState.m_nMusicSpeed + tickDelay) * (rowDelay - 1);\n\t\t\t\t\t}\n\t\t\t\t\tif(!porta) memory.chnSettings[nChn].ticksToRender = 0;\n\n\t\t\t\t\t// Panning commands have to be re-applied after a note change with potential pan change.\n\t\t\t\t\tif(m.command == CMD_PANNING8\n\t\t\t\t\t\t|| ((m.command == CMD_MODCMDEX || m.command == CMD_S3MCMDEX) && paramHi == 0x8)\n\t\t\t\t\t\t|| m.volcmd == VOLCMD_PANNING)\n\t\t\t\t\t{\n\t\t\t\t\t\tpChn->nPan = setPan;\n\t\t\t\t\t}\n\n\t\t\t\t\tif(m.command == CMD_OFFSET)\n\t\t\t\t\t{\n\t\t\t\t\t\tbool isExtended = false;\n\t\t\t\t\t\tSmpLength offset = CalculateXParam(playState.m_nPattern, playState.m_nRow, nChn, &isExtended);\n\t\t\t\t\t\tif(!isExtended)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\toffset <<= 8;\n\t\t\t\t\t\t\tif(offset == 0) offset = pChn->oldOffset;\n\t\t\t\t\t\t\toffset += static_cast<SmpLength>(pChn->nOldHiOffset) << 16;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tSampleOffset(*pChn, offset);\n\t\t\t\t\t} else if(m.command == CMD_OFFSETPERCENTAGE)\n\t\t\t\t\t{\n\t\t\t\t\t\tSampleOffset(*pChn, Util::muldiv_unsigned(pChn->nLength, m.param, 255));\n\t\t\t\t\t} else if(m.command == CMD_REVERSEOFFSET && pChn->pModSample != nullptr)\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\t// Re-sync what we've got so far\n\t\t\t\t\t\tReverseSampleOffset(*pChn, m.param);\n\t\t\t\t\t\tstartTick = playState.m_nMusicSpeed - 1;\n\t\t\t\t\t} else if(m.volcmd == VOLCMD_OFFSET)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(m.vol <= CountOf(pChn->pModSample->cues) && pChn->pModSample != nullptr)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tSmpLength offset;\n\t\t\t\t\t\t\tif(m.vol == 0)\n\t\t\t\t\t\t\t\toffset = pChn->oldOffset;\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\toffset = pChn->oldOffset = pChn->pModSample->cues[m.vol - 1];\n\t\t\t\t\t\t\tSampleOffset(*pChn, offset);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif(m.note == NOTE_KEYOFF || m.note == NOTE_NOTECUT || (m.note == NOTE_FADE && GetNumInstruments())\n\t\t\t\t\t|| ((m.command == CMD_MODCMDEX || m.command == CMD_S3MCMDEX) && (m.param & 0xF0) == 0xC0 && paramLo < numTicks)\n\t\t\t\t\t|| (m.command == CMD_DELAYCUT && paramLo != 0 && startTick + paramLo < numTicks))\n\t\t\t\t{\n\t\t\t\t\tstopNote = true;\n\t\t\t\t}\n\n\t\t\t\tif(m.command == CMD_VOLUME)\n\t\t\t\t{\n\t\t\t\t\tpChn->nVolume = m.param * 4;\n\t\t\t\t} else if(m.volcmd == VOLCMD_VOLUME)\n\t\t\t\t{\n\t\t\t\t\tpChn->nVolume = m.vol * 4;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(pChn->pModSample && !stopNote)\n\t\t\t\t{\n\t\t\t\t\t// Check if we don't want to emulate some effect and thus stop processing.\n\t\t\t\t\tif(m.command < MAX_EFFECTS)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(forbiddenCommands[m.command])\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tstopNote = true;\n\t\t\t\t\t\t} else if(m.command == CMD_MODCMDEX)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// Special case: Slides using extended commands\n\t\t\t\t\t\t\tswitch(m.param & 0xF0)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\tcase 0x10:\n\t\t\t\t\t\t\tcase 0x20:\n\t\t\t\t\t\t\t\tstopNote = true;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif(m.volcmd < forbiddenVolCommands.size() && forbiddenVolCommands[m.volcmd])\n\t\t\t\t\t{\n\t\t\t\t\t\tstopNote = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif(stopNote)\n\t\t\t\t{\n\t\t\t\t\tpChn->Stop();\n\t\t\t\t\tmemory.chnSettings[nChn].ticksToRender = 0;\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tif(oldTickDuration != tickDuration && oldTickDuration != 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\t// Re-sync what we've got so far\n\t\t\t\t\t}\n\n\t\t\t\t\tswitch(m.command)\n\t\t\t\t\t{\n\t\t\t\t\tcase CMD_TONEPORTAVOL:\n\t\t\t\t\tcase CMD_VOLUMESLIDE:\n\t\t\t\t\tcase CMD_VIBRATOVOL:\n\t\t\t\t\t\tif(m.param || (GetType() != MOD_TYPE_MOD))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tfor(uint32 i = 0; i < numTicks; i++)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tpChn->isFirstTick = (i == 0);\n\t\t\t\t\t\t\t\tVolumeSlide(pChn, m.param);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase CMD_MODCMDEX:\n\t\t\t\t\t\tif((m.param & 0x0F) || (GetType() & (MOD_TYPE_XM | MOD_TYPE_MT2)))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tpChn->isFirstTick = true;\n\t\t\t\t\t\t\tswitch(m.param & 0xF0)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\tcase 0xA0: FineVolumeUp(pChn, m.param & 0x0F, false); break;\n\t\t\t\t\t\t\tcase 0xB0: FineVolumeDown(pChn, m.param & 0x0F, false); break;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase CMD_S3MCMDEX:\n\t\t\t\t\t\tif(m.param == 0x9E)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// Play forward\n\t\t\t\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\t// Re-sync what we've got so far\n\t\t\t\t\t\t\tpChn->dwFlags.reset(CHN_PINGPONGFLAG);\n\t\t\t\t\t\t} else if(m.param == 0x9F)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// Reverse\n\t\t\t\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\t// Re-sync what we've got so far\n\t\t\t\t\t\t\tpChn->dwFlags.set(CHN_PINGPONGFLAG);\n\t\t\t\t\t\t\tif(!pChn->position.GetInt() && pChn->nLength && (m.IsNote() || !pChn->dwFlags[CHN_LOOP]))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tpChn->position.Set(pChn->nLength - 1, SamplePosition::fractMax);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else if((m.param & 0xF0) == 0x70)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// TODO\n\t\t\t\t\t\t\t//ExtendedS3MCommands(nChn, param);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tpChn->isFirstTick = true;\n\t\t\t\t\tswitch(m.volcmd)\n\t\t\t\t\t{\n\t\t\t\t\tcase VOLCMD_FINEVOLUP:\t\tFineVolumeUp(pChn, m.vol, m_playBehaviour[kITVolColMemory]); break;\n\t\t\t\t\tcase VOLCMD_FINEVOLDOWN:\tFineVolumeDown(pChn, m.vol, m_playBehaviour[kITVolColMemory]); break;\n\t\t\t\t\tcase VOLCMD_VOLSLIDEUP:\n\t\t\t\t\tcase VOLCMD_VOLSLIDEDOWN:\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// IT Compatibility: Volume column volume slides have their own memory\n\t\t\t\t\t\t\t// Test case: VolColMemory.it\n\t\t\t\t\t\t\tModCommand::VOL vol = m.vol;\n\t\t\t\t\t\t\tif(vol == 0 && m_playBehaviour[kITVolColMemory])\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tvol = pChn->nOldVolParam;\n\t\t\t\t\t\t\t\tif(vol == 0)\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif(m.volcmd == VOLCMD_VOLSLIDEUP)\n\t\t\t\t\t\t\t\tvol <<= 4;\n\t\t\t\t\t\t\tfor(uint32 i = 0; i < numTicks; i++)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tpChn->isFirstTick = (i == 0);\n\t\t\t\t\t\t\t\tVolumeSlide(pChn, vol);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\n\t\t\t\t\tif(porta)\n\t\t\t\t\t{\n\t\t\t\t\t\t// Portamento needs immediate syncing, as the pitch changes on each tick\n\t\t\t\t\t\tuint32 portaTick = memory.chnSettings[nChn].ticksToRender + startTick + 1;\n\t\t\t\t\t\tmemory.chnSettings[nChn].ticksToRender += numTicks;\n\t\t\t\t\t\tmemory.RenderChannel(nChn, tickDuration, portaTick);\n\t\t\t\t\t} else\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.chnSettings[nChn].ticksToRender += (numTicks - startTick);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\toldTickDuration = tickDuration;\n\n\t\t// Pattern loop is not executed in FT2 if there are any position jump or pattern break commands on the same row.\n\t\t// Pattern loop is not executed in IT if there are any position jump commands on the same row.\n\t\t// Test case for FT2 exception: PatLoop-Jumps.xm, PatLoop-Various.xm\n\t\t// Test case for IT: exception: LoopBreak.it\n\t\tif(patternLoopEndedOnThisRow\n\t\t\t&& (!m_playBehaviour[kFT2PatternLoopWithJumps] || !(positionJumpOnThisRow || patternBreakOnThisRow))\n\t\t\t&& (!m_playBehaviour[kITPatternLoopWithJumps] || !positionJumpOnThisRow))\n\t\t{\n\t\t\tstd::map<double, int> startTimes;\n\t\t\t// This is really just a simple estimation for nested pattern loops. It should handle cases correctly where all parallel loops start and end on the same row.\n\t\t\t// If one of them starts or ends \"in between\", it will most likely calculate a wrong duration.\n\t\t\t// For S3M files, it's also way off.\n\t\t\tpChn = playState.Chn;\n\t\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++, pChn++)\n\t\t\t{\n\t\t\t\tModCommand::COMMAND command = pChn->rowCommand.command;\n\t\t\t\tModCommand::PARAM param = pChn->rowCommand.param;\n\t\t\t\tif((command == CMD_S3MCMDEX && param >= 0xB1 && param <= 0xBF)\n\t\t\t\t\t|| (command == CMD_MODCMDEX && param >= 0x61 && param <= 0x6F))\n\t\t\t\t{\n\t\t\t\t\tconst double start = memory.chnSettings[nChn].patLoop;\n\t\t\t\t\tif(!startTimes[start]) startTimes[start] = 1;\n\t\t\t\t\tstartTimes[start] = mpt::lcm(startTimes[start], 1 + (param & 0x0F));\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor(const auto &i : startTimes)\n\t\t\t{\n\t\t\t\tmemory.elapsedTime += (memory.elapsedTime - i.first) * (double)(i.second - 1);\n\t\t\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++, pChn++)\n\t\t\t\t{\n\t\t\t\t\tif(memory.chnSettings[nChn].patLoop == i.first)\n\t\t\t\t\t{\n\t\t\t\t\t\tplayState.m_lTotalSampleCount += (playState.m_lTotalSampleCount - memory.chnSettings[nChn].patLoopSmp) * (i.second - 1);\n\t\t\t\t\t\tif(m_playBehaviour[kITPatternLoopTargetReset] || (GetType() == MOD_TYPE_S3M))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tmemory.chnSettings[nChn].patLoop = memory.elapsedTime;\n\t\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopStart = playState.m_nRow + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(GetType() == MOD_TYPE_IT)\n\t\t\t{\n\t\t\t\t// IT pattern loop start row update - at the end of a pattern loop, set pattern loop start to next row (for upcoming pattern loops with missing SB0)\n\t\t\t\tpChn = playState.Chn;\n\t\t\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++, pChn++)\n\t\t\t\t{\n\t\t\t\t\tif((pChn->rowCommand.command == CMD_S3MCMDEX && pChn->rowCommand.param >= 0xB1 && pChn->rowCommand.param <= 0xBF))\n\t\t\t\t\t{\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoop = memory.elapsedTime;\n\t\t\t\t\t\tmemory.chnSettings[nChn].patLoopSmp = playState.m_lTotalSampleCount;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Now advance the sample positions for sample seeking on channels that are still playing\n\tif(adjustSamplePos)\n\t{\n\t\tfor(CHANNELINDEX nChn = 0; nChn < GetNumChannels(); nChn++)\n\t\t{\n\t\t\tif(memory.chnSettings[nChn].ticksToRender != GetLengthMemory::IGNORE_CHANNEL)\n\t\t\t{\n\t\t\t\tmemory.RenderChannel(nChn, oldTickDuration);\n\t\t\t}\n\t\t}\n\t}\n\n\tif(retval.targetReached || target.mode == GetLengthTarget::NoTarget)\n\t{\n\t\tretval.lastOrder = playState.m_nCurrentOrder;\n\t\tretval.lastRow = playState.m_nRow;\n\t}\n\tretval.duration = memory.elapsedTime;\n\tresults.push_back(retval);\n\n\t// Store final variables\n\tif(adjustMode & eAdjust)\n\t{\n\t\tif(retval.targetReached || target.mode == GetLengthTarget::NoTarget)\n\t\t{\n\t\t\t// Target found, or there is no target (i.e. play whole song)...\n\t\t\tm_PlayState = std::move(playState);\n\t\t\tm_PlayState.m_nNextRow = m_PlayState.m_nRow;\n\t\t\tm_PlayState.m_nFrameDelay = m_PlayState.m_nPatternDelay = 0;\n\t\t\tm_PlayState.m_nTickCount = Util::MaxValueOfType(m_PlayState.m_nTickCount) - 1;\n\t\t\tm_PlayState.m_bPositionChanged = true;\n\t\t\tfor(CHANNELINDEX n = 0; n < GetNumChannels(); n++)\n\t\t\t{\n\t\t\t\tif(m_PlayState.Chn[n].nLastNote != NOTE_NONE)\n\t\t\t\t{\n\t\t\t\t\tm_PlayState.Chn[n].nNewNote = m_PlayState.Chn[n].nLastNote;\n\t\t\t\t}\n\t\t\t\tif(memory.chnSettings[n].vol != 0xFF && !adjustSamplePos)\n\t\t\t\t{\n\t\t\t\t\tm_PlayState.Chn[n].nVolume = std::min(memory.chnSettings[n].vol, uint8(64)) * 4;\n\t\t\t\t}\n\t\t\t}\n\n#ifndef NO_PLUGINS\n\t\t\t// If there were any PC events, update plugin parameters to their latest value.\n\t\t\tstd::bitset<MAX_MIXPLUGINS> plugSetProgram;\n\t\t\tfor(const auto &param : memory.plugParams)\n\t\t\t{\n\t\t\t\tPLUGINDEX plug = param.first.first - 1;\n\t\t\t\tIMixPlugin *plugin = m_MixPlugins[plug].pMixPlugin;\n\t\t\t\tif(plugin != nullptr)\n\t\t\t\t{\n\t\t\t\t\tif(!plugSetProgram[plug])\n\t\t\t\t\t{\n\t\t\t\t\t\t// Used for bridged plugins to avoid sending out individual messages for each parameter.\n\t\t\t\t\t\tplugSetProgram.set(plug);\n\t\t\t\t\t\tplugin->BeginSetProgram();\n\t\t\t\t\t}\n\t\t\t\t\tplugin->SetParameter(param.first.second, param.second / PlugParamValue(ModCommand::maxColumnValue));\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(plugSetProgram.any())\n\t\t\t{\n\t\t\t\tfor(PLUGINDEX i = 0; i < MAX_MIXPLUGINS; i++)\n\t\t\t\t{\n\t\t\t\t\tif(plugSetProgram[i])\n\t\t\t\t\t{\n\t\t\t\t\t\tm_MixPlugins[i].pMixPlugin->EndSetProgram();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n#endif // NO_PLUGINS\n\t\t} else if(adjustMode != eAdjustOnSuccess)\n\t\t{\n\t\t\t// Target not found (e.g. when jumping to a hidden sub song), reset global variables...\n\t\t\tm_PlayState.m_nMusicSpeed = m_nDefaultSpeed;\n\t\t\tm_PlayState.m_nMusicTempo = m_nDefaultTempo;\n\t\t\tm_PlayState.m_nGlobalVolume = m_nDefaultGlobalVolume;\n\t\t}\n\t\t// When adjusting the playback status, we will also want to update the visited rows vector according to the current position.\n\t\tif(sequence != Order.GetCurrentSequenceIndex())\n\t\t{\n\t\t\tOrder.SetSequence(sequence);\n\t\t}\n\t\tvisitedSongRows.Set(visitedRows);\n\t}\n\n\treturn results;\n\n}", "commit_link": "github.com/OpenMPT/openmpt/commit/492022c7297ede682161d9c0ec2de15526424e76", "file_name": "soundlib/Snd_fx.cpp", "vul_type": "cwe-125", "description": "Generate a C++ function that calculates the playback length of a song or seeks to a specific position in C++ using the CSoundFile class."}
{"func_name": "search_films", "func_src_before": "@app.route('/movies/search', methods=['GET', 'POST'])\ndef search_films():\n    form = SearchForm()\n    if not form.validate_on_submit():\n        return render_template('search.html', title='Search for films', form=form)\n    search_terms = form.data['term'].split(' ')\n    search_string = ' & '.join(search_terms)\n    cur.execute(f\"SELECT * FROM film where fulltext @@ to_tsquery('{search_string}')\")\n    res = cur.fetchall()\n    return render_template('search_results.html', title='Home', res=len(res))", "func_src_after": "@app.route('/movies/search', methods=['GET', 'POST'])\ndef search_films():\n    form = SearchForm()\n    if not form.validate_on_submit():\n        return render_template('search.html', title='Search for films', form=form)\n    search_terms = form.data['term'].split(' ')\n    search_string = ' & '.join(search_terms)\n    cur.execute(\"SELECT * FROM film where fulltext @@ to_tsquery(%s)\", (search_string, ))\n    res = cur.fetchall()\n    return render_template('search_results.html', title='Home', res=len(res))", "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to handle film search using a form and PostgreSQL full-text search."}
{"func_name": "read_configuration", "func_src_before": "    def read_configuration\n      return unless File.exist?(configuration_file)\n      YAML.load(File.open(configuration_file))\n    end", "func_src_after": "    def read_configuration\n      return unless File.exist?(configuration_file)\n      YAML.safe_load(File.open(configuration_file))\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 79, "char_end": 126, "line": "      YAML.load(File.open(configuration_file))\n"}], "added": [{"line_no": 3, "char_start": 79, "char_end": 131, "line": "      YAML.safe_load(File.open(configuration_file))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 90, "char_end": 95, "chars": "safe_"}]}, "commit_link": "github.com/mroth/lolcommits/commit/7eeef6effea8eab9b9019b21cd225f67d0f8c474", "file_name": "configuration.rb", "vul_type": "cwe-502", "commit_msg": "use YAML.safe_load", "parent_commit": "ea9d98ed863ad58bffba584a3d15b8752a359bfc", "description": "Create a Ruby function that loads configuration from a YAML file if the file exists."}
{"func_name": "main", "func_src_before": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n\tssh_path[sizeof(ssh_path)] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 385, "char_end": 436, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n"}, {"line_no": 17, "char_start": 436, "char_end": 472, "line": "\tssh_path[sizeof(ssh_path)] = '\\0';\n"}, {"line_no": 78, "char_start": 1620, "char_end": 1672, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n"}, {"line_no": 79, "char_start": 1672, "char_end": 1711, "line": "\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n"}], "added": [{"line_no": 16, "char_start": 385, "char_end": 437, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n"}, {"line_no": 17, "char_start": 437, "char_end": 477, "line": "\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}, {"line_no": 78, "char_start": 1625, "char_end": 1678, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n"}, {"line_no": 79, "char_start": 1678, "char_end": 1721, "line": "\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 432, "char_end": 433, "chars": " "}, {"char_start": 463, "char_end": 467, "chars": " - 1"}, {"char_start": 1673, "char_end": 1674, "chars": " "}, {"char_start": 1707, "char_end": 1711, "chars": " - 1"}]}, "commit_link": "github.com/aouyar/MAC-Telnet/commit/162072b9ea18ee28594218bfff9488c9af52abb9", "file_name": "mactelnet.c", "vul_type": "cwe-119", "commit_msg": "Fix trivial buffer overflow bug. Thanks to haakonnessjoen.", "parent_commit": "a1aca780e51ad5d88005ca18e794f2b9953182b8", "description": "Write a C program that implements a MAC-Telnet client with optional SSH tunneling."}
{"func_name": "set_interface_var", "func_src_before": "set_interface_var(const char *iface,\n\t\t  const char *var, const char *name,\n\t\t  uint32_t val)\n{\n\tFILE *fp;\n\tchar spath[64+IFNAMSIZ];\t/* XXX: magic constant */\n\tif (snprintf(spath, sizeof(spath), var, iface) >= sizeof(spath))\n\t\treturn -1;\n\n\tif (access(spath, F_OK) != 0)\n\t\treturn -1;\n\n\tfp = fopen(spath, \"w\");\n\tif (!fp) {\n\t\tif (name)\n\t\t\tflog(LOG_ERR, \"failed to set %s (%u) for %s: %s\",\n\t\t\t     name, val, iface, strerror(errno));\n\t\treturn -1;\n\t}\n\tfprintf(fp, \"%u\", val);\n\tfclose(fp);\n\n\treturn 0;\n}", "func_src_after": "set_interface_var(const char *iface,\n\t\t  const char *var, const char *name,\n\t\t  uint32_t val)\n{\n\tFILE *fp;\n\tchar spath[64+IFNAMSIZ];\t/* XXX: magic constant */\n\tif (snprintf(spath, sizeof(spath), var, iface) >= sizeof(spath))\n\t\treturn -1;\n\n\t/* No path traversal */\n\tif (strstr(name, \"..\") || strchr(name, '/'))\n\t\treturn -1;\n\n\tif (access(spath, F_OK) != 0)\n\t\treturn -1;\n\n\tfp = fopen(spath, \"w\");\n\tif (!fp) {\n\t\tif (name)\n\t\t\tflog(LOG_ERR, \"failed to set %s (%u) for %s: %s\",\n\t\t\t     name, val, iface, strerror(errno));\n\t\treturn -1;\n\t}\n\tfprintf(fp, \"%u\", val);\n\tfclose(fp);\n\n\treturn 0;\n}", "commit_link": "github.com/reubenhwk/radvd/commit/92e22ca23e52066da2258df8c76a2dca8a428bcc", "file_name": "device-linux.c", "vul_type": "cwe-022", "description": "Write a C function to update a network interface variable in a file, handling file paths and potential errors."}
{"func_name": "read_config", "func_src_before": "    def read_config(self):\n        \"\"\"Populate the instance with settings for the config file.\n\n        If we can't find any section for the given site, error gracefully.\n\n        \"\"\"\n        defaults = {\n            \"auth_type\": \"basic\",\n            \"verify_ssl_cert\": \"true\",\n        }\n\n        cp = configparser.RawConfigParser(defaults)\n        cp.read(CONFIG_LOCATIONS)\n\n        if not cp.has_option(self.site, \"base_url\"):\n            raise exceptions.ConfigError(\"unable to find a [{}] section with \"\n                                         \"a base_url.\".format(self.site))\n\n        self.base_url = cp.get(self.site, \"base_url\").rstrip(\"/\")\n        self.username = cp.get(self.site, \"username\")\n        self.password = cp.get(self.site, \"password\")\n        self.verify_ssl_cert = cp.getboolean(self.site, \"verify_ssl_cert\")\n\n        # load auth\n        auth_type = cp.get(self.site, \"auth_type\")\n        auth_type = auth_type.lower()\n        if auth_type not in AUTH_TYPES:\n            supported_auths = \", \".join(sorted(AUTH_TYPES.keys()))\n            msg = (\"invalid auth setting '{}', supported: {}\"\n                  .format(auth_type, supported_auths))\n            raise exceptions.ConfigError(msg)\n        self.auth_type = auth_type\n\n        self.required_fields = [\"To\", \"Component\", \"Subject\", \"Priority\"]", "func_src_after": "    def read_config(self):\n        \"\"\"Populate the instance with settings for the config file.\n\n        If we can't find any section for the given site, error gracefully.\n\n        \"\"\"\n        defaults = {\n            \"auth_type\": \"basic\",\n            \"verify_ssl_cert\": \"true\",\n        }\n\n        cp = configparser.RawConfigParser(defaults)\n        cp.read(CONFIG_LOCATIONS)\n\n        if not cp.has_option(self.site, \"base_url\"):\n            raise exceptions.ConfigError(\"unable to find a [{}] section with \"\n                                         \"a base_url.\".format(self.site))\n\n        self.base_url = cp.get(self.site, \"base_url\").rstrip(\"/\")\n        self.username = cp.get(self.site, \"username\")\n        self.password = cp.get(self.site, \"password\")\n        self.verify_ssl_cert = cp.getboolean(self.site, \"verify_ssl_cert\")\n\n        # load auth\n        auth_type = cp.get(self.site, \"auth_type\")\n        auth_type = auth_type.lower()\n        if auth_type not in AUTH_TYPES:\n            supported_auths = \", \".join(sorted(AUTH_TYPES.keys()))\n            msg = (\"invalid auth setting '{}', supported: {}\"\n                  .format(auth_type, supported_auths))\n            raise exceptions.ConfigError(msg)\n        self.auth_type = auth_type\n\n        if cp.has_option(self.site, \"editor\"):\n            self.config_editor = cp.get(self.site, \"editor\")\n        else:\n            self.config_editor = os.getenv(\"EDITOR\")\n\n        self.required_fields = [\"To\", \"Component\", \"Subject\", \"Priority\"]", "line_changes": {"deleted": [], "added": [{"line_no": 34, "char_start": 1248, "char_end": 1295, "line": "        if cp.has_option(self.site, \"editor\"):\n"}, {"line_no": 35, "char_start": 1295, "char_end": 1356, "line": "            self.config_editor = cp.get(self.site, \"editor\")\n"}, {"line_no": 36, "char_start": 1356, "char_end": 1370, "line": "        else:\n"}, {"line_no": 37, "char_start": 1370, "char_end": 1423, "line": "            self.config_editor = os.getenv(\"EDITOR\")\n"}, {"line_no": 38, "char_start": 1423, "char_end": 1424, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1248, "char_end": 1424, "chars": "        if cp.has_option(self.site, \"editor\"):\n            self.config_editor = cp.get(self.site, \"editor\")\n        else:\n            self.config_editor = os.getenv(\"EDITOR\")\n\n"}]}, "commit_link": "github.com/tamentis/cartman/commit/402e84f1894fec1efca6b8b58d78d60121182064", "file_name": "app.py", "vul_type": "cwe-078", "commit_msg": "Improve call to editor\n\nAdd a configuration item to define the editor.\n\nUse subprocess.call() to avoid shell usage and escaping problems.\n\nCheck editor return value.", "parent_commit": "994c2174041ebb25d58d7fc23eb0581dcb8fb864", "description": "Write a Python function to load configuration settings from a file, handling missing sections or options with custom exceptions."}
{"func_name": "ipxitf_ioctl", "func_src_before": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = -EFAULT;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\tbreak;\n\t\tipxitf_put(ipxif);\n\t\trc = 0;\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "func_src_after": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = 0;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\trc = -EFAULT;\n\t\tipxitf_put(ipxif);\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/ee0d8d8482345ff97a75a7d747efc309f13b0d80", "file_name": "net/ipx/af_ipx.c", "vul_type": "cwe-416", "description": "Write a C function named `ipxitf_ioctl` that handles IPX network interface control commands."}
{"func_name": "encryptPassword", "func_src_before": "    encryptPassword: function(password) {\n        if (!password) return '';\n        return crypto.createHmac('sha1', this.salt).update(password).digest('hex');\n    }", "func_src_after": "    encryptPassword: function(password) {\n        if (!password) return '';\n        return bcrypt.hashSync(password, 10);\n    }", "line_changes": {"deleted": [{"line_no": 3, "char_start": 76, "char_end": 160, "line": "        return crypto.createHmac('sha1', this.salt).update(password).digest('hex');\n"}], "added": [{"line_no": 3, "char_start": 76, "char_end": 122, "line": "        return bcrypt.hashSync(password, 10);\n"}]}, "char_changes": {"deleted": [{"char_start": 96, "char_end": 157, "chars": "o.createHmac('sha1', this.salt).update(password).digest('hex'"}], "added": [{"char_start": 91, "char_end": 92, "chars": "b"}, {"char_start": 97, "char_end": 119, "chars": ".hashSync(password, 10"}]}, "commit_link": "github.com/andela/temari-cfh/commit/e5e4de5f2cc14fcd86464c83b5d110c9e05f2eba", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Improved user password encryption to use bcrypt instead of SHA1.", "parent_commit": "d56dd3474970c1f8b1dbf3599a451c3d2609c13d", "description": "Create a JavaScript function named `encryptPassword` that takes a password string and returns its hashed version."}
{"func_name": "bin_symbols", "func_src_before": "static int bin_symbols(RCore *r, int mode, ut64 laddr, int va, ut64 at, const char *name, bool exponly, const char *args) {\n\tRBinInfo *info = r_bin_get_info (r->bin);\n\tRList *entries = r_bin_get_entries (r->bin);\n\tRBinSymbol *symbol;\n\tRBinAddr *entry;\n\tRListIter *iter;\n\tbool firstexp = true;\n\tbool printHere = false;\n\tint i = 0, lastfs = 's';\n\tbool bin_demangle = r_config_get_i (r->config, \"bin.demangle\");\n\tif (!info) {\n\t\treturn 0;\n\t}\n\n\tif (args && *args == '.') {\n\t\tprintHere = true;\n\t}\n\n\tbool is_arm = info && info->arch && !strncmp (info->arch, \"arm\", 3);\n\tconst char *lang = bin_demangle ? r_config_get (r->config, \"bin.lang\") : NULL;\n\n\tRList *symbols = r_bin_get_symbols (r->bin);\n\tr_spaces_push (&r->anal->meta_spaces, \"bin\");\n\n\tif (IS_MODE_JSON (mode) && !printHere) {\n\t\tr_cons_printf (\"[\");\n\t} else if (IS_MODE_SET (mode)) {\n\t\tr_flag_space_set (r->flags, R_FLAGS_FS_SYMBOLS);\n\t} else if (!at && exponly) {\n\t\tif (IS_MODE_RAD (mode)) {\n\t\t\tr_cons_printf (\"fs exports\\n\");\n\t\t} else if (IS_MODE_NORMAL (mode)) {\n\t\t\tr_cons_printf (printHere ? \"\" : \"[Exports]\\n\");\n\t\t}\n\t} else if (!at && !exponly) {\n\t\tif (IS_MODE_RAD (mode)) {\n\t\t\tr_cons_printf (\"fs symbols\\n\");\n\t\t} else if (IS_MODE_NORMAL (mode)) {\n\t\t\tr_cons_printf (printHere ? \"\" : \"[Symbols]\\n\");\n\t\t}\n\t}\n\tif (IS_MODE_NORMAL (mode)) {\n\t\tr_cons_printf (\"Num Paddr      Vaddr      Bind     Type Size Name\\n\");\n\t}\n\n\n\tsize_t count = 0;\n\tr_list_foreach (symbols, iter, symbol) {\n\t\tif (!symbol->name) {\n\t\t\tcontinue;\n\t\t}\n\t\tchar *r_symbol_name = r_str_escape_utf8 (symbol->name, false, true);\n\t\tut64 addr = compute_addr (r->bin, symbol->paddr, symbol->vaddr, va);\n\t\tint len = symbol->size ? symbol->size : 32;\n\t\tSymName sn = {0};\n\n\t\tif (exponly && !isAnExport (symbol)) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (name && strcmp (r_symbol_name, name)) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (at && (!symbol->size || !is_in_range (at, addr, symbol->size))) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif ((printHere && !is_in_range (r->offset, symbol->paddr, len))\n\t\t\t\t&& (printHere && !is_in_range (r->offset, addr, len))) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tcount ++;\n\t\tsnInit (r, &sn, symbol, lang);\n\n\t\tif (IS_MODE_SET (mode) && (is_section_symbol (symbol) || is_file_symbol (symbol))) {\n\t\t\t/*\n\t\t\t * Skip section symbols because they will have their own flag.\n\t\t\t * Skip also file symbols because not useful for now.\n\t\t\t */\n\t\t} else if (IS_MODE_SET (mode) && is_special_symbol (symbol)) {\n\t\t\tif (is_arm) {\n\t\t\t\thandle_arm_special_symbol (r, symbol, va);\n\t\t\t}\n\t\t} else if (IS_MODE_SET (mode)) {\n\t\t\t// TODO: provide separate API in RBinPlugin to let plugins handle anal hints/metadata\n\t\t\tif (is_arm) {\n\t\t\t\thandle_arm_symbol (r, symbol, info, va);\n\t\t\t}\n\t\t\tselect_flag_space (r, symbol);\n\t\t\t/* If that's a Classed symbol (method or so) */\n\t\t\tif (sn.classname) {\n\t\t\t\tRFlagItem *fi = r_flag_get (r->flags, sn.methflag);\n\t\t\t\tif (r->bin->prefix) {\n\t\t\t\t\tchar *prname = r_str_newf (\"%s.%s\", r->bin->prefix, sn.methflag);\n\t\t\t\t\tr_name_filter (sn.methflag, -1);\n\t\t\t\t\tfree (sn.methflag);\n\t\t\t\t\tsn.methflag = prname;\n\t\t\t\t}\n\t\t\t\tif (fi) {\n\t\t\t\t\tr_flag_item_set_realname (fi, sn.methname);\n\t\t\t\t\tif ((fi->offset - r->flags->base) == addr) {\n\t\t\t\t//\t\tchar *comment = fi->comment ? strdup (fi->comment) : NULL;\n\t\t\t\t\t\tr_flag_unset (r->flags, fi);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfi = r_flag_set (r->flags, sn.methflag, addr, symbol->size);\n\t\t\t\t\tchar *comment = fi->comment ? strdup (fi->comment) : NULL;\n\t\t\t\t\tif (comment) {\n\t\t\t\t\t\tr_flag_item_set_comment (fi, comment);\n\t\t\t\t\t\tR_FREE (comment);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst char *n = sn.demname ? sn.demname : sn.name;\n\t\t\t\tconst char *fn = sn.demflag ? sn.demflag : sn.nameflag;\n\t\t\t\tchar *fnp = (r->bin->prefix) ?\n\t\t\t\t\tr_str_newf (\"%s.%s\", r->bin->prefix, fn):\n\t\t\t\t\tstrdup (fn);\n\t\t\t\tRFlagItem *fi = r_flag_set (r->flags, fnp, addr, symbol->size);\n\t\t\t\tif (fi) {\n\t\t\t\t\tr_flag_item_set_realname (fi, n);\n\t\t\t\t\tfi->demangled = (bool)(size_t)sn.demname;\n\t\t\t\t} else {\n\t\t\t\t\tif (fn) {\n\t\t\t\t\t\teprintf (\"[Warning] Can't find flag (%s)\\n\", fn);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfree (fnp);\n\t\t\t}\n\t\t\tif (sn.demname) {\n\t\t\t\tr_meta_add (r->anal, R_META_TYPE_COMMENT,\n\t\t\t\t\taddr, symbol->size, sn.demname);\n\t\t\t}\n\t\t\tr_flag_space_pop (r->flags);\n\t\t} else if (IS_MODE_JSON (mode)) {\n\t\t\tchar *str = r_str_escape_utf8_for_json (r_symbol_name, -1);\n\t\t\t// str = r_str_replace (str, \"\\\"\", \"\\\\\\\"\", 1);\n\t\t\tr_cons_printf (\"%s{\\\"name\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"demname\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"flagname\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"ordinal\\\":%d,\"\n\t\t\t\t\"\\\"bind\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"size\\\":%d,\"\n\t\t\t\t\"\\\"type\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"vaddr\\\":%\"PFMT64d\",\"\n\t\t\t\t\"\\\"paddr\\\":%\"PFMT64d\"}\",\n\t\t\t\t((exponly && firstexp) || printHere) ? \"\" : (iter->p ? \",\" : \"\"),\n\t\t\t\tstr,\n\t\t\t\tsn.demname? sn.demname: \"\",\n\t\t\t\tsn.nameflag,\n\t\t\t\tsymbol->ordinal,\n\t\t\t\tsymbol->bind,\n\t\t\t\t(int)symbol->size,\n\t\t\t\tsymbol->type,\n\t\t\t\t(ut64)addr, (ut64)symbol->paddr);\n\t\t\tfree (str);\n\t\t} else if (IS_MODE_SIMPLE (mode)) {\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tr_cons_printf (\"0x%08\"PFMT64x\" %d %s\\n\",\n\t\t\t\taddr, (int)symbol->size, name);\n\t\t} else if (IS_MODE_SIMPLEST (mode)) {\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tr_cons_printf (\"%s\\n\", name);\n\t\t} else if (IS_MODE_RAD (mode)) {\n\t\t\t/* Skip special symbols because we do not flag them and\n\t\t\t * they shouldn't be printed in the rad format either */\n\t\t\tif (is_special_symbol (symbol)) {\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tRBinFile *binfile;\n\t\t\tRBinPlugin *plugin;\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tif (!name) {\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tif (!strncmp (name, \"imp.\", 4)) {\n\t\t\t\tif (lastfs != 'i') {\n\t\t\t\t\tr_cons_printf (\"fs imports\\n\");\n\t\t\t\t}\n\t\t\t\tlastfs = 'i';\n\t\t\t} else {\n\t\t\t\tif (lastfs != 's') {\n\t\t\t\t\tconst char *fs = exponly? \"exports\": \"symbols\";\n\t\t\t\t\tr_cons_printf (\"fs %s\\n\", fs);\n\t\t\t\t}\n\t\t\t\tlastfs = 's';\n\t\t\t}\n\t\t\tif (r->bin->prefix || *name) { // we don't want unnamed symbol flags\n\t\t\t\tchar *flagname = construct_symbol_flagname (\"sym\", name, MAXFLAG_LEN_DEFAULT);\n\t\t\t\tif (!flagname) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"f %s%s%s %u 0x%08\" PFMT64x \"\\\"\\n\",\n\t\t\t\t\tr->bin->prefix ? r->bin->prefix : \"\", r->bin->prefix ? \".\" : \"\",\n\t\t\t\t\tflagname, symbol->size, addr);\n\t\t\t\tfree (flagname);\n\t\t\t}\n\t\t\tbinfile = r_bin_cur (r->bin);\n\t\t\tplugin = r_bin_file_cur_plugin (binfile);\n\t\t\tif (plugin && plugin->name) {\n\t\t\t\tif (r_str_startswith (plugin->name, \"pe\")) {\n\t\t\t\t\tchar *module = strdup (r_symbol_name);\n\t\t\t\t\tchar *p = strstr (module, \".dll_\");\n\t\t\t\t\tif (p && strstr (module, \"imp.\")) {\n\t\t\t\t\t\tchar *symname = __filterShell (p + 5);\n\t\t\t\t\t\tchar *m = __filterShell (module);\n\t\t\t\t\t\t*p = 0;\n\t\t\t\t\t\tif (r->bin->prefix) {\n\t\t\t\t\t\t\tr_cons_printf (\"k bin/pe/%s/%d=%s.%s\\n\",\n\t\t\t\t\t\t\t\tmodule, symbol->ordinal, r->bin->prefix, symname);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tr_cons_printf (\"k bin/pe/%s/%d=%s\\n\",\n\t\t\t\t\t\t\t\tmodule, symbol->ordinal, symname);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfree (symname);\n\t\t\t\t\t\tfree (m);\n\t\t\t\t\t}\n\t\t\t\t\tfree (module);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tconst char *bind = symbol->bind? symbol->bind: \"NONE\";\n\t\t\tconst char *type = symbol->type? symbol->type: \"NONE\";\n\t\t\tconst char *name = r_str_get (sn.demname? sn.demname: r_symbol_name);\n\t\t\t// const char *fwd = r_str_get (symbol->forwarder);\n\t\t\tr_cons_printf (\"%03u\", symbol->ordinal);\n\t\t\tif (symbol->paddr == UT64_MAX) {\n\t\t\t\tr_cons_printf (\" ----------\");\n\t\t\t} else {\n\t\t\t\tr_cons_printf (\" 0x%08\"PFMT64x, symbol->paddr);\n\t\t\t}\n\t\t\tr_cons_printf (\" 0x%08\"PFMT64x\" %6s %6s %4d%s%s\\n\",\n\t\t\t               addr, bind, type, symbol->size, *name? \" \": \"\", name);\n\t\t}\nnext:\n\t\tsnFini (&sn);\n\t\ti++;\n\t\tfree (r_symbol_name);\n\t\tif (exponly && firstexp) {\n\t\t\tfirstexp = false;\n\t\t}\n\t\tif (printHere) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (count == 0 && IS_MODE_JSON (mode)) {\n\t\tr_cons_printf (\"{}\");\n\t}\n\n\n\t//handle thumb and arm for entry point since they are not present in symbols\n\tif (is_arm) {\n\t\tr_list_foreach (entries, iter, entry) {\n\t\t\tif (IS_MODE_SET (mode)) {\n\t\t\t\thandle_arm_entry (r, entry, info, va);\n\t\t\t}\n\t\t}\n\t}\n\tif (IS_MODE_JSON (mode) && !printHere) {\n\t\tr_cons_printf (\"]\");\n\t}\n\n\tr_spaces_pop (&r->anal->meta_spaces);\n\treturn true;\n}", "func_src_after": "static int bin_symbols(RCore *r, int mode, ut64 laddr, int va, ut64 at, const char *name, bool exponly, const char *args) {\n\tRBinInfo *info = r_bin_get_info (r->bin);\n\tRList *entries = r_bin_get_entries (r->bin);\n\tRBinSymbol *symbol;\n\tRBinAddr *entry;\n\tRListIter *iter;\n\tbool firstexp = true;\n\tbool printHere = false;\n\tint i = 0, lastfs = 's';\n\tbool bin_demangle = r_config_get_i (r->config, \"bin.demangle\");\n\tif (!info) {\n\t\treturn 0;\n\t}\n\n\tif (args && *args == '.') {\n\t\tprintHere = true;\n\t}\n\n\tbool is_arm = info && info->arch && !strncmp (info->arch, \"arm\", 3);\n\tconst char *lang = bin_demangle ? r_config_get (r->config, \"bin.lang\") : NULL;\n\n\tRList *symbols = r_bin_get_symbols (r->bin);\n\tr_spaces_push (&r->anal->meta_spaces, \"bin\");\n\n\tif (IS_MODE_JSON (mode) && !printHere) {\n\t\tr_cons_printf (\"[\");\n\t} else if (IS_MODE_SET (mode)) {\n\t\tr_flag_space_set (r->flags, R_FLAGS_FS_SYMBOLS);\n\t} else if (!at && exponly) {\n\t\tif (IS_MODE_RAD (mode)) {\n\t\t\tr_cons_printf (\"fs exports\\n\");\n\t\t} else if (IS_MODE_NORMAL (mode)) {\n\t\t\tr_cons_printf (printHere ? \"\" : \"[Exports]\\n\");\n\t\t}\n\t} else if (!at && !exponly) {\n\t\tif (IS_MODE_RAD (mode)) {\n\t\t\tr_cons_printf (\"fs symbols\\n\");\n\t\t} else if (IS_MODE_NORMAL (mode)) {\n\t\t\tr_cons_printf (printHere ? \"\" : \"[Symbols]\\n\");\n\t\t}\n\t}\n\tif (IS_MODE_NORMAL (mode)) {\n\t\tr_cons_printf (\"Num Paddr      Vaddr      Bind     Type Size Name\\n\");\n\t}\n\n\n\tsize_t count = 0;\n\tr_list_foreach (symbols, iter, symbol) {\n\t\tif (!symbol->name) {\n\t\t\tcontinue;\n\t\t}\n\t\tchar *r_symbol_name = r_str_escape_utf8 (symbol->name, false, true);\n\t\tut64 addr = compute_addr (r->bin, symbol->paddr, symbol->vaddr, va);\n\t\tint len = symbol->size ? symbol->size : 32;\n\t\tSymName sn = {0};\n\n\t\tif (exponly && !isAnExport (symbol)) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (name && strcmp (r_symbol_name, name)) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (at && (!symbol->size || !is_in_range (at, addr, symbol->size))) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif ((printHere && !is_in_range (r->offset, symbol->paddr, len))\n\t\t\t\t&& (printHere && !is_in_range (r->offset, addr, len))) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tcount ++;\n\t\tsnInit (r, &sn, symbol, lang);\n\n\t\tif (IS_MODE_SET (mode) && (is_section_symbol (symbol) || is_file_symbol (symbol))) {\n\t\t\t/*\n\t\t\t * Skip section symbols because they will have their own flag.\n\t\t\t * Skip also file symbols because not useful for now.\n\t\t\t */\n\t\t} else if (IS_MODE_SET (mode) && is_special_symbol (symbol)) {\n\t\t\tif (is_arm) {\n\t\t\t\thandle_arm_special_symbol (r, symbol, va);\n\t\t\t}\n\t\t} else if (IS_MODE_SET (mode)) {\n\t\t\t// TODO: provide separate API in RBinPlugin to let plugins handle anal hints/metadata\n\t\t\tif (is_arm) {\n\t\t\t\thandle_arm_symbol (r, symbol, info, va);\n\t\t\t}\n\t\t\tselect_flag_space (r, symbol);\n\t\t\t/* If that's a Classed symbol (method or so) */\n\t\t\tif (sn.classname) {\n\t\t\t\tRFlagItem *fi = r_flag_get (r->flags, sn.methflag);\n\t\t\t\tif (r->bin->prefix) {\n\t\t\t\t\tchar *prname = r_str_newf (\"%s.%s\", r->bin->prefix, sn.methflag);\n\t\t\t\t\tr_name_filter (sn.methflag, -1);\n\t\t\t\t\tfree (sn.methflag);\n\t\t\t\t\tsn.methflag = prname;\n\t\t\t\t}\n\t\t\t\tif (fi) {\n\t\t\t\t\tr_flag_item_set_realname (fi, sn.methname);\n\t\t\t\t\tif ((fi->offset - r->flags->base) == addr) {\n\t\t\t\t//\t\tchar *comment = fi->comment ? strdup (fi->comment) : NULL;\n\t\t\t\t\t\tr_flag_unset (r->flags, fi);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfi = r_flag_set (r->flags, sn.methflag, addr, symbol->size);\n\t\t\t\t\tchar *comment = fi->comment ? strdup (fi->comment) : NULL;\n\t\t\t\t\tif (comment) {\n\t\t\t\t\t\tr_flag_item_set_comment (fi, comment);\n\t\t\t\t\t\tR_FREE (comment);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst char *n = sn.demname ? sn.demname : sn.name;\n\t\t\t\tconst char *fn = sn.demflag ? sn.demflag : sn.nameflag;\n\t\t\t\tchar *fnp = (r->bin->prefix) ?\n\t\t\t\t\tr_str_newf (\"%s.%s\", r->bin->prefix, fn):\n\t\t\t\t\tstrdup (fn);\n\t\t\t\tRFlagItem *fi = r_flag_set (r->flags, fnp, addr, symbol->size);\n\t\t\t\tif (fi) {\n\t\t\t\t\tr_flag_item_set_realname (fi, n);\n\t\t\t\t\tfi->demangled = (bool)(size_t)sn.demname;\n\t\t\t\t} else {\n\t\t\t\t\tif (fn) {\n\t\t\t\t\t\teprintf (\"[Warning] Can't find flag (%s)\\n\", fn);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfree (fnp);\n\t\t\t}\n\t\t\tif (sn.demname) {\n\t\t\t\tr_meta_add (r->anal, R_META_TYPE_COMMENT,\n\t\t\t\t\taddr, symbol->size, sn.demname);\n\t\t\t}\n\t\t\tr_flag_space_pop (r->flags);\n\t\t} else if (IS_MODE_JSON (mode)) {\n\t\t\tchar *str = r_str_escape_utf8_for_json (r_symbol_name, -1);\n\t\t\t// str = r_str_replace (str, \"\\\"\", \"\\\\\\\"\", 1);\n\t\t\tr_cons_printf (\"%s{\\\"name\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"demname\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"flagname\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"ordinal\\\":%d,\"\n\t\t\t\t\"\\\"bind\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"size\\\":%d,\"\n\t\t\t\t\"\\\"type\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"vaddr\\\":%\"PFMT64d\",\"\n\t\t\t\t\"\\\"paddr\\\":%\"PFMT64d\"}\",\n\t\t\t\t((exponly && firstexp) || printHere) ? \"\" : (iter->p ? \",\" : \"\"),\n\t\t\t\tstr,\n\t\t\t\tsn.demname? sn.demname: \"\",\n\t\t\t\tsn.nameflag,\n\t\t\t\tsymbol->ordinal,\n\t\t\t\tsymbol->bind,\n\t\t\t\t(int)symbol->size,\n\t\t\t\tsymbol->type,\n\t\t\t\t(ut64)addr, (ut64)symbol->paddr);\n\t\t\tfree (str);\n\t\t} else if (IS_MODE_SIMPLE (mode)) {\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tr_cons_printf (\"0x%08\"PFMT64x\" %d %s\\n\",\n\t\t\t\taddr, (int)symbol->size, name);\n\t\t} else if (IS_MODE_SIMPLEST (mode)) {\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tr_cons_printf (\"%s\\n\", name);\n\t\t} else if (IS_MODE_RAD (mode)) {\n\t\t\t/* Skip special symbols because we do not flag them and\n\t\t\t * they shouldn't be printed in the rad format either */\n\t\t\tif (is_special_symbol (symbol)) {\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tRBinFile *binfile;\n\t\t\tRBinPlugin *plugin;\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tif (!name) {\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tif (!strncmp (name, \"imp.\", 4)) {\n\t\t\t\tif (lastfs != 'i') {\n\t\t\t\t\tr_cons_printf (\"fs imports\\n\");\n\t\t\t\t}\n\t\t\t\tlastfs = 'i';\n\t\t\t} else {\n\t\t\t\tif (lastfs != 's') {\n\t\t\t\t\tconst char *fs = exponly? \"exports\": \"symbols\";\n\t\t\t\t\tr_cons_printf (\"fs %s\\n\", fs);\n\t\t\t\t}\n\t\t\t\tlastfs = 's';\n\t\t\t}\n\t\t\tif (r->bin->prefix || *name) { // we don't want unnamed symbol flags\n\t\t\t\tchar *flagname = construct_symbol_flagname (\"sym\", name, MAXFLAG_LEN_DEFAULT);\n\t\t\t\tif (!flagname) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"f %s%s%s %u 0x%08\" PFMT64x \"\\\"\\n\",\n\t\t\t\t\tr->bin->prefix ? r->bin->prefix : \"\", r->bin->prefix ? \".\" : \"\",\n\t\t\t\t\tflagname, symbol->size, addr);\n\t\t\t\tfree (flagname);\n\t\t\t}\n\t\t\tbinfile = r_bin_cur (r->bin);\n\t\t\tplugin = r_bin_file_cur_plugin (binfile);\n\t\t\tif (plugin && plugin->name) {\n\t\t\t\tif (r_str_startswith (plugin->name, \"pe\")) {\n\t\t\t\t\tchar *module = strdup (r_symbol_name);\n\t\t\t\t\tchar *p = strstr (module, \".dll_\");\n\t\t\t\t\tif (p && strstr (module, \"imp.\")) {\n\t\t\t\t\t\tchar *symname = __filterShell (p + 5);\n\t\t\t\t\t\tchar *m = __filterShell (module);\n\t\t\t\t\t\t*p = 0;\n\t\t\t\t\t\tif (r->bin->prefix) {\n\t\t\t\t\t\t\tr_cons_printf (\"\\\"k bin/pe/%s/%d=%s.%s\\\"\\n\",\n\t\t\t\t\t\t\t\tmodule, symbol->ordinal, r->bin->prefix, symname);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tr_cons_printf (\"\\\"k bin/pe/%s/%d=%s\\\"\\n\",\n\t\t\t\t\t\t\t\tmodule, symbol->ordinal, symname);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfree (symname);\n\t\t\t\t\t\tfree (m);\n\t\t\t\t\t}\n\t\t\t\t\tfree (module);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tconst char *bind = symbol->bind? symbol->bind: \"NONE\";\n\t\t\tconst char *type = symbol->type? symbol->type: \"NONE\";\n\t\t\tconst char *name = r_str_get (sn.demname? sn.demname: r_symbol_name);\n\t\t\t// const char *fwd = r_str_get (symbol->forwarder);\n\t\t\tr_cons_printf (\"%03u\", symbol->ordinal);\n\t\t\tif (symbol->paddr == UT64_MAX) {\n\t\t\t\tr_cons_printf (\" ----------\");\n\t\t\t} else {\n\t\t\t\tr_cons_printf (\" 0x%08\"PFMT64x, symbol->paddr);\n\t\t\t}\n\t\t\tr_cons_printf (\" 0x%08\"PFMT64x\" %6s %6s %4d%s%s\\n\",\n\t\t\t               addr, bind, type, symbol->size, *name? \" \": \"\", name);\n\t\t}\nnext:\n\t\tsnFini (&sn);\n\t\ti++;\n\t\tfree (r_symbol_name);\n\t\tif (exponly && firstexp) {\n\t\t\tfirstexp = false;\n\t\t}\n\t\tif (printHere) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (count == 0 && IS_MODE_JSON (mode)) {\n\t\tr_cons_printf (\"{}\");\n\t}\n\n\n\t//handle thumb and arm for entry point since they are not present in symbols\n\tif (is_arm) {\n\t\tr_list_foreach (entries, iter, entry) {\n\t\t\tif (IS_MODE_SET (mode)) {\n\t\t\t\thandle_arm_entry (r, entry, info, va);\n\t\t\t}\n\t\t}\n\t}\n\tif (IS_MODE_JSON (mode) && !printHere) {\n\t\tr_cons_printf (\"]\");\n\t}\n\n\tr_spaces_pop (&r->anal->meta_spaces);\n\treturn true;\n}", "commit_link": "github.com/radareorg/radare2/commit/5411543a310a470b1257fb93273cdd6e8dfcb3af", "file_name": "libr/core/cbin.c", "vul_type": "cwe-078", "description": "Write a C function to process and print binary symbols in various formats based on the given mode."}
{"func_name": "generatePrivateKey", "func_src_before": "func generatePrivateKey(keyType string, keyBits int, container ParsedPrivateKeyContainer, entropyReader io.Reader) error {\n\tvar err error\n\tvar privateKeyType PrivateKeyType\n\tvar privateKeyBytes []byte\n\tvar privateKey crypto.Signer\n\n\tvar randReader io.Reader = rand.Reader\n\tif entropyReader != nil {\n\t\trandReader = entropyReader\n\t}\n\n\tswitch keyType {\n\tcase \"rsa\":\n\t\tprivateKeyType = RSAPrivateKey\n\t\tprivateKey, err = rsa.GenerateKey(randReader, keyBits)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating RSA private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes = x509.MarshalPKCS1PrivateKey(privateKey.(*rsa.PrivateKey))\n\tcase \"ec\":\n\t\tprivateKeyType = ECPrivateKey\n\t\tvar curve elliptic.Curve\n\t\tswitch keyBits {\n\t\tcase 224:\n\t\t\tcurve = elliptic.P224()\n\t\tcase 256:\n\t\t\tcurve = elliptic.P256()\n\t\tcase 384:\n\t\t\tcurve = elliptic.P384()\n\t\tcase 521:\n\t\t\tcurve = elliptic.P521()\n\t\tdefault:\n\t\t\treturn errutil.UserError{Err: fmt.Sprintf(\"unsupported bit length for EC key: %d\", keyBits)}\n\t\t}\n\t\tprivateKey, err = ecdsa.GenerateKey(curve, randReader)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating EC private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes, err = x509.MarshalECPrivateKey(privateKey.(*ecdsa.PrivateKey))\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error marshalling EC private key: %v\", err)}\n\t\t}\n\tcase \"ed25519\":\n\t\tprivateKeyType = Ed25519PrivateKey\n\t\t_, privateKey, err = ed25519.GenerateKey(randReader)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating ed25519 private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes, err = x509.MarshalPKCS8PrivateKey(privateKey.(ed25519.PrivateKey))\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error marshalling Ed25519 private key: %v\", err)}\n\t\t}\n\tdefault:\n\t\treturn errutil.UserError{Err: fmt.Sprintf(\"unknown key type: %s\", keyType)}\n\t}\n\n\tcontainer.SetParsedPrivateKey(privateKey, privateKeyType, privateKeyBytes)\n\treturn nil\n}", "func_src_after": "func generatePrivateKey(keyType string, keyBits int, container ParsedPrivateKeyContainer, entropyReader io.Reader) error {\n\tvar err error\n\tvar privateKeyType PrivateKeyType\n\tvar privateKeyBytes []byte\n\tvar privateKey crypto.Signer\n\n\tvar randReader io.Reader = rand.Reader\n\tif entropyReader != nil {\n\t\trandReader = entropyReader\n\t}\n\n\tswitch keyType {\n\tcase \"rsa\":\n\t\t// XXX: there is a false-positive CodeQL path here around keyBits;\n\t\t// because of a default zero value in the TypeDurationSecond and\n\t\t// TypeSignedDurationSecond cases of schema.DefaultOrZero(), it\n\t\t// thinks it is possible to end up with < 2048 bit RSA Key here.\n\t\t// While this is true for SSH keys, it isn't true for PKI keys\n\t\t// due to ValidateKeyTypeLength(...) below. While we could close\n\t\t// the report as a false-positive, enforcing a minimum keyBits size\n\t\t// here of 2048 would ensure no other paths exist.\n\t\tif keyBits < 2048 {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"insecure bit length for RSA private key: %d\", keyBits)}\n\t\t}\n\t\tprivateKeyType = RSAPrivateKey\n\t\tprivateKey, err = rsa.GenerateKey(randReader, keyBits)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating RSA private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes = x509.MarshalPKCS1PrivateKey(privateKey.(*rsa.PrivateKey))\n\tcase \"ec\":\n\t\tprivateKeyType = ECPrivateKey\n\t\tvar curve elliptic.Curve\n\t\tswitch keyBits {\n\t\tcase 224:\n\t\t\tcurve = elliptic.P224()\n\t\tcase 256:\n\t\t\tcurve = elliptic.P256()\n\t\tcase 384:\n\t\t\tcurve = elliptic.P384()\n\t\tcase 521:\n\t\t\tcurve = elliptic.P521()\n\t\tdefault:\n\t\t\treturn errutil.UserError{Err: fmt.Sprintf(\"unsupported bit length for EC key: %d\", keyBits)}\n\t\t}\n\t\tprivateKey, err = ecdsa.GenerateKey(curve, randReader)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating EC private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes, err = x509.MarshalECPrivateKey(privateKey.(*ecdsa.PrivateKey))\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error marshalling EC private key: %v\", err)}\n\t\t}\n\tcase \"ed25519\":\n\t\tprivateKeyType = Ed25519PrivateKey\n\t\t_, privateKey, err = ed25519.GenerateKey(randReader)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating ed25519 private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes, err = x509.MarshalPKCS8PrivateKey(privateKey.(ed25519.PrivateKey))\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error marshalling Ed25519 private key: %v\", err)}\n\t\t}\n\tdefault:\n\t\treturn errutil.UserError{Err: fmt.Sprintf(\"unknown key type: %s\", keyType)}\n\t}\n\n\tcontainer.SetParsedPrivateKey(privateKey, privateKeyType, privateKeyBytes)\n\treturn nil\n}", "line_changes": {"deleted": [], "added": [{"line_no": 22, "char_start": 887, "char_end": 909, "line": "\t\tif keyBits < 2048 {\n"}, {"line_no": 23, "char_start": 909, "char_end": 1015, "line": "\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"insecure bit length for RSA private key: %d\", keyBits)}\n"}, {"line_no": 24, "char_start": 1015, "char_end": 1019, "line": "\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 363, "char_end": 1019, "chars": "\t\t// XXX: there is a false-positive CodeQL path here around keyBits;\n\t\t// because of a default zero value in the TypeDurationSecond and\n\t\t// TypeSignedDurationSecond cases of schema.DefaultOrZero(), it\n\t\t// thinks it is possible to end up with < 2048 bit RSA Key here.\n\t\t// While this is true for SSH keys, it isn't true for PKI keys\n\t\t// due to ValidateKeyTypeLength(...) below. While we could close\n\t\t// the report as a false-positive, enforcing a minimum keyBits size\n\t\t// here of 2048 would ensure no other paths exist.\n\t\tif keyBits < 2048 {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"insecure bit length for RSA private key: %d\", keyBits)}\n\t\t}\n"}]}, "commit_link": "github.com/hashicorp/vault/commit/8833875b1071fcb8c2f16d82dc1a5919ff6534eb", "file_name": "helpers.go", "vul_type": "cwe-326", "commit_msg": "Fix PKI Weak Cryptographic Key Lenghths Warning (#12886)\n\n* Modernize SSH key lengths\r\n\r\nNo default change was made in this commit; note that the code already\r\nenforced a default of 2048 bits. ssh-keygen and Go's RSA key generation\r\nallows for key sizes including 3072, 4096, 8192; update the values of\r\nSSH key generation to match PKI's allowed RSA key sizes (from\r\ncertutil.ValidateKeyTypeLength(...)). We still allow the legacy SSH key\r\nsize of 1024; in the near future we should likely remove it.\r\n\r\nSigned-off-by: Alexander Scheel <alex.scheel@hashicorp.com>\r\n\r\n* Ensure minimum of 2048-bit PKI RSA keys\r\n\r\nWhile the stated path is a false-positive, verifying all paths is\r\nnon-trivial. We largely validate API call lengths using\r\ncertutil.ValidateKeyTypeLength(...), but ensuring no other path calls\r\ncertutil.generatePrivateKey(...) --- directly or indirectly --- is\r\nnon-trivial. Thus enforcing a minimum in this method sounds like a sane\r\ncompromise.\r\n\r\nResolves: https://github.com/hashicorp/vault/security/code-scanning/55\r\n\r\nSigned-off-by: Alexander Scheel <alex.scheel@hashicorp.com>", "parent_commit": "14101f866414d2ed7850648b465c746ac8fda621", "description": "Write a Go function to generate a private key of a specified type and size, optionally using a custom entropy source."}
{"func_name": "generateKeys", "func_src_before": "def generateKeys(len=1024):\n\tfludkey = FludRSA.generate(len)\n\treturn fludkey.publickey(), fludkey.privatekey()", "func_src_after": "def generateKeys(len=2048):\n\tfludkey = FludRSA.generate(len)\n\treturn fludkey.publickey(), fludkey.privatekey()", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 28, "line": "def generateKeys(len=1024):\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 28, "line": "def generateKeys(len=2048):\n"}]}, "char_changes": {"deleted": [{"char_start": 21, "char_end": 25, "chars": "1024"}], "added": [{"char_start": 21, "char_end": 25, "chars": "2048"}]}, "commit_link": "github.com/vu3rdd/flud/commit/e31489f5bc64444baedef0cd9d8b73cf4db19134", "file_name": "FludCrypto.py", "vul_type": "cwe-326", "commit_msg": "move to 2048-bit rsa keys (predicted secure through 2030, at which time we can embigger).", "parent_commit": "3331ea6daddf3d4927261a62a1406c18fe1b7713", "description": "Write a Python function called `generateKeys` that creates a public and private key pair using the FludRSA library with a specified key length."}
{"func_name": "get_monthly_ranks_for_scene", "func_src_before": "def get_monthly_ranks_for_scene(db, scene, tag):\n\n    sql = \"SELECT date, rank FROM ranks WHERE scene='{}' AND player='{}'\".format(scene, tag)\n    res = db.exec(sql)\n\n    res = [r for r in res if played_during_month(db, scene, tag, get_previous_month(r[0]))]\n\n    # Build up a dict of {date: rank}\n    ranks = {}\n    for r in res:\n        ranks[r[0]] = r[1]\n\n    return ranks", "func_src_after": "def get_monthly_ranks_for_scene(db, scene, tag):\n\n    sql = \"SELECT date, rank FROM ranks WHERE scene='{scene}' AND player='{tag}'\"\n    args = {'scene': scene, 'tag': tag}\n    res = db.exec(sql, args)\n\n    res = [r for r in res if played_during_month(db, scene, tag, get_previous_month(r[0]))]\n\n    # Build up a dict of {date: rank}\n    ranks = {}\n    for r in res:\n        ranks[r[0]] = r[1]\n\n    return ranks", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve a dictionary of dates and ranks for a specific scene and player from a database, ensuring the player was active in the previous month."}
{"func_name": "SMB2_write", "func_src_before": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "func_src_after": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tcifs_small_buf_release(req);\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/6a3eb3360667170988f8a6477f6686242061488a", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "In C, write a function to perform an SMB2 write operation with error handling and encryption check."}
{"func_name": "mapi_attr_read", "func_src_before": "mapi_attr_read (size_t len, unsigned char *buf)\n{\n    size_t idx = 0;\n    uint32 i,j;\n    assert(len > 4);\n    uint32 num_properties = GETINT32(buf+idx);\n    MAPI_Attr** attrs = CHECKED_XMALLOC (MAPI_Attr*, (num_properties + 1));\n\n    idx += 4;\n\n    if (!attrs) return NULL;\n    for (i = 0; i < num_properties; i++)\n    {\n\tMAPI_Attr* a = attrs[i] = CHECKED_XCALLOC(MAPI_Attr, 1);\n\tMAPI_Value* v = NULL;\n\n\tCHECKINT16(idx, len); a->type = GETINT16(buf+idx); idx += 2;\n\tCHECKINT16(idx, len); a->name = GETINT16(buf+idx); idx += 2;\n\n\t/* handle special case of GUID prefixed properties */\n\tif (a->name & GUID_EXISTS_FLAG)\n\t{\n\t    /* copy GUID */\n\t    a->guid = CHECKED_XMALLOC(GUID, 1);\n\t    copy_guid_from_buf(a->guid, buf+idx, len);\n\t    idx += sizeof (GUID);\n\n\t    CHECKINT32(idx, len); a->num_names = GETINT32(buf+idx); idx += 4;\n\t    if (a->num_names > 0)\n\t    {\n\t\t/* FIXME: do something useful here! */\n\t\tsize_t i;\n\n\t\ta->names = CHECKED_XCALLOC(VarLenData, a->num_names);\n\n\t\tfor (i = 0; i < a->num_names; i++)\n\t\t{\n\t\t    size_t j;\n\n\t\t    CHECKINT32(idx, len); a->names[i].len = GETINT32(buf+idx); idx += 4;\n\n\t\t    /* read the data into a buffer */\n\t\t    a->names[i].data \n\t\t\t= CHECKED_XMALLOC(unsigned char, a->names[i].len);\n\t\t    for (j = 0; j < (a->names[i].len >> 1); j++)\n\t\t\ta->names[i].data[j] = (buf+idx)[j*2];\n\n\t\t    /* But what are we going to do with it? */\n\t\t    \n\t\t    idx += pad_to_4byte(a->names[i].len);\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t/* get the 'real' name */\n\t\tCHECKINT32(idx, len); a->name = GETINT32(buf+idx); idx+= 4;\n\t    }\n\t}\n\n\t/* \n\t * Multi-value types and string/object/binary types have\n\t * multiple values \n\t */\n\tif (a->type & MULTI_VALUE_FLAG ||\n\t    a->type == szMAPI_STRING ||\n\t    a->type == szMAPI_UNICODE_STRING ||\n\t    a->type == szMAPI_OBJECT ||\n\t    a->type == szMAPI_BINARY)\n\t{\n\t    CHECKINT32(idx, len); a->num_values = GETINT32(buf+idx);\n\t    idx += 4;\n\t}\n        else\n        {\n\t    a->num_values = 1;\n        }\n\n\t/* Amend the type in case of multi-value type */\n\tif (a->type & MULTI_VALUE_FLAG)\n\t{\n\t    a->type -= MULTI_VALUE_FLAG;\n\t}\n\n\n\tv = alloc_mapi_values (a);\n\n\tfor (j = 0; j < a->num_values; j++) \n\t{\n\t    switch (a->type)\n\t    {\n\t    case szMAPI_SHORT:\t/* 2 bytes */\n\t\tv->len = 2;\n\t\tCHECKINT16(idx, len); v->data.bytes2 = GETINT16(buf+idx);\n\t\tidx += 4;\t/* assume padding of 2, advance by 4! */\n\t\tbreak;\n\n\t    case szMAPI_INT:\t/* 4 bytes */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += 4;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_FLOAT:\t/* 4 bytes */\n\t    case szMAPI_BOOLEAN: /* this should be 2 bytes + 2 padding */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_SYSTIME: /* 8 bytes */\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += 8;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_DOUBLE:\t/* 8 bytes */\n\t    case szMAPI_APPTIME:\n\t    case szMAPI_CURRENCY:\n\t    case szMAPI_INT8BYTE:\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_CLSID:\n\t\tv->len = sizeof (GUID);\n\t\tcopy_guid_from_buf(&v->data.guid, buf+idx, len);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_STRING:\n\t    case szMAPI_UNICODE_STRING:\n\t    case szMAPI_OBJECT:\n\t    case szMAPI_BINARY:\n\t\tCHECKINT32(idx, len); v->len = GETINT32(buf+idx); idx += 4;\n\n\t\tif (a->type == szMAPI_UNICODE_STRING)\n\t\t{\n\t\t    v->data.buf = (unsigned char*)unicode_to_utf8(v->len, buf+idx);\n\t\t}\n\t\telse\n\t\t{\n\t\t    v->data.buf = CHECKED_XMALLOC(unsigned char, v->len);\n\t\t    memmove (v->data.buf, buf+idx, v->len);\n\t\t}\n\n\t\tidx += pad_to_4byte(v->len);\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_NULL:\t/* illegal in input tnef streams */\n\t    case szMAPI_ERROR:\n\t    case szMAPI_UNSPECIFIED:\n\t\tfprintf (stderr,\n\t\t\t \"Invalid attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    default:\t\t/* should never get here */\n\t\tfprintf (stderr,\n\t\t\t \"Undefined attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    }\n\t    if (DEBUG_ON) mapi_attr_dump (attrs[i]);\n\t}\n    }\n    attrs[i] = NULL;\n\n    return attrs;\n}", "func_src_after": "mapi_attr_read (size_t len, unsigned char *buf)\n{\n    size_t idx = 0;\n    uint32 i,j;\n    assert(len > 4);\n    uint32 num_properties = GETINT32(buf+idx);\n    assert((num_properties+1) != 0);\n    MAPI_Attr** attrs = CHECKED_XMALLOC (MAPI_Attr*, (num_properties + 1));\n\n    idx += 4;\n\n    if (!attrs) return NULL;\n    for (i = 0; i < num_properties; i++)\n    {\n\tMAPI_Attr* a = attrs[i] = CHECKED_XCALLOC(MAPI_Attr, 1);\n\tMAPI_Value* v = NULL;\n\n\tCHECKINT16(idx, len); a->type = GETINT16(buf+idx); idx += 2;\n\tCHECKINT16(idx, len); a->name = GETINT16(buf+idx); idx += 2;\n\n\t/* handle special case of GUID prefixed properties */\n\tif (a->name & GUID_EXISTS_FLAG)\n\t{\n\t    /* copy GUID */\n\t    a->guid = CHECKED_XMALLOC(GUID, 1);\n\t    copy_guid_from_buf(a->guid, buf+idx, len);\n\t    idx += sizeof (GUID);\n\n\t    CHECKINT32(idx, len); a->num_names = GETINT32(buf+idx); idx += 4;\n\t    if (a->num_names > 0)\n\t    {\n\t\t/* FIXME: do something useful here! */\n\t\tsize_t i;\n\n\t\ta->names = CHECKED_XCALLOC(VarLenData, a->num_names);\n\n\t\tfor (i = 0; i < a->num_names; i++)\n\t\t{\n\t\t    size_t j;\n\n\t\t    CHECKINT32(idx, len); a->names[i].len = GETINT32(buf+idx); idx += 4;\n\n\t\t    /* read the data into a buffer */\n\t\t    a->names[i].data \n\t\t\t= CHECKED_XMALLOC(unsigned char, a->names[i].len);\n\t\t    assert((idx+(a->names[i].len*2)) <= len);\n\t\t    for (j = 0; j < (a->names[i].len >> 1); j++)\n\t\t\ta->names[i].data[j] = (buf+idx)[j*2];\n\n\t\t    /* But what are we going to do with it? */\n\t\t    \n\t\t    idx += pad_to_4byte(a->names[i].len);\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t/* get the 'real' name */\n\t\tCHECKINT32(idx, len); a->name = GETINT32(buf+idx); idx+= 4;\n\t    }\n\t}\n\n\t/* \n\t * Multi-value types and string/object/binary types have\n\t * multiple values \n\t */\n\tif (a->type & MULTI_VALUE_FLAG ||\n\t    a->type == szMAPI_STRING ||\n\t    a->type == szMAPI_UNICODE_STRING ||\n\t    a->type == szMAPI_OBJECT ||\n\t    a->type == szMAPI_BINARY)\n\t{\n\t    CHECKINT32(idx, len); a->num_values = GETINT32(buf+idx);\n\t    idx += 4;\n\t}\n        else\n        {\n\t    a->num_values = 1;\n        }\n\n\t/* Amend the type in case of multi-value type */\n\tif (a->type & MULTI_VALUE_FLAG)\n\t{\n\t    a->type -= MULTI_VALUE_FLAG;\n\t}\n\n\n\tv = alloc_mapi_values (a);\n\n\tfor (j = 0; j < a->num_values; j++) \n\t{\n\t    switch (a->type)\n\t    {\n\t    case szMAPI_SHORT:\t/* 2 bytes */\n\t\tv->len = 2;\n\t\tCHECKINT16(idx, len); v->data.bytes2 = GETINT16(buf+idx);\n\t\tidx += 4;\t/* assume padding of 2, advance by 4! */\n\t\tbreak;\n\n\t    case szMAPI_INT:\t/* 4 bytes */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += 4;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_FLOAT:\t/* 4 bytes */\n\t    case szMAPI_BOOLEAN: /* this should be 2 bytes + 2 padding */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_SYSTIME: /* 8 bytes */\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += 8;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_DOUBLE:\t/* 8 bytes */\n\t    case szMAPI_APPTIME:\n\t    case szMAPI_CURRENCY:\n\t    case szMAPI_INT8BYTE:\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_CLSID:\n\t\tv->len = sizeof (GUID);\n\t\tcopy_guid_from_buf(&v->data.guid, buf+idx, len);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_STRING:\n\t    case szMAPI_UNICODE_STRING:\n\t    case szMAPI_OBJECT:\n\t    case szMAPI_BINARY:\n\t\tCHECKINT32(idx, len); v->len = GETINT32(buf+idx); idx += 4;\n\n\t\tassert(v->len + idx <= len);\n\n\t\tif (a->type == szMAPI_UNICODE_STRING)\n\t\t{\n\t\t    assert(v->len != 0);\n\t\t    v->data.buf = (unsigned char*)unicode_to_utf8(v->len, buf+idx);\n\t\t}\n\t\telse\n\t\t{\n\t\t    v->data.buf = CHECKED_XMALLOC(unsigned char, v->len);\n\t\t    memmove (v->data.buf, buf+idx, v->len);\n\t\t}\n\n\t\tidx += pad_to_4byte(v->len);\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_NULL:\t/* illegal in input tnef streams */\n\t    case szMAPI_ERROR:\n\t    case szMAPI_UNSPECIFIED:\n\t\tfprintf (stderr,\n\t\t\t \"Invalid attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    default:\t\t/* should never get here */\n\t\tfprintf (stderr,\n\t\t\t \"Undefined attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    }\n\t    if (DEBUG_ON) mapi_attr_dump (attrs[i]);\n\t}\n    }\n    attrs[i] = NULL;\n\n    return attrs;\n}", "commit_link": "github.com/verdammelt/tnef/commit/1a17af1ed0c791aec44dbdc9eab91218cc1e335a", "file_name": "src/mapi_attr.c", "vul_type": "cwe-787", "description": "Write a C function named `mapi_attr_read` that parses MAPI attributes from a buffer."}
{"func_name": "TestCreateBasket_InvalidName", "func_src_before": "func TestCreateBasket_InvalidName(t *testing.T) {\n\tbasket := \">>>\"\n\n\tr, err := http.NewRequest(\"POST\", \"http://localhost:55555/api/baskets/\"+basket, strings.NewReader(\"\"))\n\tif assert.NoError(t, err) {\n\t\tw := httptest.NewRecorder()\n\t\tps := append(make(httprouter.Params, 0), httprouter.Param{Key: \"basket\", Value: basket})\n\t\tCreateBasket(w, r, ps)\n\n\t\t// validate response: 400 - Bad Request\n\t\tassert.Equal(t, 400, w.Code, \"wrong HTTP result code\")\n\t\tassert.Equal(t, \"invalid basket name; [\"+basket+\"] does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n\t\t\t\"wrong error message\")\n\t\t// validate database\n\t\tassert.Nil(t, basketsDb.Get(basket), \"basket '%v' should not be created\", basket)\n\t}\n}", "func_src_after": "func TestCreateBasket_InvalidName(t *testing.T) {\n\tbasket := \">>>\"\n\n\tr, err := http.NewRequest(\"POST\", \"http://localhost:55555/api/baskets/\"+basket, strings.NewReader(\"\"))\n\tif assert.NoError(t, err) {\n\t\tw := httptest.NewRecorder()\n\t\tps := append(make(httprouter.Params, 0), httprouter.Param{Key: \"basket\", Value: basket})\n\t\tCreateBasket(w, r, ps)\n\n\t\t// validate response: 400 - Bad Request\n\t\tassert.Equal(t, 400, w.Code, \"wrong HTTP result code\")\n\t\tassert.Equal(t, \"invalid basket name; the name does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n\t\t\t\"wrong error message\")\n\t\t// validate database\n\t\tassert.Nil(t, basketsDb.Get(basket), \"basket '%v' should not be created\", basket)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 12, "char_start": 447, "char_end": 574, "line": "\t\tassert.Equal(t, \"invalid basket name; [\"+basket+\"] does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n"}], "added": [{"line_no": 12, "char_start": 447, "char_end": 570, "line": "\t\tassert.Equal(t, \"invalid basket name; the name does not match pattern: \"+validBasketName.String()+\"\\n\", w.Body.String(),\n"}]}, "char_changes": {"deleted": [{"char_start": 487, "char_end": 499, "chars": "[\"+basket+\"]"}], "added": [{"char_start": 487, "char_end": 495, "chars": "the name"}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers_test.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go test function to validate that creating a basket with an invalid name results in a bad request and no database entry."}
{"func_name": "save", "func_src_before": "    def save(output, *options)\n      output.respond_to?(:write) or\n        return open(output, 'w') { |io| save(io, *options) }\n\n      opthash = {\n        :format => :yaml,\n        :session => false,\n      }\n      case options.size\n      when 0\n      when 1\n        case options = options.first\n        when Symbol\n          opthash[:format] = options\n        else\n          opthash.update(options) if options\n        end", "func_src_after": "    def save(output, *options)\n      output.respond_to?(:write) or\n        return ::File.open(output, 'w') { |io| save(io, *options) }\n\n      opthash = {\n        :format => :yaml,\n        :session => false,\n      }\n      case options.size\n      when 0\n      when 1\n        case options = options.first\n        when Symbol\n          opthash[:format] = options\n        else\n          opthash.update(options) if options\n        end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 67, "char_end": 128, "line": "        return open(output, 'w') { |io| save(io, *options) }\n"}], "added": [{"line_no": 3, "char_start": 67, "char_end": 135, "line": "        return ::File.open(output, 'w') { |io| save(io, *options) }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 82, "char_end": 89, "chars": "::File."}]}, "commit_link": "github.com/sparklemotion/mechanize/commit/aae0b13514a1a0caf93b1cf233733c50e679069a", "file_name": "cookie_jar.rb", "vul_type": "cwe-078", "commit_msg": "fix(security): prevent command injection in CookieJar\n\nRelated to https://github.com/sparklemotion/mechanize/security/advisories/GHSA-qrqm-fpv6-6r8g", "description": "Write a Ruby method named `save` that takes an output destination and an optional set of parameters to configure the save process."}
{"func_name": "get_asset_and_volume", "func_src_before": "@app.route('/get_asset_and_volume')\ndef get_asset_and_volume():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n    #print asset_id\n    ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"get_assets\",[[\"' + asset_id + '\"], 0]]}')\n    result = ws.recv()\n    j = json.loads(result)\n\n    dynamic_asset_data_id =  j[\"result\"][0][\"dynamic_asset_data_id\"]\n\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+dynamic_asset_data_id+'\"]]]}')\n    result2 = ws.recv()\n    j2 = json.loads(result2)\n    #print j2[\"result\"][0][\"current_supply\"]\n\n    j[\"result\"][0][\"current_supply\"] = j2[\"result\"][0][\"current_supply\"]\n    j[\"result\"][0][\"confidential_supply\"] = j2[\"result\"][0][\"confidential_supply\"]\n    #print j[\"result\"]\n\n    j[\"result\"][0][\"accumulated_fees\"] = j2[\"result\"][0][\"accumulated_fees\"]\n    j[\"result\"][0][\"fee_pool\"] = j2[\"result\"][0][\"fee_pool\"]\n\n    issuer = j[\"result\"][0][\"issuer\"]\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+issuer+'\"]]]}')\n    result3 = ws.recv()\n    j3 = json.loads(result3)\n    j[\"result\"][0][\"issuer_name\"] = j3[\"result\"][0][\"name\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT volume, mcap FROM assets WHERE aid='\"+asset_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    try:\n        j[\"result\"][0][\"volume\"] = results[0][0]\n        j[\"result\"][0][\"mcap\"] = results[0][1]\n    except:\n        j[\"result\"][0][\"volume\"] = 0\n        j[\"result\"][0][\"mcap\"] = 0\n\n    return jsonify(j[\"result\"])", "func_src_after": "@app.route('/get_asset_and_volume')\ndef get_asset_and_volume():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n    #print asset_id\n    ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"get_assets\",[[\"' + asset_id + '\"], 0]]}')\n    result = ws.recv()\n    j = json.loads(result)\n\n    dynamic_asset_data_id =  j[\"result\"][0][\"dynamic_asset_data_id\"]\n\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+dynamic_asset_data_id+'\"]]]}')\n    result2 = ws.recv()\n    j2 = json.loads(result2)\n    #print j2[\"result\"][0][\"current_supply\"]\n\n    j[\"result\"][0][\"current_supply\"] = j2[\"result\"][0][\"current_supply\"]\n    j[\"result\"][0][\"confidential_supply\"] = j2[\"result\"][0][\"confidential_supply\"]\n    #print j[\"result\"]\n\n    j[\"result\"][0][\"accumulated_fees\"] = j2[\"result\"][0][\"accumulated_fees\"]\n    j[\"result\"][0][\"fee_pool\"] = j2[\"result\"][0][\"fee_pool\"]\n\n    issuer = j[\"result\"][0][\"issuer\"]\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+issuer+'\"]]]}')\n    result3 = ws.recv()\n    j3 = json.loads(result3)\n    j[\"result\"][0][\"issuer_name\"] = j3[\"result\"][0][\"name\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT volume, mcap FROM assets WHERE aid=%s\"\n    cur.execute(query, (asset_id,))\n    results = cur.fetchall()\n    con.close()\n    try:\n        j[\"result\"][0][\"volume\"] = results[0][0]\n        j[\"result\"][0][\"mcap\"] = results[0][1]\n    except:\n        j[\"result\"][0][\"volume\"] = 0\n        j[\"result\"][0][\"mcap\"] = 0\n\n    return jsonify(j[\"result\"])", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "In Python, create a Flask endpoint '/get_asset_and_volume' that retrieves and combines asset details from a WebSocket connection and volume data from a PostgreSQL database."}
{"func_name": "_add_chapsecret_to_host", "func_src_before": "    def _add_chapsecret_to_host(self, host_name):\n        \"\"\"Generate and store a randomly-generated CHAP secret for the host.\"\"\"\n\n        chap_secret = utils.generate_password()\n        ssh_cmd = ('svctask chhost -chapsecret \"%(chap_secret)s\" %(host_name)s'\n                   % {'chap_secret': chap_secret, 'host_name': host_name})\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from chhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_add_chapsecret_to_host', ssh_cmd, out, err)\n        return chap_secret", "func_src_after": "    def _add_chapsecret_to_host(self, host_name):\n        \"\"\"Generate and store a randomly-generated CHAP secret for the host.\"\"\"\n\n        chap_secret = utils.generate_password()\n        ssh_cmd = ['svctask', 'chhost', '-chapsecret', chap_secret, host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from chhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_add_chapsecret_to_host', ssh_cmd, out, err)\n        return chap_secret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to generate a CHAP secret and execute an SSH command to apply it to a host."}
{"func_name": "extend_volume", "func_src_before": "    def extend_volume(self, volume, new_size):\n        LOG.debug(_('enter: extend_volume: volume %s') % volume['id'])\n        ret = self._ensure_vdisk_no_fc_mappings(volume['name'],\n                                                allow_snaps=False)\n        if not ret:\n            exception_message = (_('extend_volume: Extending a volume with '\n                                   'snapshots is not supported.'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        extend_amt = int(new_size) - volume['size']\n        ssh_cmd = ('svctask expandvdisksize -size %(amt)d -unit gb %(name)s'\n                   % {'amt': extend_amt, 'name': volume['name']})\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from expandvdisksize\n        self._assert_ssh_return(len(out.strip()) == 0, 'extend_volume',\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: extend_volume: volume %s') % volume['id'])", "func_src_after": "    def extend_volume(self, volume, new_size):\n        LOG.debug(_('enter: extend_volume: volume %s') % volume['id'])\n        ret = self._ensure_vdisk_no_fc_mappings(volume['name'],\n                                                allow_snaps=False)\n        if not ret:\n            exception_message = (_('extend_volume: Extending a volume with '\n                                   'snapshots is not supported.'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        extend_amt = int(new_size) - volume['size']\n        ssh_cmd = (['svctask', 'expandvdisksize', '-size', str(extend_amt),\n                    '-unit', 'gb', volume['name']])\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from expandvdisksize\n        self._assert_ssh_return(len(out.strip()) == 0, 'extend_volume',\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: extend_volume: volume %s') % volume['id'])", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to increase the size of a storage volume using SSH commands, ensuring no snapshots exist."}
{"func_name": "save", "func_src_before": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        self.description = self.description_plain_text\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "func_src_after": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        # uses bleach to remove potentially harmful HTML code\n        self.description = bleach.clean(str(self.description_plain_text),\n                                        tags=CE.settings.bleach_allowed,\n                                        strip=True)\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "commit_link": "github.com/stevetasticsteve/CLA_Hub/commit/a06d85cd0b0964f8469e5c4bc9a6c132aa0b4c37", "file_name": "CE/models.py", "vul_type": "cwe-079", "description": "Write a Python method named `save` that sanitizes user input, handles cross-referencing or tagging, generates a slug from the title, and then calls the superclass's save method."}
{"func_name": "AP4_HdlrAtom::AP4_HdlrAtom", "func_src_before": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    int name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    if (name_size == 0) return;\n    char* name = new char[name_size+1];\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "func_src_after": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    if (size < AP4_FULL_ATOM_HEADER_SIZE+20) return;\n    AP4_UI32 name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    char* name = new char[name_size+1];\n    if (name == NULL) return;\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/22192de5367fa0cee985917f092be4060b7c00b0", "file_name": "Source/C++/Core/Ap4HdlrAtom.cpp", "vul_type": "cwe-476", "description": "Write a C++ constructor for the `AP4_HdlrAtom` class that initializes an atom and reads its handler type and name from a byte stream."}
{"func_name": "store_metadata", "func_src_before": "    def store_metadata(self, session, key, mType, value):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"UPDATE %s SET %s = %r WHERE identifier = '%s';\" %\n                 (self.table, mType, value, id)\n                 )\n        try:\n            self._query(query)\n        except:\n            return None\n        return value", "func_src_after": "    def store_metadata(self, session, key, mType, value):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"UPDATE %s SET %s = $1 WHERE identifier = $2;\" %\n                 (self.table, mType)\n                 )\n        args = (value, id)\n        try:\n            self._query(query, *args)\n        except:\n            return None\n        return value", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089", "description": "Write a Python function to update a database record's metadata field identified by a key, handling string normalization and query execution."}
{"func_name": "usage", "func_src_before": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd = cmd + ' -' + args\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "func_src_after": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    flags = ''\n    allowed = ('a', 'B', 'h', 'H', 'i', 'k', 'l', 'P', 't', 'T', 'x', 'v')\n    for flag in args:\n        if flag in allowed:\n            flags += flag\n        else:\n            break\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd += ' -{0}'.format(flags)\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "commit_link": "github.com/saltstack/salt/commit/ebdef37b7e5d2b95a01d34b211c61c61da67e46a", "file_name": "salt/modules/disk.py", "vul_type": "cwe-078", "description": "Write a Python function named `usage` that returns disk usage information for mounted volumes, with optional arguments for additional flags."}
{"func_name": "AcceptBasketRequests", "func_src_before": "func AcceptBasketRequests(w http.ResponseWriter, r *http.Request) {\n\tname := strings.Split(r.URL.Path, \"/\")[1]\n\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\trequest := basket.Add(r)\n\n\t\t// forward request if configured and it's a first forwarding\n\t\tconfig := basket.Config()\n\t\tif len(config.ForwardURL) > 0 && r.Header.Get(DoNotForwardHeader) != \"1\" {\n\t\t\tif config.ProxyResponse {\n\t\t\t\tforwardAndProxyResponse(w, request, config, name)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tgo forwardAndForget(request, config, name)\n\t\t}\n\n\t\twriteBasketResponse(w, r, name, basket)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n}", "func_src_after": "func AcceptBasketRequests(w http.ResponseWriter, r *http.Request) {\n\tname := strings.Split(r.URL.Path, \"/\")[1]\n\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\trequest := basket.Add(r)\n\n\t\t// forward request if configured and it's a first forwarding\n\t\tconfig := basket.Config()\n\t\tif len(config.ForwardURL) > 0 && r.Header.Get(DoNotForwardHeader) != \"1\" {\n\t\t\tif config.ProxyResponse {\n\t\t\t\tforwardAndProxyResponse(w, request, config, name)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tgo forwardAndForget(request, config, name)\n\t\t}\n\n\t\twriteBasketResponse(w, r, name, basket)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 153, "char_end": 277, "line": "\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}], "added": [{"line_no": 5, "char_start": 153, "char_end": 275, "line": "\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}]}, "char_changes": {"deleted": [{"char_start": 191, "char_end": 194, "chars": "[\"+"}, {"char_start": 198, "char_end": 201, "chars": "+\"]"}], "added": [{"char_start": 191, "char_end": 195, "chars": "the "}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go function to handle HTTP requests for a basket service, validating names and optionally forwarding requests."}
{"func_name": "add_language", "func_src_before": "    def add_language(self, language):\n        \"\"\"\"Add new language for item translations.\"\"\"\n        if self.connection:\n            self.cursor.execute('insert into itemlanguage (language) values (\"%s\")' % language[0])\n            self.connection.commit()", "func_src_after": "    def add_language(self, language):\n        \"\"\"\"Add new language for item translations.\"\"\"\n        if self.connection:\n            t = (language[0], )\n            self.cursor.execute('insert into itemlanguage (language) values (?)', t)\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new language into a database table for item translations, using parameter substitution."}
{"func_name": "insertUsage", "func_src_before": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES ('\"+date+\"','\"+str(user)+\"','\"+command+\"')\")\n\tconn.commit()\n\tconn.close()", "func_src_after": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES (?,?,?)\",(date,str(user),command))\n\tconn.commit()\n\tconn.close()", "commit_link": "github.com/DangerBlack/DungeonsAndDragonsMasterBot/commit/63f980c6dff746f5fcf3005d0646b6c24f81cdc0", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a user's command usage into a database with the current date."}
{"func_name": "pref_get", "func_src_before": "@app.route(\"/api/preferences/get/<key>\")\ndef pref_get(key):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    if key in get_preferences():\n        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n    else:\n        return Response(json.dumps({'key': key, 'error': 'novalue'}))", "func_src_after": "@app.route(\"/api/preferences/get/<key>\")\ndef pref_get(key):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    if key in get_preferences():\n        return Response(\n            json.dumps({'key': key, 'value': get_preferences()[key]}),\n            mimetype='application/json'\n        )\n    else:\n        return Response(\n            json.dumps({'key': key, 'error': 'novalue'}),\n            mimetype='application/json'\n        )", "line_changes": {"deleted": [{"line_no": 7, "char_start": 167, "char_end": 250, "line": "        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n"}, {"line_no": 9, "char_start": 260, "char_end": 329, "line": "        return Response(json.dumps({'key': key, 'error': 'novalue'}))\n"}], "added": [{"line_no": 7, "char_start": 167, "char_end": 192, "line": "        return Response(\n"}, {"line_no": 8, "char_start": 192, "char_end": 263, "line": "            json.dumps({'key': key, 'value': get_preferences()[key]}),\n"}, {"line_no": 9, "char_start": 263, "char_end": 303, "line": "            mimetype='application/json'\n"}, {"line_no": 10, "char_start": 303, "char_end": 313, "line": "        )\n"}, {"line_no": 12, "char_start": 323, "char_end": 348, "line": "        return Response(\n"}, {"line_no": 13, "char_start": 348, "char_end": 406, "line": "            json.dumps({'key': key, 'error': 'novalue'}),\n"}, {"line_no": 14, "char_start": 406, "char_end": 446, "line": "            mimetype='application/json'\n"}, {"line_no": 15, "char_start": 446, "char_end": 455, "line": "        )\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 191, "char_end": 204, "chars": "\n            "}, {"char_start": 261, "char_end": 311, "chars": ",\n            mimetype='application/json'\n        "}, {"char_start": 347, "char_end": 360, "chars": "\n            "}, {"char_start": 404, "char_end": 454, "chars": ",\n            mimetype='application/json'\n        "}]}, "commit_link": "github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "file_name": "app.py", "vul_type": "cwe-079", "commit_msg": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "description": "Create a Python Flask endpoint to retrieve a user's preference by key, returning JSON responses and requiring user authentication."}
{"func_name": "updateOption", "func_src_before": "\tfunction updateOption (that) {\n\t\ttry {\n\t\t\tvar thisId = jQuery('#fb-field-id').val();\n\t\t\tvar thisOptionid = that.attr('optionid');\n\t\t\tvar thisOptionValue = that.val();\n\t\t\tvar thisType = jQuery('#fb-new-type').val();\n\t\t\t// Update preview\n\t\t\tif (thisType === \"radio\") {\n\t\t\t\tjQuery('#fb-radio-' + thisId + '-' + thisOptionid + ' span').html(thisOptionValue);\n\t\t\t} else {\n\t\t\t\tjQuery('#fb-' + thisId + '-' + thisOptionid).text(thisOptionValue);\n\t\t\t}\n\t\t\t// Update fbForm object\n\t\t\tfbForm.fields[thisId].options[thisOptionid] = thisOptionValue;\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"updateOption(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tfunction updateOption (that) {\n\t\ttry {\n\t\t\tvar thisId = jQuery('#fb-field-id').val();\n\t\t\tvar thisOptionid = that.attr('optionid');\n\t\t\tvar thisOptionValue = that.val();\n\t\t\tvar thisType = jQuery('#fb-new-type').val();\n\t\t\t// Update preview\n\t\t\tif (thisType === \"radio\") {\n\t\t\t\tjQuery('#fb-radio-' + thisId + '-' + thisOptionid + ' span').text(thisOptionValue);\n\t\t\t} else {\n\t\t\t\tjQuery('#fb-' + thisId + '-' + thisOptionid).text(thisOptionValue);\n\t\t\t}\n\t\t\t// Update fbForm object\n\t\t\tfbForm.fields[thisId].options[thisOptionid] = thisOptionValue;\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"updateOption(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 268, "char_end": 356, "line": "\t\t\t\tjQuery('#fb-radio-' + thisId + '-' + thisOptionid + ' span').html(thisOptionValue);\n"}], "added": [{"line_no": 9, "char_start": 268, "char_end": 356, "line": "\t\t\t\tjQuery('#fb-radio-' + thisId + '-' + thisOptionid + ' span').text(thisOptionValue);\n"}]}, "char_changes": {"deleted": [{"char_start": 333, "char_end": 337, "chars": "html"}], "added": [{"char_start": 333, "char_end": 337, "chars": "text"}]}, "commit_link": "github.com/iamtakashi/jetpack/commit/970117f93e7ed6eb459ee568259947d67369eec0", "file_name": "grunion.js", "vul_type": "cwe-079", "commit_msg": "Grunion: Fix 2 XSS vulnerabilities.\nPreview of field labels.\nPreview of radio option labels.\nAlso:\nPrevent future potential XSS in feedback message.\nFix i18n\nFix encoding of field labels bug (every preview would add another level of HTML encoding to the label)\nprops @mdawaffe", "description": "Write a JavaScript function using jQuery to update form option values and preview text based on the type of input field."}
{"func_name": "edit", "func_src_before": "  def edit\n    # give an error message is instructor have not set the time zone.\n    if current_user.timezonepref.nil?\n      flash.now[:error] = \"You have not specified your preferred timezone yet. Please do this before you set up the deadlines.\"\n    end\n    @topics = SignUpTopic.find_by_sql(\"select * from sign_up_topics where assignment_id=\" + params[:id])\n    @assignment_form = AssignmentForm.create_form_object(params[:id])\n    @user = current_user\n\n    @assignment_questionnaires = AssignmentQuestionnaire.where(assignment_id: params[:id])\n    @due_date_all = DueDate.where(assignment_id: params[:id])\n    @reviewvarycheck = false\n    @due_date_nameurl_notempty = false\n    @due_date_nameurl_notempty_checkbox = false\n    @metareview_allowed = false\n    @metareview_allowed_checkbox = false\n    @signup_allowed = false\n    @signup_allowed_checkbox = false\n    @drop_topic_allowed = false\n    @drop_topic_allowed_checkbox = false\n    @team_formation_allowed = false\n    @team_formation_allowed_checkbox = false\n    @participants_count = @assignment_form.assignment.participants.size\n    @teams_count = @assignment_form.assignment.teams.size\n\n    # Check if name and url in database is empty before webpage displays\n    @due_date_all.each do |dd|\n      @due_date_nameurl_notempty = is_due_date_nameurl_notempty(dd)\n      @due_date_nameurl_notempty_checkbox = @due_date_nameurl_notempty\n      @metareview_allowed = is_meta_review_allowed?(dd)\n      @drop_topic_allowed = is_drop_topic_allowed?(dd)\n      @signup_allowed = is_signup_allowed?(dd)\n      @team_formation_allowed = is_team_formation_allowed?(dd)\n\n      if dd.due_at.present?\n        dd.due_at = dd.due_at.to_s.in_time_zone(current_user.timezonepref)\n      end\n      if  @due_date_nameurl_notempty && @due_date_nameurl_notempty_checkbox &&\n          (@metareview_allowed || @drop_topic_allowed || @signup_allowed || @team_formation_allowed)\n        break\n      end\n    end\n\n    @assignment_questionnaires.each do |aq|\n      unless aq.used_in_round.nil?\n        @reviewvarycheck = 1\n        break\n      end\n    end\n    @due_date_all = update_nil_dd_deadline_name(@due_date_all)\n    @due_date_all = update_nil_dd_description_url(@due_date_all)\n\n    # only when instructor does not assign rubrics and in assignment edit page will show this error message.\n    if !empty_rubrics_list.empty? && request.original_fullpath == \"/assignments/#{@assignment_form.assignment.id}/edit\"\n      rubrics_needed = needed_rubrics(empty_rubrics_list)\n      flash.now[:error] = \"You did not specify all the necessary rubrics. You need \" + rubrics_needed +\n          \" of assignment <b>#{@assignment_form.assignment.name}</b> before saving the assignment. You can assign rubrics <a id='go_to_tabs2' style='color: blue;'>here</a>.\"\n    end\n\n    if @assignment_form.assignment.directory_path.nil? || @assignment_form.assignment.directory_path.empty?\n      flash.now[:error] = \"You did not specify your submission directory.\"\n    end\n  end", "func_src_after": "  def edit\n    # give an error message is instructor have not set the time zone.\n    if current_user.timezonepref.nil?\n      flash.now[:error] = \"You have not specified your preferred timezone yet. Please do this before you set up the deadlines.\"\n    end\n    @topics = SignUpTopic.where(assignment_id: params[:id])\n    @assignment_form = AssignmentForm.create_form_object(params[:id])\n    @user = current_user\n\n    @assignment_questionnaires = AssignmentQuestionnaire.where(assignment_id: params[:id])\n    @due_date_all = DueDate.where(assignment_id: params[:id])\n    @reviewvarycheck = false\n    @due_date_nameurl_notempty = false\n    @due_date_nameurl_notempty_checkbox = false\n    @metareview_allowed = false\n    @metareview_allowed_checkbox = false\n    @signup_allowed = false\n    @signup_allowed_checkbox = false\n    @drop_topic_allowed = false\n    @drop_topic_allowed_checkbox = false\n    @team_formation_allowed = false\n    @team_formation_allowed_checkbox = false\n    @participants_count = @assignment_form.assignment.participants.size\n    @teams_count = @assignment_form.assignment.teams.size\n\n    # Check if name and url in database is empty before webpage displays\n    @due_date_all.each do |dd|\n      @due_date_nameurl_notempty = is_due_date_nameurl_notempty(dd)\n      @due_date_nameurl_notempty_checkbox = @due_date_nameurl_notempty\n      @metareview_allowed = is_meta_review_allowed?(dd)\n      @drop_topic_allowed = is_drop_topic_allowed?(dd)\n      @signup_allowed = is_signup_allowed?(dd)\n      @team_formation_allowed = is_team_formation_allowed?(dd)\n\n      if dd.due_at.present?\n        dd.due_at = dd.due_at.to_s.in_time_zone(current_user.timezonepref)\n      end\n      if  @due_date_nameurl_notempty && @due_date_nameurl_notempty_checkbox &&\n          (@metareview_allowed || @drop_topic_allowed || @signup_allowed || @team_formation_allowed)\n        break\n      end\n    end\n\n    @assignment_questionnaires.each do |aq|\n      unless aq.used_in_round.nil?\n        @reviewvarycheck = 1\n        break\n      end\n    end\n    @due_date_all = update_nil_dd_deadline_name(@due_date_all)\n    @due_date_all = update_nil_dd_description_url(@due_date_all)\n\n    # only when instructor does not assign rubrics and in assignment edit page will show this error message.\n    if !empty_rubrics_list.empty? && request.original_fullpath == \"/assignments/#{@assignment_form.assignment.id}/edit\"\n      rubrics_needed = needed_rubrics(empty_rubrics_list)\n      flash.now[:error] = \"You did not specify all the necessary rubrics. You need \" + rubrics_needed +\n          \" of assignment <b>#{@assignment_form.assignment.name}</b> before saving the assignment. You can assign rubrics <a id='go_to_tabs2' style='color: blue;'>here</a>.\"\n    end\n\n    if @assignment_form.assignment.directory_path.nil? || @assignment_form.assignment.directory_path.empty?\n      flash.now[:error] = \"You did not specify your submission directory.\"\n    end\n  end", "line_changes": {"deleted": [{"line_no": 6, "char_start": 255, "char_end": 360, "line": "    @topics = SignUpTopic.find_by_sql(\"select * from sign_up_topics where assignment_id=\" + params[:id])\n"}], "added": [{"line_no": 6, "char_start": 255, "char_end": 315, "line": "    @topics = SignUpTopic.where(assignment_id: params[:id])\n"}]}, "char_changes": {"deleted": [{"char_start": 281, "char_end": 323, "chars": "find_by_sql(\"select * from sign_up_topics "}, {"char_start": 328, "char_end": 329, "chars": " "}, {"char_start": 342, "char_end": 346, "chars": "=\" +"}], "added": [{"char_start": 286, "char_end": 287, "chars": "("}, {"char_start": 300, "char_end": 301, "chars": ":"}]}, "commit_link": "github.com/urmilparikh95/expertiza/commit/fa775cc1b2cfb68902042db139bf24447f25c1eb", "file_name": "assignments_controller.rb", "vul_type": "cwe-089", "commit_msg": "Handle possible SQL injections.", "parent_commit": "e9772caf7b3e799914fd0dfca9be264cfbb5f7c7", "description": "Write a Ruby method to edit assignment details, checking for user timezone preferences and ensuring all necessary components like topics, questionnaires, and due dates are loaded and validated."}
{"func_name": "set_pre_prov_vars", "func_src_before": "  def set_pre_prov_vars\n    @layout = \"miq_request_vm\"\n    @edit = {}\n    @edit[:explorer] = @explorer\n    @edit[:vm_sortdir] ||= \"ASC\"\n    @edit[:vm_sortcol] ||= \"name\"\n    @edit[:prov_type] = \"VM Provision\"\n    @edit[:hide_deprecated_templates] = true if request.parameters[:controller] == \"vm_cloud\"\n\n    unless %w(image_miq_request_new miq_template_miq_request_new).include?(params[:pressed])\n      report_name = \"ProvisionTemplates.yaml\"\n      path_to_report = ManageIQ::UI::Classic::Engine.root.join(\"product\", \"views\", report_name).to_s\n      @view = MiqReport.new(YAML.load(File.open(path_to_report)))\n      @view.db = get_template_kls.to_s\n      report_scopes = %i(eligible_for_provisioning non_deprecated)\n      options = {\n        :model         => @view.db,\n        :gtl_type      => \"table\",\n        :named_scope   => report_scopes,\n        :report_name   => report_name,\n        :custom_action => {\n          :url  => \"/miq_request/pre_prov/?sel_id=\",\n          :type => 'provisioning'\n        }\n      }\n\n      @report_data_additional_options = ApplicationController::ReportDataAdditionalOptions.from_options(options)\n      @report_data_additional_options.with_no_checkboxes(true)\n\n      @edit[:template_kls] = get_template_kls\n    end\n    session[:changed] = false # Turn off the submit button\n    @edit[:explorer] = true if @explorer\n    @in_a_form = true\n  end", "func_src_after": "  def set_pre_prov_vars\n    @layout = \"miq_request_vm\"\n    @edit = {}\n    @edit[:explorer] = @explorer\n    @edit[:vm_sortdir] ||= \"ASC\"\n    @edit[:vm_sortcol] ||= \"name\"\n    @edit[:prov_type] = \"VM Provision\"\n    @edit[:hide_deprecated_templates] = true if request.parameters[:controller] == \"vm_cloud\"\n\n    unless %w(image_miq_request_new miq_template_miq_request_new).include?(params[:pressed])\n      report_name = \"ProvisionTemplates.yaml\"\n      path_to_report = ManageIQ::UI::Classic::Engine.root.join(\"product\", \"views\", report_name).to_s\n      @view = MiqReport.new(YAML.safe_load(File.open(path_to_report), [Symbol]))\n      @view.db = get_template_kls.to_s\n      report_scopes = %i(eligible_for_provisioning non_deprecated)\n      options = {\n        :model         => @view.db,\n        :gtl_type      => \"table\",\n        :named_scope   => report_scopes,\n        :report_name   => report_name,\n        :custom_action => {\n          :url  => \"/miq_request/pre_prov/?sel_id=\",\n          :type => 'provisioning'\n        }\n      }\n\n      @report_data_additional_options = ApplicationController::ReportDataAdditionalOptions.from_options(options)\n      @report_data_additional_options.with_no_checkboxes(true)\n\n      @edit[:template_kls] = get_template_kls\n    end\n    session[:changed] = false # Turn off the submit button\n    @edit[:explorer] = true if @explorer\n    @in_a_form = true\n  end", "line_changes": {"deleted": [{"line_no": 13, "char_start": 544, "char_end": 610, "line": "      @view = MiqReport.new(YAML.load(File.open(path_to_report)))\n"}], "added": [{"line_no": 13, "char_start": 544, "char_end": 625, "line": "      @view = MiqReport.new(YAML.safe_load(File.open(path_to_report), [Symbol]))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 577, "char_end": 582, "chars": "safe_"}, {"char_start": 612, "char_end": 622, "chars": ", [Symbol]"}]}, "commit_link": "github.com/ManageIQ/manageiq-ui-classic/commit/b199ca1d7b5049ee4c0bd8323ea3977bf3de3341", "file_name": "miq_request_methods.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load instead of YAML.load", "parent_commit": "cf54d8a126322759948bcf196e99a1a4399c62d0", "description": "Write a Ruby method named `set_pre_prov_vars` that initializes instance variables for VM provisioning settings and loads a YAML report configuration."}
{"func_name": "voutf", "func_src_before": "static void voutf(struct GlobalConfig *config,\n                  const char *prefix,\n                  const char *fmt,\n                  va_list ap)\n{\n  size_t width = (79 - strlen(prefix));\n  if(!config->mute) {\n    size_t len;\n    char *ptr;\n    char *print_buffer;\n\n    print_buffer = curlx_mvaprintf(fmt, ap);\n    if(!print_buffer)\n      return;\n    len = strlen(print_buffer);\n\n    ptr = print_buffer;\n    while(len > 0) {\n      fputs(prefix, config->errors);\n\n      if(len > width) {\n        size_t cut = width-1;\n\n        while(!ISSPACE(ptr[cut]) && cut) {\n          cut--;\n        }\n        if(0 == cut)\n          /* not a single cutting position was found, just cut it at the\n             max text width then! */\n          cut = width-1;\n\n        (void)fwrite(ptr, cut + 1, 1, config->errors);\n        fputs(\"\\n\", config->errors);\n        ptr += cut + 1; /* skip the space too */\n        len -= cut;\n      }\n      else {\n        fputs(ptr, config->errors);\n        len = 0;\n      }\n    }\n    curl_free(print_buffer);\n  }\n}", "func_src_after": "static void voutf(struct GlobalConfig *config,\n                  const char *prefix,\n                  const char *fmt,\n                  va_list ap)\n{\n  size_t width = (79 - strlen(prefix));\n  if(!config->mute) {\n    size_t len;\n    char *ptr;\n    char *print_buffer;\n\n    print_buffer = curlx_mvaprintf(fmt, ap);\n    if(!print_buffer)\n      return;\n    len = strlen(print_buffer);\n\n    ptr = print_buffer;\n    while(len > 0) {\n      fputs(prefix, config->errors);\n\n      if(len > width) {\n        size_t cut = width-1;\n\n        while(!ISSPACE(ptr[cut]) && cut) {\n          cut--;\n        }\n        if(0 == cut)\n          /* not a single cutting position was found, just cut it at the\n             max text width then! */\n          cut = width-1;\n\n        (void)fwrite(ptr, cut + 1, 1, config->errors);\n        fputs(\"\\n\", config->errors);\n        ptr += cut + 1; /* skip the space too */\n        len -= cut + 1;\n      }\n      else {\n        fputs(ptr, config->errors);\n        len = 0;\n      }\n    }\n    curl_free(print_buffer);\n  }\n}", "commit_link": "github.com/curl/curl/commit/d530e92f59ae9bb2d47066c3c460b25d2ffeb211", "file_name": "src/tool_msgs.c", "vul_type": "cwe-125", "description": "Write a C function named `voutf` that formats and outputs a string with a prefix to an error stream, wrapping lines to a maximum width."}
{"func_name": "patch", "func_src_before": "    @jwt_required\n    def patch(self, user_id):\n        \"\"\" Replaces information of corresponding user_id with request body \"\"\"\n        query = f\"\"\"update users set user_id = %s \"\"\"\n        query += f\"\"\"where user_id = '{user_id}'\"\"\"\n        json_data = request.get_json()\n        parameters = (json_data['user_id'], )\n        database_utilities.execute_query(query, parameters)", "func_src_after": "    @jwt_required\n    def patch(self, user_id):\n        \"\"\" Replaces information of corresponding user_id with request body \"\"\"\n        query = f\"\"\"update users set user_id = %s \"\"\"\n        query += f\"\"\"where user_id = %s\"\"\"\n        json_data = request.get_json()\n        parameters = (json_data['user_id'], user_id)\n        database_utilities.execute_query(query, parameters)", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's ID in the database using JWT authentication and the user's ID from the request body."}
{"func_name": "init", "func_src_before": "\tinit : function(settings) {\n\t\tvar theme, nl, baseHREF = \"\", i, cssPath, entities, h, p, src, elements = [], head;\n\n\t\t// IE 5.0x is no longer supported since 5.5, 6.0 and 7.0 now exists. We can't support old browsers forever, sorry.\n\t\tif (this.isMSIE5_0)\n\t\t\treturn;\n\n\t\tthis.settings = settings;\n\n\t\t// Check if valid browser has execcommand support\n\t\tif (typeof(document.execCommand) == 'undefined')\n\t\t\treturn;\n\n\t\t// Get script base path\n\t\tif (!tinyMCE.baseURL) {\n\t\t\t// Search through head\n\t\t\thead = document.getElementsByTagName('head')[0];\n\n\t\t\tif (head) {\n\t\t\t\tfor (i=0, nl = head.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\t\telements.push(nl[i]);\n\t\t\t}\n\n\t\t\t// Search through rest of document\n\t\t\tfor (i=0, nl = document.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\telements.push(nl[i]);\n\n\t\t\t// If base element found, add that infront of baseURL\n\t\t\tnl = document.getElementsByTagName('base');\n\t\t\tfor (i=0; i<nl.length; i++) {\n\t\t\t\tif (nl[i].href)\n\t\t\t\t\tbaseHREF = nl[i].href;\n\t\t\t}\n\n\t\t\tfor (i=0; i<elements.length; i++) {\n\t\t\t\tif (elements[i].src && (elements[i].src.indexOf(\"tiny_mce.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_dev.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_src.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_gzip\") != -1)) {\n\t\t\t\t\tsrc = elements[i].src;\n\n\t\t\t\t\ttinyMCE.srcMode = (src.indexOf('_src') != -1 || src.indexOf('_dev') != -1) ? '_src' : '';\n\t\t\t\t\ttinyMCE.gzipMode = src.indexOf('_gzip') != -1;\n\t\t\t\t\tsrc = src.substring(0, src.lastIndexOf('/'));\n\n\t\t\t\t\tif (settings.exec_mode == \"src\" || settings.exec_mode == \"normal\")\n\t\t\t\t\t\ttinyMCE.srcMode = settings.exec_mode == \"src\" ? '_src' : '';\n\n\t\t\t\t\t// Force it absolute if page has a base href\n\t\t\t\t\tif (baseHREF !== '' && src.indexOf('://') == -1)\n\t\t\t\t\t\ttinyMCE.baseURL = baseHREF + src;\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.baseURL = src;\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Get document base path\n\t\tthis.documentBasePath = escapePath(document.location.href);\n\t\tif (this.documentBasePath.indexOf('?') != -1)\n\t\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.indexOf('?'));\n\t\tthis.documentURL = this.documentBasePath;\n\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.lastIndexOf('/'));\n\n\t\t// If not HTTP absolute\n\t\tif (tinyMCE.baseURL.indexOf('://') == -1 && tinyMCE.baseURL.charAt(0) != '/') {\n\t\t\t// If site absolute\n\t\t\ttinyMCE.baseURL = this.documentBasePath + \"/\" + tinyMCE.baseURL;\n\t\t}\n\n\t\t// Set default values on settings\n\t\tthis._def(\"mode\", \"none\");\n\t\tthis._def(\"theme\", \"advanced\");\n\t\tthis._def(\"plugins\", \"\", true);\n\t\tthis._def(\"language\", \"en\");\n\t\tthis._def(\"docs_language\", this.settings.language);\n\t\tthis._def(\"elements\", \"\");\n\t\tthis._def(\"textarea_trigger\", \"mce_editable\");\n\t\tthis._def(\"editor_selector\", \"\");\n\t\tthis._def(\"editor_deselector\", \"mceNoEditor\");\n\t\tthis._def(\"valid_elements\", \"+a[id|style|rel|rev|charset|hreflang|dir|lang|tabindex|accesskey|type|name|href|target|title|class|onfocus|onblur|onclick|ondblclick|onmousedown|onmouseup|onmouseover|onmousemove|onmouseout|onkeypress|onkeydown|onkeyup],-strong/-b[class|style],-em/-i[class|style],-strike[class|style],-u[class|style],#p[id|style|dir|class|align],-ol[class|style],-ul[class|style],-li[class|style],br,img[id|dir|lang|longdesc|usemap|style|class|src|onmouseover|onmouseout|border|alt=|title|hspace|vspace|width|height|align],-sub[style|class],-sup[style|class],-blockquote[dir|style],-table[border=0|cellspacing|cellpadding|width|height|class|align|summary|style|dir|id|lang|bgcolor|background|bordercolor],-tr[id|lang|dir|class|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor],tbody[id|class],thead[id|class],tfoot[id|class],#td[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor|scope],-th[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|scope],caption[id|lang|dir|class|style],-div[id|dir|class|align|style],-span[style|class|align],-pre[class|align|style],address[class|align|style],-h1[id|style|dir|class|align],-h2[id|style|dir|class|align],-h3[id|style|dir|class|align],-h4[id|style|dir|class|align],-h5[id|style|dir|class|align],-h6[id|style|dir|class|align],hr[class|style],-font[face|size|style|id|class|dir|color],dd[id|class|title|style|dir|lang],dl[id|class|title|style|dir|lang],dt[id|class|title|style|dir|lang],cite[title|id|class|style|dir|lang],abbr[title|id|class|style|dir|lang],acronym[title|id|class|style|dir|lang],del[title|id|class|style|dir|lang|datetime|cite],ins[title|id|class|style|dir|lang|datetime|cite]\");\n\t\tthis._def(\"extended_valid_elements\", \"\");\n\t\tthis._def(\"invalid_elements\", \"\");\n\t\tthis._def(\"encoding\", \"\");\n\t\tthis._def(\"urlconverter_callback\", tinyMCE.getParam(\"urlconvertor_callback\", \"TinyMCE_Engine.prototype.convertURL\"));\n\t\tthis._def(\"save_callback\", \"\");\n\t\tthis._def(\"force_br_newlines\", false);\n\t\tthis._def(\"force_p_newlines\", true);\n\t\tthis._def(\"add_form_submit_trigger\", true);\n\t\tthis._def(\"relative_urls\", true);\n\t\tthis._def(\"remove_script_host\", true);\n\t\tthis._def(\"focus_alert\", true);\n\t\tthis._def(\"document_base_url\", this.documentURL);\n\t\tthis._def(\"visual\", true);\n\t\tthis._def(\"visual_table_class\", \"mceVisualAid\");\n\t\tthis._def(\"setupcontent_callback\", \"\");\n\t\tthis._def(\"fix_content_duplication\", true);\n\t\tthis._def(\"custom_undo_redo\", true);\n\t\tthis._def(\"custom_undo_redo_levels\", -1);\n\t\tthis._def(\"custom_undo_redo_keyboard_shortcuts\", true);\n\t\tthis._def(\"custom_undo_redo_restore_selection\", true);\n\t\tthis._def(\"custom_undo_redo_global\", false);\n\t\tthis._def(\"verify_html\", true);\n\t\tthis._def(\"apply_source_formatting\", false);\n\t\tthis._def(\"directionality\", \"ltr\");\n\t\tthis._def(\"cleanup_on_startup\", false);\n\t\tthis._def(\"inline_styles\", false);\n\t\tthis._def(\"convert_newlines_to_brs\", false);\n\t\tthis._def(\"auto_reset_designmode\", true);\n\t\tthis._def(\"entities\", \"39,#39,160,nbsp,161,iexcl,162,cent,163,pound,164,curren,165,yen,166,brvbar,167,sect,168,uml,169,copy,170,ordf,171,laquo,172,not,173,shy,174,reg,175,macr,176,deg,177,plusmn,178,sup2,179,sup3,180,acute,181,micro,182,para,183,middot,184,cedil,185,sup1,186,ordm,187,raquo,188,frac14,189,frac12,190,frac34,191,iquest,192,Agrave,193,Aacute,194,Acirc,195,Atilde,196,Auml,197,Aring,198,AElig,199,Ccedil,200,Egrave,201,Eacute,202,Ecirc,203,Euml,204,Igrave,205,Iacute,206,Icirc,207,Iuml,208,ETH,209,Ntilde,210,Ograve,211,Oacute,212,Ocirc,213,Otilde,214,Ouml,215,times,216,Oslash,217,Ugrave,218,Uacute,219,Ucirc,220,Uuml,221,Yacute,222,THORN,223,szlig,224,agrave,225,aacute,226,acirc,227,atilde,228,auml,229,aring,230,aelig,231,ccedil,232,egrave,233,eacute,234,ecirc,235,euml,236,igrave,237,iacute,238,icirc,239,iuml,240,eth,241,ntilde,242,ograve,243,oacute,244,ocirc,245,otilde,246,ouml,247,divide,248,oslash,249,ugrave,250,uacute,251,ucirc,252,uuml,253,yacute,254,thorn,255,yuml,402,fnof,913,Alpha,914,Beta,915,Gamma,916,Delta,917,Epsilon,918,Zeta,919,Eta,920,Theta,921,Iota,922,Kappa,923,Lambda,924,Mu,925,Nu,926,Xi,927,Omicron,928,Pi,929,Rho,931,Sigma,932,Tau,933,Upsilon,934,Phi,935,Chi,936,Psi,937,Omega,945,alpha,946,beta,947,gamma,948,delta,949,epsilon,950,zeta,951,eta,952,theta,953,iota,954,kappa,955,lambda,956,mu,957,nu,958,xi,959,omicron,960,pi,961,rho,962,sigmaf,963,sigma,964,tau,965,upsilon,966,phi,967,chi,968,psi,969,omega,977,thetasym,978,upsih,982,piv,8226,bull,8230,hellip,8242,prime,8243,Prime,8254,oline,8260,frasl,8472,weierp,8465,image,8476,real,8482,trade,8501,alefsym,8592,larr,8593,uarr,8594,rarr,8595,darr,8596,harr,8629,crarr,8656,lArr,8657,uArr,8658,rArr,8659,dArr,8660,hArr,8704,forall,8706,part,8707,exist,8709,empty,8711,nabla,8712,isin,8713,notin,8715,ni,8719,prod,8721,sum,8722,minus,8727,lowast,8730,radic,8733,prop,8734,infin,8736,ang,8743,and,8744,or,8745,cap,8746,cup,8747,int,8756,there4,8764,sim,8773,cong,8776,asymp,8800,ne,8801,equiv,8804,le,8805,ge,8834,sub,8835,sup,8836,nsub,8838,sube,8839,supe,8853,oplus,8855,otimes,8869,perp,8901,sdot,8968,lceil,8969,rceil,8970,lfloor,8971,rfloor,9001,lang,9002,rang,9674,loz,9824,spades,9827,clubs,9829,hearts,9830,diams,34,quot,38,amp,60,lt,62,gt,338,OElig,339,oelig,352,Scaron,353,scaron,376,Yuml,710,circ,732,tilde,8194,ensp,8195,emsp,8201,thinsp,8204,zwnj,8205,zwj,8206,lrm,8207,rlm,8211,ndash,8212,mdash,8216,lsquo,8217,rsquo,8218,sbquo,8220,ldquo,8221,rdquo,8222,bdquo,8224,dagger,8225,Dagger,8240,permil,8249,lsaquo,8250,rsaquo,8364,euro\", true);\n\t\tthis._def(\"entity_encoding\", \"named\");\n\t\tthis._def(\"cleanup_callback\", \"\");\n\t\tthis._def(\"add_unload_trigger\", true);\n\t\tthis._def(\"ask\", false);\n\t\tthis._def(\"nowrap\", false);\n\t\tthis._def(\"auto_resize\", false);\n\t\tthis._def(\"auto_focus\", false);\n\t\tthis._def(\"cleanup\", true);\n\t\tthis._def(\"remove_linebreaks\", true);\n\t\tthis._def(\"button_tile_map\", false);\n\t\tthis._def(\"submit_patch\", true);\n\t\tthis._def(\"browsers\", \"msie,safari,gecko,opera\", true);\n\t\tthis._def(\"dialog_type\", \"window\");\n\t\tthis._def(\"accessibility_warnings\", true);\n\t\tthis._def(\"accessibility_focus\", true);\n\t\tthis._def(\"merge_styles_invalid_parents\", \"\");\n\t\tthis._def(\"force_hex_style_colors\", true);\n\t\tthis._def(\"trim_span_elements\", true);\n\t\tthis._def(\"convert_fonts_to_spans\", false);\n\t\tthis._def(\"doctype\", '<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">');\n\t\tthis._def(\"font_size_classes\", '');\n\t\tthis._def(\"font_size_style_values\", 'xx-small,x-small,small,medium,large,x-large,xx-large', true);\n\t\tthis._def(\"event_elements\", 'a,img', true);\n\t\tthis._def(\"convert_urls\", true);\n\t\tthis._def(\"table_inline_editing\", false);\n\t\tthis._def(\"object_resizing\", true);\n\t\tthis._def(\"custom_shortcuts\", true);\n\t\tthis._def(\"convert_on_click\", false);\n\t\tthis._def(\"content_css\", '');\n\t\tthis._def(\"fix_list_elements\", true);\n\t\tthis._def(\"fix_table_elements\", false);\n\t\tthis._def(\"strict_loading_mode\", document.contentType == 'application/xhtml+xml');\n\t\tthis._def(\"hidden_tab_class\", '');\n\t\tthis._def(\"display_tab_class\", '');\n\t\tthis._def(\"gecko_spellcheck\", false);\n\t\tthis._def(\"hide_selects_on_submit\", true);\n\t\tthis._def(\"forced_root_block\", false);\n\t\tthis._def(\"remove_trailing_nbsp\", false);\n\t\tthis._def(\"save_on_tinymce_forms\", false);\n\n\t\t// Force strict loading mode to false on non Gecko browsers\n\t\tif (this.isMSIE && !this.isOpera)\n\t\t\tthis.settings.strict_loading_mode = false;\n\n\t\t// Browser check IE\n\t\tif (this.isMSIE && this.settings.browsers.indexOf('msie') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Gecko\n\t\tif (this.isGecko && this.settings.browsers.indexOf('gecko') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Safari\n\t\tif (this.isSafari && this.settings.browsers.indexOf('safari') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Opera\n\t\tif (this.isOpera && this.settings.browsers.indexOf('opera') == -1)\n\t\t\treturn;\n\n\t\t// If not super absolute make it so\n\t\tbaseHREF = tinyMCE.settings.document_base_url;\n\t\th = document.location.href;\n\t\tp = h.indexOf('://');\n\t\tif (p > 0 && document.location.protocol != \"file:\") {\n\t\t\tp = h.indexOf('/', p + 3);\n\t\t\th = h.substring(0, p);\n\n\t\t\tif (baseHREF.indexOf('://') == -1)\n\t\t\t\tbaseHREF = h + baseHREF;\n\n\t\t\ttinyMCE.settings.document_base_url = baseHREF;\n\t\t\ttinyMCE.settings.document_base_prefix = h;\n\t\t}\n\n\t\t// Trim away query part\n\t\tif (baseHREF.indexOf('?') != -1)\n\t\t\tbaseHREF = baseHREF.substring(0, baseHREF.indexOf('?'));\n\n\t\tthis.settings.base_href = baseHREF.substring(0, baseHREF.lastIndexOf('/')) + \"/\";\n\n\t\ttheme = this.settings.theme;\n\t\tthis.inlineStrict = 'A|BR|SPAN|BDO|MAP|OBJECT|IMG|TT|I|B|BIG|SMALL|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|#text|#comment';\n\t\tthis.inlineTransitional = 'A|BR|SPAN|BDO|OBJECT|APPLET|IMG|MAP|IFRAME|TT|I|B|U|S|STRIKE|BIG|SMALL|FONT|BASEFONT|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|INPUT|SELECT|TEXTAREA|LABEL|BUTTON|#text|#comment';\n\t\tthis.blockElms = 'H[1-6]|P|DIV|ADDRESS|PRE|FORM|TABLE|LI|OL|UL|TD|CAPTION|BLOCKQUOTE|CENTER|DL|DT|DD|DIR|FIELDSET|FORM|NOSCRIPT|NOFRAMES|MENU|ISINDEX|SAMP';\n\t\tthis.blockRegExp = new RegExp(\"^(\" + this.blockElms + \")$\", \"i\");\n\t\tthis.posKeyCodes = [13,45,36,35,33,34,37,38,39,40];\n\t\tthis.uniqueURL = 'javascript:void(091039730);'; // Make unique URL non real URL\n\t\tthis.uniqueTag = '<div id=\"mceTMPElement\" style=\"display: none\">TMP</div>';\n\t\tthis.callbacks = ['onInit', 'getInfo', 'getEditorTemplate', 'setupContent', 'onChange', 'onPageLoad', 'handleNodeChange', 'initInstance', 'execCommand', 'getControlHTML', 'handleEvent', 'cleanup', 'removeInstance'];\n\n\t\t// Theme url\n\t\tthis.settings.theme_href = tinyMCE.baseURL + \"/themes/\" + theme;\n\n\t\tif (!tinyMCE.isIE || tinyMCE.isOpera)\n\t\t\tthis.settings.force_br_newlines = false;\n\n\t\tif (tinyMCE.getParam(\"popups_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"popups_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.popups_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.popups_css = cssPath;\n\t\t} else\n\t\t\tthis.settings.popups_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_popup.css\";\n\n\t\tif (tinyMCE.getParam(\"editor_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"editor_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.editor_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.editor_css = cssPath;\n\t\t} else {\n\t\t\tif (this.settings.editor_css !== '')\n\t\t\t\tthis.settings.editor_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_ui.css\";\n\t\t}\n\n\t\t// Only do this once\n\t\tif (this.configs.length == 0) {\n\t\t\tif (typeof(TinyMCECompressed) == \"undefined\") {\n\t\t\t\ttinyMCE.addEvent(window, \"DOMContentLoaded\", TinyMCE_Engine.prototype.onLoad);\n\n\t\t\t\tif (tinyMCE.isRealIE) {\n\t\t\t\t\tif (document.body)\n\t\t\t\t\t\ttinyMCE.addEvent(document.body, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.addEvent(document, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t}\n\n\t\t\t\ttinyMCE.addEvent(window, \"load\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\ttinyMCE._addUnloadEvents();\n\t\t\t}\n\t\t}\n\n\t\tthis.loadScript(tinyMCE.baseURL + '/themes/' + this.settings.theme + '/editor_template' + tinyMCE.srcMode + '.js');\n\t\tthis.loadScript(tinyMCE.baseURL + '/langs/' + this.settings.language +  '.js');\n\t\tthis.loadCSS(this.settings.editor_css);\n\n\t\t// Add plugins\n\t\tp = tinyMCE.getParam('plugins', '', true, ',');\n\t\tif (p.length > 0) {\n\t\t\tfor (i=0; i<p.length; i++) {\n\t\t\t\tif (p[i].charAt(0) != '-')\n\t\t\t\t\tthis.loadScript(tinyMCE.baseURL + '/plugins/' + p[i] + '/editor_plugin' + tinyMCE.srcMode + '.js');\n\t\t\t}\n\t\t}\n\n\t\t// Setup entities\n\t\tif (tinyMCE.getParam('entity_encoding') == 'named') {\n\t\t\tsettings.cleanup_entities = [];\n\t\t\tentities = tinyMCE.getParam('entities', '', true, ',');\n\t\t\tfor (i=0; i<entities.length; i+=2)\n\t\t\t\tsettings.cleanup_entities['c' + entities[i]] = entities[i+1];\n\t\t}\n\n\t\t// Save away this config\n\t\tsettings.index = this.configs.length;\n\t\tthis.configs[this.configs.length] = settings;\n\n\t\t// Start loading first one in chain\n\t\tthis.loadNextScript();\n\n\t\t// Force flicker free CSS backgrounds in IE\n\t\tif (this.isIE && !this.isOpera) {\n\t\t\ttry {\n\t\t\t\tdocument.execCommand('BackgroundImageCache', false, true);\n\t\t\t} catch (e) {\n\t\t\t\t// Ignore\n\t\t\t}\n\t\t}\n\n\t\t// Setup XML encoding regexps\n\t\tthis.xmlEncodeRe = new RegExp('[<>&\"]', 'g');\n\t},", "func_src_after": "\tinit : function(settings) {\n\t\tvar theme, nl, baseHREF = \"\", i, cssPath, entities, h, p, src, elements = [], head;\n\n\t\t// IE 5.0x is no longer supported since 5.5, 6.0 and 7.0 now exists. We can't support old browsers forever, sorry.\n\t\tif (this.isMSIE5_0)\n\t\t\treturn;\n\n\t\tthis.settings = settings;\n\n\t\t// Check if valid browser has execcommand support\n\t\tif (typeof(document.execCommand) == 'undefined')\n\t\t\treturn;\n\n\t\t// Get script base path\n\t\tif (!tinyMCE.baseURL) {\n\t\t\t// Search through head\n\t\t\thead = document.getElementsByTagName('head')[0];\n\n\t\t\tif (head) {\n\t\t\t\tfor (i=0, nl = head.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\t\telements.push(nl[i]);\n\t\t\t}\n\n\t\t\t// Search through rest of document\n\t\t\tfor (i=0, nl = document.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\telements.push(nl[i]);\n\n\t\t\t// If base element found, add that infront of baseURL\n\t\t\tnl = document.getElementsByTagName('base');\n\t\t\tfor (i=0; i<nl.length; i++) {\n\t\t\t\tif (nl[i].href)\n\t\t\t\t\tbaseHREF = nl[i].href;\n\t\t\t}\n\n\t\t\tfor (i=0; i<elements.length; i++) {\n\t\t\t\tif (elements[i].src && (elements[i].src.indexOf(\"tiny_mce.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_dev.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_src.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_gzip\") != -1)) {\n\t\t\t\t\tsrc = elements[i].src;\n\n\t\t\t\t\ttinyMCE.srcMode = (src.indexOf('_src') != -1 || src.indexOf('_dev') != -1) ? '_src' : '';\n\t\t\t\t\ttinyMCE.gzipMode = src.indexOf('_gzip') != -1;\n\t\t\t\t\tsrc = src.substring(0, src.lastIndexOf('/'));\n\n\t\t\t\t\tif (settings.exec_mode == \"src\" || settings.exec_mode == \"normal\")\n\t\t\t\t\t\ttinyMCE.srcMode = settings.exec_mode == \"src\" ? '_src' : '';\n\n\t\t\t\t\t// Force it absolute if page has a base href\n\t\t\t\t\tif (baseHREF !== '' && src.indexOf('://') == -1)\n\t\t\t\t\t\ttinyMCE.baseURL = baseHREF + src;\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.baseURL = src;\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Get document base path\n\t\tthis.documentBasePath = escapePath(document.location.href);\n\t\tif (this.documentBasePath.indexOf('?') != -1)\n\t\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.indexOf('?'));\n\t\tthis.documentURL = this.documentBasePath;\n\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.lastIndexOf('/'));\n\n\t\t// If not HTTP absolute\n\t\tif (tinyMCE.baseURL.indexOf('://') == -1 && tinyMCE.baseURL.charAt(0) != '/') {\n\t\t\t// If site absolute\n\t\t\ttinyMCE.baseURL = this.documentBasePath + \"/\" + tinyMCE.baseURL;\n\t\t}\n\n\t\t// Set default values on settings\n\t\tthis._def(\"mode\", \"none\");\n\t\tthis._def(\"theme\", \"advanced\");\n\t\tthis._def(\"plugins\", \"\", true);\n\t\tthis._def(\"language\", \"en\");\n\t\tthis._def(\"docs_language\", this.settings.language);\n\t\tthis._def(\"elements\", \"\");\n\t\tthis._def(\"textarea_trigger\", \"mce_editable\");\n\t\tthis._def(\"editor_selector\", \"\");\n\t\tthis._def(\"editor_deselector\", \"mceNoEditor\");\n\t\tthis._def(\"valid_elements\", \"+a[id|style|rel|rev|charset|hreflang|dir|lang|tabindex|accesskey|type|name|href|target|title|class|onfocus|onblur|onclick|ondblclick|onmousedown|onmouseup|onmouseover|onmousemove|onmouseout|onkeypress|onkeydown|onkeyup],-strong/-b[class|style],-em/-i[class|style],-strike[class|style],-u[class|style],#p[id|style|dir|class|align],-ol[class|style],-ul[class|style],-li[class|style],br,img[id|dir|lang|longdesc|usemap|style|class|src|onmouseover|onmouseout|border|alt=|title|hspace|vspace|width|height|align],-sub[style|class],-sup[style|class],-blockquote[dir|style],-table[border=0|cellspacing|cellpadding|width|height|class|align|summary|style|dir|id|lang|bgcolor|background|bordercolor],-tr[id|lang|dir|class|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor],tbody[id|class],thead[id|class],tfoot[id|class],#td[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor|scope],-th[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|scope],caption[id|lang|dir|class|style],-div[id|dir|class|align|style],-span[style|class|align],-pre[class|align|style],address[class|align|style],-h1[id|style|dir|class|align],-h2[id|style|dir|class|align],-h3[id|style|dir|class|align],-h4[id|style|dir|class|align],-h5[id|style|dir|class|align],-h6[id|style|dir|class|align],hr[class|style],-font[face|size|style|id|class|dir|color],dd[id|class|title|style|dir|lang],dl[id|class|title|style|dir|lang],dt[id|class|title|style|dir|lang],cite[title|id|class|style|dir|lang],abbr[title|id|class|style|dir|lang],acronym[title|id|class|style|dir|lang],del[title|id|class|style|dir|lang|datetime|cite],ins[title|id|class|style|dir|lang|datetime|cite]\");\n\t\tthis._def(\"extended_valid_elements\", \"\");\n\t\tthis._def(\"invalid_elements\", \"\");\n\t\tthis._def(\"encoding\", \"\");\n\t\tthis._def(\"urlconverter_callback\", tinyMCE.getParam(\"urlconvertor_callback\", \"TinyMCE_Engine.prototype.convertURL\"));\n\t\tthis._def(\"save_callback\", \"\");\n\t\tthis._def(\"force_br_newlines\", false);\n\t\tthis._def(\"force_p_newlines\", true);\n\t\tthis._def(\"add_form_submit_trigger\", true);\n\t\tthis._def(\"relative_urls\", true);\n\t\tthis._def(\"remove_script_host\", true);\n\t\tthis._def(\"focus_alert\", true);\n\t\tthis._def(\"document_base_url\", this.documentURL);\n\t\tthis._def(\"visual\", true);\n\t\tthis._def(\"visual_table_class\", \"mceVisualAid\");\n\t\tthis._def(\"setupcontent_callback\", \"\");\n\t\tthis._def(\"fix_content_duplication\", true);\n\t\tthis._def(\"custom_undo_redo\", true);\n\t\tthis._def(\"custom_undo_redo_levels\", -1);\n\t\tthis._def(\"custom_undo_redo_keyboard_shortcuts\", true);\n\t\tthis._def(\"custom_undo_redo_restore_selection\", true);\n\t\tthis._def(\"custom_undo_redo_global\", false);\n\t\tthis._def(\"verify_html\", true);\n\t\tthis._def(\"apply_source_formatting\", false);\n\t\tthis._def(\"directionality\", \"ltr\");\n\t\tthis._def(\"cleanup_on_startup\", false);\n\t\tthis._def(\"inline_styles\", false);\n\t\tthis._def(\"convert_newlines_to_brs\", false);\n\t\tthis._def(\"auto_reset_designmode\", true);\n\t\tthis._def(\"entities\", \"39,#39,160,nbsp,161,iexcl,162,cent,163,pound,164,curren,165,yen,166,brvbar,167,sect,168,uml,169,copy,170,ordf,171,laquo,172,not,173,shy,174,reg,175,macr,176,deg,177,plusmn,178,sup2,179,sup3,180,acute,181,micro,182,para,183,middot,184,cedil,185,sup1,186,ordm,187,raquo,188,frac14,189,frac12,190,frac34,191,iquest,192,Agrave,193,Aacute,194,Acirc,195,Atilde,196,Auml,197,Aring,198,AElig,199,Ccedil,200,Egrave,201,Eacute,202,Ecirc,203,Euml,204,Igrave,205,Iacute,206,Icirc,207,Iuml,208,ETH,209,Ntilde,210,Ograve,211,Oacute,212,Ocirc,213,Otilde,214,Ouml,215,times,216,Oslash,217,Ugrave,218,Uacute,219,Ucirc,220,Uuml,221,Yacute,222,THORN,223,szlig,224,agrave,225,aacute,226,acirc,227,atilde,228,auml,229,aring,230,aelig,231,ccedil,232,egrave,233,eacute,234,ecirc,235,euml,236,igrave,237,iacute,238,icirc,239,iuml,240,eth,241,ntilde,242,ograve,243,oacute,244,ocirc,245,otilde,246,ouml,247,divide,248,oslash,249,ugrave,250,uacute,251,ucirc,252,uuml,253,yacute,254,thorn,255,yuml,402,fnof,913,Alpha,914,Beta,915,Gamma,916,Delta,917,Epsilon,918,Zeta,919,Eta,920,Theta,921,Iota,922,Kappa,923,Lambda,924,Mu,925,Nu,926,Xi,927,Omicron,928,Pi,929,Rho,931,Sigma,932,Tau,933,Upsilon,934,Phi,935,Chi,936,Psi,937,Omega,945,alpha,946,beta,947,gamma,948,delta,949,epsilon,950,zeta,951,eta,952,theta,953,iota,954,kappa,955,lambda,956,mu,957,nu,958,xi,959,omicron,960,pi,961,rho,962,sigmaf,963,sigma,964,tau,965,upsilon,966,phi,967,chi,968,psi,969,omega,977,thetasym,978,upsih,982,piv,8226,bull,8230,hellip,8242,prime,8243,Prime,8254,oline,8260,frasl,8472,weierp,8465,image,8476,real,8482,trade,8501,alefsym,8592,larr,8593,uarr,8594,rarr,8595,darr,8596,harr,8629,crarr,8656,lArr,8657,uArr,8658,rArr,8659,dArr,8660,hArr,8704,forall,8706,part,8707,exist,8709,empty,8711,nabla,8712,isin,8713,notin,8715,ni,8719,prod,8721,sum,8722,minus,8727,lowast,8730,radic,8733,prop,8734,infin,8736,ang,8743,and,8744,or,8745,cap,8746,cup,8747,int,8756,there4,8764,sim,8773,cong,8776,asymp,8800,ne,8801,equiv,8804,le,8805,ge,8834,sub,8835,sup,8836,nsub,8838,sube,8839,supe,8853,oplus,8855,otimes,8869,perp,8901,sdot,8968,lceil,8969,rceil,8970,lfloor,8971,rfloor,9001,lang,9002,rang,9674,loz,9824,spades,9827,clubs,9829,hearts,9830,diams,34,quot,38,amp,60,lt,62,gt,338,OElig,339,oelig,352,Scaron,353,scaron,376,Yuml,710,circ,732,tilde,8194,ensp,8195,emsp,8201,thinsp,8204,zwnj,8205,zwj,8206,lrm,8207,rlm,8211,ndash,8212,mdash,8216,lsquo,8217,rsquo,8218,sbquo,8220,ldquo,8221,rdquo,8222,bdquo,8224,dagger,8225,Dagger,8240,permil,8249,lsaquo,8250,rsaquo,8364,euro\", true);\n\t\tthis._def(\"entity_encoding\", \"named\");\n\t\tthis._def(\"cleanup_callback\", \"\");\n\t\tthis._def(\"add_unload_trigger\", true);\n\t\tthis._def(\"ask\", false);\n\t\tthis._def(\"nowrap\", false);\n\t\tthis._def(\"auto_resize\", false);\n\t\tthis._def(\"auto_focus\", false);\n\t\tthis._def(\"cleanup\", true);\n\t\tthis._def(\"remove_linebreaks\", true);\n\t\tthis._def(\"button_tile_map\", false);\n\t\tthis._def(\"submit_patch\", true);\n\t\tthis._def(\"browsers\", \"msie,safari,gecko,opera\", true);\n\t\tthis._def(\"dialog_type\", \"window\");\n\t\tthis._def(\"accessibility_warnings\", true);\n\t\tthis._def(\"accessibility_focus\", true);\n\t\tthis._def(\"merge_styles_invalid_parents\", \"\");\n\t\tthis._def(\"force_hex_style_colors\", true);\n\t\tthis._def(\"trim_span_elements\", true);\n\t\tthis._def(\"convert_fonts_to_spans\", false);\n\t\tthis._def(\"doctype\", '<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">');\n\t\tthis._def(\"font_size_classes\", '');\n\t\tthis._def(\"font_size_style_values\", 'xx-small,x-small,small,medium,large,x-large,xx-large', true);\n\t\tthis._def(\"event_elements\", 'a,img', true);\n\t\tthis._def(\"convert_urls\", true);\n\t\tthis._def(\"table_inline_editing\", false);\n\t\tthis._def(\"object_resizing\", true);\n\t\tthis._def(\"custom_shortcuts\", true);\n\t\tthis._def(\"convert_on_click\", false);\n\t\tthis._def(\"content_css\", '');\n\t\tthis._def(\"fix_list_elements\", true);\n\t\tthis._def(\"fix_table_elements\", false);\n\t\tthis._def(\"strict_loading_mode\", document.contentType == 'application/xhtml+xml');\n\t\tthis._def(\"hidden_tab_class\", '');\n\t\tthis._def(\"display_tab_class\", '');\n\t\tthis._def(\"gecko_spellcheck\", false);\n\t\tthis._def(\"hide_selects_on_submit\", true);\n\t\tthis._def(\"forced_root_block\", false);\n\t\tthis._def(\"remove_trailing_nbsp\", false);\n\t\tthis._def(\"save_on_tinymce_forms\", false);\n\n\t\t// Force strict loading mode to false on non Gecko browsers\n\t\tif (this.isMSIE && !this.isOpera)\n\t\t\tthis.settings.strict_loading_mode = false;\n\n\t\t// Browser check IE\n\t\tif (this.isMSIE && this.settings.browsers.indexOf('msie') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Gecko\n\t\tif (this.isGecko && this.settings.browsers.indexOf('gecko') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Safari\n\t\tif (this.isSafari && this.settings.browsers.indexOf('safari') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Opera\n\t\tif (this.isOpera && this.settings.browsers.indexOf('opera') == -1)\n\t\t\treturn;\n\n\t\t// If not super absolute make it so\n\t\tbaseHREF = tinyMCE.settings.document_base_url;\n\t\th = escapePath(document.location.href);\n\t\tp = h.indexOf('://');\n\t\tif (p > 0 && document.location.protocol != \"file:\") {\n\t\t\tp = h.indexOf('/', p + 3);\n\t\t\th = h.substring(0, p);\n\n\t\t\tif (baseHREF.indexOf('://') == -1)\n\t\t\t\tbaseHREF = h + baseHREF;\n\n\t\t\ttinyMCE.settings.document_base_url = baseHREF;\n\t\t\ttinyMCE.settings.document_base_prefix = h;\n\t\t}\n\n\t\t// Trim away query part\n\t\tif (baseHREF.indexOf('?') != -1)\n\t\t\tbaseHREF = baseHREF.substring(0, baseHREF.indexOf('?'));\n\n\t\tthis.settings.base_href = baseHREF.substring(0, baseHREF.lastIndexOf('/')) + \"/\";\n\n\t\ttheme = this.settings.theme;\n\t\tthis.inlineStrict = 'A|BR|SPAN|BDO|MAP|OBJECT|IMG|TT|I|B|BIG|SMALL|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|#text|#comment';\n\t\tthis.inlineTransitional = 'A|BR|SPAN|BDO|OBJECT|APPLET|IMG|MAP|IFRAME|TT|I|B|U|S|STRIKE|BIG|SMALL|FONT|BASEFONT|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|INPUT|SELECT|TEXTAREA|LABEL|BUTTON|#text|#comment';\n\t\tthis.blockElms = 'H[1-6]|P|DIV|ADDRESS|PRE|FORM|TABLE|LI|OL|UL|TD|CAPTION|BLOCKQUOTE|CENTER|DL|DT|DD|DIR|FIELDSET|FORM|NOSCRIPT|NOFRAMES|MENU|ISINDEX|SAMP';\n\t\tthis.blockRegExp = new RegExp(\"^(\" + this.blockElms + \")$\", \"i\");\n\t\tthis.posKeyCodes = [13,45,36,35,33,34,37,38,39,40];\n\t\tthis.uniqueURL = 'javascript:void(091039730);'; // Make unique URL non real URL\n\t\tthis.uniqueTag = '<div id=\"mceTMPElement\" style=\"display: none\">TMP</div>';\n\t\tthis.callbacks = ['onInit', 'getInfo', 'getEditorTemplate', 'setupContent', 'onChange', 'onPageLoad', 'handleNodeChange', 'initInstance', 'execCommand', 'getControlHTML', 'handleEvent', 'cleanup', 'removeInstance'];\n\n\t\t// Theme url\n\t\tthis.settings.theme_href = tinyMCE.baseURL + \"/themes/\" + theme;\n\n\t\tif (!tinyMCE.isIE || tinyMCE.isOpera)\n\t\t\tthis.settings.force_br_newlines = false;\n\n\t\tif (tinyMCE.getParam(\"popups_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"popups_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.popups_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.popups_css = cssPath;\n\t\t} else\n\t\t\tthis.settings.popups_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_popup.css\";\n\n\t\tif (tinyMCE.getParam(\"editor_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"editor_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.editor_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.editor_css = cssPath;\n\t\t} else {\n\t\t\tif (this.settings.editor_css !== '')\n\t\t\t\tthis.settings.editor_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_ui.css\";\n\t\t}\n\n\t\t// Only do this once\n\t\tif (this.configs.length == 0) {\n\t\t\tif (typeof(TinyMCECompressed) == \"undefined\") {\n\t\t\t\ttinyMCE.addEvent(window, \"DOMContentLoaded\", TinyMCE_Engine.prototype.onLoad);\n\n\t\t\t\tif (tinyMCE.isRealIE) {\n\t\t\t\t\tif (document.body)\n\t\t\t\t\t\ttinyMCE.addEvent(document.body, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.addEvent(document, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t}\n\n\t\t\t\ttinyMCE.addEvent(window, \"load\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\ttinyMCE._addUnloadEvents();\n\t\t\t}\n\t\t}\n\n\t\tthis.loadScript(tinyMCE.baseURL + '/themes/' + this.settings.theme + '/editor_template' + tinyMCE.srcMode + '.js');\n\t\tthis.loadScript(tinyMCE.baseURL + '/langs/' + this.settings.language +  '.js');\n\t\tthis.loadCSS(this.settings.editor_css);\n\n\t\t// Add plugins\n\t\tp = tinyMCE.getParam('plugins', '', true, ',');\n\t\tif (p.length > 0) {\n\t\t\tfor (i=0; i<p.length; i++) {\n\t\t\t\tif (p[i].charAt(0) != '-')\n\t\t\t\t\tthis.loadScript(tinyMCE.baseURL + '/plugins/' + p[i] + '/editor_plugin' + tinyMCE.srcMode + '.js');\n\t\t\t}\n\t\t}\n\n\t\t// Setup entities\n\t\tif (tinyMCE.getParam('entity_encoding') == 'named') {\n\t\t\tsettings.cleanup_entities = [];\n\t\t\tentities = tinyMCE.getParam('entities', '', true, ',');\n\t\t\tfor (i=0; i<entities.length; i+=2)\n\t\t\t\tsettings.cleanup_entities['c' + entities[i]] = entities[i+1];\n\t\t}\n\n\t\t// Save away this config\n\t\tsettings.index = this.configs.length;\n\t\tthis.configs[this.configs.length] = settings;\n\n\t\t// Start loading first one in chain\n\t\tthis.loadNextScript();\n\n\t\t// Force flicker free CSS backgrounds in IE\n\t\tif (this.isIE && !this.isOpera) {\n\t\t\ttry {\n\t\t\t\tdocument.execCommand('BackgroundImageCache', false, true);\n\t\t\t} catch (e) {\n\t\t\t\t// Ignore\n\t\t\t}\n\t\t}\n\n\t\t// Setup XML encoding regexps\n\t\tthis.xmlEncodeRe = new RegExp('[<>&\"]', 'g');\n\t},", "line_changes": {"deleted": [{"line_no": 172, "char_start": 10731, "char_end": 10761, "line": "\t\th = document.location.href;\n"}], "added": [{"line_no": 172, "char_start": 10731, "char_end": 10773, "line": "\t\th = escapePath(document.location.href);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 10737, "char_end": 10748, "chars": "escapePath("}, {"char_start": 10770, "char_end": 10771, "chars": ")"}]}, "commit_link": "github.com/jaffa-projects/jaffa-framework/commit/f9241bf1b4e4f06fc9778b2314664b58f4fbe309", "file_name": "tiny_mce_src.js", "vul_type": "cwe-079", "commit_msg": "Coverity CWE79 (DOM XSS) new TinyMCE vulnerability fix", "description": "Write a JavaScript function to initialize a WYSIWYG editor with given settings."}
{"func_name": "ExprAppendMultiKeysymList", "func_src_before": "ExprAppendMultiKeysymList(ExprDef *expr, ExprDef *append)\n{\n    unsigned nSyms = darray_size(expr->keysym_list.syms);\n    unsigned numEntries = darray_size(append->keysym_list.syms);\n\n    darray_append(expr->keysym_list.symsMapIndex, nSyms);\n    darray_append(expr->keysym_list.symsNumEntries, numEntries);\n    darray_concat(expr->keysym_list.syms, append->keysym_list.syms);\n\n    FreeStmt((ParseCommon *) &append);\n\n    return expr;\n}", "func_src_after": "ExprAppendMultiKeysymList(ExprDef *expr, ExprDef *append)\n{\n    unsigned nSyms = darray_size(expr->keysym_list.syms);\n    unsigned numEntries = darray_size(append->keysym_list.syms);\n\n    darray_append(expr->keysym_list.symsMapIndex, nSyms);\n    darray_append(expr->keysym_list.symsNumEntries, numEntries);\n    darray_concat(expr->keysym_list.syms, append->keysym_list.syms);\n\n    FreeStmt((ParseCommon *) append);\n\n    return expr;\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/c1e5ac16e77a21f87bdf3bc4dea61b037a17dddb", "file_name": "src/xkbcomp/ast-build.c", "vul_type": "cwe-416", "description": "Write a C function to append one keysym list to another and update indices, then free the appended structure."}
{"func_name": "__init__.view_grocery_list", "func_src_before": "        def view_grocery_list():\n            print(\"grocery== list\")\n            groceryListFrame = Frame(self)\n            groceryListFrame.rowconfigure(0, weight=1)\n            groceryListFrame.columnconfigure(0, weight=1)\n            groceryListFrame.rowconfigure(1, weight=3)\n            groceryListFrame.columnconfigure(1, weight=3)\n            groceryListFrame.pack()\n\n            menu.pack_forget()\n            groceryButton.pack_forget()\n            label.configure(text=\"Grocery List\")\n\n            i = 0\n            database_file = \"meal_planner.db\"\n            item_array = []\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                tableName = \"ingredients_\" + str(weekNumber)\n                selection = cursor.execute(\"\"\"SELECT * FROM \"\"\" + tableName)\n                for result in [selection]:\n                    for row in result.fetchall():\n                        print(row)\n                        for ingredient in row:\n                            print(ingredient)\n                            item_array.append(str(ingredient).split())\n                        i = i +1\n                        Label(groceryListFrame, text=ingredient, font=MEDIUM_FONT, justify=LEFT).grid(row=i, column=0, sticky=\"w\")\n            \n\n            j = 0\n            for item in item_array:\n                print(item)\n\n\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [groceryListFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def view_grocery_list():\n            print(\"grocery== list\")\n            groceryListFrame = Frame(self)\n            groceryListFrame.rowconfigure(0, weight=1)\n            groceryListFrame.columnconfigure(0, weight=1)\n            groceryListFrame.rowconfigure(1, weight=3)\n            groceryListFrame.columnconfigure(1, weight=3)\n            groceryListFrame.pack()\n\n            menu.pack_forget()\n            groceryButton.pack_forget()\n            label.configure(text=\"Grocery List\")\n\n            i = 0\n            database_file = \"meal_planner.db\"\n            item_array = []\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                tableName = \"ingredients_\" + str(weekNumber)\n                selection = cursor.execute(\"\"\"SELECT * FROM ?;\"\"\", (tableName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        print(row)\n                        for ingredient in row:\n                            print(ingredient)\n                            item_array.append(str(ingredient).split())\n                        i = i +1\n                        Label(groceryListFrame, text=ingredient, font=MEDIUM_FONT, justify=LEFT).grid(row=i, column=0, sticky=\"w\")\n            \n\n            j = 0\n            for item in item_array:\n                print(item)\n\n\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [groceryListFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089", "description": "Write a Python function to display a grocery list from a SQLite database and provide a return button to the main menu."}
{"func_name": "_gdContributionsCalc", "func_src_before": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "func_src_after": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "commit_link": "github.com/libgd/libgd/commit/4f65a3e4eedaffa1efcf9ee1eb08f0b504fbc31a", "file_name": "src/gd_interpolation.c", "vul_type": "cwe-125", "description": "In C, write a function to calculate the contribution of source pixels to a line with scaling, using a specified interpolation method."}
{"func_name": "start", "func_src_before": "def start():\n    print(\"[*] Starting backdoor process\")\n    print(\"[*] Decompressing target to tmp directory...\")\n    #subprocess.call(\"jar -x %s\" % target, shell=True)\n    with zipfile.ZipFile(target, 'r') as zip:\n        zip.extractall(\"tmp\")\n    print(\"[*] Target dumped to tmp directory\")\n\n    print(\"[*] Modifying manifest file...\")\n    oldmain=\"\"\n    man = open(\"tmp/META-INF/MANIFEST.MF\",\"r\").read()\n    with open(\"tmp/META-INF/MANIFEST.MF\",\"w\") as f:\n        for l in man.split(\"\\n\"):\n            if \"Main-Class\" in l:\n                oldmain=l[12:]\n                f.write(\"Main-Class: %s\\n\" % \"Backdoor\")\n            else:\n                f.write(\"%s\\n\" % l)\n    print(\"[*] Manifest file modified\")\n    \n    print(\"[*] Modifying provided backdoor...\")\n    inmain=False\n    level=0\n    bd=open(backdoor, \"r\").read()\n    with open(\"tmp/%s\" % backdoor,'w') as f:\n        for l in bd.split(\"\\n\"):\n            if \"main(\" in l:\n                inmain=True\n                f.write(l)\n            elif \"}\" in l and level<2 and inmain:\n                f.write(\"%s.main(args);}\" % oldmain)\n                inmain=False\n            elif \"}\" in l and level>1 and inmain:\n                level-=1\n                f.write(l)\n            elif \"{\" in l and inmain:\n                level+=1\n                f.write(l)\n            else:\n                f.write(l)\n    print(\"[*] Provided backdoor successfully modified\")\n\n    print(\"[*] Compiling modified backdoor...\")\n    if subprocess.call(\"javac -cp tmp/ tmp/%s\" % backdoor, shell=True) != 0:\n        print(\"[!] Error compiling %s\" % backdoor)\n    print(\"[*] Compiled modified backdoor\")\n                \n    if(len(oldmain)<1):\n        print(\"[!] Main-Class manifest attribute not found\")\n    else:\n        print(\"[*] Repackaging target jar file...\")\n        createZip(\"tmp\",outfile)\n        print(\"[*] Target jar successfully repackaged\")\n    shutil.rmtree('tmp/')", "func_src_after": "def start():\n    print(\"[*] Starting backdoor process\")\n    print(\"[*] Decompressing target to tmp directory...\")\n    #subprocess.call(\"jar -x %s\" % target, shell=True)\n    with zipfile.ZipFile(target, 'r') as zip:\n        zip.extractall(\"tmp\")\n    print(\"[*] Target dumped to tmp directory\")\n\n    print(\"[*] Modifying manifest file...\")\n    oldmain=\"\"\n    man = open(\"tmp/META-INF/MANIFEST.MF\",\"r\").read()\n    with open(\"tmp/META-INF/MANIFEST.MF\",\"w\") as f:\n        for l in man.split(\"\\n\"):\n            if \"Main-Class\" in l:\n                oldmain=l[12:]\n                f.write(\"Main-Class: %s\\n\" % \"Backdoor\")\n            else:\n                f.write(\"%s\\n\" % l)\n    print(\"[*] Manifest file modified\")\n    \n    print(\"[*] Modifying provided backdoor...\")\n    inmain=False\n    level=0\n    bd=open(backdoor, \"r\").read()\n    with open(\"tmp/%s\" % backdoor,'w') as f:\n        for l in bd.split(\"\\n\"):\n            if \"main(\" in l:\n                inmain=True\n                f.write(l)\n            elif \"}\" in l and level<2 and inmain:\n                f.write(\"%s.main(args);}\" % oldmain)\n                inmain=False\n            elif \"}\" in l and level>1 and inmain:\n                level-=1\n                f.write(l)\n            elif \"{\" in l and inmain:\n                level+=1\n                f.write(l)\n            else:\n                f.write(l)\n    print(\"[*] Provided backdoor successfully modified\")\n\n    print(\"[*] Compiling modified backdoor...\")\n    #if subprocess.call(\"javac -cp tmp/ tmp/%s\" % backdoor, shell=True) != 0:\n    if subprocess.call(['javac','-cp','tmp/','tmp/%s'%backdoor],shell=False) != 0:\n        print(\"[!] Error compiling %s\" % backdoor)\n    print(\"[*] Compiled modified backdoor\")\n                \n    if(len(oldmain)<1):\n        print(\"[!] Main-Class manifest attribute not found\")\n    else:\n        print(\"[*] Repackaging target jar file...\")\n        createZip(\"tmp\",outfile)\n        print(\"[*] Target jar successfully repackaged\")\n    shutil.rmtree('tmp/')", "commit_link": "github.com/Atticuss/ajar/commit/5ed8aba271ad20e6168f2e3bd6c25ba89b84484f", "file_name": "ajar.py", "vul_type": "cwe-078", "description": "Write a Python function to inject a backdoor into a Java application by modifying its manifest and main class, then recompiling and repackaging it."}
{"func_name": "imap_hcache_open", "func_src_before": "header_cache_t *imap_hcache_open(struct ImapData *idata, const char *path)\n{\n  struct ImapMbox mx;\n  struct Url url;\n  char cachepath[PATH_MAX];\n  char mbox[PATH_MAX];\n\n  if (path)\n    imap_cachepath(idata, path, mbox, sizeof(mbox));\n  else\n  {\n    if (!idata->ctx || imap_parse_path(idata->ctx->path, &mx) < 0)\n      return NULL;\n\n    imap_cachepath(idata, mx.mbox, mbox, sizeof(mbox));\n    FREE(&mx.mbox);\n  }\n\n  mutt_account_tourl(&idata->conn->account, &url);\n  url.path = mbox;\n  url_tostring(&url, cachepath, sizeof(cachepath), U_PATH);\n\n  return mutt_hcache_open(HeaderCache, cachepath, imap_hcache_namer);\n}", "func_src_after": "header_cache_t *imap_hcache_open(struct ImapData *idata, const char *path)\n{\n  struct ImapMbox mx;\n  struct Url url;\n  char cachepath[PATH_MAX];\n  char mbox[PATH_MAX];\n\n  if (path)\n    imap_cachepath(idata, path, mbox, sizeof(mbox));\n  else\n  {\n    if (!idata->ctx || imap_parse_path(idata->ctx->path, &mx) < 0)\n      return NULL;\n\n    imap_cachepath(idata, mx.mbox, mbox, sizeof(mbox));\n    FREE(&mx.mbox);\n  }\n\n  if (strstr(mbox, \"/../\") || (strcmp(mbox, \"..\") == 0) || (strncmp(mbox, \"../\", 3) == 0))\n    return NULL;\n  size_t len = strlen(mbox);\n  if ((len > 3) && (strcmp(mbox + len - 3, \"/..\") == 0))\n    return NULL;\n\n  mutt_account_tourl(&idata->conn->account, &url);\n  url.path = mbox;\n  url_tostring(&url, cachepath, sizeof(cachepath), U_PATH);\n\n  return mutt_hcache_open(HeaderCache, cachepath, imap_hcache_namer);\n}", "commit_link": "github.com/neomutt/neomutt/commit/57971dba06346b2d7179294f4528b8d4427a7c5d", "file_name": "imap/util.c", "vul_type": "cwe-022", "description": "Write a C function named `imap_hcache_open` that opens an IMAP header cache, optionally using a provided path."}
{"func_name": "ExprResolveLhs", "func_src_before": "ExprResolveLhs(struct xkb_context *ctx, const ExprDef *expr,\n               const char **elem_rtrn, const char **field_rtrn,\n               ExprDef **index_rtrn)\n{\n    switch (expr->expr.op) {\n    case EXPR_IDENT:\n        *elem_rtrn = NULL;\n        *field_rtrn = xkb_atom_text(ctx, expr->ident.ident);\n        *index_rtrn = NULL;\n        return (*field_rtrn != NULL);\n    case EXPR_FIELD_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->field_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->field_ref.field);\n        *index_rtrn = NULL;\n        return true;\n    case EXPR_ARRAY_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->array_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->array_ref.field);\n        *index_rtrn = expr->array_ref.entry;\n        return true;\n    default:\n        break;\n    }\n    log_wsgo(ctx, \"Unexpected operator %d in ResolveLhs\\n\", expr->expr.op);\n    return false;\n}", "func_src_after": "ExprResolveLhs(struct xkb_context *ctx, const ExprDef *expr,\n               const char **elem_rtrn, const char **field_rtrn,\n               ExprDef **index_rtrn)\n{\n    switch (expr->expr.op) {\n    case EXPR_IDENT:\n        *elem_rtrn = NULL;\n        *field_rtrn = xkb_atom_text(ctx, expr->ident.ident);\n        *index_rtrn = NULL;\n        return (*field_rtrn != NULL);\n    case EXPR_FIELD_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->field_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->field_ref.field);\n        *index_rtrn = NULL;\n        return (*elem_rtrn != NULL && *field_rtrn != NULL);\n    case EXPR_ARRAY_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->array_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->array_ref.field);\n        *index_rtrn = expr->array_ref.entry;\n\tif (expr->array_ref.element != XKB_ATOM_NONE && *elem_rtrn == NULL)\n\t\treturn false;\n\tif (*field_rtrn == NULL)\n\t\treturn false;\n        return true;\n    default:\n        break;\n    }\n    log_wsgo(ctx, \"Unexpected operator %d in ResolveLhs\\n\", expr->expr.op);\n    return false;\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/bb4909d2d8fa6b08155e449986a478101e2b2634", "file_name": "src/xkbcomp/expr.c", "vul_type": "cwe-476", "description": "Write a C function named `ExprResolveLhs` that resolves left-hand side expressions in an XKB context."}
{"func_name": "getSeriesDateFromDatabase", "func_src_before": "def getSeriesDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = '\" + str(getTitle(submission)) + \"'\").fetchone()[0]\n    database.close()", "func_src_after": "def getSeriesDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = ?\", [getTitle(submission)]).fetchone()[0]\n    database.close()", "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the start date of a series from an SQLite database using the series title."}
{"func_name": "ComplexImages", "func_src_before": "MagickExport Image *ComplexImages(const Image *images,const ComplexOperator op,\n  ExceptionInfo *exception)\n{\n#define ComplexImageTag  \"Complex/Image\"\n\n  CacheView\n    *Ai_view,\n    *Ar_view,\n    *Bi_view,\n    *Br_view,\n    *Ci_view,\n    *Cr_view;\n\n  const char\n    *artifact;\n\n  const Image\n    *Ai_image,\n    *Ar_image,\n    *Bi_image,\n    *Br_image;\n\n  double\n    snr;\n\n  Image\n    *Ci_image,\n    *complex_images,\n    *Cr_image,\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  ssize_t\n    y;\n\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  if (images->next == (Image *) NULL)\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),ImageError,\n        \"ImageSequenceRequired\",\"`%s'\",images->filename);\n      return((Image *) NULL);\n    }\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(image,DirectClass,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return(image);\n    }\n  image->depth=32UL;\n  complex_images=NewImageList();\n  AppendImageToList(&complex_images,image);\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    {\n      complex_images=DestroyImageList(complex_images);\n      return(complex_images);\n    }\n  AppendImageToList(&complex_images,image);\n  /*\n    Apply complex mathematics to image pixels.\n  */\n  artifact=GetImageArtifact(image,\"complex:snr\");\n  snr=0.0;\n  if (artifact != (const char *) NULL)\n    snr=StringToDouble(artifact,(char **) NULL);\n  Ar_image=images;\n  Ai_image=images->next;\n  Br_image=images;\n  Bi_image=images->next;\n  if ((images->next->next != (Image *) NULL) &&\n      (images->next->next->next != (Image *) NULL))\n    {\n      Br_image=images->next->next;\n      Bi_image=images->next->next->next;\n    }\n  Cr_image=complex_images;\n  Ci_image=complex_images->next;\n  Ar_view=AcquireVirtualCacheView(Ar_image,exception);\n  Ai_view=AcquireVirtualCacheView(Ai_image,exception);\n  Br_view=AcquireVirtualCacheView(Br_image,exception);\n  Bi_view=AcquireVirtualCacheView(Bi_image,exception);\n  Cr_view=AcquireAuthenticCacheView(Cr_image,exception);\n  Ci_view=AcquireAuthenticCacheView(Ci_image,exception);\n  status=MagickTrue;\n  progress=0;\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(Cr_image,complex_images,Cr_image->rows,1L)\n#endif\n  for (y=0; y < (ssize_t) Cr_image->rows; y++)\n  {\n    register const Quantum\n      *magick_restrict Ai,\n      *magick_restrict Ar,\n      *magick_restrict Bi,\n      *magick_restrict Br;\n\n    register Quantum\n      *magick_restrict Ci,\n      *magick_restrict Cr;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    Ar=GetCacheViewVirtualPixels(Ar_view,0,y,Cr_image->columns,1,exception);\n    Ai=GetCacheViewVirtualPixels(Ai_view,0,y,Cr_image->columns,1,exception);\n    Br=GetCacheViewVirtualPixels(Br_view,0,y,Cr_image->columns,1,exception);\n    Bi=GetCacheViewVirtualPixels(Bi_view,0,y,Cr_image->columns,1,exception);\n    Cr=QueueCacheViewAuthenticPixels(Cr_view,0,y,Cr_image->columns,1,exception);\n    Ci=QueueCacheViewAuthenticPixels(Ci_view,0,y,Ci_image->columns,1,exception);\n    if ((Ar == (const Quantum *) NULL) || (Ai == (const Quantum *) NULL) || \n        (Br == (const Quantum *) NULL) || (Bi == (const Quantum *) NULL) ||\n        (Cr == (Quantum *) NULL) || (Ci == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < (ssize_t) Cr_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      for (i=0; i < (ssize_t) GetPixelChannels(Cr_image); i++)\n      {\n        switch (op)\n        {\n          case AddComplexOperator:\n          {\n            Cr[i]=Ar[i]+Br[i];\n            Ci[i]=Ai[i]+Bi[i];\n            break;\n          }\n          case ConjugateComplexOperator:\n          default:\n          {\n            Cr[i]=Ar[i];\n            Ci[i]=(-Bi[i]);\n            break;\n          }\n          case DivideComplexOperator:\n          {\n            double\n              gamma;\n\n            gamma=PerceptibleReciprocal((double) Br[i]*Br[i]+Bi[i]*Bi[i]+snr);\n            Cr[i]=gamma*((double) Ar[i]*Br[i]+(double) Ai[i]*Bi[i]);\n            Ci[i]=gamma*((double) Ai[i]*Br[i]-(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case MagnitudePhaseComplexOperator:\n          {\n            Cr[i]=sqrt((double) Ar[i]*Ar[i]+(double) Ai[i]*Ai[i]);\n            Ci[i]=atan2((double) Ai[i],(double) Ar[i])/(2.0*MagickPI)+0.5;\n            break;\n          }\n          case MultiplyComplexOperator:\n          {\n            Cr[i]=QuantumScale*((double) Ar[i]*Br[i]-(double) Ai[i]*Bi[i]);\n            Ci[i]=QuantumScale*((double) Ai[i]*Br[i]+(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case RealImaginaryComplexOperator:\n          {\n            Cr[i]=Ar[i]*cos(2.0*MagickPI*(Ai[i]-0.5));\n            Ci[i]=Ar[i]*sin(2.0*MagickPI*(Ai[i]-0.5));\n            break;\n          }\n          case SubtractComplexOperator:\n          {\n            Cr[i]=Ar[i]-Br[i];\n            Ci[i]=Ai[i]-Bi[i];\n            break;\n          }\n        }\n      }\n      Ar+=GetPixelChannels(Ar_image);\n      Ai+=GetPixelChannels(Ai_image);\n      Br+=GetPixelChannels(Br_image);\n      Bi+=GetPixelChannels(Bi_image);\n      Cr+=GetPixelChannels(Cr_image);\n      Ci+=GetPixelChannels(Ci_image);\n    }\n    if (SyncCacheViewAuthenticPixels(Ci_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (SyncCacheViewAuthenticPixels(Cr_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (images->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(images,ComplexImageTag,progress,images->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  Cr_view=DestroyCacheView(Cr_view);\n  Ci_view=DestroyCacheView(Ci_view);\n  Br_view=DestroyCacheView(Br_view);\n  Bi_view=DestroyCacheView(Bi_view);\n  Ar_view=DestroyCacheView(Ar_view);\n  Ai_view=DestroyCacheView(Ai_view);\n  if (status == MagickFalse)\n    complex_images=DestroyImageList(complex_images);\n  return(complex_images);\n}", "func_src_after": "MagickExport Image *ComplexImages(const Image *images,const ComplexOperator op,\n  ExceptionInfo *exception)\n{\n#define ComplexImageTag  \"Complex/Image\"\n\n  CacheView\n    *Ai_view,\n    *Ar_view,\n    *Bi_view,\n    *Br_view,\n    *Ci_view,\n    *Cr_view;\n\n  const char\n    *artifact;\n\n  const Image\n    *Ai_image,\n    *Ar_image,\n    *Bi_image,\n    *Br_image;\n\n  double\n    snr;\n\n  Image\n    *Ci_image,\n    *complex_images,\n    *Cr_image,\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  size_t\n    number_channels;\n\n  ssize_t\n    y;\n\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  if (images->next == (Image *) NULL)\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),ImageError,\n        \"ImageSequenceRequired\",\"`%s'\",images->filename);\n      return((Image *) NULL);\n    }\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(image,DirectClass,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return(image);\n    }\n  image->depth=32UL;\n  complex_images=NewImageList();\n  AppendImageToList(&complex_images,image);\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    {\n      complex_images=DestroyImageList(complex_images);\n      return(complex_images);\n    }\n  AppendImageToList(&complex_images,image);\n  /*\n    Apply complex mathematics to image pixels.\n  */\n  artifact=GetImageArtifact(image,\"complex:snr\");\n  snr=0.0;\n  if (artifact != (const char *) NULL)\n    snr=StringToDouble(artifact,(char **) NULL);\n  Ar_image=images;\n  Ai_image=images->next;\n  Br_image=images;\n  Bi_image=images->next;\n  if ((images->next->next != (Image *) NULL) &&\n      (images->next->next->next != (Image *) NULL))\n    {\n      Br_image=images->next->next;\n      Bi_image=images->next->next->next;\n    }\n  Cr_image=complex_images;\n  Ci_image=complex_images->next;\n  number_channels=MagickMin(MagickMin(MagickMin(\n    Ar_image->number_channels,Ai_image->number_channels),MagickMin(\n    Br_image->number_channels,Bi_image->number_channels)),MagickMin(\n    Cr_image->number_channels,Ci_image->number_channels));\n  Ar_view=AcquireVirtualCacheView(Ar_image,exception);\n  Ai_view=AcquireVirtualCacheView(Ai_image,exception);\n  Br_view=AcquireVirtualCacheView(Br_image,exception);\n  Bi_view=AcquireVirtualCacheView(Bi_image,exception);\n  Cr_view=AcquireAuthenticCacheView(Cr_image,exception);\n  Ci_view=AcquireAuthenticCacheView(Ci_image,exception);\n  status=MagickTrue;\n  progress=0;\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(Cr_image,complex_images,Cr_image->rows,1L)\n#endif\n  for (y=0; y < (ssize_t) Cr_image->rows; y++)\n  {\n    register const Quantum\n      *magick_restrict Ai,\n      *magick_restrict Ar,\n      *magick_restrict Bi,\n      *magick_restrict Br;\n\n    register Quantum\n      *magick_restrict Ci,\n      *magick_restrict Cr;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    Ar=GetCacheViewVirtualPixels(Ar_view,0,y,Cr_image->columns,1,exception);\n    Ai=GetCacheViewVirtualPixels(Ai_view,0,y,Cr_image->columns,1,exception);\n    Br=GetCacheViewVirtualPixels(Br_view,0,y,Cr_image->columns,1,exception);\n    Bi=GetCacheViewVirtualPixels(Bi_view,0,y,Cr_image->columns,1,exception);\n    Cr=QueueCacheViewAuthenticPixels(Cr_view,0,y,Cr_image->columns,1,exception);\n    Ci=QueueCacheViewAuthenticPixels(Ci_view,0,y,Ci_image->columns,1,exception);\n    if ((Ar == (const Quantum *) NULL) || (Ai == (const Quantum *) NULL) || \n        (Br == (const Quantum *) NULL) || (Bi == (const Quantum *) NULL) ||\n        (Cr == (Quantum *) NULL) || (Ci == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < (ssize_t) Cr_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      for (i=0; i < (ssize_t) number_channels; i++)\n      {\n        switch (op)\n        {\n          case AddComplexOperator:\n          {\n            Cr[i]=Ar[i]+Br[i];\n            Ci[i]=Ai[i]+Bi[i];\n            break;\n          }\n          case ConjugateComplexOperator:\n          default:\n          {\n            Cr[i]=Ar[i];\n            Ci[i]=(-Bi[i]);\n            break;\n          }\n          case DivideComplexOperator:\n          {\n            double\n              gamma;\n\n            gamma=PerceptibleReciprocal((double) Br[i]*Br[i]+Bi[i]*Bi[i]+snr);\n            Cr[i]=gamma*((double) Ar[i]*Br[i]+(double) Ai[i]*Bi[i]);\n            Ci[i]=gamma*((double) Ai[i]*Br[i]-(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case MagnitudePhaseComplexOperator:\n          {\n            Cr[i]=sqrt((double) Ar[i]*Ar[i]+(double) Ai[i]*Ai[i]);\n            Ci[i]=atan2((double) Ai[i],(double) Ar[i])/(2.0*MagickPI)+0.5;\n            break;\n          }\n          case MultiplyComplexOperator:\n          {\n            Cr[i]=QuantumScale*((double) Ar[i]*Br[i]-(double) Ai[i]*Bi[i]);\n            Ci[i]=QuantumScale*((double) Ai[i]*Br[i]+(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case RealImaginaryComplexOperator:\n          {\n            Cr[i]=Ar[i]*cos(2.0*MagickPI*(Ai[i]-0.5));\n            Ci[i]=Ar[i]*sin(2.0*MagickPI*(Ai[i]-0.5));\n            break;\n          }\n          case SubtractComplexOperator:\n          {\n            Cr[i]=Ar[i]-Br[i];\n            Ci[i]=Ai[i]-Bi[i];\n            break;\n          }\n        }\n      }\n      Ar+=GetPixelChannels(Ar_image);\n      Ai+=GetPixelChannels(Ai_image);\n      Br+=GetPixelChannels(Br_image);\n      Bi+=GetPixelChannels(Bi_image);\n      Cr+=GetPixelChannels(Cr_image);\n      Ci+=GetPixelChannels(Ci_image);\n    }\n    if (SyncCacheViewAuthenticPixels(Ci_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (SyncCacheViewAuthenticPixels(Cr_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (images->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(images,ComplexImageTag,progress,images->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  Cr_view=DestroyCacheView(Cr_view);\n  Ci_view=DestroyCacheView(Ci_view);\n  Br_view=DestroyCacheView(Br_view);\n  Bi_view=DestroyCacheView(Bi_view);\n  Ar_view=DestroyCacheView(Ar_view);\n  Ai_view=DestroyCacheView(Ai_view);\n  if (status == MagickFalse)\n    complex_images=DestroyImageList(complex_images);\n  return(complex_images);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/d5089971bd792311aaab5cb73460326d7ef7f32d", "file_name": "MagickCore/fourier.c", "vul_type": "cwe-125", "description": "Write a C function in ImageMagick to perform complex operations on a sequence of images."}
{"func_name": "set_eeprom_serial_number", "func_src_before": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 16);\n  _dirty = 1;\n\n  return 0;\n}", "func_src_after": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 12);\n  _dirty = 1;\n\n  return 0;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 16);\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 12);\n"}]}, "char_changes": {"deleted": [{"char_start": 80, "char_end": 81, "chars": "6"}], "added": [{"char_start": 80, "char_end": 81, "chars": "2"}]}, "commit_link": "github.com/picoflamingo/BBCape_EEPROM/commit/0b2d0afdd72e6ca35e9312bd43e29d488ae8c2e5", "file_name": "bbcape_eeprom.c", "vul_type": "cwe-787", "commit_msg": "Buffer Overflow fixed (https://github.com/picoflamingo/BBCape_EEPROM/issues/1)", "parent_commit": "21b1310205d6b2d9073efc51c6a32edbd9a08b89", "description": "Write a C function named `set_eeprom_serial_number` that copies a serial number string into an EEPROM structure and sets a dirty flag."}
{"func_name": "view_page_record", "func_src_before": "@app.route('/<page_name>/history/record')\ndef view_page_record(page_name):\n    content_id = request.args.get('id')\n    query = db.query(\"select page_content.content, page_content.timestamp from page, page_content where page.id = page_content.page_id and page_content.id = '%s'\" % content_id)\n    page_record = query.namedresult()[0]\n\n    return render_template(\n        'page_record.html',\n        page_name = page_name,\n        page_record = page_record\n    )", "func_src_after": "@app.route('/<page_name>/history/record')\ndef view_page_record(page_name):\n    content_id = request.args.get('id')\n    query = db.query(\"select page_content.content, page_content.timestamp from page, page_content where page.id = page_content.page_id and page_content.id = $1\", content_id)\n    page_record = query.namedresult()[0]\n\n    return render_template(\n        'page_record.html',\n        page_name = page_name,\n        page_record = page_record\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to display a specific historical record of a page using its content ID from a database."}
{"func_name": "al_segment_cwd_prefix", "func_src_before": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 64, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "func_src_after": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 16, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "line_changes": {"deleted": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 64, \" %s \", prefix);\n"}], "added": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 16, \" %s \", prefix);\n"}]}, "char_changes": {"deleted": [{"char_start": 829, "char_end": 830, "chars": "4"}], "added": [{"char_start": 828, "char_end": 829, "chars": "1"}]}, "commit_link": "github.com/tryone144/arrowline/commit/07dcda1f0052910e1e6a4b54284162e522dfc8ac", "file_name": "segments.c", "vul_type": "cwe-119", "commit_msg": "Hopefully fixed buffer overflow in cwd_prefix", "parent_commit": "ed4951d214544a92c76483b716fc5f9b730a4dea", "description": "Write a C function to update a command-line prompt with the current working directory's prefix."}
{"func_name": "summary", "func_src_before": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount='\" + session['username'] + \"'\");\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "func_src_after": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount=%s\", (session['username']));\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint that retrieves the user's highest score course concentration from a MySQL database and displays it on a summary page if logged in, otherwise redirects to the login page."}
{"func_name": "ap_limit_section", "func_src_before": "AP_CORE_DECLARE_NONSTD(const char *) ap_limit_section(cmd_parms *cmd,\n                                                      void *dummy,\n                                                      const char *arg)\n{\n    const char *endp = ap_strrchr_c(arg, '>');\n    const char *limited_methods;\n    void *tog = cmd->cmd->cmd_data;\n    apr_int64_t limited = 0;\n    apr_int64_t old_limited = cmd->limited;\n    const char *errmsg;\n\n    if (endp == NULL) {\n        return unclosed_directive(cmd);\n    }\n\n    limited_methods = apr_pstrmemdup(cmd->temp_pool, arg, endp - arg);\n\n    if (!limited_methods[0]) {\n        return missing_container_arg(cmd);\n    }\n\n    while (limited_methods[0]) {\n        char *method = ap_getword_conf(cmd->temp_pool, &limited_methods);\n        int methnum;\n\n        /* check for builtin or module registered method number */\n        methnum = ap_method_number_of(method);\n\n        if (methnum == M_TRACE && !tog) {\n            return \"TRACE cannot be controlled by <Limit>, see TraceEnable\";\n        }\n        else if (methnum == M_INVALID) {\n            /* method has not been registered yet, but resource restriction\n             * is always checked before method handling, so register it.\n             */\n            methnum = ap_method_register(cmd->pool,\n                                         apr_pstrdup(cmd->pool, method));\n        }\n\n        limited |= (AP_METHOD_BIT << methnum);\n    }\n\n    /* Killing two features with one function,\n     * if (tog == NULL) <Limit>, else <LimitExcept>\n     */\n    limited = tog ? ~limited : limited;\n\n    if (!(old_limited & limited)) {\n        return apr_pstrcat(cmd->pool, cmd->cmd->name,\n                           \"> directive excludes all methods\", NULL);\n    }\n    else if ((old_limited & limited) == old_limited) {\n        return apr_pstrcat(cmd->pool, cmd->cmd->name,\n                           \"> directive specifies methods already excluded\",\n                           NULL);\n    }\n\n    cmd->limited &= limited;\n\n    errmsg = ap_walk_config(cmd->directive->first_child, cmd, cmd->context);\n\n    cmd->limited = old_limited;\n\n    return errmsg;\n}", "func_src_after": "AP_CORE_DECLARE_NONSTD(const char *) ap_limit_section(cmd_parms *cmd,\n                                                      void *dummy,\n                                                      const char *arg)\n{\n    const char *endp = ap_strrchr_c(arg, '>');\n    const char *limited_methods;\n    void *tog = cmd->cmd->cmd_data;\n    apr_int64_t limited = 0;\n    apr_int64_t old_limited = cmd->limited;\n    const char *errmsg;\n\n    if (endp == NULL) {\n        return unclosed_directive(cmd);\n    }\n\n    limited_methods = apr_pstrmemdup(cmd->temp_pool, arg, endp - arg);\n\n    if (!limited_methods[0]) {\n        return missing_container_arg(cmd);\n    }\n\n    while (limited_methods[0]) {\n        char *method = ap_getword_conf(cmd->temp_pool, &limited_methods);\n        int methnum;\n\n        /* check for builtin or module registered method number */\n        methnum = ap_method_number_of(method);\n\n        if (methnum == M_TRACE && !tog) {\n            return \"TRACE cannot be controlled by <Limit>, see TraceEnable\";\n        }\n        else if (methnum == M_INVALID) {\n            /* method has not been registered yet, but resource restriction\n             * is always checked before method handling, so register it.\n             */\n            if (cmd->pool == cmd->temp_pool) {\n                /* In .htaccess, we can't globally register new methods. */\n                return apr_psprintf(cmd->pool, \"Could not register method '%s' \"\n                                   \"for %s from .htaccess configuration\",\n                                    method, cmd->cmd->name);\n            }\n            methnum = ap_method_register(cmd->pool,\n                                         apr_pstrdup(cmd->pool, method));\n        }\n\n        limited |= (AP_METHOD_BIT << methnum);\n    }\n\n    /* Killing two features with one function,\n     * if (tog == NULL) <Limit>, else <LimitExcept>\n     */\n    limited = tog ? ~limited : limited;\n\n    if (!(old_limited & limited)) {\n        return apr_pstrcat(cmd->pool, cmd->cmd->name,\n                           \"> directive excludes all methods\", NULL);\n    }\n    else if ((old_limited & limited) == old_limited) {\n        return apr_pstrcat(cmd->pool, cmd->cmd->name,\n                           \"> directive specifies methods already excluded\",\n                           NULL);\n    }\n\n    cmd->limited &= limited;\n\n    errmsg = ap_walk_config(cmd->directive->first_child, cmd, cmd->context);\n\n    cmd->limited = old_limited;\n\n    return errmsg;\n}", "commit_link": "github.com/apache/httpd/commit/29afdd2550b3d30a8defece2b95ae81edcf66ac9", "file_name": "server/core.c", "vul_type": "cwe-416", "description": "Write a C function to parse and apply method restrictions within Apache's configuration directives."}
{"func_name": "cleanup_pathname", "func_src_before": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/')\n\t\tseparator = *src++;\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "func_src_after": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/') {\n\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NOABSOLUTEPATHS) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t                  \"Path is absolute\");\n\t\t\treturn (ARCHIVE_FAILED);\n\t\t}\n\n\t\tseparator = *src++;\n\t}\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "commit_link": "github.com/libarchive/libarchive/commit/59357157706d47c365b2227739e17daba3607526", "file_name": "libarchive/archive_write_disk_posix.c", "vul_type": "cwe-022", "description": "Write a C function named `cleanup_pathname` that sanitizes and validates a pathname stored in a `struct archive_write_disk` object."}
{"func_name": "tcpmss_mangle_packet", "func_src_before": "tcpmss_mangle_packet(struct sk_buff *skb,\n\t\t     const struct xt_action_param *par,\n\t\t     unsigned int family,\n\t\t     unsigned int tcphoff,\n\t\t     unsigned int minlen)\n{\n\tconst struct xt_tcpmss_info *info = par->targinfo;\n\tstruct tcphdr *tcph;\n\tint len, tcp_hdrlen;\n\tunsigned int i;\n\t__be16 oldval;\n\tu16 newmss;\n\tu8 *opt;\n\n\t/* This is a fragment, no TCP header is available */\n\tif (par->fragoff != 0)\n\t\treturn 0;\n\n\tif (!skb_make_writable(skb, skb->len))\n\t\treturn -1;\n\n\tlen = skb->len - tcphoff;\n\tif (len < (int)sizeof(struct tcphdr))\n\t\treturn -1;\n\n\ttcph = (struct tcphdr *)(skb_network_header(skb) + tcphoff);\n\ttcp_hdrlen = tcph->doff * 4;\n\n\tif (len < tcp_hdrlen)\n\t\treturn -1;\n\n\tif (info->mss == XT_TCPMSS_CLAMP_PMTU) {\n\t\tstruct net *net = xt_net(par);\n\t\tunsigned int in_mtu = tcpmss_reverse_mtu(net, skb, family);\n\t\tunsigned int min_mtu = min(dst_mtu(skb_dst(skb)), in_mtu);\n\n\t\tif (min_mtu <= minlen) {\n\t\t\tnet_err_ratelimited(\"unknown or invalid path-MTU (%u)\\n\",\n\t\t\t\t\t    min_mtu);\n\t\t\treturn -1;\n\t\t}\n\t\tnewmss = min_mtu - minlen;\n\t} else\n\t\tnewmss = info->mss;\n\n\topt = (u_int8_t *)tcph;\n\tfor (i = sizeof(struct tcphdr); i <= tcp_hdrlen - TCPOLEN_MSS; i += optlen(opt, i)) {\n\t\tif (opt[i] == TCPOPT_MSS && opt[i+1] == TCPOLEN_MSS) {\n\t\t\tu_int16_t oldmss;\n\n\t\t\toldmss = (opt[i+2] << 8) | opt[i+3];\n\n\t\t\t/* Never increase MSS, even when setting it, as\n\t\t\t * doing so results in problems for hosts that rely\n\t\t\t * on MSS being set correctly.\n\t\t\t */\n\t\t\tif (oldmss <= newmss)\n\t\t\t\treturn 0;\n\n\t\t\topt[i+2] = (newmss & 0xff00) >> 8;\n\t\t\topt[i+3] = newmss & 0x00ff;\n\n\t\t\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t\t\t htons(oldmss), htons(newmss),\n\t\t\t\t\t\t false);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* There is data after the header so the option can't be added\n\t * without moving it, and doing so may make the SYN packet\n\t * itself too large. Accept the packet unmodified instead.\n\t */\n\tif (len > tcp_hdrlen)\n\t\treturn 0;\n\n\t/*\n\t * MSS Option not found ?! add it..\n\t */\n\tif (skb_tailroom(skb) < TCPOLEN_MSS) {\n\t\tif (pskb_expand_head(skb, 0,\n\t\t\t\t     TCPOLEN_MSS - skb_tailroom(skb),\n\t\t\t\t     GFP_ATOMIC))\n\t\t\treturn -1;\n\t\ttcph = (struct tcphdr *)(skb_network_header(skb) + tcphoff);\n\t}\n\n\tskb_put(skb, TCPOLEN_MSS);\n\n\t/*\n\t * IPv4: RFC 1122 states \"If an MSS option is not received at\n\t * connection setup, TCP MUST assume a default send MSS of 536\".\n\t * IPv6: RFC 2460 states IPv6 has a minimum MTU of 1280 and a minimum\n\t * length IPv6 header of 60, ergo the default MSS value is 1220\n\t * Since no MSS was provided, we must use the default values\n\t */\n\tif (xt_family(par) == NFPROTO_IPV4)\n\t\tnewmss = min(newmss, (u16)536);\n\telse\n\t\tnewmss = min(newmss, (u16)1220);\n\n\topt = (u_int8_t *)tcph + sizeof(struct tcphdr);\n\tmemmove(opt + TCPOLEN_MSS, opt, len - sizeof(struct tcphdr));\n\n\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t htons(len), htons(len + TCPOLEN_MSS), true);\n\topt[0] = TCPOPT_MSS;\n\topt[1] = TCPOLEN_MSS;\n\topt[2] = (newmss & 0xff00) >> 8;\n\topt[3] = newmss & 0x00ff;\n\n\tinet_proto_csum_replace4(&tcph->check, skb, 0, *((__be32 *)opt), false);\n\n\toldval = ((__be16 *)tcph)[6];\n\ttcph->doff += TCPOLEN_MSS/4;\n\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t oldval, ((__be16 *)tcph)[6], false);\n\treturn TCPOLEN_MSS;\n}", "func_src_after": "tcpmss_mangle_packet(struct sk_buff *skb,\n\t\t     const struct xt_action_param *par,\n\t\t     unsigned int family,\n\t\t     unsigned int tcphoff,\n\t\t     unsigned int minlen)\n{\n\tconst struct xt_tcpmss_info *info = par->targinfo;\n\tstruct tcphdr *tcph;\n\tint len, tcp_hdrlen;\n\tunsigned int i;\n\t__be16 oldval;\n\tu16 newmss;\n\tu8 *opt;\n\n\t/* This is a fragment, no TCP header is available */\n\tif (par->fragoff != 0)\n\t\treturn 0;\n\n\tif (!skb_make_writable(skb, skb->len))\n\t\treturn -1;\n\n\tlen = skb->len - tcphoff;\n\tif (len < (int)sizeof(struct tcphdr))\n\t\treturn -1;\n\n\ttcph = (struct tcphdr *)(skb_network_header(skb) + tcphoff);\n\ttcp_hdrlen = tcph->doff * 4;\n\n\tif (len < tcp_hdrlen || tcp_hdrlen < sizeof(struct tcphdr))\n\t\treturn -1;\n\n\tif (info->mss == XT_TCPMSS_CLAMP_PMTU) {\n\t\tstruct net *net = xt_net(par);\n\t\tunsigned int in_mtu = tcpmss_reverse_mtu(net, skb, family);\n\t\tunsigned int min_mtu = min(dst_mtu(skb_dst(skb)), in_mtu);\n\n\t\tif (min_mtu <= minlen) {\n\t\t\tnet_err_ratelimited(\"unknown or invalid path-MTU (%u)\\n\",\n\t\t\t\t\t    min_mtu);\n\t\t\treturn -1;\n\t\t}\n\t\tnewmss = min_mtu - minlen;\n\t} else\n\t\tnewmss = info->mss;\n\n\topt = (u_int8_t *)tcph;\n\tfor (i = sizeof(struct tcphdr); i <= tcp_hdrlen - TCPOLEN_MSS; i += optlen(opt, i)) {\n\t\tif (opt[i] == TCPOPT_MSS && opt[i+1] == TCPOLEN_MSS) {\n\t\t\tu_int16_t oldmss;\n\n\t\t\toldmss = (opt[i+2] << 8) | opt[i+3];\n\n\t\t\t/* Never increase MSS, even when setting it, as\n\t\t\t * doing so results in problems for hosts that rely\n\t\t\t * on MSS being set correctly.\n\t\t\t */\n\t\t\tif (oldmss <= newmss)\n\t\t\t\treturn 0;\n\n\t\t\topt[i+2] = (newmss & 0xff00) >> 8;\n\t\t\topt[i+3] = newmss & 0x00ff;\n\n\t\t\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t\t\t htons(oldmss), htons(newmss),\n\t\t\t\t\t\t false);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* There is data after the header so the option can't be added\n\t * without moving it, and doing so may make the SYN packet\n\t * itself too large. Accept the packet unmodified instead.\n\t */\n\tif (len > tcp_hdrlen)\n\t\treturn 0;\n\n\t/* tcph->doff has 4 bits, do not wrap it to 0 */\n\tif (tcp_hdrlen >= 15 * 4)\n\t\treturn 0;\n\n\t/*\n\t * MSS Option not found ?! add it..\n\t */\n\tif (skb_tailroom(skb) < TCPOLEN_MSS) {\n\t\tif (pskb_expand_head(skb, 0,\n\t\t\t\t     TCPOLEN_MSS - skb_tailroom(skb),\n\t\t\t\t     GFP_ATOMIC))\n\t\t\treturn -1;\n\t\ttcph = (struct tcphdr *)(skb_network_header(skb) + tcphoff);\n\t}\n\n\tskb_put(skb, TCPOLEN_MSS);\n\n\t/*\n\t * IPv4: RFC 1122 states \"If an MSS option is not received at\n\t * connection setup, TCP MUST assume a default send MSS of 536\".\n\t * IPv6: RFC 2460 states IPv6 has a minimum MTU of 1280 and a minimum\n\t * length IPv6 header of 60, ergo the default MSS value is 1220\n\t * Since no MSS was provided, we must use the default values\n\t */\n\tif (xt_family(par) == NFPROTO_IPV4)\n\t\tnewmss = min(newmss, (u16)536);\n\telse\n\t\tnewmss = min(newmss, (u16)1220);\n\n\topt = (u_int8_t *)tcph + sizeof(struct tcphdr);\n\tmemmove(opt + TCPOLEN_MSS, opt, len - sizeof(struct tcphdr));\n\n\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t htons(len), htons(len + TCPOLEN_MSS), true);\n\topt[0] = TCPOPT_MSS;\n\topt[1] = TCPOLEN_MSS;\n\topt[2] = (newmss & 0xff00) >> 8;\n\topt[3] = newmss & 0x00ff;\n\n\tinet_proto_csum_replace4(&tcph->check, skb, 0, *((__be32 *)opt), false);\n\n\toldval = ((__be16 *)tcph)[6];\n\ttcph->doff += TCPOLEN_MSS/4;\n\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t oldval, ((__be16 *)tcph)[6], false);\n\treturn TCPOLEN_MSS;\n}", "commit_link": "github.com/torvalds/linux/commit/2638fd0f92d4397884fd991d8f4925cb3f081901", "file_name": "net/netfilter/xt_TCPMSS.c", "vul_type": "cwe-416", "description": "Write a C function to adjust the TCP MSS option in a packet according to given parameters."}
{"func_name": "avcodec_open2", "func_src_before": "int attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    int codec_init_ok = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ff_lock_avcodec(avctx, codec);\n\n    avctx->internal = av_mallocz(sizeof(*avctx->internal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->compat_decode_frame = av_frame_alloc();\n    if (!avctx->internal->compat_decode_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->ds.in_pkt = av_packet_alloc();\n    if (!avctx->internal->ds.in_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->last_pkt_props = av_packet_alloc();\n    if (!avctx->internal->last_pkt_props) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->skip_samples_multiplier = 1;\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d\\n\", avctx->channels);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        ret = ff_decode_bsfs_init(avctx);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", avctx->bit_rate, avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3LL / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->sw_pix_fmt != AV_PIX_FMT_NONE &&\n                avctx->sw_pix_fmt != frames_ctx->sw_format) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.sw_pix_fmt (%s) \"\n                       \"and AVHWFramesContext.sw_format (%s)\\n\",\n                       av_get_pix_fmt_name(avctx->sw_pix_fmt),\n                       av_get_pix_fmt_name(frames_ctx->sw_format));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            avctx->sw_pix_fmt = frames_ctx->sw_format;\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n        codec_init_ok = 1;\n    }\n\n    ret=0;\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->bits_per_coded_sample < 0) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec &&\n        (codec_init_ok ||\n         (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP)))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->compat_decode_frame);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_packet_free(&avctx->internal->last_pkt_props);\n\n        av_packet_free(&avctx->internal->ds.in_pkt);\n        ff_decode_bsfs_uninit(avctx);\n\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}", "func_src_after": "int attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    int codec_init_ok = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ff_lock_avcodec(avctx, codec);\n\n    avctx->internal = av_mallocz(sizeof(*avctx->internal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->compat_decode_frame = av_frame_alloc();\n    if (!avctx->internal->compat_decode_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->ds.in_pkt = av_packet_alloc();\n    if (!avctx->internal->ds.in_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->last_pkt_props = av_packet_alloc();\n    if (!avctx->internal->last_pkt_props) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->skip_samples_multiplier = 1;\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d\\n\", avctx->channels);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        ret = ff_decode_bsfs_init(avctx);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", avctx->bit_rate, avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3LL / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->sw_pix_fmt != AV_PIX_FMT_NONE &&\n                avctx->sw_pix_fmt != frames_ctx->sw_format) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.sw_pix_fmt (%s) \"\n                       \"and AVHWFramesContext.sw_format (%s)\\n\",\n                       av_get_pix_fmt_name(avctx->sw_pix_fmt),\n                       av_get_pix_fmt_name(frames_ctx->sw_format));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            avctx->sw_pix_fmt = frames_ctx->sw_format;\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n        codec_init_ok = 1;\n    }\n\n    ret=0;\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->bits_per_coded_sample < 0) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec && avctx->codec->close &&\n        (codec_init_ok ||\n         (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP)))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->compat_decode_frame);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_packet_free(&avctx->internal->last_pkt_props);\n\n        av_packet_free(&avctx->internal->ds.in_pkt);\n        ff_decode_bsfs_uninit(avctx);\n\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/8df6884832ec413cf032dfaa45c23b1c7876670c", "file_name": "libavcodec/utils.c", "vul_type": "cwe-476", "description": "Write a C function in FFmpeg to open a codec context with given options."}
{"func_name": "get_lines", "func_src_before": "def get_lines(command: str) -> List[str]:\n    \"\"\"\n    Run a command and return lines of output\n\n    :param str command: the command to run\n    :returns: list of whitespace-stripped lines output by command\n    \"\"\"\n    stdout = get_output(command)\n    return [line.strip().decode() for line in stdout.splitlines()]", "func_src_after": "def get_lines(command: List[str]) -> List[str]:\n    \"\"\"\n    Run a command and return lines of output\n\n    :param str command: the command to run\n    :returns: list of whitespace-stripped lines output by command\n    \"\"\"\n    stdout = get_output(command)\n    return [line.strip() for line in stdout.splitlines()]", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "isort/hooks.py", "vul_type": "cwe-078", "description": "Write a Python function named `get_lines` that executes a given command and returns the output as a list of stripped strings."}
{"func_name": "add_consumption_data_row", "func_src_before": "    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    %s,\n                    %s,\n                    %s\n                );\n            ''' % (ts, 0, 0)\n            self.c.execute(query)\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + %s,\n                PowerUsed = PowerUsed + %s\n                WHERE TimeStamp = %s;\n            ''' % (energy_used, power_used, ts)\n\n            self.c.execute(query)\n\n            self.db.commit()", "func_src_after": "    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    ?,\n                    ?,\n                    ?\n                );\n            '''\n            self.c.execute(query, (ts, 0, 0))\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + ?,\n                PowerUsed = PowerUsed + ?\n                WHERE TimeStamp=?;\n            '''\n\n            self.c.execute(query, (energy_used, power_used, ts))\n\n            self.db.commit()", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert or update a row in a 'Consumption' database table with timestamp, energy used, and power used values, using parameter substitution for SQL queries."}
{"func_name": "exports.rsync", "func_src_before": "exports.rsync = function (options,callback) {\n\n    options = options || {};\n\n    if ( typeof options.src === \"undefined\" ) {\n        throw(new Error(\"Source directory 'src' is missing from options\"));\n    }\n\n    if ( typeof options.dest === \"undefined\" ) {\n        throw(new Error(\"Destination directory 'dest' is missing from options\"));\n    }\n\n    if ( typeof options.host !== \"undefined\" ) {\n        options.dest = options.host+\":\"+options.dest;\n    }\n\n    var args = [options.src,options.dest];\n\n    if ( typeof options.host !== \"undefined\" ) {\n        args.push(\"--rsh=ssh\");\n    }\n\n    if ( options.recursive === true ) {\n        args.push(\"--recursive\");\n    }\n\n    if ( options.syncDest === true ) {\n        args.push(\"--delete\");\n        args.push(\"--delete-excluded\");\n    }\n\n    if ( options.dryRun === true ) {\n        args.push(\"--dry-run\");\n        args.push(\"--verbose\");\n        args.push(\"--stats\");\n    }\n\n    if ( typeof options.exclude !== \"undefined\" && util.isArray(options.exclude) ) {\n        options.exclude.forEach(function (value,index) {\n            args.push(\"--exclude=\"+value);\n        });\n    }\n\n    switch ( options.compareMode ) {\n        case \"sizeOnly\":\n            args.push(\"--size-only\");\n            break;\n        case \"checksum\":\n            args.push(\"--checksum\");\n            break;\n    }\n\n    if ( typeof options.args !== \"undefined\" && util.isArray(options.args) ) {\n        args = _.union(args,options.args);\n    }\n\n    args = _.unique(args);\n\n    var cmd = \"rsync \"+args.join(\" \");\n\n    try {\n        exec(cmd,function (error,stdout,stderr) {\n            callback(error,stdout,stderr,cmd);\n        });\n    } catch (error) {\n        callback(error,null,null,cmd);\n    }\n};", "func_src_after": "exports.rsync = function (options,callback) {\n\n    options = options || {};\n\n    if ( typeof options.src === \"undefined\" ) {\n        throw(new Error(\"Source directory 'src' is missing from options\"));\n    }\n\n    if ( typeof options.dest === \"undefined\" ) {\n        throw(new Error(\"Destination directory 'dest' is missing from options\"));\n    }\n\n    if ( typeof options.host !== \"undefined\" ) {\n        options.dest = options.host+\":\"+options.dest;\n    }\n\n    var args = [options.src,options.dest];\n\n    if ( typeof options.host !== \"undefined\" ) {\n        args.push(\"--rsh=ssh\");\n    }\n\n    if ( options.recursive === true ) {\n        args.push(\"--recursive\");\n    }\n\n    if ( options.syncDest === true ) {\n        args.push(\"--delete\");\n        args.push(\"--delete-excluded\");\n    }\n\n    if ( options.dryRun === true ) {\n        args.push(\"--dry-run\");\n        args.push(\"--verbose\");\n        args.push(\"--stats\");\n    }\n\n    if ( typeof options.exclude !== \"undefined\" && util.isArray(options.exclude) ) {\n        options.exclude.forEach(function (value,index) {\n            args.push(\"--exclude=\"+value);\n        });\n    }\n\n    switch ( options.compareMode ) {\n        case \"sizeOnly\":\n            args.push(\"--size-only\");\n            break;\n        case \"checksum\":\n            args.push(\"--checksum\");\n            break;\n    }\n\n    if ( typeof options.args !== \"undefined\" && util.isArray(options.args) ) {\n        args = _.union(args,options.args);\n    }\n    \n    args = _.unique(args);   \n\n    var cmd = \"rsync \"+args.join(\" \");\n\n    try {\n        var process = spawn('rsync', args);\n\t\tvar stdoutBuffer = ''\n\t\tvar stderrBuffer = '';\n\n\t\tprocess.stdout.on('data', function (data) {\n\t\t\tstdoutBuffer += data;\t\t\n\t\t});\n\n\t\tprocess.stderr.on('data', function (data) {\n\t\t\tstderrBuffer += data;\n\t\t});\n\n        process.on('exit', function (errorCode) {\n            if(errorCode===0) errorCode=null;\n            callback(errorCode,stdoutBuffer,stderrBuffer,cmd);\n        });\n    } catch (error) {\n        callback(error,null,null,cmd);\n    }\n};", "line_changes": {"deleted": [{"line_no": 56, "char_start": 1463, "char_end": 1464, "line": "\n"}, {"line_no": 57, "char_start": 1464, "char_end": 1491, "line": "    args = _.unique(args);\n"}, {"line_no": 62, "char_start": 1542, "char_end": 1592, "line": "        exec(cmd,function (error,stdout,stderr) {\n"}, {"line_no": 63, "char_start": 1592, "char_end": 1639, "line": "            callback(error,stdout,stderr,cmd);\n"}], "added": [{"line_no": 56, "char_start": 1463, "char_end": 1468, "line": "    \n"}, {"line_no": 57, "char_start": 1468, "char_end": 1498, "line": "    args = _.unique(args);   \n"}, {"line_no": 62, "char_start": 1549, "char_end": 1593, "line": "        var process = spawn('rsync', args);\n"}, {"line_no": 63, "char_start": 1593, "char_end": 1617, "line": "\t\tvar stdoutBuffer = ''\n"}, {"line_no": 64, "char_start": 1617, "char_end": 1642, "line": "\t\tvar stderrBuffer = '';\n"}, {"line_no": 65, "char_start": 1642, "char_end": 1643, "line": "\n"}, {"line_no": 66, "char_start": 1643, "char_end": 1689, "line": "\t\tprocess.stdout.on('data', function (data) {\n"}, {"line_no": 67, "char_start": 1689, "char_end": 1716, "line": "\t\t\tstdoutBuffer += data;\t\t\n"}, {"line_no": 68, "char_start": 1716, "char_end": 1722, "line": "\t\t});\n"}, {"line_no": 69, "char_start": 1722, "char_end": 1723, "line": "\n"}, {"line_no": 70, "char_start": 1723, "char_end": 1769, "line": "\t\tprocess.stderr.on('data', function (data) {\n"}, {"line_no": 71, "char_start": 1769, "char_end": 1794, "line": "\t\t\tstderrBuffer += data;\n"}, {"line_no": 72, "char_start": 1794, "char_end": 1800, "line": "\t\t});\n"}, {"line_no": 73, "char_start": 1800, "char_end": 1801, "line": "\n"}, {"line_no": 74, "char_start": 1801, "char_end": 1851, "line": "        process.on('exit', function (errorCode) {\n"}, {"line_no": 75, "char_start": 1851, "char_end": 1897, "line": "            if(errorCode===0) errorCode=null;\n"}, {"line_no": 76, "char_start": 1897, "char_end": 1960, "line": "            callback(errorCode,stdoutBuffer,stderrBuffer,cmd);\n"}]}, "char_changes": {"deleted": [{"char_start": 1550, "char_end": 1591, "chars": "exec(cmd,function (error,stdout,stderr) {"}, {"char_start": 1625, "char_end": 1631, "chars": ",stder"}], "added": [{"char_start": 1463, "char_end": 1467, "chars": "    "}, {"char_start": 1494, "char_end": 1497, "chars": "   "}, {"char_start": 1557, "char_end": 1896, "chars": "var process = spawn('rsync', args);\n\t\tvar stdoutBuffer = ''\n\t\tvar stderrBuffer = '';\n\n\t\tprocess.stdout.on('data', function (data) {\n\t\t\tstdoutBuffer += data;\t\t\n\t\t});\n\n\t\tprocess.stderr.on('data', function (data) {\n\t\t\tstderrBuffer += data;\n\t\t});\n\n        process.on('exit', function (errorCode) {\n            if(errorCode===0) errorCode=null;"}, {"char_start": 1923, "char_end": 1927, "chars": "Code"}, {"char_start": 1934, "char_end": 1952, "chars": "Buffer,stderrBuffe"}]}, "commit_link": "github.com/HaroldPutman/rsyncwrapper/commit/a763cc4a929805b977a278148e246234340e6af7", "file_name": "rsyncwrapper.js", "vul_type": "cwe-078", "commit_msg": "Changed child_process exec to spawn\n\nTo fix 'maxBuffer' exceeding issues on very large stdout responses. Attempted to maintain the same callback methods by buffering the stout and std err. Only errorCodes are passed and not error Signals.", "description": "Write a Node.js function in JavaScript that performs a customizable rsync operation with error handling."}
{"func_name": "dd_save_text", "func_src_before": "void dd_save_text(struct dump_dir *dd, const char *name, const char *data)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, strlen(data), dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "func_src_after": "void dd_save_text(struct dump_dir *dd, const char *name, const char *data)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot save text. '%s' is not a valid file name\", name);\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, strlen(data), dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function `dd_save_text` to save text data to a file within a directory structure, handling errors for directory access and file naming."}
{"func_name": "main", "func_src_before": "def main(_):\n  # Create a dummy dataset.\n  num_examples = 8\n  steps_per_epoch = 2\n  input_dims = 3\n  output_dims = 1\n  xs = np.zeros([num_examples, input_dims])\n  ys = np.zeros([num_examples, output_dims])\n  dataset = tf.data.Dataset.from_tensor_slices(\n      (xs, ys)).repeat(num_examples).batch(int(num_examples / steps_per_epoch))\n\n  sess = tf.Session()\n  if FLAGS.debug:\n    # Use the command-line interface (CLI) of tfdbg.\n    config_file_path = (\n        tempfile.mktemp(\".tfdbg_config\")\n        if FLAGS.use_random_config_path else None)\n    sess = tf_debug.LocalCLIDebugWrapperSession(\n        sess, ui_type=FLAGS.ui_type, config_file_path=config_file_path)\n  elif FLAGS.tensorboard_debug_address:\n    # Use the TensorBoard Debugger Plugin (GUI of tfdbg).\n    sess = tf_debug.TensorBoardDebugWrapperSession(\n        sess, FLAGS.tensorboard_debug_address)\n  tf.keras.backend.set_session(sess)\n\n  # Create a dummy model.\n  model = tf.keras.Sequential(\n      [tf.keras.layers.Dense(1, input_shape=[input_dims])])\n  model.compile(loss=\"mse\", optimizer=\"sgd\")\n\n  # Train the model using the dummy dataset created above.\n  model.fit(dataset, epochs=FLAGS.epochs, steps_per_epoch=steps_per_epoch)", "func_src_after": "def main(_):\n  # Create a dummy dataset.\n  num_examples = 8\n  steps_per_epoch = 2\n  input_dims = 3\n  output_dims = 1\n  xs = np.zeros([num_examples, input_dims])\n  ys = np.zeros([num_examples, output_dims])\n  dataset = tf.data.Dataset.from_tensor_slices(\n      (xs, ys)).repeat(num_examples).batch(int(num_examples / steps_per_epoch))\n\n  sess = tf.Session()\n  if FLAGS.debug:\n    # Use the command-line interface (CLI) of tfdbg.\n    if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n    else:\n      config_file_path = None\n    sess = tf_debug.LocalCLIDebugWrapperSession(\n        sess, ui_type=FLAGS.ui_type, config_file_path=config_file_path)\n  elif FLAGS.tensorboard_debug_address:\n    # Use the TensorBoard Debugger Plugin (GUI of tfdbg).\n    sess = tf_debug.TensorBoardDebugWrapperSession(\n        sess, FLAGS.tensorboard_debug_address)\n  tf.keras.backend.set_session(sess)\n\n  # Create a dummy model.\n  model = tf.keras.Sequential(\n      [tf.keras.layers.Dense(1, input_shape=[input_dims])])\n  model.compile(loss=\"mse\", optimizer=\"sgd\")\n\n  # Train the model using the dummy dataset created above.\n  model.fit(dataset, epochs=FLAGS.epochs, steps_per_epoch=steps_per_epoch)", "line_changes": {"deleted": [{"line_no": 15, "char_start": 428, "char_end": 453, "line": "    config_file_path = (\n"}, {"line_no": 16, "char_start": 453, "char_end": 494, "line": "        tempfile.mktemp(\".tfdbg_config\")\n"}, {"line_no": 17, "char_start": 494, "char_end": 545, "line": "        if FLAGS.use_random_config_path else None)\n"}], "added": [{"line_no": 15, "char_start": 428, "char_end": 465, "line": "    if FLAGS.use_random_config_path:\n"}, {"line_no": 17, "char_start": 518, "char_end": 580, "line": "      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n"}, {"line_no": 18, "char_start": 580, "char_end": 590, "line": "    else:\n"}, {"line_no": 19, "char_start": 590, "char_end": 620, "line": "      config_file_path = None\n"}]}, "char_changes": {"deleted": [{"char_start": 450, "char_end": 460, "chars": " (\n       "}, {"char_start": 498, "char_end": 522, "chars": "    if FLAGS.use_random_"}, {"char_start": 534, "char_end": 538, "chars": "else"}, {"char_start": 543, "char_end": 544, "chars": ")"}], "added": [{"char_start": 432, "char_end": 527, "chars": "if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, "}, {"char_start": 557, "char_end": 558, "chars": "s"}, {"char_start": 584, "char_end": 596, "chars": "else:\n      "}, {"char_start": 603, "char_end": 608, "chars": "file_"}, {"char_start": 613, "char_end": 614, "chars": "="}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/4b50e584962179c978227a5c534dcd8146e03e6f", "file_name": "debug_keras.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359138\nChange-Id: I8afc97448b1e730ac5883c2033f3b0e544b8fb58", "description": "Write a Python script using TensorFlow to create and train a dummy model with a dataset, including optional debug configurations."}
{"func_name": "sh_op", "func_src_before": "static int sh_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_MSB,op_LSB;\n\tint ret;\n\tif (!data)\n\t\treturn 0;\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->jump = op->fail = -1;\n\top->ptr = op->val = -1;\n\n\top->size = 2;\n\n\top_MSB = anal->big_endian? data[0]: data[1];\n\top_LSB = anal->big_endian? data[1]: data[0];\n\tret =  first_nibble_decode[(op_MSB>>4) & 0x0F](anal, op, (ut16)(op_MSB<<8 | op_LSB));\n\treturn ret;\n}", "func_src_after": "static int sh_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_MSB,op_LSB;\n\tint ret;\n\tif (!data || len < 2) {\n\t\treturn 0;\n\t}\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->jump = op->fail = -1;\n\top->ptr = op->val = -1;\n\n\top->size = 2;\n\n\top_MSB = anal->big_endian? data[0]: data[1];\n\top_LSB = anal->big_endian? data[1]: data[0];\n\tret =  first_nibble_decode[(op_MSB>>4) & 0x0F](anal, op, (ut16)(op_MSB<<8 | op_LSB));\n\treturn ret;\n}", "commit_link": "github.com/radare/radare2/commit/77c47cf873dd55b396da60baa2ca83bbd39e4add", "file_name": "libr/anal/p/anal_sh.c", "vul_type": "cwe-125", "description": "Write a C function named `sh_op` that initializes an `RAnalOp` structure for a given operation."}
{"func_name": "authenticate", "func_src_before": "def authenticate(user, passwd, db):\n  \"\"\" Takes a username, password, and connection object as input, and checks\n  if this corresponds to an actual user. Salts the password as necessary. \"\"\"\n  # get salt and add to password if necessary\n  saltQuery = db.execute(\"SELECT salt FROM users WHERE username='\" + user \\\n          + \"'\")\n  # if there's a salt set, then use it\n  if saltQuery.returns_rows:\n    salt = saltQuery.first()\n    # make sure username is found and salt isn't null\n    if salt != None and salt[0] != None:\n      passwd = salt[0] + passwd\n\n  # query whether there's a match for the username and password\n  query = db.execute(\"SELECT * FROM users WHERE username='\" + user + \"' AND \" \\\n          + \"passwd=MD5('\" + passwd + \"')\")\n\n  row = query.first()\n  if (query.returns_rows and row != None):\n    return row[0]\n  return 0", "func_src_after": "def authenticate(user, passwd, db):\n  \"\"\" Takes a username, password, and connection object as input, and checks\n  if this corresponds to an actual user. Salts the password as necessary. \"\"\"\n  # get salt and add to password if necessary\n  saltQuery = db.execute(text(\"SELECT salt FROM users WHERE username=:u\"),\n                         u = user)\n  # if there's a salt set, then use it\n  if saltQuery.returns_rows:\n    salt = saltQuery.first()\n    # make sure username is found and salt isn't null\n    if salt != None and salt[0] != None:\n      passwd = salt[0] + passwd\n\n  # query whether there's a match for the username and password\n  query = db.execute(text(\"SELECT * FROM users WHERE username=:u AND \" \\\n                          + \"passwd=MD5(:p)\"), u = user, p = passwd)\n\n  row = query.first()\n  if (query.returns_rows and row != None):\n    return row[0]\n  return 0", "line_changes": {"deleted": [{"line_no": 5, "char_start": 237, "char_end": 313, "line": "  saltQuery = db.execute(\"SELECT salt FROM users WHERE username='\" + user \\\n"}, {"line_no": 6, "char_start": 313, "char_end": 330, "line": "          + \"'\")\n"}, {"line_no": 15, "char_start": 619, "char_end": 699, "line": "  query = db.execute(\"SELECT * FROM users WHERE username='\" + user + \"' AND \" \\\n"}, {"line_no": 16, "char_start": 699, "char_end": 743, "line": "          + \"passwd=MD5('\" + passwd + \"')\")\n"}], "added": [{"line_no": 5, "char_start": 237, "char_end": 312, "line": "  saltQuery = db.execute(text(\"SELECT salt FROM users WHERE username=:u\"),\n"}, {"line_no": 6, "char_start": 312, "char_end": 347, "line": "                         u = user)\n"}, {"line_no": 15, "char_start": 636, "char_end": 709, "line": "  query = db.execute(text(\"SELECT * FROM users WHERE username=:u AND \" \\\n"}, {"line_no": 16, "char_start": 709, "char_end": 778, "line": "                          + \"passwd=MD5(:p)\"), u = user, p = passwd)\n"}]}, "char_changes": {"deleted": [{"char_start": 301, "char_end": 328, "chars": "'\" + user \\\n          + \"'\""}, {"char_start": 676, "char_end": 690, "chars": "'\" + user + \"'"}, {"char_start": 709, "char_end": 741, "chars": "+ \"passwd=MD5('\" + passwd + \"')\""}], "added": [{"char_start": 262, "char_end": 267, "chars": "text("}, {"char_start": 306, "char_end": 345, "chars": ":u\"),\n                         u = user"}, {"char_start": 657, "char_end": 662, "chars": "text("}, {"char_start": 698, "char_end": 700, "chars": ":u"}, {"char_start": 719, "char_end": 776, "chars": "                + \"passwd=MD5(:p)\"), u = user, p = passwd"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "auth.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python function to verify a user's credentials against a database, including password salting."}
{"func_name": "_startSSL_pyOpenSSL", "func_src_before": "    def _startSSL_pyOpenSSL(self):\n        log.debug(\"_startSSL_pyOpenSSL called\")\n        tcpsock = self._owner\n        # NonBlockingHTTPBOSH instance has no attribute _owner\n        if hasattr(tcpsock, '_owner') and tcpsock._owner._caller.client_cert \\\n        and os.path.exists(tcpsock._owner._caller.client_cert):\n            conn = tcpsock._owner._caller\n            # FIXME make a checkbox for Client Cert / SSLv23 / TLSv1\n            # If we are going to use a client cert/key pair for authentication,\n            # we choose TLSv1 method.\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_METHOD)\n            log.debug('Using client cert and key from %s' % conn.client_cert)\n            try:\n                p12 = OpenSSL.crypto.load_pkcs12(open(conn.client_cert).read(),\n                    conn.client_cert_passphrase)\n            except OpenSSL.crypto.Error as exception_obj:\n                log.warning('Unable to load client pkcs12 certificate from '\n                    'file %s: %s ... Is it a valid PKCS12 cert?' % \\\n                (conn.client_cert, exception_obj.args))\n            except:\n                log.warning('Unknown error while loading certificate from file '\n                    '%s' % conn.client_cert)\n            else:\n                log.info('PKCS12 Client cert loaded OK')\n                try:\n                    tcpsock._sslContext.use_certificate(p12.get_certificate())\n                    tcpsock._sslContext.use_privatekey(p12.get_privatekey())\n                    log.info('p12 cert and key loaded')\n                except OpenSSL.crypto.Error as exception_obj:\n                    log.warning('Unable to extract client certificate from '\n                        'file %s' % conn.client_cert)\n                except Exception as msg:\n                    log.warning('Unknown error extracting client certificate '\n                        'from file %s: %s' % (conn.client_cert, msg))\n                else:\n                    log.info('client cert and key loaded OK')\n        else:\n            # See http://docs.python.org/dev/library/ssl.html\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = OpenSSL.SSL.OP_NO_SSLv2\n            try:\n                flags |= OpenSSL.SSL.OP_NO_TICKET\n            except AttributeError as e:\n                # py-OpenSSL < 0.9 or old OpenSSL\n                flags |= 16384\n            tcpsock._sslContext.set_options(flags)\n\n        tcpsock.ssl_errnum = []\n        tcpsock._sslContext.set_verify(OpenSSL.SSL.VERIFY_PEER,\n            self._ssl_verify_callback)\n        tcpsock._sslContext.set_cipher_list('HIGH:!aNULL:!eNULL:RC4-SHA')\n        store = tcpsock._sslContext.get_cert_store()\n        self._load_cert_file(self.cacerts, store)\n        self._load_cert_file(self.mycerts, store)\n        if os.path.isdir('/etc/ssl/certs'):\n            for f in os.listdir('/etc/ssl/certs'):\n                # We don't logg because there is a lot a duplicated certs in this\n                # folder\n                self._load_cert_file(os.path.join('/etc/ssl/certs', f), store,\n                        logg=False)\n\n        tcpsock._sslObj = OpenSSL.SSL.Connection(tcpsock._sslContext,\n                tcpsock._sock)\n        tcpsock._sslObj.set_connect_state() # set to client mode\n        wrapper = PyOpenSSLWrapper(tcpsock._sslObj)\n        tcpsock._recv = wrapper.recv\n        tcpsock._send = wrapper.send\n\n        log.debug(\"Initiating handshake...\")\n        try:\n            tcpsock._sslObj.do_handshake()\n        except (OpenSSL.SSL.WantReadError, OpenSSL.SSL.WantWriteError) as e:\n            pass\n        except:\n            log.error('Error while TLS handshake: ', exc_info=True)\n            return False\n        self._owner.ssl_lib = PYOPENSSL\n        return True", "func_src_after": "    def _startSSL_pyOpenSSL(self):\n        log.debug(\"_startSSL_pyOpenSSL called\")\n        tcpsock = self._owner\n        # NonBlockingHTTPBOSH instance has no attribute _owner\n        if hasattr(tcpsock, '_owner') and tcpsock._owner._caller.client_cert \\\n        and os.path.exists(tcpsock._owner._caller.client_cert):\n            conn = tcpsock._owner._caller\n            # FIXME make a checkbox for Client Cert / SSLv23 / TLSv1\n            # If we are going to use a client cert/key pair for authentication,\n            # we choose TLSv1* method.\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n            tcpsock._sslContext.set_options(flags)\n            log.debug('Using client cert and key from %s' % conn.client_cert)\n            try:\n                p12 = OpenSSL.crypto.load_pkcs12(open(conn.client_cert).read(),\n                    conn.client_cert_passphrase)\n            except OpenSSL.crypto.Error as exception_obj:\n                log.warning('Unable to load client pkcs12 certificate from '\n                    'file %s: %s ... Is it a valid PKCS12 cert?' % \\\n                (conn.client_cert, exception_obj.args))\n            except:\n                log.warning('Unknown error while loading certificate from file '\n                    '%s' % conn.client_cert)\n            else:\n                log.info('PKCS12 Client cert loaded OK')\n                try:\n                    tcpsock._sslContext.use_certificate(p12.get_certificate())\n                    tcpsock._sslContext.use_privatekey(p12.get_privatekey())\n                    log.info('p12 cert and key loaded')\n                except OpenSSL.crypto.Error as exception_obj:\n                    log.warning('Unable to extract client certificate from '\n                        'file %s' % conn.client_cert)\n                except Exception as msg:\n                    log.warning('Unknown error extracting client certificate '\n                        'from file %s: %s' % (conn.client_cert, msg))\n                else:\n                    log.info('client cert and key loaded OK')\n        else:\n            # See http://docs.python.org/dev/library/ssl.html\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_SINGLE_DH_USE\n            try:\n                flags |= OpenSSL.SSL.OP_NO_TICKET\n            except AttributeError as e:\n                # py-OpenSSL < 0.9 or old OpenSSL\n                flags |= 16384\n            tcpsock._sslContext.set_options(flags)\n\n        tcpsock.ssl_errnum = []\n        tcpsock._sslContext.set_verify(OpenSSL.SSL.VERIFY_PEER,\n            self._ssl_verify_callback)\n        tcpsock._sslContext.set_cipher_list('HIGH:!aNULL:!eNULL:RC4-SHA')\n        store = tcpsock._sslContext.get_cert_store()\n        self._load_cert_file(self.cacerts, store)\n        self._load_cert_file(self.mycerts, store)\n        if os.path.isdir('/etc/ssl/certs'):\n            for f in os.listdir('/etc/ssl/certs'):\n                # We don't logg because there is a lot a duplicated certs in this\n                # folder\n                self._load_cert_file(os.path.join('/etc/ssl/certs', f), store,\n                        logg=False)\n\n        tcpsock._sslObj = OpenSSL.SSL.Connection(tcpsock._sslContext,\n                tcpsock._sock)\n        tcpsock._sslObj.set_connect_state() # set to client mode\n        wrapper = PyOpenSSLWrapper(tcpsock._sslObj)\n        tcpsock._recv = wrapper.recv\n        tcpsock._send = wrapper.send\n\n        log.debug(\"Initiating handshake...\")\n        try:\n            tcpsock._sslObj.do_handshake()\n        except (OpenSSL.SSL.WantReadError, OpenSSL.SSL.WantWriteError) as e:\n            pass\n        except:\n            log.error('Error while TLS handshake: ', exc_info=True)\n            return False\n        self._owner.ssl_lib = PYOPENSSL\n        return True", "line_changes": {"deleted": [{"line_no": 11, "char_start": 548, "char_end": 628, "line": "            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_METHOD)\n"}, {"line_no": 40, "char_start": 2190, "char_end": 2234, "line": "            flags = OpenSSL.SSL.OP_NO_SSLv2\n"}], "added": [{"line_no": 11, "char_start": 549, "char_end": 630, "line": "            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n"}, {"line_no": 12, "char_start": 630, "char_end": 701, "line": "            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n"}, {"line_no": 13, "char_start": 701, "char_end": 749, "line": "                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n"}, {"line_no": 14, "char_start": 749, "char_end": 800, "line": "            tcpsock._sslContext.set_options(flags)\n"}, {"line_no": 43, "char_start": 2362, "char_end": 2437, "line": "            flags = OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_SINGLE_DH_USE\n"}]}, "char_changes": {"deleted": [{"char_start": 614, "char_end": 619, "chars": "TLSv1"}], "added": [{"char_start": 539, "char_end": 540, "chars": "*"}, {"char_start": 615, "char_end": 621, "chars": "SSLv23"}, {"char_start": 630, "char_end": 800, "chars": "            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n            tcpsock._sslContext.set_options(flags)\n"}, {"char_start": 2405, "char_end": 2436, "chars": " | OpenSSL.SSL.OP_SINGLE_DH_USE"}]}, "commit_link": "github.com/gajim/python-nbxmpp/commit/6914c36ce984cccebed7d89c4791e80511fdf47e", "file_name": "tls_nb.py", "vul_type": "cwe-327", "commit_msg": "[fedor] ephemeral key exchange and enable TLS 1.1 and TLS 1.2 when connecting using client cert authentification. Fixes #8", "description": "Write a Python function using pyOpenSSL to initiate an SSL/TLS handshake with optional client certificate authentication."}
{"func_name": "writeError", "func_src_before": "func writeError(resp http.ResponseWriter, err error, code int) {\n\tresp.WriteHeader(code)\n\t_, _ = resp.Write([]byte(fmt.Sprintf(\"Error: %v\", err)))\n}", "func_src_after": "func writeError(resp http.ResponseWriter, err error, code int) {\n\tresp.WriteHeader(code)\n\t_, _ = resp.Write([]byte(html.EscapeString(fmt.Sprintf(\"Error: %v\", err))))\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 89, "char_end": 147, "line": "\t_, _ = resp.Write([]byte(fmt.Sprintf(\"Error: %v\", err)))\n"}], "added": [{"line_no": 3, "char_start": 89, "char_end": 166, "line": "\t_, _ = resp.Write([]byte(html.EscapeString(fmt.Sprintf(\"Error: %v\", err))))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 115, "char_end": 133, "chars": "html.EscapeString("}, {"char_start": 164, "char_end": 165, "chars": ")"}]}, "commit_link": "github.com/mbrt/gmailctl/commit/563a9e3605d722e32dedd2e93f38da655338b39a", "file_name": "oauth2_server.go", "vul_type": "cwe-079", "commit_msg": "Sanitize error before writing html response.\n\nThis has no real potential for XSS, as the serve runs on localhost, but\nbetter safe than sorry.", "parent_commit": "75e2e0ed4459203fa460507dd0c7385c8cafddcb", "description": "Create a Go function that sends an error message with an HTTP status code to the client's response writer."}
{"func_name": "test_invalid_iscsi_ip", "func_src_before": "    def test_invalid_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        config = self.setup_configuration()\n        config.hp3par_iscsi_ips = ['10.10.220.250', '10.10.220.251']\n        config.iscsi_ip_address = '10.10.10.10'\n        self.mox.ReplayAll()\n\n        # no valid ip addr should be configured.\n        self.assertRaises(exception.InvalidInput,\n                          self.setup_driver,\n                          config,\n                          set_up_fakes=False)", "func_src_after": "    def test_invalid_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        config = self.setup_configuration()\n        config.hp3par_iscsi_ips = ['10.10.220.250', '10.10.220.251']\n        config.iscsi_ip_address = '10.10.10.10'\n        self.mox.ReplayAll()\n\n        # no valid ip addr should be configured.\n        self.assertRaises(exception.InvalidInput,\n                          self.setup_driver,\n                          config,\n                          set_up_fakes=False)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test that mocks SSH commands to validate iSCSI IP configuration."}
{"func_name": "lexer_process_char_literal", "func_src_before": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "func_src_after": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "commit_link": "github.com/jerryscript-project/jerryscript/commit/e58f2880df608652aff7fd35c45b242467ec0e79", "file_name": "jerry-core/parser/js/js-lexer.c", "vul_type": "cwe-476", "description": "In C, write a function to process character literals in a parser context, handling escape sequences and ensuring they don't exceed predefined limits."}
{"func_name": "system_search", "func_src_before": "    def system_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        table = conn.execute(f\"select * from populated where lower(name) = '{search}'\")\r\n        results = table.fetchone()\r\n        if not results:\r\n            table = conn.execute(f\"select * from systems where lower(name) = '{search}'\")\r\n            results = table.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in table.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[1:], results[1:]) if field)\r\n        else:\r\n            return 'No systems found.'", "func_src_after": "    def system_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        table = conn.execute('select * from populated where lower(name) = ?', (search,))\r\n        results = table.fetchone()\r\n        if not results:\r\n            table = conn.execute('select * from systems where lower(name) = ?', (search,))\r\n            results = table.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in table.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[1:], results[1:]) if field)\r\n        else:\r\n            return 'No systems found.'", "commit_link": "github.com/BeatButton/beattie/commit/ab36b2053ee09faf4cc9a279cf7a4c010864cb29", "file_name": "eddb.py", "vul_type": "cwe-089", "description": "Write a Python function that performs a case-insensitive search on two SQLite database tables and returns formatted results."}
{"func_name": "ReadVIFFImage", "func_src_before": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(max_packets,\n      bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(MagickMax(number_pixels,\n      max_packets),bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ca0c886abd6d3ef335eb74150cd23b89ebd17135", "file_name": "coders/viff.c", "vul_type": "cwe-125", "description": "Write a C function to read a VIFF image file in ImageMagick."}
{"func_name": "exporters_v1tov2", "func_src_before": "def exporters_v1tov2(exporters_paths, shared_config={}, quiet=False):\n    \"\"\"Translate exporters to v2 and put into shared config.\n\n    Args:\n        exporters_path (list): List of exporters file paths.\n        shared_config (dict): Shared config to add exporters to.\n        quiet (bool): Quiet mode.\n\n    Returns:\n        list: List of exporters keys added to shared config.\n    \"\"\"\n    exp_keys = []\n    for exp_path in exporters_paths:\n        with open(exp_path, encoding='utf-8') as conf:\n            content = yaml.load(conf, Loader=yaml.Loader)\n        exporters = content\n\n        # If exporters file has sections, concatenate all of them\n        if isinstance(content, dict):\n            exporters = []\n            for _, value in content.items():\n                exporters.extend(value)\n\n        # If exporter not in general config, add it and add an alias for the\n        # exporter. Refer to the alias in the SLO config file.\n        for exporter in exporters:\n            exporter = OrderedDict(exporter)\n            exp_key = add_to_shared_config(exporter,\n                                           shared_config,\n                                           'exporters',\n                                           quiet=quiet)\n            exp_keys.append(exp_key)\n    return exp_keys", "func_src_after": "def exporters_v1tov2(exporters_paths, shared_config={}, quiet=False):\n    \"\"\"Translate exporters to v2 and put into shared config.\n\n    Args:\n        exporters_path (list): List of exporters file paths.\n        shared_config (dict): Shared config to add exporters to.\n        quiet (bool): Quiet mode.\n\n    Returns:\n        list: List of exporters keys added to shared config.\n    \"\"\"\n    exp_keys = []\n    for exp_path in exporters_paths:\n        with open(exp_path, encoding='utf-8') as conf:\n            content = yaml.load(conf, Loader=yaml.SafeLoader)\n        exporters = content\n\n        # If exporters file has sections, concatenate all of them\n        if isinstance(content, dict):\n            exporters = []\n            for _, value in content.items():\n                exporters.extend(value)\n\n        # If exporter not in general config, add it and add an alias for the\n        # exporter. Refer to the alias in the SLO config file.\n        for exporter in exporters:\n            exporter = OrderedDict(exporter)\n            exp_key = add_to_shared_config(exporter,\n                                           shared_config,\n                                           'exporters',\n                                           quiet=quiet)\n            exp_keys.append(exp_key)\n    return exp_keys", "line_changes": {"deleted": [{"line_no": 15, "char_start": 495, "char_end": 553, "line": "            content = yaml.load(conf, Loader=yaml.Loader)\n"}], "added": [{"line_no": 15, "char_start": 495, "char_end": 557, "line": "            content = yaml.load(conf, Loader=yaml.SafeLoader)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 545, "char_end": 549, "chars": "Safe"}]}, "commit_link": "github.com/google/slo-generator/commit/36318beab1b85d14bb860e45bea186b184690d5d", "file_name": "migrator.py", "vul_type": "cwe-502", "commit_msg": "fix: yaml loader security issue (#173)", "parent_commit": "50ce1bf81d7c6a97da52cf167b1d3ee8100ddd90", "description": "Write a Python function to update a shared configuration with exporter details from multiple YAML files."}
{"func_name": "makeJudge", "func_src_before": "def makeJudge(judge):\n\tdb.execute(\"UPDATE players SET Judge = 1 WHERE Name = '%s' COLLATE NOCASE\" % (judge)) \n\tdatabase.commit()", "func_src_after": "def makeJudge(judge):\n\tdb.execute(\"UPDATE players SET Judge = 1 WHERE Name = ? COLLATE NOCASE\", judge) \n\tdatabase.commit()", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function called `makeJudge` that sets a player's 'Judge' status to 1 in a database by their name, case-insensitively."}
{"func_name": "handle_method_call", "func_src_before": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (element == NULL || element[0] == '\\0' || strlen(element) > 64)\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "func_src_after": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "commit_link": "github.com/abrt/abrt/commit/f3c2a6af3455b2882e28570e8a04f1c2d4500d5b", "file_name": "src/dbus/abrt-dbus.c", "vul_type": "cwe-022", "description": "Write a C function to handle various method calls for problem management over D-Bus."}
{"func_name": "llrpt_alpha", "func_src_before": "llrpt_alpha (PNODE node, SYMTAB stab, BOOLEAN *eflg)\n{\n\tstatic char scratch[2];\n\tINT i;\n\tPNODE argvar = builtin_args(node);\n\tPVALUE val = eval_and_coerce(PINT, argvar, stab, eflg);\n\tif (*eflg) {\n\t\tprog_var_error(node, stab, argvar, val, nonint1, \"alpha\");\n\t\treturn NULL;\n\t}\n\ti = pvalue_to_int(val);\n\tdelete_pvalue_ptr(&val);\n\tif (i < 1 || i > 26)\n\t\tsprintf(scratch, \"XX\");\n\telse\n\t\tsprintf(scratch, \"%c\", 'a' + i - 1);\n\treturn create_pvalue_from_string(scratch);\n}", "func_src_after": "llrpt_alpha (PNODE node, SYMTAB stab, BOOLEAN *eflg)\n{\n\tstatic char scratch[2];\n\tINT i;\n\tPNODE argvar = builtin_args(node);\n\tPVALUE val = eval_and_coerce(PINT, argvar, stab, eflg);\n\tif (*eflg) {\n\t\tprog_var_error(node, stab, argvar, val, nonint1, \"alpha\");\n\t\treturn NULL;\n\t}\n\ti = pvalue_to_int(val);\n\tdelete_pvalue_ptr(&val);\n\tif (i < 1 || i > 26)\n\t\tsprintf(scratch, \"%c\", \"X\");\n\telse\n\t\tsprintf(scratch, \"%c\", 'a' + i - 1);\n\treturn create_pvalue_from_string(scratch);\n}", "line_changes": {"deleted": [{"line_no": 14, "char_start": 347, "char_end": 373, "line": "\t\tsprintf(scratch, \"XX\");\n"}], "added": [{"line_no": 14, "char_start": 347, "char_end": 378, "line": "\t\tsprintf(scratch, \"%c\", \"X\");\n"}]}, "char_changes": {"deleted": [{"char_start": 367, "char_end": 368, "chars": "X"}], "added": [{"char_start": 367, "char_end": 373, "chars": "%c\", \""}]}, "commit_link": "github.com/MarcNo/lifelines/commit/36132f776e25c3d26c88eefff46f3b5763ca6494", "file_name": "builtin.c", "vul_type": "cwe-787", "commit_msg": "Avoid sprintf buffer overflow", "parent_commit": "e0a7577aedead452f15f1852f3fe25ecb06a0eee", "description": "Write a function in C that takes an integer and returns the corresponding lowercase letter of the English alphabet, or \"X\" if the integer is out of range."}
{"func_name": "(anonymous)", "func_src_before": "app.use((req, res, next) => {\n    if (req.path === '/api/upload') {\n        next();\n    } else {\n        lusca.csrf()(req, res, next);\n    }\n});", "func_src_after": "app.use((req, res, next) => {\n    if (req.path === '/api/upload' || req.path === '/upload' || req.path === '/' || req.path === '/getPosts/:userId') {\n        next();\n    } else {\n        lusca.csrf()(req, res, next);\n    }\n});", "line_changes": {"deleted": [{"line_no": 2, "char_start": 30, "char_end": 68, "line": "    if (req.path === '/api/upload') {\n"}], "added": [{"line_no": 2, "char_start": 30, "char_end": 150, "line": "    if (req.path === '/api/upload' || req.path === '/upload' || req.path === '/' || req.path === '/getPosts/:userId') {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 64, "char_end": 146, "chars": " || req.path === '/upload' || req.path === '/' || req.path === '/getPosts/:userId'"}]}, "commit_link": "github.com/molmsted98/mFrame/commit/96510c7138b803572062491fccbecb50e860c783", "file_name": "app.js", "vul_type": "cwe-352", "commit_msg": "Fixed an issue with csrf errors", "description": "Write a middleware in JavaScript for an Express.js application that bypasses CSRF protection for specific routes."}
{"func_name": "ReadRLEImage", "func_src_before": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    one,\n    offset,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 64)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((number_pixels*number_planes) != (size_t) (number_pixels*number_planes))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*MagickMax(number_planes,4);\n    pixel_info=AcquireVirtualMemory(pixel_info_length,sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            if (IsValidColormapIndex(image,*p & mask,&index,exception) ==\n                MagickFalse)\n              break;\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                if (IsValidColormapIndex(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception) == MagickFalse)\n                  break;\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    number_planes_filled,\n    one,\n    offset,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 64)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    number_planes_filled=(number_planes % 2 == 0) ? number_planes :\n      number_planes+1;\n    if ((number_pixels*number_planes_filled) != (size_t) (number_pixels*\n         number_planes_filled))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*number_planes_filled;\n    pixel_info=AcquireVirtualMemory(pixel_info_length,sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            if (IsValidColormapIndex(image,*p & mask,&index,exception) ==\n                MagickFalse)\n              break;\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                if (IsValidColormapIndex(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception) == MagickFalse)\n                  break;\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/2ad6d33493750a28a5a655d319a8e0b16c392de1", "file_name": "coders/rle.c", "vul_type": "cwe-125", "description": "Write a C function to read and process RLE (run-length encoded) image data."}
{"func_name": "add_article_action", "func_src_before": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = request.POST[\"notes\"]\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "func_src_after": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = escape(request.POST[\"notes\"])\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = escape(str(request.POST[str(\"notes_\" + str(art.id))]))\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/reservation_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle adding single or multiple articles to a reservation, with redirection and error handling."}
{"func_name": "search", "func_src_before": "  def search\n    escaped = params[:name].gsub('\\\\', '\\\\\\\\\\\\\\\\').gsub('%', '\\%').gsub('_', '\\_')\n    @searched = Restaurant.where(\"name like '%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'\")\n    if @searched.empty?\n      @error = \"\u691c\u7d22\u30ef\u30fc\u30c9\u304c\u30d2\u30c3\u30c8\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u3082\u3046\u4e00\u5ea6\u5165\u308c\u306a\u304a\u3057\u3066\u4e0b\u3055\u3044\u3002\"\n    end\n  end", "func_src_after": "  def search\n    escaped = params[:name].gsub('\\\\', '\\\\\\\\\\\\\\\\').gsub('%', '\\%').gsub('_', '\\_')\n    @searched = Restaurant.where(\"name like ? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%\")\n    if @searched.empty?\n      @error = \"\u691c\u7d22\u30ef\u30fc\u30c9\u304c\u30d2\u30c3\u30c8\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u3082\u3046\u4e00\u5ea6\u5165\u308c\u306a\u304a\u3057\u3066\u4e0b\u3055\u3044\u3002\"\n    end\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 96, "char_end": 203, "line": "    @searched = Restaurant.where(\"name like '%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'\")\n"}], "added": [{"line_no": 3, "char_start": 96, "char_end": 195, "line": "    @searched = Restaurant.where(\"name like ? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%\")\n"}]}, "char_changes": {"deleted": [{"char_start": 140, "char_end": 200, "chars": "'%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'"}], "added": [{"char_start": 140, "char_end": 192, "chars": "? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%"}]}, "commit_link": "github.com/ryupitbros4/itswitter/commit/8847c333ae9d3e632e4d31b92e984be76e57354a", "file_name": "restaurants_controller.rb", "vul_type": "cwe-089", "commit_msg": "Prevent SQL injection.", "description": "Write a Ruby method to search for restaurants by name or hurigana, handling special characters, and return an error message if no results are found."}
{"func_name": "canonicalize", "func_src_before": "    def canonicalize(self):\n        \"\"\"::\n\n            path = path.canonicalize()\n\n        Canonicalize path. ::\n\n            # \"/foo/baz\"\n            Pyjo.Path.new('/foo/./bar/../baz').canonicalize()\n\n            # \"/../baz\"\n            Pyjo.Path.new('/foo/../bar/../../baz').canonicalize()\n        \"\"\"\n        parts = self.parts\n        i = 0\n        while i < len(parts):\n            if parts[i] == '.' or parts[i] == '':\n                parts.pop(i)\n            elif i < 1 or parts[i] != '..' or parts[i - 1] == '..':\n                i += 1\n            else:\n                i -= 1\n                parts.pop(i)\n                parts.pop(i)\n\n        if not parts:\n            self.trailing_slash = False\n\n        return self", "func_src_after": "    def canonicalize(self):\n        \"\"\"::\n\n            path = path.canonicalize()\n\n        Canonicalize path by resolving ``.`` and ``..``, in addition ``...`` will be\n        treated as ``.`` to protect from path traversal attacks.\n\n            # \"/foo/baz\"\n            Pyjo.Path.new('/foo/./bar/../baz').canonicalize()\n\n            # \"/../baz\"\n            Pyjo.Path.new('/foo/../bar/../../baz').canonicalize()\n\n            # \"/foo/bar\"\n            Pyjo.Path.new('/foo/.../bar').canonicalize()\n        \"\"\"\n        parts = self.parts\n        i = 0\n        while i < len(parts):\n            if parts[i] == '' or parts[i] == '.' or parts[i] == '...':\n                parts.pop(i)\n            elif i < 1 or parts[i] != '..' or parts[i - 1] == '..':\n                i += 1\n            else:\n                i -= 1\n                parts.pop(i)\n                parts.pop(i)\n\n        if not parts:\n            self.trailing_slash = False\n\n        return self", "commit_link": "github.com/dex4er/Pyjoyment/commit/e4b115bc80c41615b2133091af3a74ee5d995c2e", "file_name": "Pyjo/Path.py", "vul_type": "cwe-022", "description": "Write a Python function named `canonicalize` that simplifies file paths by resolving \".\", \"..\", and optionally \"...\" in a path object."}
{"func_name": "download", "func_src_before": "    def download(self, log_files, sort='time', limit=-1, nfl_filter='',\n                 output_format='default'):\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            nfl_esc = nfl_filter.replace('(', '\\(').replace(')', '\\)')\n            # remove the slash that is intentionally added in the URL\n            # to avoid failure of filtering stats data.\n            if nfl_esc.startswith('/'):\n                nfl_esc = nfl_esc[1:]\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            if output_format == 'python':\n                data = self.format_source_code(nfl_filter)\n            elif output_format == 'json':\n                data = stats.to_json(nfl_esc, limit)\n            elif output_format == 'csv':\n                data = stats.to_csv(nfl_esc, limit)\n            elif output_format == 'ods':\n                data = stats.to_ods(nfl_esc, limit)\n            else:\n                profile_tmp_all = tempfile.mktemp('.profile', 'all')\n                stats.dump_stats(profile_tmp_all)\n                data = open(profile_tmp_all).read()\n                os.remove(profile_tmp_all)\n            return data, [('content-type', self.format_dict[output_format])]\n        except ODFLIBNotInstalled as ex:\n            raise ex\n        except Exception as ex:\n            raise ProfileException(_('Data download error: %s') % ex)", "func_src_after": "    def download(self, log_files, sort='time', limit=-1, nfl_filter='',\n                 output_format='default'):\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            nfl_esc = nfl_filter.replace('(', '\\(').replace(')', '\\)')\n            # remove the slash that is intentionally added in the URL\n            # to avoid failure of filtering stats data.\n            if nfl_esc.startswith('/'):\n                nfl_esc = nfl_esc[1:]\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            if output_format == 'python':\n                data = self.format_source_code(nfl_filter)\n            elif output_format == 'json':\n                data = stats.to_json(nfl_esc, limit)\n            elif output_format == 'csv':\n                data = stats.to_csv(nfl_esc, limit)\n            elif output_format == 'ods':\n                data = stats.to_ods(nfl_esc, limit)\n            else:\n                data = stats.print_stats()\n            return data, [('content-type', self.format_dict[output_format])]\n        except ODFLIBNotInstalled as ex:\n            raise ex\n        except Exception as ex:\n            raise ProfileException(_('Data download error: %s') % ex)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 969, "char_end": 1038, "line": "                profile_tmp_all = tempfile.mktemp('.profile', 'all')\n"}, {"line_no": 23, "char_start": 1038, "char_end": 1088, "line": "                stats.dump_stats(profile_tmp_all)\n"}, {"line_no": 24, "char_start": 1088, "char_end": 1140, "line": "                data = open(profile_tmp_all).read()\n"}, {"line_no": 25, "char_start": 1140, "char_end": 1183, "line": "                os.remove(profile_tmp_all)\n"}], "added": [{"line_no": 22, "char_start": 969, "char_end": 1012, "line": "                data = stats.print_stats()\n"}]}, "char_changes": {"deleted": [{"char_start": 985, "char_end": 1181, "chars": "profile_tmp_all = tempfile.mktemp('.profile', 'all')\n                stats.dump_stats(profile_tmp_all)\n                data = open(profile_tmp_all).read()\n                os.remove(profile_tmp_all"}], "added": [{"char_start": 985, "char_end": 1010, "chars": "data = stats.print_stats("}]}, "commit_link": "github.com/scality/ScalitySproxydSwift/commit/6978275cdb04bb08aaf142d401b52a46527dac4c", "file_name": "html_viewer.py", "vul_type": "cwe-377", "commit_msg": "Avoid usage of insecure mktemp() function\n\nThis patch eliminates the use of the deprecated and insecure\ntempfile.mktemp() function.  It has been replaced with secure\nalternatives where temporary files are actually required.\n\nChange-Id: I0a13d6d44cd1abc4b66fa33f39eea407617a01d5\nSecurityImpact\nCloses-bug: #1348869", "description": "Write a Python function named `download` that processes log files and returns data in various formats based on given parameters."}
{"func_name": "mrb_vm_exec", "func_src_before": "mrb_vm_exec(mrb_state *mrb, struct RProc *proc, mrb_code *pc)\n{\n  /* mrb_assert(mrb_proc_cfunc_p(proc)) */\n  mrb_irep *irep = proc->body.irep;\n  mrb_value *pool = irep->pool;\n  mrb_sym *syms = irep->syms;\n  mrb_code i;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n\n#ifdef DIRECT_THREADED\n  static void *optable[] = {\n    &&L_OP_NOP, &&L_OP_MOVE,\n    &&L_OP_LOADL, &&L_OP_LOADI, &&L_OP_LOADSYM, &&L_OP_LOADNIL,\n    &&L_OP_LOADSELF, &&L_OP_LOADT, &&L_OP_LOADF,\n    &&L_OP_GETGLOBAL, &&L_OP_SETGLOBAL, &&L_OP_GETSPECIAL, &&L_OP_SETSPECIAL,\n    &&L_OP_GETIV, &&L_OP_SETIV, &&L_OP_GETCV, &&L_OP_SETCV,\n    &&L_OP_GETCONST, &&L_OP_SETCONST, &&L_OP_GETMCNST, &&L_OP_SETMCNST,\n    &&L_OP_GETUPVAR, &&L_OP_SETUPVAR,\n    &&L_OP_JMP, &&L_OP_JMPIF, &&L_OP_JMPNOT,\n    &&L_OP_ONERR, &&L_OP_RESCUE, &&L_OP_POPERR, &&L_OP_RAISE, &&L_OP_EPUSH, &&L_OP_EPOP,\n    &&L_OP_SEND, &&L_OP_SENDB, &&L_OP_FSEND,\n    &&L_OP_CALL, &&L_OP_SUPER, &&L_OP_ARGARY, &&L_OP_ENTER,\n    &&L_OP_KARG, &&L_OP_KDICT, &&L_OP_RETURN, &&L_OP_TAILCALL, &&L_OP_BLKPUSH,\n    &&L_OP_ADD, &&L_OP_ADDI, &&L_OP_SUB, &&L_OP_SUBI, &&L_OP_MUL, &&L_OP_DIV,\n    &&L_OP_EQ, &&L_OP_LT, &&L_OP_LE, &&L_OP_GT, &&L_OP_GE,\n    &&L_OP_ARRAY, &&L_OP_ARYCAT, &&L_OP_ARYPUSH, &&L_OP_AREF, &&L_OP_ASET, &&L_OP_APOST,\n    &&L_OP_STRING, &&L_OP_STRCAT, &&L_OP_HASH,\n    &&L_OP_LAMBDA, &&L_OP_RANGE, &&L_OP_OCLASS,\n    &&L_OP_CLASS, &&L_OP_MODULE, &&L_OP_EXEC,\n    &&L_OP_METHOD, &&L_OP_SCLASS, &&L_OP_TCLASS,\n    &&L_OP_DEBUG, &&L_OP_STOP, &&L_OP_ERR,\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb->c->ci->proc = proc;\n  mrb->c->ci->nregs = irep->nregs;\n\n#define regs (mrb->c->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE) {\n      /* A B    R(A) := R(B) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL) {\n      /* A Bx   R(A) := Pool(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n#ifdef MRB_WORD_BOXING\n      mrb_value val = pool[bx];\n#ifndef MRB_WITHOUT_FLOAT\n      if (mrb_float_p(val)) {\n        val = mrb_float_value(mrb, mrb_float(val));\n      }\n#endif\n      regs[a] = val;\n#else\n      regs[a] = pool[bx];\n#endif\n      NEXT;\n    }\n\n    CASE(OP_LOADI) {\n      /* A sBx  R(A) := sBx */\n      int a = GETARG_A(i);\n      mrb_int bx = GETARG_sBx(i);\n      SET_INT_VALUE(regs[a], bx);\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM) {\n      /* A Bx   R(A) := Syms(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      SET_SYM_VALUE(regs[a], syms[bx]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF) {\n      /* A      R(A) := self */\n      int a = GETARG_A(i);\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT) {\n      /* A      R(A) := true */\n      int a = GETARG_A(i);\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF) {\n      /* A      R(A) := false */\n      int a = GETARG_A(i);\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGLOBAL) {\n      /* A Bx   R(A) := getglobal(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_gv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGLOBAL) {\n      /* A Bx   setglobal(Syms(Bx), R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_gv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSPECIAL) {\n      /* A Bx   R(A) := Special[Bx] */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_special_get(mrb, bx);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSPECIAL) {\n      /* A Bx   Special[Bx] := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_special_set(mrb, bx, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV) {\n      /* A Bx   R(A) := ivget(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_iv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETIV) {\n      /* A Bx   ivset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_iv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV) {\n      /* A Bx   R(A) := cvget(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val;\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_cv_get(mrb, syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV) {\n      /* A Bx   cvset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_cv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCONST) {\n      /* A Bx    R(A) := constget(Syms(Bx)) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_sym sym = syms[bx];\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_const_get(mrb, sym);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST) {\n      /* A Bx   constset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_const_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST) {\n      /* A Bx   R(A) := R(A)::Syms(Bx) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_const_get(mrb, regs[a], syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST) {\n      /* A Bx    R(A+1)::Syms(Bx) := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_const_set(mrb, regs[a+1], syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR) {\n      /* A B C  R(A) := uvget(B,C) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (!e) {\n        *regs_a = mrb_nil_value();\n      }\n      else {\n        *regs_a = e->stack[b];\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR) {\n      /* A B C  uvset(B,C,R(A)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_STACK_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP) {\n      /* sBx    pc+=sBx */\n      int sbx = GETARG_sBx(i);\n      pc += sbx;\n      JUMP;\n    }\n\n    CASE(OP_JMPIF) {\n      /* A sBx  if R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPNOT) {\n      /* A sBx  if !R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (!mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ONERR) {\n      /* sBx    pc+=sBx on exception */\n      int sbx = GETARG_sBx(i);\n      if (mrb->c->rsize <= mrb->c->ci->ridx) {\n        if (mrb->c->rsize == 0) mrb->c->rsize = RESCUE_STACK_INIT_SIZE;\n        else mrb->c->rsize *= 2;\n        mrb->c->rescue = (mrb_code **)mrb_realloc(mrb, mrb->c->rescue, sizeof(mrb_code*) * mrb->c->rsize);\n      }\n      mrb->c->rescue[mrb->c->ci->ridx++] = pc + sbx;\n      NEXT;\n    }\n\n    CASE(OP_RESCUE) {\n      /* A B    R(A) := exc; clear(exc); R(B) := matched (bool) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value exc;\n\n      if (c == 0) {\n        exc = mrb_obj_value(mrb->exc);\n        mrb->exc = 0;\n      }\n      else {           /* continued; exc taken from R(A) */\n        exc = regs[a];\n      }\n      if (b != 0) {\n        mrb_value e = regs[b];\n        struct RClass *ec;\n\n        switch (mrb_type(e)) {\n        case MRB_TT_CLASS:\n        case MRB_TT_MODULE:\n          break;\n        default:\n          {\n            mrb_value exc;\n\n            exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                  \"class or module required for rescue clause\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n        }\n        ec = mrb_class_ptr(e);\n        regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      }\n      if (a != 0 && c == 0) {\n        regs[a] = exc;\n      }\n      NEXT;\n    }\n\n    CASE(OP_POPERR) {\n      /* A      A.times{rescue_pop()} */\n      int a = GETARG_A(i);\n\n      mrb->c->ci->ridx -= a;\n      NEXT;\n    }\n\n    CASE(OP_RAISE) {\n      /* A      raise(R(A)) */\n      int a = GETARG_A(i);\n\n      mrb_exc_set(mrb, regs[a]);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EPUSH) {\n      /* Bx     ensure_push(SEQ[Bx]) */\n      int bx = GETARG_Bx(i);\n      struct RProc *p;\n\n      p = mrb_closure_new(mrb, irep->reps[bx]);\n      /* push ensure_stack */\n      if (mrb->c->esize <= mrb->c->eidx+1) {\n        if (mrb->c->esize == 0) mrb->c->esize = ENSURE_STACK_INIT_SIZE;\n        else mrb->c->esize *= 2;\n        mrb->c->ensure = (struct RProc **)mrb_realloc(mrb, mrb->c->ensure, sizeof(struct RProc*) * mrb->c->esize);\n      }\n      mrb->c->ensure[mrb->c->eidx++] = p;\n      mrb->c->ensure[mrb->c->eidx] = NULL;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EPOP) {\n      /* A      A.times{ensure_pop().call} */\n      int a = GETARG_A(i);\n      mrb_callinfo *ci = mrb->c->ci;\n      int n, epos = ci->epos;\n      mrb_value self = regs[0];\n      struct RClass *target_class = ci->target_class;\n\n      if (mrb->c->eidx <= epos) {\n        NEXT;\n      }\n\n      if (a > mrb->c->eidx - epos)\n        a = mrb->c->eidx - epos;\n      pc = pc + 1;\n      for (n=0; n<a; n++) {\n        proc = mrb->c->ensure[epos+n];\n        mrb->c->ensure[epos+n] = NULL;\n        if (proc == NULL) continue;\n        irep = proc->body.irep;\n        ci = cipush(mrb);\n        ci->mid = ci[-1].mid;\n        ci->argc = 0;\n        ci->proc = proc;\n        ci->stackent = mrb->c->stack;\n        ci->nregs = irep->nregs;\n        ci->target_class = target_class;\n        ci->pc = pc;\n        ci->acc = ci[-1].nregs;\n        mrb->c->stack += ci->acc;\n        stack_extend(mrb, ci->nregs);\n        regs[0] = self;\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb->c->eidx = epos;\n      JUMP;\n    }\n\n    CASE(OP_LOADNIL) {\n      /* A     R(A) := nil */\n      int a = GETARG_A(i);\n\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_SENDB) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C),&R(A+C+1))*/\n      /* fall through */\n    };\n\n  L_SEND:\n    CASE(OP_SEND) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = syms[GETARG_B(i)];\n\n      mrb_assert(bidx < ci->nregs);\n\n      recv = regs[a];\n      if (GET_OPCODE(i) != OP_SENDB) {\n        SET_NIL_VALUE(regs[bidx]);\n        blk = regs[bidx];\n      }\n      else {\n        blk = regs[bidx];\n        if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n          blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n          /* The stack might have been reallocated during mrb_convert_type(),\n             see #3622 */\n          regs[bidx] = blk;\n        }\n      }\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m) || (missing == mrb->c->ci->mid && mrb_obj_eq(mrb, regs[0], recv))) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        if (argc >= 0) {\n          if (a+2 >= irep->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(mid));\n        mid = missing;\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->argc = argc;\n\n      ci->pc = pc + 1;\n      ci->acc = a;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          ci->proc = p;\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (GET_OPCODE(i) == OP_SENDB) {\n          if (mrb_type(blk) == MRB_TT_PROC) {\n            struct RProc *p = mrb_proc_ptr(blk);\n            if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == ci[-1].env) {\n              p->flags |= MRB_PROC_ORPHAN;\n            }\n          }\n        }\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = recv;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_FSEND) {\n      /* A B C  R(A) := fcall(R(A),Syms(B),R(A+1),... ,R(A+C-1)) */\n      /* not implemented yet */\n      NEXT;\n    }\n\n    CASE(OP_CALL) {\n      /* A      R(A) := self.call(frame.argc, frame.argv) */\n      mrb_callinfo *ci;\n      mrb_value recv = mrb->c->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->target_class = MRB_PROC_TARGET_CLASS(m);\n      ci->proc = m;\n      if (MRB_PROC_ENV_P(m)) {\n        mrb_sym mid;\n        struct REnv *e = MRB_PROC_ENV(m);\n\n        mid = e->mid;\n        if (mid) ci->mid = mid;\n        if (!e->stack) {\n          e->stack = mrb->c->stack;\n        }\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = mrb->c->ci;\n        mrb->c->stack = ci->stackent;\n        regs[ci->acc] = recv;\n        pc = ci->pc;\n        cipop(mrb);\n        irep = mrb->c->ci->proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->stack[0] = mrb_nil_value();\n          goto L_RETURN;\n        }\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, ci->nregs);\n        if (ci->argc < 0) {\n          if (irep->nregs > 3) {\n            stack_clear(regs+3, irep->nregs-3);\n          }\n        }\n        else if (ci->argc+2 < irep->nregs) {\n          stack_clear(regs+ci->argc+2, irep->nregs-ci->argc-2);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_SUPER) {\n      /* A C  R(A) := super(R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(ci->proc);\n\n      mrb_assert(bidx < ci->nregs);\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->tt == MRB_TT_MODULE) {\n        target_class = ci->target_class;\n        if (target_class->tt != MRB_TT_ICLASS) {\n          mrb_value exc = mrb_exc_new_str_lit(mrb, E_RUNTIME_ERROR, \"superclass info lost [mruby limitations]\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      blk = regs[bidx];\n      if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n        blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n        /* The stack or ci stack might have been reallocated during\n           mrb_convert_type(), see #3622 and #3784 */\n        regs[bidx] = blk;\n        ci = mrb->c->ci;\n      }\n      c = target_class->super;\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n\n        if (mid != missing) {\n          c = mrb_class(mrb, recv);\n        }\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (argc >= 0) {\n          if (a+2 >= ci->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(ci->mid));\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->pc = pc + 1;\n      ci->argc = argc;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n      mrb->c->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          ci->proc = MRB_METHOD_PROC(m);\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = v;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* fill callinfo */\n        ci->acc = a;\n\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_ARGARY) {\n      /* A Bx   R(A) := argument array (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb->c->ci->target_class == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_STACK_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = (int)ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      regs[a+1] = stack[m1+r+m2];\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER) {\n      /* Ax             arg setup according to flags (23=5:5:1:5:5:1:1) */\n      /* number of optional arguments times OP_JMP should follow */\n      mrb_aspec ax = GETARG_Ax(i);\n      int m1 = MRB_ASPEC_REQ(ax);\n      int o  = MRB_ASPEC_OPT(ax);\n      int r  = MRB_ASPEC_REST(ax);\n      int m2 = MRB_ASPEC_POST(ax);\n      /* unused\n      int k  = MRB_ASPEC_KEY(ax);\n      int kd = MRB_ASPEC_KDICT(ax);\n      int b  = MRB_ASPEC_BLOCK(ax);\n      */\n      int argc = mrb->c->ci->argc;\n      mrb_value *argv = regs+1;\n      mrb_value *argv0 = argv;\n      int len = m1 + o + r + m2;\n      mrb_value *blk = &argv[argc < 0 ? 1 : argc];\n\n      if (argc < 0) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n      if (mrb->c->ci->proc && MRB_PROC_STRICT_P(mrb->c->ci->proc)) {\n        if (argc >= 0) {\n          if (argc < m1 + m2 || (r == 0 && argc > len)) {\n            argnum_error(mrb, m1+m2);\n            goto L_RAISE;\n          }\n        }\n      }\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n      if (argc < len) {\n        int mlen = m2;\n        if (argc < m1+m2) {\n          if (m1 < argc)\n            mlen = argc - m1;\n          else\n            mlen = 0;\n        }\n        regs[len+1] = *blk; /* move block */\n        SET_NIL_VALUE(regs[argc+1]);\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        if (r) {\n          regs[m1+o+1] = mrb_ary_new_capa(mrb, 0);\n        }\n        if (o == 0 || argc < m1+m2) pc++;\n        else\n          pc += argc - m1 - m2 + 1;\n      }\n      else {\n        int rnum = 0;\n        if (argv0 != argv) {\n          regs[len+1] = *blk; /* move block */\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          regs[m1+o+1] = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n        }\n        if (m2) {\n          if (argc-m2 > m1) {\n            value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n          }\n        }\n        if (argv0 == argv) {\n          regs[len+1] = *blk; /* move block */\n        }\n        pc += o + 1;\n      }\n      mrb->c->ci->argc = len;\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-len-2 > 0) {\n        stack_clear(&regs[len+2], irep->nlocals-len-2);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG) {\n      /* A B C          R(A) := kdict[Syms(B)]; if C kdict.rm(Syms(B)) */\n      /* if C == 2; raise unless kdict.empty? */\n      /* OP_JMP should follow to skip init code */\n      NEXT;\n    }\n\n    CASE(OP_KDICT) {\n      /* A C            R(A) := kdict */\n      NEXT;\n    }\n\n    L_RETURN:\n      i = MKOP_AB(OP_RETURN, GETARG_A(i), OP_R_NORMAL);\n      /* fall through */\n    CASE(OP_RETURN) {\n      /* A B     return R(A) (B=normal,in-block return/break) */\n      mrb_callinfo *ci;\n\n#define ecall_adjust() do {\\\n  ptrdiff_t cioff = ci - mrb->c->cibase;\\\n  ecall(mrb);\\\n  ci = mrb->c->cibase + cioff;\\\n} while (0)\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk;\n\n        if (ci->argc < 0) {\n          blk = regs[2];\n        }\n        else {\n          blk = regs[ci->argc+1];\n        }\n        if (mrb_type(blk) == MRB_TT_PROC) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == ci[-1].env) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n        mrb_callinfo *ci0;\n\n      L_RAISE:\n        ci0 = ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          if (ci->ridx == 0) goto L_FTOP;\n          goto L_RESCUE;\n        }\n        while (ci[0].ridx == ci[-1].ridx) {\n          cipop(mrb);\n          mrb->c->stack = ci->stackent;\n          if (ci->acc == CI_ACC_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          ci = mrb->c->ci;\n          if (ci == mrb->c->cibase) {\n            if (ci->ridx == 0) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                while (c->eidx > ci->epos) {\n                  ecall_adjust();\n                }\n                if (c->fib) {\n                  mrb_write_barrier(mrb, (struct RBasic*)c->fib);\n                }\n                mrb->c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n          /* call ensure only when we skip this callinfo */\n          if (ci[0].ridx == ci[-1].ridx) {\n            while (mrb->c->eidx > ci->epos) {\n              ecall_adjust();\n            }\n          }\n        }\n      L_RESCUE:\n        if (ci->ridx == 0) goto L_STOP;\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci < ci0) {\n          mrb->c->stack = ci[1].stackent;\n        }\n        stack_extend(mrb, irep->nregs);\n        pc = mrb->c->rescue[--ci->ridx];\n      }\n      else {\n        int acc;\n        mrb_value v;\n        struct RProc *dst;\n\n        ci = mrb->c->ci;\n        v = regs[GETARG_A(i)];\n        mrb_gc_protect(mrb, v);\n        switch (GETARG_B(i)) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->acc >=0 && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            mrb_callinfo *cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_STACK_SHARED_P(e) || e->cxt != mrb->c) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->acc < 0) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) {\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            break;\n          }\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n\n            if (!mrb->c->prev) { /* toplevel return */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            if (mrb->c->prev->ci == mrb->c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_str_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            while (mrb->c->eidx > 0) {\n              ecall(mrb);\n            }\n            /* automatic yield at the end */\n            c = mrb->c;\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            c->prev = NULL;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            ci = mrb->c->ci;\n          }\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) { \n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_str_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_STACK_SHARED_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e == mrb->c->cibase->env && proc != mrb->c->cibase->proc) {\n              goto L_BREAK_ERROR;\n            }\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          while (mrb->c->eidx > mrb->c->ci->epos) {\n            ecall_adjust();\n          }\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->acc < 0) {\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n          L_BREAK:\n            v = ((struct RBreak*)mrb->exc)->val;\n            proc = ((struct RBreak*)mrb->exc)->proc;\n            mrb->exc = NULL;\n            ci = mrb->c->ci;\n          }\n          mrb->c->stack = ci->stackent;\n          proc = proc->upper;\n          while (mrb->c->cibase < ci &&  ci[-1].proc != proc) {\n            if (ci[-1].acc == CI_ACC_SKIP) {\n              while (ci < mrb->c->ci) {\n                cipop(mrb);\n              }\n              goto L_BREAK_ERROR;\n            }\n            ci--;\n          }\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        while (ci < mrb->c->ci) {\n          cipop(mrb);\n        }\n        ci[0].ridx = ci[-1].ridx;\n        while (mrb->c->eidx > ci->epos) {\n          ecall_adjust();\n        }\n        if (mrb->c->vmexec && !ci->target_class) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->acc;\n        mrb->c->stack = ci->stackent;\n        cipop(mrb);\n        if (acc == CI_ACC_SKIP || acc == CI_ACC_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        ci = mrb->c->ci;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym2name(mrb, ci->mid)));\n        proc = mrb->c->ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        regs[acc] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_TAILCALL) {\n      /* A B C  return call(R(A),Syms(B),R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int n = GETARG_C(i);\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci;\n      mrb_value recv;\n      mrb_sym mid = syms[b];\n\n      recv = regs[a];\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_value sym = mrb_symbol_value(mid);\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args;\n\n          if (n == CALL_MAXARGS) {\n            args = regs[a+1];\n          }\n          else {\n            args = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          }\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (n == CALL_MAXARGS) {\n          mrb_ary_unshift(mrb, regs[a+1], sym);\n        }\n        else {\n          value_move(regs+a+2, regs+a+1, ++n);\n          regs[a+1] = sym;\n        }\n      }\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->mid = mid;\n      ci->target_class = c;\n      if (n == CALL_MAXARGS) {\n        ci->argc = -1;\n      }\n      else {\n        ci->argc = n;\n      }\n\n      /* move stack */\n      value_move(mrb->c->stack, &regs[a], ci->argc+1);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb->c->stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n        goto L_RETURN;\n      }\n      else {\n        /* setup environment for calling method */\n        struct RProc *p = MRB_METHOD_PROC(m);\n        irep = p->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci->argc < 0) {\n          stack_extend(mrb, (irep->nregs < 3) ? 3 : irep->nregs);\n        }\n        else {\n          stack_extend(mrb, irep->nregs);\n        }\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH) {\n      /* A Bx   R(A) := block (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_STACK_SHARED_P(e) && e->mid == 0) ||\n            MRB_ENV_STACK_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2];\n      NEXT;\n    }\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH_BODY(op,v1,v2) do {\\\n  v1(regs[a]) = v1(regs[a]) op v2(regs[a+1]);\\\n} while(0)\n\n    CASE(OP_ADD) {\n      /* A B C  R(A) := R(A)+R(A+1) (Syms[B]=:+,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n          mrb_value *regs_a = regs + a;\n\n          x = mrb_fixnum(regs_a[0]);\n          y = mrb_fixnum(regs_a[1]);\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      case TYPES2(MRB_TT_STRING,MRB_TT_STRING):\n        regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);\n        break;\n      default:\n        goto L_SEND;\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SUB) {\n      /* A B C  R(A) := R(A)-R(A+1) (Syms[B]=:-,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_MUL) {\n      /* A B C  R(A) := R(A)*R(A+1) (Syms[B]=:*,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_mul_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_DIV) {\n      /* A B C  R(A) := R(A)/R(A+1) (Syms[B]=:/,C=1)*/\n      int a = GETARG_A(i);\n#ifndef MRB_WITHOUT_FLOAT\n      double x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n#ifdef MRB_WITHOUT_FLOAT\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_INT_VALUE(regs[a], y ? x / y : 0);\n        }\n        break;\n#else\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n\n#ifndef MRB_WITHOUT_FLOAT\n      if (y == 0) {\n        if (x > 0) f = INFINITY;\n        else if (x < 0) f = -INFINITY;\n        else /* if (x == 0) */ f = NAN;\n      }\n      else {\n        f = x / y;\n      }\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ADDI) {\n      /* A B C  R(A) := R(A)+C (Syms[B]=:+)*/\n      int a = GETARG_A(i);\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs[a])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + GETARG_C(i));\n        }\n#else\n        mrb_float(regs[a]) += GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs[a+1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SUBI) {\n      /* A B C  R(A) := R(A)-C (Syms[B]=:-)*/\n      int a = GETARG_A(i);\n      mrb_value *regs_a = regs + a;\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs_a[0])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs_a[0]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs_a[0], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - GETARG_C(i));\n        }\n#else\n        mrb_float(regs_a[0]) -= GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs_a[1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_WITHOUT_FLOAT\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ) {\n      /* A B C  R(A) := R(A)==R(A+1) (Syms[B]=:==,C=1)*/\n      int a = GETARG_A(i);\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT) {\n      /* A B C  R(A) := R(A)<R(A+1) (Syms[B]=:<,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<);\n      NEXT;\n    }\n\n    CASE(OP_LE) {\n      /* A B C  R(A) := R(A)<=R(A+1) (Syms[B]=:<=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<=);\n      NEXT;\n    }\n\n    CASE(OP_GT) {\n      /* A B C  R(A) := R(A)>R(A+1) (Syms[B]=:>,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>);\n      NEXT;\n    }\n\n    CASE(OP_GE) {\n      /* A B C  R(A) := R(A)>=R(A+1) (Syms[B]=:>=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>=);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY) {\n      /* A B C          R(A) := ary_new(R(B),R(B+1)..R(B+C)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT) {\n      /* A B            mrb_ary_concat(R(A),R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_value splat = mrb_ary_splat(mrb, regs[b]);\n      mrb_ary_concat(mrb, regs[a], splat);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH) {\n      /* A B            R(A).push(R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_ary_push(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_AREF) {\n      /* A B C          R(A) := R(B)[C] */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET) {\n      /* A B C          R(B)[C] := R(A) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST) {\n      /* A B C  *R(A),R(A+1)..R(A+C) := R(A) */\n      int a = GETARG_A(i);\n      mrb_value v = regs[a];\n      int pre  = GETARG_B(i);\n      int post = GETARG_C(i);\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRING) {\n      /* A Bx           R(A) := str_new(Lit(Bx)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int bx = GETARG_Bx(i);\n      mrb_value str = mrb_str_dup(mrb, pool[bx]);\n\n      regs[a] = str;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT) {\n      /* A B    R(A).concat(R(B)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int b = GETARG_B(i);\n\n      mrb_str_concat(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_HASH) {\n      /* A B C   R(A) := hash_new(R(B),R(B+1)..R(B+C)) */\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      int lim = b+c*2;\n      mrb_value hash = mrb_hash_new_capa(mrb, c);\n\n      while (b < lim) {\n        mrb_hash_set(mrb, hash, regs[b], regs[b+1]);\n        b+=2;\n      }\n      regs[GETARG_A(i)] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA) {\n      /* A b c  R(A) := lambda(SEQ[b],c) (b:c = 14:2) */\n      struct RProc *p;\n      int a = GETARG_A(i);\n      int b = GETARG_b(i);\n      int c = GETARG_c(i);\n      mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS) {\n      /* A      R(A) := ::Object */\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS) {\n      /* A B    R(A) := newclass(R(A),Syms(B),R(A+1)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base, super;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE) {\n      /* A B            R(A) := newmodule(R(A),Syms(B)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC) {\n      /* A Bx   R(A) := blockexec(R(A),SEQ[Bx]) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_callinfo *ci;\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      mrb_irep *nirep = irep->reps[bx];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      ci = cipush(mrb);\n      ci->pc = pc + 1;\n      ci->acc = a;\n      ci->mid = 0;\n      ci->stackent = mrb->c->stack;\n      ci->argc = 0;\n      ci->target_class = mrb_class_ptr(recv);\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      /* setup block to call */\n      ci->proc = p;\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      ci->nregs = irep->nregs;\n      stack_extend(mrb, ci->nregs);\n      stack_clear(regs+1, ci->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_METHOD) {\n      /* A B            R(A).newmethod(Syms(B),R(A+1)) */\n      int a = GETARG_A(i);\n      struct RClass *c = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, c, syms[GETARG_B(i)], m);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS) {\n      /* A B    R(A) := R(B).singleton_class */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n\n      regs[a] = mrb_singleton_class(mrb, regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS) {\n      /* A      R(A) := target_class */\n      if (!mrb->c->ci->target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR, \"no target class or module\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->c->ci->target_class);\n      NEXT;\n    }\n\n    CASE(OP_RANGE) {\n      /* A B C  R(A) := range_new(R(B),R(B+1),C) */\n      int b = GETARG_B(i);\n      mrb_value val = mrb_range_new(mrb, regs[b], regs[b+1], GETARG_C(i));\n      regs[GETARG_A(i)] = val;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG) {\n      /* A B C    debug print R(A),R(B),R(C) */\n#ifdef MRB_ENABLE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_DISABLE_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", GETARG_A(i), GETARG_B(i), GETARG_C(i));\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_STOP) {\n      /*        stop VM */\n    L_STOP:\n      while (mrb->c->eidx > 0) {\n        ecall(mrb);\n      }\n      ERR_PC_CLR(mrb);\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n\n    CASE(OP_ERR) {\n      /* Bx     raise RuntimeError with message Lit(Bx) */\n      mrb_value msg = mrb_str_dup(mrb, pool[GETARG_Bx(i)]);\n      mrb_value exc;\n\n      if (GETARG_A(i) == 0) {\n        exc = mrb_exc_new_str(mrb, E_RUNTIME_ERROR, msg);\n      }\n      else {\n        exc = mrb_exc_new_str(mrb, E_LOCALJUMP_ERROR, msg);\n      }\n      ERR_PC_SET(mrb, pc);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n  }\n  END_DISPATCH;\n#undef regs\n\n  }\n  MRB_CATCH(&c_jmp) {\n    exc_catched = TRUE;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}", "func_src_after": "mrb_vm_exec(mrb_state *mrb, struct RProc *proc, mrb_code *pc)\n{\n  /* mrb_assert(mrb_proc_cfunc_p(proc)) */\n  mrb_irep *irep = proc->body.irep;\n  mrb_value *pool = irep->pool;\n  mrb_sym *syms = irep->syms;\n  mrb_code i;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n\n#ifdef DIRECT_THREADED\n  static void *optable[] = {\n    &&L_OP_NOP, &&L_OP_MOVE,\n    &&L_OP_LOADL, &&L_OP_LOADI, &&L_OP_LOADSYM, &&L_OP_LOADNIL,\n    &&L_OP_LOADSELF, &&L_OP_LOADT, &&L_OP_LOADF,\n    &&L_OP_GETGLOBAL, &&L_OP_SETGLOBAL, &&L_OP_GETSPECIAL, &&L_OP_SETSPECIAL,\n    &&L_OP_GETIV, &&L_OP_SETIV, &&L_OP_GETCV, &&L_OP_SETCV,\n    &&L_OP_GETCONST, &&L_OP_SETCONST, &&L_OP_GETMCNST, &&L_OP_SETMCNST,\n    &&L_OP_GETUPVAR, &&L_OP_SETUPVAR,\n    &&L_OP_JMP, &&L_OP_JMPIF, &&L_OP_JMPNOT,\n    &&L_OP_ONERR, &&L_OP_RESCUE, &&L_OP_POPERR, &&L_OP_RAISE, &&L_OP_EPUSH, &&L_OP_EPOP,\n    &&L_OP_SEND, &&L_OP_SENDB, &&L_OP_FSEND,\n    &&L_OP_CALL, &&L_OP_SUPER, &&L_OP_ARGARY, &&L_OP_ENTER,\n    &&L_OP_KARG, &&L_OP_KDICT, &&L_OP_RETURN, &&L_OP_TAILCALL, &&L_OP_BLKPUSH,\n    &&L_OP_ADD, &&L_OP_ADDI, &&L_OP_SUB, &&L_OP_SUBI, &&L_OP_MUL, &&L_OP_DIV,\n    &&L_OP_EQ, &&L_OP_LT, &&L_OP_LE, &&L_OP_GT, &&L_OP_GE,\n    &&L_OP_ARRAY, &&L_OP_ARYCAT, &&L_OP_ARYPUSH, &&L_OP_AREF, &&L_OP_ASET, &&L_OP_APOST,\n    &&L_OP_STRING, &&L_OP_STRCAT, &&L_OP_HASH,\n    &&L_OP_LAMBDA, &&L_OP_RANGE, &&L_OP_OCLASS,\n    &&L_OP_CLASS, &&L_OP_MODULE, &&L_OP_EXEC,\n    &&L_OP_METHOD, &&L_OP_SCLASS, &&L_OP_TCLASS,\n    &&L_OP_DEBUG, &&L_OP_STOP, &&L_OP_ERR,\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb->c->ci->proc = proc;\n  mrb->c->ci->nregs = irep->nregs;\n\n#define regs (mrb->c->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE) {\n      /* A B    R(A) := R(B) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL) {\n      /* A Bx   R(A) := Pool(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n#ifdef MRB_WORD_BOXING\n      mrb_value val = pool[bx];\n#ifndef MRB_WITHOUT_FLOAT\n      if (mrb_float_p(val)) {\n        val = mrb_float_value(mrb, mrb_float(val));\n      }\n#endif\n      regs[a] = val;\n#else\n      regs[a] = pool[bx];\n#endif\n      NEXT;\n    }\n\n    CASE(OP_LOADI) {\n      /* A sBx  R(A) := sBx */\n      int a = GETARG_A(i);\n      mrb_int bx = GETARG_sBx(i);\n      SET_INT_VALUE(regs[a], bx);\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM) {\n      /* A Bx   R(A) := Syms(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      SET_SYM_VALUE(regs[a], syms[bx]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF) {\n      /* A      R(A) := self */\n      int a = GETARG_A(i);\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT) {\n      /* A      R(A) := true */\n      int a = GETARG_A(i);\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF) {\n      /* A      R(A) := false */\n      int a = GETARG_A(i);\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGLOBAL) {\n      /* A Bx   R(A) := getglobal(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_gv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGLOBAL) {\n      /* A Bx   setglobal(Syms(Bx), R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_gv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSPECIAL) {\n      /* A Bx   R(A) := Special[Bx] */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_special_get(mrb, bx);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSPECIAL) {\n      /* A Bx   Special[Bx] := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_special_set(mrb, bx, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV) {\n      /* A Bx   R(A) := ivget(Bx) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val = mrb_vm_iv_get(mrb, syms[bx]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETIV) {\n      /* A Bx   ivset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_iv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV) {\n      /* A Bx   R(A) := cvget(Syms(Bx)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_value val;\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_cv_get(mrb, syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV) {\n      /* A Bx   cvset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_cv_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCONST) {\n      /* A Bx    R(A) := constget(Syms(Bx)) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_sym sym = syms[bx];\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_vm_const_get(mrb, sym);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST) {\n      /* A Bx   constset(Syms(Bx),R(A)) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_vm_const_set(mrb, syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST) {\n      /* A Bx   R(A) := R(A)::Syms(Bx) */\n      mrb_value val;\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n\n      ERR_PC_SET(mrb, pc);\n      val = mrb_const_get(mrb, regs[a], syms[bx]);\n      ERR_PC_CLR(mrb);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST) {\n      /* A Bx    R(A+1)::Syms(Bx) := R(A) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_const_set(mrb, regs[a+1], syms[bx], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR) {\n      /* A B C  R(A) := uvget(B,C) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_STACK_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR) {\n      /* A B C  uvset(B,C,R(A)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_STACK_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP) {\n      /* sBx    pc+=sBx */\n      int sbx = GETARG_sBx(i);\n      pc += sbx;\n      JUMP;\n    }\n\n    CASE(OP_JMPIF) {\n      /* A sBx  if R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPNOT) {\n      /* A sBx  if !R(A) pc+=sBx */\n      int a = GETARG_A(i);\n      int sbx = GETARG_sBx(i);\n      if (!mrb_test(regs[a])) {\n        pc += sbx;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ONERR) {\n      /* sBx    pc+=sBx on exception */\n      int sbx = GETARG_sBx(i);\n      if (mrb->c->rsize <= mrb->c->ci->ridx) {\n        if (mrb->c->rsize == 0) mrb->c->rsize = RESCUE_STACK_INIT_SIZE;\n        else mrb->c->rsize *= 2;\n        mrb->c->rescue = (mrb_code **)mrb_realloc(mrb, mrb->c->rescue, sizeof(mrb_code*) * mrb->c->rsize);\n      }\n      mrb->c->rescue[mrb->c->ci->ridx++] = pc + sbx;\n      NEXT;\n    }\n\n    CASE(OP_RESCUE) {\n      /* A B    R(A) := exc; clear(exc); R(B) := matched (bool) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value exc;\n\n      if (c == 0) {\n        exc = mrb_obj_value(mrb->exc);\n        mrb->exc = 0;\n      }\n      else {           /* continued; exc taken from R(A) */\n        exc = regs[a];\n      }\n      if (b != 0) {\n        mrb_value e = regs[b];\n        struct RClass *ec;\n\n        switch (mrb_type(e)) {\n        case MRB_TT_CLASS:\n        case MRB_TT_MODULE:\n          break;\n        default:\n          {\n            mrb_value exc;\n\n            exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                  \"class or module required for rescue clause\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n        }\n        ec = mrb_class_ptr(e);\n        regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      }\n      if (a != 0 && c == 0) {\n        regs[a] = exc;\n      }\n      NEXT;\n    }\n\n    CASE(OP_POPERR) {\n      /* A      A.times{rescue_pop()} */\n      int a = GETARG_A(i);\n\n      mrb->c->ci->ridx -= a;\n      NEXT;\n    }\n\n    CASE(OP_RAISE) {\n      /* A      raise(R(A)) */\n      int a = GETARG_A(i);\n\n      mrb_exc_set(mrb, regs[a]);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EPUSH) {\n      /* Bx     ensure_push(SEQ[Bx]) */\n      int bx = GETARG_Bx(i);\n      struct RProc *p;\n\n      p = mrb_closure_new(mrb, irep->reps[bx]);\n      /* push ensure_stack */\n      if (mrb->c->esize <= mrb->c->eidx+1) {\n        if (mrb->c->esize == 0) mrb->c->esize = ENSURE_STACK_INIT_SIZE;\n        else mrb->c->esize *= 2;\n        mrb->c->ensure = (struct RProc **)mrb_realloc(mrb, mrb->c->ensure, sizeof(struct RProc*) * mrb->c->esize);\n      }\n      mrb->c->ensure[mrb->c->eidx++] = p;\n      mrb->c->ensure[mrb->c->eidx] = NULL;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EPOP) {\n      /* A      A.times{ensure_pop().call} */\n      int a = GETARG_A(i);\n      mrb_callinfo *ci = mrb->c->ci;\n      int n, epos = ci->epos;\n      mrb_value self = regs[0];\n      struct RClass *target_class = ci->target_class;\n\n      if (mrb->c->eidx <= epos) {\n        NEXT;\n      }\n\n      if (a > mrb->c->eidx - epos)\n        a = mrb->c->eidx - epos;\n      pc = pc + 1;\n      for (n=0; n<a; n++) {\n        proc = mrb->c->ensure[epos+n];\n        mrb->c->ensure[epos+n] = NULL;\n        if (proc == NULL) continue;\n        irep = proc->body.irep;\n        ci = cipush(mrb);\n        ci->mid = ci[-1].mid;\n        ci->argc = 0;\n        ci->proc = proc;\n        ci->stackent = mrb->c->stack;\n        ci->nregs = irep->nregs;\n        ci->target_class = target_class;\n        ci->pc = pc;\n        ci->acc = ci[-1].nregs;\n        mrb->c->stack += ci->acc;\n        stack_extend(mrb, ci->nregs);\n        regs[0] = self;\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb->c->eidx = epos;\n      JUMP;\n    }\n\n    CASE(OP_LOADNIL) {\n      /* A     R(A) := nil */\n      int a = GETARG_A(i);\n\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_SENDB) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C),&R(A+C+1))*/\n      /* fall through */\n    };\n\n  L_SEND:\n    CASE(OP_SEND) {\n      /* A B C  R(A) := call(R(A),Syms(B),R(A+1),...,R(A+C)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = syms[GETARG_B(i)];\n\n      mrb_assert(bidx < ci->nregs);\n\n      recv = regs[a];\n      if (GET_OPCODE(i) != OP_SENDB) {\n        SET_NIL_VALUE(regs[bidx]);\n        blk = regs[bidx];\n      }\n      else {\n        blk = regs[bidx];\n        if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n          blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n          /* The stack might have been reallocated during mrb_convert_type(),\n             see #3622 */\n          regs[bidx] = blk;\n        }\n      }\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m) || (missing == mrb->c->ci->mid && mrb_obj_eq(mrb, regs[0], recv))) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        if (argc >= 0) {\n          if (a+2 >= irep->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(mid));\n        mid = missing;\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->argc = argc;\n\n      ci->pc = pc + 1;\n      ci->acc = a;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          ci->proc = p;\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (GET_OPCODE(i) == OP_SENDB) {\n          if (mrb_type(blk) == MRB_TT_PROC) {\n            struct RProc *p = mrb_proc_ptr(blk);\n            if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == ci[-1].env) {\n              p->flags |= MRB_PROC_ORPHAN;\n            }\n          }\n        }\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = recv;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_FSEND) {\n      /* A B C  R(A) := fcall(R(A),Syms(B),R(A+1),... ,R(A+C-1)) */\n      /* not implemented yet */\n      NEXT;\n    }\n\n    CASE(OP_CALL) {\n      /* A      R(A) := self.call(frame.argc, frame.argv) */\n      mrb_callinfo *ci;\n      mrb_value recv = mrb->c->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->target_class = MRB_PROC_TARGET_CLASS(m);\n      ci->proc = m;\n      if (MRB_PROC_ENV_P(m)) {\n        mrb_sym mid;\n        struct REnv *e = MRB_PROC_ENV(m);\n\n        mid = e->mid;\n        if (mid) ci->mid = mid;\n        if (!e->stack) {\n          e->stack = mrb->c->stack;\n        }\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = mrb->c->ci;\n        mrb->c->stack = ci->stackent;\n        regs[ci->acc] = recv;\n        pc = ci->pc;\n        cipop(mrb);\n        irep = mrb->c->ci->proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        JUMP;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->stack[0] = mrb_nil_value();\n          goto L_RETURN;\n        }\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, ci->nregs);\n        if (ci->argc < 0) {\n          if (irep->nregs > 3) {\n            stack_clear(regs+3, irep->nregs-3);\n          }\n        }\n        else if (ci->argc+2 < irep->nregs) {\n          stack_clear(regs+ci->argc+2, irep->nregs-ci->argc-2);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_SUPER) {\n      /* A C  R(A) := super(R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int n = GETARG_C(i);\n      int argc = (n == CALL_MAXARGS) ? -1 : n;\n      int bidx = (argc < 0) ? a+2 : a+n+1;\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(ci->proc);\n\n      mrb_assert(bidx < ci->nregs);\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->tt == MRB_TT_MODULE) {\n        target_class = ci->target_class;\n        if (target_class->tt != MRB_TT_ICLASS) {\n          mrb_value exc = mrb_exc_new_str_lit(mrb, E_RUNTIME_ERROR, \"superclass info lost [mruby limitations]\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      blk = regs[bidx];\n      if (!mrb_nil_p(blk) && mrb_type(blk) != MRB_TT_PROC) {\n        blk = mrb_convert_type(mrb, blk, MRB_TT_PROC, \"Proc\", \"to_proc\");\n        /* The stack or ci stack might have been reallocated during\n           mrb_convert_type(), see #3622 and #3784 */\n        regs[bidx] = blk;\n        ci = mrb->c->ci;\n      }\n      c = target_class->super;\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n\n        if (mid != missing) {\n          c = mrb_class(mrb, recv);\n        }\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args = (argc < 0) ? regs[a+1] : mrb_ary_new_from_values(mrb, n, regs+a+1);\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (argc >= 0) {\n          if (a+2 >= ci->nregs) {\n            stack_extend(mrb, a+3);\n          }\n          regs[a+1] = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          regs[a+2] = blk;\n          argc = -1;\n        }\n        mrb_ary_unshift(mrb, regs[a+1], mrb_symbol_value(ci->mid));\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb);\n      ci->mid = mid;\n      ci->stackent = mrb->c->stack;\n      ci->target_class = c;\n      ci->pc = pc + 1;\n      ci->argc = argc;\n\n      /* prepare stack */\n      mrb->c->stack += a;\n      mrb->c->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n        ci->nregs = (argc < 0) ? 3 : n+2;\n        if (MRB_METHOD_PROC_P(m)) {\n          ci->proc = MRB_METHOD_PROC(m);\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (!ci->target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->acc == CI_ACC_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->stack[0] = v;\n        /* pop stackpos */\n        mrb->c->stack = ci->stackent;\n        pc = ci->pc;\n        cipop(mrb);\n        JUMP;\n      }\n      else {\n        /* fill callinfo */\n        ci->acc = a;\n\n        /* setup environment for calling method */\n        proc = ci->proc = MRB_METHOD_PROC(m);\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        ci->nregs = irep->nregs;\n        stack_extend(mrb, (argc < 0 && ci->nregs < 3) ? 3 : ci->nregs);\n        pc = irep->iseq;\n        JUMP;\n      }\n    }\n\n    CASE(OP_ARGARY) {\n      /* A Bx   R(A) := argument array (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb->c->ci->target_class == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_str_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_STACK_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = (int)ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      regs[a+1] = stack[m1+r+m2];\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER) {\n      /* Ax             arg setup according to flags (23=5:5:1:5:5:1:1) */\n      /* number of optional arguments times OP_JMP should follow */\n      mrb_aspec ax = GETARG_Ax(i);\n      int m1 = MRB_ASPEC_REQ(ax);\n      int o  = MRB_ASPEC_OPT(ax);\n      int r  = MRB_ASPEC_REST(ax);\n      int m2 = MRB_ASPEC_POST(ax);\n      /* unused\n      int k  = MRB_ASPEC_KEY(ax);\n      int kd = MRB_ASPEC_KDICT(ax);\n      int b  = MRB_ASPEC_BLOCK(ax);\n      */\n      int argc = mrb->c->ci->argc;\n      mrb_value *argv = regs+1;\n      mrb_value *argv0 = argv;\n      int len = m1 + o + r + m2;\n      mrb_value *blk = &argv[argc < 0 ? 1 : argc];\n\n      if (argc < 0) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n      if (mrb->c->ci->proc && MRB_PROC_STRICT_P(mrb->c->ci->proc)) {\n        if (argc >= 0) {\n          if (argc < m1 + m2 || (r == 0 && argc > len)) {\n            argnum_error(mrb, m1+m2);\n            goto L_RAISE;\n          }\n        }\n      }\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n      if (argc < len) {\n        int mlen = m2;\n        if (argc < m1+m2) {\n          if (m1 < argc)\n            mlen = argc - m1;\n          else\n            mlen = 0;\n        }\n        regs[len+1] = *blk; /* move block */\n        SET_NIL_VALUE(regs[argc+1]);\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        if (r) {\n          regs[m1+o+1] = mrb_ary_new_capa(mrb, 0);\n        }\n        if (o == 0 || argc < m1+m2) pc++;\n        else\n          pc += argc - m1 - m2 + 1;\n      }\n      else {\n        int rnum = 0;\n        if (argv0 != argv) {\n          regs[len+1] = *blk; /* move block */\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          regs[m1+o+1] = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n        }\n        if (m2) {\n          if (argc-m2 > m1) {\n            value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n          }\n        }\n        if (argv0 == argv) {\n          regs[len+1] = *blk; /* move block */\n        }\n        pc += o + 1;\n      }\n      mrb->c->ci->argc = len;\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-len-2 > 0) {\n        stack_clear(&regs[len+2], irep->nlocals-len-2);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG) {\n      /* A B C          R(A) := kdict[Syms(B)]; if C kdict.rm(Syms(B)) */\n      /* if C == 2; raise unless kdict.empty? */\n      /* OP_JMP should follow to skip init code */\n      NEXT;\n    }\n\n    CASE(OP_KDICT) {\n      /* A C            R(A) := kdict */\n      NEXT;\n    }\n\n    L_RETURN:\n      i = MKOP_AB(OP_RETURN, GETARG_A(i), OP_R_NORMAL);\n      /* fall through */\n    CASE(OP_RETURN) {\n      /* A B     return R(A) (B=normal,in-block return/break) */\n      mrb_callinfo *ci;\n\n#define ecall_adjust() do {\\\n  ptrdiff_t cioff = ci - mrb->c->cibase;\\\n  ecall(mrb);\\\n  ci = mrb->c->cibase + cioff;\\\n} while (0)\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk;\n\n        if (ci->argc < 0) {\n          blk = regs[2];\n        }\n        else {\n          blk = regs[ci->argc+1];\n        }\n        if (mrb_type(blk) == MRB_TT_PROC) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == ci[-1].env) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n        mrb_callinfo *ci0;\n\n      L_RAISE:\n        ci0 = ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          if (ci->ridx == 0) goto L_FTOP;\n          goto L_RESCUE;\n        }\n        while (ci[0].ridx == ci[-1].ridx) {\n          cipop(mrb);\n          mrb->c->stack = ci->stackent;\n          if (ci->acc == CI_ACC_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          ci = mrb->c->ci;\n          if (ci == mrb->c->cibase) {\n            if (ci->ridx == 0) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                while (c->eidx > ci->epos) {\n                  ecall_adjust();\n                }\n                if (c->fib) {\n                  mrb_write_barrier(mrb, (struct RBasic*)c->fib);\n                }\n                mrb->c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n          /* call ensure only when we skip this callinfo */\n          if (ci[0].ridx == ci[-1].ridx) {\n            while (mrb->c->eidx > ci->epos) {\n              ecall_adjust();\n            }\n          }\n        }\n      L_RESCUE:\n        if (ci->ridx == 0) goto L_STOP;\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci < ci0) {\n          mrb->c->stack = ci[1].stackent;\n        }\n        stack_extend(mrb, irep->nregs);\n        pc = mrb->c->rescue[--ci->ridx];\n      }\n      else {\n        int acc;\n        mrb_value v;\n        struct RProc *dst;\n\n        ci = mrb->c->ci;\n        v = regs[GETARG_A(i)];\n        mrb_gc_protect(mrb, v);\n        switch (GETARG_B(i)) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->acc >=0 && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            mrb_callinfo *cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_STACK_SHARED_P(e) || e->cxt != mrb->c) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->acc < 0) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) {\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            break;\n          }\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n\n            if (!mrb->c->prev) { /* toplevel return */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            if (mrb->c->prev->ci == mrb->c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_str_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            while (mrb->c->eidx > 0) {\n              ecall(mrb);\n            }\n            /* automatic yield at the end */\n            c = mrb->c;\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            c->prev = NULL;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            ci = mrb->c->ci;\n          }\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) { \n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_str_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_STACK_SHARED_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e == mrb->c->cibase->env && proc != mrb->c->cibase->proc) {\n              goto L_BREAK_ERROR;\n            }\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          while (mrb->c->eidx > mrb->c->ci->epos) {\n            ecall_adjust();\n          }\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->acc < 0) {\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n          L_BREAK:\n            v = ((struct RBreak*)mrb->exc)->val;\n            proc = ((struct RBreak*)mrb->exc)->proc;\n            mrb->exc = NULL;\n            ci = mrb->c->ci;\n          }\n          mrb->c->stack = ci->stackent;\n          proc = proc->upper;\n          while (mrb->c->cibase < ci &&  ci[-1].proc != proc) {\n            if (ci[-1].acc == CI_ACC_SKIP) {\n              while (ci < mrb->c->ci) {\n                cipop(mrb);\n              }\n              goto L_BREAK_ERROR;\n            }\n            ci--;\n          }\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        while (ci < mrb->c->ci) {\n          cipop(mrb);\n        }\n        ci[0].ridx = ci[-1].ridx;\n        while (mrb->c->eidx > ci->epos) {\n          ecall_adjust();\n        }\n        if (mrb->c->vmexec && !ci->target_class) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->acc;\n        mrb->c->stack = ci->stackent;\n        cipop(mrb);\n        if (acc == CI_ACC_SKIP || acc == CI_ACC_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        ci = mrb->c->ci;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym2name(mrb, ci->mid)));\n        proc = mrb->c->ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        regs[acc] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_TAILCALL) {\n      /* A B C  return call(R(A),Syms(B),R(A+1),... ,R(A+C+1)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int n = GETARG_C(i);\n      mrb_method_t m;\n      struct RClass *c;\n      mrb_callinfo *ci;\n      mrb_value recv;\n      mrb_sym mid = syms[b];\n\n      recv = regs[a];\n      c = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &c, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        mrb_value sym = mrb_symbol_value(mid);\n        mrb_sym missing = mrb_intern_lit(mrb, \"method_missing\");\n        m = mrb_method_search_vm(mrb, &c, missing);\n        if (MRB_METHOD_UNDEF_P(m)) {\n          mrb_value args;\n\n          if (n == CALL_MAXARGS) {\n            args = regs[a+1];\n          }\n          else {\n            args = mrb_ary_new_from_values(mrb, n, regs+a+1);\n          }\n          ERR_PC_SET(mrb, pc);\n          mrb_method_missing(mrb, mid, recv, args);\n        }\n        mid = missing;\n        if (n == CALL_MAXARGS) {\n          mrb_ary_unshift(mrb, regs[a+1], sym);\n        }\n        else {\n          value_move(regs+a+2, regs+a+1, ++n);\n          regs[a+1] = sym;\n        }\n      }\n\n      /* replace callinfo */\n      ci = mrb->c->ci;\n      ci->mid = mid;\n      ci->target_class = c;\n      if (n == CALL_MAXARGS) {\n        ci->argc = -1;\n      }\n      else {\n        ci->argc = n;\n      }\n\n      /* move stack */\n      value_move(mrb->c->stack, &regs[a], ci->argc+1);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb->c->stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n        goto L_RETURN;\n      }\n      else {\n        /* setup environment for calling method */\n        struct RProc *p = MRB_METHOD_PROC(m);\n        irep = p->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        if (ci->argc < 0) {\n          stack_extend(mrb, (irep->nregs < 3) ? 3 : irep->nregs);\n        }\n        else {\n          stack_extend(mrb, irep->nregs);\n        }\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH) {\n      /* A Bx   R(A) := block (16=6:1:5:4) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      int m1 = (bx>>10)&0x3f;\n      int r  = (bx>>9)&0x1;\n      int m2 = (bx>>4)&0x1f;\n      int lv = (bx>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_STACK_SHARED_P(e) && e->mid == 0) ||\n            MRB_ENV_STACK_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2];\n      NEXT;\n    }\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH_BODY(op,v1,v2) do {\\\n  v1(regs[a]) = v1(regs[a]) op v2(regs[a+1]);\\\n} while(0)\n\n    CASE(OP_ADD) {\n      /* A B C  R(A) := R(A)+R(A+1) (Syms[B]=:+,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n          mrb_value *regs_a = regs + a;\n\n          x = mrb_fixnum(regs_a[0]);\n          y = mrb_fixnum(regs_a[1]);\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + y);\n        }\n#else\n        OP_MATH_BODY(+,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      case TYPES2(MRB_TT_STRING,MRB_TT_STRING):\n        regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);\n        break;\n      default:\n        goto L_SEND;\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SUB) {\n      /* A B C  R(A) := R(A)-R(A+1) (Syms[B]=:-,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x - y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - y);\n        }\n#else\n        OP_MATH_BODY(-,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_MUL) {\n      /* A B C  R(A) := R(A)*R(A+1) (Syms[B]=:*,C=1)*/\n      int a = GETARG_A(i);\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n        {\n          mrb_int x, y, z;\n\n          x = mrb_fixnum(regs[a]);\n          y = mrb_fixnum(regs[a+1]);\n          if (mrb_int_mul_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x * y);\n        }\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_fixnum);\n#endif\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          mrb_float y = mrb_float(regs[a+1]);\n          SET_FLOAT_VALUE(mrb, regs[a], x * y);\n        }\n#else\n        OP_MATH_BODY(*,mrb_float,mrb_float);\n#endif\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_DIV) {\n      /* A B C  R(A) := R(A)/R(A+1) (Syms[B]=:/,C=1)*/\n      int a = GETARG_A(i);\n#ifndef MRB_WITHOUT_FLOAT\n      double x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\n#ifdef MRB_WITHOUT_FLOAT\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = mrb_fixnum(regs[a+1]);\n          SET_INT_VALUE(regs[a], y ? x / y : 0);\n        }\n        break;\n#else\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_fixnum(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_fixnum(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        goto L_SEND;\n      }\n\n#ifndef MRB_WITHOUT_FLOAT\n      if (y == 0) {\n        if (x > 0) f = INFINITY;\n        else if (x < 0) f = -INFINITY;\n        else /* if (x == 0) */ f = NAN;\n      }\n      else {\n        f = x / y;\n      }\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ADDI) {\n      /* A B C  R(A) := R(A)+C (Syms[B]=:+)*/\n      int a = GETARG_A(i);\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs[a])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs[a]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_add_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs[a], (mrb_float)x + (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs[a], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x + GETARG_C(i));\n        }\n#else\n        mrb_float(regs[a]) += GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs[a+1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SUBI) {\n      /* A B C  R(A) := R(A)-C (Syms[B]=:-)*/\n      int a = GETARG_A(i);\n      mrb_value *regs_a = regs + a;\n\n      /* need to check if + is overridden */\n      switch (mrb_type(regs_a[0])) {\n      case MRB_TT_FIXNUM:\n        {\n          mrb_int x = mrb_fixnum(regs_a[0]);\n          mrb_int y = GETARG_C(i);\n          mrb_int z;\n\n          if (mrb_int_sub_overflow(x, y, &z)) {\n#ifndef MRB_WITHOUT_FLOAT\n            SET_FLOAT_VALUE(mrb, regs_a[0], (mrb_float)x - (mrb_float)y);\n            break;\n#endif\n          }\n          SET_INT_VALUE(regs_a[0], z);\n        }\n        break;\n#ifndef MRB_WITHOUT_FLOAT\n      case MRB_TT_FLOAT:\n#ifdef MRB_WORD_BOXING\n        {\n          mrb_float x = mrb_float(regs[a]);\n          SET_FLOAT_VALUE(mrb, regs[a], x - GETARG_C(i));\n        }\n#else\n        mrb_float(regs_a[0]) -= GETARG_C(i);\n#endif\n        break;\n#endif\n      default:\n        SET_INT_VALUE(regs_a[1], GETARG_C(i));\n        i = MKOP_ABC(OP_SEND, a, GETARG_B(i), 1);\n        goto L_SEND;\n      }\n      NEXT;\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_WITHOUT_FLOAT\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FIXNUM,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FIXNUM):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    goto L_SEND;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ) {\n      /* A B C  R(A) := R(A)==R(A+1) (Syms[B]=:==,C=1)*/\n      int a = GETARG_A(i);\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT) {\n      /* A B C  R(A) := R(A)<R(A+1) (Syms[B]=:<,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<);\n      NEXT;\n    }\n\n    CASE(OP_LE) {\n      /* A B C  R(A) := R(A)<=R(A+1) (Syms[B]=:<=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(<=);\n      NEXT;\n    }\n\n    CASE(OP_GT) {\n      /* A B C  R(A) := R(A)>R(A+1) (Syms[B]=:>,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>);\n      NEXT;\n    }\n\n    CASE(OP_GE) {\n      /* A B C  R(A) := R(A)>=R(A+1) (Syms[B]=:>=,C=1)*/\n      int a = GETARG_A(i);\n      OP_CMP(>=);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY) {\n      /* A B C          R(A) := ary_new(R(B),R(B+1)..R(B+C)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT) {\n      /* A B            mrb_ary_concat(R(A),R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_value splat = mrb_ary_splat(mrb, regs[b]);\n      mrb_ary_concat(mrb, regs[a], splat);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH) {\n      /* A B            R(A).push(R(B)) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      mrb_ary_push(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_AREF) {\n      /* A B C          R(A) := R(B)[C] */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET) {\n      /* A B C          R(B)[C] := R(A) */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST) {\n      /* A B C  *R(A),R(A+1)..R(A+C) := R(A) */\n      int a = GETARG_A(i);\n      mrb_value v = regs[a];\n      int pre  = GETARG_B(i);\n      int post = GETARG_C(i);\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRING) {\n      /* A Bx           R(A) := str_new(Lit(Bx)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int bx = GETARG_Bx(i);\n      mrb_value str = mrb_str_dup(mrb, pool[bx]);\n\n      regs[a] = str;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT) {\n      /* A B    R(A).concat(R(B)) */\n      mrb_int a = GETARG_A(i);\n      mrb_int b = GETARG_B(i);\n\n      mrb_str_concat(mrb, regs[a], regs[b]);\n      NEXT;\n    }\n\n    CASE(OP_HASH) {\n      /* A B C   R(A) := hash_new(R(B),R(B+1)..R(B+C)) */\n      int b = GETARG_B(i);\n      int c = GETARG_C(i);\n      int lim = b+c*2;\n      mrb_value hash = mrb_hash_new_capa(mrb, c);\n\n      while (b < lim) {\n        mrb_hash_set(mrb, hash, regs[b], regs[b+1]);\n        b+=2;\n      }\n      regs[GETARG_A(i)] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA) {\n      /* A b c  R(A) := lambda(SEQ[b],c) (b:c = 14:2) */\n      struct RProc *p;\n      int a = GETARG_A(i);\n      int b = GETARG_b(i);\n      int c = GETARG_c(i);\n      mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS) {\n      /* A      R(A) := ::Object */\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS) {\n      /* A B    R(A) := newclass(R(A),Syms(B),R(A+1)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base, super;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE) {\n      /* A B            R(A) := newmodule(R(A),Syms(B)) */\n      struct RClass *c = 0, *baseclass;\n      int a = GETARG_A(i);\n      mrb_value base;\n      mrb_sym id = syms[GETARG_B(i)];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC) {\n      /* A Bx   R(A) := blockexec(R(A),SEQ[Bx]) */\n      int a = GETARG_A(i);\n      int bx = GETARG_Bx(i);\n      mrb_callinfo *ci;\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      mrb_irep *nirep = irep->reps[bx];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      ci = cipush(mrb);\n      ci->pc = pc + 1;\n      ci->acc = a;\n      ci->mid = 0;\n      ci->stackent = mrb->c->stack;\n      ci->argc = 0;\n      ci->target_class = mrb_class_ptr(recv);\n\n      /* prepare stack */\n      mrb->c->stack += a;\n\n      /* setup block to call */\n      ci->proc = p;\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      ci->nregs = irep->nregs;\n      stack_extend(mrb, ci->nregs);\n      stack_clear(regs+1, ci->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_METHOD) {\n      /* A B            R(A).newmethod(Syms(B),R(A+1)) */\n      int a = GETARG_A(i);\n      struct RClass *c = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, c, syms[GETARG_B(i)], m);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS) {\n      /* A B    R(A) := R(B).singleton_class */\n      int a = GETARG_A(i);\n      int b = GETARG_B(i);\n\n      regs[a] = mrb_singleton_class(mrb, regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS) {\n      /* A      R(A) := target_class */\n      if (!mrb->c->ci->target_class) {\n        mrb_value exc = mrb_exc_new_str_lit(mrb, E_TYPE_ERROR, \"no target class or module\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      regs[GETARG_A(i)] = mrb_obj_value(mrb->c->ci->target_class);\n      NEXT;\n    }\n\n    CASE(OP_RANGE) {\n      /* A B C  R(A) := range_new(R(B),R(B+1),C) */\n      int b = GETARG_B(i);\n      mrb_value val = mrb_range_new(mrb, regs[b], regs[b+1], GETARG_C(i));\n      regs[GETARG_A(i)] = val;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG) {\n      /* A B C    debug print R(A),R(B),R(C) */\n#ifdef MRB_ENABLE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_DISABLE_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", GETARG_A(i), GETARG_B(i), GETARG_C(i));\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_STOP) {\n      /*        stop VM */\n    L_STOP:\n      while (mrb->c->eidx > 0) {\n        ecall(mrb);\n      }\n      ERR_PC_CLR(mrb);\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n\n    CASE(OP_ERR) {\n      /* Bx     raise RuntimeError with message Lit(Bx) */\n      mrb_value msg = mrb_str_dup(mrb, pool[GETARG_Bx(i)]);\n      mrb_value exc;\n\n      if (GETARG_A(i) == 0) {\n        exc = mrb_exc_new_str(mrb, E_RUNTIME_ERROR, msg);\n      }\n      else {\n        exc = mrb_exc_new_str(mrb, E_LOCALJUMP_ERROR, msg);\n      }\n      ERR_PC_SET(mrb, pc);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n  }\n  END_DISPATCH;\n#undef regs\n\n  }\n  MRB_CATCH(&c_jmp) {\n    exc_catched = TRUE;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}", "commit_link": "github.com/mruby/mruby/commit/1905091634a6a2925c911484434448e568330626", "file_name": "src/vm.c", "vul_type": "cwe-416", "description": "Execute a Ruby method from a given bytecode in the MRuby language."}
{"func_name": "TiledInputFile::rawTileData", "func_src_before": "TiledInputFile::rawTileData (int &dx, int &dy,\n\t\t\t     int &lx, int &ly,\n                             const char *&pixelData,\n\t\t\t     int &pixelDataSize)\n{\n    try\n    {\n        Lock lock (*_data->_streamData);\n\n        if (!isValidTile (dx, dy, lx, ly))\n            throw IEX_NAMESPACE::ArgExc (\"Tried to read a tile outside \"\n\t\t\t       \"the image file's data window.\");\n\n        TileBuffer *tileBuffer = _data->getTileBuffer (0);\n\n        //\n        // if file is a multipart file, we have to seek to the required tile\n        // since we don't know where the file pointer is\n        //\n        int old_dx=dx;\n        int old_dy=dy;\n        int old_lx=lx;\n        int old_ly=ly;\n        if(isMultiPart(version()))\n        {\n            _data->_streamData->is->seekg(_data->tileOffsets(dx,dy,lx,ly));\n        }\n        readNextTileData (_data->_streamData, _data, dx, dy, lx, ly,\n\t\t\t  tileBuffer->buffer,\n                          pixelDataSize);\n        if(isMultiPart(version()))\n        {\n            if (old_dx!=dx || old_dy !=dy || old_lx!=lx || old_ly!=ly)\n            {\n                throw IEX_NAMESPACE::ArgExc (\"rawTileData read the wrong tile\");\n            }\n        }\n        pixelData = tileBuffer->buffer;\n    }\n    catch (IEX_NAMESPACE::BaseExc &e)\n    {\n        REPLACE_EXC (e, \"Error reading pixel data from image \"\n                     \"file \\\"\" << fileName() << \"\\\". \" << e.what());\n        throw;\n    }\n}", "func_src_after": "TiledInputFile::rawTileData (int &dx, int &dy,\n\t\t\t     int &lx, int &ly,\n                             const char *&pixelData,\n\t\t\t     int &pixelDataSize)\n{\n    try\n    {\n        Lock lock (*_data->_streamData);\n\n        if (!isValidTile (dx, dy, lx, ly))\n            throw IEX_NAMESPACE::ArgExc (\"Tried to read a tile outside \"\n\t\t\t       \"the image file's data window.\");\n\n        TileBuffer *tileBuffer = _data->getTileBuffer (0);\n\n        //\n        // if file is a multipart file, we have to seek to the required tile\n        // since we don't know where the file pointer is\n        //\n        int old_dx=dx;\n        int old_dy=dy;\n        int old_lx=lx;\n        int old_ly=ly;\n        if(isMultiPart(version()))\n        {\n            _data->_streamData->is->seekg(_data->tileOffsets(dx,dy,lx,ly));\n        }\n        readNextTileData (_data->_streamData, _data, dx, dy, lx, ly,\n\t\t\t  tileBuffer->buffer,\n                          pixelDataSize);\n        if(isMultiPart(version()))\n        {\n            if (old_dx!=dx || old_dy !=dy || old_lx!=lx || old_ly!=ly)\n            {\n                throw IEX_NAMESPACE::ArgExc (\"rawTileData read the wrong tile\");\n            }\n        }\n        else\n        {\n             if(!isValidTile (dx, dy, lx, ly) )\n             {\n                 throw IEX_NAMESPACE::IoExc (\"rawTileData read an invalid tile\");\n             }\n        }\n        pixelData = tileBuffer->buffer;\n    }\n    catch (IEX_NAMESPACE::BaseExc &e)\n    {\n        REPLACE_EXC (e, \"Error reading pixel data from image \"\n                     \"file \\\"\" << fileName() << \"\\\". \" << e.what());\n        throw;\n    }\n}", "commit_link": "github.com/AcademySoftwareFoundation/openexr/commit/6bb36714528a9563dd3b92720c5063a1284b86f8", "file_name": "OpenEXR/IlmImf/ImfTiledInputFile.cpp", "vul_type": "cwe-787", "description": "Provide a C++ function to read raw tile data from an image file, handling multipart files and validating tile coordinates."}
{"func_name": "HPHP::SimpleParser::TryParse", "func_src_before": "  static bool TryParse(const char* inp, int length,\n                       TypedValue* buf, Variant& out,\n                       JSONContainerType container_type, bool is_tsimplejson) {\n    SimpleParser parser(inp, length, buf, container_type, is_tsimplejson);\n    bool ok = parser.parseValue();\n    parser.skipSpace();\n    if (!ok || parser.p != inp + length) {\n      // Unsupported, malformed, or trailing garbage. Release entire stack.\n      tvDecRefRange(buf, parser.top);\n      return false;\n    }\n    out = Variant::attach(*--parser.top);\n    return true;\n  }", "func_src_after": "  static bool TryParse(const char* inp, int length,\n                       TypedValue* buf, Variant& out,\n                       JSONContainerType container_type, bool is_tsimplejson) {\n    SimpleParser parser(inp, length, buf, container_type, is_tsimplejson);\n    bool ok = parser.parseValue();\n    if (!ok ||\n        (parser.skipSpace(), parser.p != inp + length)) {\n      // Unsupported, malformed, or trailing garbage. Release entire stack.\n      tvDecRefRange(buf, parser.top);\n      return false;\n    }\n    out = Variant::attach(*--parser.top);\n    return true;\n  }", "commit_link": "github.com/facebook/hhvm/commit/bd586671a3c22eb2f07e55f11b3ce64e1f7961e7", "file_name": "hphp/runtime/ext/json/JSON_parser.cpp", "vul_type": "cwe-125", "description": "Create a C++ function named `TryParse` that attempts to parse a JSON string into a typed value and handles errors."}
{"func_name": "_create_3par_iscsi_host", "func_src_before": "    def _create_3par_iscsi_host(self, hostname, iscsi_iqn, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same iqn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        cmd = 'createhost -iscsi -persona %s -domain %s %s %s' % \\\n              (persona_id, domain, hostname, iscsi_iqn)\n        out = self.common._cli_run(cmd, None)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n        return hostname", "func_src_after": "    def _create_3par_iscsi_host(self, hostname, iscsi_iqn, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same iqn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        cmd = ['createhost', '-iscsi', '-persona', persona_id, '-domain',\n               domain, hostname, iscsi_iqn]\n        out = self.common._cli_run(cmd)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_iscsi.py", "vul_type": "cwe-078", "description": "Write a Python function to create an iSCSI host on a 3PAR system, handling potential conflicts with existing IQNs."}
{"func_name": "get_mapped_projects", "func_src_before": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                                   AND t.validated_by = {0}\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                            AND t.mapped_by = {0}\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''.format(user_id)\n\n        results = db.engine.execute(sql)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "func_src_after": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                                   AND t.validated_by = :user_id\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                            AND t.mapped_by = :user_id\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''\n\n        results = db.engine.execute(text(sql), user_id=user_id)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/user.py", "vul_type": "cwe-089", "description": "In Python, write a method to retrieve a user's mapped projects with task counts and localization details."}
{"func_name": "build_path", "func_src_before": "def build_path(root_dir, path):\n    resolved_path = (Path(root_dir) / path).resolve()\n\n    if not resolved_path.is_relative_to(root_dir):\n        raise ValueError(f\"Attempted directory traversal: {path}\")\n\n    return resolved_path", "func_src_after": "def build_path(root_dir, path):\n    absolute_path = Path(root_dir) / path\n\n    if \"..\" in absolute_path.parts:\n        raise ValueError(f\"Attempted directory traversal: {path}\")\n\n    return absolute_path", "line_changes": {"deleted": [{"line_no": 2, "char_start": 32, "char_end": 86, "line": "    resolved_path = (Path(root_dir) / path).resolve()\n"}, {"line_no": 4, "char_start": 87, "char_end": 138, "line": "    if not resolved_path.is_relative_to(root_dir):\n"}, {"line_no": 7, "char_start": 206, "char_end": 230, "line": "    return resolved_path\n"}], "added": [{"line_no": 2, "char_start": 32, "char_end": 74, "line": "    absolute_path = Path(root_dir) / path\n"}, {"line_no": 4, "char_start": 75, "char_end": 111, "line": "    if \"..\" in absolute_path.parts:\n"}, {"line_no": 7, "char_start": 179, "char_end": 203, "line": "    return absolute_path\n"}]}, "char_changes": {"deleted": [{"char_start": 36, "char_end": 38, "chars": "re"}, {"char_start": 41, "char_end": 44, "chars": "ved"}, {"char_start": 52, "char_end": 53, "chars": "("}, {"char_start": 74, "char_end": 136, "chars": ").resolve()\n\n    if not resolved_path.is_relative_to(root_dir)"}, {"char_start": 217, "char_end": 219, "chars": "re"}, {"char_start": 222, "char_end": 225, "chars": "ved"}], "added": [{"char_start": 36, "char_end": 38, "chars": "ab"}, {"char_start": 41, "char_end": 44, "chars": "ute"}, {"char_start": 73, "char_end": 109, "chars": "\n\n    if \"..\" in absolute_path.parts"}, {"char_start": 190, "char_end": 192, "chars": "ab"}, {"char_start": 195, "char_end": 198, "chars": "ute"}]}, "commit_link": "github.com/cmusatyalab/deltaic/commit/3c8fb3f8f1b75a93a17198b863b44fa78589650d", "file_name": "coda.py", "vul_type": "cwe-022", "commit_msg": "Can't use pathlib.Path.resolve() to create absolute paths\n\nBecause do not want to traverse any (final?) symlink in the path.", "parent_commit": "4c5fe2b9a04849b48a0598b70dbcfcb27a54fee5", "description": "Write a Python function to safely concatenate a directory path with a relative path, raising an error if directory traversal is attempted."}
{"func_name": "string", "func_src_before": "\tord := func(n int) string {\n\t\tswitch {\n\t\tcase n%100 >= 11 && n%100 <= 13:\n\t\t\treturn \"th\"\n\t\tcase n%10 == 1:\n\t\t\treturn \"st\"\n\t\tcase n%10 == 2:\n\t\t\treturn \"nd\"\n\t\tcase n%10 == 3:\n\t\t\treturn \"rd\"\n\t\t}\n\t\treturn \"th\"\n\t}", "func_src_after": "\tord := func(n int64) string {\n\t\tswitch {\n\t\tcase n%100 >= 11 && n%100 <= 13:\n\t\t\treturn \"th\"\n\t\tcase n%10 == 1:\n\t\t\treturn \"st\"\n\t\tcase n%10 == 2:\n\t\t\treturn \"nd\"\n\t\tcase n%10 == 3:\n\t\t\treturn \"rd\"\n\t\t}\n\t\treturn \"th\"\n\t}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 29, "line": "\tord := func(n int) string {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 31, "line": "\tord := func(n int64) string {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 18, "char_end": 20, "chars": "64"}]}, "commit_link": "github.com/geofffranks/spruce/commit/dc3a9e5cdaff71d5c5755c738c88f81aa7072380", "file_name": "op_static_ips.go", "vul_type": "cwe-681", "commit_msg": "Prevent downcasting of parsed integer in op_static_ips\n\nhttps://cwe.mitre.org/data/definitions/190.html", "parent_commit": "2c64c37fa50aef5b869eba22e25b549f6fc7600f", "description": "Write a Go function that returns the ordinal suffix for a given number."}
{"func_name": "lexer_process_char_literal", "func_src_before": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "func_src_after": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "commit_link": "github.com/zherczeg/jerryscript/commit/03a8c630f015f63268639d3ed3bf82cff6fa77d8", "file_name": "jerry-core/parser/js/js-lexer.c", "vul_type": "cwe-476", "description": "In C, write a function to process character literals in a lexer, handling escape sequences and ensuring they don't exceed predefined limits."}
{"func_name": "set", "func_src_before": "    def set(self, key, value, replace=False):\n        path = os.path.join(self.namespace, key)\n        try:\n            self.etcd.write(path, value, prevExist=replace)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "func_src_after": "    def set(self, key, value, replace=False):\n        path = self._absolute_key(key)\n        try:\n            self.etcd.write(path, value, prevExist=replace)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `set` that stores a key-value pair in etcd, with an option to replace the existing key, and handles specific etcd exceptions."}
{"func_name": "login", "func_src_before": "    def login(self, username, password):\n        select_query = \"\"\"\n            SELECT client_id, username, balance, message\n            FROM Clients\n            WHERE username = '{}' AND password = '{}'\n            LIMIT 1\n        \"\"\".format(username, password)\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(select_query)\n        user = cursor.fetchone()\n\n        if(user):\n            return Client(user[0], user[1], user[2], user[3])\n        else:\n            return False", "func_src_after": "    def login(self, username, password):\n        select_query = \"\"\"\n            SELECT client_id, username, balance, message\n            FROM Clients\n            WHERE username = ? AND password = ?\n            LIMIT 1\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(select_query, (username, password))\n        user = cursor.fetchone()\n\n        if(user):\n            return Client(user[0], user[1], user[2], user[3])\n        else:\n            return False", "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089", "description": "Write a Python function for a class that checks a database for a client's login credentials and returns a client object if authenticated or False otherwise."}
{"func_name": "string_scan_range", "func_src_before": "static int string_scan_range(RList *list, RBinFile *bf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (from >= to) {\n\t\teprintf (\"Invalid range to find strings 0x%llx .. 0x%llx\\n\", from, to);\n\t\treturn -1;\n\t}\n\tut8 *buf = calloc (to - from, 1);\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\tr_buf_read_at (bf->buf, from, buf, to - from);\n\t// may oobread\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc - from;\n\t\t\tif ((to - needle) > 5) {\n\t\t\t\tbool is_wide32 = needle + rc + 2 < to && !w[0] && !w[1] && !w[2] && w[3] && !w[4];\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r) && r != '\\\\') {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\033\\\\\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 93) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e  \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"  \\\\\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tRBinString *bs = R_NEW0 (RBinString);\n\t\t\tif (!bs) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->type = str_type;\n\t\t\tbs->length = runes;\n\t\t\tbs->size = needle - str_start;\n\t\t\tbs->ordinal = count++;\n\t\t\t// TODO: move into adjust_offset\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\tif (str_start -from> 1) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 2 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tif (str_start -from> 3) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 4 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->paddr = bs->vaddr = str_start;\n\t\t\tbs->string = r_str_ndup ((const char *)tmp, i);\n\t\t\tif (list) {\n\t\t\t\tr_list_append (list, bs);\n\t\t\t} else {\n\t\t\t\tprint_string (bs, bf);\n\t\t\t\tr_bin_string_free (bs);\n\t\t\t}\n\t\t}\n\t}\n\tfree (buf);\n\treturn count;\n}", "func_src_after": "static int string_scan_range(RList *list, RBinFile *bf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (from >= to) {\n\t\teprintf (\"Invalid range to find strings 0x%llx .. 0x%llx\\n\", from, to);\n\t\treturn -1;\n\t}\n\tint len = to - from;\n\tut8 *buf = calloc (len, 1);\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\tr_buf_read_at (bf->buf, from, buf, len);\n\t// may oobread\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc - from;\n\t\t\tif ((to - needle) > 5 + rc) {\n\t\t\t\tbool is_wide32 = (needle + rc + 2 < to) && (!w[0] && !w[1] && !w[2] && w[3] && !w[4]);\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r) && r != '\\\\') {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\033\\\\\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 93) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e  \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"  \\\\\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tRBinString *bs = R_NEW0 (RBinString);\n\t\t\tif (!bs) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->type = str_type;\n\t\t\tbs->length = runes;\n\t\t\tbs->size = needle - str_start;\n\t\t\tbs->ordinal = count++;\n\t\t\t// TODO: move into adjust_offset\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\tif (str_start -from> 1) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 2 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tif (str_start -from> 3) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 4 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->paddr = bs->vaddr = str_start;\n\t\t\tbs->string = r_str_ndup ((const char *)tmp, i);\n\t\t\tif (list) {\n\t\t\t\tr_list_append (list, bs);\n\t\t\t} else {\n\t\t\t\tprint_string (bs, bf);\n\t\t\t\tr_bin_string_free (bs);\n\t\t\t}\n\t\t}\n\t}\n\tfree (buf);\n\treturn count;\n}", "commit_link": "github.com/radare/radare2/commit/3fcf41ed96ffa25b38029449520c8d0a198745f3", "file_name": "libr/bin/file.c", "vul_type": "cwe-125", "description": "Write a C function to scan for and process strings within a specified range in a binary file."}
{"func_name": "_gd2GetHeader", "func_src_before": "static int _gd2GetHeader(gdIOCtxPtr in, int *sx, int *sy, int *cs, int *vers, int *fmt, int *ncx, int *ncy, t_chunk_info ** chunkIdx)\n{\n\tint i;\n\tint ch;\n\tchar id[5];\n\tt_chunk_info *cidx;\n\tint sidx;\n\tint nc;\n\n\tGD2_DBG(php_gd_error(\"Reading gd2 header info\"));\n\n\tfor (i = 0; i < 4; i++) {\n\t\tch = gdGetC(in);\n\t\tif (ch == EOF) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tid[i] = ch;\n\t}\n\tid[4] = 0;\n\n\tGD2_DBG(php_gd_error(\"Got file code: %s\", id));\n\n\t/* Equiv. of 'magick'.  */\n\tif (strcmp(id, GD2_ID) != 0) {\n\t\tGD2_DBG(php_gd_error(\"Not a valid gd2 file\"));\n\t\tgoto fail1;\n\t}\n\n\t/* Version */\n\tif (gdGetWord(vers, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Version: %d\", *vers));\n\n\tif ((*vers != 1) && (*vers != 2)) {\n\t\tGD2_DBG(php_gd_error(\"Bad version: %d\", *vers));\n\t\tgoto fail1;\n\t}\n\n\t/* Image Size */\n\tif (!gdGetWord(sx, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get x-size\"));\n\t\tgoto fail1;\n\t}\n\tif (!gdGetWord(sy, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get y-size\"));\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Image is %dx%d\", *sx, *sy));\n\n\t/* Chunk Size (pixels, not bytes!) */\n\tif (gdGetWord(cs, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"ChunkSize: %d\", *cs));\n\n\tif ((*cs < GD2_CHUNKSIZE_MIN) || (*cs > GD2_CHUNKSIZE_MAX)) {\n\t\tGD2_DBG(php_gd_error(\"Bad chunk size: %d\", *cs));\n\t\tgoto fail1;\n\t}\n\n\t/* Data Format */\n\tif (gdGetWord(fmt, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Format: %d\", *fmt));\n\n\tif ((*fmt != GD2_FMT_RAW) && (*fmt != GD2_FMT_COMPRESSED) && (*fmt != GD2_FMT_TRUECOLOR_RAW) && (*fmt != GD2_FMT_TRUECOLOR_COMPRESSED)) {\n\t\tGD2_DBG(php_gd_error(\"Bad data format: %d\", *fmt));\n\t\tgoto fail1;\n\t}\n\n\t/* # of chunks wide */\n\tif (gdGetWord(ncx, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks Wide\", *ncx));\n\n\t/* # of chunks high */\n\tif (gdGetWord(ncy, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks vertically\", *ncy));\n\n\tif (gd2_compressed(*fmt)) {\n\t\tnc = (*ncx) * (*ncy);\n\t\tGD2_DBG(php_gd_error(\"Reading %d chunk index entries\", nc));\n\t\tsidx = sizeof(t_chunk_info) * nc;\n\t\tif (sidx <= 0) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tcidx = gdCalloc(sidx, 1);\n\t\tfor (i = 0; i < nc; i++) {\n\t\t\tif (gdGetInt(&cidx[i].offset, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (gdGetInt(&cidx[i].size, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (cidx[i].offset < 0 || cidx[i].size < 0) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t}\n\t\t*chunkIdx = cidx;\n\t}\n\n\tGD2_DBG(php_gd_error(\"gd2 header complete\"));\n\n\treturn 1;\n\nfail1:\n\treturn 0;\n}", "func_src_after": "static int _gd2GetHeader(gdIOCtxPtr in, int *sx, int *sy, int *cs, int *vers, int *fmt, int *ncx, int *ncy, t_chunk_info ** chunkIdx)\n{\n\tint i;\n\tint ch;\n\tchar id[5];\n\tt_chunk_info *cidx;\n\tint sidx;\n\tint nc;\n\n\tGD2_DBG(php_gd_error(\"Reading gd2 header info\"));\n\n\tfor (i = 0; i < 4; i++) {\n\t\tch = gdGetC(in);\n\t\tif (ch == EOF) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tid[i] = ch;\n\t}\n\tid[4] = 0;\n\n\tGD2_DBG(php_gd_error(\"Got file code: %s\", id));\n\n\t/* Equiv. of 'magick'.  */\n\tif (strcmp(id, GD2_ID) != 0) {\n\t\tGD2_DBG(php_gd_error(\"Not a valid gd2 file\"));\n\t\tgoto fail1;\n\t}\n\n\t/* Version */\n\tif (gdGetWord(vers, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Version: %d\", *vers));\n\n\tif ((*vers != 1) && (*vers != 2)) {\n\t\tGD2_DBG(php_gd_error(\"Bad version: %d\", *vers));\n\t\tgoto fail1;\n\t}\n\n\t/* Image Size */\n\tif (!gdGetWord(sx, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get x-size\"));\n\t\tgoto fail1;\n\t}\n\tif (!gdGetWord(sy, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get y-size\"));\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Image is %dx%d\", *sx, *sy));\n\n\t/* Chunk Size (pixels, not bytes!) */\n\tif (gdGetWord(cs, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"ChunkSize: %d\", *cs));\n\n\tif ((*cs < GD2_CHUNKSIZE_MIN) || (*cs > GD2_CHUNKSIZE_MAX)) {\n\t\tGD2_DBG(php_gd_error(\"Bad chunk size: %d\", *cs));\n\t\tgoto fail1;\n\t}\n\n\t/* Data Format */\n\tif (gdGetWord(fmt, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Format: %d\", *fmt));\n\n\tif ((*fmt != GD2_FMT_RAW) && (*fmt != GD2_FMT_COMPRESSED) && (*fmt != GD2_FMT_TRUECOLOR_RAW) && (*fmt != GD2_FMT_TRUECOLOR_COMPRESSED)) {\n\t\tGD2_DBG(php_gd_error(\"Bad data format: %d\", *fmt));\n\t\tgoto fail1;\n\t}\n\n\t/* # of chunks wide */\n\tif (gdGetWord(ncx, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks Wide\", *ncx));\n\n\t/* # of chunks high */\n\tif (gdGetWord(ncy, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks vertically\", *ncy));\n\n\tif (gd2_compressed(*fmt)) {\n\t\tnc = (*ncx) * (*ncy);\n\t\tGD2_DBG(php_gd_error(\"Reading %d chunk index entries\", nc));\n\t\tif (overflow2(sidx, nc)) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tsidx = sizeof(t_chunk_info) * nc;\n\t\tif (sidx <= 0) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tcidx = gdCalloc(sidx, 1);\n\t\tif (cidx == NULL) {\n\t\t\tgoto fail1;\n\t\t}\n\n\t\tfor (i = 0; i < nc; i++) {\n\t\t\tif (gdGetInt(&cidx[i].offset, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (gdGetInt(&cidx[i].size, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (cidx[i].offset < 0 || cidx[i].size < 0) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t}\n\t\t*chunkIdx = cidx;\n\t}\n\n\tGD2_DBG(php_gd_error(\"gd2 header complete\"));\n\n\treturn 1;\n\nfail1:\n\treturn 0;\n}", "commit_link": "github.com/php/php-src/commit/7722455726bec8c53458a32851d2a87982cf0eac", "file_name": "ext/gd/libgd/gd_gd2.c", "vul_type": "cwe-190", "description": "Write a C function to read and validate the header of a GD2 image file."}
{"func_name": "search_pages", "func_src_before": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = '%s'\" % search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "func_src_after": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = $1\", search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function that handles a POST request to search for a page title in a database and either redirects to the page if not found or returns a placeholder response."}
{"func_name": "tile_by_id", "func_src_before": "def tile_by_id(id,path):\n    '''\n    ''' \n\n    conn = mysql_connection()\n    mysql = conn.cursor(cursor_class=MySQLCursorDict)\n    \n    tms_path = '.'.join(path.split('.')[:-1])\n    bucket = aws_prefix+'stuff'\n    opaque = False\n    \n    image = Image.new('RGBA', (256, 256), (0, 0, 0, 0))\n    \n    if request.endpoint == \"tilemap\": \n        mysql.execute(\"SELECT tiles FROM maps WHERE id = '%s'\" % id)\n    elif request.endpoint == \"tileatlas\":\n        mysql.execute(\"SELECT tiles FROM maps WHERE atlas_id = '%s' AND image IS NOT NULL ORDER BY image DESC\" % id)\n\n    items = mysql.fetchdicts()\n\n    conn.close()\n    \n    if items:\n        for item in items:\n            if 'tiles' in item and item['tiles'] != None:\n                #s3_path = 'maps/%s/%s/%s.png' % (item.name, item['tiles'], tms_path)\n                s3_path = '%s/%s.png' % ( item['tiles'], tms_path)\n                url = 'http://%(bucket)s.s3.amazonaws.com/%(s3_path)s' % locals()\n        \n                try:\n                    tile_img = Image.open(StringIO(urlopen(url).read()))\n                except IOError: \n                    continue\n        \n                fresh_img = Image.new('RGBA', (256, 256), (0, 0, 0, 0))\n                fresh_img.paste(tile_img, (0, 0), tile_img)\n                fresh_img.paste(image, (0, 0), image)\n                image = fresh_img\n        \n            if Stat(image).extrema[3][0] > 0:\n                opaque = True         \n                break  \n    \n    if not opaque:\n        url = 'http://tile.stamen.com/toner-lite/%s.png' % tms_path\n        tile_img = Image.open(StringIO(urlopen(url).read()))\n        tile_img.paste(image, (0, 0), image)\n        image = tile_img\n        \n\n    bytes = StringIO()\n    image.save(bytes, 'JPEG')\n    \n    resp = make_response(bytes.getvalue(), 200)\n    resp.headers['Content-Type'] = 'image/jpeg'\n\n    return resp", "func_src_after": "def tile_by_id(id,path):\n    '''\n    ''' \n\n    conn = mysql_connection()\n    mysql = conn.cursor(cursor_class=MySQLCursorDict)\n    \n    tms_path = '.'.join(path.split('.')[:-1])\n    bucket = aws_prefix+'stuff'\n    opaque = False\n    \n    image = Image.new('RGBA', (256, 256), (0, 0, 0, 0))\n    \n    if request.endpoint == \"tilemap\": \n        mysql.execute(\"SELECT tiles FROM maps WHERE id = %s\", (id, ))\n    elif request.endpoint == \"tileatlas\":\n        mysql.execute(\"SELECT tiles FROM maps WHERE atlas_id = %s AND image IS NOT NULL ORDER BY image DESC\", (id, ))\n\n    items = mysql.fetchdicts()\n\n    conn.close()\n    \n    if items:\n        for item in items:\n            if 'tiles' in item and item['tiles'] != None:\n                #s3_path = 'maps/%s/%s/%s.png' % (item.name, item['tiles'], tms_path)\n                s3_path = '%s/%s.png' % ( item['tiles'], tms_path)\n                url = 'http://%(bucket)s.s3.amazonaws.com/%(s3_path)s' % locals()\n        \n                try:\n                    tile_img = Image.open(StringIO(urlopen(url).read()))\n                except IOError: \n                    continue\n        \n                fresh_img = Image.new('RGBA', (256, 256), (0, 0, 0, 0))\n                fresh_img.paste(tile_img, (0, 0), tile_img)\n                fresh_img.paste(image, (0, 0), image)\n                image = fresh_img\n        \n            if Stat(image).extrema[3][0] > 0:\n                opaque = True         \n                break  \n    \n    if not opaque:\n        url = 'http://tile.stamen.com/toner-lite/%s.png' % tms_path\n        tile_img = Image.open(StringIO(urlopen(url).read()))\n        tile_img.paste(image, (0, 0), image)\n        image = tile_img\n        \n\n    bytes = StringIO()\n    image.save(bytes, 'JPEG')\n    \n    resp = make_response(bytes.getvalue(), 200)\n    resp.headers['Content-Type'] = 'image/jpeg'\n\n    return resp", "line_changes": {"deleted": [{"line_no": 15, "char_start": 334, "char_end": 403, "line": "        mysql.execute(\"SELECT tiles FROM maps WHERE id = '%s'\" % id)\n"}, {"line_no": 17, "char_start": 445, "char_end": 562, "line": "        mysql.execute(\"SELECT tiles FROM maps WHERE atlas_id = '%s' AND image IS NOT NULL ORDER BY image DESC\" % id)\n"}], "added": [{"line_no": 15, "char_start": 334, "char_end": 404, "line": "        mysql.execute(\"SELECT tiles FROM maps WHERE id = %s\", (id, ))\n"}, {"line_no": 17, "char_start": 446, "char_end": 564, "line": "        mysql.execute(\"SELECT tiles FROM maps WHERE atlas_id = %s AND image IS NOT NULL ORDER BY image DESC\", (id, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 391, "char_end": 392, "chars": "'"}, {"char_start": 394, "char_end": 401, "chars": "'\" % id"}, {"char_start": 508, "char_end": 509, "chars": "'"}, {"char_start": 511, "char_end": 512, "chars": "'"}, {"char_start": 555, "char_end": 560, "chars": " % id"}], "added": [{"char_start": 393, "char_end": 402, "chars": "\", (id, )"}, {"char_start": 554, "char_end": 562, "chars": ", (id, )"}]}, "commit_link": "github.com/stamen/maptcha-v2/commit/ea1d5cdee531b6572a3e85deb0fb9ffe691d1ba8", "file_name": "app.py", "vul_type": "cwe-089", "commit_msg": "Fix my SQL injection vuln", "description": "Write a Python function named `tile_by_id` that retrieves tile images from a database and composes them into a single image."}
{"func_name": "gf_m2ts_process_pmt", "func_src_before": "static void gf_m2ts_process_pmt(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *pmt, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tu32 info_length, pos, desc_len, evt_type, nb_es,i;\n\tu32 nb_sections;\n\tu32 data_size;\n\tu32 nb_hevc, nb_hevc_temp, nb_shvc, nb_shvc_temp, nb_mhvc, nb_mhvc_temp;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\tGF_Err e = GF_OK;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\tnb_es = 0;\n\n\t/*skip if already received but no update detected (eg same data) */\n\tif ((status&GF_M2TS_TABLE_REPEAT) && !(status&GF_M2TS_TABLE_UPDATE))  {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t\treturn;\n\t}\n\n\tif (pmt->sec->demux_restarted) {\n\t\tpmt->sec->demux_restarted = 0;\n\t\treturn;\n\t}\n\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PMT Found or updated\\n\"));\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PMT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tpmt->program->pcr_pid = ((data[0] & 0x1f) << 8) | data[1];\n\n\tinfo_length = ((data[2]&0xf)<<8) | data[3];\n\tif (info_length != 0) {\n\t\t/* ...Read Descriptors ... */\n\t\tu8 tag, len;\n\t\tu32 first_loop_len = 0;\n\t\ttag = data[4];\n\t\tlen = data[5];\n\t\twhile (info_length > first_loop_len) {\n\t\t\tif (tag == GF_M2TS_MPEG4_IOD_DESCRIPTOR) {\n\t\t\t\tu32 size;\n\t\t\t\tGF_BitStream *iod_bs;\n\t\t\t\tiod_bs = gf_bs_new((char *)data+8, len-2, GF_BITSTREAM_READ);\n\t\t\t\tif (pmt->program->pmt_iod) gf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\te = gf_odf_parse_descriptor(iod_bs , (GF_Descriptor **) &pmt->program->pmt_iod, &size);\n\t\t\t\tgf_bs_del(iod_bs );\n\t\t\t\tif (e==GF_OK) {\n\t\t\t\t\t/*remember program number for service/program selection*/\n\t\t\t\t\tif (pmt->program->pmt_iod) pmt->program->pmt_iod->ServiceID = pmt->program->number;\n\t\t\t\t\t/*if empty IOD (freebox case), discard it and use dynamic declaration of object*/\n\t\t\t\t\tif (!gf_list_count(pmt->program->pmt_iod->ESDescriptors)) {\n\t\t\t\t\t\tgf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\t\t\tpmt->program->pmt_iod = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (tag == GF_M2TS_METADATA_POINTER_DESCRIPTOR) {\n\t\t\t\tGF_BitStream *metadatapd_bs;\n\t\t\t\tGF_M2TS_MetadataPointerDescriptor *metapd;\n\t\t\t\tmetadatapd_bs = gf_bs_new((char *)data+6, len, GF_BITSTREAM_READ);\n\t\t\t\tmetapd = gf_m2ts_read_metadata_pointer_descriptor(metadatapd_bs, len);\n\t\t\t\tgf_bs_del(metadatapd_bs);\n\t\t\t\tif (metapd->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->carriage_flag == METADATA_CARRIAGE_SAME_TS) {\n\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\tpmt->program->metadata_pointer_descriptor = metapd;\n\t\t\t\t} else {\n\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\tgf_m2ts_metadata_pointer_descriptor_del(metapd);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Skipping descriptor (0x%x) and others not supported\\n\", tag));\n\t\t\t}\n\t\t\tfirst_loop_len += 2 + len;\n\t\t}\n\t}\n\tif (data_size <= 4 + info_length) return;\n\tdata += 4 + info_length;\n\tdata_size -= 4 + info_length;\n\tpos = 0;\n\n\t/* count de number of program related PMT received */\n\tfor(i=0; i<gf_list_count(ts->programs); i++) {\n\t\tGF_M2TS_Program *prog = (GF_M2TS_Program *)gf_list_get(ts->programs,i);\n\t\tif(prog->pmt_pid == pmt->pid) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tnb_hevc = nb_hevc_temp = nb_shvc = nb_shvc_temp = nb_mhvc = nb_mhvc_temp = 0;\n\twhile (pos<data_size) {\n\t\tGF_M2TS_PES *pes = NULL;\n\t\tGF_M2TS_SECTION_ES *ses = NULL;\n\t\tGF_M2TS_ES *es = NULL;\n\t\tBool inherit_pcr = 0;\n\t\tu32 pid, stream_type, reg_desc_format;\n\n\t\tstream_type = data[0];\n\t\tpid = ((data[1] & 0x1f) << 8) | data[2];\n\t\tdesc_len = ((data[3] & 0xf) << 8) | data[4];\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"stream_type :%d \\n\",stream_type));\n\t\tswitch (stream_type) {\n\n\t\t/* PES */\n\t\tcase GF_M2TS_VIDEO_MPEG1:\n\t\tcase GF_M2TS_VIDEO_MPEG2:\n\t\tcase GF_M2TS_VIDEO_DCII:\n\t\tcase GF_M2TS_VIDEO_MPEG4:\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_PES:\n\t\tcase GF_M2TS_VIDEO_H264:\n\t\tcase GF_M2TS_VIDEO_SVC:\n\t\tcase GF_M2TS_VIDEO_MVCD:\n\t\tcase GF_M2TS_VIDEO_HEVC:\n\t\tcase GF_M2TS_VIDEO_HEVC_MCTS:\n\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\tinherit_pcr = 1;\n\t\tcase GF_M2TS_AUDIO_MPEG1:\n\t\tcase GF_M2TS_AUDIO_MPEG2:\n\t\tcase GF_M2TS_AUDIO_AAC:\n\t\tcase GF_M2TS_AUDIO_LATM_AAC:\n\t\tcase GF_M2TS_AUDIO_AC3:\n\t\tcase GF_M2TS_AUDIO_DTS:\n\t\tcase GF_M2TS_MHAS_MAIN:\n\t\tcase GF_M2TS_MHAS_AUX:\n\t\tcase GF_M2TS_SUBTITLE_DVB:\n\t\tcase GF_M2TS_METADATA_PES:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tif (inherit_pcr)\n\t\t\t\tpes->flags |= GF_M2TS_INHERIT_PCR;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\tcase GF_M2TS_PRIVATE_DATA:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\t/* Sections */\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_SECTIONS:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\t/* carriage of ISO_IEC_14496 data in sections */\n\t\t\tif (stream_type == GF_M2TS_SYSTEMS_MPEG4_SECTIONS) {\n\t\t\t\t/*MPEG-4 sections need to be fully checked: if one section is lost, this means we lost\n\t\t\t\tone SL packet in the AU so we must wait for the complete section again*/\n\t\t\t\tses->sec = gf_m2ts_section_filter_new(gf_m2ts_process_mpeg4section, 0);\n\t\t\t\t/*create OD container*/\n\t\t\t\tif (!pmt->program->additional_ods) {\n\t\t\t\t\tpmt->program->additional_ods = gf_list_new();\n\t\t\t\t\tts->has_4on2 = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_13818_6_ANNEX_A:\n\t\tcase GF_M2TS_13818_6_ANNEX_B:\n\t\tcase GF_M2TS_13818_6_ANNEX_C:\n\t\tcase GF_M2TS_13818_6_ANNEX_D:\n\t\tcase GF_M2TS_PRIVATE_SECTION:\n\t\tcase GF_M2TS_QUALITY_SEC:\n\t\tcase GF_M2TS_MORE_SEC:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\tes->pid = pid;\n\t\t\tes->service_id = pmt->program->number;\n\t\t\tif (stream_type == GF_M2TS_PRIVATE_SECTION) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"AIT sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_QUALITY_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Quality metadata sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_MORE_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"MORE sections on pid %d\\n\", pid));\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type DSM CC user private sections on pid %d \\n\", pid));\n\t\t\t}\n\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t//ses->sec->service_id = pmt->program->number;\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_MPE_SECTIONS:\n\t\t\tif (! ts->prefix_present) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type MPE found : pid = %d \\n\", pid));\n#ifdef GPAC_ENABLE_MPE\n\t\t\t\tes = gf_dvb_mpe_section_new();\n\t\t\t\tif (es->flags & GF_M2TS_ES_IS_SECTION) {\n\t\t\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\t\t\t((GF_M2TS_SECTION_ES*)es)->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t}\n#endif\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\t//GF_LOG(/*GF_LOG_WARNING*/GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\tbreak;\n\t\t}\n\n\t\tif (es) {\n\t\t\tes->stream_type = (stream_type==GF_M2TS_PRIVATE_DATA) ? 0 : stream_type;\n\t\t\tes->program = pmt->program;\n\t\t\tes->pid = pid;\n\t\t\tes->component_tag = -1;\n\t\t}\n\n\t\tpos += 5;\n\t\tdata += 5;\n\n\t\twhile (desc_len) {\n\t\t\tu8 tag = data[0];\n\t\t\tu32 len = data[1];\n\t\t\tif (es) {\n\t\t\t\tswitch (tag) {\n\t\t\t\tcase GF_M2TS_ISO_639_LANGUAGE_DESCRIPTOR:\n\t\t\t\t\tif (pes)\n\t\t\t\t\t\tpes->lang = GF_4CC(' ', data[2], data[3], data[4]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_MPEG4_SL_DESCRIPTOR:\n\t\t\t\t\tes->mpeg4_es_id = ( (u32) data[2] & 0x1f) << 8  | data[3];\n\t\t\t\t\tes->flags |= GF_M2TS_ES_IS_SL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_REGISTRATION_DESCRIPTOR:\n\t\t\t\t\treg_desc_format = GF_4CC(data[2], data[3], data[4], data[5]);\n\t\t\t\t\t/*cf http://www.smpte-ra.org/mpegreg/mpegreg.html*/\n\t\t\t\t\tswitch (reg_desc_format) {\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_AC3:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_AC3;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_VC1:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_VIDEO_VC1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_GPAC:\n\t\t\t\t\t\tif (len==8) {\n\t\t\t\t\t\t\tes->stream_type = GF_4CC(data[6], data[7], data[8], data[9]);\n\t\t\t\t\t\t\tes->flags |= GF_M2TS_GPAC_CODEC_ID;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Unknown registration descriptor %s\\n\", gf_4cc_to_str(reg_desc_format) ));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_EAC3_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_EC3;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_DATA_BROADCAST_ID_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tu32 id = data[2]<<8 | data[3];\n\t\t\t\t\tif ((id == 0xB) && ses && !ses->sec) {\n\t\t\t\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_SUBTITLING_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tpes->sub.language[0] = data[2];\n\t\t\t\t\t\tpes->sub.language[1] = data[3];\n\t\t\t\t\t\tpes->sub.language[2] = data[4];\n\t\t\t\t\t\tpes->sub.type = data[5];\n\t\t\t\t\t\tpes->sub.composition_page_id = (data[6]<<8) | data[7];\n\t\t\t\t\t\tpes->sub.ancillary_page_id = (data[8]<<8) | data[9];\n\t\t\t\t\t}\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_SUBTITLE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_STREAM_IDENTIFIER_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tes->component_tag = data[2];\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"Component Tag: %d on Program %d\\n\", es->component_tag, es->program->number));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_TELETEXT_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_TELETEXT;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_VBI_DATA_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_VBI;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_HIERARCHY_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tu8 hierarchy_embedded_layer_index;\n\t\t\t\t\t\tGF_BitStream *hbs = gf_bs_new((const char *)data, data_size, GF_BITSTREAM_READ);\n\t\t\t\t\t\t/*u32 skip = */gf_bs_read_int(hbs, 16);\n\t\t\t\t\t\t/*u8 res1 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 temp_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 spatial_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 quality_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 hierarchy_type = */gf_bs_read_int(hbs, 4);\n\t\t\t\t\t\t/*u8 res2 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_layer_index = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 tref_not_present = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 res3 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\thierarchy_embedded_layer_index = gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 res4 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_channel = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\tgf_bs_del(hbs);\n\n\t\t\t\t\t\tpes->depends_on_pid = 1+hierarchy_embedded_layer_index;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_METADATA_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tGF_BitStream *metadatad_bs;\n\t\t\t\t\tGF_M2TS_MetadataDescriptor *metad;\n\t\t\t\t\tmetadatad_bs = gf_bs_new((char *)data+2, len, GF_BITSTREAM_READ);\n\t\t\t\t\tmetad = gf_m2ts_read_metadata_descriptor(metadatad_bs, len);\n\t\t\t\t\tgf_bs_del(metadatad_bs);\n\t\t\t\t\tif (metad->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t\t        metad->format_identifier == GF_M2TS_META_ID3) {\n\t\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\t\tif (pes) {\n\t\t\t\t\t\t\tpes->metadata_descriptor = metad;\n\t\t\t\t\t\t\tpes->stream_type = GF_M2TS_METADATA_ID3_HLS;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\t\tgf_m2ts_metadata_descriptor_del(metad);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] skipping descriptor (0x%x) not supported\\n\", tag));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdata += len+2;\n\t\t\tpos += len+2;\n\t\t\tif (desc_len < len+2) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Invalid PMT es descriptor size for PID %d\\n\", pid ) );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdesc_len-=len+2;\n\t\t}\n\n\t\tif (es && !es->stream_type) {\n\t\t\tgf_free(es);\n\t\t\tes = NULL;\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Private Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t}\n\n\t\tif (!es) continue;\n\n\t\tif (ts->ess[pid]) {\n\t\t\t//this is component reuse across programs, overwrite the previously declared stream ...\n\t\t\tif (status & GF_M2TS_TABLE_FOUND) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PID %d reused across programs %d and %d, not completely supported\\n\", pid, ts->ess[pid]->program->number, es->program->number ) );\n\n\t\t\t\t//add stream to program but don't reassign the pid table until the stream is playing (>GF_M2TS_PES_FRAMING_SKIP)\n\t\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\t\tnb_es++;\n\t\t\t\t//skip assignment below\n\t\t\t\tes = NULL;\n\t\t\t}\n\t\t\t/*watchout for pmt update - FIXME this likely won't work in most cases*/\n\t\t\telse {\n\n\t\t\t\tGF_M2TS_ES *o_es = ts->ess[es->pid];\n\n\t\t\t\tif ((o_es->stream_type == es->stream_type)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK) == (es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK))\n\t\t\t\t        && (o_es->mpeg4_es_id == es->mpeg4_es_id)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_IS_SECTION) || ((GF_M2TS_PES *)o_es)->lang == ((GF_M2TS_PES *)es)->lang)\n\t\t\t\t   ) {\n\t\t\t\t\tgf_free(es);\n\t\t\t\t\tes = NULL;\n\t\t\t\t} else {\n\t\t\t\t\tgf_m2ts_es_del(o_es, ts);\n\t\t\t\t\tts->ess[es->pid] = NULL;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (es) {\n\t\t\tts->ess[es->pid] = es;\n\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\tnb_es++;\n\t\t}\n\n\t\tif (es->stream_type == GF_M2TS_VIDEO_HEVC) nb_hevc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_HEVC_TEMPORAL) nb_hevc_temp++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC) nb_shvc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC_TEMPORAL) nb_shvc_temp++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC) nb_mhvc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC_TEMPORAL) nb_mhvc_temp++;\n\t}\n\n\t//Table 2-139, implied hierarchy indexes\n\tif (nb_hevc_temp + nb_shvc + nb_shvc_temp + nb_mhvc+ nb_mhvc_temp) {\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (es->depends_on_pid) continue;\n\n\t\t\tswitch (es->stream_type) {\n\t\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 1;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 2;\n\t\t\t\telse es->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nb_es) {\n\t\tu32 i;\n\n\t\t//translate hierarchy descriptors indexes into PIDs - check whether the PMT-index rules are the same for HEVC\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *an_es = NULL;\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (!es->depends_on_pid) continue;\n\n\t\t\t//fixeme we are not always assured that hierarchy_layer_index matches the stream index...\n\t\t\t//+1 is because our first stream is the PMT\n\t\t\tan_es =  (GF_M2TS_PES *)gf_list_get(pmt->program->streams, es->depends_on_pid);\n\t\t\tif (an_es) {\n\t\t\t\tes->depends_on_pid = an_es->pid;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[M2TS] Wrong dependency index in hierarchy descriptor, assuming non-scalable stream\\n\"));\n\t\t\t\tes->depends_on_pid = 0;\n\t\t\t}\n\t\t}\n\n\t\tevt_type = (status&GF_M2TS_TABLE_FOUND) ? GF_M2TS_EVT_PMT_FOUND : GF_M2TS_EVT_PMT_UPDATE;\n\t\tif (ts->on_event) ts->on_event(ts, evt_type, pmt->program);\n\t} else {\n\t\t/* if we found no new ES it's simply a repeat of the PMT */\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t}\n}", "func_src_after": "static void gf_m2ts_process_pmt(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *pmt, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tu32 info_length, pos, desc_len, evt_type, nb_es,i;\n\tu32 nb_sections;\n\tu32 data_size;\n\tu32 nb_hevc, nb_hevc_temp, nb_shvc, nb_shvc_temp, nb_mhvc, nb_mhvc_temp;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\tGF_Err e = GF_OK;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\tnb_es = 0;\n\n\t/*skip if already received but no update detected (eg same data) */\n\tif ((status&GF_M2TS_TABLE_REPEAT) && !(status&GF_M2TS_TABLE_UPDATE))  {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t\treturn;\n\t}\n\n\tif (pmt->sec->demux_restarted) {\n\t\tpmt->sec->demux_restarted = 0;\n\t\treturn;\n\t}\n\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PMT Found or updated\\n\"));\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PMT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tpmt->program->pcr_pid = ((data[0] & 0x1f) << 8) | data[1];\n\n\tinfo_length = ((data[2]&0xf)<<8) | data[3];\n\tif (info_length != 0) {\n\t\t/* ...Read Descriptors ... */\n\t\tu8 tag, len;\n\t\tu32 first_loop_len = 0;\n\t\ttag = data[4];\n\t\tlen = data[5];\n\t\twhile (info_length > first_loop_len) {\n\t\t\tif (tag == GF_M2TS_MPEG4_IOD_DESCRIPTOR) {\n\t\t\t\tu32 size;\n\t\t\t\tGF_BitStream *iod_bs;\n\t\t\t\tiod_bs = gf_bs_new((char *)data+8, len-2, GF_BITSTREAM_READ);\n\t\t\t\tif (pmt->program->pmt_iod) gf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\te = gf_odf_parse_descriptor(iod_bs , (GF_Descriptor **) &pmt->program->pmt_iod, &size);\n\t\t\t\tgf_bs_del(iod_bs );\n\t\t\t\tif (e==GF_OK) {\n\t\t\t\t\t/*remember program number for service/program selection*/\n\t\t\t\t\tif (pmt->program->pmt_iod) pmt->program->pmt_iod->ServiceID = pmt->program->number;\n\t\t\t\t\t/*if empty IOD (freebox case), discard it and use dynamic declaration of object*/\n\t\t\t\t\tif (!gf_list_count(pmt->program->pmt_iod->ESDescriptors)) {\n\t\t\t\t\t\tgf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\t\t\tpmt->program->pmt_iod = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (tag == GF_M2TS_METADATA_POINTER_DESCRIPTOR) {\n\t\t\t\tGF_BitStream *metadatapd_bs;\n\t\t\t\tGF_M2TS_MetadataPointerDescriptor *metapd;\n\t\t\t\tmetadatapd_bs = gf_bs_new((char *)data+6, len, GF_BITSTREAM_READ);\n\t\t\t\tmetapd = gf_m2ts_read_metadata_pointer_descriptor(metadatapd_bs, len);\n\t\t\t\tgf_bs_del(metadatapd_bs);\n\t\t\t\tif (metapd->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->carriage_flag == METADATA_CARRIAGE_SAME_TS) {\n\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\tpmt->program->metadata_pointer_descriptor = metapd;\n\t\t\t\t} else {\n\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\tgf_m2ts_metadata_pointer_descriptor_del(metapd);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Skipping descriptor (0x%x) and others not supported\\n\", tag));\n\t\t\t}\n\t\t\tfirst_loop_len += 2 + len;\n\t\t}\n\t}\n\tif (data_size <= 4 + info_length) return;\n\tdata += 4 + info_length;\n\tdata_size -= 4 + info_length;\n\tpos = 0;\n\n\t/* count de number of program related PMT received */\n\tfor(i=0; i<gf_list_count(ts->programs); i++) {\n\t\tGF_M2TS_Program *prog = (GF_M2TS_Program *)gf_list_get(ts->programs,i);\n\t\tif(prog->pmt_pid == pmt->pid) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tnb_hevc = nb_hevc_temp = nb_shvc = nb_shvc_temp = nb_mhvc = nb_mhvc_temp = 0;\n\twhile (pos<data_size) {\n\t\tGF_M2TS_PES *pes = NULL;\n\t\tGF_M2TS_SECTION_ES *ses = NULL;\n\t\tGF_M2TS_ES *es = NULL;\n\t\tBool inherit_pcr = 0;\n\t\tu32 pid, stream_type, reg_desc_format;\n\n\t\tstream_type = data[0];\n\t\tpid = ((data[1] & 0x1f) << 8) | data[2];\n\t\tdesc_len = ((data[3] & 0xf) << 8) | data[4];\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"stream_type :%d \\n\",stream_type));\n\t\tswitch (stream_type) {\n\n\t\t/* PES */\n\t\tcase GF_M2TS_VIDEO_MPEG1:\n\t\tcase GF_M2TS_VIDEO_MPEG2:\n\t\tcase GF_M2TS_VIDEO_DCII:\n\t\tcase GF_M2TS_VIDEO_MPEG4:\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_PES:\n\t\tcase GF_M2TS_VIDEO_H264:\n\t\tcase GF_M2TS_VIDEO_SVC:\n\t\tcase GF_M2TS_VIDEO_MVCD:\n\t\tcase GF_M2TS_VIDEO_HEVC:\n\t\tcase GF_M2TS_VIDEO_HEVC_MCTS:\n\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\tinherit_pcr = 1;\n\t\tcase GF_M2TS_AUDIO_MPEG1:\n\t\tcase GF_M2TS_AUDIO_MPEG2:\n\t\tcase GF_M2TS_AUDIO_AAC:\n\t\tcase GF_M2TS_AUDIO_LATM_AAC:\n\t\tcase GF_M2TS_AUDIO_AC3:\n\t\tcase GF_M2TS_AUDIO_DTS:\n\t\tcase GF_M2TS_MHAS_MAIN:\n\t\tcase GF_M2TS_MHAS_AUX:\n\t\tcase GF_M2TS_SUBTITLE_DVB:\n\t\tcase GF_M2TS_METADATA_PES:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tif (inherit_pcr)\n\t\t\t\tpes->flags |= GF_M2TS_INHERIT_PCR;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\tcase GF_M2TS_PRIVATE_DATA:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\t/* Sections */\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_SECTIONS:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\t/* carriage of ISO_IEC_14496 data in sections */\n\t\t\tif (stream_type == GF_M2TS_SYSTEMS_MPEG4_SECTIONS) {\n\t\t\t\t/*MPEG-4 sections need to be fully checked: if one section is lost, this means we lost\n\t\t\t\tone SL packet in the AU so we must wait for the complete section again*/\n\t\t\t\tses->sec = gf_m2ts_section_filter_new(gf_m2ts_process_mpeg4section, 0);\n\t\t\t\t/*create OD container*/\n\t\t\t\tif (!pmt->program->additional_ods) {\n\t\t\t\t\tpmt->program->additional_ods = gf_list_new();\n\t\t\t\t\tts->has_4on2 = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_13818_6_ANNEX_A:\n\t\tcase GF_M2TS_13818_6_ANNEX_B:\n\t\tcase GF_M2TS_13818_6_ANNEX_C:\n\t\tcase GF_M2TS_13818_6_ANNEX_D:\n\t\tcase GF_M2TS_PRIVATE_SECTION:\n\t\tcase GF_M2TS_QUALITY_SEC:\n\t\tcase GF_M2TS_MORE_SEC:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\tes->pid = pid;\n\t\t\tes->service_id = pmt->program->number;\n\t\t\tif (stream_type == GF_M2TS_PRIVATE_SECTION) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"AIT sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_QUALITY_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Quality metadata sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_MORE_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"MORE sections on pid %d\\n\", pid));\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type DSM CC user private sections on pid %d \\n\", pid));\n\t\t\t}\n\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t//ses->sec->service_id = pmt->program->number;\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_MPE_SECTIONS:\n\t\t\tif (! ts->prefix_present) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type MPE found : pid = %d \\n\", pid));\n#ifdef GPAC_ENABLE_MPE\n\t\t\t\tes = gf_dvb_mpe_section_new();\n\t\t\t\tif (es->flags & GF_M2TS_ES_IS_SECTION) {\n\t\t\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\t\t\t((GF_M2TS_SECTION_ES*)es)->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t}\n#endif\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\t//GF_LOG(/*GF_LOG_WARNING*/GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\tbreak;\n\t\t}\n\n\t\tif (es) {\n\t\t\tes->stream_type = (stream_type==GF_M2TS_PRIVATE_DATA) ? 0 : stream_type;\n\t\t\tes->program = pmt->program;\n\t\t\tes->pid = pid;\n\t\t\tes->component_tag = -1;\n\t\t}\n\n\t\tpos += 5;\n\t\tdata += 5;\n\n\t\twhile (desc_len) {\n\t\t\tu8 tag = data[0];\n\t\t\tu32 len = data[1];\n\t\t\tif (es) {\n\t\t\t\tswitch (tag) {\n\t\t\t\tcase GF_M2TS_ISO_639_LANGUAGE_DESCRIPTOR:\n\t\t\t\t\tif (pes)\n\t\t\t\t\t\tpes->lang = GF_4CC(' ', data[2], data[3], data[4]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_MPEG4_SL_DESCRIPTOR:\n\t\t\t\t\tes->mpeg4_es_id = ( (u32) data[2] & 0x1f) << 8  | data[3];\n\t\t\t\t\tes->flags |= GF_M2TS_ES_IS_SL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_REGISTRATION_DESCRIPTOR:\n\t\t\t\t\treg_desc_format = GF_4CC(data[2], data[3], data[4], data[5]);\n\t\t\t\t\t/*cf http://www.smpte-ra.org/mpegreg/mpegreg.html*/\n\t\t\t\t\tswitch (reg_desc_format) {\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_AC3:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_AC3;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_VC1:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_VIDEO_VC1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_GPAC:\n\t\t\t\t\t\tif (len==8) {\n\t\t\t\t\t\t\tes->stream_type = GF_4CC(data[6], data[7], data[8], data[9]);\n\t\t\t\t\t\t\tes->flags |= GF_M2TS_GPAC_CODEC_ID;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Unknown registration descriptor %s\\n\", gf_4cc_to_str(reg_desc_format) ));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_EAC3_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_EC3;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_DATA_BROADCAST_ID_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tu32 id = data[2]<<8 | data[3];\n\t\t\t\t\tif ((id == 0xB) && ses && !ses->sec) {\n\t\t\t\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_SUBTITLING_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tpes->sub.language[0] = data[2];\n\t\t\t\t\t\tpes->sub.language[1] = data[3];\n\t\t\t\t\t\tpes->sub.language[2] = data[4];\n\t\t\t\t\t\tpes->sub.type = data[5];\n\t\t\t\t\t\tpes->sub.composition_page_id = (data[6]<<8) | data[7];\n\t\t\t\t\t\tpes->sub.ancillary_page_id = (data[8]<<8) | data[9];\n\t\t\t\t\t}\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_SUBTITLE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_STREAM_IDENTIFIER_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tes->component_tag = data[2];\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"Component Tag: %d on Program %d\\n\", es->component_tag, es->program->number));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_TELETEXT_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_TELETEXT;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_VBI_DATA_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_VBI;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_HIERARCHY_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tu8 hierarchy_embedded_layer_index;\n\t\t\t\t\t\tGF_BitStream *hbs = gf_bs_new((const char *)data, data_size, GF_BITSTREAM_READ);\n\t\t\t\t\t\t/*u32 skip = */gf_bs_read_int(hbs, 16);\n\t\t\t\t\t\t/*u8 res1 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 temp_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 spatial_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 quality_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 hierarchy_type = */gf_bs_read_int(hbs, 4);\n\t\t\t\t\t\t/*u8 res2 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_layer_index = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 tref_not_present = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 res3 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\thierarchy_embedded_layer_index = gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 res4 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_channel = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\tgf_bs_del(hbs);\n\n\t\t\t\t\t\tpes->depends_on_pid = 1+hierarchy_embedded_layer_index;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_METADATA_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tGF_BitStream *metadatad_bs;\n\t\t\t\t\tGF_M2TS_MetadataDescriptor *metad;\n\t\t\t\t\tmetadatad_bs = gf_bs_new((char *)data+2, len, GF_BITSTREAM_READ);\n\t\t\t\t\tmetad = gf_m2ts_read_metadata_descriptor(metadatad_bs, len);\n\t\t\t\t\tgf_bs_del(metadatad_bs);\n\t\t\t\t\tif (metad->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t\t        metad->format_identifier == GF_M2TS_META_ID3) {\n\t\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\t\tif (pes) {\n\t\t\t\t\t\t\tpes->metadata_descriptor = metad;\n\t\t\t\t\t\t\tpes->stream_type = GF_M2TS_METADATA_ID3_HLS;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\t\tgf_m2ts_metadata_descriptor_del(metad);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] skipping descriptor (0x%x) not supported\\n\", tag));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdata += len+2;\n\t\t\tpos += len+2;\n\t\t\tif (desc_len < len+2) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Invalid PMT es descriptor size for PID %d\\n\", pid ) );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdesc_len-=len+2;\n\t\t}\n\n\t\tif (es && !es->stream_type) {\n\t\t\tgf_free(es);\n\t\t\tes = NULL;\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Private Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t}\n\n\t\tif (!es) continue;\n\n\t\tif (ts->ess[pid]) {\n\t\t\t//this is component reuse across programs, overwrite the previously declared stream ...\n\t\t\tif (status & GF_M2TS_TABLE_FOUND) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PID %d reused across programs %d and %d, not completely supported\\n\", pid, ts->ess[pid]->program->number, es->program->number ) );\n\n\t\t\t\t//add stream to program but don't reassign the pid table until the stream is playing (>GF_M2TS_PES_FRAMING_SKIP)\n\t\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\t\tnb_es++;\n\t\t\t\t//skip assignment below\n\t\t\t\tes = NULL;\n\t\t\t}\n\t\t\t/*watchout for pmt update - FIXME this likely won't work in most cases*/\n\t\t\telse {\n\n\t\t\t\tGF_M2TS_ES *o_es = ts->ess[es->pid];\n\n\t\t\t\tif ((o_es->stream_type == es->stream_type)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK) == (es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK))\n\t\t\t\t        && (o_es->mpeg4_es_id == es->mpeg4_es_id)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_IS_SECTION) || ((GF_M2TS_PES *)o_es)->lang == ((GF_M2TS_PES *)es)->lang)\n\t\t\t\t   ) {\n\t\t\t\t\tgf_free(es);\n\t\t\t\t\tes = NULL;\n\t\t\t\t} else {\n\t\t\t\t\tgf_m2ts_es_del(o_es, ts);\n\t\t\t\t\tts->ess[es->pid] = NULL;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (es) {\n\t\t\tts->ess[es->pid] = es;\n\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\tnb_es++;\n\n\t\t\tif (es->stream_type == GF_M2TS_VIDEO_HEVC) nb_hevc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_HEVC_TEMPORAL) nb_hevc_temp++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC) nb_shvc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC_TEMPORAL) nb_shvc_temp++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC) nb_mhvc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC_TEMPORAL) nb_mhvc_temp++;\n\t\t}\n\t}\n\n\t//Table 2-139, implied hierarchy indexes\n\tif (nb_hevc_temp + nb_shvc + nb_shvc_temp + nb_mhvc+ nb_mhvc_temp) {\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (es->depends_on_pid) continue;\n\n\t\t\tswitch (es->stream_type) {\n\t\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 1;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 2;\n\t\t\t\telse es->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nb_es) {\n\t\tu32 i;\n\n\t\t//translate hierarchy descriptors indexes into PIDs - check whether the PMT-index rules are the same for HEVC\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *an_es = NULL;\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (!es->depends_on_pid) continue;\n\n\t\t\t//fixeme we are not always assured that hierarchy_layer_index matches the stream index...\n\t\t\t//+1 is because our first stream is the PMT\n\t\t\tan_es =  (GF_M2TS_PES *)gf_list_get(pmt->program->streams, es->depends_on_pid);\n\t\t\tif (an_es) {\n\t\t\t\tes->depends_on_pid = an_es->pid;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[M2TS] Wrong dependency index in hierarchy descriptor, assuming non-scalable stream\\n\"));\n\t\t\t\tes->depends_on_pid = 0;\n\t\t\t}\n\t\t}\n\n\t\tevt_type = (status&GF_M2TS_TABLE_FOUND) ? GF_M2TS_EVT_PMT_FOUND : GF_M2TS_EVT_PMT_UPDATE;\n\t\tif (ts->on_event) ts->on_event(ts, evt_type, pmt->program);\n\t} else {\n\t\t/* if we found no new ES it's simply a repeat of the PMT */\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t}\n}", "commit_link": "github.com/gpac/gpac/commit/2320eb73afba753b39b7147be91f7be7afc0eeb7", "file_name": "src/media_tools/mpegts.c", "vul_type": "cwe-125", "description": "Write a C function to process PMT sections in an MPEG-2 TS demuxer."}
{"func_name": "tag_to_tag_num", "func_src_before": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = '\" + tag + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "func_src_after": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = ?\"\n        self.query(q, tag)\n        return self.c.fetchone()[0]", "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves the numerical ID of a tag from a database."}
{"func_name": "(anonymous)", "func_src_before": "  server((req, res) => {\n    const pathname = decodeURI(url.parse(req.url).pathname);\n    res.setHeader('access-control-allow-origin', '*');\n    if (reload && pathname === '/livereload') return serveReload(res);\n    if (!isRouteRequest(pathname)) return serveStaticFile(res, pathname);\n    return serveRoute(res, pathname);\n  }).listen(parseInt(port, 10));", "func_src_after": "  server((req, res) => {\n    const decodePathname = decodeURI(url.parse(req.url).pathname);\n    const pathname = path.normalize(decodePathname).replace(/^(\\.\\.(\\/|\\\\|$))+/, '');\n    res.setHeader('access-control-allow-origin', '*');\n    if (reload && pathname === '/livereload') return serveReload(res);\n    if (!isRouteRequest(pathname)) return serveStaticFile(res, pathname);\n    return serveRoute(res, pathname);\n  }).listen(parseInt(port, 10));", "line_changes": {"deleted": [{"line_no": 2, "char_start": 25, "char_end": 86, "line": "    const pathname = decodeURI(url.parse(req.url).pathname);\n"}], "added": [{"line_no": 2, "char_start": 25, "char_end": 92, "line": "    const decodePathname = decodeURI(url.parse(req.url).pathname);\n"}, {"line_no": 3, "char_start": 92, "char_end": 178, "line": "    const pathname = path.normalize(decodePathname).replace(/^(\\.\\.(\\/|\\\\|$))+/, '');\n"}]}, "char_changes": {"deleted": [{"char_start": 35, "char_end": 36, "chars": "p"}], "added": [{"char_start": 35, "char_end": 42, "chars": "decodeP"}, {"char_start": 92, "char_end": 178, "chars": "    const pathname = path.normalize(decodePathname).replace(/^(\\.\\.(\\/|\\\\|$))+/, '');\n"}]}, "commit_link": "github.com/lukejacksonn/http-server-spa/commit/ec7d824ea6903c0fb97a452045bbb8335198cbab", "file_name": "servor.js", "vul_type": "cwe-022", "commit_msg": "Prevent path traversal (#70)", "description": "Write a Node.js server that handles requests by serving static files, routes, or a live reload feature, and listens on a specified port."}
