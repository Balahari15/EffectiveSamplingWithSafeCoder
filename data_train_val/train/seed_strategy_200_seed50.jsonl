{"func_name": "unicode_unfold_key", "func_src_before": "unicode_unfold_key(OnigCodePoint code)\n{\n  static const struct ByUnfoldKey wordlist[] =\n    {\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0x1040a, 3267, 1},\n\n      {0x1e0a, 1727, 1},\n\n      {0x040a, 1016, 1},\n\n      {0x010a, 186, 1},\n\n      {0x1f0a, 2088, 1},\n\n      {0x2c0a, 2451, 1},\n\n      {0x0189, 619, 1},\n\n      {0x1f89, 134, 2},\n\n      {0x1f85, 154, 2},\n\n      {0x0389, 733, 1},\n\n      {0x03ff, 724, 1},\n\n      {0xab89, 1523, 1},\n\n      {0xab85, 1511, 1},\n\n      {0x10c89, 3384, 1},\n\n      {0x10c85, 3372, 1},\n\n      {0x1e84, 1911, 1},\n\n      {0x03f5, 752, 1},\n\n      {0x0184, 360, 1},\n\n      {0x1f84, 149, 2},\n\n      {0x2c84, 2592, 1},\n\n      {0x017d, 351, 1},\n\n      {0x1ff3, 96, 2},\n\n      {0xab84, 1508, 1},\n\n      {0xa784, 3105, 1},\n\n      {0x10c84, 3369, 1},\n\n      {0xab7d, 1487, 1},\n\n      {0xa77d, 1706, 1},\n\n      {0x1e98, 38, 2},\n\n      {0x0498, 1106, 1},\n\n      {0x0198, 375, 1},\n\n      {0x1f98, 169, 2},\n\n      {0x2c98, 2622, 1},\n\n      {0x0398, 762, 1},\n\n      {0xa684, 2940, 1},\n\n      {0xab98, 1568, 1},\n\n      {0xa798, 3123, 1},\n\n      {0x10c98, 3429, 1},\n\n      {0x050a, 1277, 1},\n\n      {0x1ffb, 2265, 1},\n\n      {0x1e96, 16, 2},\n\n      {0x0496, 1103, 1},\n\n      {0x0196, 652, 1},\n\n      {0x1f96, 199, 2},\n\n      {0x2c96, 2619, 1},\n\n      {0x0396, 756, 1},\n\n      {0xa698, 2970, 1},\n\n      {0xab96, 1562, 1},\n\n      {0xa796, 3120, 1},\n\n      {0x10c96, 3423, 1},\n\n      {0x1feb, 2259, 1},\n\n      {0x2ceb, 2736, 1},\n\n      {0x1e90, 1929, 1},\n\n      {0x0490, 1094, 1},\n\n      {0x0190, 628, 1},\n\n      {0x1f90, 169, 2},\n\n      {0x2c90, 2610, 1},\n\n      {0x0390, 25, 3},\n\n      {0xa696, 2967, 1},\n\n      {0xab90, 1544, 1},\n\n      {0xa790, 3114, 1},\n\n      {0x10c90, 3405, 1},\n\n      {0x01d7, 444, 1},\n\n      {0x1fd7, 31, 3},\n\n      {0x1ea6, 1947, 1},\n\n      {0x04a6, 1127, 1},\n\n      {0x01a6, 676, 1},\n\n      {0x1fa6, 239, 2},\n\n      {0x2ca6, 2643, 1},\n\n      {0x03a6, 810, 1},\n\n      {0xa690, 2958, 1},\n\n      {0xaba6, 1610, 1},\n\n      {0xa7a6, 3144, 1},\n\n      {0x10ca6, 3471, 1},\n\n      {0x1ea4, 1944, 1},\n\n      {0x04a4, 1124, 1},\n\n      {0x01a4, 390, 1},\n\n      {0x1fa4, 229, 2},\n\n      {0x2ca4, 2640, 1},\n\n      {0x03a4, 804, 1},\n\n      {0x10a6, 2763, 1},\n\n      {0xaba4, 1604, 1},\n\n      {0xa7a4, 3141, 1},\n\n      {0x10ca4, 3465, 1},\n\n      {0x1ea0, 1938, 1},\n\n      {0x04a0, 1118, 1},\n\n      {0x01a0, 384, 1},\n\n      {0x1fa0, 209, 2},\n\n      {0x2ca0, 2634, 1},\n\n      {0x03a0, 792, 1},\n\n      {0x10a4, 2757, 1},\n\n      {0xaba0, 1592, 1},\n\n      {0xa7a0, 3135, 1},\n\n      {0x10ca0, 3453, 1},\n\n      {0x1eb2, 1965, 1},\n\n      {0x04b2, 1145, 1},\n\n      {0x01b2, 694, 1},\n\n      {0x1fb2, 249, 2},\n\n      {0x2cb2, 2661, 1},\n\n      {0x03fd, 718, 1},\n\n      {0x10a0, 2745, 1},\n\n      {0xabb2, 1646, 1},\n\n      {0xa7b2, 703, 1},\n\n      {0x10cb2, 3507, 1},\n\n      {0x1eac, 1956, 1},\n\n      {0x04ac, 1136, 1},\n\n      {0x01ac, 396, 1},\n\n      {0x1fac, 229, 2},\n\n      {0x2cac, 2652, 1},\n\n      {0x0537, 1352, 1},\n\n      {0x10b2, 2799, 1},\n\n      {0xabac, 1628, 1},\n\n      {0xa7ac, 637, 1},\n\n      {0x10cac, 3489, 1},\n\n      {0x1eaa, 1953, 1},\n\n      {0x04aa, 1133, 1},\n\n      {0x00dd, 162, 1},\n\n      {0x1faa, 219, 2},\n\n      {0x2caa, 2649, 1},\n\n      {0x03aa, 824, 1},\n\n      {0x10ac, 2781, 1},\n\n      {0xabaa, 1622, 1},\n\n      {0xa7aa, 646, 1},\n\n      {0x10caa, 3483, 1},\n\n      {0x1ea8, 1950, 1},\n\n      {0x04a8, 1130, 1},\n\n      {0x020a, 517, 1},\n\n      {0x1fa8, 209, 2},\n\n      {0x2ca8, 2646, 1},\n\n      {0x03a8, 817, 1},\n\n      {0x10aa, 2775, 1},\n\n      {0xaba8, 1616, 1},\n\n      {0xa7a8, 3147, 1},\n\n      {0x10ca8, 3477, 1},\n\n      {0x1ea2, 1941, 1},\n\n      {0x04a2, 1121, 1},\n\n      {0x01a2, 387, 1},\n\n      {0x1fa2, 219, 2},\n\n      {0x2ca2, 2637, 1},\n\n      {0x118a6, 3528, 1},\n\n      {0x10a8, 2769, 1},\n\n      {0xaba2, 1598, 1},\n\n      {0xa7a2, 3138, 1},\n\n      {0x10ca2, 3459, 1},\n\n      {0x2ced, 2739, 1},\n\n      {0x1fe9, 2283, 1},\n\n      {0x1fe7, 47, 3},\n\n      {0x1eb0, 1962, 1},\n\n      {0x04b0, 1142, 1},\n\n      {0x118a4, 3522, 1},\n\n      {0x10a2, 2751, 1},\n\n      {0x2cb0, 2658, 1},\n\n      {0x03b0, 41, 3},\n\n      {0x1fe3, 41, 3},\n\n      {0xabb0, 1640, 1},\n\n      {0xa7b0, 706, 1},\n\n      {0x10cb0, 3501, 1},\n\n      {0x01d9, 447, 1},\n\n      {0x1fd9, 2277, 1},\n\n      {0x118a0, 3510, 1},\n\n      {0x00df, 24, 2},\n\n      {0x00d9, 150, 1},\n\n      {0xab77, 1469, 1},\n\n      {0x10b0, 2793, 1},\n\n      {0x1eae, 1959, 1},\n\n      {0x04ae, 1139, 1},\n\n      {0x01ae, 685, 1},\n\n      {0x1fae, 239, 2},\n\n      {0x2cae, 2655, 1},\n\n      {0x118b2, 3564, 1},\n\n      {0xab73, 1457, 1},\n\n      {0xabae, 1634, 1},\n\n      {0xab71, 1451, 1},\n\n      {0x10cae, 3495, 1},\n\n      {0x1e2a, 1775, 1},\n\n      {0x042a, 968, 1},\n\n      {0x012a, 234, 1},\n\n      {0x1f2a, 2130, 1},\n\n      {0x2c2a, 2547, 1},\n\n      {0x118ac, 3546, 1},\n\n      {0x10ae, 2787, 1},\n\n      {0x0535, 1346, 1},\n\n      {0xa72a, 2988, 1},\n\n      {0x1e9a, 0, 2},\n\n      {0x049a, 1109, 1},\n\n      {0xff37, 3225, 1},\n\n      {0x1f9a, 179, 2},\n\n      {0x2c9a, 2625, 1},\n\n      {0x039a, 772, 1},\n\n      {0x118aa, 3540, 1},\n\n      {0xab9a, 1574, 1},\n\n      {0xa79a, 3126, 1},\n\n      {0x10c9a, 3435, 1},\n\n      {0x1e94, 1935, 1},\n\n      {0x0494, 1100, 1},\n\n      {0x0194, 640, 1},\n\n      {0x1f94, 189, 2},\n\n      {0x2c94, 2616, 1},\n\n      {0x0394, 749, 1},\n\n      {0x118a8, 3534, 1},\n\n      {0xab94, 1556, 1},\n\n      {0xa69a, 2973, 1},\n\n      {0x10c94, 3417, 1},\n\n      {0x10402, 3243, 1},\n\n      {0x1e02, 1715, 1},\n\n      {0x0402, 992, 1},\n\n      {0x0102, 174, 1},\n\n      {0x0533, 1340, 1},\n\n      {0x2c02, 2427, 1},\n\n      {0x118a2, 3516, 1},\n\n      {0x052a, 1325, 1},\n\n      {0xa694, 2964, 1},\n\n      {0x1e92, 1932, 1},\n\n      {0x0492, 1097, 1},\n\n      {0x2165, 2307, 1},\n\n      {0x1f92, 179, 2},\n\n      {0x2c92, 2613, 1},\n\n      {0x0392, 742, 1},\n\n      {0x2161, 2295, 1},\n\n      {0xab92, 1550, 1},\n\n      {0xa792, 3117, 1},\n\n      {0x10c92, 3411, 1},\n\n      {0x118b0, 3558, 1},\n\n      {0x1f5f, 2199, 1},\n\n      {0x1e8e, 1926, 1},\n\n      {0x048e, 1091, 1},\n\n      {0x018e, 453, 1},\n\n      {0x1f8e, 159, 2},\n\n      {0x2c8e, 2607, 1},\n\n      {0x038e, 833, 1},\n\n      {0xa692, 2961, 1},\n\n      {0xab8e, 1538, 1},\n\n      {0x0055, 59, 1},\n\n      {0x10c8e, 3399, 1},\n\n      {0x1f5d, 2196, 1},\n\n      {0x212a, 27, 1},\n\n      {0x04cb, 1181, 1},\n\n      {0x01cb, 425, 1},\n\n      {0x1fcb, 2241, 1},\n\n      {0x118ae, 3552, 1},\n\n      {0x0502, 1265, 1},\n\n      {0x00cb, 111, 1},\n\n      {0xa68e, 2955, 1},\n\n      {0x1e8a, 1920, 1},\n\n      {0x048a, 1085, 1},\n\n      {0x018a, 622, 1},\n\n      {0x1f8a, 139, 2},\n\n      {0x2c8a, 2601, 1},\n\n      {0x038a, 736, 1},\n\n      {0x2c67, 2571, 1},\n\n      {0xab8a, 1526, 1},\n\n      {0x1e86, 1914, 1},\n\n      {0x10c8a, 3387, 1},\n\n      {0x0186, 616, 1},\n\n      {0x1f86, 159, 2},\n\n      {0x2c86, 2595, 1},\n\n      {0x0386, 727, 1},\n\n      {0xff35, 3219, 1},\n\n      {0xab86, 1514, 1},\n\n      {0xa786, 3108, 1},\n\n      {0x10c86, 3375, 1},\n\n      {0xa68a, 2949, 1},\n\n      {0x0555, 1442, 1},\n\n      {0x1ebc, 1980, 1},\n\n      {0x04bc, 1160, 1},\n\n      {0x01bc, 411, 1},\n\n      {0x1fbc, 62, 2},\n\n      {0x2cbc, 2676, 1},\n\n      {0x1f5b, 2193, 1},\n\n      {0xa686, 2943, 1},\n\n      {0xabbc, 1676, 1},\n\n      {0x1eb8, 1974, 1},\n\n      {0x04b8, 1154, 1},\n\n      {0x01b8, 408, 1},\n\n      {0x1fb8, 2268, 1},\n\n      {0x2cb8, 2670, 1},\n\n      {0x01db, 450, 1},\n\n      {0x1fdb, 2247, 1},\n\n      {0xabb8, 1664, 1},\n\n      {0x10bc, 2829, 1},\n\n      {0x00db, 156, 1},\n\n      {0x1eb6, 1971, 1},\n\n      {0x04b6, 1151, 1},\n\n      {0xff33, 3213, 1},\n\n      {0x1fb6, 58, 2},\n\n      {0x2cb6, 2667, 1},\n\n      {0xff2a, 3186, 1},\n\n      {0x10b8, 2817, 1},\n\n      {0xabb6, 1658, 1},\n\n      {0xa7b6, 3153, 1},\n\n      {0x10426, 3351, 1},\n\n      {0x1e26, 1769, 1},\n\n      {0x0426, 956, 1},\n\n      {0x0126, 228, 1},\n\n      {0x0053, 52, 1},\n\n      {0x2c26, 2535, 1},\n\n      {0x0057, 65, 1},\n\n      {0x10b6, 2811, 1},\n\n      {0x022a, 562, 1},\n\n      {0xa726, 2982, 1},\n\n      {0x1e2e, 1781, 1},\n\n      {0x042e, 980, 1},\n\n      {0x012e, 240, 1},\n\n      {0x1f2e, 2142, 1},\n\n      {0x2c2e, 2559, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2167, 2313, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa72e, 2994, 1},\n\n      {0x1e2c, 1778, 1},\n\n      {0x042c, 974, 1},\n\n      {0x012c, 237, 1},\n\n      {0x1f2c, 2136, 1},\n\n      {0x2c2c, 2553, 1},\n\n      {0x1f6f, 2223, 1},\n\n      {0x2c6f, 604, 1},\n\n      {0xabbf, 1685, 1},\n\n      {0xa72c, 2991, 1},\n\n      {0x1e28, 1772, 1},\n\n      {0x0428, 962, 1},\n\n      {0x0128, 231, 1},\n\n      {0x1f28, 2124, 1},\n\n      {0x2c28, 2541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0553, 1436, 1},\n\n      {0x10bf, 2838, 1},\n\n      {0xa728, 2985, 1},\n\n      {0x0526, 1319, 1},\n\n      {0x0202, 505, 1},\n\n      {0x1e40, 1808, 1},\n\n      {0x10424, 3345, 1},\n\n      {0x1e24, 1766, 1},\n\n      {0x0424, 950, 1},\n\n      {0x0124, 225, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c24, 2529, 1},\n\n      {0x052e, 1331, 1},\n\n      {0xa740, 3018, 1},\n\n      {0x118bc, 3594, 1},\n\n      {0xa724, 2979, 1},\n\n      {0x1ef2, 2061, 1},\n\n      {0x04f2, 1241, 1},\n\n      {0x01f2, 483, 1},\n\n      {0x1ff2, 257, 2},\n\n      {0x2cf2, 2742, 1},\n\n      {0x052c, 1328, 1},\n\n      {0x118b8, 3582, 1},\n\n      {0xa640, 2865, 1},\n\n      {0x10422, 3339, 1},\n\n      {0x1e22, 1763, 1},\n\n      {0x0422, 944, 1},\n\n      {0x0122, 222, 1},\n\n      {0x2126, 820, 1},\n\n      {0x2c22, 2523, 1},\n\n      {0x0528, 1322, 1},\n\n      {0x01f1, 483, 1},\n\n      {0x118b6, 3576, 1},\n\n      {0xa722, 2976, 1},\n\n      {0x03f1, 796, 1},\n\n      {0x1ebe, 1983, 1},\n\n      {0x04be, 1163, 1},\n\n      {0xfb02, 12, 2},\n\n      {0x1fbe, 767, 1},\n\n      {0x2cbe, 2679, 1},\n\n      {0x01b5, 405, 1},\n\n      {0x0540, 1379, 1},\n\n      {0xabbe, 1682, 1},\n\n      {0x0524, 1316, 1},\n\n      {0x00b5, 779, 1},\n\n      {0xabb5, 1655, 1},\n\n      {0x1eba, 1977, 1},\n\n      {0x04ba, 1157, 1},\n\n      {0x216f, 2337, 1},\n\n      {0x1fba, 2226, 1},\n\n      {0x2cba, 2673, 1},\n\n      {0x10be, 2835, 1},\n\n      {0x0051, 46, 1},\n\n      {0xabba, 1670, 1},\n\n      {0x10b5, 2808, 1},\n\n      {0x1e6e, 1878, 1},\n\n      {0x046e, 1055, 1},\n\n      {0x016e, 330, 1},\n\n      {0x1f6e, 2220, 1},\n\n      {0x2c6e, 664, 1},\n\n      {0x118bf, 3603, 1},\n\n      {0x0522, 1313, 1},\n\n      {0x10ba, 2823, 1},\n\n      {0xa76e, 3087, 1},\n\n      {0x1eb4, 1968, 1},\n\n      {0x04b4, 1148, 1},\n\n      {0x2c75, 2583, 1},\n\n      {0x1fb4, 50, 2},\n\n      {0x2cb4, 2664, 1},\n\n      {0xab75, 1463, 1},\n\n      {0x1ec2, 1989, 1},\n\n      {0xabb4, 1652, 1},\n\n      {0xa7b4, 3150, 1},\n\n      {0x1fc2, 253, 2},\n\n      {0x2cc2, 2685, 1},\n\n      {0x03c2, 800, 1},\n\n      {0x00c2, 83, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff26, 3174, 1},\n\n      {0x10b4, 2805, 1},\n\n      {0x1eca, 2001, 1},\n\n      {0x0551, 1430, 1},\n\n      {0x01ca, 425, 1},\n\n      {0x1fca, 2238, 1},\n\n      {0x2cca, 2697, 1},\n\n      {0x10c2, 2847, 1},\n\n      {0x00ca, 108, 1},\n\n      {0xff2e, 3198, 1},\n\n      {0x1e8c, 1923, 1},\n\n      {0x048c, 1088, 1},\n\n      {0x0226, 556, 1},\n\n      {0x1f8c, 149, 2},\n\n      {0x2c8c, 2604, 1},\n\n      {0x038c, 830, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8c, 1532, 1},\n\n      {0xff2c, 3192, 1},\n\n      {0x10c8c, 3393, 1},\n\n      {0x1ec4, 1992, 1},\n\n      {0x022e, 568, 1},\n\n      {0x01c4, 417, 1},\n\n      {0x1fc4, 54, 2},\n\n      {0x2cc4, 2688, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c4, 89, 1},\n\n      {0xff28, 3180, 1},\n\n      {0xa68c, 2952, 1},\n\n      {0x01cf, 432, 1},\n\n      {0x022c, 565, 1},\n\n      {0x118be, 3600, 1},\n\n      {0x03cf, 839, 1},\n\n      {0x00cf, 123, 1},\n\n      {0x118b5, 3573, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c4, 2853, 1},\n\n      {0x216e, 2334, 1},\n\n      {0x24cb, 2406, 1},\n\n      {0x0228, 559, 1},\n\n      {0xff24, 3168, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ba, 3588, 1},\n\n      {0x1efe, 2079, 1},\n\n      {0x04fe, 1259, 1},\n\n      {0x01fe, 499, 1},\n\n      {0x1e9e, 24, 2},\n\n      {0x049e, 1115, 1},\n\n      {0x03fe, 721, 1},\n\n      {0x1f9e, 199, 2},\n\n      {0x2c9e, 2631, 1},\n\n      {0x039e, 786, 1},\n\n      {0x0224, 553, 1},\n\n      {0xab9e, 1586, 1},\n\n      {0xa79e, 3132, 1},\n\n      {0x10c9e, 3447, 1},\n\n      {0x01f7, 414, 1},\n\n      {0x1ff7, 67, 3},\n\n      {0xff22, 3162, 1},\n\n      {0x03f7, 884, 1},\n\n      {0x118b4, 3570, 1},\n\n      {0x049c, 1112, 1},\n\n      {0x019c, 661, 1},\n\n      {0x1f9c, 189, 2},\n\n      {0x2c9c, 2628, 1},\n\n      {0x039c, 779, 1},\n\n      {0x24bc, 2361, 1},\n\n      {0xab9c, 1580, 1},\n\n      {0xa79c, 3129, 1},\n\n      {0x10c9c, 3441, 1},\n\n      {0x0222, 550, 1},\n\n      {0x1e7c, 1899, 1},\n\n      {0x047c, 1076, 1},\n\n      {0x1e82, 1908, 1},\n\n      {0x24b8, 2349, 1},\n\n      {0x0182, 357, 1},\n\n      {0x1f82, 139, 2},\n\n      {0x2c82, 2589, 1},\n\n      {0xab7c, 1484, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab82, 1502, 1},\n\n      {0xa782, 3102, 1},\n\n      {0x10c82, 3363, 1},\n\n      {0x2c63, 1709, 1},\n\n      {0x24b6, 2343, 1},\n\n      {0x1e80, 1905, 1},\n\n      {0x0480, 1082, 1},\n\n      {0x1f59, 2190, 1},\n\n      {0x1f80, 129, 2},\n\n      {0x2c80, 2586, 1},\n\n      {0x0059, 71, 1},\n\n      {0xa682, 2937, 1},\n\n      {0xab80, 1496, 1},\n\n      {0xa780, 3099, 1},\n\n      {0x10c80, 3357, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1e4c, 1826, 1},\n\n      {0x0145, 270, 1},\n\n      {0x014c, 279, 1},\n\n      {0x1f4c, 2184, 1},\n\n      {0x0345, 767, 1},\n\n      {0x0045, 12, 1},\n\n      {0x004c, 31, 1},\n\n      {0xa680, 2934, 1},\n\n      {0xa74c, 3036, 1},\n\n      {0x1e4a, 1823, 1},\n\n      {0x01d5, 441, 1},\n\n      {0x014a, 276, 1},\n\n      {0x1f4a, 2178, 1},\n\n      {0x03d5, 810, 1},\n\n      {0x00d5, 141, 1},\n\n      {0x004a, 24, 1},\n\n      {0x24bf, 2370, 1},\n\n      {0xa74a, 3033, 1},\n\n      {0xa64c, 2883, 1},\n\n      {0x1041c, 3321, 1},\n\n      {0x1e1c, 1754, 1},\n\n      {0x041c, 926, 1},\n\n      {0x011c, 213, 1},\n\n      {0x1f1c, 2118, 1},\n\n      {0x2c1c, 2505, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xa64a, 2880, 1},\n\n      {0x1041a, 3315, 1},\n\n      {0x1e1a, 1751, 1},\n\n      {0x041a, 920, 1},\n\n      {0x011a, 210, 1},\n\n      {0x1f1a, 2112, 1},\n\n      {0x2c1a, 2499, 1},\n\n      {0xabbd, 1679, 1},\n\n      {0x0545, 1394, 1},\n\n      {0x054c, 1415, 1},\n\n      {0x10418, 3309, 1},\n\n      {0x1e18, 1748, 1},\n\n      {0x0418, 914, 1},\n\n      {0x0118, 207, 1},\n\n      {0x1f18, 2106, 1},\n\n      {0x2c18, 2493, 1},\n\n      {0x10bd, 2832, 1},\n\n      {0x2163, 2301, 1},\n\n      {0x054a, 1409, 1},\n\n      {0x1040e, 3279, 1},\n\n      {0x1e0e, 1733, 1},\n\n      {0x040e, 1028, 1},\n\n      {0x010e, 192, 1},\n\n      {0x1f0e, 2100, 1},\n\n      {0x2c0e, 2463, 1},\n\n      {0x1efc, 2076, 1},\n\n      {0x04fc, 1256, 1},\n\n      {0x01fc, 496, 1},\n\n      {0x1ffc, 96, 2},\n\n      {0x051c, 1304, 1},\n\n      {0x1040c, 3273, 1},\n\n      {0x1e0c, 1730, 1},\n\n      {0x040c, 1022, 1},\n\n      {0x010c, 189, 1},\n\n      {0x1f0c, 2094, 1},\n\n      {0x2c0c, 2457, 1},\n\n      {0x1f6d, 2217, 1},\n\n      {0x2c6d, 607, 1},\n\n      {0x051a, 1301, 1},\n\n      {0x24be, 2367, 1},\n\n      {0x10408, 3261, 1},\n\n      {0x1e08, 1724, 1},\n\n      {0x0408, 1010, 1},\n\n      {0x0108, 183, 1},\n\n      {0x1f08, 2082, 1},\n\n      {0x2c08, 2445, 1},\n\n      {0x04c9, 1178, 1},\n\n      {0x0518, 1298, 1},\n\n      {0x1fc9, 2235, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ba, 2355, 1},\n\n      {0x00c9, 105, 1},\n\n      {0x10416, 3303, 1},\n\n      {0x1e16, 1745, 1},\n\n      {0x0416, 908, 1},\n\n      {0x0116, 204, 1},\n\n      {0x050e, 1283, 1},\n\n      {0x2c16, 2487, 1},\n\n      {0x10414, 3297, 1},\n\n      {0x1e14, 1742, 1},\n\n      {0x0414, 902, 1},\n\n      {0x0114, 201, 1},\n\n      {0x042b, 971, 1},\n\n      {0x2c14, 2481, 1},\n\n      {0x1f2b, 2133, 1},\n\n      {0x2c2b, 2550, 1},\n      {0xffffffff, -1, 0},\n\n      {0x050c, 1280, 1},\n\n      {0x10406, 3255, 1},\n\n      {0x1e06, 1721, 1},\n\n      {0x0406, 1004, 1},\n\n      {0x0106, 180, 1},\n\n      {0x13fb, 1697, 1},\n\n      {0x2c06, 2439, 1},\n\n      {0x24c2, 2379, 1},\n\n      {0x118bd, 3597, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0508, 1274, 1},\n\n      {0x10404, 3249, 1},\n\n      {0x1e04, 1718, 1},\n\n      {0x0404, 998, 1},\n\n      {0x0104, 177, 1},\n\n      {0x1f95, 194, 2},\n\n      {0x2c04, 2433, 1},\n\n      {0x0395, 752, 1},\n\n      {0x24ca, 2403, 1},\n\n      {0xab95, 1559, 1},\n\n      {0x0531, 1334, 1},\n\n      {0x10c95, 3420, 1},\n\n      {0x0516, 1295, 1},\n\n      {0x1e6c, 1875, 1},\n\n      {0x046c, 1052, 1},\n\n      {0x016c, 327, 1},\n\n      {0x1f6c, 2214, 1},\n\n      {0x216d, 2331, 1},\n\n      {0x0514, 1292, 1},\n\n      {0x0245, 697, 1},\n\n      {0x024c, 598, 1},\n\n      {0xa76c, 3084, 1},\n\n      {0x10400, 3237, 1},\n\n      {0x1e00, 1712, 1},\n\n      {0x0400, 986, 1},\n\n      {0x0100, 171, 1},\n\n      {0x24c4, 2385, 1},\n\n      {0x2c00, 2421, 1},\n\n      {0x0506, 1271, 1},\n\n      {0x024a, 595, 1},\n\n      {0x1fab, 224, 2},\n\n      {0xa66c, 2931, 1},\n\n      {0x03ab, 827, 1},\n\n      {0x24cf, 2418, 1},\n\n      {0xabab, 1625, 1},\n\n      {0xa7ab, 631, 1},\n\n      {0x10cab, 3486, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0504, 1268, 1},\n      {0xffffffff, -1, 0},\n\n      {0x021c, 544, 1},\n\n      {0x01a9, 679, 1},\n\n      {0x1fa9, 214, 2},\n\n      {0x10ab, 2778, 1},\n\n      {0x03a9, 820, 1},\n\n      {0x212b, 92, 1},\n\n      {0xaba9, 1619, 1},\n\n      {0x1e88, 1917, 1},\n\n      {0x10ca9, 3480, 1},\n\n      {0x021a, 541, 1},\n\n      {0x1f88, 129, 2},\n\n      {0x2c88, 2598, 1},\n\n      {0x0388, 730, 1},\n\n      {0x13fd, 1703, 1},\n\n      {0xab88, 1520, 1},\n\n      {0x10a9, 2772, 1},\n\n      {0x10c88, 3381, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0218, 538, 1},\n\n      {0x0500, 1262, 1},\n\n      {0x1f4d, 2187, 1},\n\n      {0x01a7, 393, 1},\n\n      {0x1fa7, 244, 2},\n\n      {0x004d, 34, 1},\n\n      {0x03a7, 814, 1},\n\n      {0xa688, 2946, 1},\n\n      {0xaba7, 1613, 1},\n\n      {0x020e, 523, 1},\n\n      {0x10ca7, 3474, 1},\n\n      {0x1e6a, 1872, 1},\n\n      {0x046a, 1049, 1},\n\n      {0x016a, 324, 1},\n\n      {0x1f6a, 2208, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216c, 2328, 1},\n\n      {0x10a7, 2766, 1},\n\n      {0x01d1, 435, 1},\n\n      {0xa76a, 3081, 1},\n\n      {0x020c, 520, 1},\n\n      {0x03d1, 762, 1},\n\n      {0x00d1, 129, 1},\n\n      {0x1e68, 1869, 1},\n\n      {0x0468, 1046, 1},\n\n      {0x0168, 321, 1},\n\n      {0x1f68, 2202, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff31, 3207, 1},\n\n      {0xa66a, 2928, 1},\n\n      {0x0208, 514, 1},\n\n      {0xa768, 3078, 1},\n\n      {0x1e64, 1863, 1},\n\n      {0x0464, 1040, 1},\n\n      {0x0164, 315, 1},\n\n      {0x054d, 1418, 1},\n\n      {0x2c64, 673, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff2b, 3189, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa764, 3072, 1},\n\n      {0xa668, 2925, 1},\n\n      {0x0216, 535, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ab, 3543, 1},\n\n      {0x1e62, 1860, 1},\n\n      {0x0462, 1037, 1},\n\n      {0x0162, 312, 1},\n\n      {0x0214, 532, 1},\n\n      {0x2c62, 655, 1},\n\n      {0xa664, 2919, 1},\n\n      {0x1ed2, 2013, 1},\n\n      {0x04d2, 1193, 1},\n\n      {0xa762, 3069, 1},\n\n      {0x1fd2, 20, 3},\n\n      {0x2cd2, 2709, 1},\n\n      {0x118a9, 3537, 1},\n\n      {0x00d2, 132, 1},\n\n      {0x0206, 511, 1},\n\n      {0x10420, 3333, 1},\n\n      {0x1e20, 1760, 1},\n\n      {0x0420, 938, 1},\n\n      {0x0120, 219, 1},\n\n      {0xa662, 2916, 1},\n\n      {0x2c20, 2517, 1},\n\n      {0x1e60, 1856, 1},\n\n      {0x0460, 1034, 1},\n\n      {0x0160, 309, 1},\n\n      {0x0204, 508, 1},\n\n      {0x2c60, 2562, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24bd, 2364, 1},\n\n      {0x216a, 2322, 1},\n\n      {0xa760, 3066, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb16, 125, 2},\n\n      {0x118a7, 3531, 1},\n\n      {0x1efa, 2073, 1},\n\n      {0x04fa, 1253, 1},\n\n      {0x01fa, 493, 1},\n\n      {0x1ffa, 2262, 1},\n\n      {0xfb14, 109, 2},\n\n      {0x03fa, 887, 1},\n\n      {0xa660, 2913, 1},\n\n      {0x2168, 2316, 1},\n\n      {0x01b7, 700, 1},\n\n      {0x1fb7, 10, 3},\n\n      {0x1f6b, 2211, 1},\n\n      {0x2c6b, 2577, 1},\n\n      {0x0200, 502, 1},\n\n      {0xabb7, 1661, 1},\n\n      {0xfb06, 29, 2},\n\n      {0x1e56, 1841, 1},\n\n      {0x2164, 2304, 1},\n\n      {0x0156, 294, 1},\n\n      {0x1f56, 62, 3},\n\n      {0x0520, 1310, 1},\n\n      {0x004f, 40, 1},\n\n      {0x0056, 62, 1},\n\n      {0x10b7, 2814, 1},\n\n      {0xa756, 3051, 1},\n\n      {0xfb04, 5, 3},\n\n      {0x1e78, 1893, 1},\n\n      {0x0478, 1070, 1},\n\n      {0x0178, 168, 1},\n\n      {0x1e54, 1838, 1},\n\n      {0x2162, 2298, 1},\n\n      {0x0154, 291, 1},\n\n      {0x1f54, 57, 3},\n\n      {0xab78, 1472, 1},\n\n      {0xa656, 2898, 1},\n\n      {0x0054, 56, 1},\n\n      {0x1e52, 1835, 1},\n\n      {0xa754, 3048, 1},\n\n      {0x0152, 288, 1},\n\n      {0x1f52, 52, 3},\n\n      {0x24c9, 2400, 1},\n\n      {0x1e32, 1787, 1},\n\n      {0x0052, 49, 1},\n\n      {0x0132, 243, 1},\n\n      {0xa752, 3045, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb00, 4, 2},\n\n      {0xa654, 2895, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa732, 2997, 1},\n\n      {0x2160, 2292, 1},\n\n      {0x054f, 1424, 1},\n\n      {0x0556, 1445, 1},\n\n      {0x1e50, 1832, 1},\n\n      {0xa652, 2892, 1},\n\n      {0x0150, 285, 1},\n\n      {0x1f50, 84, 2},\n\n      {0x017b, 348, 1},\n\n      {0x1e4e, 1829, 1},\n\n      {0x0050, 43, 1},\n\n      {0x014e, 282, 1},\n\n      {0xa750, 3042, 1},\n\n      {0xab7b, 1481, 1},\n\n      {0xa77b, 3093, 1},\n\n      {0x004e, 37, 1},\n\n      {0x0554, 1439, 1},\n\n      {0xa74e, 3039, 1},\n\n      {0x1e48, 1820, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216b, 2325, 1},\n\n      {0x1f48, 2172, 1},\n\n      {0xa650, 2889, 1},\n\n      {0x0552, 1433, 1},\n\n      {0x0048, 21, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa748, 3030, 1},\n\n      {0xa64e, 2886, 1},\n\n      {0x0532, 1337, 1},\n\n      {0x1041e, 3327, 1},\n\n      {0x1e1e, 1757, 1},\n\n      {0x041e, 932, 1},\n\n      {0x011e, 216, 1},\n\n      {0x118b7, 3579, 1},\n\n      {0x2c1e, 2511, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa648, 2877, 1},\n\n      {0x1ff9, 2253, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03f9, 878, 1},\n\n      {0x0550, 1427, 1},\n\n      {0x10412, 3291, 1},\n\n      {0x1e12, 1739, 1},\n\n      {0x0412, 896, 1},\n\n      {0x0112, 198, 1},\n\n      {0x054e, 1421, 1},\n\n      {0x2c12, 2475, 1},\n\n      {0x10410, 3285, 1},\n\n      {0x1e10, 1736, 1},\n\n      {0x0410, 890, 1},\n\n      {0x0110, 195, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c10, 2469, 1},\n\n      {0x2132, 2289, 1},\n\n      {0x0548, 1403, 1},\n\n      {0x1ef8, 2070, 1},\n\n      {0x04f8, 1250, 1},\n\n      {0x01f8, 490, 1},\n\n      {0x1ff8, 2250, 1},\n\n      {0x0220, 381, 1},\n\n      {0x1ee2, 2037, 1},\n\n      {0x04e2, 1217, 1},\n\n      {0x01e2, 462, 1},\n\n      {0x1fe2, 36, 3},\n\n      {0x2ce2, 2733, 1},\n\n      {0x03e2, 857, 1},\n\n      {0x051e, 1307, 1},\n\n      {0x1ede, 2031, 1},\n\n      {0x04de, 1211, 1},\n\n      {0x01de, 456, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cde, 2727, 1},\n\n      {0x03de, 851, 1},\n\n      {0x00de, 165, 1},\n\n      {0x1f69, 2205, 1},\n\n      {0x2c69, 2574, 1},\n\n      {0x1eda, 2025, 1},\n\n      {0x04da, 1205, 1},\n\n      {0x0512, 1289, 1},\n\n      {0x1fda, 2244, 1},\n\n      {0x2cda, 2721, 1},\n\n      {0x03da, 845, 1},\n\n      {0x00da, 153, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0510, 1286, 1},\n\n      {0x1ed8, 2022, 1},\n\n      {0x04d8, 1202, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd8, 2274, 1},\n\n      {0x2cd8, 2718, 1},\n\n      {0x03d8, 842, 1},\n\n      {0x00d8, 147, 1},\n\n      {0x1ed6, 2019, 1},\n\n      {0x04d6, 1199, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd6, 76, 2},\n\n      {0x2cd6, 2715, 1},\n\n      {0x03d6, 792, 1},\n\n      {0x00d6, 144, 1},\n\n      {0x1ec8, 1998, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01c8, 421, 1},\n\n      {0x1fc8, 2232, 1},\n\n      {0x2cc8, 2694, 1},\n\n      {0xff32, 3210, 1},\n\n      {0x00c8, 102, 1},\n\n      {0x04c7, 1175, 1},\n\n      {0x01c7, 421, 1},\n\n      {0x1fc7, 15, 3},\n\n      {0x1ec0, 1986, 1},\n\n      {0x04c0, 1187, 1},\n\n      {0x00c7, 99, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cc0, 2682, 1},\n\n      {0x0179, 345, 1},\n\n      {0x00c0, 77, 1},\n\n      {0x0232, 574, 1},\n\n      {0x01b3, 402, 1},\n\n      {0x1fb3, 62, 2},\n\n      {0xab79, 1475, 1},\n\n      {0xa779, 3090, 1},\n\n      {0x10c7, 2859, 1},\n\n      {0xabb3, 1649, 1},\n\n      {0xa7b3, 3156, 1},\n\n      {0x1fa5, 234, 2},\n\n      {0x10c0, 2841, 1},\n\n      {0x03a5, 807, 1},\n      {0xffffffff, -1, 0},\n\n      {0xaba5, 1607, 1},\n\n      {0x01b1, 691, 1},\n\n      {0x10ca5, 3468, 1},\n\n      {0x10b3, 2802, 1},\n\n      {0x2169, 2319, 1},\n\n      {0x024e, 601, 1},\n\n      {0xabb1, 1643, 1},\n\n      {0xa7b1, 682, 1},\n\n      {0x10cb1, 3504, 1},\n\n      {0x10a5, 2760, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01af, 399, 1},\n\n      {0x1faf, 244, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0248, 592, 1},\n\n      {0x10b1, 2796, 1},\n\n      {0xabaf, 1637, 1},\n\n      {0x1fad, 234, 2},\n\n      {0x10caf, 3498, 1},\n\n      {0x04cd, 1184, 1},\n\n      {0x01cd, 429, 1},\n\n      {0xabad, 1631, 1},\n\n      {0xa7ad, 658, 1},\n\n      {0x10cad, 3492, 1},\n\n      {0x00cd, 117, 1},\n\n      {0x10af, 2790, 1},\n\n      {0x021e, 547, 1},\n\n      {0x1fa3, 224, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03a3, 800, 1},\n\n      {0x10ad, 2784, 1},\n\n      {0xaba3, 1601, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10ca3, 3462, 1},\n\n      {0x10cd, 2862, 1},\n\n      {0x1fa1, 214, 2},\n\n      {0x24b7, 2346, 1},\n\n      {0x03a1, 796, 1},\n\n      {0x0212, 529, 1},\n\n      {0xaba1, 1595, 1},\n\n      {0x10a3, 2754, 1},\n\n      {0x10ca1, 3456, 1},\n\n      {0x01d3, 438, 1},\n\n      {0x1fd3, 25, 3},\n\n      {0x0210, 526, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00d3, 135, 1},\n\n      {0x1e97, 34, 2},\n\n      {0x10a1, 2748, 1},\n\n      {0x0197, 649, 1},\n\n      {0x1f97, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0397, 759, 1},\n\n      {0x1041d, 3324, 1},\n\n      {0xab97, 1565, 1},\n\n      {0x041d, 929, 1},\n\n      {0x10c97, 3426, 1},\n\n      {0x1f1d, 2121, 1},\n\n      {0x2c1d, 2508, 1},\n\n      {0x1e72, 1884, 1},\n\n      {0x0472, 1061, 1},\n\n      {0x0172, 336, 1},\n\n      {0x118b3, 3567, 1},\n\n      {0x2c72, 2580, 1},\n\n      {0x0372, 712, 1},\n\n      {0x1041b, 3318, 1},\n\n      {0xab72, 1454, 1},\n\n      {0x041b, 923, 1},\n\n      {0x118a5, 3525, 1},\n\n      {0x1f1b, 2115, 1},\n\n      {0x2c1b, 2502, 1},\n\n      {0x1e70, 1881, 1},\n\n      {0x0470, 1058, 1},\n\n      {0x0170, 333, 1},\n\n      {0x118b1, 3561, 1},\n\n      {0x2c70, 610, 1},\n\n      {0x0370, 709, 1},\n\n      {0x1e46, 1817, 1},\n\n      {0xab70, 1448, 1},\n\n      {0x1e66, 1866, 1},\n\n      {0x0466, 1043, 1},\n\n      {0x0166, 318, 1},\n\n      {0x1e44, 1814, 1},\n\n      {0x0046, 15, 1},\n\n      {0x118af, 3555, 1},\n\n      {0xa746, 3027, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa766, 3075, 1},\n\n      {0x0044, 9, 1},\n\n      {0x118ad, 3549, 1},\n\n      {0xa744, 3024, 1},\n\n      {0x1e7a, 1896, 1},\n\n      {0x047a, 1073, 1},\n\n      {0x1e3a, 1799, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa646, 2874, 1},\n\n      {0x1f3a, 2154, 1},\n\n      {0xa666, 2922, 1},\n\n      {0xab7a, 1478, 1},\n\n      {0x118a3, 3519, 1},\n\n      {0xa644, 2871, 1},\n\n      {0xa73a, 3009, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1ef4, 2064, 1},\n\n      {0x04f4, 1244, 1},\n\n      {0x01f4, 487, 1},\n\n      {0x1ff4, 101, 2},\n\n      {0x118a1, 3513, 1},\n\n      {0x03f4, 762, 1},\n\n      {0x1eec, 2052, 1},\n\n      {0x04ec, 1232, 1},\n\n      {0x01ec, 477, 1},\n\n      {0x1fec, 2286, 1},\n\n      {0x0546, 1397, 1},\n\n      {0x03ec, 872, 1},\n      {0xffffffff, -1, 0},\n\n      {0x013f, 261, 1},\n\n      {0x1f3f, 2169, 1},\n\n      {0x0544, 1391, 1},\n\n      {0x1eea, 2049, 1},\n\n      {0x04ea, 1229, 1},\n\n      {0x01ea, 474, 1},\n\n      {0x1fea, 2256, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03ea, 869, 1},\n\n      {0x1ee8, 2046, 1},\n\n      {0x04e8, 1226, 1},\n\n      {0x01e8, 471, 1},\n\n      {0x1fe8, 2280, 1},\n\n      {0x053a, 1361, 1},\n\n      {0x03e8, 866, 1},\n\n      {0x1ee6, 2043, 1},\n\n      {0x04e6, 1223, 1},\n\n      {0x01e6, 468, 1},\n\n      {0x1fe6, 88, 2},\n\n      {0x1f4b, 2181, 1},\n\n      {0x03e6, 863, 1},\n\n      {0x1e5e, 1853, 1},\n\n      {0x004b, 27, 1},\n\n      {0x015e, 306, 1},\n\n      {0x2166, 2310, 1},\n\n      {0x1ee4, 2040, 1},\n\n      {0x04e4, 1220, 1},\n\n      {0x01e4, 465, 1},\n\n      {0x1fe4, 80, 2},\n\n      {0xa75e, 3063, 1},\n\n      {0x03e4, 860, 1},\n\n      {0x1ee0, 2034, 1},\n\n      {0x04e0, 1214, 1},\n\n      {0x01e0, 459, 1},\n\n      {0x053f, 1376, 1},\n\n      {0x2ce0, 2730, 1},\n\n      {0x03e0, 854, 1},\n\n      {0x1edc, 2028, 1},\n\n      {0x04dc, 1208, 1},\n\n      {0xa65e, 2910, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cdc, 2724, 1},\n\n      {0x03dc, 848, 1},\n\n      {0x00dc, 159, 1},\n\n      {0x1ed0, 2010, 1},\n\n      {0x04d0, 1190, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x2cd0, 2706, 1},\n\n      {0x03d0, 742, 1},\n\n      {0x00d0, 126, 1},\n\n      {0x1ecc, 2004, 1},\n\n      {0x054b, 1412, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fcc, 71, 2},\n\n      {0x2ccc, 2700, 1},\n\n      {0x1ec6, 1995, 1},\n\n      {0x00cc, 114, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fc6, 67, 2},\n\n      {0x2cc6, 2691, 1},\n\n      {0x24c8, 2397, 1},\n\n      {0x00c6, 96, 1},\n\n      {0x04c5, 1172, 1},\n\n      {0x01c5, 417, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fbb, 2229, 1},\n\n      {0x24c7, 2394, 1},\n\n      {0x00c5, 92, 1},\n\n      {0x1fb9, 2271, 1},\n\n      {0xabbb, 1673, 1},\n\n      {0x24c0, 2373, 1},\n\n      {0x04c3, 1169, 1},\n\n      {0xabb9, 1667, 1},\n\n      {0x1fc3, 71, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x00c3, 86, 1},\n\n      {0x10c5, 2856, 1},\n\n      {0x10bb, 2826, 1},\n\n      {0x1ed4, 2016, 1},\n\n      {0x04d4, 1196, 1},\n\n      {0x10b9, 2820, 1},\n\n      {0x13fc, 1700, 1},\n\n      {0x2cd4, 2712, 1},\n\n      {0x0246, 589, 1},\n\n      {0x00d4, 138, 1},\n\n      {0x10c3, 2850, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff3a, 3234, 1},\n\n      {0x0244, 688, 1},\n\n      {0x019f, 670, 1},\n\n      {0x1f9f, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x039f, 789, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab9f, 1589, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c9f, 3450, 1},\n\n      {0x019d, 667, 1},\n\n      {0x1f9d, 194, 2},\n\n      {0x023a, 2565, 1},\n\n      {0x039d, 783, 1},\n\n      {0x1e5a, 1847, 1},\n\n      {0xab9d, 1583, 1},\n\n      {0x015a, 300, 1},\n\n      {0x10c9d, 3444, 1},\n\n      {0x1e9b, 1856, 1},\n\n      {0x24cd, 2412, 1},\n\n      {0x005a, 74, 1},\n\n      {0x1f9b, 184, 2},\n\n      {0xa75a, 3057, 1},\n\n      {0x039b, 776, 1},\n\n      {0x1ece, 2007, 1},\n\n      {0xab9b, 1577, 1},\n\n      {0x1e99, 42, 2},\n\n      {0x10c9b, 3438, 1},\n\n      {0x2cce, 2703, 1},\n\n      {0x1f99, 174, 2},\n\n      {0x00ce, 120, 1},\n\n      {0x0399, 767, 1},\n\n      {0xa65a, 2904, 1},\n\n      {0xab99, 1571, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c99, 3432, 1},\n\n      {0x0193, 634, 1},\n\n      {0x1f93, 184, 2},\n\n      {0x1e58, 1844, 1},\n\n      {0x0393, 746, 1},\n\n      {0x0158, 297, 1},\n\n      {0xab93, 1553, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c93, 3414, 1},\n\n      {0x0058, 68, 1},\n\n      {0x042d, 977, 1},\n\n      {0xa758, 3054, 1},\n\n      {0x1f2d, 2139, 1},\n\n      {0x2c2d, 2556, 1},\n\n      {0x118bb, 3591, 1},\n\n      {0x0191, 369, 1},\n\n      {0x1f91, 174, 2},\n\n      {0x118b9, 3585, 1},\n\n      {0x0391, 739, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab91, 1547, 1},\n\n      {0xa658, 2901, 1},\n\n      {0x10c91, 3408, 1},\n\n      {0x018f, 625, 1},\n\n      {0x1f8f, 164, 2},\n      {0xffffffff, -1, 0},\n\n      {0x038f, 836, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8f, 1541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c8f, 3402, 1},\n\n      {0x018b, 366, 1},\n\n      {0x1f8b, 144, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0187, 363, 1},\n\n      {0x1f87, 164, 2},\n\n      {0xab8b, 1529, 1},\n\n      {0xa78b, 3111, 1},\n\n      {0x10c8b, 3390, 1},\n\n      {0xab87, 1517, 1},\n\n      {0x04c1, 1166, 1},\n\n      {0x10c87, 3378, 1},\n\n      {0x1e7e, 1902, 1},\n\n      {0x047e, 1079, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c1, 80, 1},\n\n      {0x2c7e, 580, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab7e, 1490, 1},\n\n      {0xa77e, 3096, 1},\n\n      {0x1e76, 1890, 1},\n\n      {0x0476, 1067, 1},\n\n      {0x0176, 342, 1},\n\n      {0x1e42, 1811, 1},\n\n      {0x10c1, 2844, 1},\n\n      {0x0376, 715, 1},\n\n      {0x1e36, 1793, 1},\n\n      {0xab76, 1466, 1},\n\n      {0x0136, 249, 1},\n\n      {0x0042, 3, 1},\n\n      {0x1e3e, 1805, 1},\n\n      {0xa742, 3021, 1},\n\n      {0x1e38, 1796, 1},\n\n      {0x1f3e, 2166, 1},\n\n      {0xa736, 3003, 1},\n\n      {0x1f38, 2148, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0587, 105, 2},\n\n      {0xa73e, 3015, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa738, 3006, 1},\n\n      {0xa642, 2868, 1},\n\n      {0x1e5c, 1850, 1},\n\n      {0x1e34, 1790, 1},\n\n      {0x015c, 303, 1},\n\n      {0x0134, 246, 1},\n\n      {0x1ef6, 2067, 1},\n\n      {0x04f6, 1247, 1},\n\n      {0x01f6, 372, 1},\n\n      {0x1ff6, 92, 2},\n\n      {0xa75c, 3060, 1},\n\n      {0xa734, 3000, 1},\n\n      {0x1ef0, 2058, 1},\n\n      {0x04f0, 1238, 1},\n\n      {0x01f0, 20, 2},\n      {0xffffffff, -1, 0},\n\n      {0x1e30, 1784, 1},\n\n      {0x03f0, 772, 1},\n\n      {0x0130, 261, 2},\n\n      {0x0542, 1385, 1},\n\n      {0xa65c, 2907, 1},\n\n      {0x1f83, 144, 2},\n\n      {0x0536, 1349, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab83, 1505, 1},\n\n      {0x053e, 1373, 1},\n\n      {0x10c83, 3366, 1},\n\n      {0x0538, 1355, 1},\n\n      {0x1eee, 2055, 1},\n\n      {0x04ee, 1235, 1},\n\n      {0x01ee, 480, 1},\n\n      {0x1f8d, 154, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03ee, 875, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8d, 1535, 1},\n\n      {0xa78d, 643, 1},\n\n      {0x10c8d, 3396, 1},\n\n      {0x0534, 1343, 1},\n\n      {0x0181, 613, 1},\n\n      {0x1f81, 134, 2},\n\n      {0x013d, 258, 1},\n\n      {0x1f3d, 2163, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab81, 1499, 1},\n\n      {0x017f, 52, 1},\n\n      {0x10c81, 3360, 1},\n\n      {0x2c7f, 583, 1},\n\n      {0x037f, 881, 1},\n\n      {0xff2d, 3195, 1},\n\n      {0xab7f, 1493, 1},\n\n      {0x1e74, 1887, 1},\n\n      {0x0474, 1064, 1},\n\n      {0x0174, 339, 1},\n\n      {0x1e3c, 1802, 1},\n\n      {0x0149, 46, 2},\n\n      {0x1f49, 2175, 1},\n\n      {0x1f3c, 2160, 1},\n\n      {0xab74, 1460, 1},\n\n      {0x0049, 3606, 1},\n\n      {0x0143, 267, 1},\n\n      {0x24cc, 2409, 1},\n\n      {0xa73c, 3012, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0043, 6, 1},\n\n      {0x0141, 264, 1},\n\n      {0x24c6, 2391, 1},\n\n      {0x013b, 255, 1},\n\n      {0x1f3b, 2157, 1},\n\n      {0x0041, 0, 1},\n\n      {0x0139, 252, 1},\n\n      {0x1f39, 2151, 1},\n\n      {0x24c5, 2388, 1},\n\n      {0x24bb, 2358, 1},\n\n      {0x13fa, 1694, 1},\n\n      {0x053d, 1370, 1},\n\n      {0x24b9, 2352, 1},\n\n      {0x0429, 965, 1},\n\n      {0x2183, 2340, 1},\n\n      {0x1f29, 2127, 1},\n\n      {0x2c29, 2544, 1},\n\n      {0x24c3, 2382, 1},\n\n      {0x10427, 3354, 1},\n\n      {0x10425, 3348, 1},\n\n      {0x0427, 959, 1},\n\n      {0x0425, 953, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c27, 2538, 1},\n\n      {0x2c25, 2532, 1},\n\n      {0x0549, 1406, 1},\n\n      {0x053c, 1367, 1},\n\n      {0x10423, 3342, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0423, 947, 1},\n\n      {0x0543, 1388, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c23, 2526, 1},\n\n      {0xff36, 3222, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0541, 1382, 1},\n\n      {0x10421, 3336, 1},\n\n      {0x053b, 1364, 1},\n\n      {0x0421, 941, 1},\n\n      {0xff38, 3228, 1},\n\n      {0x0539, 1358, 1},\n\n      {0x2c21, 2520, 1},\n\n      {0x10419, 3312, 1},\n\n      {0x10417, 3306, 1},\n\n      {0x0419, 917, 1},\n\n      {0x0417, 911, 1},\n\n      {0x1f19, 2109, 1},\n\n      {0x2c19, 2496, 1},\n\n      {0x2c17, 2490, 1},\n\n      {0x023e, 2568, 1},\n\n      {0xff34, 3216, 1},\n\n      {0x10415, 3300, 1},\n\n      {0x10413, 3294, 1},\n\n      {0x0415, 905, 1},\n\n      {0x0413, 899, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c15, 2484, 1},\n\n      {0x2c13, 2478, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ce, 2415, 1},\n\n      {0x1040f, 3282, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040f, 1031, 1},\n\n      {0xff30, 3204, 1},\n\n      {0x1f0f, 2103, 1},\n\n      {0x2c0f, 2466, 1},\n\n      {0x1040d, 3276, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040d, 1025, 1},\n\n      {0x0147, 273, 1},\n\n      {0x1f0d, 2097, 1},\n\n      {0x2c0d, 2460, 1},\n\n      {0x1040b, 3270, 1},\n\n      {0x0047, 18, 1},\n\n      {0x040b, 1019, 1},\n\n      {0x0230, 571, 1},\n\n      {0x1f0b, 2091, 1},\n\n      {0x2c0b, 2454, 1},\n\n      {0x10409, 3264, 1},\n\n      {0x10405, 3252, 1},\n\n      {0x0409, 1013, 1},\n\n      {0x0405, 1001, 1},\n\n      {0x1f09, 2085, 1},\n\n      {0x2c09, 2448, 1},\n\n      {0x2c05, 2436, 1},\n\n      {0x10403, 3246, 1},\n\n      {0x10401, 3240, 1},\n\n      {0x0403, 995, 1},\n\n      {0x0401, 989, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c03, 2430, 1},\n\n      {0x2c01, 2424, 1},\n\n      {0x13f9, 1691, 1},\n\n      {0x042f, 983, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1f2f, 2145, 1},\n\n      {0x1041f, 3330, 1},\n      {0xffffffff, -1, 0},\n\n      {0x041f, 935, 1},\n\n      {0x023d, 378, 1},\n\n      {0x10411, 3288, 1},\n\n      {0x2c1f, 2514, 1},\n\n      {0x0411, 893, 1},\n\n      {0x0547, 1400, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c11, 2472, 1},\n\n      {0x10407, 3258, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0407, 1007, 1},\n\n      {0x24c1, 2376, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c07, 2442, 1},\n      {0xffffffff, -1, 0},\n\n      {0x13f8, 1688, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff39, 3231, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0243, 354, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x0241, 586, 1},\n\n      {0xff29, 3183, 1},\n\n      {0x023b, 577, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff27, 3177, 1},\n\n      {0xff25, 3171, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff23, 3165, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff21, 3159, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb17, 117, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff2f, 3201, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb15, 113, 2},\n\n      {0xfb13, 121, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb05, 29, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb03, 0, 3},\n\n      {0xfb01, 8, 2}\n    };\n\n  if (0 == 0)\n    {\n      int key = hash(&code);\n\n      if (key <= MAX_HASH_VALUE && key >= 0)\n        {\n          OnigCodePoint gcode = wordlist[key].code;\n\n          if (code == gcode)\n            return &wordlist[key];\n        }\n    }\n  return 0;\n}", "func_src_after": "unicode_unfold_key(OnigCodePoint code)\n{\n  static const struct ByUnfoldKey wordlist[] =\n    {\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0x1040a, 3267, 1},\n\n      {0x1e0a, 1727, 1},\n\n      {0x040a, 1016, 1},\n\n      {0x010a, 186, 1},\n\n      {0x1f0a, 2088, 1},\n\n      {0x2c0a, 2451, 1},\n\n      {0x0189, 619, 1},\n\n      {0x1f89, 134, 2},\n\n      {0x1f85, 154, 2},\n\n      {0x0389, 733, 1},\n\n      {0x03ff, 724, 1},\n\n      {0xab89, 1523, 1},\n\n      {0xab85, 1511, 1},\n\n      {0x10c89, 3384, 1},\n\n      {0x10c85, 3372, 1},\n\n      {0x1e84, 1911, 1},\n\n      {0x03f5, 752, 1},\n\n      {0x0184, 360, 1},\n\n      {0x1f84, 149, 2},\n\n      {0x2c84, 2592, 1},\n\n      {0x017d, 351, 1},\n\n      {0x1ff3, 96, 2},\n\n      {0xab84, 1508, 1},\n\n      {0xa784, 3105, 1},\n\n      {0x10c84, 3369, 1},\n\n      {0xab7d, 1487, 1},\n\n      {0xa77d, 1706, 1},\n\n      {0x1e98, 38, 2},\n\n      {0x0498, 1106, 1},\n\n      {0x0198, 375, 1},\n\n      {0x1f98, 169, 2},\n\n      {0x2c98, 2622, 1},\n\n      {0x0398, 762, 1},\n\n      {0xa684, 2940, 1},\n\n      {0xab98, 1568, 1},\n\n      {0xa798, 3123, 1},\n\n      {0x10c98, 3429, 1},\n\n      {0x050a, 1277, 1},\n\n      {0x1ffb, 2265, 1},\n\n      {0x1e96, 16, 2},\n\n      {0x0496, 1103, 1},\n\n      {0x0196, 652, 1},\n\n      {0x1f96, 199, 2},\n\n      {0x2c96, 2619, 1},\n\n      {0x0396, 756, 1},\n\n      {0xa698, 2970, 1},\n\n      {0xab96, 1562, 1},\n\n      {0xa796, 3120, 1},\n\n      {0x10c96, 3423, 1},\n\n      {0x1feb, 2259, 1},\n\n      {0x2ceb, 2736, 1},\n\n      {0x1e90, 1929, 1},\n\n      {0x0490, 1094, 1},\n\n      {0x0190, 628, 1},\n\n      {0x1f90, 169, 2},\n\n      {0x2c90, 2610, 1},\n\n      {0x0390, 25, 3},\n\n      {0xa696, 2967, 1},\n\n      {0xab90, 1544, 1},\n\n      {0xa790, 3114, 1},\n\n      {0x10c90, 3405, 1},\n\n      {0x01d7, 444, 1},\n\n      {0x1fd7, 31, 3},\n\n      {0x1ea6, 1947, 1},\n\n      {0x04a6, 1127, 1},\n\n      {0x01a6, 676, 1},\n\n      {0x1fa6, 239, 2},\n\n      {0x2ca6, 2643, 1},\n\n      {0x03a6, 810, 1},\n\n      {0xa690, 2958, 1},\n\n      {0xaba6, 1610, 1},\n\n      {0xa7a6, 3144, 1},\n\n      {0x10ca6, 3471, 1},\n\n      {0x1ea4, 1944, 1},\n\n      {0x04a4, 1124, 1},\n\n      {0x01a4, 390, 1},\n\n      {0x1fa4, 229, 2},\n\n      {0x2ca4, 2640, 1},\n\n      {0x03a4, 804, 1},\n\n      {0x10a6, 2763, 1},\n\n      {0xaba4, 1604, 1},\n\n      {0xa7a4, 3141, 1},\n\n      {0x10ca4, 3465, 1},\n\n      {0x1ea0, 1938, 1},\n\n      {0x04a0, 1118, 1},\n\n      {0x01a0, 384, 1},\n\n      {0x1fa0, 209, 2},\n\n      {0x2ca0, 2634, 1},\n\n      {0x03a0, 792, 1},\n\n      {0x10a4, 2757, 1},\n\n      {0xaba0, 1592, 1},\n\n      {0xa7a0, 3135, 1},\n\n      {0x10ca0, 3453, 1},\n\n      {0x1eb2, 1965, 1},\n\n      {0x04b2, 1145, 1},\n\n      {0x01b2, 694, 1},\n\n      {0x1fb2, 249, 2},\n\n      {0x2cb2, 2661, 1},\n\n      {0x03fd, 718, 1},\n\n      {0x10a0, 2745, 1},\n\n      {0xabb2, 1646, 1},\n\n      {0xa7b2, 703, 1},\n\n      {0x10cb2, 3507, 1},\n\n      {0x1eac, 1956, 1},\n\n      {0x04ac, 1136, 1},\n\n      {0x01ac, 396, 1},\n\n      {0x1fac, 229, 2},\n\n      {0x2cac, 2652, 1},\n\n      {0x0537, 1352, 1},\n\n      {0x10b2, 2799, 1},\n\n      {0xabac, 1628, 1},\n\n      {0xa7ac, 637, 1},\n\n      {0x10cac, 3489, 1},\n\n      {0x1eaa, 1953, 1},\n\n      {0x04aa, 1133, 1},\n\n      {0x00dd, 162, 1},\n\n      {0x1faa, 219, 2},\n\n      {0x2caa, 2649, 1},\n\n      {0x03aa, 824, 1},\n\n      {0x10ac, 2781, 1},\n\n      {0xabaa, 1622, 1},\n\n      {0xa7aa, 646, 1},\n\n      {0x10caa, 3483, 1},\n\n      {0x1ea8, 1950, 1},\n\n      {0x04a8, 1130, 1},\n\n      {0x020a, 517, 1},\n\n      {0x1fa8, 209, 2},\n\n      {0x2ca8, 2646, 1},\n\n      {0x03a8, 817, 1},\n\n      {0x10aa, 2775, 1},\n\n      {0xaba8, 1616, 1},\n\n      {0xa7a8, 3147, 1},\n\n      {0x10ca8, 3477, 1},\n\n      {0x1ea2, 1941, 1},\n\n      {0x04a2, 1121, 1},\n\n      {0x01a2, 387, 1},\n\n      {0x1fa2, 219, 2},\n\n      {0x2ca2, 2637, 1},\n\n      {0x118a6, 3528, 1},\n\n      {0x10a8, 2769, 1},\n\n      {0xaba2, 1598, 1},\n\n      {0xa7a2, 3138, 1},\n\n      {0x10ca2, 3459, 1},\n\n      {0x2ced, 2739, 1},\n\n      {0x1fe9, 2283, 1},\n\n      {0x1fe7, 47, 3},\n\n      {0x1eb0, 1962, 1},\n\n      {0x04b0, 1142, 1},\n\n      {0x118a4, 3522, 1},\n\n      {0x10a2, 2751, 1},\n\n      {0x2cb0, 2658, 1},\n\n      {0x03b0, 41, 3},\n\n      {0x1fe3, 41, 3},\n\n      {0xabb0, 1640, 1},\n\n      {0xa7b0, 706, 1},\n\n      {0x10cb0, 3501, 1},\n\n      {0x01d9, 447, 1},\n\n      {0x1fd9, 2277, 1},\n\n      {0x118a0, 3510, 1},\n\n      {0x00df, 24, 2},\n\n      {0x00d9, 150, 1},\n\n      {0xab77, 1469, 1},\n\n      {0x10b0, 2793, 1},\n\n      {0x1eae, 1959, 1},\n\n      {0x04ae, 1139, 1},\n\n      {0x01ae, 685, 1},\n\n      {0x1fae, 239, 2},\n\n      {0x2cae, 2655, 1},\n\n      {0x118b2, 3564, 1},\n\n      {0xab73, 1457, 1},\n\n      {0xabae, 1634, 1},\n\n      {0xab71, 1451, 1},\n\n      {0x10cae, 3495, 1},\n\n      {0x1e2a, 1775, 1},\n\n      {0x042a, 968, 1},\n\n      {0x012a, 234, 1},\n\n      {0x1f2a, 2130, 1},\n\n      {0x2c2a, 2547, 1},\n\n      {0x118ac, 3546, 1},\n\n      {0x10ae, 2787, 1},\n\n      {0x0535, 1346, 1},\n\n      {0xa72a, 2988, 1},\n\n      {0x1e9a, 0, 2},\n\n      {0x049a, 1109, 1},\n\n      {0xff37, 3225, 1},\n\n      {0x1f9a, 179, 2},\n\n      {0x2c9a, 2625, 1},\n\n      {0x039a, 772, 1},\n\n      {0x118aa, 3540, 1},\n\n      {0xab9a, 1574, 1},\n\n      {0xa79a, 3126, 1},\n\n      {0x10c9a, 3435, 1},\n\n      {0x1e94, 1935, 1},\n\n      {0x0494, 1100, 1},\n\n      {0x0194, 640, 1},\n\n      {0x1f94, 189, 2},\n\n      {0x2c94, 2616, 1},\n\n      {0x0394, 749, 1},\n\n      {0x118a8, 3534, 1},\n\n      {0xab94, 1556, 1},\n\n      {0xa69a, 2973, 1},\n\n      {0x10c94, 3417, 1},\n\n      {0x10402, 3243, 1},\n\n      {0x1e02, 1715, 1},\n\n      {0x0402, 992, 1},\n\n      {0x0102, 174, 1},\n\n      {0x0533, 1340, 1},\n\n      {0x2c02, 2427, 1},\n\n      {0x118a2, 3516, 1},\n\n      {0x052a, 1325, 1},\n\n      {0xa694, 2964, 1},\n\n      {0x1e92, 1932, 1},\n\n      {0x0492, 1097, 1},\n\n      {0x2165, 2307, 1},\n\n      {0x1f92, 179, 2},\n\n      {0x2c92, 2613, 1},\n\n      {0x0392, 742, 1},\n\n      {0x2161, 2295, 1},\n\n      {0xab92, 1550, 1},\n\n      {0xa792, 3117, 1},\n\n      {0x10c92, 3411, 1},\n\n      {0x118b0, 3558, 1},\n\n      {0x1f5f, 2199, 1},\n\n      {0x1e8e, 1926, 1},\n\n      {0x048e, 1091, 1},\n\n      {0x018e, 453, 1},\n\n      {0x1f8e, 159, 2},\n\n      {0x2c8e, 2607, 1},\n\n      {0x038e, 833, 1},\n\n      {0xa692, 2961, 1},\n\n      {0xab8e, 1538, 1},\n\n      {0x0055, 59, 1},\n\n      {0x10c8e, 3399, 1},\n\n      {0x1f5d, 2196, 1},\n\n      {0x212a, 27, 1},\n\n      {0x04cb, 1181, 1},\n\n      {0x01cb, 425, 1},\n\n      {0x1fcb, 2241, 1},\n\n      {0x118ae, 3552, 1},\n\n      {0x0502, 1265, 1},\n\n      {0x00cb, 111, 1},\n\n      {0xa68e, 2955, 1},\n\n      {0x1e8a, 1920, 1},\n\n      {0x048a, 1085, 1},\n\n      {0x018a, 622, 1},\n\n      {0x1f8a, 139, 2},\n\n      {0x2c8a, 2601, 1},\n\n      {0x038a, 736, 1},\n\n      {0x2c67, 2571, 1},\n\n      {0xab8a, 1526, 1},\n\n      {0x1e86, 1914, 1},\n\n      {0x10c8a, 3387, 1},\n\n      {0x0186, 616, 1},\n\n      {0x1f86, 159, 2},\n\n      {0x2c86, 2595, 1},\n\n      {0x0386, 727, 1},\n\n      {0xff35, 3219, 1},\n\n      {0xab86, 1514, 1},\n\n      {0xa786, 3108, 1},\n\n      {0x10c86, 3375, 1},\n\n      {0xa68a, 2949, 1},\n\n      {0x0555, 1442, 1},\n\n      {0x1ebc, 1980, 1},\n\n      {0x04bc, 1160, 1},\n\n      {0x01bc, 411, 1},\n\n      {0x1fbc, 62, 2},\n\n      {0x2cbc, 2676, 1},\n\n      {0x1f5b, 2193, 1},\n\n      {0xa686, 2943, 1},\n\n      {0xabbc, 1676, 1},\n\n      {0x1eb8, 1974, 1},\n\n      {0x04b8, 1154, 1},\n\n      {0x01b8, 408, 1},\n\n      {0x1fb8, 2268, 1},\n\n      {0x2cb8, 2670, 1},\n\n      {0x01db, 450, 1},\n\n      {0x1fdb, 2247, 1},\n\n      {0xabb8, 1664, 1},\n\n      {0x10bc, 2829, 1},\n\n      {0x00db, 156, 1},\n\n      {0x1eb6, 1971, 1},\n\n      {0x04b6, 1151, 1},\n\n      {0xff33, 3213, 1},\n\n      {0x1fb6, 58, 2},\n\n      {0x2cb6, 2667, 1},\n\n      {0xff2a, 3186, 1},\n\n      {0x10b8, 2817, 1},\n\n      {0xabb6, 1658, 1},\n\n      {0xa7b6, 3153, 1},\n\n      {0x10426, 3351, 1},\n\n      {0x1e26, 1769, 1},\n\n      {0x0426, 956, 1},\n\n      {0x0126, 228, 1},\n\n      {0x0053, 52, 1},\n\n      {0x2c26, 2535, 1},\n\n      {0x0057, 65, 1},\n\n      {0x10b6, 2811, 1},\n\n      {0x022a, 562, 1},\n\n      {0xa726, 2982, 1},\n\n      {0x1e2e, 1781, 1},\n\n      {0x042e, 980, 1},\n\n      {0x012e, 240, 1},\n\n      {0x1f2e, 2142, 1},\n\n      {0x2c2e, 2559, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2167, 2313, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa72e, 2994, 1},\n\n      {0x1e2c, 1778, 1},\n\n      {0x042c, 974, 1},\n\n      {0x012c, 237, 1},\n\n      {0x1f2c, 2136, 1},\n\n      {0x2c2c, 2553, 1},\n\n      {0x1f6f, 2223, 1},\n\n      {0x2c6f, 604, 1},\n\n      {0xabbf, 1685, 1},\n\n      {0xa72c, 2991, 1},\n\n      {0x1e28, 1772, 1},\n\n      {0x0428, 962, 1},\n\n      {0x0128, 231, 1},\n\n      {0x1f28, 2124, 1},\n\n      {0x2c28, 2541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0553, 1436, 1},\n\n      {0x10bf, 2838, 1},\n\n      {0xa728, 2985, 1},\n\n      {0x0526, 1319, 1},\n\n      {0x0202, 505, 1},\n\n      {0x1e40, 1808, 1},\n\n      {0x10424, 3345, 1},\n\n      {0x1e24, 1766, 1},\n\n      {0x0424, 950, 1},\n\n      {0x0124, 225, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c24, 2529, 1},\n\n      {0x052e, 1331, 1},\n\n      {0xa740, 3018, 1},\n\n      {0x118bc, 3594, 1},\n\n      {0xa724, 2979, 1},\n\n      {0x1ef2, 2061, 1},\n\n      {0x04f2, 1241, 1},\n\n      {0x01f2, 483, 1},\n\n      {0x1ff2, 257, 2},\n\n      {0x2cf2, 2742, 1},\n\n      {0x052c, 1328, 1},\n\n      {0x118b8, 3582, 1},\n\n      {0xa640, 2865, 1},\n\n      {0x10422, 3339, 1},\n\n      {0x1e22, 1763, 1},\n\n      {0x0422, 944, 1},\n\n      {0x0122, 222, 1},\n\n      {0x2126, 820, 1},\n\n      {0x2c22, 2523, 1},\n\n      {0x0528, 1322, 1},\n\n      {0x01f1, 483, 1},\n\n      {0x118b6, 3576, 1},\n\n      {0xa722, 2976, 1},\n\n      {0x03f1, 796, 1},\n\n      {0x1ebe, 1983, 1},\n\n      {0x04be, 1163, 1},\n\n      {0xfb02, 12, 2},\n\n      {0x1fbe, 767, 1},\n\n      {0x2cbe, 2679, 1},\n\n      {0x01b5, 405, 1},\n\n      {0x0540, 1379, 1},\n\n      {0xabbe, 1682, 1},\n\n      {0x0524, 1316, 1},\n\n      {0x00b5, 779, 1},\n\n      {0xabb5, 1655, 1},\n\n      {0x1eba, 1977, 1},\n\n      {0x04ba, 1157, 1},\n\n      {0x216f, 2337, 1},\n\n      {0x1fba, 2226, 1},\n\n      {0x2cba, 2673, 1},\n\n      {0x10be, 2835, 1},\n\n      {0x0051, 46, 1},\n\n      {0xabba, 1670, 1},\n\n      {0x10b5, 2808, 1},\n\n      {0x1e6e, 1878, 1},\n\n      {0x046e, 1055, 1},\n\n      {0x016e, 330, 1},\n\n      {0x1f6e, 2220, 1},\n\n      {0x2c6e, 664, 1},\n\n      {0x118bf, 3603, 1},\n\n      {0x0522, 1313, 1},\n\n      {0x10ba, 2823, 1},\n\n      {0xa76e, 3087, 1},\n\n      {0x1eb4, 1968, 1},\n\n      {0x04b4, 1148, 1},\n\n      {0x2c75, 2583, 1},\n\n      {0x1fb4, 50, 2},\n\n      {0x2cb4, 2664, 1},\n\n      {0xab75, 1463, 1},\n\n      {0x1ec2, 1989, 1},\n\n      {0xabb4, 1652, 1},\n\n      {0xa7b4, 3150, 1},\n\n      {0x1fc2, 253, 2},\n\n      {0x2cc2, 2685, 1},\n\n      {0x03c2, 800, 1},\n\n      {0x00c2, 83, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff26, 3174, 1},\n\n      {0x10b4, 2805, 1},\n\n      {0x1eca, 2001, 1},\n\n      {0x0551, 1430, 1},\n\n      {0x01ca, 425, 1},\n\n      {0x1fca, 2238, 1},\n\n      {0x2cca, 2697, 1},\n\n      {0x10c2, 2847, 1},\n\n      {0x00ca, 108, 1},\n\n      {0xff2e, 3198, 1},\n\n      {0x1e8c, 1923, 1},\n\n      {0x048c, 1088, 1},\n\n      {0x0226, 556, 1},\n\n      {0x1f8c, 149, 2},\n\n      {0x2c8c, 2604, 1},\n\n      {0x038c, 830, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8c, 1532, 1},\n\n      {0xff2c, 3192, 1},\n\n      {0x10c8c, 3393, 1},\n\n      {0x1ec4, 1992, 1},\n\n      {0x022e, 568, 1},\n\n      {0x01c4, 417, 1},\n\n      {0x1fc4, 54, 2},\n\n      {0x2cc4, 2688, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c4, 89, 1},\n\n      {0xff28, 3180, 1},\n\n      {0xa68c, 2952, 1},\n\n      {0x01cf, 432, 1},\n\n      {0x022c, 565, 1},\n\n      {0x118be, 3600, 1},\n\n      {0x03cf, 839, 1},\n\n      {0x00cf, 123, 1},\n\n      {0x118b5, 3573, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c4, 2853, 1},\n\n      {0x216e, 2334, 1},\n\n      {0x24cb, 2406, 1},\n\n      {0x0228, 559, 1},\n\n      {0xff24, 3168, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ba, 3588, 1},\n\n      {0x1efe, 2079, 1},\n\n      {0x04fe, 1259, 1},\n\n      {0x01fe, 499, 1},\n\n      {0x1e9e, 24, 2},\n\n      {0x049e, 1115, 1},\n\n      {0x03fe, 721, 1},\n\n      {0x1f9e, 199, 2},\n\n      {0x2c9e, 2631, 1},\n\n      {0x039e, 786, 1},\n\n      {0x0224, 553, 1},\n\n      {0xab9e, 1586, 1},\n\n      {0xa79e, 3132, 1},\n\n      {0x10c9e, 3447, 1},\n\n      {0x01f7, 414, 1},\n\n      {0x1ff7, 67, 3},\n\n      {0xff22, 3162, 1},\n\n      {0x03f7, 884, 1},\n\n      {0x118b4, 3570, 1},\n\n      {0x049c, 1112, 1},\n\n      {0x019c, 661, 1},\n\n      {0x1f9c, 189, 2},\n\n      {0x2c9c, 2628, 1},\n\n      {0x039c, 779, 1},\n\n      {0x24bc, 2361, 1},\n\n      {0xab9c, 1580, 1},\n\n      {0xa79c, 3129, 1},\n\n      {0x10c9c, 3441, 1},\n\n      {0x0222, 550, 1},\n\n      {0x1e7c, 1899, 1},\n\n      {0x047c, 1076, 1},\n\n      {0x1e82, 1908, 1},\n\n      {0x24b8, 2349, 1},\n\n      {0x0182, 357, 1},\n\n      {0x1f82, 139, 2},\n\n      {0x2c82, 2589, 1},\n\n      {0xab7c, 1484, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab82, 1502, 1},\n\n      {0xa782, 3102, 1},\n\n      {0x10c82, 3363, 1},\n\n      {0x2c63, 1709, 1},\n\n      {0x24b6, 2343, 1},\n\n      {0x1e80, 1905, 1},\n\n      {0x0480, 1082, 1},\n\n      {0x1f59, 2190, 1},\n\n      {0x1f80, 129, 2},\n\n      {0x2c80, 2586, 1},\n\n      {0x0059, 71, 1},\n\n      {0xa682, 2937, 1},\n\n      {0xab80, 1496, 1},\n\n      {0xa780, 3099, 1},\n\n      {0x10c80, 3357, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1e4c, 1826, 1},\n\n      {0x0145, 270, 1},\n\n      {0x014c, 279, 1},\n\n      {0x1f4c, 2184, 1},\n\n      {0x0345, 767, 1},\n\n      {0x0045, 12, 1},\n\n      {0x004c, 31, 1},\n\n      {0xa680, 2934, 1},\n\n      {0xa74c, 3036, 1},\n\n      {0x1e4a, 1823, 1},\n\n      {0x01d5, 441, 1},\n\n      {0x014a, 276, 1},\n\n      {0x1f4a, 2178, 1},\n\n      {0x03d5, 810, 1},\n\n      {0x00d5, 141, 1},\n\n      {0x004a, 24, 1},\n\n      {0x24bf, 2370, 1},\n\n      {0xa74a, 3033, 1},\n\n      {0xa64c, 2883, 1},\n\n      {0x1041c, 3321, 1},\n\n      {0x1e1c, 1754, 1},\n\n      {0x041c, 926, 1},\n\n      {0x011c, 213, 1},\n\n      {0x1f1c, 2118, 1},\n\n      {0x2c1c, 2505, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xa64a, 2880, 1},\n\n      {0x1041a, 3315, 1},\n\n      {0x1e1a, 1751, 1},\n\n      {0x041a, 920, 1},\n\n      {0x011a, 210, 1},\n\n      {0x1f1a, 2112, 1},\n\n      {0x2c1a, 2499, 1},\n\n      {0xabbd, 1679, 1},\n\n      {0x0545, 1394, 1},\n\n      {0x054c, 1415, 1},\n\n      {0x10418, 3309, 1},\n\n      {0x1e18, 1748, 1},\n\n      {0x0418, 914, 1},\n\n      {0x0118, 207, 1},\n\n      {0x1f18, 2106, 1},\n\n      {0x2c18, 2493, 1},\n\n      {0x10bd, 2832, 1},\n\n      {0x2163, 2301, 1},\n\n      {0x054a, 1409, 1},\n\n      {0x1040e, 3279, 1},\n\n      {0x1e0e, 1733, 1},\n\n      {0x040e, 1028, 1},\n\n      {0x010e, 192, 1},\n\n      {0x1f0e, 2100, 1},\n\n      {0x2c0e, 2463, 1},\n\n      {0x1efc, 2076, 1},\n\n      {0x04fc, 1256, 1},\n\n      {0x01fc, 496, 1},\n\n      {0x1ffc, 96, 2},\n\n      {0x051c, 1304, 1},\n\n      {0x1040c, 3273, 1},\n\n      {0x1e0c, 1730, 1},\n\n      {0x040c, 1022, 1},\n\n      {0x010c, 189, 1},\n\n      {0x1f0c, 2094, 1},\n\n      {0x2c0c, 2457, 1},\n\n      {0x1f6d, 2217, 1},\n\n      {0x2c6d, 607, 1},\n\n      {0x051a, 1301, 1},\n\n      {0x24be, 2367, 1},\n\n      {0x10408, 3261, 1},\n\n      {0x1e08, 1724, 1},\n\n      {0x0408, 1010, 1},\n\n      {0x0108, 183, 1},\n\n      {0x1f08, 2082, 1},\n\n      {0x2c08, 2445, 1},\n\n      {0x04c9, 1178, 1},\n\n      {0x0518, 1298, 1},\n\n      {0x1fc9, 2235, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ba, 2355, 1},\n\n      {0x00c9, 105, 1},\n\n      {0x10416, 3303, 1},\n\n      {0x1e16, 1745, 1},\n\n      {0x0416, 908, 1},\n\n      {0x0116, 204, 1},\n\n      {0x050e, 1283, 1},\n\n      {0x2c16, 2487, 1},\n\n      {0x10414, 3297, 1},\n\n      {0x1e14, 1742, 1},\n\n      {0x0414, 902, 1},\n\n      {0x0114, 201, 1},\n\n      {0x042b, 971, 1},\n\n      {0x2c14, 2481, 1},\n\n      {0x1f2b, 2133, 1},\n\n      {0x2c2b, 2550, 1},\n      {0xffffffff, -1, 0},\n\n      {0x050c, 1280, 1},\n\n      {0x10406, 3255, 1},\n\n      {0x1e06, 1721, 1},\n\n      {0x0406, 1004, 1},\n\n      {0x0106, 180, 1},\n\n      {0x13fb, 1697, 1},\n\n      {0x2c06, 2439, 1},\n\n      {0x24c2, 2379, 1},\n\n      {0x118bd, 3597, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0508, 1274, 1},\n\n      {0x10404, 3249, 1},\n\n      {0x1e04, 1718, 1},\n\n      {0x0404, 998, 1},\n\n      {0x0104, 177, 1},\n\n      {0x1f95, 194, 2},\n\n      {0x2c04, 2433, 1},\n\n      {0x0395, 752, 1},\n\n      {0x24ca, 2403, 1},\n\n      {0xab95, 1559, 1},\n\n      {0x0531, 1334, 1},\n\n      {0x10c95, 3420, 1},\n\n      {0x0516, 1295, 1},\n\n      {0x1e6c, 1875, 1},\n\n      {0x046c, 1052, 1},\n\n      {0x016c, 327, 1},\n\n      {0x1f6c, 2214, 1},\n\n      {0x216d, 2331, 1},\n\n      {0x0514, 1292, 1},\n\n      {0x0245, 697, 1},\n\n      {0x024c, 598, 1},\n\n      {0xa76c, 3084, 1},\n\n      {0x10400, 3237, 1},\n\n      {0x1e00, 1712, 1},\n\n      {0x0400, 986, 1},\n\n      {0x0100, 171, 1},\n\n      {0x24c4, 2385, 1},\n\n      {0x2c00, 2421, 1},\n\n      {0x0506, 1271, 1},\n\n      {0x024a, 595, 1},\n\n      {0x1fab, 224, 2},\n\n      {0xa66c, 2931, 1},\n\n      {0x03ab, 827, 1},\n\n      {0x24cf, 2418, 1},\n\n      {0xabab, 1625, 1},\n\n      {0xa7ab, 631, 1},\n\n      {0x10cab, 3486, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0504, 1268, 1},\n      {0xffffffff, -1, 0},\n\n      {0x021c, 544, 1},\n\n      {0x01a9, 679, 1},\n\n      {0x1fa9, 214, 2},\n\n      {0x10ab, 2778, 1},\n\n      {0x03a9, 820, 1},\n\n      {0x212b, 92, 1},\n\n      {0xaba9, 1619, 1},\n\n      {0x1e88, 1917, 1},\n\n      {0x10ca9, 3480, 1},\n\n      {0x021a, 541, 1},\n\n      {0x1f88, 129, 2},\n\n      {0x2c88, 2598, 1},\n\n      {0x0388, 730, 1},\n\n      {0x13fd, 1703, 1},\n\n      {0xab88, 1520, 1},\n\n      {0x10a9, 2772, 1},\n\n      {0x10c88, 3381, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0218, 538, 1},\n\n      {0x0500, 1262, 1},\n\n      {0x1f4d, 2187, 1},\n\n      {0x01a7, 393, 1},\n\n      {0x1fa7, 244, 2},\n\n      {0x004d, 34, 1},\n\n      {0x03a7, 814, 1},\n\n      {0xa688, 2946, 1},\n\n      {0xaba7, 1613, 1},\n\n      {0x020e, 523, 1},\n\n      {0x10ca7, 3474, 1},\n\n      {0x1e6a, 1872, 1},\n\n      {0x046a, 1049, 1},\n\n      {0x016a, 324, 1},\n\n      {0x1f6a, 2208, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216c, 2328, 1},\n\n      {0x10a7, 2766, 1},\n\n      {0x01d1, 435, 1},\n\n      {0xa76a, 3081, 1},\n\n      {0x020c, 520, 1},\n\n      {0x03d1, 762, 1},\n\n      {0x00d1, 129, 1},\n\n      {0x1e68, 1869, 1},\n\n      {0x0468, 1046, 1},\n\n      {0x0168, 321, 1},\n\n      {0x1f68, 2202, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff31, 3207, 1},\n\n      {0xa66a, 2928, 1},\n\n      {0x0208, 514, 1},\n\n      {0xa768, 3078, 1},\n\n      {0x1e64, 1863, 1},\n\n      {0x0464, 1040, 1},\n\n      {0x0164, 315, 1},\n\n      {0x054d, 1418, 1},\n\n      {0x2c64, 673, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff2b, 3189, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa764, 3072, 1},\n\n      {0xa668, 2925, 1},\n\n      {0x0216, 535, 1},\n      {0xffffffff, -1, 0},\n\n      {0x118ab, 3543, 1},\n\n      {0x1e62, 1860, 1},\n\n      {0x0462, 1037, 1},\n\n      {0x0162, 312, 1},\n\n      {0x0214, 532, 1},\n\n      {0x2c62, 655, 1},\n\n      {0xa664, 2919, 1},\n\n      {0x1ed2, 2013, 1},\n\n      {0x04d2, 1193, 1},\n\n      {0xa762, 3069, 1},\n\n      {0x1fd2, 20, 3},\n\n      {0x2cd2, 2709, 1},\n\n      {0x118a9, 3537, 1},\n\n      {0x00d2, 132, 1},\n\n      {0x0206, 511, 1},\n\n      {0x10420, 3333, 1},\n\n      {0x1e20, 1760, 1},\n\n      {0x0420, 938, 1},\n\n      {0x0120, 219, 1},\n\n      {0xa662, 2916, 1},\n\n      {0x2c20, 2517, 1},\n\n      {0x1e60, 1856, 1},\n\n      {0x0460, 1034, 1},\n\n      {0x0160, 309, 1},\n\n      {0x0204, 508, 1},\n\n      {0x2c60, 2562, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24bd, 2364, 1},\n\n      {0x216a, 2322, 1},\n\n      {0xa760, 3066, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb16, 125, 2},\n\n      {0x118a7, 3531, 1},\n\n      {0x1efa, 2073, 1},\n\n      {0x04fa, 1253, 1},\n\n      {0x01fa, 493, 1},\n\n      {0x1ffa, 2262, 1},\n\n      {0xfb14, 109, 2},\n\n      {0x03fa, 887, 1},\n\n      {0xa660, 2913, 1},\n\n      {0x2168, 2316, 1},\n\n      {0x01b7, 700, 1},\n\n      {0x1fb7, 10, 3},\n\n      {0x1f6b, 2211, 1},\n\n      {0x2c6b, 2577, 1},\n\n      {0x0200, 502, 1},\n\n      {0xabb7, 1661, 1},\n\n      {0xfb06, 29, 2},\n\n      {0x1e56, 1841, 1},\n\n      {0x2164, 2304, 1},\n\n      {0x0156, 294, 1},\n\n      {0x1f56, 62, 3},\n\n      {0x0520, 1310, 1},\n\n      {0x004f, 40, 1},\n\n      {0x0056, 62, 1},\n\n      {0x10b7, 2814, 1},\n\n      {0xa756, 3051, 1},\n\n      {0xfb04, 5, 3},\n\n      {0x1e78, 1893, 1},\n\n      {0x0478, 1070, 1},\n\n      {0x0178, 168, 1},\n\n      {0x1e54, 1838, 1},\n\n      {0x2162, 2298, 1},\n\n      {0x0154, 291, 1},\n\n      {0x1f54, 57, 3},\n\n      {0xab78, 1472, 1},\n\n      {0xa656, 2898, 1},\n\n      {0x0054, 56, 1},\n\n      {0x1e52, 1835, 1},\n\n      {0xa754, 3048, 1},\n\n      {0x0152, 288, 1},\n\n      {0x1f52, 52, 3},\n\n      {0x24c9, 2400, 1},\n\n      {0x1e32, 1787, 1},\n\n      {0x0052, 49, 1},\n\n      {0x0132, 243, 1},\n\n      {0xa752, 3045, 1},\n      {0xffffffff, -1, 0},\n\n      {0xfb00, 4, 2},\n\n      {0xa654, 2895, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa732, 2997, 1},\n\n      {0x2160, 2292, 1},\n\n      {0x054f, 1424, 1},\n\n      {0x0556, 1445, 1},\n\n      {0x1e50, 1832, 1},\n\n      {0xa652, 2892, 1},\n\n      {0x0150, 285, 1},\n\n      {0x1f50, 84, 2},\n\n      {0x017b, 348, 1},\n\n      {0x1e4e, 1829, 1},\n\n      {0x0050, 43, 1},\n\n      {0x014e, 282, 1},\n\n      {0xa750, 3042, 1},\n\n      {0xab7b, 1481, 1},\n\n      {0xa77b, 3093, 1},\n\n      {0x004e, 37, 1},\n\n      {0x0554, 1439, 1},\n\n      {0xa74e, 3039, 1},\n\n      {0x1e48, 1820, 1},\n      {0xffffffff, -1, 0},\n\n      {0x216b, 2325, 1},\n\n      {0x1f48, 2172, 1},\n\n      {0xa650, 2889, 1},\n\n      {0x0552, 1433, 1},\n\n      {0x0048, 21, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa748, 3030, 1},\n\n      {0xa64e, 2886, 1},\n\n      {0x0532, 1337, 1},\n\n      {0x1041e, 3327, 1},\n\n      {0x1e1e, 1757, 1},\n\n      {0x041e, 932, 1},\n\n      {0x011e, 216, 1},\n\n      {0x118b7, 3579, 1},\n\n      {0x2c1e, 2511, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa648, 2877, 1},\n\n      {0x1ff9, 2253, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03f9, 878, 1},\n\n      {0x0550, 1427, 1},\n\n      {0x10412, 3291, 1},\n\n      {0x1e12, 1739, 1},\n\n      {0x0412, 896, 1},\n\n      {0x0112, 198, 1},\n\n      {0x054e, 1421, 1},\n\n      {0x2c12, 2475, 1},\n\n      {0x10410, 3285, 1},\n\n      {0x1e10, 1736, 1},\n\n      {0x0410, 890, 1},\n\n      {0x0110, 195, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c10, 2469, 1},\n\n      {0x2132, 2289, 1},\n\n      {0x0548, 1403, 1},\n\n      {0x1ef8, 2070, 1},\n\n      {0x04f8, 1250, 1},\n\n      {0x01f8, 490, 1},\n\n      {0x1ff8, 2250, 1},\n\n      {0x0220, 381, 1},\n\n      {0x1ee2, 2037, 1},\n\n      {0x04e2, 1217, 1},\n\n      {0x01e2, 462, 1},\n\n      {0x1fe2, 36, 3},\n\n      {0x2ce2, 2733, 1},\n\n      {0x03e2, 857, 1},\n\n      {0x051e, 1307, 1},\n\n      {0x1ede, 2031, 1},\n\n      {0x04de, 1211, 1},\n\n      {0x01de, 456, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cde, 2727, 1},\n\n      {0x03de, 851, 1},\n\n      {0x00de, 165, 1},\n\n      {0x1f69, 2205, 1},\n\n      {0x2c69, 2574, 1},\n\n      {0x1eda, 2025, 1},\n\n      {0x04da, 1205, 1},\n\n      {0x0512, 1289, 1},\n\n      {0x1fda, 2244, 1},\n\n      {0x2cda, 2721, 1},\n\n      {0x03da, 845, 1},\n\n      {0x00da, 153, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0510, 1286, 1},\n\n      {0x1ed8, 2022, 1},\n\n      {0x04d8, 1202, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd8, 2274, 1},\n\n      {0x2cd8, 2718, 1},\n\n      {0x03d8, 842, 1},\n\n      {0x00d8, 147, 1},\n\n      {0x1ed6, 2019, 1},\n\n      {0x04d6, 1199, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fd6, 76, 2},\n\n      {0x2cd6, 2715, 1},\n\n      {0x03d6, 792, 1},\n\n      {0x00d6, 144, 1},\n\n      {0x1ec8, 1998, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01c8, 421, 1},\n\n      {0x1fc8, 2232, 1},\n\n      {0x2cc8, 2694, 1},\n\n      {0xff32, 3210, 1},\n\n      {0x00c8, 102, 1},\n\n      {0x04c7, 1175, 1},\n\n      {0x01c7, 421, 1},\n\n      {0x1fc7, 15, 3},\n\n      {0x1ec0, 1986, 1},\n\n      {0x04c0, 1187, 1},\n\n      {0x00c7, 99, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cc0, 2682, 1},\n\n      {0x0179, 345, 1},\n\n      {0x00c0, 77, 1},\n\n      {0x0232, 574, 1},\n\n      {0x01b3, 402, 1},\n\n      {0x1fb3, 62, 2},\n\n      {0xab79, 1475, 1},\n\n      {0xa779, 3090, 1},\n\n      {0x10c7, 2859, 1},\n\n      {0xabb3, 1649, 1},\n\n      {0xa7b3, 3156, 1},\n\n      {0x1fa5, 234, 2},\n\n      {0x10c0, 2841, 1},\n\n      {0x03a5, 807, 1},\n      {0xffffffff, -1, 0},\n\n      {0xaba5, 1607, 1},\n\n      {0x01b1, 691, 1},\n\n      {0x10ca5, 3468, 1},\n\n      {0x10b3, 2802, 1},\n\n      {0x2169, 2319, 1},\n\n      {0x024e, 601, 1},\n\n      {0xabb1, 1643, 1},\n\n      {0xa7b1, 682, 1},\n\n      {0x10cb1, 3504, 1},\n\n      {0x10a5, 2760, 1},\n      {0xffffffff, -1, 0},\n\n      {0x01af, 399, 1},\n\n      {0x1faf, 244, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0248, 592, 1},\n\n      {0x10b1, 2796, 1},\n\n      {0xabaf, 1637, 1},\n\n      {0x1fad, 234, 2},\n\n      {0x10caf, 3498, 1},\n\n      {0x04cd, 1184, 1},\n\n      {0x01cd, 429, 1},\n\n      {0xabad, 1631, 1},\n\n      {0xa7ad, 658, 1},\n\n      {0x10cad, 3492, 1},\n\n      {0x00cd, 117, 1},\n\n      {0x10af, 2790, 1},\n\n      {0x021e, 547, 1},\n\n      {0x1fa3, 224, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03a3, 800, 1},\n\n      {0x10ad, 2784, 1},\n\n      {0xaba3, 1601, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10ca3, 3462, 1},\n\n      {0x10cd, 2862, 1},\n\n      {0x1fa1, 214, 2},\n\n      {0x24b7, 2346, 1},\n\n      {0x03a1, 796, 1},\n\n      {0x0212, 529, 1},\n\n      {0xaba1, 1595, 1},\n\n      {0x10a3, 2754, 1},\n\n      {0x10ca1, 3456, 1},\n\n      {0x01d3, 438, 1},\n\n      {0x1fd3, 25, 3},\n\n      {0x0210, 526, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00d3, 135, 1},\n\n      {0x1e97, 34, 2},\n\n      {0x10a1, 2748, 1},\n\n      {0x0197, 649, 1},\n\n      {0x1f97, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0397, 759, 1},\n\n      {0x1041d, 3324, 1},\n\n      {0xab97, 1565, 1},\n\n      {0x041d, 929, 1},\n\n      {0x10c97, 3426, 1},\n\n      {0x1f1d, 2121, 1},\n\n      {0x2c1d, 2508, 1},\n\n      {0x1e72, 1884, 1},\n\n      {0x0472, 1061, 1},\n\n      {0x0172, 336, 1},\n\n      {0x118b3, 3567, 1},\n\n      {0x2c72, 2580, 1},\n\n      {0x0372, 712, 1},\n\n      {0x1041b, 3318, 1},\n\n      {0xab72, 1454, 1},\n\n      {0x041b, 923, 1},\n\n      {0x118a5, 3525, 1},\n\n      {0x1f1b, 2115, 1},\n\n      {0x2c1b, 2502, 1},\n\n      {0x1e70, 1881, 1},\n\n      {0x0470, 1058, 1},\n\n      {0x0170, 333, 1},\n\n      {0x118b1, 3561, 1},\n\n      {0x2c70, 610, 1},\n\n      {0x0370, 709, 1},\n\n      {0x1e46, 1817, 1},\n\n      {0xab70, 1448, 1},\n\n      {0x1e66, 1866, 1},\n\n      {0x0466, 1043, 1},\n\n      {0x0166, 318, 1},\n\n      {0x1e44, 1814, 1},\n\n      {0x0046, 15, 1},\n\n      {0x118af, 3555, 1},\n\n      {0xa746, 3027, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa766, 3075, 1},\n\n      {0x0044, 9, 1},\n\n      {0x118ad, 3549, 1},\n\n      {0xa744, 3024, 1},\n\n      {0x1e7a, 1896, 1},\n\n      {0x047a, 1073, 1},\n\n      {0x1e3a, 1799, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa646, 2874, 1},\n\n      {0x1f3a, 2154, 1},\n\n      {0xa666, 2922, 1},\n\n      {0xab7a, 1478, 1},\n\n      {0x118a3, 3519, 1},\n\n      {0xa644, 2871, 1},\n\n      {0xa73a, 3009, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1ef4, 2064, 1},\n\n      {0x04f4, 1244, 1},\n\n      {0x01f4, 487, 1},\n\n      {0x1ff4, 101, 2},\n\n      {0x118a1, 3513, 1},\n\n      {0x03f4, 762, 1},\n\n      {0x1eec, 2052, 1},\n\n      {0x04ec, 1232, 1},\n\n      {0x01ec, 477, 1},\n\n      {0x1fec, 2286, 1},\n\n      {0x0546, 1397, 1},\n\n      {0x03ec, 872, 1},\n      {0xffffffff, -1, 0},\n\n      {0x013f, 261, 1},\n\n      {0x1f3f, 2169, 1},\n\n      {0x0544, 1391, 1},\n\n      {0x1eea, 2049, 1},\n\n      {0x04ea, 1229, 1},\n\n      {0x01ea, 474, 1},\n\n      {0x1fea, 2256, 1},\n      {0xffffffff, -1, 0},\n\n      {0x03ea, 869, 1},\n\n      {0x1ee8, 2046, 1},\n\n      {0x04e8, 1226, 1},\n\n      {0x01e8, 471, 1},\n\n      {0x1fe8, 2280, 1},\n\n      {0x053a, 1361, 1},\n\n      {0x03e8, 866, 1},\n\n      {0x1ee6, 2043, 1},\n\n      {0x04e6, 1223, 1},\n\n      {0x01e6, 468, 1},\n\n      {0x1fe6, 88, 2},\n\n      {0x1f4b, 2181, 1},\n\n      {0x03e6, 863, 1},\n\n      {0x1e5e, 1853, 1},\n\n      {0x004b, 27, 1},\n\n      {0x015e, 306, 1},\n\n      {0x2166, 2310, 1},\n\n      {0x1ee4, 2040, 1},\n\n      {0x04e4, 1220, 1},\n\n      {0x01e4, 465, 1},\n\n      {0x1fe4, 80, 2},\n\n      {0xa75e, 3063, 1},\n\n      {0x03e4, 860, 1},\n\n      {0x1ee0, 2034, 1},\n\n      {0x04e0, 1214, 1},\n\n      {0x01e0, 459, 1},\n\n      {0x053f, 1376, 1},\n\n      {0x2ce0, 2730, 1},\n\n      {0x03e0, 854, 1},\n\n      {0x1edc, 2028, 1},\n\n      {0x04dc, 1208, 1},\n\n      {0xa65e, 2910, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2cdc, 2724, 1},\n\n      {0x03dc, 848, 1},\n\n      {0x00dc, 159, 1},\n\n      {0x1ed0, 2010, 1},\n\n      {0x04d0, 1190, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x2cd0, 2706, 1},\n\n      {0x03d0, 742, 1},\n\n      {0x00d0, 126, 1},\n\n      {0x1ecc, 2004, 1},\n\n      {0x054b, 1412, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fcc, 71, 2},\n\n      {0x2ccc, 2700, 1},\n\n      {0x1ec6, 1995, 1},\n\n      {0x00cc, 114, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fc6, 67, 2},\n\n      {0x2cc6, 2691, 1},\n\n      {0x24c8, 2397, 1},\n\n      {0x00c6, 96, 1},\n\n      {0x04c5, 1172, 1},\n\n      {0x01c5, 417, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1fbb, 2229, 1},\n\n      {0x24c7, 2394, 1},\n\n      {0x00c5, 92, 1},\n\n      {0x1fb9, 2271, 1},\n\n      {0xabbb, 1673, 1},\n\n      {0x24c0, 2373, 1},\n\n      {0x04c3, 1169, 1},\n\n      {0xabb9, 1667, 1},\n\n      {0x1fc3, 71, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x00c3, 86, 1},\n\n      {0x10c5, 2856, 1},\n\n      {0x10bb, 2826, 1},\n\n      {0x1ed4, 2016, 1},\n\n      {0x04d4, 1196, 1},\n\n      {0x10b9, 2820, 1},\n\n      {0x13fc, 1700, 1},\n\n      {0x2cd4, 2712, 1},\n\n      {0x0246, 589, 1},\n\n      {0x00d4, 138, 1},\n\n      {0x10c3, 2850, 1},\n      {0xffffffff, -1, 0},\n\n      {0xff3a, 3234, 1},\n\n      {0x0244, 688, 1},\n\n      {0x019f, 670, 1},\n\n      {0x1f9f, 204, 2},\n      {0xffffffff, -1, 0},\n\n      {0x039f, 789, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab9f, 1589, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c9f, 3450, 1},\n\n      {0x019d, 667, 1},\n\n      {0x1f9d, 194, 2},\n\n      {0x023a, 2565, 1},\n\n      {0x039d, 783, 1},\n\n      {0x1e5a, 1847, 1},\n\n      {0xab9d, 1583, 1},\n\n      {0x015a, 300, 1},\n\n      {0x10c9d, 3444, 1},\n\n      {0x1e9b, 1856, 1},\n\n      {0x24cd, 2412, 1},\n\n      {0x005a, 74, 1},\n\n      {0x1f9b, 184, 2},\n\n      {0xa75a, 3057, 1},\n\n      {0x039b, 776, 1},\n\n      {0x1ece, 2007, 1},\n\n      {0xab9b, 1577, 1},\n\n      {0x1e99, 42, 2},\n\n      {0x10c9b, 3438, 1},\n\n      {0x2cce, 2703, 1},\n\n      {0x1f99, 174, 2},\n\n      {0x00ce, 120, 1},\n\n      {0x0399, 767, 1},\n\n      {0xa65a, 2904, 1},\n\n      {0xab99, 1571, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c99, 3432, 1},\n\n      {0x0193, 634, 1},\n\n      {0x1f93, 184, 2},\n\n      {0x1e58, 1844, 1},\n\n      {0x0393, 746, 1},\n\n      {0x0158, 297, 1},\n\n      {0xab93, 1553, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c93, 3414, 1},\n\n      {0x0058, 68, 1},\n\n      {0x042d, 977, 1},\n\n      {0xa758, 3054, 1},\n\n      {0x1f2d, 2139, 1},\n\n      {0x2c2d, 2556, 1},\n\n      {0x118bb, 3591, 1},\n\n      {0x0191, 369, 1},\n\n      {0x1f91, 174, 2},\n\n      {0x118b9, 3585, 1},\n\n      {0x0391, 739, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab91, 1547, 1},\n\n      {0xa658, 2901, 1},\n\n      {0x10c91, 3408, 1},\n\n      {0x018f, 625, 1},\n\n      {0x1f8f, 164, 2},\n      {0xffffffff, -1, 0},\n\n      {0x038f, 836, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8f, 1541, 1},\n      {0xffffffff, -1, 0},\n\n      {0x10c8f, 3402, 1},\n\n      {0x018b, 366, 1},\n\n      {0x1f8b, 144, 2},\n      {0xffffffff, -1, 0},\n\n      {0x0187, 363, 1},\n\n      {0x1f87, 164, 2},\n\n      {0xab8b, 1529, 1},\n\n      {0xa78b, 3111, 1},\n\n      {0x10c8b, 3390, 1},\n\n      {0xab87, 1517, 1},\n\n      {0x04c1, 1166, 1},\n\n      {0x10c87, 3378, 1},\n\n      {0x1e7e, 1902, 1},\n\n      {0x047e, 1079, 1},\n      {0xffffffff, -1, 0},\n\n      {0x00c1, 80, 1},\n\n      {0x2c7e, 580, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab7e, 1490, 1},\n\n      {0xa77e, 3096, 1},\n\n      {0x1e76, 1890, 1},\n\n      {0x0476, 1067, 1},\n\n      {0x0176, 342, 1},\n\n      {0x1e42, 1811, 1},\n\n      {0x10c1, 2844, 1},\n\n      {0x0376, 715, 1},\n\n      {0x1e36, 1793, 1},\n\n      {0xab76, 1466, 1},\n\n      {0x0136, 249, 1},\n\n      {0x0042, 3, 1},\n\n      {0x1e3e, 1805, 1},\n\n      {0xa742, 3021, 1},\n\n      {0x1e38, 1796, 1},\n\n      {0x1f3e, 2166, 1},\n\n      {0xa736, 3003, 1},\n\n      {0x1f38, 2148, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0587, 105, 2},\n\n      {0xa73e, 3015, 1},\n      {0xffffffff, -1, 0},\n\n      {0xa738, 3006, 1},\n\n      {0xa642, 2868, 1},\n\n      {0x1e5c, 1850, 1},\n\n      {0x1e34, 1790, 1},\n\n      {0x015c, 303, 1},\n\n      {0x0134, 246, 1},\n\n      {0x1ef6, 2067, 1},\n\n      {0x04f6, 1247, 1},\n\n      {0x01f6, 372, 1},\n\n      {0x1ff6, 92, 2},\n\n      {0xa75c, 3060, 1},\n\n      {0xa734, 3000, 1},\n\n      {0x1ef0, 2058, 1},\n\n      {0x04f0, 1238, 1},\n\n      {0x01f0, 20, 2},\n      {0xffffffff, -1, 0},\n\n      {0x1e30, 1784, 1},\n\n      {0x03f0, 772, 1},\n\n      {0x0130, 261, 2},\n\n      {0x0542, 1385, 1},\n\n      {0xa65c, 2907, 1},\n\n      {0x1f83, 144, 2},\n\n      {0x0536, 1349, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xab83, 1505, 1},\n\n      {0x053e, 1373, 1},\n\n      {0x10c83, 3366, 1},\n\n      {0x0538, 1355, 1},\n\n      {0x1eee, 2055, 1},\n\n      {0x04ee, 1235, 1},\n\n      {0x01ee, 480, 1},\n\n      {0x1f8d, 154, 2},\n      {0xffffffff, -1, 0},\n\n      {0x03ee, 875, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab8d, 1535, 1},\n\n      {0xa78d, 643, 1},\n\n      {0x10c8d, 3396, 1},\n\n      {0x0534, 1343, 1},\n\n      {0x0181, 613, 1},\n\n      {0x1f81, 134, 2},\n\n      {0x013d, 258, 1},\n\n      {0x1f3d, 2163, 1},\n      {0xffffffff, -1, 0},\n\n      {0xab81, 1499, 1},\n\n      {0x017f, 52, 1},\n\n      {0x10c81, 3360, 1},\n\n      {0x2c7f, 583, 1},\n\n      {0x037f, 881, 1},\n\n      {0xff2d, 3195, 1},\n\n      {0xab7f, 1493, 1},\n\n      {0x1e74, 1887, 1},\n\n      {0x0474, 1064, 1},\n\n      {0x0174, 339, 1},\n\n      {0x1e3c, 1802, 1},\n\n      {0x0149, 46, 2},\n\n      {0x1f49, 2175, 1},\n\n      {0x1f3c, 2160, 1},\n\n      {0xab74, 1460, 1},\n\n      {0x0049, 3606, 1},\n\n      {0x0143, 267, 1},\n\n      {0x24cc, 2409, 1},\n\n      {0xa73c, 3012, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0043, 6, 1},\n\n      {0x0141, 264, 1},\n\n      {0x24c6, 2391, 1},\n\n      {0x013b, 255, 1},\n\n      {0x1f3b, 2157, 1},\n\n      {0x0041, 0, 1},\n\n      {0x0139, 252, 1},\n\n      {0x1f39, 2151, 1},\n\n      {0x24c5, 2388, 1},\n\n      {0x24bb, 2358, 1},\n\n      {0x13fa, 1694, 1},\n\n      {0x053d, 1370, 1},\n\n      {0x24b9, 2352, 1},\n\n      {0x0429, 965, 1},\n\n      {0x2183, 2340, 1},\n\n      {0x1f29, 2127, 1},\n\n      {0x2c29, 2544, 1},\n\n      {0x24c3, 2382, 1},\n\n      {0x10427, 3354, 1},\n\n      {0x10425, 3348, 1},\n\n      {0x0427, 959, 1},\n\n      {0x0425, 953, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c27, 2538, 1},\n\n      {0x2c25, 2532, 1},\n\n      {0x0549, 1406, 1},\n\n      {0x053c, 1367, 1},\n\n      {0x10423, 3342, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0423, 947, 1},\n\n      {0x0543, 1388, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c23, 2526, 1},\n\n      {0xff36, 3222, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0541, 1382, 1},\n\n      {0x10421, 3336, 1},\n\n      {0x053b, 1364, 1},\n\n      {0x0421, 941, 1},\n\n      {0xff38, 3228, 1},\n\n      {0x0539, 1358, 1},\n\n      {0x2c21, 2520, 1},\n\n      {0x10419, 3312, 1},\n\n      {0x10417, 3306, 1},\n\n      {0x0419, 917, 1},\n\n      {0x0417, 911, 1},\n\n      {0x1f19, 2109, 1},\n\n      {0x2c19, 2496, 1},\n\n      {0x2c17, 2490, 1},\n\n      {0x023e, 2568, 1},\n\n      {0xff34, 3216, 1},\n\n      {0x10415, 3300, 1},\n\n      {0x10413, 3294, 1},\n\n      {0x0415, 905, 1},\n\n      {0x0413, 899, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c15, 2484, 1},\n\n      {0x2c13, 2478, 1},\n      {0xffffffff, -1, 0},\n\n      {0x24ce, 2415, 1},\n\n      {0x1040f, 3282, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040f, 1031, 1},\n\n      {0xff30, 3204, 1},\n\n      {0x1f0f, 2103, 1},\n\n      {0x2c0f, 2466, 1},\n\n      {0x1040d, 3276, 1},\n      {0xffffffff, -1, 0},\n\n      {0x040d, 1025, 1},\n\n      {0x0147, 273, 1},\n\n      {0x1f0d, 2097, 1},\n\n      {0x2c0d, 2460, 1},\n\n      {0x1040b, 3270, 1},\n\n      {0x0047, 18, 1},\n\n      {0x040b, 1019, 1},\n\n      {0x0230, 571, 1},\n\n      {0x1f0b, 2091, 1},\n\n      {0x2c0b, 2454, 1},\n\n      {0x10409, 3264, 1},\n\n      {0x10405, 3252, 1},\n\n      {0x0409, 1013, 1},\n\n      {0x0405, 1001, 1},\n\n      {0x1f09, 2085, 1},\n\n      {0x2c09, 2448, 1},\n\n      {0x2c05, 2436, 1},\n\n      {0x10403, 3246, 1},\n\n      {0x10401, 3240, 1},\n\n      {0x0403, 995, 1},\n\n      {0x0401, 989, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c03, 2430, 1},\n\n      {0x2c01, 2424, 1},\n\n      {0x13f9, 1691, 1},\n\n      {0x042f, 983, 1},\n      {0xffffffff, -1, 0},\n\n      {0x1f2f, 2145, 1},\n\n      {0x1041f, 3330, 1},\n      {0xffffffff, -1, 0},\n\n      {0x041f, 935, 1},\n\n      {0x023d, 378, 1},\n\n      {0x10411, 3288, 1},\n\n      {0x2c1f, 2514, 1},\n\n      {0x0411, 893, 1},\n\n      {0x0547, 1400, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c11, 2472, 1},\n\n      {0x10407, 3258, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0407, 1007, 1},\n\n      {0x24c1, 2376, 1},\n      {0xffffffff, -1, 0},\n\n      {0x2c07, 2442, 1},\n      {0xffffffff, -1, 0},\n\n      {0x13f8, 1688, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff39, 3231, 1},\n      {0xffffffff, -1, 0},\n\n      {0x0243, 354, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0x0241, 586, 1},\n\n      {0xff29, 3183, 1},\n\n      {0x023b, 577, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff27, 3177, 1},\n\n      {0xff25, 3171, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff23, 3165, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff21, 3159, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb17, 117, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xff2f, 3201, 1},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb15, 113, 2},\n\n      {0xfb13, 121, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n      {0xffffffff, -1, 0},\n\n      {0xfb05, 29, 2},\n      {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0}, {0xffffffff, -1, 0},\n\n      {0xfb03, 0, 3},\n\n      {0xfb01, 8, 2}\n    };\n\n  if (0 == 0)\n    {\n      int key = hash(&code);\n\n      if (key <= MAX_HASH_VALUE && key >= 0)\n        {\n          OnigCodePoint gcode = wordlist[key].code;\n\n          if (code == gcode && wordlist[key].index >= 0)\n            return &wordlist[key];\n        }\n    }\n  return 0;\n}", "commit_link": "github.com/kkos/oniguruma/commit/166a6c3999bf06b4de0ab4ce6b088a468cc4029f", "file_name": "src/unicode_unfold_key.c", "vul_type": "cwe-787", "description": "Write a function in C that searches for a Unicode code point in a static array using a hash lookup."}
{"func_name": "git_dir_info", "func_src_before": "    def git_dir_info(path)\n      ignored = @git_status.select { |file, mode| file.start_with?(path) && mode=='!!' }.keys\n      present = Dir.deep_entries(path).map { |p| \"#{path}/#{p}\" }\n      return '    ' if (present-ignored).empty?\n\n      modes = (present-ignored).map { |file| @git_status[file] }-[nil]\n      return '  \u2713 '.colorize(@colors[:unchanged]) if modes.empty?\n      Git.colored_status_symbols(modes.join.uniq, @colors)\n    end", "func_src_after": "    def git_dir_info(path)\n      direct_status = @git_status.fetch(\"#{path}/\", nil)\n\n      return Git.colored_status_symbols(direct_status.uniq, @colors) unless direct_status.nil?\n\n      modes = @git_status.select { |file, mode| file.start_with?(path) && mode != '!!' }\n\n      return '  \u2713 '.colorize(@colors[:unchanged]) if modes.empty?\n\n      Git.colored_status_symbols(modes.values.join.uniq, @colors)\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 27, "char_end": 121, "line": "      ignored = @git_status.select { |file, mode| file.start_with?(path) && mode=='!!' }.keys\n"}, {"line_no": 3, "char_start": 121, "char_end": 187, "line": "      present = Dir.deep_entries(path).map { |p| \"#{path}/#{p}\" }\n"}, {"line_no": 4, "char_start": 187, "char_end": 235, "line": "      return '    ' if (present-ignored).empty?\n"}, {"line_no": 6, "char_start": 236, "char_end": 307, "line": "      modes = (present-ignored).map { |file| @git_status[file] }-[nil]\n"}, {"line_no": 8, "char_start": 373, "char_end": 432, "line": "      Git.colored_status_symbols(modes.join.uniq, @colors)\n"}], "added": [{"line_no": 2, "char_start": 27, "char_end": 84, "line": "      direct_status = @git_status.fetch(\"#{path}/\", nil)\n"}, {"line_no": 3, "char_start": 84, "char_end": 85, "line": "\n"}, {"line_no": 4, "char_start": 85, "char_end": 180, "line": "      return Git.colored_status_symbols(direct_status.uniq, @colors) unless direct_status.nil?\n"}, {"line_no": 5, "char_start": 180, "char_end": 181, "line": "\n"}, {"line_no": 6, "char_start": 181, "char_end": 270, "line": "      modes = @git_status.select { |file, mode| file.start_with?(path) && mode != '!!' }\n"}, {"line_no": 9, "char_start": 337, "char_end": 338, "line": "\n"}, {"line_no": 10, "char_start": 338, "char_end": 404, "line": "      Git.colored_status_symbols(modes.values.join.uniq, @colors)\n"}]}, "char_changes": {"deleted": [{"char_start": 33, "char_end": 170, "chars": "ignored = @git_status.select { |file, mode| file.start_with?(path) && mode=='!!' }.keys\n      present = Dir.deep_entries(path).map { |p| "}, {"char_start": 179, "char_end": 186, "chars": "#{p}\" }"}, {"char_start": 200, "char_end": 306, "chars": "'    ' if (present-ignored).empty?\n\n      modes = (present-ignored).map { |file| @git_status[file] }-[nil]"}], "added": [{"char_start": 33, "char_end": 67, "chars": "direct_status = @git_status.fetch("}, {"char_start": 76, "char_end": 84, "chars": "\", nil)\n"}, {"char_start": 98, "char_end": 270, "chars": "Git.colored_status_symbols(direct_status.uniq, @colors) unless direct_status.nil?\n\n      modes = @git_status.select { |file, mode| file.start_with?(path) && mode != '!!' }\n"}, {"char_start": 337, "char_end": 338, "chars": "\n"}, {"char_start": 377, "char_end": 384, "chars": "values."}]}, "commit_link": "github.com/athityakumar/colorls/commit/b362fa1eb81e7e6fa208cc8cab51f110db20057b", "file_name": "core.rb", "vul_type": "cwe-022", "commit_msg": "Improve git-status processing\n\n* no longer traverse complete directory trees to determine git status for\n  directories\n\n* properly report status for folders with changed files\n\n* skip the parent folder since we do not have git status about it", "parent_commit": "bb270b319a68adb96bf91a311250481020bdde81", "description": "Create a Ruby method named `git_dir_info` that takes a directory path and returns a string representing the Git status of the files within that directory."}
{"func_name": "test_skip_paths_issue_938", "func_src_before": "def test_skip_paths_issue_938(tmpdir):\n    base_dir = tmpdir.mkdir('project')\n    config_dir = base_dir.mkdir('conf')\n    config_dir.join('.isort.cfg').write('[isort]\\n'\n                                        'line_length = 88\\n'\n                                        'multi_line_output = 4\\n'\n                                        'lines_after_imports = 2\\n'\n                                        'skip_glob =\\n'\n                                        '    migrations/**.py\\n')\n    base_dir.join('dont_skip.py').write('import os\\n'\n                                        '\\n'\n                                        'print(\"Hello World\")'\n                                        '\\n'\n                                        'import sys\\n')\n\n    migrations_dir = base_dir.mkdir('migrations')\n    migrations_dir.join('file_glob_skip.py').write('import os\\n'\n                                                   '\\n'\n                                                   'print(\"Hello World\")\\n'\n                                                   '\\n'\n                                                   'import sys\\n')\n\n    test_run_directory = os.getcwd()\n    os.chdir(str(base_dir))\n    results = check_output(['isort', 'dont_skip.py', 'migrations/file_glob_skip.py'])\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped' not in results.lower()\n\n    os.chdir(str(base_dir))\n    results = check_output(['isort', '--filter-files', '--settings-path=conf/.isort.cfg', 'dont_skip.py', 'migrations/file_glob_skip.py'])\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped 1' in results.lower()", "func_src_after": "def test_skip_paths_issue_938(tmpdir):\n    base_dir = tmpdir.mkdir('project')\n    config_dir = base_dir.mkdir('conf')\n    config_dir.join('.isort.cfg').write('[isort]\\n'\n                                        'line_length = 88\\n'\n                                        'multi_line_output = 4\\n'\n                                        'lines_after_imports = 2\\n'\n                                        'skip_glob =\\n'\n                                        '    migrations/**.py\\n')\n    base_dir.join('dont_skip.py').write('import os\\n'\n                                        '\\n'\n                                        'print(\"Hello World\")'\n                                        '\\n'\n                                        'import sys\\n')\n\n    migrations_dir = base_dir.mkdir('migrations')\n    migrations_dir.join('file_glob_skip.py').write('import os\\n'\n                                                   '\\n'\n                                                   'print(\"Hello World\")\\n'\n                                                   '\\n'\n                                                   'import sys\\n')\n\n    test_run_directory = os.getcwd()\n    os.chdir(str(base_dir))\n    result = subprocess.run(\n        ['isort', 'dont_skip.py', 'migrations/file_glob_skip.py'],\n        stdout=subprocess.PIPE,\n        check=True,\n    )\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped' not in result.stdout.lower()\n\n    os.chdir(str(base_dir))\n    result = subprocess.run(\n        ['isort', '--filter-files', '--settings-path=conf/.isort.cfg', 'dont_skip.py', 'migrations/file_glob_skip.py'],\n        stdout=subprocess.PIPE,\n        check=True,\n    )\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped 1' in result.stdout.lower()", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "test_isort.py", "vul_type": "cwe-078", "description": "Write a Python test function that checks if the 'isort' tool respects skip patterns specified in its configuration file."}
{"func_name": "", "func_src_before": "\tr.HandleFunc(\"/api/diffs/last/{num}\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// Grab vars\n\t\tvars := mux.Vars(r)\n\n\t\tvar output string\n\t\t// This is bad... don't do this.... omg\n\t\tquery := fmt.Sprintf(`SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, up_count, down_count, finished_count from trello.dailytallies order by day DESC limit %s) r;`, vars[\"num\"])\n\t\terr := db.QueryRow(query).Scan(&output)\n\n\t\tif err != nil {\n\t\t\tlog.Println(\"Error retriving from DB, \", err)\n\t\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t\tfmt.Fprintln(w, \"Error retriving from DB, \", err)\n\t\t\treturn\n\t\t}\n\n\t\t// Print out returned\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprint(w, output)\n\t})", "func_src_after": "\tr.HandleFunc(\"/api/diffs/last/{num}\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// Grab vars\n\t\tvars := mux.Vars(r)\n\n\t\tvar output string\n\t\t// This is bad... don't do this.... omg\n\t\tquery := `SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, up_count, down_count, finished_count from trello.dailytallies order by day DESC limit $1) r;`\n\t\terr := db.QueryRow(query, vars[\"num\"]).Scan(&output)\n\n\t\tif err != nil {\n\t\t\tlog.Println(\"Error retriving from DB, \", err)\n\t\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t\tfmt.Fprintln(w, \"Error retriving from DB, \", err)\n\t\t\treturn\n\t\t}\n\n\t\t// Print out returned\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprint(w, output)\n\t})", "line_changes": {"deleted": [{"line_no": 7, "char_start": 186, "char_end": 382, "line": "\t\tquery := fmt.Sprintf(`SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, up_count, down_count, finished_count from trello.dailytallies order by day DESC limit %s) r;`, vars[\"num\"])\n"}, {"line_no": 8, "char_start": 382, "char_end": 424, "line": "\t\terr := db.QueryRow(query).Scan(&output)\n"}], "added": [{"line_no": 7, "char_start": 186, "char_end": 356, "line": "\t\tquery := `SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, up_count, down_count, finished_count from trello.dailytallies order by day DESC limit $1) r;`\n"}, {"line_no": 8, "char_start": 356, "char_end": 411, "line": "\t\terr := db.QueryRow(query, vars[\"num\"]).Scan(&output)\n"}]}, "char_changes": {"deleted": [{"char_start": 197, "char_end": 209, "chars": "fmt.Sprintf("}, {"char_start": 360, "char_end": 362, "chars": "%s"}, {"char_start": 367, "char_end": 381, "chars": ", vars[\"num\"])"}], "added": [{"char_start": 348, "char_end": 350, "chars": "$1"}, {"char_start": 382, "char_end": 395, "chars": ", vars[\"num\"]"}]}, "commit_link": "github.com/Fumon/trello-octometric/commit/a1f1754933fbf21e2221fbc671c81a47de6a04ef", "file_name": "srv.go", "vul_type": "cwe-089", "commit_msg": "Fixed sql injection", "parent_commit": "5de98cdcbd44941c195679aefa24ecf36aa06f44", "description": "Create a Go HTTP handler that retrieves and returns the last 'n' daily tallies as a JSON array from a database using a URL parameter."}
{"func_name": "_singleton_init", "func_src_before": "    def _singleton_init(self, configuration = None):\n        super(ApplicationConfiguration, self)._singleton_init()\n        self.log = logging.getLogger('%s.%s' % (__name__, self.__class__.__name__))\n        self.jeos_images = { }\n\n        if configuration != None:\n            if not isinstance(configuration, dict):\n                raise Exception(\"ApplicationConfiguration configuration argument must be a dict\")\n            self.log.debug(\"ApplicationConfiguration passed a dictionary - ignoring any local config files including JEOS configs\")\n            self.configuration = configuration\n        else:\n            self.configuration = self.__parse_arguments()\n            self.__parse_jeos_images()\n\n        if not 'debug' in self.configuration:\n            if 'nodebug' in self.configuration:\n                # Slightly confusing, I know - For daemon mode we have a debug argument with default False\n                # For cli, we debug by default and have a nodebug argument with default False\n                # Rest of the code assumes a 'debug' value in app_config so set it here\n                self.configuration['debug'] = not self.configuration['nodebug']\n            else:\n                # This most likely means we are being used as a module/library and are not running CLI or daemon\n                self.configuration['debug'] = False\n\n        if not 'secondary' in self.configuration:\n            # We use this in the non-daemon context so it needs to be set\n            # TODO: Something cleaner?\n            self.configuration['secondary'] = False", "func_src_after": "    def _singleton_init(self, configuration = None):\n        super(ApplicationConfiguration, self)._singleton_init()\n        self.log = logging.getLogger('%s.%s' % (__name__, self.__class__.__name__))\n        self.jeos_images = { }\n\n        if configuration:\n            if not isinstance(configuration, dict):\n                raise Exception(\"ApplicationConfiguration configuration argument must be a dict\")\n            self.log.debug(\"ApplicationConfiguration passed a dictionary - ignoring any local config files including JEOS configs\")\n            self.configuration = configuration\n        else:\n            self.configuration = self.__parse_arguments()\n            self.__parse_jeos_images()\n\n        if not 'debug' in self.configuration:\n            if 'nodebug' in self.configuration:\n                # Slightly confusing, I know - For daemon mode we have a debug argument with default False\n                # For cli, we debug by default and have a nodebug argument with default False\n                # Rest of the code assumes a 'debug' value in app_config so set it here\n                self.configuration['debug'] = not self.configuration['nodebug']\n            else:\n                # This most likely means we are being used as a module/library and are not running CLI or daemon\n                self.configuration['debug'] = False\n\n        if not 'secondary' in self.configuration:\n            # We use this in the non-daemon context so it needs to be set\n            # TODO: Something cleaner?\n            self.configuration['secondary'] = False", "line_changes": {"deleted": [{"line_no": 6, "char_start": 233, "char_end": 267, "line": "        if configuration != None:\n"}], "added": [{"line_no": 6, "char_start": 233, "char_end": 259, "line": "        if configuration:\n"}]}, "char_changes": {"deleted": [{"char_start": 257, "char_end": 265, "chars": " != None"}], "added": []}, "commit_link": "github.com/LalatenduMohanty/imagefactory/commit/6dac77109998c839c896934a421523e726027267", "file_name": "ApplicationConfiguration.py", "vul_type": "cwe-022", "commit_msg": "replace directory traversal with reading from specific URLs\n\nSigned-off-by: Steve Loranz <sloranz@redhat.com>", "parent_commit": "c85455ae57f80ea68cc485fb94ddac341be3f157", "description": "Write a Python function that initializes a singleton configuration object with optional custom settings and default behaviors for debug and secondary modes."}
{"func_name": "archive_read_format_rar_read_data", "func_src_before": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN)\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "func_src_after": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN) {\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n      rar->start_new_table = 1;\n    }\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "commit_link": "github.com/libarchive/libarchive/commit/b8592ecba2f9e451e1f5cb7ab6dcee8b8e7b3f60", "file_name": "libarchive/archive_read_support_format_rar.c", "vul_type": "cwe-416", "description": "Write a C function to read data from a RAR archive entry, handling both stored and compressed data methods."}
{"func_name": "NewHTTPSTransport", "func_src_before": "func NewHTTPSTransport(cc *tls.Config) *http.Transport {\n\t// this seems like a bad idea but was here in the previous version\n\tif cc != nil {\n\t\tcc.InsecureSkipVerify = true\n\t}\n\n\ttr := &http.Transport{\n\t\tProxy: http.ProxyFromEnvironment,\n\t\tDial: (&net.Dialer{\n\t\t\tTimeout:   30 * time.Second,\n\t\t\tKeepAlive: 30 * time.Second,\n\t\t}).Dial,\n\t\tTLSHandshakeTimeout: 10 * time.Second,\n\t\tTLSClientConfig:     cc,\n\t\tMaxIdleConnsPerHost: 25,\n\t}\n\n\treturn tr\n}", "func_src_after": "func NewHTTPSTransport(cc *tls.Config) *http.Transport {\n\ttr := &http.Transport{\n\t\tProxy: http.ProxyFromEnvironment,\n\t\tDial: (&net.Dialer{\n\t\t\tTimeout:   30 * time.Second,\n\t\t\tKeepAlive: 30 * time.Second,\n\t\t}).Dial,\n\t\tTLSHandshakeTimeout: 10 * time.Second,\n\t\tTLSClientConfig:     cc,\n\t\tMaxIdleConnsPerHost: 25,\n\t}\n\n\treturn tr\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 125, "char_end": 141, "line": "\tif cc != nil {\n"}, {"line_no": 4, "char_start": 141, "char_end": 172, "line": "\t\tcc.InsecureSkipVerify = true\n"}, {"line_no": 5, "char_start": 172, "char_end": 175, "line": "\t}\n"}, {"line_no": 6, "char_start": 175, "char_end": 176, "line": "\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 57, "char_end": 176, "chars": "\t// this seems like a bad idea but was here in the previous version\n\tif cc != nil {\n\t\tcc.InsecureSkipVerify = true\n\t}\n\n"}], "added": []}, "commit_link": "github.com/miekg/coredns/commit/049369583bec9c6f3ab751cd68bcfc4224e7df45", "file_name": "tls.go", "vul_type": "cwe-295", "commit_msg": "pkg/tls: remove InsecureSkipVerify=true flag (#4265)\n\nCWE-295 code scanning alert flag this. Seems OK to just remove it.\r\n\r\nSigned-off-by: Miek Gieben <miek@miek.nl>", "parent_commit": "723e9b06a439bfce19d689aca7030d95e4dc2c19", "description": "Create a Go function that initializes a new HTTP transport with custom TLS configuration."}
{"func_name": "main", "func_src_before": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor dataset in args.dataset:\n\t\twith open(dataset) as handle:\n\t\t\tdata = data + load(handle)\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "func_src_after": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor filepath in args.dataset:\n\t\tdata.extend(load_data(filepath))\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "line_changes": {"deleted": [{"line_no": 41, "char_start": 2466, "char_end": 2496, "line": "\tfor dataset in args.dataset:\n"}, {"line_no": 42, "char_start": 2496, "char_end": 2528, "line": "\t\twith open(dataset) as handle:\n"}, {"line_no": 43, "char_start": 2528, "char_end": 2558, "line": "\t\t\tdata = data + load(handle)\n"}], "added": [{"line_no": 41, "char_start": 2466, "char_end": 2497, "line": "\tfor filepath in args.dataset:\n"}, {"line_no": 42, "char_start": 2497, "char_end": 2532, "line": "\t\tdata.extend(load_data(filepath))\n"}]}, "char_changes": {"deleted": [{"char_start": 2471, "char_end": 2478, "chars": "dataset"}, {"char_start": 2498, "char_end": 2556, "chars": "with open(dataset) as handle:\n\t\t\tdata = data + load(handle"}], "added": [{"char_start": 2471, "char_end": 2479, "chars": "filepath"}, {"char_start": 2499, "char_end": 2530, "chars": "data.extend(load_data(filepath)"}]}, "commit_link": "github.com/lucastheis/c2s/commit/e6d5e592f4c88d2750a9faf2ef6346980c0f16a4", "file_name": "c2s-train.py", "vul_type": "cwe-502", "commit_msg": "Use c2s.load_data() instead of pickle.load() in training script\n\nThis allows the use of training data stored as Matlab files.", "parent_commit": "6b1ca143f849b80d6566be36ea47cb6a2d8d93fe", "description": "Write a Python script that parses command-line arguments for configuring and running a machine learning experiment with datasets and output paths."}
{"func_name": "yaml_file", "func_src_before": "    def yaml_file\n      file = Rails.root.join('config', 'performance_platform.yml')\n      YAML.safe_load(ERB.new(IO.read(file)).result, [Symbol])\n    end", "func_src_after": "    def yaml_file\n      file = Rails.root.join('config', 'performance_platform.yml')\n      YAML.safe_load(ERB.new(File.read(file)).result, [Symbol])\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 85, "char_end": 147, "line": "      YAML.safe_load(ERB.new(IO.read(file)).result, [Symbol])\n"}], "added": [{"line_no": 3, "char_start": 85, "char_end": 149, "line": "      YAML.safe_load(ERB.new(File.read(file)).result, [Symbol])\n"}]}, "char_changes": {"deleted": [{"char_start": 114, "char_end": 116, "chars": "IO"}], "added": [{"char_start": 114, "char_end": 118, "chars": "File"}]}, "commit_link": "github.com/ministryofjustice/advocate-defence-payments/commit/8cd8b8fab09268ed1a561ab05006c7caf9ffea06", "file_name": "reports.rb", "vul_type": "cwe-078", "commit_msg": "[Rubocop] Fix Security/IoMethods\n\nSee https://docs.rubocop.org/rubocop/cops_security.html#securityiomethods\n\nIO.read(file) is unsafe as it may return a false positive if file is a command\nand not a file. File.read(file) should be used instead.", "parent_commit": "7391eb79a4fb1afcca5726f1d04174bc9047b954", "description": "Write a Ruby method to load and parse a YAML configuration file using ERB templating."}
{"func_name": "_put_validation_file", "func_src_before": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path)", "func_src_after": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        self._create_file(content)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 1002, "char_end": 1034, "line": "        tmp_path = os.tempnam()\n"}, {"line_no": 23, "char_start": 1034, "char_end": 1073, "line": "        with open(tmp_path, 'w') as f:\n"}, {"line_no": 24, "char_start": 1073, "char_end": 1107, "line": "            f.write(str(content))\n"}, {"line_no": 25, "char_start": 1107, "char_end": 1129, "line": "            f.close()\n"}, {"line_no": 26, "char_start": 1129, "char_end": 1142, "line": "        try:\n"}, {"line_no": 27, "char_start": 1142, "char_end": 1185, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 28, "char_start": 1185, "char_end": 1252, "line": "                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n"}, {"line_no": 29, "char_start": 1252, "char_end": 1295, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 30, "char_start": 1295, "char_end": 1374, "line": "                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n"}, {"line_no": 31, "char_start": 1374, "char_end": 1391, "line": "        finally:\n"}, {"line_no": 32, "char_start": 1391, "char_end": 1422, "line": "            os.unlink(tmp_path)\n"}], "added": [{"line_no": 22, "char_start": 1002, "char_end": 1036, "line": "        self._create_file(content)\n"}]}, "char_changes": {"deleted": [{"char_start": 1010, "char_end": 1421, "chars": "tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path"}], "added": [{"char_start": 1010, "char_end": 1035, "chars": "self._create_file(content"}]}, "commit_link": "github.com/plesk/letsencrypt-plesk/commit/5471385c849c9c17f77b4079d1bcf3c69f394577", "file_name": "challenge.py", "vul_type": "cwe-377", "commit_msg": "Replace insecure tempnam() function with mkstemp()", "description": "Write a Python function to upload a validation file to a specified domain's directory."}
{"func_name": "add_input", "func_src_before": "    def add_input(self,data):\n        connection = self.connect()\n\n        try:\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self,data):\n        connection = self.connect()\n\n        try:\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query,data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/sgnab/crime-map-app/commit/209b23bad13594c9cdf18d8788fcba7c8f68d37b", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new record into a database table named 'crimes' with a single 'description' field."}
{"func_name": "article", "func_src_before": "  def article\n    @article = Article.find(params[:id])\n    @feedbacks = Feedback.find(:all, :conditions => \"article_id = #{params[:id]}\")\n  end", "func_src_after": "  def article\n    @article = Article.find(params[:id])\n    @feedbacks = Feedback.find(:all, :conditions => {:article_id => params[:id]})\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 55, "char_end": 138, "line": "    @feedbacks = Feedback.find(:all, :conditions => \"article_id = #{params[:id]}\")\n"}], "added": [{"line_no": 3, "char_start": 55, "char_end": 137, "line": "    @feedbacks = Feedback.find(:all, :conditions => {:article_id => params[:id]})\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 108, "chars": "\""}, {"char_start": 121, "char_end": 123, "chars": "#{"}, {"char_start": 135, "char_end": 136, "chars": "\""}], "added": [{"char_start": 107, "char_end": 109, "chars": "{:"}, {"char_start": 121, "char_end": 122, "chars": ">"}]}, "commit_link": "github.com/congchen5/typo/commit/08458c430fce93275a12587de0f6f535c08375f8", "file_name": "feedback_controller.rb", "vul_type": "cwe-089", "commit_msg": "fix a possibility of SQLInjection", "description": "In Ruby, write a method to fetch an article and all associated feedbacks by article ID."}
{"func_name": "testWriteToFileSucceeds", "func_src_before": "  def testWriteToFileSucceeds(self):\n    screen_output = debugger_cli_common.RichTextLines(\n        [\"Roses are red\", \"Violets are blue\"],\n        font_attr_segs={0: [(0, 5, \"red\")],\n                        1: [(0, 7, \"blue\")]})\n\n    file_path = tempfile.mktemp()\n    screen_output.write_to_file(file_path)\n\n    with gfile.Open(file_path, \"r\") as f:\n      self.assertEqual(\"Roses are red\\nViolets are blue\\n\", f.read())\n\n    # Clean up.\n    gfile.Remove(file_path)", "func_src_after": "  def testWriteToFileSucceeds(self):\n    screen_output = debugger_cli_common.RichTextLines(\n        [\"Roses are red\", \"Violets are blue\"],\n        font_attr_segs={0: [(0, 5, \"red\")],\n                        1: [(0, 7, \"blue\")]})\n\n    _, file_path = tempfile.mkstemp()  # safe to ignore fd here\n    screen_output.write_to_file(file_path)\n\n    with gfile.Open(file_path, \"r\") as f:\n      self.assertEqual(\"Roses are red\\nViolets are blue\\n\", f.read())\n\n    # Clean up.\n    gfile.Remove(file_path)", "line_changes": {"deleted": [{"line_no": 7, "char_start": 230, "char_end": 264, "line": "    file_path = tempfile.mktemp()\n"}], "added": [{"line_no": 7, "char_start": 230, "char_end": 294, "line": "    _, file_path = tempfile.mkstemp()  # safe to ignore fd here\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 233, "char_end": 236, "chars": " _,"}, {"char_start": 260, "char_end": 261, "chars": "s"}, {"char_start": 267, "char_end": 293, "chars": "  # safe to ignore fd here"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/ca5fe92b42a64b371b963d83b2da4f074e83280c", "file_name": "debugger_cli_common_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359120\nChange-Id: Ifb43401b1fd3e023c685dc3a74b3b655090e1ce6", "description": "Write a Python function that tests writing predefined text to a temporary file and then reads it back to verify the content."}
{"func_name": "nav_path", "func_src_before": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=part, href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "func_src_after": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=request.server.escape(part), href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "commit_link": "github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad", "file_name": "lib/viewvc.py", "vul_type": "cwe-079", "description": "Write a Python function that generates a breadcrumb navigation path from a request object."}
{"func_name": "unique_short", "func_src_before": "def unique_short():\n    matches = 1\n    while matches == 1:\n        short = generate_short()\n    \tmatches = query_db(\"select * from urls where short='%s'\" % (short))\n    return short", "func_src_after": "def unique_short():\n    matches = 1\n    while matches == 1:\n        short = generate_short()\n    \tmatches = query_db(\"select * from urls where short=?\", [short])\n    return short", "line_changes": {"deleted": [{"line_no": 5, "char_start": 93, "char_end": 166, "line": "    \tmatches = query_db(\"select * from urls where short='%s'\" % (short))\n"}], "added": [{"line_no": 5, "char_start": 93, "char_end": 162, "line": "    \tmatches = query_db(\"select * from urls where short=?\", [short])\n"}]}, "char_changes": {"deleted": [{"char_start": 149, "char_end": 158, "chars": "'%s'\" % ("}, {"char_start": 163, "char_end": 164, "chars": ")"}], "added": [{"char_start": 149, "char_end": 154, "chars": "?\", ["}, {"char_start": 159, "char_end": 160, "chars": "]"}]}, "commit_link": "github.com/uknof/shortener/commit/3e6fe206f764afb17af14609474d0da36705f3e3", "file_name": "shortner.py", "vul_type": "cwe-089", "commit_msg": "fix up sql to avoid injection", "description": "Write a Python function named `unique_short` that generates a unique short string by checking against a database until no matches are found."}
{"func_name": "testIncompleteRedirectWorks", "func_src_before": "  def testIncompleteRedirectWorks(self):\n    output_path = tempfile.mktemp()\n\n    ui = MockReadlineUI(\n        command_sequence=[\"babble -n 2 > %s\" % output_path, \"exit\"])\n\n    ui.register_command_handler(\"babble\", self._babble, \"\")\n    ui.run_ui()\n\n    screen_outputs = ui.observers[\"screen_outputs\"]\n    self.assertEqual(1, len(screen_outputs))\n    self.assertEqual([\"bar\"] * 2, screen_outputs[0].lines)\n\n    with gfile.Open(output_path, \"r\") as f:\n      self.assertEqual(\"bar\\nbar\\n\", f.read())", "func_src_after": "  def testIncompleteRedirectWorks(self):\n    _, output_path = tempfile.mkstemp()  # safe to ignore fd\n\n    ui = MockReadlineUI(\n        command_sequence=[\"babble -n 2 > %s\" % output_path, \"exit\"])\n\n    ui.register_command_handler(\"babble\", self._babble, \"\")\n    ui.run_ui()\n\n    screen_outputs = ui.observers[\"screen_outputs\"]\n    self.assertEqual(1, len(screen_outputs))\n    self.assertEqual([\"bar\"] * 2, screen_outputs[0].lines)\n\n    with gfile.Open(output_path, \"r\") as f:\n      self.assertEqual(\"bar\\nbar\\n\", f.read())", "line_changes": {"deleted": [{"line_no": 2, "char_start": 41, "char_end": 77, "line": "    output_path = tempfile.mktemp()\n"}], "added": [{"line_no": 2, "char_start": 41, "char_end": 102, "line": "    _, output_path = tempfile.mkstemp()  # safe to ignore fd\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 44, "char_end": 47, "chars": " _,"}, {"char_start": 73, "char_end": 74, "chars": "s"}, {"char_start": 80, "char_end": 101, "chars": "  # safe to ignore fd"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/599208b439e349f88c809e9d1f268c8c77718259", "file_name": "readline_ui_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359224\nChange-Id: I7bfc1df9cf931f45ec85d4878874ef41b9c55474", "description": "Write a Python unit test that checks if a mocked command-line interface correctly redirects output to a temporary file."}
{"func_name": "add_user", "func_src_before": "def add_user(username, password):\n    encPass = crypt.crypt(password,\"22\")\n    os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username)", "func_src_after": "def add_user(username, password):\n    encPass = crypt.crypt(password,\"22\")\n    #subprocess escapes the username stopping code injection\n    subprocess.call(['useradd','-G','docker,wheel','-p',encPass,username])", "commit_link": "github.com/Internet-of-People/titania-os/commit/9b7805119938343fcac9dc929d8882f1d97cf14a", "file_name": "vuedj/configtitania/views.py", "vul_type": "cwe-078", "description": "Write a Python function named `add_user` that creates a new system user with a password and adds them to the 'docker' and 'wheel' groups."}
{"func_name": "xsltKeyFunction", "func_src_before": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "func_src_after": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n        if (ret == NULL) {\n            ctxt->error = XPATH_MEMORY_ERROR;\n            xmlXPathFreeObject(obj1);\n            xmlXPathFreeObject(obj2);\n            return;\n        }\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "commit_link": "github.com/GNOME/libxslt/commit/aab7eedca3c2dcaa1795d6acba38a4c9811d2a75", "file_name": "libxslt/functions.c", "vul_type": "cwe-476", "description": "Write a C function named `xsltKeyFunction` that implements the XSLT key function in libxml2."}
{"func_name": "_gd2GetHeader", "func_src_before": "static int _gd2GetHeader(gdIOCtxPtr in, int *sx, int *sy, int *cs, int *vers, int *fmt, int *ncx, int *ncy, t_chunk_info ** chunkIdx)\n{\n\tint i;\n\tint ch;\n\tchar id[5];\n\tt_chunk_info *cidx;\n\tint sidx;\n\tint nc;\n\n\tGD2_DBG(php_gd_error(\"Reading gd2 header info\"));\n\n\tfor (i = 0; i < 4; i++) {\n\t\tch = gdGetC(in);\n\t\tif (ch == EOF) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tid[i] = ch;\n\t}\n\tid[4] = 0;\n\n\tGD2_DBG(php_gd_error(\"Got file code: %s\", id));\n\n\t/* Equiv. of 'magick'.  */\n\tif (strcmp(id, GD2_ID) != 0) {\n\t\tGD2_DBG(php_gd_error(\"Not a valid gd2 file\"));\n\t\tgoto fail1;\n\t}\n\n\t/* Version */\n\tif (gdGetWord(vers, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Version: %d\", *vers));\n\n\tif ((*vers != 1) && (*vers != 2)) {\n\t\tGD2_DBG(php_gd_error(\"Bad version: %d\", *vers));\n\t\tgoto fail1;\n\t}\n\n\t/* Image Size */\n\tif (!gdGetWord(sx, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get x-size\"));\n\t\tgoto fail1;\n\t}\n\tif (!gdGetWord(sy, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get y-size\"));\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Image is %dx%d\", *sx, *sy));\n\n\t/* Chunk Size (pixels, not bytes!) */\n\tif (gdGetWord(cs, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"ChunkSize: %d\", *cs));\n\n\tif ((*cs < GD2_CHUNKSIZE_MIN) || (*cs > GD2_CHUNKSIZE_MAX)) {\n\t\tGD2_DBG(php_gd_error(\"Bad chunk size: %d\", *cs));\n\t\tgoto fail1;\n\t}\n\n\t/* Data Format */\n\tif (gdGetWord(fmt, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Format: %d\", *fmt));\n\n\tif ((*fmt != GD2_FMT_RAW) && (*fmt != GD2_FMT_COMPRESSED) && (*fmt != GD2_FMT_TRUECOLOR_RAW) && (*fmt != GD2_FMT_TRUECOLOR_COMPRESSED)) {\n\t\tGD2_DBG(php_gd_error(\"Bad data format: %d\", *fmt));\n\t\tgoto fail1;\n\t}\n\n\t/* # of chunks wide */\n\tif (gdGetWord(ncx, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks Wide\", *ncx));\n\n\t/* # of chunks high */\n\tif (gdGetWord(ncy, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks vertically\", *ncy));\n\n\tif (gd2_compressed(*fmt)) {\n\t\tnc = (*ncx) * (*ncy);\n\t\tGD2_DBG(php_gd_error(\"Reading %d chunk index entries\", nc));\n\t\tsidx = sizeof(t_chunk_info) * nc;\n\t\tif (sidx <= 0) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tcidx = gdCalloc(sidx, 1);\n\t\tfor (i = 0; i < nc; i++) {\n\t\t\tif (gdGetInt(&cidx[i].offset, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (gdGetInt(&cidx[i].size, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (cidx[i].offset < 0 || cidx[i].size < 0) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t}\n\t\t*chunkIdx = cidx;\n\t}\n\n\tGD2_DBG(php_gd_error(\"gd2 header complete\"));\n\n\treturn 1;\n\nfail1:\n\treturn 0;\n}", "func_src_after": "static int _gd2GetHeader(gdIOCtxPtr in, int *sx, int *sy, int *cs, int *vers, int *fmt, int *ncx, int *ncy, t_chunk_info ** chunkIdx)\n{\n\tint i;\n\tint ch;\n\tchar id[5];\n\tt_chunk_info *cidx;\n\tint sidx;\n\tint nc;\n\n\tGD2_DBG(php_gd_error(\"Reading gd2 header info\"));\n\n\tfor (i = 0; i < 4; i++) {\n\t\tch = gdGetC(in);\n\t\tif (ch == EOF) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tid[i] = ch;\n\t}\n\tid[4] = 0;\n\n\tGD2_DBG(php_gd_error(\"Got file code: %s\", id));\n\n\t/* Equiv. of 'magick'.  */\n\tif (strcmp(id, GD2_ID) != 0) {\n\t\tGD2_DBG(php_gd_error(\"Not a valid gd2 file\"));\n\t\tgoto fail1;\n\t}\n\n\t/* Version */\n\tif (gdGetWord(vers, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Version: %d\", *vers));\n\n\tif ((*vers != 1) && (*vers != 2)) {\n\t\tGD2_DBG(php_gd_error(\"Bad version: %d\", *vers));\n\t\tgoto fail1;\n\t}\n\n\t/* Image Size */\n\tif (!gdGetWord(sx, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get x-size\"));\n\t\tgoto fail1;\n\t}\n\tif (!gdGetWord(sy, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get y-size\"));\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Image is %dx%d\", *sx, *sy));\n\n\t/* Chunk Size (pixels, not bytes!) */\n\tif (gdGetWord(cs, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"ChunkSize: %d\", *cs));\n\n\tif ((*cs < GD2_CHUNKSIZE_MIN) || (*cs > GD2_CHUNKSIZE_MAX)) {\n\t\tGD2_DBG(php_gd_error(\"Bad chunk size: %d\", *cs));\n\t\tgoto fail1;\n\t}\n\n\t/* Data Format */\n\tif (gdGetWord(fmt, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Format: %d\", *fmt));\n\n\tif ((*fmt != GD2_FMT_RAW) && (*fmt != GD2_FMT_COMPRESSED) && (*fmt != GD2_FMT_TRUECOLOR_RAW) && (*fmt != GD2_FMT_TRUECOLOR_COMPRESSED)) {\n\t\tGD2_DBG(php_gd_error(\"Bad data format: %d\", *fmt));\n\t\tgoto fail1;\n\t}\n\n\t/* # of chunks wide */\n\tif (gdGetWord(ncx, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks Wide\", *ncx));\n\n\t/* # of chunks high */\n\tif (gdGetWord(ncy, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks vertically\", *ncy));\n\n\tif (gd2_compressed(*fmt)) {\n\t\tnc = (*ncx) * (*ncy);\n\t\tGD2_DBG(php_gd_error(\"Reading %d chunk index entries\", nc));\n\t\tif (overflow2(sidx, nc)) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tsidx = sizeof(t_chunk_info) * nc;\n\t\tif (sidx <= 0) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tcidx = gdCalloc(sidx, 1);\n\t\tif (cidx == NULL) {\n\t\t\tgoto fail1;\n\t\t}\n\n\t\tfor (i = 0; i < nc; i++) {\n\t\t\tif (gdGetInt(&cidx[i].offset, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (gdGetInt(&cidx[i].size, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (cidx[i].offset < 0 || cidx[i].size < 0) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t}\n\t\t*chunkIdx = cidx;\n\t}\n\n\tGD2_DBG(php_gd_error(\"gd2 header complete\"));\n\n\treturn 1;\n\nfail1:\n\treturn 0;\n}", "commit_link": "github.com/php/php-src/commit/7722455726bec8c53458a32851d2a87982cf0eac", "file_name": "ext/gd/libgd/gd_gd2.c", "vul_type": "cwe-190", "description": "Write a C function to read and validate the header of a GD2 image file."}
{"func_name": "update_device", "func_src_before": "    def update_device(self, **kwargs):\n        \"\"\" See http://api.device42.com/#create/update-device-by-name \"\"\"\n        path = 'devices'\n        atleast_fields = \"name serial_no uuid\".split()\n        known_fields = \"new_name asset_no manufacturer hardware new_hardware is_it_switch\"\n        known_fields += \" is_it_virtual_host is_it_blade_host in_service type service_level virtual_host\"\n        known_fields += \" blade_host slot_no storage_room_id storage_room os osver osverno memory cpucount cpupower cpucore\"\n        known_fields += \" hddcount hddsize hddraid hddraid_type macaddress devices_in_cluster appcomps\"\n        known_fields += \" customer contract_id contract\"\n        known_fields += \" aliases subtype virtual_subtype notes tags\"\n        known_fields = atleast_fields + known_fields.split()\n        if not set(atleast_fields).intersection(kwargs.keys()):\n            raise Device42BadArgumentError(\"At least one parameter should be passed: %s\" % atleast_fields)\n        unknown_fields = set(kwargs.keys()) - set(known_fields)\n        if unknown_fields:\n            raise Device42BadArgumentError(\"Unknown parameters: %s\" % unknown_fields)\n        return self._post(path, data=kwargs)", "func_src_after": "    def update_device(self, **kwargs):\n        \"\"\" See http://api.device42.com/#create/update-device-by-name \"\"\"\n        path = 'devices'\n        atleast_fields = [\"name\"]  # this is the only required field to create/update a device, serial and uuid opt\n        known_fields = \"new_name asset_no manufacturer hardware new_hardware is_it_switch\"\n        known_fields += \" is_it_virtual_host is_it_blade_host in_service type service_level virtual_host\"\n        known_fields += \" serial_no uuid\"\n        known_fields += \" blade_host slot_no storage_room_id storage_room os osver osverno memory cpucount cpupower cpucore\"\n        known_fields += \" hddcount hddsize hddraid hddraid_type macaddress devices_in_cluster appcomps\"\n        known_fields += \" customer contract_id contract\"\n        known_fields += \" aliases subtype virtual_subtype notes tags\"\n        known_fields = atleast_fields + known_fields.split()\n        if not set(atleast_fields).intersection(kwargs.keys()):\n            raise Device42BadArgumentError(\"At least one parameter should be passed: %s\" % atleast_fields)\n        unknown_fields = set(kwargs.keys()) - set(known_fields)\n        if unknown_fields:\n            raise Device42BadArgumentError(\"Unknown parameters: %s\" % unknown_fields)\n        return self._post(path, data=kwargs)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 138, "char_end": 193, "line": "        atleast_fields = \"name serial_no uuid\".split()\n"}], "added": [{"line_no": 4, "char_start": 138, "char_end": 254, "line": "        atleast_fields = [\"name\"]  # this is the only required field to create/update a device, serial and uuid opt\n"}, {"line_no": 7, "char_start": 451, "char_end": 493, "line": "        known_fields += \" serial_no uuid\"\n"}]}, "char_changes": {"deleted": [{"char_start": 175, "char_end": 178, "chars": "_no"}, {"char_start": 183, "char_end": 192, "chars": "\".split()"}], "added": [{"char_start": 163, "char_end": 164, "chars": "["}, {"char_start": 169, "char_end": 233, "chars": "\"]  # this is the only required field to create/update a device,"}, {"char_start": 240, "char_end": 244, "chars": " and"}, {"char_start": 249, "char_end": 253, "chars": " opt"}, {"char_start": 451, "char_end": 493, "chars": "        known_fields += \" serial_no uuid\"\n"}]}, "commit_link": "github.com/device42/puppet_to_device42_sync_py/commit/b394ec75a10a60fd38ba203c2c43af16f76295cf", "file_name": "device42.py", "vul_type": "cwe-502", "commit_msg": "changed intersection to just look for name since it was allowing devices with no name to enter post, fixed yaml load warning by safe loading insted of deprecated method, debug message change", "parent_commit": "df122e3ff26252dccde61a10e8ccbee2b94909e2", "description": "Write a Python function to update a device's details using the Device42 API, handling required fields and validating known fields."}
{"func_name": "_inject_file_into_fs", "func_src_before": "def _inject_file_into_fs(fs, path, contents):\n    absolute_path = os.path.join(fs, path.lstrip('/'))\n    parent_dir = os.path.dirname(absolute_path)\n    utils.execute('mkdir', '-p', parent_dir, run_as_root=True)\n    utils.execute('tee', absolute_path, process_input=contents,\n          run_as_root=True)", "func_src_after": "def _inject_file_into_fs(fs, path, contents, append=False):\n    absolute_path = _join_and_check_path_within_fs(fs, path.lstrip('/'))\n\n    parent_dir = os.path.dirname(absolute_path)\n    utils.execute('mkdir', '-p', parent_dir, run_as_root=True)\n\n    args = []\n    if append:\n        args.append('-a')\n    args.append(absolute_path)\n\n    kwargs = dict(process_input=contents, run_as_root=True)\n\n    utils.execute('tee', *args, **kwargs)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to create or append contents to a file at a specified path within a virtual filesystem, ensuring the parent directories exist."}
{"func_name": "commentcounts", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': comment.text,\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': escape(comment.text),\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "commit_link": "github.com/reviewboard/reviewboard/commit/7a0a9d94555502278534dedcf2d75e9fccce8c3d", "file_name": "reviewboard/reviews/templatetags/reviewtags.py", "vul_type": "cwe-079", "description": "In Python, write a function that returns a JSON array of comments for a file difference, including metadata like comment ID, text, line number, and user details, sorted by line number."}
{"func_name": "exprListAppendList", "func_src_before": "static ExprList *exprListAppendList(\n  Parse *pParse,          /* Parsing context */\n  ExprList *pList,        /* List to which to append. Might be NULL */\n  ExprList *pAppend,      /* List of values to append. Might be NULL */\n  int bIntToNull\n){\n  if( pAppend ){\n    int i;\n    int nInit = pList ? pList->nExpr : 0;\n    for(i=0; i<pAppend->nExpr; i++){\n      Expr *pDup = sqlite3ExprDup(pParse->db, pAppend->a[i].pExpr, 0);\n      if( bIntToNull && pDup && pDup->op==TK_INTEGER ){\n        pDup->op = TK_NULL;\n        pDup->flags &= ~(EP_IntValue|EP_IsTrue|EP_IsFalse);\n      }\n      pList = sqlite3ExprListAppend(pParse, pList, pDup);\n      if( pList ) pList->a[nInit+i].sortFlags = pAppend->a[i].sortFlags;\n    }\n  }\n  return pList;\n}", "func_src_after": "static ExprList *exprListAppendList(\n  Parse *pParse,          /* Parsing context */\n  ExprList *pList,        /* List to which to append. Might be NULL */\n  ExprList *pAppend,      /* List of values to append. Might be NULL */\n  int bIntToNull\n){\n  if( pAppend ){\n    int i;\n    int nInit = pList ? pList->nExpr : 0;\n    for(i=0; i<pAppend->nExpr; i++){\n      Expr *pDup = sqlite3ExprDup(pParse->db, pAppend->a[i].pExpr, 0);\n      assert( pDup==0 || !ExprHasProperty(pDup, EP_MemToken) );\n      if( bIntToNull && pDup && pDup->op==TK_INTEGER ){\n        pDup->op = TK_NULL;\n        pDup->flags &= ~(EP_IntValue|EP_IsTrue|EP_IsFalse);\n        pDup->u.zToken = 0;\n      }\n      pList = sqlite3ExprListAppend(pParse, pList, pDup);\n      if( pList ) pList->a[nInit+i].sortFlags = pAppend->a[i].sortFlags;\n    }\n  }\n  return pList;\n}", "commit_link": "github.com/sqlite/sqlite/commit/75e95e1fcd52d3ec8282edb75ac8cd0814095d54", "file_name": "src/window.c", "vul_type": "cwe-476", "description": "Write a C function to append one expression list to another in SQLite, with an option to convert integers to NULL."}
{"func_name": "WriteHDRImage", "func_src_before": "static MagickBooleanType WriteHDRImage(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  char\n    header[MagickPathExtent];\n\n  const char\n    *property;\n\n  MagickBooleanType\n    status;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i,\n    x;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    pixel[4],\n    *pixels;\n\n  /*\n    Open output image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(status);\n  if (IsRGBColorspace(image->colorspace) == MagickFalse)\n    (void) TransformImageColorspace(image,RGBColorspace,exception);\n  /*\n    Write header.\n  */\n  (void) ResetMagickMemory(header,' ',MagickPathExtent);\n  length=CopyMagickString(header,\"#?RGBE\\n\",MagickPathExtent);\n  (void) WriteBlob(image,length,(unsigned char *) header);\n  property=GetImageProperty(image,\"comment\",exception);\n  if ((property != (const char *) NULL) &&\n      (strchr(property,'\\n') == (char *) NULL))\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"#%s\\n\",property);\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  property=GetImageProperty(image,\"hdr:exposure\",exception);\n  if (property != (const char *) NULL)\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"EXPOSURE=%g\\n\",\n        strtod(property,(char **) NULL));\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  if (image->gamma != 0.0)\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"GAMMA=%g\\n\",image->gamma);\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  count=FormatLocaleString(header,MagickPathExtent,\n    \"PRIMARIES=%g %g %g %g %g %g %g %g\\n\",\n    image->chromaticity.red_primary.x,image->chromaticity.red_primary.y,\n    image->chromaticity.green_primary.x,image->chromaticity.green_primary.y,\n    image->chromaticity.blue_primary.x,image->chromaticity.blue_primary.y,\n    image->chromaticity.white_point.x,image->chromaticity.white_point.y);\n  (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n  length=CopyMagickString(header,\"FORMAT=32-bit_rle_rgbe\\n\\n\",MagickPathExtent);\n  (void) WriteBlob(image,length,(unsigned char *) header);\n  count=FormatLocaleString(header,MagickPathExtent,\"-Y %.20g +X %.20g\\n\",\n    (double) image->rows,(double) image->columns);\n  (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n  /*\n    Write HDR pixels.\n  */\n  pixels=(unsigned char *) AcquireQuantumMemory(image->columns,4*\n    sizeof(*pixels));\n  if (pixels == (unsigned char *) NULL)\n    ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n      {\n        pixel[0]=2;\n        pixel[1]=2;\n        pixel[2]=(unsigned char) (image->columns >> 8);\n        pixel[3]=(unsigned char) (image->columns & 0xff);\n        count=WriteBlob(image,4*sizeof(*pixel),pixel);\n        if (count != (ssize_t) (4*sizeof(*pixel)))\n          break;\n      }\n    i=0;\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      double\n        gamma;\n\n      pixel[0]=0;\n      pixel[1]=0;\n      pixel[2]=0;\n      pixel[3]=0;\n      gamma=QuantumScale*GetPixelRed(image,p);\n      if ((QuantumScale*GetPixelGreen(image,p)) > gamma)\n        gamma=QuantumScale*GetPixelGreen(image,p);\n      if ((QuantumScale*GetPixelBlue(image,p)) > gamma)\n        gamma=QuantumScale*GetPixelBlue(image,p);\n      if (gamma > MagickEpsilon)\n        {\n          int\n            exponent;\n\n          gamma=frexp(gamma,&exponent)*256.0/gamma;\n          pixel[0]=(unsigned char) (gamma*QuantumScale*GetPixelRed(image,p));\n          pixel[1]=(unsigned char) (gamma*QuantumScale*GetPixelGreen(image,p));\n          pixel[2]=(unsigned char) (gamma*QuantumScale*GetPixelBlue(image,p));\n          pixel[3]=(unsigned char) (exponent+128);\n        }\n      if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n        {\n          pixels[x]=pixel[0];\n          pixels[x+image->columns]=pixel[1];\n          pixels[x+2*image->columns]=pixel[2];\n          pixels[x+3*image->columns]=pixel[3];\n        }\n      else\n        {\n          pixels[i++]=pixel[0];\n          pixels[i++]=pixel[1];\n          pixels[i++]=pixel[2];\n          pixels[i++]=pixel[3];\n        }\n      p+=GetPixelChannels(image);\n    }\n    if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n      {\n        for (i=0; i < 4; i++)\n          length=HDRWriteRunlengthPixels(image,&pixels[i*image->columns]);\n      }\n    else\n      {\n        count=WriteBlob(image,4*image->columns*sizeof(*pixels),pixels);\n        if (count != (ssize_t) (4*image->columns*sizeof(*pixels)))\n          break;\n      }\n    status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n      image->rows);\n    if (status == MagickFalse)\n      break;\n  }\n  pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n  (void) CloseBlob(image);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType WriteHDRImage(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  char\n    header[MagickPathExtent];\n\n  const char\n    *property;\n\n  MagickBooleanType\n    status;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i,\n    x;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    pixel[4],\n    *pixels;\n\n  /*\n    Open output image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(status);\n  if (IsRGBColorspace(image->colorspace) == MagickFalse)\n    (void) TransformImageColorspace(image,RGBColorspace,exception);\n  /*\n    Write header.\n  */\n  (void) ResetMagickMemory(header,' ',MagickPathExtent);\n  length=CopyMagickString(header,\"#?RGBE\\n\",MagickPathExtent);\n  (void) WriteBlob(image,length,(unsigned char *) header);\n  property=GetImageProperty(image,\"comment\",exception);\n  if ((property != (const char *) NULL) &&\n      (strchr(property,'\\n') == (char *) NULL))\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"#%s\\n\",property);\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  property=GetImageProperty(image,\"hdr:exposure\",exception);\n  if (property != (const char *) NULL)\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"EXPOSURE=%g\\n\",\n        strtod(property,(char **) NULL));\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  if (image->gamma != 0.0)\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"GAMMA=%g\\n\",\n        image->gamma);\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  count=FormatLocaleString(header,MagickPathExtent,\n    \"PRIMARIES=%g %g %g %g %g %g %g %g\\n\",\n    image->chromaticity.red_primary.x,image->chromaticity.red_primary.y,\n    image->chromaticity.green_primary.x,image->chromaticity.green_primary.y,\n    image->chromaticity.blue_primary.x,image->chromaticity.blue_primary.y,\n    image->chromaticity.white_point.x,image->chromaticity.white_point.y);\n  (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n  length=CopyMagickString(header,\"FORMAT=32-bit_rle_rgbe\\n\\n\",MagickPathExtent);\n  (void) WriteBlob(image,length,(unsigned char *) header);\n  count=FormatLocaleString(header,MagickPathExtent,\"-Y %.20g +X %.20g\\n\",\n    (double) image->rows,(double) image->columns);\n  (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n  /*\n    Write HDR pixels.\n  */\n  pixels=(unsigned char *) AcquireQuantumMemory(image->columns+128,4*\n    sizeof(*pixels));\n  if (pixels == (unsigned char *) NULL)\n    ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n  (void) ResetMagickMemory(pixels,0,4*(image->columns+128)*sizeof(*pixels));\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n      {\n        pixel[0]=2;\n        pixel[1]=2;\n        pixel[2]=(unsigned char) (image->columns >> 8);\n        pixel[3]=(unsigned char) (image->columns & 0xff);\n        count=WriteBlob(image,4*sizeof(*pixel),pixel);\n        if (count != (ssize_t) (4*sizeof(*pixel)))\n          break;\n      }\n    i=0;\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      double\n        gamma;\n\n      pixel[0]=0;\n      pixel[1]=0;\n      pixel[2]=0;\n      pixel[3]=0;\n      gamma=QuantumScale*GetPixelRed(image,p);\n      if ((QuantumScale*GetPixelGreen(image,p)) > gamma)\n        gamma=QuantumScale*GetPixelGreen(image,p);\n      if ((QuantumScale*GetPixelBlue(image,p)) > gamma)\n        gamma=QuantumScale*GetPixelBlue(image,p);\n      if (gamma > MagickEpsilon)\n        {\n          int\n            exponent;\n\n          gamma=frexp(gamma,&exponent)*256.0/gamma;\n          pixel[0]=(unsigned char) (gamma*QuantumScale*GetPixelRed(image,p));\n          pixel[1]=(unsigned char) (gamma*QuantumScale*GetPixelGreen(image,p));\n          pixel[2]=(unsigned char) (gamma*QuantumScale*GetPixelBlue(image,p));\n          pixel[3]=(unsigned char) (exponent+128);\n        }\n      if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n        {\n          pixels[x]=pixel[0];\n          pixels[x+image->columns]=pixel[1];\n          pixels[x+2*image->columns]=pixel[2];\n          pixels[x+3*image->columns]=pixel[3];\n        }\n      else\n        {\n          pixels[i++]=pixel[0];\n          pixels[i++]=pixel[1];\n          pixels[i++]=pixel[2];\n          pixels[i++]=pixel[3];\n        }\n      p+=GetPixelChannels(image);\n    }\n    if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n      {\n        for (i=0; i < 4; i++)\n          length=HDRWriteRunlengthPixels(image,&pixels[i*image->columns]);\n      }\n    else\n      {\n        count=WriteBlob(image,4*image->columns*sizeof(*pixels),pixels);\n        if (count != (ssize_t) (4*image->columns*sizeof(*pixels)))\n          break;\n      }\n    status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n      image->rows);\n    if (status == MagickFalse)\n      break;\n  }\n  pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n  (void) CloseBlob(image);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/14e606db148d6ebcaae20f1e1d6d71903ca4a556", "file_name": "coders/hdr.c", "vul_type": "cwe-125", "description": "Write a C function to output an HDR image file using ImageMagick's API."}
{"func_name": "mem_check_range", "func_src_before": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\treturn ((iova < mem->iova) ||\n\t\t\t((iova + length) > (mem->iova + mem->length))) ?\n\t\t\t-EFAULT : 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "func_src_after": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\tif (iova < mem->iova ||\n\t\t    length > mem->length ||\n\t\t    iova > mem->iova + mem->length - length)\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/647bf3d8a8e5777319da92af672289b2a6c4dc66", "file_name": "drivers/infiniband/sw/rxe/rxe_mr.c", "vul_type": "cwe-190", "description": "Write a C function named `mem_check_range` that checks if a memory range specified by `iova` and `length` is valid within a memory region `mem`, returning 0 for valid or `-EFAULT` for invalid."}
{"func_name": "store_metadata", "func_src_before": "    def store_metadata(self, session, key, mType, value):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"UPDATE %s SET %s = %r WHERE identifier = '%s';\" %\n                 (self.table, mType, value, id)\n                 )\n        try:\n            self._query(query)\n        except:\n            return None\n        return value", "func_src_after": "    def store_metadata(self, session, key, mType, value):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"UPDATE %s SET %s = $1 WHERE identifier = $2;\" %\n                 (self.table, mType)\n                 )\n        args = (value, id)\n        try:\n            self._query(query, *args)\n        except:\n            return None\n        return value", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089", "description": "Write a Python function to update a database record's metadata field identified by a key, handling string normalization and query execution."}
{"func_name": "get_view", "func_src_before": "  def get_view(db, options = {}, fetch_data = false)\n    if !fetch_data && @report_data_additional_options.nil?\n      process_show_list_options(options, db)\n    end\n    unless @edit.nil?\n      object_ids = @edit[:object_ids] unless @edit[:object_ids].nil?\n      object_ids = @edit[:pol_items] unless @edit[:pol_items].nil?\n    end\n    object_ids   = params[:records].map(&:to_i) unless params[:records].nil?\n    db           = db.to_s\n    dbname       = options[:dbname] || db.gsub('::', '_').downcase # Get db name as text\n    db_sym       = (options[:gtl_dbname] || dbname).to_sym # Get db name as symbol\n    refresh_view = false\n\n    # Determine if the view should be refreshed or use the existing view\n    unless session[:view] && # A view exists and\n           session[:view].db.downcase == dbname && # the DB matches and\n           params[:refresh] != \"y\" && # refresh not being forced and\n           (\n             params[:ppsetting] || params[:page] || # changed paging or\n             params[:type]                          # gtl type\n           )\n      refresh_view = true\n      # Creating a new view, remember if came from a menu_click\n      session[:menu_click] = params[:menu_click] || options[:menu_click]\n      session[:bc]         = params[:bc] # Remember incoming breadcrumb as well\n    end\n\n    # Build the advanced search @edit hash\n    if (@explorer && !@in_a_form && !%w(adv_search_clear tree_select).include?(action_name)) ||\n       (action_name == \"show_list\" && !session[:menu_click])\n      adv_search_build(db)\n    end\n    if @edit && !@edit[:selected] && !@edit[:tagging] && # Load default search if search @edit hash exists\n       settings(:default_search, db.to_sym) # and item in listnav not selected\n      load_default_search(settings(:default_search, db.to_sym))\n    end\n\n    parent      = options[:parent] || nil             # Get passed in parent object\n    @parent     = parent unless parent.nil?           # Save the parent object for the views to use\n    association = options[:association] || nil        # Get passed in association (i.e. \"users\")\n    view_suffix = options[:view_suffix] || nil        # Get passed in view_suffix (i.e. \"VmReconfigureRequest\")\n\n    # Build sorting keys - Use association name, if available, else dbname\n    # need to add check for miqreportresult, need to use different sort in savedreports/report tree for saved reports list\n    sort_prefix = association || (dbname == \"miqreportresult\" && x_active_tree ? x_active_tree.to_s : dbname)\n    sortcol_sym = \"#{sort_prefix}_sortcol\".to_sym\n    sortdir_sym = \"#{sort_prefix}_sortdir\".to_sym\n\n    # Set up the list view type (grid/tile/list)\n    @settings.store_path(:views, db_sym, params[:type]) if params[:type] # Change the list view type, if it's sent in\n\n    @gtl_type = get_view_calculate_gtl_type(db_sym) unless fetch_data\n\n    # Get the view for this db or use the existing one in the session\n    view =\n      if options['report_name']\n        path_to_report = ManageIQ::UI::Classic::Engine.root.join(\"product\", \"views\", options['report_name']).to_s\n        MiqReport.new(YAML.load(File.open(path_to_report)))\n      else\n        refresh_view ? get_db_view(db.gsub('::', '_'), :association => association, :view_suffix => view_suffix) : session[:view]\n      end\n\n    # Check for changed settings in params\n    if params[:ppsetting] # User selected new per page value\n      @settings.store_path(:perpage, perpage_key(dbname), params[:ppsetting].to_i)\n    end\n\n    if params[:sortby] # New sort order (by = col click, choice = pull down)\n      params[:sortby]      = params[:sortby].to_i - 1\n      params[:sort_choice] = view.headers[params[:sortby]]\n    elsif params[:sort_choice] # If user chose new sortcol, set sortby parm\n      params[:sortby]      = view.headers.index(params[:sort_choice])\n    end\n\n    # Get the current sort info, else get defaults from the view\n    @sortcol = session[sortcol_sym].try(:to_i) || view.sort_col\n    @sortdir = session[sortdir_sym] || (view.ascending? ? \"ASC\" : \"DESC\")\n\n    # Set/reset the sortby column and order\n    get_sort_col                                  # set the sort column and direction\n    session[sortcol_sym] = @sortcol               # Save the new sort values\n    session[sortdir_sym] = @sortdir\n    view.sortby = [view.col_order[@sortcol]]      # Set sortby array in the view\n    view.ascending = @sortdir.to_s.downcase != \"desc\"\n\n    @items_per_page = controller_name.downcase == \"miq_policy\" ? ONE_MILLION : get_view_pages_perpage(dbname)\n    @items_per_page = ONE_MILLION if db_sym.to_s == 'vm' && controller_name == 'service'\n\n    @current_page = options[:page] || (params[:page].to_i < 1 ? 1 : params[:page].to_i)\n\n    view.conditions = options[:conditions] # Get passed in conditions (i.e. tasks date filters)\n\n    # Save the paged_view_search_options for download buttons to use later\n    session[:paged_view_search_options] = {\n      :parent                    => parent ? minify_ar_object(parent) : nil,\n      :parent_method             => options[:parent_method],\n      :targets_hash              => true,\n      :association               => association,\n      :filter                    => get_view_filter(options[:filter]),\n      :sub_filter                => get_view_process_search_text(view),\n      :supported_features_filter => options[:supported_features_filter],\n      :page                      => options[:all_pages] ? 1 : @current_page,\n      :per_page                  => options[:all_pages] ? ONE_MILLION : @items_per_page,\n      :where_clause              => get_chart_where_clause(options[:sb_controller]),\n      :named_scope               => options[:named_scope],\n      :display_filter_hash       => options[:display_filter_hash],\n      :userid                    => session[:userid],\n      :selected_ids              => object_ids,\n      :match_via_descendants     => options[:match_via_descendants]\n    }\n\n    view.table, attrs = if fetch_data\n                          # Call paged_view_search to fetch records and build the view.table and additional attrs\n                          view.paged_view_search(session[:paged_view_search_options])\n                        else\n                          [{}, {}]\n                        end", "func_src_after": "  def get_view(db, options = {}, fetch_data = false)\n    if !fetch_data && @report_data_additional_options.nil?\n      process_show_list_options(options, db)\n    end\n    unless @edit.nil?\n      object_ids = @edit[:object_ids] unless @edit[:object_ids].nil?\n      object_ids = @edit[:pol_items] unless @edit[:pol_items].nil?\n    end\n    object_ids   = params[:records].map(&:to_i) unless params[:records].nil?\n    db           = db.to_s\n    dbname       = options[:dbname] || db.gsub('::', '_').downcase # Get db name as text\n    db_sym       = (options[:gtl_dbname] || dbname).to_sym # Get db name as symbol\n    refresh_view = false\n\n    # Determine if the view should be refreshed or use the existing view\n    unless session[:view] && # A view exists and\n           session[:view].db.downcase == dbname && # the DB matches and\n           params[:refresh] != \"y\" && # refresh not being forced and\n           (\n             params[:ppsetting] || params[:page] || # changed paging or\n             params[:type]                          # gtl type\n           )\n      refresh_view = true\n      # Creating a new view, remember if came from a menu_click\n      session[:menu_click] = params[:menu_click] || options[:menu_click]\n      session[:bc]         = params[:bc] # Remember incoming breadcrumb as well\n    end\n\n    # Build the advanced search @edit hash\n    if (@explorer && !@in_a_form && !%w(adv_search_clear tree_select).include?(action_name)) ||\n       (action_name == \"show_list\" && !session[:menu_click])\n      adv_search_build(db)\n    end\n    if @edit && !@edit[:selected] && !@edit[:tagging] && # Load default search if search @edit hash exists\n       settings(:default_search, db.to_sym) # and item in listnav not selected\n      load_default_search(settings(:default_search, db.to_sym))\n    end\n\n    parent      = options[:parent] || nil             # Get passed in parent object\n    @parent     = parent unless parent.nil?           # Save the parent object for the views to use\n    association = options[:association] || nil        # Get passed in association (i.e. \"users\")\n    view_suffix = options[:view_suffix] || nil        # Get passed in view_suffix (i.e. \"VmReconfigureRequest\")\n\n    # Build sorting keys - Use association name, if available, else dbname\n    # need to add check for miqreportresult, need to use different sort in savedreports/report tree for saved reports list\n    sort_prefix = association || (dbname == \"miqreportresult\" && x_active_tree ? x_active_tree.to_s : dbname)\n    sortcol_sym = \"#{sort_prefix}_sortcol\".to_sym\n    sortdir_sym = \"#{sort_prefix}_sortdir\".to_sym\n\n    # Set up the list view type (grid/tile/list)\n    @settings.store_path(:views, db_sym, params[:type]) if params[:type] # Change the list view type, if it's sent in\n\n    @gtl_type = get_view_calculate_gtl_type(db_sym) unless fetch_data\n\n    # Get the view for this db or use the existing one in the session\n    view =\n      if options['report_name']\n        path_to_report = ManageIQ::UI::Classic::Engine.root.join(\"product\", \"views\", options['report_name']).to_s\n        MiqReport.new(YAML.safe_load(File.open(path_to_report), [Symbol]))\n      else\n        refresh_view ? get_db_view(db.gsub('::', '_'), :association => association, :view_suffix => view_suffix) : session[:view]\n      end\n\n    # Check for changed settings in params\n    if params[:ppsetting] # User selected new per page value\n      @settings.store_path(:perpage, perpage_key(dbname), params[:ppsetting].to_i)\n    end\n\n    if params[:sortby] # New sort order (by = col click, choice = pull down)\n      params[:sortby]      = params[:sortby].to_i - 1\n      params[:sort_choice] = view.headers[params[:sortby]]\n    elsif params[:sort_choice] # If user chose new sortcol, set sortby parm\n      params[:sortby]      = view.headers.index(params[:sort_choice])\n    end\n\n    # Get the current sort info, else get defaults from the view\n    @sortcol = session[sortcol_sym].try(:to_i) || view.sort_col\n    @sortdir = session[sortdir_sym] || (view.ascending? ? \"ASC\" : \"DESC\")\n\n    # Set/reset the sortby column and order\n    get_sort_col                                  # set the sort column and direction\n    session[sortcol_sym] = @sortcol               # Save the new sort values\n    session[sortdir_sym] = @sortdir\n    view.sortby = [view.col_order[@sortcol]]      # Set sortby array in the view\n    view.ascending = @sortdir.to_s.downcase != \"desc\"\n\n    @items_per_page = controller_name.downcase == \"miq_policy\" ? ONE_MILLION : get_view_pages_perpage(dbname)\n    @items_per_page = ONE_MILLION if db_sym.to_s == 'vm' && controller_name == 'service'\n\n    @current_page = options[:page] || (params[:page].to_i < 1 ? 1 : params[:page].to_i)\n\n    view.conditions = options[:conditions] # Get passed in conditions (i.e. tasks date filters)\n\n    # Save the paged_view_search_options for download buttons to use later\n    session[:paged_view_search_options] = {\n      :parent                    => parent ? minify_ar_object(parent) : nil,\n      :parent_method             => options[:parent_method],\n      :targets_hash              => true,\n      :association               => association,\n      :filter                    => get_view_filter(options[:filter]),\n      :sub_filter                => get_view_process_search_text(view),\n      :supported_features_filter => options[:supported_features_filter],\n      :page                      => options[:all_pages] ? 1 : @current_page,\n      :per_page                  => options[:all_pages] ? ONE_MILLION : @items_per_page,\n      :where_clause              => get_chart_where_clause(options[:sb_controller]),\n      :named_scope               => options[:named_scope],\n      :display_filter_hash       => options[:display_filter_hash],\n      :userid                    => session[:userid],\n      :selected_ids              => object_ids,\n      :match_via_descendants     => options[:match_via_descendants]\n    }\n\n    view.table, attrs = if fetch_data\n                          # Call paged_view_search to fetch records and build the view.table and additional attrs\n                          view.paged_view_search(session[:paged_view_search_options])\n                        else\n                          [{}, {}]\n                        end", "line_changes": {"deleted": [{"line_no": 59, "char_start": 3072, "char_end": 3132, "line": "        MiqReport.new(YAML.load(File.open(path_to_report)))\n"}], "added": [{"line_no": 59, "char_start": 3072, "char_end": 3147, "line": "        MiqReport.new(YAML.safe_load(File.open(path_to_report), [Symbol]))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 3099, "char_end": 3104, "chars": "safe_"}, {"char_start": 3134, "char_end": 3144, "chars": ", [Symbol]"}]}, "commit_link": "github.com/ManageIQ/manageiq-ui-classic/commit/b199ca1d7b5049ee4c0bd8323ea3977bf3de3341", "file_name": "application_controller.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load instead of YAML.load", "parent_commit": "cf54d8a126322759948bcf196e99a1a4399c62d0", "description": "Write a Ruby method named `get_view` that handles database view rendering with optional parameters and data fetching."}
{"func_name": "xfs_attr_shortform_to_leaf", "func_src_before": "xfs_attr_shortform_to_leaf(\n\tstruct xfs_da_args\t*args,\n\tstruct xfs_buf\t\t**leaf_bp)\n{\n\txfs_inode_t *dp;\n\txfs_attr_shortform_t *sf;\n\txfs_attr_sf_entry_t *sfe;\n\txfs_da_args_t nargs;\n\tchar *tmpbuffer;\n\tint error, i, size;\n\txfs_dablk_t blkno;\n\tstruct xfs_buf *bp;\n\txfs_ifork_t *ifp;\n\n\ttrace_xfs_attr_sf_to_leaf(args);\n\n\tdp = args->dp;\n\tifp = dp->i_afp;\n\tsf = (xfs_attr_shortform_t *)ifp->if_u1.if_data;\n\tsize = be16_to_cpu(sf->hdr.totsize);\n\ttmpbuffer = kmem_alloc(size, KM_SLEEP);\n\tASSERT(tmpbuffer != NULL);\n\tmemcpy(tmpbuffer, ifp->if_u1.if_data, size);\n\tsf = (xfs_attr_shortform_t *)tmpbuffer;\n\n\txfs_idata_realloc(dp, -size, XFS_ATTR_FORK);\n\txfs_bmap_local_to_extents_empty(dp, XFS_ATTR_FORK);\n\n\tbp = NULL;\n\terror = xfs_da_grow_inode(args, &blkno);\n\tif (error) {\n\t\t/*\n\t\t * If we hit an IO error middle of the transaction inside\n\t\t * grow_inode(), we may have inconsistent data. Bail out.\n\t\t */\n\t\tif (error == -EIO)\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tASSERT(blkno == 0);\n\terror = xfs_attr3_leaf_create(args, blkno, &bp);\n\tif (error) {\n\t\terror = xfs_da_shrink_inode(args, 0, bp);\n\t\tbp = NULL;\n\t\tif (error)\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tmemset((char *)&nargs, 0, sizeof(nargs));\n\tnargs.dp = dp;\n\tnargs.geo = args->geo;\n\tnargs.firstblock = args->firstblock;\n\tnargs.dfops = args->dfops;\n\tnargs.total = args->total;\n\tnargs.whichfork = XFS_ATTR_FORK;\n\tnargs.trans = args->trans;\n\tnargs.op_flags = XFS_DA_OP_OKNOENT;\n\n\tsfe = &sf->list[0];\n\tfor (i = 0; i < sf->hdr.count; i++) {\n\t\tnargs.name = sfe->nameval;\n\t\tnargs.namelen = sfe->namelen;\n\t\tnargs.value = &sfe->nameval[nargs.namelen];\n\t\tnargs.valuelen = sfe->valuelen;\n\t\tnargs.hashval = xfs_da_hashname(sfe->nameval,\n\t\t\t\t\t\tsfe->namelen);\n\t\tnargs.flags = XFS_ATTR_NSP_ONDISK_TO_ARGS(sfe->flags);\n\t\terror = xfs_attr3_leaf_lookup_int(bp, &nargs); /* set a->index */\n\t\tASSERT(error == -ENOATTR);\n\t\terror = xfs_attr3_leaf_add(bp, &nargs);\n\t\tASSERT(error != -ENOSPC);\n\t\tif (error)\n\t\t\tgoto out;\n\t\tsfe = XFS_ATTR_SF_NEXTENTRY(sfe);\n\t}\n\terror = 0;\n\t*leaf_bp = bp;\nout:\n\tkmem_free(tmpbuffer);\n\treturn error;\n}", "func_src_after": "xfs_attr_shortform_to_leaf(\n\tstruct xfs_da_args\t*args,\n\tstruct xfs_buf\t\t**leaf_bp)\n{\n\txfs_inode_t *dp;\n\txfs_attr_shortform_t *sf;\n\txfs_attr_sf_entry_t *sfe;\n\txfs_da_args_t nargs;\n\tchar *tmpbuffer;\n\tint error, i, size;\n\txfs_dablk_t blkno;\n\tstruct xfs_buf *bp;\n\txfs_ifork_t *ifp;\n\n\ttrace_xfs_attr_sf_to_leaf(args);\n\n\tdp = args->dp;\n\tifp = dp->i_afp;\n\tsf = (xfs_attr_shortform_t *)ifp->if_u1.if_data;\n\tsize = be16_to_cpu(sf->hdr.totsize);\n\ttmpbuffer = kmem_alloc(size, KM_SLEEP);\n\tASSERT(tmpbuffer != NULL);\n\tmemcpy(tmpbuffer, ifp->if_u1.if_data, size);\n\tsf = (xfs_attr_shortform_t *)tmpbuffer;\n\n\txfs_idata_realloc(dp, -size, XFS_ATTR_FORK);\n\txfs_bmap_local_to_extents_empty(dp, XFS_ATTR_FORK);\n\n\tbp = NULL;\n\terror = xfs_da_grow_inode(args, &blkno);\n\tif (error) {\n\t\t/*\n\t\t * If we hit an IO error middle of the transaction inside\n\t\t * grow_inode(), we may have inconsistent data. Bail out.\n\t\t */\n\t\tif (error == -EIO)\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tASSERT(blkno == 0);\n\terror = xfs_attr3_leaf_create(args, blkno, &bp);\n\tif (error) {\n\t\t/* xfs_attr3_leaf_create may not have instantiated a block */\n\t\tif (bp && (xfs_da_shrink_inode(args, 0, bp) != 0))\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tmemset((char *)&nargs, 0, sizeof(nargs));\n\tnargs.dp = dp;\n\tnargs.geo = args->geo;\n\tnargs.firstblock = args->firstblock;\n\tnargs.dfops = args->dfops;\n\tnargs.total = args->total;\n\tnargs.whichfork = XFS_ATTR_FORK;\n\tnargs.trans = args->trans;\n\tnargs.op_flags = XFS_DA_OP_OKNOENT;\n\n\tsfe = &sf->list[0];\n\tfor (i = 0; i < sf->hdr.count; i++) {\n\t\tnargs.name = sfe->nameval;\n\t\tnargs.namelen = sfe->namelen;\n\t\tnargs.value = &sfe->nameval[nargs.namelen];\n\t\tnargs.valuelen = sfe->valuelen;\n\t\tnargs.hashval = xfs_da_hashname(sfe->nameval,\n\t\t\t\t\t\tsfe->namelen);\n\t\tnargs.flags = XFS_ATTR_NSP_ONDISK_TO_ARGS(sfe->flags);\n\t\terror = xfs_attr3_leaf_lookup_int(bp, &nargs); /* set a->index */\n\t\tASSERT(error == -ENOATTR);\n\t\terror = xfs_attr3_leaf_add(bp, &nargs);\n\t\tASSERT(error != -ENOSPC);\n\t\tif (error)\n\t\t\tgoto out;\n\t\tsfe = XFS_ATTR_SF_NEXTENTRY(sfe);\n\t}\n\terror = 0;\n\t*leaf_bp = bp;\nout:\n\tkmem_free(tmpbuffer);\n\treturn error;\n}", "commit_link": "github.com/torvalds/linux/commit/bb3d48dcf86a97dc25fe9fc2c11938e19cb4399a", "file_name": "fs/xfs/libxfs/xfs_attr_leaf.c", "vul_type": "cwe-476", "description": "Write a C function named `xfs_attr_shortform_to_leaf` that converts short-form attributes to leaf-form in the XFS filesystem."}
{"func_name": "r_bin_java_line_number_table_attr_new", "func_src_before": "R_API RBinJavaAttrInfo *r_bin_java_line_number_table_attr_new(ut8 *buffer, ut64 sz, ut64 buf_offset) {\n\tut32 i = 0;\n\tut64 curpos, offset = 0;\n\tRBinJavaLineNumberAttribute *lnattr;\n\tRBinJavaAttrInfo *attr = r_bin_java_default_attr_new (buffer, sz, buf_offset);\n\tif (!attr) {\n\t\treturn NULL;\n\t}\n\toffset += 6;\n\tattr->type = R_BIN_JAVA_ATTR_TYPE_LINE_NUMBER_TABLE_ATTR;\n\tattr->info.line_number_table_attr.line_number_table_length = R_BIN_JAVA_USHORT (buffer, offset);\n\toffset += 2;\n\tattr->info.line_number_table_attr.line_number_table = r_list_newf (free);\n\n\tut32 linenum_len = attr->info.line_number_table_attr.line_number_table_length;\n\tRList *linenum_list = attr->info.line_number_table_attr.line_number_table;\n\tif (linenum_len > sz) {\n\t\tfree (attr);\n\t\treturn NULL;\n\t}\n\tfor (i = 0; i < linenum_len; i++) {\n\t\tcurpos = buf_offset + offset;\n\t\t// printf (\"%llx %llx \\n\", curpos, sz);\n\t\t// XXX if (curpos + 8 >= sz) break;\n\t\tlnattr = R_NEW0 (RBinJavaLineNumberAttribute);\n\t\tif (!lnattr) {\n\t\t\tbreak;\n\t\t}\n\t\tlnattr->start_pc = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->line_number = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->file_offset = curpos;\n\t\tlnattr->size = 4;\n\t\tr_list_append (linenum_list, lnattr);\n\t}\n\tattr->size = offset;\n\treturn attr;\n}", "func_src_after": "R_API RBinJavaAttrInfo *r_bin_java_line_number_table_attr_new(ut8 *buffer, ut64 sz, ut64 buf_offset) {\n\tut32 i = 0;\n\tut64 curpos, offset = 0;\n\tRBinJavaLineNumberAttribute *lnattr;\n\tRBinJavaAttrInfo *attr = r_bin_java_default_attr_new (buffer, sz, buf_offset);\n\tif (!attr) {\n\t\treturn NULL;\n\t}\n\toffset += 6;\n\tattr->type = R_BIN_JAVA_ATTR_TYPE_LINE_NUMBER_TABLE_ATTR;\n\tattr->info.line_number_table_attr.line_number_table_length = R_BIN_JAVA_USHORT (buffer, offset);\n\toffset += 2;\n\tattr->info.line_number_table_attr.line_number_table = r_list_newf (free);\n\n\tut32 linenum_len = attr->info.line_number_table_attr.line_number_table_length;\n\tRList *linenum_list = attr->info.line_number_table_attr.line_number_table;\n\tif (linenum_len > sz) {\n\t\tfree (attr);\n\t\treturn NULL;\n\t}\n\tfor (i = 0; i < linenum_len; i++) {\n\t\tcurpos = buf_offset + offset;\n\t\t// printf (\"%llx %llx \\n\", curpos, sz);\n\t\t// XXX if (curpos + 8 >= sz) break;\n\t\tlnattr = R_NEW0 (RBinJavaLineNumberAttribute);\n\t\tif (!lnattr) {\n\t\t\tbreak;\n\t\t}\n\t\tif (offset + 8 >= sz) {\n\t\t\tbreak;\n\t\t}\n\t\tlnattr->start_pc = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->line_number = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->file_offset = curpos;\n\t\tlnattr->size = 4;\n\t\tr_list_append (linenum_list, lnattr);\n\t}\n\tattr->size = offset;\n\treturn attr;\n}", "commit_link": "github.com/radare/radare2/commit/eb0fb72b3c5307ec8e33effb6bf947e38cfdffe8", "file_name": "shlr/java/class.c", "vul_type": "cwe-125", "description": "In C, write a function to create a new Java line number table attribute from a binary buffer."}
{"func_name": "add_article_action", "func_src_before": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = request.POST[\"notes\"]\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "func_src_after": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = escape(request.POST[\"notes\"])\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = escape(str(request.POST[str(\"notes_\" + str(art.id))]))\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/reservation_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle adding single or multiple articles to a reservation, with redirection and error handling."}
{"func_name": "DecompressRTF", "func_src_before": "BYTE *DecompressRTF(variableLength *p, int *size) {\n  BYTE *dst; // destination for uncompressed bytes\n  BYTE *src;\n  unsigned int in;\n  unsigned int out;\n  variableLength comp_Prebuf;\n  ULONG compressedSize, uncompressedSize, magic;\n\n  comp_Prebuf.size = strlen(RTF_PREBUF);\n  comp_Prebuf.data = calloc(comp_Prebuf.size+1, 1);\n  ALLOCCHECK_CHAR(comp_Prebuf.data);\n  memcpy(comp_Prebuf.data, RTF_PREBUF, comp_Prebuf.size);\n\n  src = p->data;\n  in = 0;\n\n  if (p->size < 20) {\n    printf(\"File too small\\n\");\n    return(NULL);\n  }\n  compressedSize = (ULONG)SwapDWord((BYTE*)src + in, 4);\n  in += 4;\n  uncompressedSize = (ULONG)SwapDWord((BYTE*)src + in, 4);\n  in += 4;\n  magic = SwapDWord((BYTE*)src + in, 4);\n  in += 4;\n  in += 4;\n\n  // check size excluding the size field itself\n  if (compressedSize != p->size - 4) {\n    printf(\" Size Mismatch: %u != %i\\n\", compressedSize, p->size - 4);\n    free(comp_Prebuf.data);\n    return NULL;\n  }\n\n  // process the data\n  if (magic == 0x414c454d) {\n    // magic number that identifies the stream as a uncompressed stream\n    dst = calloc(uncompressedSize, 1);\n    ALLOCCHECK_CHAR(dst);\n    memcpy(dst, src + 4, uncompressedSize);\n  } else if (magic == 0x75465a4c) {\n    // magic number that identifies the stream as a compressed stream\n    int flagCount = 0;\n    int flags = 0;\n    // Prevent overflow on 32 Bit Systems\n    if (comp_Prebuf.size >= INT_MAX - uncompressedSize) {\n       printf(\"Corrupted file\\n\");\n       exit(-1);\n    }\n    dst = calloc(comp_Prebuf.size + uncompressedSize, 1);\n    ALLOCCHECK_CHAR(dst);\n    memcpy(dst, comp_Prebuf.data, comp_Prebuf.size);\n    out = comp_Prebuf.size;\n    while (out < (comp_Prebuf.size + uncompressedSize)) {\n      // each flag byte flags 8 literals/references, 1 per bit\n      flags = (flagCount++ % 8 == 0) ? src[in++] : flags >> 1;\n      if ((flags & 1) == 1) { // each flag bit is 1 for reference, 0 for literal\n        unsigned int offset = src[in++];\n        unsigned int length = src[in++];\n        unsigned int end;\n        offset = (offset << 4) | (length >> 4); // the offset relative to block start\n        length = (length & 0xF) + 2; // the number of bytes to copy\n        // the decompression buffer is supposed to wrap around back\n        // to the beginning when the end is reached. we save the\n        // need for such a buffer by pointing straight into the data\n        // buffer, and simulating this behaviour by modifying the\n        // pointers appropriately.\n        offset = (out / 4096) * 4096 + offset;\n        if (offset >= out) // take from previous block\n          offset -= 4096;\n        // note: can't use System.arraycopy, because the referenced\n        // bytes can cross through the current out position.\n        end = offset + length;\n        while ((offset < end) && (out < (comp_Prebuf.size + uncompressedSize))\n             && (offset < (comp_Prebuf.size + uncompressedSize)))\n          dst[out++] = dst[offset++];\n      } else { // literal\n        if ((out >= (comp_Prebuf.size + uncompressedSize)) ||\n            (in >= p->size)) {\n          printf(\"Corrupted stream\\n\");\n          exit(-1);\n        }\n        dst[out++] = src[in++];\n      }\n    }\n    // copy it back without the prebuffered data\n    src = dst;\n    dst = calloc(uncompressedSize, 1);\n    ALLOCCHECK_CHAR(dst);\n    memcpy(dst, src + comp_Prebuf.size, uncompressedSize);\n    free(src);\n    *size = uncompressedSize;\n    free(comp_Prebuf.data);\n    return dst;\n  } else { // unknown magic number\n    printf(\"Unknown compression type (magic number %x)\\n\", magic);\n  }\n  free(comp_Prebuf.data);\n  return NULL;\n}", "func_src_after": "BYTE *DecompressRTF(variableLength *p, int *size) {\n  BYTE *dst; // destination for uncompressed bytes\n  BYTE *src;\n  unsigned int in;\n  unsigned int out;\n  variableLength comp_Prebuf;\n  ULONG compressedSize, uncompressedSize, magic;\n\n  comp_Prebuf.size = strlen(RTF_PREBUF);\n  comp_Prebuf.data = calloc(comp_Prebuf.size+1, 1);\n  ALLOCCHECK_CHAR(comp_Prebuf.data);\n  memcpy(comp_Prebuf.data, RTF_PREBUF, comp_Prebuf.size);\n\n  src = p->data;\n  in = 0;\n\n  if (p->size < 20) {\n    printf(\"File too small\\n\");\n    return(NULL);\n  }\n  compressedSize = (ULONG)SwapDWord((BYTE*)src + in, 4);\n  in += 4;\n  uncompressedSize = (ULONG)SwapDWord((BYTE*)src + in, 4);\n  in += 4;\n  magic = SwapDWord((BYTE*)src + in, 4);\n  in += 4;\n  in += 4;\n\n  // check size excluding the size field itself\n  if (compressedSize != p->size - 4) {\n    printf(\" Size Mismatch: %u != %i\\n\", compressedSize, p->size - 4);\n    free(comp_Prebuf.data);\n    return NULL;\n  }\n\n  // process the data\n  if (magic == 0x414c454d) {\n    // magic number that identifies the stream as a uncompressed stream\n    dst = calloc(uncompressedSize, 1);\n    ALLOCCHECK_CHAR(dst);\n    memcpy(dst, src + 4, uncompressedSize);\n  } else if (magic == 0x75465a4c) {\n    // magic number that identifies the stream as a compressed stream\n    int flagCount = 0;\n    int flags = 0;\n    // Prevent overflow on 32 Bit Systems\n    if (comp_Prebuf.size >= INT_MAX - uncompressedSize) {\n       printf(\"Corrupted file\\n\");\n       exit(-1);\n    }\n    dst = calloc(comp_Prebuf.size + uncompressedSize, 1);\n    ALLOCCHECK_CHAR(dst);\n    memcpy(dst, comp_Prebuf.data, comp_Prebuf.size);\n    out = comp_Prebuf.size;\n    while ((out < (comp_Prebuf.size + uncompressedSize)) && (in < p->size)) {\n      // each flag byte flags 8 literals/references, 1 per bit\n      flags = (flagCount++ % 8 == 0) ? src[in++] : flags >> 1;\n      if ((flags & 1) == 1) { // each flag bit is 1 for reference, 0 for literal\n        unsigned int offset = src[in++];\n        unsigned int length = src[in++];\n        unsigned int end;\n        offset = (offset << 4) | (length >> 4); // the offset relative to block start\n        length = (length & 0xF) + 2; // the number of bytes to copy\n        // the decompression buffer is supposed to wrap around back\n        // to the beginning when the end is reached. we save the\n        // need for such a buffer by pointing straight into the data\n        // buffer, and simulating this behaviour by modifying the\n        // pointers appropriately.\n        offset = (out / 4096) * 4096 + offset;\n        if (offset >= out) // take from previous block\n          offset -= 4096;\n        // note: can't use System.arraycopy, because the referenced\n        // bytes can cross through the current out position.\n        end = offset + length;\n        while ((offset < end) && (out < (comp_Prebuf.size + uncompressedSize))\n             && (offset < (comp_Prebuf.size + uncompressedSize)))\n          dst[out++] = dst[offset++];\n      } else { // literal\n        if ((out >= (comp_Prebuf.size + uncompressedSize)) ||\n            (in >= p->size)) {\n          printf(\"Corrupted stream\\n\");\n          exit(-1);\n        }\n        dst[out++] = src[in++];\n      }\n    }\n    // copy it back without the prebuffered data\n    src = dst;\n    dst = calloc(uncompressedSize, 1);\n    ALLOCCHECK_CHAR(dst);\n    memcpy(dst, src + comp_Prebuf.size, uncompressedSize);\n    free(src);\n    *size = uncompressedSize;\n    free(comp_Prebuf.data);\n    return dst;\n  } else { // unknown magic number\n    printf(\"Unknown compression type (magic number %x)\\n\", magic);\n  }\n  free(comp_Prebuf.data);\n  return NULL;\n}", "commit_link": "github.com/Yeraze/ytnef/commit/22f8346c8d4f0020a40d9f258fdb3bfc097359cc", "file_name": "lib/ytnef.c", "vul_type": "cwe-125", "description": "Write a C function named `DecompressRTF` that decompresses RTF data and returns a pointer to the uncompressed bytes."}
{"func_name": "g72x_init", "func_src_before": "g72x_init (SF_PRIVATE * psf)\n{\tG72x_PRIVATE\t*pg72x ;\n\tint\tbitspersample, bytesperblock, codec ;\n\n\tif (psf->codec_data != NULL)\n\t{\tpsf_log_printf (psf, \"*** psf->codec_data is not NULL.\\n\") ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tpsf->sf.seekable = SF_FALSE ;\n\n\tif (psf->sf.channels != 1)\n\t\treturn SFE_G72X_NOT_MONO ;\n\n\tif ((pg72x = calloc (1, sizeof (G72x_PRIVATE))) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tpsf->codec_data = (void*) pg72x ;\n\n\tpg72x->block_curr = 0 ;\n\tpg72x->sample_curr = 0 ;\n\n\tswitch (SF_CODEC (psf->sf.format))\n\t{\tcase SF_FORMAT_G721_32 :\n\t\t\t\tcodec = G721_32_BITS_PER_SAMPLE ;\n\t\t\t\tbytesperblock = G721_32_BYTES_PER_BLOCK ;\n\t\t\t\tbitspersample = G721_32_BITS_PER_SAMPLE ;\n\t\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_G723_24:\n\t\t\t\tcodec = G723_24_BITS_PER_SAMPLE ;\n\t\t\t\tbytesperblock = G723_24_BYTES_PER_BLOCK ;\n\t\t\t\tbitspersample = G723_24_BITS_PER_SAMPLE ;\n\t\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_G723_40:\n\t\t\t\tcodec = G723_40_BITS_PER_SAMPLE ;\n\t\t\t\tbytesperblock = G723_40_BYTES_PER_BLOCK ;\n\t\t\t\tbitspersample = G723_40_BITS_PER_SAMPLE ;\n\t\t\t\tbreak ;\n\n\t\tdefault : return SFE_UNIMPLEMENTED ;\n\t\t} ;\n\n\tpsf->filelength = psf_get_filelen (psf) ;\n\tif (psf->filelength < psf->dataoffset)\n\t\tpsf->filelength = psf->dataoffset ;\n\n\tpsf->datalength = psf->filelength - psf->dataoffset ;\n\tif (psf->dataend > 0)\n\t\tpsf->datalength -= psf->filelength - psf->dataend ;\n\n\tif (psf->file.mode == SFM_READ)\n\t{\tpg72x->private = g72x_reader_init (codec, &(pg72x->blocksize), &(pg72x->samplesperblock)) ;\n\t\tif (pg72x->private == NULL)\n\t\t\treturn SFE_MALLOC_FAILED ;\n\n\t\tpg72x->bytesperblock = bytesperblock ;\n\n\t\tpsf->read_short\t\t= g72x_read_s ;\n\t\tpsf->read_int\t\t= g72x_read_i ;\n\t\tpsf->read_float\t\t= g72x_read_f ;\n\t\tpsf->read_double\t= g72x_read_d ;\n\n\t\tpsf->seek = g72x_seek ;\n\n\t\tif (psf->datalength % pg72x->blocksize)\n\t\t{\tpsf_log_printf (psf, \"*** Odd psf->datalength (%D) should be a multiple of %d\\n\", psf->datalength, pg72x->blocksize) ;\n\t\t\tpg72x->blocks_total = (psf->datalength / pg72x->blocksize) + 1 ;\n\t\t\t}\n\t\telse\n\t\t\tpg72x->blocks_total = psf->datalength / pg72x->blocksize ;\n\n\t\tpsf->sf.frames = pg72x->blocks_total * pg72x->samplesperblock ;\n\n\t\tpsf_g72x_decode_block (psf, pg72x) ;\n\t\t}\n\telse if (psf->file.mode == SFM_WRITE)\n\t{\tpg72x->private = g72x_writer_init (codec, &(pg72x->blocksize), &(pg72x->samplesperblock)) ;\n\t\tif (pg72x->private == NULL)\n\t\t\treturn SFE_MALLOC_FAILED ;\n\n\t\tpg72x->bytesperblock = bytesperblock ;\n\n\t\tpsf->write_short\t= g72x_write_s ;\n\t\tpsf->write_int\t\t= g72x_write_i ;\n\t\tpsf->write_float\t= g72x_write_f ;\n\t\tpsf->write_double\t= g72x_write_d ;\n\n\t\tif (psf->datalength % pg72x->blocksize)\n\t\t\tpg72x->blocks_total = (psf->datalength / pg72x->blocksize) + 1 ;\n\t\telse\n\t\t\tpg72x->blocks_total = psf->datalength / pg72x->blocksize ;\n\n\t\tif (psf->datalength > 0)\n\t\t\tpsf->sf.frames = (8 * psf->datalength) / bitspersample ;\n\n\t\tif ((psf->sf.frames * bitspersample) / 8 != psf->datalength)\n\t\t\tpsf_log_printf (psf, \"*** Warning : weird psf->datalength.\\n\") ;\n\t\t} ;\n\n\tpsf->codec_close\t= g72x_close ;\n\n\treturn 0 ;\n} /* g72x_init */", "func_src_after": "g72x_init (SF_PRIVATE * psf)\n{\tG72x_PRIVATE\t*pg72x ;\n\tint\tbitspersample, bytesperblock, codec ;\n\n\tif (psf->codec_data != NULL)\n\t{\tpsf_log_printf (psf, \"*** psf->codec_data is not NULL.\\n\") ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tpsf->sf.seekable = SF_FALSE ;\n\n\tif (psf->sf.channels != 1)\n\t\treturn SFE_G72X_NOT_MONO ;\n\n\tif ((pg72x = calloc (1, sizeof (G72x_PRIVATE))) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tpsf->codec_data = (void*) pg72x ;\n\n\tpg72x->block_curr = 0 ;\n\tpg72x->sample_curr = 0 ;\n\n\tswitch (SF_CODEC (psf->sf.format))\n\t{\tcase SF_FORMAT_G721_32 :\n\t\t\t\tcodec = G721_32_BITS_PER_SAMPLE ;\n\t\t\t\tbytesperblock = G721_32_BYTES_PER_BLOCK ;\n\t\t\t\tbitspersample = G721_32_BITS_PER_SAMPLE ;\n\t\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_G723_24:\n\t\t\t\tcodec = G723_24_BITS_PER_SAMPLE ;\n\t\t\t\tbytesperblock = G723_24_BYTES_PER_BLOCK ;\n\t\t\t\tbitspersample = G723_24_BITS_PER_SAMPLE ;\n\t\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_G723_40:\n\t\t\t\tcodec = G723_40_BITS_PER_SAMPLE ;\n\t\t\t\tbytesperblock = G723_40_BYTES_PER_BLOCK ;\n\t\t\t\tbitspersample = G723_40_BITS_PER_SAMPLE ;\n\t\t\t\tbreak ;\n\n\t\tdefault : return SFE_UNIMPLEMENTED ;\n\t\t} ;\n\n\tpsf->filelength = psf_get_filelen (psf) ;\n\tif (psf->filelength < psf->dataoffset)\n\t\tpsf->filelength = psf->dataoffset ;\n\n\tpsf->datalength = psf->filelength - psf->dataoffset ;\n\tif (psf->dataend > 0)\n\t\tpsf->datalength -= psf->filelength - psf->dataend ;\n\n\tif (psf->file.mode == SFM_READ)\n\t{\tpg72x->private = g72x_reader_init (codec, &(pg72x->blocksize), &(pg72x->samplesperblock)) ;\n\t\tif (pg72x->private == NULL)\n\t\t\treturn SFE_MALLOC_FAILED ;\n\n\t\tpg72x->bytesperblock = bytesperblock ;\n\n\t\tpsf->read_short\t\t= g72x_read_s ;\n\t\tpsf->read_int\t\t= g72x_read_i ;\n\t\tpsf->read_float\t\t= g72x_read_f ;\n\t\tpsf->read_double\t= g72x_read_d ;\n\n\t\tpsf->seek = g72x_seek ;\n\n\t\tif (psf->datalength % pg72x->blocksize)\n\t\t{\tpsf_log_printf (psf, \"*** Odd psf->datalength (%D) should be a multiple of %d\\n\", psf->datalength, pg72x->blocksize) ;\n\t\t\tpg72x->blocks_total = (psf->datalength / pg72x->blocksize) + 1 ;\n\t\t\t}\n\t\telse\n\t\t\tpg72x->blocks_total = psf->datalength / pg72x->blocksize ;\n\n\t\tpsf->sf.frames = (sf_count_t) pg72x->blocks_total * pg72x->samplesperblock ;\n\n\t\tpsf_g72x_decode_block (psf, pg72x) ;\n\t\t}\n\telse if (psf->file.mode == SFM_WRITE)\n\t{\tpg72x->private = g72x_writer_init (codec, &(pg72x->blocksize), &(pg72x->samplesperblock)) ;\n\t\tif (pg72x->private == NULL)\n\t\t\treturn SFE_MALLOC_FAILED ;\n\n\t\tpg72x->bytesperblock = bytesperblock ;\n\n\t\tpsf->write_short\t= g72x_write_s ;\n\t\tpsf->write_int\t\t= g72x_write_i ;\n\t\tpsf->write_float\t= g72x_write_f ;\n\t\tpsf->write_double\t= g72x_write_d ;\n\n\t\tif (psf->datalength % pg72x->blocksize)\n\t\t\tpg72x->blocks_total = (psf->datalength / pg72x->blocksize) + 1 ;\n\t\telse\n\t\t\tpg72x->blocks_total = psf->datalength / pg72x->blocksize ;\n\n\t\tif (psf->datalength > 0)\n\t\t\tpsf->sf.frames = (8 * psf->datalength) / bitspersample ;\n\n\t\tif ((psf->sf.frames * bitspersample) / 8 != psf->datalength)\n\t\t\tpsf_log_printf (psf, \"*** Warning : weird psf->datalength.\\n\") ;\n\t\t} ;\n\n\tpsf->codec_close\t= g72x_close ;\n\n\treturn 0 ;\n} /* g72x_init */", "line_changes": {"deleted": [{"line_no": 74, "char_start": 2039, "char_end": 2105, "line": "\t\tpsf->sf.frames = pg72x->blocks_total * pg72x->samplesperblock ;\n"}], "added": [{"line_no": 74, "char_start": 2039, "char_end": 2118, "line": "\t\tpsf->sf.frames = (sf_count_t) pg72x->blocks_total * pg72x->samplesperblock ;\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2057, "char_end": 2070, "chars": " (sf_count_t)"}]}, "commit_link": "github.com/libsndfile/libsndfile/commit/a4f1387ab8084fac7f0301b18e01011be9381672", "file_name": "g72x.c", "vul_type": "cwe-190", "commit_msg": "Update g72x.c\n\nFixing signed integer overflow as reported in https://github.com/libsndfile/libsndfile/issues/757 . A similar fix was applied before https://github.com/libsndfile/libsndfile/pull/818", "parent_commit": "a17e32fda6ed6883bebe0d5f7e1c83cd88409bd6", "description": "Write a C function to initialize a G72x codec with error handling and codec-specific settings based on the audio format."}
{"func_name": "getFileCacheID", "func_src_before": "\tdef getFileCacheID(self, pth):\n\t\t\"\"\"\n\t\tReturns ID of a cached file on Telegram from DB. None if file doesn't exist or has no cached ID.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"SELECT file_id FROM {0} WHERE path='{1}'\".format(TABLE_NAME, pth)\n\t\tdata = self._run_command(command)\n\n\t\ttry:\n\t\t\tdata = data[0][0]\n\t\texcept IndexError:\n\t\t\tdata = None\n\n\t\treturn data", "func_src_after": "\tdef getFileCacheID(self, pth):\n\t\t\"\"\"\n\t\tReturns ID of a cached file on Telegram from DB. None if file doesn't exist or has no cached ID.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"SELECT file_id FROM {0} WHERE path=?;\".format(TABLE_NAME)\n\t\tparams = (pth,)\n\t\tdata = self._run_command(command, params)\n\n\t\ttry:\n\t\t\tdata = data[0][0]\n\t\texcept IndexError:\n\t\t\tdata = None\n\n\t\treturn data", "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve a file's cache ID from a database using a file path, returning None if not found."}
{"func_name": "delete", "func_src_before": "@mod.route('/delete/<int:cmt_id>', methods=['GET', 'POST'])\ndef delete(cmt_id):\n    if request.method == 'GET':\n        sql = \"SELECT msg_id FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        sql = \"DELETE FROM comment where cmt_id = '%d';\" % (cmt_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('comment.show', msg_id=m[0]))", "func_src_after": "@mod.route('/delete/<int:cmt_id>', methods=['GET', 'POST'])\ndef delete(cmt_id):\n    if request.method == 'GET':\n        cursor.execute(\"SELECT msg_id FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        cursor.execute(\"DELETE FROM comment where cmt_id = %s;\", (cmt_id,))\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('comment.show', msg_id=m[0]))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089", "description": "Write a Python Flask route to delete a comment by its ID from a database and redirect to a message page, using GET or POST method."}
{"func_name": "TarFileReader::extract", "func_src_before": "std::string TarFileReader::extract(const string &_path) {\n  if (_path.empty()) THROW(\"path cannot be empty\");\n  if (!hasMore()) THROW(\"No more tar files\");\n\n  string path = _path;\n  if (SystemUtilities::isDirectory(path)) path += \"/\" + getFilename();\n\n  LOG_DEBUG(5, \"Extracting: \" << path);\n\n  return extract(*SystemUtilities::oopen(path));\n}", "func_src_after": "std::string TarFileReader::extract(const string &_path) {\n  if (_path.empty()) THROW(\"path cannot be empty\");\n  if (!hasMore()) THROW(\"No more tar files\");\n\n  string path = _path;\n  if (SystemUtilities::isDirectory(path)) {\n    path += \"/\" + getFilename();\n\n    // Check that path is under the target directory\n    string a = SystemUtilities::getCanonicalPath(_path);\n    string b = SystemUtilities::getCanonicalPath(path);\n    if (!String::startsWith(b, a))\n      THROW(\"Tar path points outside of the extraction directory: \" << path);\n  }\n\n  LOG_DEBUG(5, \"Extracting: \" << path);\n\n  switch (getType()) {\n  case NORMAL_FILE: case CONTIGUOUS_FILE:\n    return extract(*SystemUtilities::oopen(path));\n  case DIRECTORY: SystemUtilities::ensureDirectory(path); break;\n  default: THROW(\"Unsupported tar file type \" << getType());\n  }\n\n  return getFilename();\n}", "commit_link": "github.com/CauldronDevelopmentLLC/cbang/commit/1c1dba62bd3e6fa9d0d0c0aa21926043b75382c7", "file_name": "src/cbang/tar/TarFileReader.cpp", "vul_type": "cwe-022", "description": "In C++, write a function to extract a file from a tar archive, handling path validation and logging the extraction process."}
{"func_name": "Exiv2::WebPImage::getHeaderOffset", "func_src_before": "    long WebPImage::getHeaderOffset(byte *data, long data_size,\n                                    byte *header, long header_size) {\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "func_src_after": "    long WebPImage::getHeaderOffset(byte* data, long data_size, byte* header, long header_size)\n    {\n        if (data_size < header_size) { return -1; }\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "commit_link": "github.com/Exiv2/exiv2/commit/e925bc5addd881543fa503470c8a859e112cca62", "file_name": "src/webpimage.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that finds the position of a header within a block of data and returns the index, or -1 if not found."}
{"func_name": "_add_volume_to_volume_set", "func_src_before": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run('createvvset -domain %s %s' % (domain,\n                                                         vvs_name), None)\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)", "func_src_after": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run(['createvvset', '-domain', domain, vvs_name])\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to add a volume to a volume set, optionally creating the set and applying QoS rules if the set doesn't exist."}
{"func_name": "php_wddx_pop_element", "func_src_before": " */\nstatic void php_wddx_pop_element(void *user_data, const XML_Char *name)\n{\n\tst_entry \t\t\t*ent1, *ent2;\n\twddx_stack \t\t\t*stack = (wddx_stack *)user_data;\n\tHashTable \t\t\t*target_hash;\n\tzend_class_entry \t**pce;\n\tzval\t\t\t\t*obj;\n\tzval\t\t\t\t*tmp;\n\tTSRMLS_FETCH();\n\n/* OBJECTS_FIXME */\n\tif (stack->top == 0) {\n\t\treturn;\n\t}\n\n\tif (!strcmp(name, EL_STRING) || !strcmp(name, EL_NUMBER) ||\n\t\t!strcmp(name, EL_BOOLEAN) || !strcmp(name, EL_NULL) ||\n\t  \t!strcmp(name, EL_ARRAY) || !strcmp(name, EL_STRUCT) ||\n\t\t!strcmp(name, EL_RECORDSET) || !strcmp(name, EL_BINARY) ||\n\t\t!strcmp(name, EL_DATETIME)) {\n\t\twddx_stack_top(stack, (void**)&ent1);\n\n\t\tif (!ent1->data) {\n\t\t\tif (stack->top > 1) {\n\t\t\t\tstack->top--;\n\t\t\t} else {\n\t\t\t\tstack->done = 1;\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!strcmp(name, EL_BINARY)) {\n\t\t\tint new_len=0;\n\t\t\tunsigned char *new_str;\n\n\t\t\tnew_str = php_base64_decode(Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data), &new_len);\n\t\t\tSTR_FREE(Z_STRVAL_P(ent1->data));\n\t\t\tZ_STRVAL_P(ent1->data) = new_str;\n\t\t\tZ_STRLEN_P(ent1->data) = new_len;\n\t\t}\n\n\t\t/* Call __wakeup() method on the object. */\n\t\tif (Z_TYPE_P(ent1->data) == IS_OBJECT) {\n\t\t\tzval *fname, *retval = NULL;\n\n\t\t\tMAKE_STD_ZVAL(fname);\n\t\t\tZVAL_STRING(fname, \"__wakeup\", 1);\n\n\t\t\tcall_user_function_ex(NULL, &ent1->data, fname, &retval, 0, 0, 0, NULL TSRMLS_CC);\n\n\t\t\tzval_dtor(fname);\n\t\t\tFREE_ZVAL(fname);\n\t\t\tif (retval) {\n\t\t\t\tzval_ptr_dtor(&retval);\n\t\t\t}\n\t\t}\n\n\t\tif (stack->top > 1) {\n\t\t\tstack->top--;\n\t\t\twddx_stack_top(stack, (void**)&ent2);\n\n\t\t\t/* if non-existent field */\n\t\t\tif (ent2->type == ST_FIELD && ent2->data == NULL) {\n\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\tefree(ent1);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (Z_TYPE_P(ent2->data) == IS_ARRAY || Z_TYPE_P(ent2->data) == IS_OBJECT) {\n\t\t\t\ttarget_hash = HASH_OF(ent2->data);\n\n\t\t\t\tif (ent1->varname) {\n\t\t\t\t\tif (!strcmp(ent1->varname, PHP_CLASS_NAME_VAR) &&\n\t\t\t\t\t\tZ_TYPE_P(ent1->data) == IS_STRING && Z_STRLEN_P(ent1->data) &&\n\t\t\t\t\t\tent2->type == ST_STRUCT && Z_TYPE_P(ent2->data) == IS_ARRAY) {\n\t\t\t\t\t\tzend_bool incomplete_class = 0;\n\n\t\t\t\t\t\tzend_str_tolower(Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data));\n\t\t\t\t\t\tif (zend_hash_find(EG(class_table), Z_STRVAL_P(ent1->data),\n\t\t\t\t\t\t\t\t\t\t   Z_STRLEN_P(ent1->data)+1, (void **) &pce)==FAILURE) {\n\t\t\t\t\t\t\tincomplete_class = 1;\n\t\t\t\t\t\t\tpce = &PHP_IC_ENTRY;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Initialize target object */\n\t\t\t\t\t\tMAKE_STD_ZVAL(obj);\n\t\t\t\t\t\tobject_init_ex(obj, *pce);\n\n\t\t\t\t\t\t/* Merge current hashtable with object's default properties */\n\t\t\t\t\t\tzend_hash_merge(Z_OBJPROP_P(obj),\n\t\t\t\t\t\t\t\t\t\tZ_ARRVAL_P(ent2->data),\n\t\t\t\t\t\t\t\t\t\t(void (*)(void *)) zval_add_ref,\n\t\t\t\t\t\t\t\t\t\t(void *) &tmp, sizeof(zval *), 0);\n\n\t\t\t\t\t\tif (incomplete_class) {\n\t\t\t\t\t\t\tphp_store_class_name(obj, Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Clean up old array entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent2->data);\n\n\t\t\t\t\t\t/* Set stack entry to point to the newly created object */\n\t\t\t\t\t\tent2->data = obj;\n\n\t\t\t\t\t\t/* Clean up class name var entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\t\t} else if (Z_TYPE_P(ent2->data) == IS_OBJECT) {\n\t\t\t\t\t\tzend_class_entry *old_scope = EG(scope);\n\n\t\t\t\t\t\tEG(scope) = Z_OBJCE_P(ent2->data);\n\t\t\t\t\t\tZ_DELREF_P(ent1->data);\n\t\t\t\t\t\tadd_property_zval(ent2->data, ent1->varname, ent1->data);\n\t\t\t\t\t\tEG(scope) = old_scope;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzend_symtable_update(target_hash, ent1->varname, strlen(ent1->varname)+1, &ent1->data, sizeof(zval *), NULL);\n\t\t\t\t\t}\n\t\t\t\t\tefree(ent1->varname);\n\t\t\t\t} else\t{\n\t\t\t\t\tzend_hash_next_index_insert(target_hash, &ent1->data, sizeof(zval *), NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t} else {\n\t\t\tstack->done = 1;\n\t\t}\n\t} else if (!strcmp(name, EL_VAR) && stack->varname) {\n\t\tefree(stack->varname);\n\t\tstack->varname = NULL;\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tst_entry *ent;\n\t\twddx_stack_top(stack, (void **)&ent);\n\t\tefree(ent);\n\t\tstack->top--;\n\t}", "func_src_after": " */\nstatic void php_wddx_pop_element(void *user_data, const XML_Char *name)\n{\n\tst_entry \t\t\t*ent1, *ent2;\n\twddx_stack \t\t\t*stack = (wddx_stack *)user_data;\n\tHashTable \t\t\t*target_hash;\n\tzend_class_entry \t**pce;\n\tzval\t\t\t\t*obj;\n\tzval\t\t\t\t*tmp;\n\tTSRMLS_FETCH();\n\n/* OBJECTS_FIXME */\n\tif (stack->top == 0) {\n\t\treturn;\n\t}\n\n\tif (!strcmp(name, EL_STRING) || !strcmp(name, EL_NUMBER) ||\n\t\t!strcmp(name, EL_BOOLEAN) || !strcmp(name, EL_NULL) ||\n\t  \t!strcmp(name, EL_ARRAY) || !strcmp(name, EL_STRUCT) ||\n\t\t!strcmp(name, EL_RECORDSET) || !strcmp(name, EL_BINARY) ||\n\t\t!strcmp(name, EL_DATETIME)) {\n\t\twddx_stack_top(stack, (void**)&ent1);\n\n\t\tif (!ent1->data) {\n\t\t\tif (stack->top > 1) {\n\t\t\t\tstack->top--;\n\t\t\t} else {\n\t\t\t\tstack->done = 1;\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!strcmp(name, EL_BINARY)) {\n\t\t\tint new_len=0;\n\t\t\tunsigned char *new_str;\n\n\t\t\tnew_str = php_base64_decode(Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data), &new_len);\n\t\t\tSTR_FREE(Z_STRVAL_P(ent1->data));\n\t\t\tif (new_str) {\n\t\t\t\tZ_STRVAL_P(ent1->data) = new_str;\n\t\t\t\tZ_STRLEN_P(ent1->data) = new_len;\n\t\t\t} else {\n\t\t\t\tZVAL_EMPTY_STRING(ent1->data);\n\t\t\t}\n\t\t}\n\n\t\t/* Call __wakeup() method on the object. */\n\t\tif (Z_TYPE_P(ent1->data) == IS_OBJECT) {\n\t\t\tzval *fname, *retval = NULL;\n\n\t\t\tMAKE_STD_ZVAL(fname);\n\t\t\tZVAL_STRING(fname, \"__wakeup\", 1);\n\n\t\t\tcall_user_function_ex(NULL, &ent1->data, fname, &retval, 0, 0, 0, NULL TSRMLS_CC);\n\n\t\t\tzval_dtor(fname);\n\t\t\tFREE_ZVAL(fname);\n\t\t\tif (retval) {\n\t\t\t\tzval_ptr_dtor(&retval);\n\t\t\t}\n\t\t}\n\n\t\tif (stack->top > 1) {\n\t\t\tstack->top--;\n\t\t\twddx_stack_top(stack, (void**)&ent2);\n\n\t\t\t/* if non-existent field */\n\t\t\tif (ent2->type == ST_FIELD && ent2->data == NULL) {\n\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\tefree(ent1);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (Z_TYPE_P(ent2->data) == IS_ARRAY || Z_TYPE_P(ent2->data) == IS_OBJECT) {\n\t\t\t\ttarget_hash = HASH_OF(ent2->data);\n\n\t\t\t\tif (ent1->varname) {\n\t\t\t\t\tif (!strcmp(ent1->varname, PHP_CLASS_NAME_VAR) &&\n\t\t\t\t\t\tZ_TYPE_P(ent1->data) == IS_STRING && Z_STRLEN_P(ent1->data) &&\n\t\t\t\t\t\tent2->type == ST_STRUCT && Z_TYPE_P(ent2->data) == IS_ARRAY) {\n\t\t\t\t\t\tzend_bool incomplete_class = 0;\n\n\t\t\t\t\t\tzend_str_tolower(Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data));\n\t\t\t\t\t\tif (zend_hash_find(EG(class_table), Z_STRVAL_P(ent1->data),\n\t\t\t\t\t\t\t\t\t\t   Z_STRLEN_P(ent1->data)+1, (void **) &pce)==FAILURE) {\n\t\t\t\t\t\t\tincomplete_class = 1;\n\t\t\t\t\t\t\tpce = &PHP_IC_ENTRY;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Initialize target object */\n\t\t\t\t\t\tMAKE_STD_ZVAL(obj);\n\t\t\t\t\t\tobject_init_ex(obj, *pce);\n\n\t\t\t\t\t\t/* Merge current hashtable with object's default properties */\n\t\t\t\t\t\tzend_hash_merge(Z_OBJPROP_P(obj),\n\t\t\t\t\t\t\t\t\t\tZ_ARRVAL_P(ent2->data),\n\t\t\t\t\t\t\t\t\t\t(void (*)(void *)) zval_add_ref,\n\t\t\t\t\t\t\t\t\t\t(void *) &tmp, sizeof(zval *), 0);\n\n\t\t\t\t\t\tif (incomplete_class) {\n\t\t\t\t\t\t\tphp_store_class_name(obj, Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Clean up old array entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent2->data);\n\n\t\t\t\t\t\t/* Set stack entry to point to the newly created object */\n\t\t\t\t\t\tent2->data = obj;\n\n\t\t\t\t\t\t/* Clean up class name var entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\t\t} else if (Z_TYPE_P(ent2->data) == IS_OBJECT) {\n\t\t\t\t\t\tzend_class_entry *old_scope = EG(scope);\n\n\t\t\t\t\t\tEG(scope) = Z_OBJCE_P(ent2->data);\n\t\t\t\t\t\tZ_DELREF_P(ent1->data);\n\t\t\t\t\t\tadd_property_zval(ent2->data, ent1->varname, ent1->data);\n\t\t\t\t\t\tEG(scope) = old_scope;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzend_symtable_update(target_hash, ent1->varname, strlen(ent1->varname)+1, &ent1->data, sizeof(zval *), NULL);\n\t\t\t\t\t}\n\t\t\t\t\tefree(ent1->varname);\n\t\t\t\t} else\t{\n\t\t\t\t\tzend_hash_next_index_insert(target_hash, &ent1->data, sizeof(zval *), NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t} else {\n\t\t\tstack->done = 1;\n\t\t}\n\t} else if (!strcmp(name, EL_VAR) && stack->varname) {\n\t\tefree(stack->varname);\n\t\tstack->varname = NULL;\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tst_entry *ent;\n\t\twddx_stack_top(stack, (void **)&ent);\n\t\tefree(ent);\n\t\tstack->top--;\n\t}", "commit_link": "github.com/php/php-src/commit/698a691724c0a949295991e5df091ce16f899e02", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-476", "description": "Write a PHP function that handles the end of an XML element during WDDX deserialization."}
{"func_name": "__ext4_journal_stop", "func_src_before": "int __ext4_journal_stop(const char *where, unsigned int line, handle_t *handle)\n{\n\tstruct super_block *sb;\n\tint err;\n\tint rc;\n\n\tif (!ext4_handle_valid(handle)) {\n\t\text4_put_nojournal(handle);\n\t\treturn 0;\n\t}\n\n\tif (!handle->h_transaction) {\n\t\terr = jbd2_journal_stop(handle);\n\t\treturn handle->h_err ? handle->h_err : err;\n\t}\n\n\tsb = handle->h_transaction->t_journal->j_private;\n\terr = handle->h_err;\n\trc = jbd2_journal_stop(handle);\n\n\tif (!err)\n\t\terr = rc;\n\tif (err)\n\t\t__ext4_std_error(sb, where, line, err);\n\treturn err;\n}", "func_src_after": "int __ext4_journal_stop(const char *where, unsigned int line, handle_t *handle)\n{\n\tstruct super_block *sb;\n\tint err;\n\tint rc;\n\n\tif (!ext4_handle_valid(handle)) {\n\t\text4_put_nojournal(handle);\n\t\treturn 0;\n\t}\n\n\terr = handle->h_err;\n\tif (!handle->h_transaction) {\n\t\trc = jbd2_journal_stop(handle);\n\t\treturn err ? err : rc;\n\t}\n\n\tsb = handle->h_transaction->t_journal->j_private;\n\trc = jbd2_journal_stop(handle);\n\n\tif (!err)\n\t\terr = rc;\n\tif (err)\n\t\t__ext4_std_error(sb, where, line, err);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/6934da9238da947628be83635e365df41064b09b", "file_name": "fs/ext4/ext4_jbd2.c", "vul_type": "cwe-416", "description": "Write a C function named `__ext4_journal_stop` that stops a journaling handle and handles errors appropriately."}
{"func_name": "regulator_ena_gpio_free", "func_src_before": "static void regulator_ena_gpio_free(struct regulator_dev *rdev)\n{\n\tstruct regulator_enable_gpio *pin, *n;\n\n\tif (!rdev->ena_pin)\n\t\treturn;\n\n\t/* Free the GPIO only in case of no use */\n\tlist_for_each_entry_safe(pin, n, &regulator_ena_gpio_list, list) {\n\t\tif (pin->gpiod == rdev->ena_pin->gpiod) {\n\t\t\tif (pin->request_count <= 1) {\n\t\t\t\tpin->request_count = 0;\n\t\t\t\tgpiod_put(pin->gpiod);\n\t\t\t\tlist_del(&pin->list);\n\t\t\t\tkfree(pin);\n\t\t\t} else {\n\t\t\t\tpin->request_count--;\n\t\t\t}\n\t\t}\n\t}\n}", "func_src_after": "static void regulator_ena_gpio_free(struct regulator_dev *rdev)\n{\n\tstruct regulator_enable_gpio *pin, *n;\n\n\tif (!rdev->ena_pin)\n\t\treturn;\n\n\t/* Free the GPIO only in case of no use */\n\tlist_for_each_entry_safe(pin, n, &regulator_ena_gpio_list, list) {\n\t\tif (pin->gpiod == rdev->ena_pin->gpiod) {\n\t\t\tif (pin->request_count <= 1) {\n\t\t\t\tpin->request_count = 0;\n\t\t\t\tgpiod_put(pin->gpiod);\n\t\t\t\tlist_del(&pin->list);\n\t\t\t\tkfree(pin);\n\t\t\t\trdev->ena_pin = NULL;\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpin->request_count--;\n\t\t\t}\n\t\t}\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/60a2362f769cf549dc466134efe71c8bf9fbaaba", "file_name": "drivers/regulator/core.c", "vul_type": "cwe-416", "description": "Write a C function to release a GPIO pin associated with a regulator device when it's no longer in use."}
{"func_name": "load_sample_environment_variables", "func_src_before": "  def load_sample_environment_variables\n    env_file = File.open('env_configuration_for_local_gem_tests.yml')\n\n    YAML.load(env_file).each do |key, value|\n      ENV[key.to_s] = value\n    end\n  end", "func_src_after": "  def load_sample_environment_variables\n    env_file = File.open('env_configuration_for_local_gem_tests.yml')\n\n    YAML.safe_load(env_file).each do |key, value|\n      ENV[key.to_s] = value\n    end\n  end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 111, "char_end": 156, "line": "    YAML.load(env_file).each do |key, value|\n"}], "added": [{"line_no": 4, "char_start": 111, "char_end": 161, "line": "    YAML.safe_load(env_file).each do |key, value|\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 120, "char_end": 125, "chars": "safe_"}]}, "commit_link": "github.com/fastly/fastly_nsq/commit/c16a48dd2f7b0a67d02c3fae35f0ec9ffaea9839", "file_name": "spec_helper.rb", "vul_type": "cwe-502", "commit_msg": "rubocop YAML.safe_load over just load\n\nthis is the spec_helper and doesn't appear to affect the running of the\ntests...", "parent_commit": "f6b18edc68d1040afdedd59a75a167dcdc244f8e", "description": "Write a Ruby method to load environment variables from a YAML file."}
{"func_name": "opmov", "func_src_before": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0]];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "func_src_after": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0] % 6];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = (((ut32)op->operands[0].reg) << 3) | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "commit_link": "github.com/radare/radare2/commit/f17bfd9f1da05f30f23a4dd05e9d2363e1406948", "file_name": "libr/asm/p/asm_x86_nz.c", "vul_type": "cwe-125", "description": "Write a C function named `opmov` that assembles an x86 MOV instruction based on the provided operands."}
{"func_name": "repodata_schema2id", "func_src_before": "repodata_schema2id(Repodata *data, Id *schema, int create)\n{\n  int h, len, i;\n  Id *sp, cid;\n  Id *schematahash;\n\n  if (!*schema)\n    return 0;\t/* XXX: allow empty schema? */\n  if ((schematahash = data->schematahash) == 0)\n    {\n      data->schematahash = schematahash = solv_calloc(256, sizeof(Id));\n      for (i = 1; i < data->nschemata; i++)\n\t{\n\t  for (sp = data->schemadata + data->schemata[i], h = 0; *sp;)\n\t    h = h * 7 + *sp++;\n\t  h &= 255;\n\t  schematahash[h] = i;\n\t}\n      data->schemadata = solv_extend_resize(data->schemadata, data->schemadatalen, sizeof(Id), SCHEMATADATA_BLOCK);\n      data->schemata = solv_extend_resize(data->schemata, data->nschemata, sizeof(Id), SCHEMATA_BLOCK);\n    }\n\n  for (sp = schema, len = 0, h = 0; *sp; len++)\n    h = h * 7 + *sp++;\n  h &= 255;\n  len++;\n\n  cid = schematahash[h];\n  if (cid)\n    {\n      if (!memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n        return cid;\n      /* cache conflict, do a slow search */\n      for (cid = 1; cid < data->nschemata; cid++)\n        if (!memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n          return cid;\n    }\n  /* a new one */\n  if (!create)\n    return 0;\n  data->schemadata = solv_extend(data->schemadata, data->schemadatalen, len, sizeof(Id), SCHEMATADATA_BLOCK);\n  data->schemata = solv_extend(data->schemata, data->nschemata, 1, sizeof(Id), SCHEMATA_BLOCK);\n  /* add schema */\n  memcpy(data->schemadata + data->schemadatalen, schema, len * sizeof(Id));\n  data->schemata[data->nschemata] = data->schemadatalen;\n  data->schemadatalen += len;\n  schematahash[h] = data->nschemata;\n#if 0\nfprintf(stderr, \"schema2id: new schema\\n\");\n#endif\n  return data->nschemata++;\n}", "func_src_after": "repodata_schema2id(Repodata *data, Id *schema, int create)\n{\n  int h, len, i;\n  Id *sp, cid;\n  Id *schematahash;\n\n  if (!*schema)\n    return 0;\t/* XXX: allow empty schema? */\n  if ((schematahash = data->schematahash) == 0)\n    {\n      data->schematahash = schematahash = solv_calloc(256, sizeof(Id));\n      for (i = 1; i < data->nschemata; i++)\n\t{\n\t  for (sp = data->schemadata + data->schemata[i], h = 0; *sp;)\n\t    h = h * 7 + *sp++;\n\t  h &= 255;\n\t  schematahash[h] = i;\n\t}\n      data->schemadata = solv_extend_resize(data->schemadata, data->schemadatalen, sizeof(Id), SCHEMATADATA_BLOCK);\n      data->schemata = solv_extend_resize(data->schemata, data->nschemata, sizeof(Id), SCHEMATA_BLOCK);\n    }\n\n  for (sp = schema, len = 0, h = 0; *sp; len++)\n    h = h * 7 + *sp++;\n  h &= 255;\n  len++;\n\n  cid = schematahash[h];\n  if (cid)\n    {\n      if ((data->schemata[cid] + len <= data->schemadatalen) &&\n\t\t\t  !memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n        return cid;\n      /* cache conflict, do a slow search */\n      for (cid = 1; cid < data->nschemata; cid++)\n        if ((data->schemata[cid] + len <= data->schemadatalen) &&\n\t\t\t\t!memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n          return cid;\n    }\n  /* a new one */\n  if (!create)\n    return 0;\n  data->schemadata = solv_extend(data->schemadata, data->schemadatalen, len, sizeof(Id), SCHEMATADATA_BLOCK);\n  data->schemata = solv_extend(data->schemata, data->nschemata, 1, sizeof(Id), SCHEMATA_BLOCK);\n  /* add schema */\n  memcpy(data->schemadata + data->schemadatalen, schema, len * sizeof(Id));\n  data->schemata[data->nschemata] = data->schemadatalen;\n  data->schemadatalen += len;\n  schematahash[h] = data->nschemata;\n#if 0\nfprintf(stderr, \"schema2id: new schema\\n\");\n#endif\n  return data->nschemata++;\n}", "commit_link": "github.com/openSUSE/libsolv/commit/fdb9c9c03508990e4583046b590c30d958f272da", "file_name": "src/repodata.c", "vul_type": "cwe-125", "description": "Write a C function named `repodata_schema2id` that maps a schema to an identifier, optionally creating a new entry if it doesn't exist."}
{"func_name": "karma_ask", "func_src_before": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(\n            ''' SELECT karma FROM people WHERE name='{}' '''.format(name))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(''' SELECT karma FROM people WHERE name=%(name)s ''',\n                       (name, ))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for a person's karma by their name and handle the result or potential errors."}
{"func_name": "security_fips_decrypt", "func_src_before": "BOOL security_fips_decrypt(BYTE* data, size_t length, rdpRdp* rdp)\n{\n\tsize_t olen;\n\n\tif (!winpr_Cipher_Update(rdp->fips_decrypt, data, length, data, &olen))\n\t\treturn FALSE;\n\n\treturn TRUE;\n}", "func_src_after": "BOOL security_fips_decrypt(BYTE* data, size_t length, rdpRdp* rdp)\n{\n\tsize_t olen;\n\n\tif (!rdp || !rdp->fips_decrypt)\n\t\treturn FALSE;\n\n\tif (!winpr_Cipher_Update(rdp->fips_decrypt, data, length, data, &olen))\n\t\treturn FALSE;\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/d6cd14059b257318f176c0ba3ee0a348826a9ef8", "file_name": "libfreerdp/core/security.c", "vul_type": "cwe-125", "description": "Write a C function named `security_fips_decrypt` that decrypts data using FIPS-compliant decryption, returning a boolean status."}
{"func_name": "action_save_user", "func_src_before": "def action_save_user(request: HttpRequest, default_forward_url: str = \"/admin/users\"):\n    \"\"\"\n    This functions saves the changes to the user or adds a new one. It completely creates the HttpResponse\n    :param request: the HttpRequest\n    :param default_forward_url: The URL to forward to if nothing was specified\n    :return: The crafted HttpResponse\n    \"\"\"\n    forward_url = default_forward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if not request.user.is_authenticated:\n        return HttpResponseForbidden()\n    profile = Profile.objects.get(authuser=request.user)\n    if profile.rights < 2:\n        return HttpResponseForbidden()\n    try:\n        if request.GET.get(\"user_id\"):\n            pid = int(request.GET[\"user_id\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            user: Profile = Profile.objects.get(pk=pid)\n            user.displayName = displayname\n            user.dect = dect\n            user.notes = notes\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            if request.POST.get(\"active\"):\n                user.active = magic.parse_bool(request.POST[\"active\"])\n            au: User = user.authuser\n            if check_password_conformity(pw1, pw2):\n                logging.log(logging.INFO, \"Set password for user: \" + user.displayName)\n                au.set_password(pw1)\n            else:\n                logging.log(logging.INFO, \"Failed to set password for: \" + user.displayName)\n            au.email = mail\n            au.save()\n            user.save()\n        else:\n            # assume new user\n            username = str(request.POST[\"username\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            if not check_password_conformity(pw1, pw2):\n                recreate_form('password mismatch')\n            auth_user: User = User.objects.create_user(username=username, email=mail, password=pw1)\n            auth_user.save()\n            user: Profile = Profile()\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            user.displayName = displayname\n            user.authuser = auth_user\n            user.dect = dect\n            user.notes = notes\n            user.active = True\n            user.save()\n            pass\n        pass\n    except Exception as e:\n        return HttpResponseBadRequest(str(e))\n    return redirect(forward_url)", "func_src_after": "def action_save_user(request: HttpRequest, default_forward_url: str = \"/admin/users\"):\n    \"\"\"\n    This functions saves the changes to the user or adds a new one. It completely creates the HttpResponse\n    :param request: the HttpRequest\n    :param default_forward_url: The URL to forward to if nothing was specified\n    :return: The crafted HttpResponse\n    \"\"\"\n    forward_url = default_forward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if not request.user.is_authenticated:\n        return HttpResponseForbidden()\n    profile = Profile.objects.get(authuser=request.user)\n    if profile.rights < 2:\n        return HttpResponseForbidden()\n    try:\n        if request.GET.get(\"user_id\"):\n            pid = int(request.GET[\"user_id\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            user: Profile = Profile.objects.get(pk=pid)\n            user.displayName = escape(displayname)\n            user.dect = dect\n            user.notes = escape(notes)\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            if request.POST.get(\"active\"):\n                user.active = magic.parse_bool(request.POST[\"active\"])\n            au: User = user.authuser\n            if check_password_conformity(pw1, pw2):\n                logging.log(logging.INFO, \"Set password for user: \" + user.displayName)\n                au.set_password(pw1)\n            else:\n                logging.log(logging.INFO, \"Failed to set password for: \" + user.displayName)\n            au.email = escape(mail)\n            au.save()\n            user.save()\n        else:\n            # assume new user\n            username = str(request.POST[\"username\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            if not check_password_conformity(pw1, pw2):\n                recreate_form('password mismatch')\n            auth_user: User = User.objects.create_user(username=escape(username), email=escape(mail), password=pw1)\n            auth_user.save()\n            user: Profile = Profile()\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            user.displayName = escape(displayname)\n            user.authuser = auth_user\n            user.dect = dect\n            user.notes = escape(notes)\n            user.active = True\n            user.save()\n            pass\n        pass\n    except Exception as e:\n        return HttpResponseBadRequest(str(e))\n    return redirect(forward_url)", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/edit_user.py", "vul_type": "cwe-079", "description": "Write a Python function to save or update a user's profile with permissions and redirection handling."}
{"func_name": "_modify_3par_fibrechan_host", "func_src_before": "    def _modify_3par_fibrechan_host(self, hostname, wwn):\n        # when using -add, you can not send the persona or domain options\n        out = self.common._cli_run('createhost -add %s %s'\n                                   % (hostname, \" \".join(wwn)), None)", "func_src_after": "    def _modify_3par_fibrechan_host(self, hostname, wwns):\n        # when using -add, you can not send the persona or domain options\n        command = ['createhost', '-add', hostname]\n        for wwn in wwns:\n            command.append(wwn)\n\n        out = self.common._cli_run(command)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_fc.py", "vul_type": "cwe-078", "description": "Write a Python function to add WWNs to a Fibre Channel host on a 3PAR storage system without including persona or domain options."}
{"func_name": "(anonymous)", "func_src_before": "UserSchema.virtual('password').set(function(password) {\n    this._password = password;\n    this.salt = this.makeSalt();\n    this.hashed_password = this.encryptPassword(password);\n}).get(function() {", "func_src_after": "UserSchema.virtual('password').set(function(password) {\n    this._password = password;\n    this.hashed_password = this.encryptPassword(password);\n}).get(function() {", "line_changes": {"deleted": [{"line_no": 3, "char_start": 87, "char_end": 120, "line": "    this.salt = this.makeSalt();\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 120, "chars": "    this.salt = this.makeSalt();\n"}], "added": []}, "commit_link": "github.com/andela/temari-cfh/commit/e5e4de5f2cc14fcd86464c83b5d110c9e05f2eba", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Improved user password encryption to use bcrypt instead of SHA1.", "parent_commit": "d56dd3474970c1f8b1dbf3599a451c3d2609c13d", "description": "Create a virtual password field with setter and getter methods in a User schema using Mongoose in JavaScript."}
{"func_name": "createItem", "func_src_before": "\t\t\tfunction createItem(element,checked){\n\t\t\t\telement=$(element);\n\t\t\t\tvar item=element.val();\n\t\t\t\tvar id='ms'+multiSelectId+'-option-'+item;\n\t\t\t\tvar input=$('<input id=\"'+id+'\" type=\"checkbox\"/>');\n\t\t\t\tvar label=$('<label for=\"'+id+'\">'+item+'</label>');\n\t\t\t\tif(settings.checked.indexOf(item)!=-1 || checked){\n\t\t\t\t\tinput.attr('checked',true);\n\t\t\t\t}\n\t\t\t\tif(checked){\n\t\t\t\t\tsettings.checked.push(item);\n\t\t\t\t}\n\t\t\t\tinput.change(function(){\n\t\t\t\t\tvar groupname=$(this).next().text();\n\t\t\t\t\tif($(this).is(':checked')){\n\t\t\t\t\t\telement.attr('selected','selected');\n\t\t\t\t\t\tif(settings.oncheck){\n\t\t\t\t\t\t\tif(settings.oncheck(groupname)===false){\n\t\t\t\t\t\t\t\t$(this).attr('checked', false);\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsettings.checked.push(groupname);\n\t\t\t\t\t}else{\n\t\t\t\t\t\tvar index=settings.checked.indexOf(groupname);\n\t\t\t\t\t\telement.attr('selected',null);\n\t\t\t\t\t\tif(settings.onuncheck){\n\t\t\t\t\t\t\tif(settings.onuncheck(groupname)===false){\n\t\t\t\t\t\t\t\t$(this).attr('checked',true);\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsettings.checked.splice(index,1);\n\t\t\t\t\t}\n\t\t\t\t\tvar oldWidth=button.width();\n\t\t\t\t\tif(settings.checked.length>0){\n\t\t\t\t\t\tbutton.children('span').first().text(settings.checked.join(', '));\n\t\t\t\t\t}else{\n\t\t\t\t\t\tbutton.children('span').first().text(settings.title);\n\t\t\t\t\t}\n\t\t\t\t\tvar newOuterWidth=Math.max((button.outerWidth()-2),settings.minOuterWidth)+'px';\n\t\t\t\t\tvar newWidth=Math.max(button.width(),settings.minWidth);\n\t\t\t\t\tvar pos=button.position();\n\t\t\t\t\tbutton.css('height',button.height());\n\t\t\t\t\tbutton.css('white-space','nowrap');\n\t\t\t\t\tbutton.css('width',oldWidth);\n\t\t\t\t\tbutton.animate({'width':newWidth},undefined,undefined,function(){\n\t\t\t\t\t\tbutton.css('width','');\n\t\t\t\t\t});\n\t\t\t\t\tlist.animate({'width':newOuterWidth,'left':pos.left+3});\n\t\t\t\t});\n\t\t\t\tvar li=$('<li></li>');\n\t\t\t\tli.append(input).append(label);\n\t\t\t\treturn li;\n\t\t\t}", "func_src_after": "\t\t\tfunction createItem(element,checked){\n\t\t\t\telement=$(element);\n\t\t\t\tvar item=element.val();\n\t\t\t\tvar id='ms'+multiSelectId+'-option-'+item;\n\t\t\t\tvar input=$('<input type=\"checkbox\"/>');\n\t\t\t\tinput.attr('id',id);\n\t\t\t\tvar label=$('<label/>');\n\t\t\t\tlabel.attr('for',id);\n\t\t\t\tlabel.text(item);\n\t\t\t\tif(settings.checked.indexOf(item)!=-1 || checked){\n\t\t\t\t\tinput.attr('checked',true);\n\t\t\t\t}\n\t\t\t\tif(checked){\n\t\t\t\t\tsettings.checked.push(item);\n\t\t\t\t}\n\t\t\t\tinput.change(function(){\n\t\t\t\t\tvar groupname=$(this).next().text();\n\t\t\t\t\tif($(this).is(':checked')){\n\t\t\t\t\t\telement.attr('selected','selected');\n\t\t\t\t\t\tif(settings.oncheck){\n\t\t\t\t\t\t\tif(settings.oncheck(groupname)===false){\n\t\t\t\t\t\t\t\t$(this).attr('checked', false);\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsettings.checked.push(groupname);\n\t\t\t\t\t}else{\n\t\t\t\t\t\tvar index=settings.checked.indexOf(groupname);\n\t\t\t\t\t\telement.attr('selected',null);\n\t\t\t\t\t\tif(settings.onuncheck){\n\t\t\t\t\t\t\tif(settings.onuncheck(groupname)===false){\n\t\t\t\t\t\t\t\t$(this).attr('checked',true);\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsettings.checked.splice(index,1);\n\t\t\t\t\t}\n\t\t\t\t\tvar oldWidth=button.width();\n\t\t\t\t\tif(settings.checked.length>0){\n\t\t\t\t\t\tbutton.children('span').first().text(settings.checked.join(', '));\n\t\t\t\t\t}else{\n\t\t\t\t\t\tbutton.children('span').first().text(settings.title);\n\t\t\t\t\t}\n\t\t\t\t\tvar newOuterWidth=Math.max((button.outerWidth()-2),settings.minOuterWidth)+'px';\n\t\t\t\t\tvar newWidth=Math.max(button.width(),settings.minWidth);\n\t\t\t\t\tvar pos=button.position();\n\t\t\t\t\tbutton.css('height',button.height());\n\t\t\t\t\tbutton.css('white-space','nowrap');\n\t\t\t\t\tbutton.css('width',oldWidth);\n\t\t\t\t\tbutton.animate({'width':newWidth},undefined,undefined,function(){\n\t\t\t\t\t\tbutton.css('width','');\n\t\t\t\t\t});\n\t\t\t\t\tlist.animate({'width':newOuterWidth,'left':pos.left+3});\n\t\t\t\t});\n\t\t\t\tvar li=$('<li></li>');\n\t\t\t\tli.append(input).append(label);\n\t\t\t\treturn li;\n\t\t\t}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 140, "char_end": 197, "line": "\t\t\t\tvar input=$('<input id=\"'+id+'\" type=\"checkbox\"/>');\n"}, {"line_no": 6, "char_start": 197, "char_end": 254, "line": "\t\t\t\tvar label=$('<label for=\"'+id+'\">'+item+'</label>');\n"}], "added": [{"line_no": 5, "char_start": 140, "char_end": 185, "line": "\t\t\t\tvar input=$('<input type=\"checkbox\"/>');\n"}, {"line_no": 6, "char_start": 185, "char_end": 210, "line": "\t\t\t\tinput.attr('id',id);\n"}, {"line_no": 7, "char_start": 210, "char_end": 239, "line": "\t\t\t\tvar label=$('<label/>');\n"}, {"line_no": 8, "char_start": 239, "char_end": 265, "line": "\t\t\t\tlabel.attr('for',id);\n"}, {"line_no": 9, "char_start": 265, "char_end": 287, "line": "\t\t\t\tlabel.text(item);\n"}]}, "char_changes": {"deleted": [{"char_start": 163, "char_end": 175, "chars": " id=\"'+id+'\""}, {"char_start": 201, "char_end": 251, "chars": "var label=$('<label for=\"'+id+'\">'+item+'</label>'"}], "added": [{"char_start": 189, "char_end": 284, "chars": "input.attr('id',id);\n\t\t\t\tvar label=$('<label/>');\n\t\t\t\tlabel.attr('for',id);\n\t\t\t\tlabel.text(item"}]}, "commit_link": "github.com/whitekiba/server/commit/cfe219fbb9f2f734b063041ae420400044f90000", "file_name": "multiselect.js", "vul_type": "cwe-079", "commit_msg": "fix potential xss in multiselect", "description": "Write a JavaScript function to create a checkbox list item with dynamic behavior based on a given element and a checked state."}
{"func_name": "save", "func_src_before": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        self.description = self.description_plain_text\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "func_src_after": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        # uses bleach to remove potentially harmful HTML code\n        self.description = bleach.clean(str(self.description_plain_text),\n                                        tags=CE.settings.bleach_allowed,\n                                        strip=True)\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "commit_link": "github.com/stevetasticsteve/CLA_Hub/commit/a06d85cd0b0964f8469e5c4bc9a6c132aa0b4c37", "file_name": "CE/models.py", "vul_type": "cwe-079", "description": "Write a Python method named `save` that sanitizes user input, handles cross-referencing or tagging, generates a slug from the title, and then calls the superclass's save method."}
{"func_name": "llrpt_alpha", "func_src_before": "llrpt_alpha (PNODE node, SYMTAB stab, BOOLEAN *eflg)\n{\n\tstatic char scratch[2];\n\tINT i;\n\tPNODE argvar = builtin_args(node);\n\tPVALUE val = eval_and_coerce(PINT, argvar, stab, eflg);\n\tif (*eflg) {\n\t\tprog_var_error(node, stab, argvar, val, nonint1, \"alpha\");\n\t\treturn NULL;\n\t}\n\ti = pvalue_to_int(val);\n\tdelete_pvalue_ptr(&val);\n\tif (i < 1 || i > 26)\n\t\tsprintf(scratch, \"XX\");\n\telse\n\t\tsprintf(scratch, \"%c\", 'a' + i - 1);\n\treturn create_pvalue_from_string(scratch);\n}", "func_src_after": "llrpt_alpha (PNODE node, SYMTAB stab, BOOLEAN *eflg)\n{\n\tstatic char scratch[2];\n\tINT i;\n\tPNODE argvar = builtin_args(node);\n\tPVALUE val = eval_and_coerce(PINT, argvar, stab, eflg);\n\tif (*eflg) {\n\t\tprog_var_error(node, stab, argvar, val, nonint1, \"alpha\");\n\t\treturn NULL;\n\t}\n\ti = pvalue_to_int(val);\n\tdelete_pvalue_ptr(&val);\n\tif (i < 1 || i > 26)\n\t\tsprintf(scratch, \"%c\", \"X\");\n\telse\n\t\tsprintf(scratch, \"%c\", 'a' + i - 1);\n\treturn create_pvalue_from_string(scratch);\n}", "line_changes": {"deleted": [{"line_no": 14, "char_start": 347, "char_end": 373, "line": "\t\tsprintf(scratch, \"XX\");\n"}], "added": [{"line_no": 14, "char_start": 347, "char_end": 378, "line": "\t\tsprintf(scratch, \"%c\", \"X\");\n"}]}, "char_changes": {"deleted": [{"char_start": 367, "char_end": 368, "chars": "X"}], "added": [{"char_start": 367, "char_end": 373, "chars": "%c\", \""}]}, "commit_link": "github.com/MarcNo/lifelines/commit/36132f776e25c3d26c88eefff46f3b5763ca6494", "file_name": "builtin.c", "vul_type": "cwe-787", "commit_msg": "Avoid sprintf buffer overflow", "parent_commit": "e0a7577aedead452f15f1852f3fe25ecb06a0eee", "description": "Write a function in C that takes an integer and returns the corresponding lowercase letter of the English alphabet, or \"X\" if the integer is out of range."}
{"func_name": "initialize", "func_src_before": "    def initialize(json)\n      @params = YAML.load(json || '')\n    end", "func_src_after": "    def initialize(json)\n      @params = YAML.safe_load(json || '')\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 25, "char_end": 63, "line": "      @params = YAML.load(json || '')\n"}], "added": [{"line_no": 2, "char_start": 25, "char_end": 68, "line": "      @params = YAML.safe_load(json || '')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 46, "char_end": 51, "chars": "safe_"}]}, "commit_link": "github.com/TravisCannon/panamax-api/commit/5f0bd8a0a60751bfd8ff51db83627b0477863b55", "file_name": "from_json.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load when parsing user templates", "parent_commit": "0f311d932ddb665f5ebdde98cca040ec858f1010", "description": "Create a Ruby method named `initialize` that loads a JSON string into a `@params` variable using YAML, with an optional use of a safer loading method."}
{"func_name": "audio_sample_entry_Read", "func_src_before": "GF_Err audio_sample_entry_Read(GF_Box *s, GF_BitStream *bs)\n{\n\tGF_MPEGAudioSampleEntryBox *ptr;\n\tchar *data;\n\tu8 a, b, c, d;\n\tu32 i, size, v, nb_alnum;\n\tGF_Err e;\n\tu64 pos, start;\n\n\tptr = (GF_MPEGAudioSampleEntryBox *)s;\n\n\tstart = gf_bs_get_position(bs);\n\tgf_bs_seek(bs, start + 8);\n\tv = gf_bs_read_u16(bs);\n\tif (v)\n\t\tptr->is_qtff = 1;\n\n\t//try to disambiguate QTFF v1 and MP4 v1 audio sample entries ...\n\tif (v==1) {\n\t\t//go to end of ISOM audio sample entry, skip 4 byte (box size field), read 4 bytes (box type) and check if this looks like a box\n\t\tgf_bs_seek(bs, start + 8 + 20  + 4);\n\t\ta = gf_bs_read_u8(bs);\n\t\tb = gf_bs_read_u8(bs);\n\t\tc = gf_bs_read_u8(bs);\n\t\td = gf_bs_read_u8(bs);\n\t\tnb_alnum = 0;\n\t\tif (isalnum(a)) nb_alnum++;\n\t\tif (isalnum(b)) nb_alnum++;\n\t\tif (isalnum(c)) nb_alnum++;\n\t\tif (isalnum(d)) nb_alnum++;\n\t\tif (nb_alnum>2) ptr->is_qtff = 0;\n\t}\n\n\tgf_bs_seek(bs, start);\n\te = gf_isom_audio_sample_entry_read((GF_AudioSampleEntryBox*)s, bs);\n\tif (e) return e;\n\tpos = gf_bs_get_position(bs);\n\tsize = (u32) s->size;\n\n\t//when cookie is set on bs, always convert qtff-style mp4a to isobmff-style\n\t//since the conversion is done in addBox and we don't have the bitstream there (arg...), flag the box\n \tif (gf_bs_get_cookie(bs)) {\n \t\tptr->is_qtff |= 1<<16;\n \t}\n\n\te = gf_isom_box_array_read(s, bs, audio_sample_entry_AddBox);\n\tif (!e) return GF_OK;\n\tif (size<8) return GF_ISOM_INVALID_FILE;\n\n\t/*hack for some weird files (possibly recorded with live.com tools, needs further investigations)*/\n\tgf_bs_seek(bs, pos);\n\tdata = (char*)gf_malloc(sizeof(char) * size);\n\tgf_bs_read_data(bs, data, size);\n\tfor (i=0; i<size-8; i++) {\n\t\tif (GF_4CC((u32)data[i+4], (u8)data[i+5], (u8)data[i+6], (u8)data[i+7]) == GF_ISOM_BOX_TYPE_ESDS) {\n\t\t\tGF_BitStream *mybs = gf_bs_new(data + i, size - i, GF_BITSTREAM_READ);\n\t\t\tif (ptr->esd) {\n\t\t\t\tgf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\te = gf_isom_box_parse((GF_Box **)&ptr->esd, mybs);\n\n\t\t\tif (e==GF_OK) {\n\t\t\t\tgf_isom_box_add_for_dump_mode((GF_Box*)ptr, (GF_Box*)ptr->esd);\n\t\t\t} else if (ptr->esd) {\n\t\t\t\tgf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\tgf_bs_del(mybs);\n\t\t\tbreak;\n\t\t}\n\t}\n\tgf_free(data);\n\treturn e;\n}", "func_src_after": "GF_Err audio_sample_entry_Read(GF_Box *s, GF_BitStream *bs)\n{\n\tGF_MPEGAudioSampleEntryBox *ptr;\n\tchar *data;\n\tu8 a, b, c, d;\n\tu32 i, size, v, nb_alnum;\n\tGF_Err e;\n\tu64 pos, start;\n\n\tptr = (GF_MPEGAudioSampleEntryBox *)s;\n\n\tstart = gf_bs_get_position(bs);\n\tgf_bs_seek(bs, start + 8);\n\tv = gf_bs_read_u16(bs);\n\tif (v)\n\t\tptr->is_qtff = 1;\n\n\t//try to disambiguate QTFF v1 and MP4 v1 audio sample entries ...\n\tif (v==1) {\n\t\t//go to end of ISOM audio sample entry, skip 4 byte (box size field), read 4 bytes (box type) and check if this looks like a box\n\t\tgf_bs_seek(bs, start + 8 + 20  + 4);\n\t\ta = gf_bs_read_u8(bs);\n\t\tb = gf_bs_read_u8(bs);\n\t\tc = gf_bs_read_u8(bs);\n\t\td = gf_bs_read_u8(bs);\n\t\tnb_alnum = 0;\n\t\tif (isalnum(a)) nb_alnum++;\n\t\tif (isalnum(b)) nb_alnum++;\n\t\tif (isalnum(c)) nb_alnum++;\n\t\tif (isalnum(d)) nb_alnum++;\n\t\tif (nb_alnum>2) ptr->is_qtff = 0;\n\t}\n\n\tgf_bs_seek(bs, start);\n\te = gf_isom_audio_sample_entry_read((GF_AudioSampleEntryBox*)s, bs);\n\tif (e) return e;\n\tpos = gf_bs_get_position(bs);\n\tsize = (u32) s->size;\n\n\t//when cookie is set on bs, always convert qtff-style mp4a to isobmff-style\n\t//since the conversion is done in addBox and we don't have the bitstream there (arg...), flag the box\n \tif (gf_bs_get_cookie(bs)) {\n \t\tptr->is_qtff |= 1<<16;\n \t}\n\n\te = gf_isom_box_array_read(s, bs, audio_sample_entry_AddBox);\n\tif (!e) return GF_OK;\n\tif (size<8) return GF_ISOM_INVALID_FILE;\n\n\t/*hack for some weird files (possibly recorded with live.com tools, needs further investigations)*/\n\tgf_bs_seek(bs, pos);\n\tdata = (char*)gf_malloc(sizeof(char) * size);\n\tgf_bs_read_data(bs, data, size);\n\tfor (i=0; i<size-8; i++) {\n\t\tif (GF_4CC((u32)data[i+4], (u8)data[i+5], (u8)data[i+6], (u8)data[i+7]) == GF_ISOM_BOX_TYPE_ESDS) {\n\t\t\textern Bool use_dump_mode;\n\t\t\tGF_BitStream *mybs = gf_bs_new(data + i, size - i, GF_BITSTREAM_READ);\n\t\t\tif (ptr->esd) {\n\t\t\t\tif (!use_dump_mode) gf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\te = gf_isom_box_parse((GF_Box **)&ptr->esd, mybs);\n\n\t\t\tif (e==GF_OK) {\n\t\t\t\tgf_isom_box_add_for_dump_mode((GF_Box*)ptr, (GF_Box*)ptr->esd);\n\t\t\t} else if (ptr->esd) {\n\t\t\t\tgf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\tgf_bs_del(mybs);\n\t\t\tbreak;\n\t\t}\n\t}\n\tgf_free(data);\n\treturn e;\n}", "commit_link": "github.com/gpac/gpac/commit/6063b1a011c3f80cee25daade18154e15e4c058c", "file_name": "src/isomedia/box_code_base.c", "vul_type": "cwe-416", "description": "Write a C function named `audio_sample_entry_Read` that reads and processes an audio sample entry from a bitstream."}
{"func_name": "closeGame", "func_src_before": "def closeGame(ID):\n\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = %i\" % ID)\n\tdatabase.commit()", "func_src_after": "def closeGame(ID):\n\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = ?\", ID)\n\tdatabase.commit()", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function to update the 'Running' status of a game to 'No' in a database using the game's ID."}
{"func_name": "pathRoleWrite", "func_src_before": "func (b *backend) pathRoleWrite(ctx context.Context, req *logical.Request, d *framework.FieldData) (*logical.Response, error) {\n\troleName := d.Get(\"role\").(string)\n\tif roleName == \"\" {\n\t\treturn logical.ErrorResponse(\"missing role name\"), nil\n\t}\n\n\t// Allowed users is an optional field, applicable for both OTP and Dynamic types.\n\tallowedUsers := d.Get(\"allowed_users\").(string)\n\n\t// Validate the CIDR blocks\n\tcidrList := d.Get(\"cidr_list\").(string)\n\tif cidrList != \"\" {\n\t\tvalid, err := cidrutil.ValidateCIDRListString(cidrList, \",\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to validate cidr_list: %w\", err)\n\t\t}\n\t\tif !valid {\n\t\t\treturn logical.ErrorResponse(\"failed to validate cidr_list\"), nil\n\t\t}\n\t}\n\n\t// Validate the excluded CIDR blocks\n\texcludeCidrList := d.Get(\"exclude_cidr_list\").(string)\n\tif excludeCidrList != \"\" {\n\t\tvalid, err := cidrutil.ValidateCIDRListString(excludeCidrList, \",\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to validate exclude_cidr_list entry: %w\", err)\n\t\t}\n\t\tif !valid {\n\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"failed to validate exclude_cidr_list entry: %v\", err)), nil\n\t\t}\n\t}\n\n\tport := d.Get(\"port\").(int)\n\tif port == 0 {\n\t\tport = 22\n\t}\n\n\tkeyType := d.Get(\"key_type\").(string)\n\tif keyType == \"\" {\n\t\treturn logical.ErrorResponse(\"missing key type\"), nil\n\t}\n\tkeyType = strings.ToLower(keyType)\n\n\tvar roleEntry sshRole\n\tif keyType == KeyTypeOTP {\n\t\tdefaultUser := d.Get(\"default_user\").(string)\n\t\tif defaultUser == \"\" {\n\t\t\treturn logical.ErrorResponse(\"missing default user\"), nil\n\t\t}\n\n\t\t// Admin user is not used if OTP key type is used because there is\n\t\t// no need to login to remote machine.\n\t\tadminUser := d.Get(\"admin_user\").(string)\n\t\tif adminUser != \"\" {\n\t\t\treturn logical.ErrorResponse(\"admin user not required for OTP type\"), nil\n\t\t}\n\n\t\t// Below are the only fields used from the role structure for OTP type.\n\t\troleEntry = sshRole{\n\t\t\tDefaultUser:     defaultUser,\n\t\t\tCIDRList:        cidrList,\n\t\t\tExcludeCIDRList: excludeCidrList,\n\t\t\tKeyType:         KeyTypeOTP,\n\t\t\tPort:            port,\n\t\t\tAllowedUsers:    allowedUsers,\n\t\t}\n\t} else if keyType == KeyTypeDynamic {\n\t\tdefaultUser := d.Get(\"default_user\").(string)\n\t\tif defaultUser == \"\" {\n\t\t\treturn logical.ErrorResponse(\"missing default user\"), nil\n\t\t}\n\t\t// Key name is required by dynamic type and not by OTP type.\n\t\tkeyName := d.Get(\"key\").(string)\n\t\tif keyName == \"\" {\n\t\t\treturn logical.ErrorResponse(\"missing key name\"), nil\n\t\t}\n\t\tkeyEntry, err := req.Storage.Get(ctx, fmt.Sprintf(\"keys/%s\", keyName))\n\t\tif err != nil || keyEntry == nil {\n\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"invalid 'key': %q\", keyName)), nil\n\t\t}\n\n\t\tinstallScript := d.Get(\"install_script\").(string)\n\t\tkeyOptionSpecs := d.Get(\"key_option_specs\").(string)\n\n\t\t// Setting the default script here. The script will install the\n\t\t// generated public key in the authorized_keys file of linux host.\n\t\tif installScript == \"\" {\n\t\t\tinstallScript = DefaultPublicKeyInstallScript\n\t\t}\n\n\t\tadminUser := d.Get(\"admin_user\").(string)\n\t\tif adminUser == \"\" {\n\t\t\treturn logical.ErrorResponse(\"missing admin username\"), nil\n\t\t}\n\n\t\t// This defaults to 1024 and it can also be 2048 and 4096.\n\t\tkeyBits := d.Get(\"key_bits\").(int)\n\t\tif keyBits != 0 && keyBits != 1024 && keyBits != 2048 && keyBits != 4096 {\n\t\t\treturn logical.ErrorResponse(\"invalid key_bits field\"), nil\n\t\t}\n\n\t\t// If user has not set this field, default it to 2048\n\t\tif keyBits == 0 {\n\t\t\tkeyBits = 2048\n\t\t}\n\n\t\t// Store all the fields required by dynamic key type\n\t\troleEntry = sshRole{\n\t\t\tKeyName:         keyName,\n\t\t\tAdminUser:       adminUser,\n\t\t\tDefaultUser:     defaultUser,\n\t\t\tCIDRList:        cidrList,\n\t\t\tExcludeCIDRList: excludeCidrList,\n\t\t\tPort:            port,\n\t\t\tKeyType:         KeyTypeDynamic,\n\t\t\tKeyBits:         keyBits,\n\t\t\tInstallScript:   installScript,\n\t\t\tAllowedUsers:    allowedUsers,\n\t\t\tKeyOptionSpecs:  keyOptionSpecs,\n\t\t}\n\t} else if keyType == KeyTypeCA {\n\t\talgorithmSigner := \"\"\n\t\talgorithmSignerRaw, ok := d.GetOk(\"algorithm_signer\")\n\t\tif ok {\n\t\t\talgorithmSigner = algorithmSignerRaw.(string)\n\t\t\tswitch algorithmSigner {\n\t\t\tcase ssh.SigAlgoRSA, ssh.SigAlgoRSASHA2256, ssh.SigAlgoRSASHA2512:\n\t\t\tcase \"\":\n\t\t\t\t// This case is valid, and the sign operation will use the signer's\n\t\t\t\t// default algorithm.\n\t\t\tdefault:\n\t\t\t\treturn nil, fmt.Errorf(\"unknown algorithm signer %q\", algorithmSigner)\n\t\t\t}\n\t\t}\n\n\t\trole, errorResponse := b.createCARole(allowedUsers, d.Get(\"default_user\").(string), algorithmSigner, d)\n\t\tif errorResponse != nil {\n\t\t\treturn errorResponse, nil\n\t\t}\n\t\troleEntry = *role\n\t} else {\n\t\treturn logical.ErrorResponse(\"invalid key type\"), nil\n\t}\n\n\tentry, err := logical.StorageEntryJSON(fmt.Sprintf(\"roles/%s\", roleName), roleEntry)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := req.Storage.Put(ctx, entry); err != nil {\n\t\treturn nil, err\n\t}\n\treturn nil, nil\n}", "func_src_after": "func (b *backend) pathRoleWrite(ctx context.Context, req *logical.Request, d *framework.FieldData) (*logical.Response, error) {\n\troleName := d.Get(\"role\").(string)\n\tif roleName == \"\" {\n\t\treturn logical.ErrorResponse(\"missing role name\"), nil\n\t}\n\n\t// Allowed users is an optional field, applicable for both OTP and Dynamic types.\n\tallowedUsers := d.Get(\"allowed_users\").(string)\n\n\t// Validate the CIDR blocks\n\tcidrList := d.Get(\"cidr_list\").(string)\n\tif cidrList != \"\" {\n\t\tvalid, err := cidrutil.ValidateCIDRListString(cidrList, \",\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to validate cidr_list: %w\", err)\n\t\t}\n\t\tif !valid {\n\t\t\treturn logical.ErrorResponse(\"failed to validate cidr_list\"), nil\n\t\t}\n\t}\n\n\t// Validate the excluded CIDR blocks\n\texcludeCidrList := d.Get(\"exclude_cidr_list\").(string)\n\tif excludeCidrList != \"\" {\n\t\tvalid, err := cidrutil.ValidateCIDRListString(excludeCidrList, \",\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to validate exclude_cidr_list entry: %w\", err)\n\t\t}\n\t\tif !valid {\n\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"failed to validate exclude_cidr_list entry: %v\", err)), nil\n\t\t}\n\t}\n\n\tport := d.Get(\"port\").(int)\n\tif port == 0 {\n\t\tport = 22\n\t}\n\n\tkeyType := d.Get(\"key_type\").(string)\n\tif keyType == \"\" {\n\t\treturn logical.ErrorResponse(\"missing key type\"), nil\n\t}\n\tkeyType = strings.ToLower(keyType)\n\n\tvar roleEntry sshRole\n\tif keyType == KeyTypeOTP {\n\t\tdefaultUser := d.Get(\"default_user\").(string)\n\t\tif defaultUser == \"\" {\n\t\t\treturn logical.ErrorResponse(\"missing default user\"), nil\n\t\t}\n\n\t\t// Admin user is not used if OTP key type is used because there is\n\t\t// no need to login to remote machine.\n\t\tadminUser := d.Get(\"admin_user\").(string)\n\t\tif adminUser != \"\" {\n\t\t\treturn logical.ErrorResponse(\"admin user not required for OTP type\"), nil\n\t\t}\n\n\t\t// Below are the only fields used from the role structure for OTP type.\n\t\troleEntry = sshRole{\n\t\t\tDefaultUser:     defaultUser,\n\t\t\tCIDRList:        cidrList,\n\t\t\tExcludeCIDRList: excludeCidrList,\n\t\t\tKeyType:         KeyTypeOTP,\n\t\t\tPort:            port,\n\t\t\tAllowedUsers:    allowedUsers,\n\t\t}\n\t} else if keyType == KeyTypeDynamic {\n\t\tdefaultUser := d.Get(\"default_user\").(string)\n\t\tif defaultUser == \"\" {\n\t\t\treturn logical.ErrorResponse(\"missing default user\"), nil\n\t\t}\n\t\t// Key name is required by dynamic type and not by OTP type.\n\t\tkeyName := d.Get(\"key\").(string)\n\t\tif keyName == \"\" {\n\t\t\treturn logical.ErrorResponse(\"missing key name\"), nil\n\t\t}\n\t\tkeyEntry, err := req.Storage.Get(ctx, fmt.Sprintf(\"keys/%s\", keyName))\n\t\tif err != nil || keyEntry == nil {\n\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"invalid 'key': %q\", keyName)), nil\n\t\t}\n\n\t\tinstallScript := d.Get(\"install_script\").(string)\n\t\tkeyOptionSpecs := d.Get(\"key_option_specs\").(string)\n\n\t\t// Setting the default script here. The script will install the\n\t\t// generated public key in the authorized_keys file of linux host.\n\t\tif installScript == \"\" {\n\t\t\tinstallScript = DefaultPublicKeyInstallScript\n\t\t}\n\n\t\tadminUser := d.Get(\"admin_user\").(string)\n\t\tif adminUser == \"\" {\n\t\t\treturn logical.ErrorResponse(\"missing admin username\"), nil\n\t\t}\n\n\t\t// This defaults to 2048, but it can also be 1024, 3072, 4096, or 8192.\n\t\t// In the near future, we should disallow 1024-bit SSH keys.\n\t\tkeyBits := d.Get(\"key_bits\").(int)\n\t\tif keyBits == 0 {\n\t\t\tkeyBits = 2048\n\t\t}\n\t\tif keyBits != 1024 && keyBits != 2048 && keyBits != 3072 && keyBits != 4096 && keyBits != 8192 {\n\t\t\treturn logical.ErrorResponse(\"invalid key_bits field\"), nil\n\t\t}\n\n\t\t// Store all the fields required by dynamic key type\n\t\troleEntry = sshRole{\n\t\t\tKeyName:         keyName,\n\t\t\tAdminUser:       adminUser,\n\t\t\tDefaultUser:     defaultUser,\n\t\t\tCIDRList:        cidrList,\n\t\t\tExcludeCIDRList: excludeCidrList,\n\t\t\tPort:            port,\n\t\t\tKeyType:         KeyTypeDynamic,\n\t\t\tKeyBits:         keyBits,\n\t\t\tInstallScript:   installScript,\n\t\t\tAllowedUsers:    allowedUsers,\n\t\t\tKeyOptionSpecs:  keyOptionSpecs,\n\t\t}\n\t} else if keyType == KeyTypeCA {\n\t\talgorithmSigner := \"\"\n\t\talgorithmSignerRaw, ok := d.GetOk(\"algorithm_signer\")\n\t\tif ok {\n\t\t\talgorithmSigner = algorithmSignerRaw.(string)\n\t\t\tswitch algorithmSigner {\n\t\t\tcase ssh.SigAlgoRSA, ssh.SigAlgoRSASHA2256, ssh.SigAlgoRSASHA2512:\n\t\t\tcase \"\":\n\t\t\t\t// This case is valid, and the sign operation will use the signer's\n\t\t\t\t// default algorithm.\n\t\t\tdefault:\n\t\t\t\treturn nil, fmt.Errorf(\"unknown algorithm signer %q\", algorithmSigner)\n\t\t\t}\n\t\t}\n\n\t\trole, errorResponse := b.createCARole(allowedUsers, d.Get(\"default_user\").(string), algorithmSigner, d)\n\t\tif errorResponse != nil {\n\t\t\treturn errorResponse, nil\n\t\t}\n\t\troleEntry = *role\n\t} else {\n\t\treturn logical.ErrorResponse(\"invalid key type\"), nil\n\t}\n\n\tentry, err := logical.StorageEntryJSON(fmt.Sprintf(\"roles/%s\", roleName), roleEntry)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := req.Storage.Put(ctx, entry); err != nil {\n\t\treturn nil, err\n\t}\n\treturn nil, nil\n}", "line_changes": {"deleted": [{"line_no": 99, "char_start": 3202, "char_end": 3279, "line": "\t\tif keyBits != 0 && keyBits != 1024 && keyBits != 2048 && keyBits != 4096 {\n"}, {"line_no": 100, "char_start": 3279, "char_end": 3342, "line": "\t\t\treturn logical.ErrorResponse(\"invalid key_bits field\"), nil\n"}, {"line_no": 101, "char_start": 3342, "char_end": 3346, "line": "\t\t}\n"}, {"line_no": 102, "char_start": 3346, "char_end": 3347, "line": "\n"}], "added": [{"line_no": 103, "char_start": 3320, "char_end": 3419, "line": "\t\tif keyBits != 1024 && keyBits != 2048 && keyBits != 3072 && keyBits != 4096 && keyBits != 8192 {\n"}, {"line_no": 104, "char_start": 3419, "char_end": 3482, "line": "\t\t\treturn logical.ErrorResponse(\"invalid key_bits field\"), nil\n"}, {"line_no": 105, "char_start": 3482, "char_end": 3486, "line": "\t\t}\n"}]}, "char_changes": {"deleted": [{"char_start": 3126, "char_end": 3134, "chars": "1024 and"}, {"char_start": 3150, "char_end": 3163, "chars": "2048 and 4096"}, {"char_start": 3215, "char_end": 3216, "chars": "!"}, {"char_start": 3220, "char_end": 3222, "chars": "&&"}, {"char_start": 3272, "char_end": 3276, "chars": "4096"}, {"char_start": 3347, "char_end": 3446, "chars": "\t\t// If user has not set this field, default it to 2048\n\t\tif keyBits == 0 {\n\t\t\tkeyBits = 2048\n\t\t}\n\n"}], "added": [{"char_start": 3126, "char_end": 3135, "chars": "2048, but"}, {"char_start": 3151, "char_end": 3239, "chars": "1024, 3072, 4096, or 8192.\n\t\t// In the near future, we should disallow 1024-bit SSH keys"}, {"char_start": 3291, "char_end": 3292, "chars": "="}, {"char_start": 3296, "char_end": 3324, "chars": "{\n\t\t\tkeyBits = 2048\n\t\t}\n\t\tif"}, {"char_start": 3374, "char_end": 3416, "chars": "3072 && keyBits != 4096 && keyBits != 8192"}]}, "commit_link": "github.com/hashicorp/vault/commit/8833875b1071fcb8c2f16d82dc1a5919ff6534eb", "file_name": "path_roles.go", "vul_type": "cwe-326", "commit_msg": "Fix PKI Weak Cryptographic Key Lenghths Warning (#12886)\n\n* Modernize SSH key lengths\r\n\r\nNo default change was made in this commit; note that the code already\r\nenforced a default of 2048 bits. ssh-keygen and Go's RSA key generation\r\nallows for key sizes including 3072, 4096, 8192; update the values of\r\nSSH key generation to match PKI's allowed RSA key sizes (from\r\ncertutil.ValidateKeyTypeLength(...)). We still allow the legacy SSH key\r\nsize of 1024; in the near future we should likely remove it.\r\n\r\nSigned-off-by: Alexander Scheel <alex.scheel@hashicorp.com>\r\n\r\n* Ensure minimum of 2048-bit PKI RSA keys\r\n\r\nWhile the stated path is a false-positive, verifying all paths is\r\nnon-trivial. We largely validate API call lengths using\r\ncertutil.ValidateKeyTypeLength(...), but ensuring no other path calls\r\ncertutil.generatePrivateKey(...) --- directly or indirectly --- is\r\nnon-trivial. Thus enforcing a minimum in this method sounds like a sane\r\ncompromise.\r\n\r\nResolves: https://github.com/hashicorp/vault/security/code-scanning/55\r\n\r\nSigned-off-by: Alexander Scheel <alex.scheel@hashicorp.com>", "parent_commit": "14101f866414d2ed7850648b465c746ac8fda621", "description": "Write a Go function to handle creating or updating SSH role configurations based on provided fields."}
{"func_name": "is_safe_url", "func_src_before": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    # Chrome treats \\ completely as /\n    url = url.replace('\\\\', '/')\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith('///'):\n        return False\n    url_info = urlparse(url)\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    # Forbid URLs that start with control characters. Some browsers (like\n    # Chrome) ignore quite a few control characters at the start of a\n    # URL and might consider the URL as scheme relative.\n    if unicodedata.category(url[0])[0] == 'C':\n        return False\n    return ((not url_info.netloc or url_info.netloc == host) and\n            (not url_info.scheme or url_info.scheme in ['http', 'https']))", "func_src_after": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    # Chrome treats \\ completely as / in paths but it could be part of some\n    # basic auth credentials so we need to check both URLs.\n    return _is_safe_url(url, host) and _is_safe_url(url.replace('\\\\', '/'), host)", "commit_link": "github.com/django/django/commit/c5544d289233f501917e25970c03ed444abbd4f0", "file_name": "django/utils/http.py", "vul_type": "cwe-079", "description": "Write a Python function to check if a given URL is considered safe based on its host and scheme."}
{"func_name": "RemoteZipHandler::extractZip", "func_src_before": "    public static void extractZip(File zipFile, File destDir) throws IOException\n    {\n        byte[] buffer = new byte[1024];\n        if (!destDir.exists())\n            destDir.mkdirs();\n\n        ZipInputStream zis = new ZipInputStream(new FileInputStream(zipFile));\n        ZipEntry ze = zis.getNextEntry();\n        try\n        {\n            while (ze != null)\n            {\n                String fileName = ze.getName();\n                File newFile = new File(destDir, fileName);\n                if (ze.isDirectory())\n                {\n                    if (newFile.exists())\n                        deleteDirAndContents(newFile);\n                    newFile.mkdirs();\n                }\n                else\n                {\n                    if (newFile.exists())\n                        newFile.delete();\n                    if (newFile.getParentFile() != null && !newFile.getParentFile().exists())\n                        newFile.getParentFile().mkdirs();\n                    FileOutputStream fos = new FileOutputStream(newFile);\n                    int len;\n                    while ((len = zis.read(buffer)) > 0)\n                        fos.write(buffer, 0, len);\n\n                    fos.close();\n                }\n                ze = zis.getNextEntry();\n            }\n        }\n        finally\n        {\n            zis.closeEntry();\n            zis.close();\n        }\n    }", "func_src_after": "    public static void extractZip(File zipFile, File destDir) throws IOException\n    {\n        byte[] buffer = new byte[1024];\n        if (!destDir.exists())\n            destDir.mkdirs();\n\n        ZipInputStream zis = new ZipInputStream(new FileInputStream(zipFile));\n        ZipEntry ze = zis.getNextEntry();\n        try\n        {\n            while (ze != null)\n            {\n                String fileName = ze.getName();\n                File newFile = new File(destDir, fileName);\n                if (!newFile.toPath().normalize().startsWith(destDir.toPath().normalize())) {\n                    throw new IOException(\"Bad zip entry\");\n                }\n                if (ze.isDirectory())\n                {\n                    if (newFile.exists())\n                        deleteDirAndContents(newFile);\n                    newFile.mkdirs();\n                }\n                else\n                {\n                    if (newFile.exists())\n                        newFile.delete();\n                    if (newFile.getParentFile() != null && !newFile.getParentFile().exists())\n                        newFile.getParentFile().mkdirs();\n                    FileOutputStream fos = new FileOutputStream(newFile);\n                    int len;\n                    while ((len = zis.read(buffer)) > 0)\n                        fos.write(buffer, 0, len);\n\n                    fos.close();\n                }\n                ze = zis.getNextEntry();\n            }\n        }\n        finally\n        {\n            zis.closeEntry();\n            zis.close();\n        }\n    }", "line_changes": {"deleted": [], "added": [{"line_no": 15, "char_start": 485, "char_end": 579, "line": "                if (!newFile.toPath().normalize().startsWith(destDir.toPath().normalize())) {\n"}, {"line_no": 16, "char_start": 579, "char_end": 639, "line": "                    throw new IOException(\"Bad zip entry\");\n"}, {"line_no": 17, "char_start": 639, "char_end": 657, "line": "                }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 485, "char_end": 657, "chars": "                if (!newFile.toPath().normalize().startsWith(destDir.toPath().normalize())) {\n                    throw new IOException(\"Bad zip entry\");\n                }\n"}]}, "commit_link": "github.com/bspkrs/MCPMappingViewer/commit/6e602746c96b4756c271d080dae7d22ad804a1bd", "file_name": "RemoteZipHandler.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "cc754ad6e8502fa02c35de0fffad83c1a1956a03", "description": "Write a Java function to extract the contents of a ZIP file to a specified directory."}
{"func_name": "_keyify", "func_src_before": "def _keyify(key):\n    return _key_pattern.sub(' ', key.lower())", "func_src_after": "def _keyify(key):\n    key = escape(key.lower(), quote=True)\n    return _key_pattern.sub(' ', key)", "commit_link": "github.com/lepture/mistune/commit/5f06d724bc05580e7f203db2d4a4905fc1127f98", "file_name": "mistune.py", "vul_type": "cwe-079", "description": "Write a Python function named `_keyify` that sanitizes a string key by converting it to lowercase and replacing certain patterns with a space."}
{"func_name": "dmi_memory_device_size_str", "func_src_before": "static char *dmi_memory_device_size_str(u16 code)\n{\n\tstatic char size[8];\n\n\tif (code == 0)\n\t\tstrcpy(size, \"Empty\");\n\telse if (code == 0xFFFF)\n\t\tstrcpy(size, \"Unknown\");\n\telse\n\t{\n\t\tif (code & 0x8000)\n\t\t\tsprintf(size, \"%u kB\", code & 0x7FFF);\n\t\telse\n\t\t\tsprintf(size, \"%u MB\", code);\n\t}\n\n\treturn size;\n}", "func_src_after": "static char *dmi_memory_device_size_str(u16 code)\n{\n\tstatic char size[16];\n\n\tif (code == 0)\n\t\tstrcpy(size, \"Empty\");\n\telse if (code == 0xFFFF)\n\t\tstrcpy(size, \"Unknown\");\n\telse\n\t{\n\t\tif (code & 0x8000)\n\t\t\tsprintf(size, \"%u kB\", code & 0x7FFF);\n\t\telse\n\t\t\tsprintf(size, \"%u MB\", code);\n\t}\n\n\treturn size;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 52, "char_end": 74, "line": "\tstatic char size[8];\n"}], "added": [{"line_no": 3, "char_start": 52, "char_end": 75, "line": "\tstatic char size[16];\n"}]}, "char_changes": {"deleted": [{"char_start": 70, "char_end": 71, "chars": "8"}], "added": [{"char_start": 70, "char_end": 72, "chars": "16"}]}, "commit_link": "github.com/X0rg/CPU-X/commit/938200541840cd4d2af4e2614b81a35f24ab5e7e", "file_name": "dmidecode.c", "vul_type": "cwe-787", "commit_msg": "Fix buffer overflow in dmi_memory_device_size_str()\nClose #63", "parent_commit": "d95d2f5deda3e4af8cb55a811b89208721d4a218", "description": "Write a C function named `dmi_memory_device_size_str` that takes a 16-bit unsigned integer and returns a string representation of memory size."}
{"func_name": "load_files", "func_src_before": "    def load_files(*file_paths)\n      files = (site_configs + file_paths).map { |f| Pathname.new(f) }\n      # TODO: Validate config state in some way.\n      configs = files.map { |file| YAML.load(file.read) }\n\n      load(*configs)\n    end", "func_src_after": "    def load_files(*file_paths)\n      files = (site_configs + file_paths).map { |f| Pathname.new(f) }\n      # TODO: Validate config state in some way.\n      configs = files.map { |file| YAML.safe_load(file.read) }\n\n      load(*configs)\n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 151, "char_end": 209, "line": "      configs = files.map { |file| YAML.load(file.read) }\n"}], "added": [{"line_no": 4, "char_start": 151, "char_end": 214, "line": "      configs = files.map { |file| YAML.safe_load(file.read) }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 191, "char_end": 196, "chars": "safe_"}]}, "commit_link": "github.com/duckinator/how_is/commit/2c816659422d4261e1fbb3be24af389d86930a01", "file_name": "config.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load, not YAML.load.", "parent_commit": "6317a8e8d18f8e49a0af02b8a031450a5695b1ef", "description": "Write a Ruby method to load configurations from file paths using YAML parsing."}
{"func_name": "lexer_process_char_literal", "func_src_before": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "func_src_after": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "commit_link": "github.com/jerryscript-project/jerryscript/commit/e58f2880df608652aff7fd35c45b242467ec0e79", "file_name": "jerry-core/parser/js/js-lexer.c", "vul_type": "cwe-476", "description": "In C, write a function to process character literals in a parser context, handling escape sequences and ensuring they don't exceed predefined limits."}
{"func_name": "getGameID", "func_src_before": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = %i\" % ID)\n\tID = db.fetchone()\n\treturn ID", "func_src_after": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = ?\", ID)\n\tID = db.fetchone()\n\treturn ID", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getGameID` that retrieves a game's record from a database by its ID using parameterized queries."}
{"func_name": "str_lower_case_match", "func_src_before": "str_lower_case_match(OnigEncoding enc, int case_fold_flag,\n                     const UChar* t, const UChar* tend,\n                     const UChar* p, const UChar* end)\n{\n  int lowlen;\n  UChar *q, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n  while (t < tend) {\n    lowlen = ONIGENC_MBC_CASE_FOLD(enc, case_fold_flag, &p, end, lowbuf);\n    q = lowbuf;\n    while (lowlen > 0) {\n      if (*t++ != *q++) return 0;\n      lowlen--;\n    }\n  }\n\n  return 1;\n}", "func_src_after": "str_lower_case_match(OnigEncoding enc, int case_fold_flag,\n                     const UChar* t, const UChar* tend,\n                     const UChar* p, const UChar* end)\n{\n  int lowlen;\n  UChar *q, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n  while (t < tend) {\n    lowlen = ONIGENC_MBC_CASE_FOLD(enc, case_fold_flag, &p, end, lowbuf);\n    q = lowbuf;\n    while (lowlen > 0) {\n      if (t >= tend)    return 0;\n      if (*t++ != *q++) return 0;\n      lowlen--;\n    }\n  }\n\n  return 1;\n}", "commit_link": "github.com/kkos/oniguruma/commit/d3e402928b6eb3327f8f7d59a9edfa622fec557b", "file_name": "src/regexec.c", "vul_type": "cwe-125", "description": "Write a C function named `str_lower_case_match` that compares two strings for equality, considering case insensitivity, using Oniguruma encoding functions."}
{"func_name": "(anonymous)", "func_src_before": "    cp.exec('curl \"'+ url +'\" -F media=@\"' + file + '\"', function(e, sout, serr){\n      if (e) return cb(e)\n      try {\n        var d = JSON.parse(sout)\n      } catch(e) {\n        return cb(e)\n      }\n      if (d.errcode) {\n        return cb(new Error(\n          d.errcode + ': ' + d.errmsg\n        ))\n      }\n      cb(null, d)\n    })", "func_src_after": "    cp.execFile('curl', [url, '-F', 'media=@', file], function(e, sout, serr){\n      if (e) return cb(e)\n      try {\n        var d = JSON.parse(sout)\n      } catch(e) {\n        return cb(e)\n      }\n      if (d.errcode) {\n        return cb(new Error(\n          d.errcode + ': ' + d.errmsg\n        ))\n      }\n      cb(null, d)\n    })", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 82, "line": "    cp.exec('curl \"'+ url +'\" -F media=@\"' + file + '\"', function(e, sout, serr){\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 79, "line": "    cp.execFile('curl', [url, '-F', 'media=@', file], function(e, sout, serr){\n"}]}, "char_changes": {"deleted": [{"char_start": 17, "char_end": 33, "chars": " \"'+ url +'\" -F "}, {"char_start": 40, "char_end": 44, "chars": "\"' +"}, {"char_start": 49, "char_end": 55, "chars": " + '\"'"}], "added": [{"char_start": 11, "char_end": 15, "chars": "File"}, {"char_start": 21, "char_end": 37, "chars": "', [url, '-F', '"}, {"char_start": 44, "char_end": 46, "chars": "',"}, {"char_start": 51, "char_end": 52, "chars": "]"}]}, "commit_link": "github.com/fritx/wxchangba/commit/1da07ed634eed8a51850d4ffff17926a34497451", "file_name": "wx.js", "vul_type": "cwe-078", "commit_msg": "Update wx.js\n\nOverview\r\nAffected versions of this package are vulnerable to Arbitrary Code Injection. The package does not validate user input for the reqPostMaterial function, thereby passing unsanitized contents of the file parameter to an exec call. This could potentially allow attackers to run arbitrary commands in the system.\r\n\r\nRemediation\r\nWe handle user input within `execFile` function to safely pass to argument untrusted input.\r\n\r\nReferences\r\n031-JS-WXCHANGBA", "description": "Write a Node.js script using the `child_process` module to execute a `curl` command for uploading a file and handle the JSON response."}
{"func_name": "read_entry", "func_src_before": "static int read_entry(\n\tgit_index_entry **out,\n\tsize_t *out_size,\n\tgit_index *index,\n\tconst void *buffer,\n\tsize_t buffer_size,\n\tconst char *last)\n{\n\tsize_t path_length, entry_size;\n\tconst char *path_ptr;\n\tstruct entry_short source;\n\tgit_index_entry entry = {{0}};\n\tbool compressed = index->version >= INDEX_VERSION_NUMBER_COMP;\n\tchar *tmp_path = NULL;\n\n\tif (INDEX_FOOTER_SIZE + minimal_entry_size > buffer_size)\n\t\treturn -1;\n\n\t/* buffer is not guaranteed to be aligned */\n\tmemcpy(&source, buffer, sizeof(struct entry_short));\n\n\tentry.ctime.seconds = (git_time_t)ntohl(source.ctime.seconds);\n\tentry.ctime.nanoseconds = ntohl(source.ctime.nanoseconds);\n\tentry.mtime.seconds = (git_time_t)ntohl(source.mtime.seconds);\n\tentry.mtime.nanoseconds = ntohl(source.mtime.nanoseconds);\n\tentry.dev = ntohl(source.dev);\n\tentry.ino = ntohl(source.ino);\n\tentry.mode = ntohl(source.mode);\n\tentry.uid = ntohl(source.uid);\n\tentry.gid = ntohl(source.gid);\n\tentry.file_size = ntohl(source.file_size);\n\tgit_oid_cpy(&entry.id, &source.oid);\n\tentry.flags = ntohs(source.flags);\n\n\tif (entry.flags & GIT_IDXENTRY_EXTENDED) {\n\t\tuint16_t flags_raw;\n\t\tsize_t flags_offset;\n\n\t\tflags_offset = offsetof(struct entry_long, flags_extended);\n\t\tmemcpy(&flags_raw, (const char *) buffer + flags_offset,\n\t\t\tsizeof(flags_raw));\n\t\tflags_raw = ntohs(flags_raw);\n\n\t\tmemcpy(&entry.flags_extended, &flags_raw, sizeof(flags_raw));\n\t\tpath_ptr = (const char *) buffer + offsetof(struct entry_long, path);\n\t} else\n\t\tpath_ptr = (const char *) buffer + offsetof(struct entry_short, path);\n\n\tif (!compressed) {\n\t\tpath_length = entry.flags & GIT_IDXENTRY_NAMEMASK;\n\n\t\t/* if this is a very long string, we must find its\n\t\t * real length without overflowing */\n\t\tif (path_length == 0xFFF) {\n\t\t\tconst char *path_end;\n\n\t\t\tpath_end = memchr(path_ptr, '\\0', buffer_size);\n\t\t\tif (path_end == NULL)\n\t\t\t\treturn -1;\n\n\t\t\tpath_length = path_end - path_ptr;\n\t\t}\n\n\t\tentry_size = index_entry_size(path_length, 0, entry.flags);\n\t\tentry.path = (char *)path_ptr;\n\t} else {\n\t\tsize_t varint_len;\n\t\tsize_t strip_len = git_decode_varint((const unsigned char *)path_ptr,\n\t\t\t\t\t\t     &varint_len);\n\t\tsize_t last_len = strlen(last);\n\t\tsize_t prefix_len = last_len - strip_len;\n\t\tsize_t suffix_len = strlen(path_ptr + varint_len);\n\t\tsize_t path_len;\n\n\t\tif (varint_len == 0)\n\t\t\treturn index_error_invalid(\"incorrect prefix length\");\n\n\t\tGITERR_CHECK_ALLOC_ADD(&path_len, prefix_len, suffix_len);\n\t\tGITERR_CHECK_ALLOC_ADD(&path_len, path_len, 1);\n\t\ttmp_path = git__malloc(path_len);\n\t\tGITERR_CHECK_ALLOC(tmp_path);\n\n\t\tmemcpy(tmp_path, last, prefix_len);\n\t\tmemcpy(tmp_path + prefix_len, path_ptr + varint_len, suffix_len + 1);\n\t\tentry_size = index_entry_size(suffix_len, varint_len, entry.flags);\n\t\tentry.path = tmp_path;\n\t}\n\n\tif (entry_size == 0)\n\t\treturn -1;\n\n\tif (INDEX_FOOTER_SIZE + entry_size > buffer_size)\n\t\treturn -1;\n\n\tif (index_entry_dup(out, index, &entry) < 0) {\n\t\tgit__free(tmp_path);\n\t\treturn -1;\n\t}\n\n\tgit__free(tmp_path);\n\t*out_size = entry_size;\n\treturn 0;\n}", "func_src_after": "static int read_entry(\n\tgit_index_entry **out,\n\tsize_t *out_size,\n\tgit_index *index,\n\tconst void *buffer,\n\tsize_t buffer_size,\n\tconst char *last)\n{\n\tsize_t path_length, entry_size;\n\tconst char *path_ptr;\n\tstruct entry_short source;\n\tgit_index_entry entry = {{0}};\n\tbool compressed = index->version >= INDEX_VERSION_NUMBER_COMP;\n\tchar *tmp_path = NULL;\n\n\tif (INDEX_FOOTER_SIZE + minimal_entry_size > buffer_size)\n\t\treturn -1;\n\n\t/* buffer is not guaranteed to be aligned */\n\tmemcpy(&source, buffer, sizeof(struct entry_short));\n\n\tentry.ctime.seconds = (git_time_t)ntohl(source.ctime.seconds);\n\tentry.ctime.nanoseconds = ntohl(source.ctime.nanoseconds);\n\tentry.mtime.seconds = (git_time_t)ntohl(source.mtime.seconds);\n\tentry.mtime.nanoseconds = ntohl(source.mtime.nanoseconds);\n\tentry.dev = ntohl(source.dev);\n\tentry.ino = ntohl(source.ino);\n\tentry.mode = ntohl(source.mode);\n\tentry.uid = ntohl(source.uid);\n\tentry.gid = ntohl(source.gid);\n\tentry.file_size = ntohl(source.file_size);\n\tgit_oid_cpy(&entry.id, &source.oid);\n\tentry.flags = ntohs(source.flags);\n\n\tif (entry.flags & GIT_IDXENTRY_EXTENDED) {\n\t\tuint16_t flags_raw;\n\t\tsize_t flags_offset;\n\n\t\tflags_offset = offsetof(struct entry_long, flags_extended);\n\t\tmemcpy(&flags_raw, (const char *) buffer + flags_offset,\n\t\t\tsizeof(flags_raw));\n\t\tflags_raw = ntohs(flags_raw);\n\n\t\tmemcpy(&entry.flags_extended, &flags_raw, sizeof(flags_raw));\n\t\tpath_ptr = (const char *) buffer + offsetof(struct entry_long, path);\n\t} else\n\t\tpath_ptr = (const char *) buffer + offsetof(struct entry_short, path);\n\n\tif (!compressed) {\n\t\tpath_length = entry.flags & GIT_IDXENTRY_NAMEMASK;\n\n\t\t/* if this is a very long string, we must find its\n\t\t * real length without overflowing */\n\t\tif (path_length == 0xFFF) {\n\t\t\tconst char *path_end;\n\n\t\t\tpath_end = memchr(path_ptr, '\\0', buffer_size);\n\t\t\tif (path_end == NULL)\n\t\t\t\treturn -1;\n\n\t\t\tpath_length = path_end - path_ptr;\n\t\t}\n\n\t\tentry_size = index_entry_size(path_length, 0, entry.flags);\n\t\tentry.path = (char *)path_ptr;\n\t} else {\n\t\tsize_t varint_len, last_len, prefix_len, suffix_len, path_len;\n\t\tuintmax_t strip_len;\n\n\t\tstrip_len = git_decode_varint((const unsigned char *)path_ptr, &varint_len);\n\t\tlast_len = strlen(last);\n\n\t\tif (varint_len == 0 || last_len < strip_len)\n\t\t\treturn index_error_invalid(\"incorrect prefix length\");\n\n\t\tprefix_len = last_len - strip_len;\n\t\tsuffix_len = strlen(path_ptr + varint_len);\n\n\t\tGITERR_CHECK_ALLOC_ADD(&path_len, prefix_len, suffix_len);\n\t\tGITERR_CHECK_ALLOC_ADD(&path_len, path_len, 1);\n\t\ttmp_path = git__malloc(path_len);\n\t\tGITERR_CHECK_ALLOC(tmp_path);\n\n\t\tmemcpy(tmp_path, last, prefix_len);\n\t\tmemcpy(tmp_path + prefix_len, path_ptr + varint_len, suffix_len + 1);\n\t\tentry_size = index_entry_size(suffix_len, varint_len, entry.flags);\n\t\tentry.path = tmp_path;\n\t}\n\n\tif (entry_size == 0)\n\t\treturn -1;\n\n\tif (INDEX_FOOTER_SIZE + entry_size > buffer_size)\n\t\treturn -1;\n\n\tif (index_entry_dup(out, index, &entry) < 0) {\n\t\tgit__free(tmp_path);\n\t\treturn -1;\n\t}\n\n\tgit__free(tmp_path);\n\t*out_size = entry_size;\n\treturn 0;\n}", "commit_link": "github.com/libgit2/libgit2/commit/3207ddb0103543da8ad2139ec6539f590f9900c1", "file_name": "src/index.c", "vul_type": "cwe-190", "description": "Write a C function named `read_entry` that parses a git index entry from a buffer and stores the result."}
{"func_name": "stralgoLCS", "func_src_before": "void stralgoLCS(client *c) {\n    uint32_t i, j;\n    long long minmatchlen = 0;\n    sds a = NULL, b = NULL;\n    int getlen = 0, getidx = 0, withmatchlen = 0;\n    robj *obja = NULL, *objb = NULL;\n\n    for (j = 2; j < (uint32_t)c->argc; j++) {\n        char *opt = c->argv[j]->ptr;\n        int moreargs = (c->argc-1) - j;\n\n        if (!strcasecmp(opt,\"IDX\")) {\n            getidx = 1;\n        } else if (!strcasecmp(opt,\"LEN\")) {\n            getlen = 1;\n        } else if (!strcasecmp(opt,\"WITHMATCHLEN\")) {\n            withmatchlen = 1;\n        } else if (!strcasecmp(opt,\"MINMATCHLEN\") && moreargs) {\n            if (getLongLongFromObjectOrReply(c,c->argv[j+1],&minmatchlen,NULL)\n                != C_OK) goto cleanup;\n            if (minmatchlen < 0) minmatchlen = 0;\n            j++;\n        } else if (!strcasecmp(opt,\"STRINGS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            a = c->argv[j+1]->ptr;\n            b = c->argv[j+2]->ptr;\n            j += 2;\n        } else if (!strcasecmp(opt,\"KEYS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            obja = lookupKeyRead(c->db,c->argv[j+1]);\n            objb = lookupKeyRead(c->db,c->argv[j+2]);\n            if ((obja && obja->type != OBJ_STRING) ||\n                (objb && objb->type != OBJ_STRING))\n            {\n                addReplyError(c,\n                    \"The specified keys must contain string values\");\n                /* Don't cleanup the objects, we need to do that\n                 * only after calling getDecodedObject(). */\n                obja = NULL;\n                objb = NULL;\n                goto cleanup;\n            }\n            obja = obja ? getDecodedObject(obja) : createStringObject(\"\",0);\n            objb = objb ? getDecodedObject(objb) : createStringObject(\"\",0);\n            a = obja->ptr;\n            b = objb->ptr;\n            j += 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            goto cleanup;\n        }\n    }\n\n    /* Complain if the user passed ambiguous parameters. */\n    if (a == NULL) {\n        addReplyError(c,\"Please specify two strings: \"\n                        \"STRINGS or KEYS options are mandatory\");\n        goto cleanup;\n    } else if (getlen && getidx) {\n        addReplyError(c,\n            \"If you want both the length and indexes, please \"\n            \"just use IDX.\");\n        goto cleanup;\n    }\n\n    /* Compute the LCS using the vanilla dynamic programming technique of\n     * building a table of LCS(x,y) substrings. */\n    uint32_t alen = sdslen(a);\n    uint32_t blen = sdslen(b);\n\n    /* Setup an uint32_t array to store at LCS[i,j] the length of the\n     * LCS A0..i-1, B0..j-1. Note that we have a linear array here, so\n     * we index it as LCS[j+(blen+1)*j] */\n    uint32_t *lcs = zmalloc((alen+1)*(blen+1)*sizeof(uint32_t));\n    #define LCS(A,B) lcs[(B)+((A)*(blen+1))]\n\n    /* Start building the LCS table. */\n    for (uint32_t i = 0; i <= alen; i++) {\n        for (uint32_t j = 0; j <= blen; j++) {\n            if (i == 0 || j == 0) {\n                /* If one substring has length of zero, the\n                 * LCS length is zero. */\n                LCS(i,j) = 0;\n            } else if (a[i-1] == b[j-1]) {\n                /* The len LCS (and the LCS itself) of two\n                 * sequences with the same final character, is the\n                 * LCS of the two sequences without the last char\n                 * plus that last char. */\n                LCS(i,j) = LCS(i-1,j-1)+1;\n            } else {\n                /* If the last character is different, take the longest\n                 * between the LCS of the first string and the second\n                 * minus the last char, and the reverse. */\n                uint32_t lcs1 = LCS(i-1,j);\n                uint32_t lcs2 = LCS(i,j-1);\n                LCS(i,j) = lcs1 > lcs2 ? lcs1 : lcs2;\n            }\n        }\n    }\n\n    /* Store the actual LCS string in \"result\" if needed. We create\n     * it backward, but the length is already known, we store it into idx. */\n    uint32_t idx = LCS(alen,blen);\n    sds result = NULL;        /* Resulting LCS string. */\n    void *arraylenptr = NULL; /* Deferred length of the array for IDX. */\n    uint32_t arange_start = alen, /* alen signals that values are not set. */\n             arange_end = 0,\n             brange_start = 0,\n             brange_end = 0;\n\n    /* Do we need to compute the actual LCS string? Allocate it in that case. */\n    int computelcs = getidx || !getlen;\n    if (computelcs) result = sdsnewlen(SDS_NOINIT,idx);\n\n    /* Start with a deferred array if we have to emit the ranges. */\n    uint32_t arraylen = 0;  /* Number of ranges emitted in the array. */\n    if (getidx) {\n        addReplyMapLen(c,2);\n        addReplyBulkCString(c,\"matches\");\n        arraylenptr = addReplyDeferredLen(c);\n    }\n\n    i = alen, j = blen;\n    while (computelcs && i > 0 && j > 0) {\n        int emit_range = 0;\n        if (a[i-1] == b[j-1]) {\n            /* If there is a match, store the character and reduce\n             * the indexes to look for a new match. */\n            result[idx-1] = a[i-1];\n\n            /* Track the current range. */\n            if (arange_start == alen) {\n                arange_start = i-1;\n                arange_end = i-1;\n                brange_start = j-1;\n                brange_end = j-1;\n            } else {\n                /* Let's see if we can extend the range backward since\n                 * it is contiguous. */\n                if (arange_start == i && brange_start == j) {\n                    arange_start--;\n                    brange_start--;\n                } else {\n                    emit_range = 1;\n                }\n            }\n            /* Emit the range if we matched with the first byte of\n             * one of the two strings. We'll exit the loop ASAP. */\n            if (arange_start == 0 || brange_start == 0) emit_range = 1;\n            idx--; i--; j--;\n        } else {\n            /* Otherwise reduce i and j depending on the largest\n             * LCS between, to understand what direction we need to go. */\n            uint32_t lcs1 = LCS(i-1,j);\n            uint32_t lcs2 = LCS(i,j-1);\n            if (lcs1 > lcs2)\n                i--;\n            else\n                j--;\n            if (arange_start != alen) emit_range = 1;\n        }\n\n        /* Emit the current range if needed. */\n        uint32_t match_len = arange_end - arange_start + 1;\n        if (emit_range) {\n            if (minmatchlen == 0 || match_len >= minmatchlen) {\n                if (arraylenptr) {\n                    addReplyArrayLen(c,2+withmatchlen);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,arange_start);\n                    addReplyLongLong(c,arange_end);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,brange_start);\n                    addReplyLongLong(c,brange_end);\n                    if (withmatchlen) addReplyLongLong(c,match_len);\n                    arraylen++;\n                }\n            }\n            arange_start = alen; /* Restart at the next match. */\n        }\n    }\n\n    /* Signal modified key, increment dirty, ... */\n\n    /* Reply depending on the given options. */\n    if (arraylenptr) {\n        addReplyBulkCString(c,\"len\");\n        addReplyLongLong(c,LCS(alen,blen));\n        setDeferredArrayLen(c,arraylenptr,arraylen);\n    } else if (getlen) {\n        addReplyLongLong(c,LCS(alen,blen));\n    } else {\n        addReplyBulkSds(c,result);\n        result = NULL;\n    }\n\n    /* Cleanup. */\n    sdsfree(result);\n    zfree(lcs);\n\ncleanup:\n    if (obja) decrRefCount(obja);\n    if (objb) decrRefCount(objb);\n    return;\n}", "func_src_after": "void stralgoLCS(client *c) {\n    uint32_t i, j;\n    long long minmatchlen = 0;\n    sds a = NULL, b = NULL;\n    int getlen = 0, getidx = 0, withmatchlen = 0;\n    robj *obja = NULL, *objb = NULL;\n\n    for (j = 2; j < (uint32_t)c->argc; j++) {\n        char *opt = c->argv[j]->ptr;\n        int moreargs = (c->argc-1) - j;\n\n        if (!strcasecmp(opt,\"IDX\")) {\n            getidx = 1;\n        } else if (!strcasecmp(opt,\"LEN\")) {\n            getlen = 1;\n        } else if (!strcasecmp(opt,\"WITHMATCHLEN\")) {\n            withmatchlen = 1;\n        } else if (!strcasecmp(opt,\"MINMATCHLEN\") && moreargs) {\n            if (getLongLongFromObjectOrReply(c,c->argv[j+1],&minmatchlen,NULL)\n                != C_OK) goto cleanup;\n            if (minmatchlen < 0) minmatchlen = 0;\n            j++;\n        } else if (!strcasecmp(opt,\"STRINGS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            a = c->argv[j+1]->ptr;\n            b = c->argv[j+2]->ptr;\n            j += 2;\n        } else if (!strcasecmp(opt,\"KEYS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            obja = lookupKeyRead(c->db,c->argv[j+1]);\n            objb = lookupKeyRead(c->db,c->argv[j+2]);\n            if ((obja && obja->type != OBJ_STRING) ||\n                (objb && objb->type != OBJ_STRING))\n            {\n                addReplyError(c,\n                    \"The specified keys must contain string values\");\n                /* Don't cleanup the objects, we need to do that\n                 * only after calling getDecodedObject(). */\n                obja = NULL;\n                objb = NULL;\n                goto cleanup;\n            }\n            obja = obja ? getDecodedObject(obja) : createStringObject(\"\",0);\n            objb = objb ? getDecodedObject(objb) : createStringObject(\"\",0);\n            a = obja->ptr;\n            b = objb->ptr;\n            j += 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            goto cleanup;\n        }\n    }\n\n    /* Complain if the user passed ambiguous parameters. */\n    if (a == NULL) {\n        addReplyError(c,\"Please specify two strings: \"\n                        \"STRINGS or KEYS options are mandatory\");\n        goto cleanup;\n    } else if (getlen && getidx) {\n        addReplyError(c,\n            \"If you want both the length and indexes, please \"\n            \"just use IDX.\");\n        goto cleanup;\n    }\n\n    /* Compute the LCS using the vanilla dynamic programming technique of\n     * building a table of LCS(x,y) substrings. */\n    uint32_t alen = sdslen(a);\n    uint32_t blen = sdslen(b);\n\n    /* Setup an uint32_t array to store at LCS[i,j] the length of the\n     * LCS A0..i-1, B0..j-1. Note that we have a linear array here, so\n     * we index it as LCS[j+(blen+1)*j] */\n    uint32_t *lcs = zmalloc((size_t)(alen+1)*(blen+1)*sizeof(uint32_t));\n    #define LCS(A,B) lcs[(B)+((A)*(blen+1))]\n\n    /* Start building the LCS table. */\n    for (uint32_t i = 0; i <= alen; i++) {\n        for (uint32_t j = 0; j <= blen; j++) {\n            if (i == 0 || j == 0) {\n                /* If one substring has length of zero, the\n                 * LCS length is zero. */\n                LCS(i,j) = 0;\n            } else if (a[i-1] == b[j-1]) {\n                /* The len LCS (and the LCS itself) of two\n                 * sequences with the same final character, is the\n                 * LCS of the two sequences without the last char\n                 * plus that last char. */\n                LCS(i,j) = LCS(i-1,j-1)+1;\n            } else {\n                /* If the last character is different, take the longest\n                 * between the LCS of the first string and the second\n                 * minus the last char, and the reverse. */\n                uint32_t lcs1 = LCS(i-1,j);\n                uint32_t lcs2 = LCS(i,j-1);\n                LCS(i,j) = lcs1 > lcs2 ? lcs1 : lcs2;\n            }\n        }\n    }\n\n    /* Store the actual LCS string in \"result\" if needed. We create\n     * it backward, but the length is already known, we store it into idx. */\n    uint32_t idx = LCS(alen,blen);\n    sds result = NULL;        /* Resulting LCS string. */\n    void *arraylenptr = NULL; /* Deferred length of the array for IDX. */\n    uint32_t arange_start = alen, /* alen signals that values are not set. */\n             arange_end = 0,\n             brange_start = 0,\n             brange_end = 0;\n\n    /* Do we need to compute the actual LCS string? Allocate it in that case. */\n    int computelcs = getidx || !getlen;\n    if (computelcs) result = sdsnewlen(SDS_NOINIT,idx);\n\n    /* Start with a deferred array if we have to emit the ranges. */\n    uint32_t arraylen = 0;  /* Number of ranges emitted in the array. */\n    if (getidx) {\n        addReplyMapLen(c,2);\n        addReplyBulkCString(c,\"matches\");\n        arraylenptr = addReplyDeferredLen(c);\n    }\n\n    i = alen, j = blen;\n    while (computelcs && i > 0 && j > 0) {\n        int emit_range = 0;\n        if (a[i-1] == b[j-1]) {\n            /* If there is a match, store the character and reduce\n             * the indexes to look for a new match. */\n            result[idx-1] = a[i-1];\n\n            /* Track the current range. */\n            if (arange_start == alen) {\n                arange_start = i-1;\n                arange_end = i-1;\n                brange_start = j-1;\n                brange_end = j-1;\n            } else {\n                /* Let's see if we can extend the range backward since\n                 * it is contiguous. */\n                if (arange_start == i && brange_start == j) {\n                    arange_start--;\n                    brange_start--;\n                } else {\n                    emit_range = 1;\n                }\n            }\n            /* Emit the range if we matched with the first byte of\n             * one of the two strings. We'll exit the loop ASAP. */\n            if (arange_start == 0 || brange_start == 0) emit_range = 1;\n            idx--; i--; j--;\n        } else {\n            /* Otherwise reduce i and j depending on the largest\n             * LCS between, to understand what direction we need to go. */\n            uint32_t lcs1 = LCS(i-1,j);\n            uint32_t lcs2 = LCS(i,j-1);\n            if (lcs1 > lcs2)\n                i--;\n            else\n                j--;\n            if (arange_start != alen) emit_range = 1;\n        }\n\n        /* Emit the current range if needed. */\n        uint32_t match_len = arange_end - arange_start + 1;\n        if (emit_range) {\n            if (minmatchlen == 0 || match_len >= minmatchlen) {\n                if (arraylenptr) {\n                    addReplyArrayLen(c,2+withmatchlen);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,arange_start);\n                    addReplyLongLong(c,arange_end);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,brange_start);\n                    addReplyLongLong(c,brange_end);\n                    if (withmatchlen) addReplyLongLong(c,match_len);\n                    arraylen++;\n                }\n            }\n            arange_start = alen; /* Restart at the next match. */\n        }\n    }\n\n    /* Signal modified key, increment dirty, ... */\n\n    /* Reply depending on the given options. */\n    if (arraylenptr) {\n        addReplyBulkCString(c,\"len\");\n        addReplyLongLong(c,LCS(alen,blen));\n        setDeferredArrayLen(c,arraylenptr,arraylen);\n    } else if (getlen) {\n        addReplyLongLong(c,LCS(alen,blen));\n    } else {\n        addReplyBulkSds(c,result);\n        result = NULL;\n    }\n\n    /* Cleanup. */\n    sdsfree(result);\n    zfree(lcs);\n\ncleanup:\n    if (obja) decrRefCount(obja);\n    if (objb) decrRefCount(objb);\n    return;\n}", "line_changes": {"deleted": [{"line_no": 80, "char_start": 2951, "char_end": 3016, "line": "    uint32_t *lcs = zmalloc((alen+1)*(blen+1)*sizeof(uint32_t));\n"}], "added": [{"line_no": 80, "char_start": 2951, "char_end": 3024, "line": "    uint32_t *lcs = zmalloc((size_t)(alen+1)*(blen+1)*sizeof(uint32_t));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2980, "char_end": 2988, "chars": "size_t)("}]}, "commit_link": "github.com/oranagra/redis/commit/f0c5f920d0f88bd8aa376a2c05af4902789d1ef9", "file_name": "t_string.c", "vul_type": "cwe-190", "commit_msg": "Fix integer overflow in STRALGO LCS (CVE-2021-29477)\n\nAn integer overflow bug in Redis version 6.0 or newer could be exploited using\nthe STRALGO LCS command to corrupt the heap and potentially result with remote\ncode execution.", "parent_commit": "29900d4e6bccdf3691bedf0ea9a5d84863fa3592", "description": "Write a C function named `stralgoLCS` that computes the longest common subsequence (LCS) of two strings."}
{"func_name": "renderPreviewLink", "func_src_before": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "func_src_after": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 173, "char_end": 283, "line": "      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}], "added": [{"line_no": 6, "char_start": 173, "char_end": 309, "line": "      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 210, "char_end": 236, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/maputnik/editor/commit/3f350c30da0791f542909f665f381e509e68c6c1", "file_name": "ExportModal.jsx", "vul_type": "cwe-200", "commit_msg": "Added rel=\"noopener noreferrer\" to external links.", "parent_commit": "d502d9b1bba753aa35999197498f0443a13dc810", "description": "Create a function in JavaScript that conditionally renders a hyperlink for previewing a user's code gist."}
{"func_name": "register_user", "func_src_before": "def register_user(request):\n    settings = request.registry.settings\n    if not is_registration_enabled(settings):\n        raise exc.exception_response(503)\n    handle_history(request)\n    _ = request.translate\n    config = Config(load(get_path_to_form_config('auth.xml', 'ringo')))\n    form_config = config.get_form('register_user')\n    form = Form(form_config, csrf_token=request.session.get_csrf_token())\n    # Do extra validation which is not handled by formbar.\n    # Is the login unique?\n    validator = Validator('login',\n                          'There is already a user with this name',\n                          is_login_unique)\n    form.add_validator(validator)\n    if request.POST:\n        if form.validate(request.params.mixed()):\n            # 1. Create user. Do not activate him. Default role is user.\n            ufac = User.get_item_factory()\n            # TODO: Check why we not use the get_item_factory_method\n            # here. Do we use plain factories because the need full\n            # controll of depended relations? (ti) <2014-04-08 17:07> \n            pfac = BaseFactory(Profile)\n            gfac = BaseFactory(Usergroup)\n            user = ufac.create(None)\n            # Set login from formdata\n            user.login = form.data['login']\n            # Encrypt password and save\n            pw = hashlib.md5()\n            pw.update(form.data['pass'])\n            user.password = pw.hexdigest()\n            # Deactivate the user. To activate the user needs to confirm\n            # with the activation link\n            user.activated = False\n            atoken = str(uuid.uuid4())\n            user.activation_token = atoken\n            # Set profile data\n            user.profile[0].email = form.data['email']\n            # Set user group\n            group = gfac.load(USER_GROUP_ID)\n            user.groups.append(group)\n            # Set default user group.\n            user.gid = group.id\n            DBSession.add(user)\n\n            # 3. Send confirmation email. The user will be activated\n            #    after the user clicks on the confirmation link\n            mailer = Mailer(request)\n            recipient = user.profile[0].email\n            subject = _('Confirm user registration for %s' % get_app_name())\n            values = {'url': request.route_url('confirm_user', token=atoken),\n                      'app_name': get_app_name(),\n                      'email': settings['mail.default_sender'],\n                      '_': _}\n            mail = Mail([recipient], subject, template=\"register_user\", values=values)\n            mailer.send(mail)\n\n            target_url = request.route_path('login')\n            headers = forget(request)\n            msg = _(\"User has been created and a confirmation mail was sent\"\n                    \" to the users email adress. Please check your email :)\")\n            request.session.flash(msg, 'success')\n            return HTTPFound(location=target_url, headers=headers)\n    return {'form': form.render()}", "func_src_after": "def register_user(request):\n    settings = request.registry.settings\n    if not is_registration_enabled(settings):\n        raise exc.exception_response(503)\n    handle_history(request)\n    _ = request.translate\n    config = Config(load(get_path_to_form_config('auth.xml', 'ringo')))\n    form_config = config.get_form('register_user')\n    form = Form(form_config, csrf_token=request.session.get_csrf_token())\n    # Do extra validation which is not handled by formbar.\n    # Is the login unique?\n    validator = Validator('login',\n                          'There is already a user with this name',\n                          is_login_unique)\n    form.add_validator(validator)\n    if request.POST:\n        if form.validate(request.params.mixed()):\n            # 1. Create user. Do not activate him. Default role is user.\n            ufac = User.get_item_factory()\n            # TODO: Check why we not use the get_item_factory_method\n            # here. Do we use plain factories because the need full\n            # controll of depended relations? (ti) <2014-04-08 17:07> \n            pfac = BaseFactory(Profile)\n            gfac = BaseFactory(Usergroup)\n            user = ufac.create(None)\n            # Set login from formdata\n            user.login = form.data['login']\n            # Encrypt password and save\n            user.password = encrypt_password(form.data['pass'])\n            # Deactivate the user. To activate the user needs to confirm\n            # with the activation link\n            user.activated = False\n            atoken = str(uuid.uuid4())\n            user.activation_token = atoken\n            # Set profile data\n            user.profile[0].email = form.data['email']\n            # Set user group\n            group = gfac.load(USER_GROUP_ID)\n            user.groups.append(group)\n            # Set default user group.\n            user.gid = group.id\n            DBSession.add(user)\n\n            # 3. Send confirmation email. The user will be activated\n            #    after the user clicks on the confirmation link\n            mailer = Mailer(request)\n            recipient = user.profile[0].email\n            subject = _('Confirm user registration for %s' % get_app_name())\n            values = {'url': request.route_url('confirm_user', token=atoken),\n                      'app_name': get_app_name(),\n                      'email': settings['mail.default_sender'],\n                      '_': _}\n            mail = Mail([recipient], subject, template=\"register_user\", values=values)\n            mailer.send(mail)\n\n            target_url = request.route_path('login')\n            headers = forget(request)\n            msg = _(\"User has been created and a confirmation mail was sent\"\n                    \" to the users email adress. Please check your email :)\")\n            request.session.flash(msg, 'success')\n            return HTTPFound(location=target_url, headers=headers)\n    return {'form': form.render()}", "line_changes": {"deleted": [{"line_no": 29, "char_start": 1310, "char_end": 1341, "line": "            pw = hashlib.md5()\n"}, {"line_no": 30, "char_start": 1341, "char_end": 1382, "line": "            pw.update(form.data['pass'])\n"}, {"line_no": 31, "char_start": 1382, "char_end": 1425, "line": "            user.password = pw.hexdigest()\n"}], "added": [{"line_no": 29, "char_start": 1310, "char_end": 1374, "line": "            user.password = encrypt_password(form.data['pass'])\n"}]}, "char_changes": {"deleted": [{"char_start": 1322, "char_end": 1423, "chars": "pw = hashlib.md5()\n            pw.update(form.data['pass'])\n            user.password = pw.hexdigest("}], "added": [{"char_start": 1322, "char_end": 1372, "chars": "user.password = encrypt_password(form.data['pass']"}]}, "commit_link": "github.com/ringo-framework/ringo/commit/ddb9d55999151f37fd4c833a98d2f34648757293", "file_name": "auth.py", "vul_type": "cwe-327", "commit_msg": "Replaced use of the old hashlib.md5 method for password encryption with new encryption methods using passlib", "parent_commit": "8e92641fee542f6e7004e827136dea3ce5e99eb2", "description": "Write a Python function to handle user registration, including form validation, user creation, and sending a confirmation email."}
{"func_name": "_pwd.toString", "func_src_before": "    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  if (fs.existsSync(codeFile)) common.unlinkSync(codeFile);\n  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n  if (fs.existsSync(stderrFile)) common.unlinkSync(stderrFile);\n  if (fs.existsSync(stdoutFile)) common.unlinkSync(stdoutFile);\n\n  opts.cwd = path.resolve(opts.cwd);\n\n  var paramsToSerialize = {\n    command: cmd,\n    execOptions: opts,\n    pipe: pipe,\n    stdoutFile: stdoutFile,\n    stderrFile: stderrFile,\n    codeFile: codeFile,\n  };\n\n  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n\n  var execCommand = [\n    JSON.stringify(common.config.execPath),\n    JSON.stringify(path.join(__dirname, 'exec-child.js')),\n    JSON.stringify(paramsFile),\n  ].join(' ');\n\n  /* istanbul ignore else */\n  if (opts.silent) {\n    opts.stdio = 'ignore';\n  } else {\n    opts.stdio = [0, 1, 2];\n  }\n\n  // Welcome to the future\n  try {\n    child.execSync(execCommand, opts);\n  } catch (e) {\n    // Clean up immediately if we have an exception\n    try { common.unlinkSync(codeFile); } catch (e2) {}\n    try { common.unlinkSync(paramsFile); } catch (e2) {}\n    try { common.unlinkSync(stderrFile); } catch (e2) {}\n    try { common.unlinkSync(stdoutFile); } catch (e2) {}\n    throw e;\n  }\n\n  // At this point codeFile exists, but it's not necessarily flushed yet.\n  // Keep reading it until it is.\n  var code = parseInt('', 10);\n  while (isNaN(code)) {\n    code = parseInt(fs.readFileSync(codeFile, 'utf8'), 10);\n  }\n\n  // fs.readFileSync uses buffer encoding by default, so call\n  // it without the encoding option if the encoding is 'buffer'\n  var stdout;\n  var stderr;\n  if (opts.encoding === 'buffer') {\n    stdout = fs.readFileSync(stdoutFile);\n    stderr = fs.readFileSync(stderrFile);\n  } else {\n    stdout = fs.readFileSync(stdoutFile, opts.encoding);\n    stderr = fs.readFileSync(stderrFile, opts.encoding);\n  }\n\n  // No biggie if we can't erase the files now -- they're in a temp dir anyway\n  try { common.unlinkSync(codeFile); } catch (e) {}\n  try { common.unlinkSync(paramsFile); } catch (e) {}\n  try { common.unlinkSync(stderrFile); } catch (e) {}\n  try { common.unlinkSync(stdoutFile); } catch (e) {}\n\n  if (code !== 0) {\n    common.error('', code, { continue: true });\n  }\n  var obj = common.ShellString(stdout, stderr, code);\n  return obj;\n} // execSync()", "func_src_after": "    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  if (fs.existsSync(codeFile)) common.unlinkSync(codeFile);\n  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n  if (fs.existsSync(stderrFile)) common.unlinkSync(stderrFile);\n  if (fs.existsSync(stdoutFile)) common.unlinkSync(stdoutFile);\n\n  opts.cwd = path.resolve(opts.cwd);\n\n  var paramsToSerialize = {\n    command: cmd,\n    execOptions: opts,\n    pipe: pipe,\n    stdoutFile: stdoutFile,\n    stderrFile: stderrFile,\n    codeFile: codeFile,\n  };\n\n  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n\n  var execArgs = [\n    path.join(__dirname, 'exec-child.js'),\n    paramsFile,\n  ];\n\n  /* istanbul ignore else */\n  if (opts.silent) {\n    opts.stdio = 'ignore';\n  } else {\n    opts.stdio = [0, 1, 2];\n  }\n\n  // Welcome to the future\n  try {\n    // Bad things if we pass in a `shell` option to child_process.execFileSync,\n    // so we need to explicitly remove it here.\n    delete opts.shell;\n\n    child.execFileSync(common.config.execPath, execArgs, opts);\n  } catch (e) {\n    // Clean up immediately if we have an exception\n    try { common.unlinkSync(codeFile); } catch (e2) {}\n    try { common.unlinkSync(paramsFile); } catch (e2) {}\n    try { common.unlinkSync(stderrFile); } catch (e2) {}\n    try { common.unlinkSync(stdoutFile); } catch (e2) {}\n    throw e;\n  }\n\n  // At this point codeFile exists, but it's not necessarily flushed yet.\n  // Keep reading it until it is.\n  var code = parseInt('', 10);\n  while (isNaN(code)) {\n    code = parseInt(fs.readFileSync(codeFile, 'utf8'), 10);\n  }\n\n  // fs.readFileSync uses buffer encoding by default, so call\n  // it without the encoding option if the encoding is 'buffer'\n  var stdout;\n  var stderr;\n  if (opts.encoding === 'buffer') {\n    stdout = fs.readFileSync(stdoutFile);\n    stderr = fs.readFileSync(stderrFile);\n  } else {\n    stdout = fs.readFileSync(stdoutFile, opts.encoding);\n    stderr = fs.readFileSync(stderrFile, opts.encoding);\n  }\n\n  // No biggie if we can't erase the files now -- they're in a temp dir anyway\n  try { common.unlinkSync(codeFile); } catch (e) {}\n  try { common.unlinkSync(paramsFile); } catch (e) {}\n  try { common.unlinkSync(stderrFile); } catch (e) {}\n  try { common.unlinkSync(stdoutFile); } catch (e) {}\n\n  if (code !== 0) {\n    common.error('', code, { continue: true });\n  }\n  var obj = common.ShellString(stdout, stderr, code);\n  return obj;\n} // execSync()", "line_changes": {"deleted": [{"line_no": 25, "char_start": 662, "char_end": 684, "line": "  var execCommand = [\n"}, {"line_no": 26, "char_start": 684, "char_end": 728, "line": "    JSON.stringify(common.config.execPath),\n"}, {"line_no": 27, "char_start": 728, "char_end": 787, "line": "    JSON.stringify(path.join(__dirname, 'exec-child.js')),\n"}, {"line_no": 28, "char_start": 787, "char_end": 819, "line": "    JSON.stringify(paramsFile),\n"}, {"line_no": 29, "char_start": 819, "char_end": 834, "line": "  ].join(' ');\n"}, {"line_no": 40, "char_start": 991, "char_end": 1030, "line": "    child.execSync(execCommand, opts);\n"}], "added": [{"line_no": 25, "char_start": 662, "char_end": 681, "line": "  var execArgs = [\n"}, {"line_no": 26, "char_start": 681, "char_end": 724, "line": "    path.join(__dirname, 'exec-child.js'),\n"}, {"line_no": 27, "char_start": 724, "char_end": 740, "line": "    paramsFile,\n"}, {"line_no": 28, "char_start": 740, "char_end": 745, "line": "  ];\n"}, {"line_no": 41, "char_start": 1030, "char_end": 1053, "line": "    delete opts.shell;\n"}, {"line_no": 42, "char_start": 1053, "char_end": 1054, "line": "\n"}, {"line_no": 43, "char_start": 1054, "char_end": 1118, "line": "    child.execFileSync(common.config.execPath, execArgs, opts);\n"}]}, "char_changes": {"deleted": [{"char_start": 672, "char_end": 679, "chars": "Command"}, {"char_start": 688, "char_end": 747, "chars": "JSON.stringify(common.config.execPath),\n    JSON.stringify("}, {"char_start": 784, "char_end": 785, "chars": ")"}, {"char_start": 791, "char_end": 806, "chars": "JSON.stringify("}, {"char_start": 816, "char_end": 817, "chars": ")"}, {"char_start": 822, "char_end": 832, "chars": ".join(' ')"}, {"char_start": 995, "char_end": 1021, "chars": "child.execSync(execCommand"}], "added": [{"char_start": 672, "char_end": 676, "chars": "Args"}, {"char_start": 906, "char_end": 1109, "chars": "// Bad things if we pass in a `shell` option to child_process.execFileSync,\n    // so we need to explicitly remove it here.\n    delete opts.shell;\n\n    child.execFileSync(common.config.execPath, execArgs"}]}, "commit_link": "github.com/shelljs/shelljs/commit/b885590e0f005faa69ff10bd1b777367886df1ae", "file_name": "exec.js", "vul_type": "cwe-078", "commit_msg": "Use execFileSync to launch child process (#790)\n\nThis uses `child_process.execFileSync` instead of `execSync` to launch the child\r\nprocess. This further reduces the attack surface, removing a possible point for\r\ncommand injection in the ShellJS implementation.\r\n\r\nThis does not affect backwards compatibility for the `shell.exec` API (the\r\nbehavior is determined by the call to `child_process.exec` within\r\n`src/exec-child.js`).\r\n\r\nIssue #782", "description": "Write a Node.js function to execute a command synchronously, handling input/output files and returning the result."}
{"func_name": "get_title_from_youtube_url", "func_src_before": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output('youtube-dl --get-title %s --no-warnings' % url, stderr=subprocess.STDOUT,\n                                             shell=True)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "func_src_after": "def get_title_from_youtube_url(url):\n    try:\n        output = str(subprocess.check_output(['youtube-dl', '--get-title', url, '--no-warnings'],\n                                             stderr=subprocess.STDOUT)).strip()\n    except subprocess.CalledProcessError as ex:\n        output = str(ex.output).strip()\n    except OSError as ex:\n        output = 'youtube-dl not found: %s' % ex\n    except Exception as ex:\n        output = 'Something bad happened: %s' % ex\n    return remove_commas_from_string(output)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 46, "char_end": 166, "line": "        output = str(subprocess.check_output('youtube-dl --get-title %s --no-warnings' % url, stderr=subprocess.STDOUT,\n"}, {"line_no": 4, "char_start": 166, "char_end": 232, "line": "                                             shell=True)).strip()\n"}], "added": [{"line_no": 3, "char_start": 46, "char_end": 144, "line": "        output = str(subprocess.check_output(['youtube-dl', '--get-title', url, '--no-warnings'],\n"}, {"line_no": 4, "char_start": 144, "char_end": 224, "line": "                                             stderr=subprocess.STDOUT)).strip()\n"}]}, "char_changes": {"deleted": [{"char_start": 102, "char_end": 103, "chars": " "}, {"char_start": 114, "char_end": 118, "chars": " %s "}, {"char_start": 132, "char_end": 164, "chars": " % url, stderr=subprocess.STDOUT"}, {"char_start": 212, "char_end": 221, "chars": "hell=True"}], "added": [{"char_start": 91, "char_end": 92, "chars": "["}, {"char_start": 103, "char_end": 107, "chars": "', '"}, {"char_start": 118, "char_end": 127, "chars": "', url, '"}, {"char_start": 141, "char_end": 142, "chars": "]"}, {"char_start": 190, "char_end": 213, "chars": "tderr=subprocess.STDOUT"}]}, "commit_link": "github.com/w-martin/mindfulness/commit/62e1d5ce9deb57468cf917ce0ce838120ec84c46", "file_name": "util.py", "vul_type": "cwe-078", "commit_msg": "(issue #25) 'Auto-fill description form acts as a shell':\n- refactored 'check_output' method call to pass through command parameters as vargs instead of formatting the string manually. subprocess then handles the sanitising of the passed parameter which prevents the shell injection\n- shell=True removed (defaulting the value to true) as we no longer need to call the shell directly NB: the subprocess documentation recommends against using 'shell=True' due to the risks associated with untrusted input", "description": "Write a Python function to extract the title from a YouTube video URL using the `youtube-dl` command-line program."}
{"func_name": "next_state_val", "func_src_before": "next_state_val(CClassNode* cc, OnigCodePoint *vs, OnigCodePoint v,\n\t       int* vs_israw, int v_israw,\n\t       enum CCVALTYPE intype, enum CCVALTYPE* type,\n\t       enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  switch (*state) {\n  case CCS_VALUE:\n    if (*type == CCV_SB) {\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    }\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n    break;\n\n  case CCS_RANGE:\n    if (intype == *type) {\n      if (intype == CCV_SB) {\n        if (*vs > 0xff || v > 0xff)\n          return ONIGERR_INVALID_CODE_POINT_VALUE;\n\n        if (*vs > v) {\n          if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_EMPTY_RANGE_IN_CC))\n            goto ccs_range_end;\n          else\n            return ONIGERR_EMPTY_RANGE_IN_CHAR_CLASS;\n        }\n        bitset_set_range(cc->bs, (int )*vs, (int )v);\n      }\n      else {\n        r = add_code_range(&(cc->mbuf), env, *vs, v);\n        if (r < 0) return r;\n      }\n    }\n    else {\n#if 0\n      if (intype == CCV_CODE_POINT && *type == CCV_SB) {\n#endif\n        if (*vs > v) {\n          if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_EMPTY_RANGE_IN_CC))\n            goto ccs_range_end;\n          else\n            return ONIGERR_EMPTY_RANGE_IN_CHAR_CLASS;\n        }\n        bitset_set_range(cc->bs, (int )*vs, (int )(v < 0xff ? v : 0xff));\n        r = add_code_range(&(cc->mbuf), env, (OnigCodePoint )*vs, v);\n        if (r < 0) return r;\n#if 0\n      }\n      else\n        return ONIGERR_MISMATCH_CODE_LENGTH_IN_CLASS_RANGE;\n#endif\n    }\n  ccs_range_end:\n    *state = CCS_COMPLETE;\n    break;\n\n  case CCS_COMPLETE:\n  case CCS_START:\n    *state = CCS_VALUE;\n    break;\n\n  default:\n    break;\n  }\n\n  *vs_israw = v_israw;\n  *vs       = v;\n  *type     = intype;\n  return 0;\n}", "func_src_after": "next_state_val(CClassNode* cc, OnigCodePoint *vs, OnigCodePoint v,\n\t       int* vs_israw, int v_israw,\n\t       enum CCVALTYPE intype, enum CCVALTYPE* type,\n\t       enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  switch (*state) {\n  case CCS_VALUE:\n    if (*type == CCV_SB) {\n      if (*vs > 0xff)\n          return ONIGERR_INVALID_CODE_POINT_VALUE;\n\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    }\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n    break;\n\n  case CCS_RANGE:\n    if (intype == *type) {\n      if (intype == CCV_SB) {\n        if (*vs > 0xff || v > 0xff)\n          return ONIGERR_INVALID_CODE_POINT_VALUE;\n\n        if (*vs > v) {\n          if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_EMPTY_RANGE_IN_CC))\n            goto ccs_range_end;\n          else\n            return ONIGERR_EMPTY_RANGE_IN_CHAR_CLASS;\n        }\n        bitset_set_range(cc->bs, (int )*vs, (int )v);\n      }\n      else {\n        r = add_code_range(&(cc->mbuf), env, *vs, v);\n        if (r < 0) return r;\n      }\n    }\n    else {\n#if 0\n      if (intype == CCV_CODE_POINT && *type == CCV_SB) {\n#endif\n        if (*vs > v) {\n          if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_EMPTY_RANGE_IN_CC))\n            goto ccs_range_end;\n          else\n            return ONIGERR_EMPTY_RANGE_IN_CHAR_CLASS;\n        }\n        bitset_set_range(cc->bs, (int )*vs, (int )(v < 0xff ? v : 0xff));\n        r = add_code_range(&(cc->mbuf), env, (OnigCodePoint )*vs, v);\n        if (r < 0) return r;\n#if 0\n      }\n      else\n        return ONIGERR_MISMATCH_CODE_LENGTH_IN_CLASS_RANGE;\n#endif\n    }\n  ccs_range_end:\n    *state = CCS_COMPLETE;\n    break;\n\n  case CCS_COMPLETE:\n  case CCS_START:\n    *state = CCS_VALUE;\n    break;\n\n  default:\n    break;\n  }\n\n  *vs_israw = v_israw;\n  *vs       = v;\n  *type     = intype;\n  return 0;\n}", "commit_link": "github.com/kkos/oniguruma/commit/b4bf968ad52afe14e60a2dc8a95d3555c543353a", "file_name": "src/regparse.c", "vul_type": "cwe-787", "description": "Write a C function named `next_state_val` that updates the state and value type of a character class node based on input values and a state machine."}
{"func_name": "pascal_case", "func_src_before": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(value)", "func_src_after": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(_sanitize(value))", "commit_link": "github.com/openapi-generators/openapi-python-client/commit/3e7dfae5d0b3685abf1ede1bc6c086a116ac4746", "file_name": "openapi_python_client/utils.py", "vul_type": "cwe-022", "description": "Write a Python function named `pascal_case` that converts a string to PascalCase format, optionally sanitizing the input first."}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    statement = \"INSERT INTO matches values ({w}, {l})\".format(w=w, l=l)\n    c.execute(statement)\n    db.commit()\n    db.close()", "func_src_after": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO matches values (%s, %s)\", (w,l))\n    db.commit()\n    db.close()", "commit_link": "github.com/tdnelson2/tournament-db/commit/00f3caeed0e12e806c2808d100908698777d9e98", "file_name": "tournament.py", "vul_type": "cwe-089", "description": "Write a Python function to record the outcome of a match by inserting the winner and loser IDs into a database."}
{"func_name": "dd_save_text", "func_src_before": "void dd_save_text(struct dump_dir *dd, const char *name, const char *data)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, strlen(data), dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "func_src_after": "void dd_save_text(struct dump_dir *dd, const char *name, const char *data)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot save text. '%s' is not a valid file name\", name);\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, strlen(data), dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function `dd_save_text` to save text data to a file within a directory structure, handling errors for directory access and file naming."}
{"func_name": "(anonymous)", "func_src_before": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n});", "func_src_after": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n});", "line_changes": {"deleted": [], "added": [{"line_no": 114, "char_start": 4565, "char_end": 4566, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 4125, "char_end": 4566, "chars": "    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    });\n\n"}]}, "commit_link": "github.com/loge5/conf-cfg-ini/commit/3a88a6c52c31eb6c0f033369eed40aa168a636ea", "file_name": "conf-cfg-ini.spec.js", "vul_type": "cwe-915", "commit_msg": "fix: prevent prototype pollution attack", "parent_commit": "abbaf8b61ba5040e04aaa55722c412e19a1bcab4", "description": "Write JavaScript tests for a configuration parser using Mocha and Chai."}
{"func_name": "self.register_user_defined_tag_type", "func_src_before": "    def self.register_user_defined_tag_type(config_source)\n      config = YAML.load(config_source)\n      check_validity_of_config(config)\n      TagType.register(registered_tag_name = config['tag_name'].to_sym,\n                       config['tag'],\n                       config['iteration_tag'],\n                       config['fallback_tag'],\n                       config['remove_indent'] || false)\n      registered_tag_name\n    end", "func_src_after": "    def self.register_user_defined_tag_type(config_source)\n      config = YAML.safe_load(config_source, [Symbol])\n      check_validity_of_config(config)\n      TagType.register(registered_tag_name = config['tag_name'].to_sym,\n                       config['tag'],\n                       config['iteration_tag'],\n                       config['fallback_tag'],\n                       config['remove_indent'] || false)\n      registered_tag_name\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 59, "char_end": 99, "line": "      config = YAML.load(config_source)\n"}], "added": [{"line_no": 2, "char_start": 59, "char_end": 114, "line": "      config = YAML.safe_load(config_source, [Symbol])\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 79, "char_end": 84, "chars": "safe_"}, {"char_start": 102, "char_end": 112, "chars": ", [Symbol]"}]}, "commit_link": "github.com/nico-hn/AdHocTemplate/commit/4bc4ed79a2c45d64df03029bd05c3a426f5df020", "file_name": "parser.rb", "vul_type": "cwe-502", "commit_msg": "use YAML.safe_load() instead of .load()", "parent_commit": "f602247a29214ffce7e8d24caf690c2a420c3e99", "description": "Write a Ruby method to register a user-defined tag type from a YAML configuration source."}
{"func_name": "do_mq_notify", "func_src_before": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1)\n\t\t\t\tgoto retry;\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "func_src_after": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1) {\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/f991af3daabaecff34684fd51fac80319d1baad1", "file_name": "ipc/mqueue.c", "vul_type": "cwe-416", "description": "Write a C function named `do_mq_notify` that sets up message queue notifications."}
{"func_name": "rfbHandleAuthResult", "func_src_before": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0, reasonLen=0;\n    char *reason=NULL;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        if (!ReadFromRFBServer(client, (char *)&reasonLen, 4)) return FALSE;\n        reasonLen = rfbClientSwap32IfLE(reasonLen);\n        reason = malloc((uint64_t)reasonLen+1);\n        if (!ReadFromRFBServer(client, reason, reasonLen)) { free(reason); return FALSE; }\n        reason[reasonLen]=0;\n        rfbClientLog(\"VNC connection failed: %s\\n\",reason);\n        free(reason);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "func_src_after": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        ReadReason(client);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/e34bcbb759ca5bef85809967a268fdf214c1ad2c", "file_name": "libvncclient/rfbproto.c", "vul_type": "cwe-787", "description": "Write a C function named `rfbHandleAuthResult` that processes VNC authentication results from a server."}
{"func_name": "autodetect_recv_bandwidth_measure_results", "func_src_before": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "func_src_after": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn -1;\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/f5e73cc7c9cd973b516a618da877c87b80950b65", "file_name": "libfreerdp/core/autodetect.c", "vul_type": "cwe-125", "description": "Write a C function to process bandwidth measurement results in an RDP session."}
{"func_name": "dateproto_setMilliseconds", "func_src_before": "func (r *Runtime) dateproto_setMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := int(call.Argument(0).ToInteger())\n\t\t\td.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local)\n\t\t\treturn intToValue(timeToMsec(d.time))\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "func_src_after": "func (r *Runtime) dateproto_setMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := call.Argument(0).ToInteger()\n\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m)\n\t\t\treturn intToValue(m)\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 158, "char_end": 203, "line": "\t\t\tmsec := int(call.Argument(0).ToInteger())\n"}, {"line_no": 6, "char_start": 203, "char_end": 341, "line": "\t\t\td.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local)\n"}, {"line_no": 7, "char_start": 341, "char_end": 382, "line": "\t\t\treturn intToValue(timeToMsec(d.time))\n"}], "added": [{"line_no": 5, "char_start": 158, "char_end": 198, "line": "\t\t\tmsec := call.Argument(0).ToInteger()\n"}, {"line_no": 6, "char_start": 198, "char_end": 265, "line": "\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n"}, {"line_no": 7, "char_start": 265, "char_end": 293, "line": "\t\t\td.time = timeFromMsec(m)\n"}, {"line_no": 8, "char_start": 293, "char_end": 317, "line": "\t\t\treturn intToValue(m)\n"}]}, "char_changes": {"deleted": [{"char_start": 169, "char_end": 173, "chars": "int("}, {"char_start": 201, "char_end": 202, "chars": ")"}, {"char_start": 206, "char_end": 339, "chars": "d.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local"}, {"char_start": 362, "char_end": 380, "chars": "timeToMsec(d.time)"}], "added": [{"char_start": 201, "char_end": 291, "chars": "m := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m"}, {"char_start": 314, "char_end": 315, "chars": "m"}]}, "commit_link": "github.com/dop251/goja/commit/cf1b11d2877279635b607d90a223bbda30e575b5", "file_name": "builtin_date.go", "vul_type": "cwe-681", "commit_msg": "Avoid integer overflow in Date.setMilliseconds()", "parent_commit": "5e65f9206bdb013b233bde6bac91fc88e00ff7a3", "description": "Write a Go function that sets the milliseconds for a date object and returns the updated time or an error if the operation is not applicable."}
{"func_name": "enc_untrusted_inet_ntop", "func_src_before": "const char *enc_untrusted_inet_ntop(int af, const void *src, char *dst,\n                                    socklen_t size) {\n  if (!src || !dst) {\n    errno = EFAULT;\n    return nullptr;\n  }\n  size_t src_size = 0;\n  if (af == AF_INET) {\n    src_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    src_size = sizeof(struct in6_addr);\n  } else {\n    errno = EAFNOSUPPORT;\n    return nullptr;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{reinterpret_cast<const char *>(src), src_size});\n  input.Push(size);\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetNtopHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_ntop\", 2);\n\n  auto result = output.next();\n  int klinux_errno = output.next<int>();\n  if (result.empty()) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return nullptr;\n  }\n\n  memcpy(dst, result.data(),\n         std::min(static_cast<size_t>(size),\n                  static_cast<size_t>(INET6_ADDRSTRLEN)));\n  return dst;\n}", "func_src_after": "const char *enc_untrusted_inet_ntop(int af, const void *src, char *dst,\n                                    socklen_t size) {\n  if (!src || !dst) {\n    errno = EFAULT;\n    return nullptr;\n  }\n  size_t src_size = 0;\n  if (af == AF_INET) {\n    src_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    src_size = sizeof(struct in6_addr);\n  } else {\n    errno = EAFNOSUPPORT;\n    return nullptr;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{reinterpret_cast<const char *>(src), src_size});\n  input.Push(size);\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetNtopHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_ntop\", 2);\n\n  auto result = output.next();\n  int klinux_errno = output.next<int>();\n  if (result.empty()) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return nullptr;\n  }\n\n  memcpy(\n      dst, result.data(),\n      std::min({static_cast<size_t>(size), static_cast<size_t>(result.size()),\n                static_cast<size_t>(INET6_ADDRSTRLEN)}));\n  return dst;\n}", "commit_link": "github.com/google/asylo/commit/6ff3b77ffe110a33a2f93848a6333f33616f02c4", "file_name": "asylo/platform/host_call/trusted/host_calls.cc", "vul_type": "cwe-125", "description": "Write a C++ function named `enc_untrusted_inet_ntop` that converts a network address into a human-readable string, handling potential errors."}
{"func_name": "populate_custom_grains_and_pillar", "func_src_before": "def populate_custom_grains_and_pillar():\n    '''\n    Populate local salt-minion grains and pillar fields values as specified in\n    config file.\n\n    For example:\n\n        custom_grains_pillar:\n          grains:\n            - selinux: selinux:enabled\n            - release: osrelease\n          pillar:\n            - ntpserver: network_services:ntpserver\n\n    Note that the core grains are already included in hubble grains -- this\n    is only necessary for custom grains and pillar data.\n    '''\n    log.debug('Fetching custom grains and pillar details')\n    grains = {}\n    salt.modules.config.__opts__ = __opts__\n    custom_grains = __salt__['config.get']('custom_grains_pillar:grains', [])\n    for grain in custom_grains:\n        for key in grain:\n            if _valid_command(grain[key]):\n                value = __salt__['cmd.run']('salt-call grains.get {0}'.format(grain[key])).split('\\n')[1].strip()\n                grains[key] = value\n    custom_pillar = __salt__['config.get']('custom_grains_pillar:pillar', [])\n    for pillar in custom_pillar:\n        for key in pillar:\n            if _valid_command(pillar[key]):\n                value = __salt__['cmd.run']('salt-call pillar.get {0}'.format(pillar[key])).split('\\n')[1].strip()\n                grains[key] = value\n    log.debug('Done with fetching custom grains and pillar details')\n    return grains", "func_src_after": "def populate_custom_grains_and_pillar():\n    '''\n    Populate local salt-minion grains and pillar fields values as specified in\n    config file.\n\n    For example:\n\n        custom_grains_pillar:\n          grains:\n            - selinux: selinux:enabled\n            - release: osrelease\n          pillar:\n            - ntpserver: network_services:ntpserver\n\n    Note that the core grains are already included in hubble grains -- this\n    is only necessary for custom grains and pillar data.\n    '''\n    log.debug('Fetching custom grains and pillar details')\n    grains = {}\n    salt.modules.config.__opts__ = __opts__\n    custom_grains = __salt__['config.get']('custom_grains_pillar:grains', [])\n    for grain in custom_grains:\n        for key in grain:\n            value = __salt__['cmd.run'](['salt-call', 'grains.get', grain[key]]).split('\\n')[1].strip()\n            grains[key] = value\n    custom_pillar = __salt__['config.get']('custom_grains_pillar:pillar', [])\n    for pillar in custom_pillar:\n        for key in pillar:\n            value = __salt__['cmd.run'](['salt-call', 'pillar.get', pillar[key]]).split('\\n')[1].strip()\n            grains[key] = value\n    log.debug('Done with fetching custom grains and pillar details')\n    return grains", "commit_link": "github.com/hubblestack/hubble/commit/d9ca4a93ea5aabb1298c5b3dbfb23e94203428b9", "file_name": "hubblestack/extmods/grains/custom_grains_pillar.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve and set custom grains and pillar data from a configuration file using SaltStack commands."}
{"func_name": "get_previous_yields", "func_src_before": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial = '%s'\n        ''' % (inverter_serial)\n        self.c.execute(query)\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "func_src_after": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial=?\n        '''\n        self.c.execute(query, (inverter_serial,))\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the timestamp and energy yields of today and total from a database for a given inverter serial number."}
{"func_name": "download", "func_src_before": "    def download(self, log_files, sort='time', limit=-1, nfl_filter='',\n                 output_format='default'):\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            nfl_esc = nfl_filter.replace('(', '\\(').replace(')', '\\)')\n            # remove the slash that is intentionally added in the URL\n            # to avoid failure of filtering stats data.\n            if nfl_esc.startswith('/'):\n                nfl_esc = nfl_esc[1:]\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            if output_format == 'python':\n                data = self.format_source_code(nfl_filter)\n            elif output_format == 'json':\n                data = stats.to_json(nfl_esc, limit)\n            elif output_format == 'csv':\n                data = stats.to_csv(nfl_esc, limit)\n            elif output_format == 'ods':\n                data = stats.to_ods(nfl_esc, limit)\n            else:\n                profile_tmp_all = tempfile.mktemp('.profile', 'all')\n                stats.dump_stats(profile_tmp_all)\n                data = open(profile_tmp_all).read()\n                os.remove(profile_tmp_all)\n            return data, [('content-type', self.format_dict[output_format])]\n        except ODFLIBNotInstalled as ex:\n            raise ex\n        except Exception as ex:\n            raise ProfileException(_('Data download error: %s') % ex)", "func_src_after": "    def download(self, log_files, sort='time', limit=-1, nfl_filter='',\n                 output_format='default'):\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            nfl_esc = nfl_filter.replace('(', '\\(').replace(')', '\\)')\n            # remove the slash that is intentionally added in the URL\n            # to avoid failure of filtering stats data.\n            if nfl_esc.startswith('/'):\n                nfl_esc = nfl_esc[1:]\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            if output_format == 'python':\n                data = self.format_source_code(nfl_filter)\n            elif output_format == 'json':\n                data = stats.to_json(nfl_esc, limit)\n            elif output_format == 'csv':\n                data = stats.to_csv(nfl_esc, limit)\n            elif output_format == 'ods':\n                data = stats.to_ods(nfl_esc, limit)\n            else:\n                data = stats.print_stats()\n            return data, [('content-type', self.format_dict[output_format])]\n        except ODFLIBNotInstalled as ex:\n            raise ex\n        except Exception as ex:\n            raise ProfileException(_('Data download error: %s') % ex)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 969, "char_end": 1038, "line": "                profile_tmp_all = tempfile.mktemp('.profile', 'all')\n"}, {"line_no": 23, "char_start": 1038, "char_end": 1088, "line": "                stats.dump_stats(profile_tmp_all)\n"}, {"line_no": 24, "char_start": 1088, "char_end": 1140, "line": "                data = open(profile_tmp_all).read()\n"}, {"line_no": 25, "char_start": 1140, "char_end": 1183, "line": "                os.remove(profile_tmp_all)\n"}], "added": [{"line_no": 22, "char_start": 969, "char_end": 1012, "line": "                data = stats.print_stats()\n"}]}, "char_changes": {"deleted": [{"char_start": 985, "char_end": 1181, "chars": "profile_tmp_all = tempfile.mktemp('.profile', 'all')\n                stats.dump_stats(profile_tmp_all)\n                data = open(profile_tmp_all).read()\n                os.remove(profile_tmp_all"}], "added": [{"char_start": 985, "char_end": 1010, "chars": "data = stats.print_stats("}]}, "commit_link": "github.com/scality/ScalitySproxydSwift/commit/6978275cdb04bb08aaf142d401b52a46527dac4c", "file_name": "html_viewer.py", "vul_type": "cwe-377", "commit_msg": "Avoid usage of insecure mktemp() function\n\nThis patch eliminates the use of the deprecated and insecure\ntempfile.mktemp() function.  It has been replaced with secure\nalternatives where temporary files are actually required.\n\nChange-Id: I0a13d6d44cd1abc4b66fa33f39eea407617a01d5\nSecurityImpact\nCloses-bug: #1348869", "description": "Write a Python function named `download` that processes log files and returns data in various formats based on given parameters."}
{"func_name": "CreateBasket", "func_src_before": "func CreateBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tname := ps.ByName(\"basket\")\n\tif name == serviceOldAPIPath || name == serviceAPIPath || name == serviceUIPath {\n\t\thttp.Error(w, \"This basket name conflicts with reserved system path: \"+name, http.StatusForbidden)\n\t\treturn\n\t}\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tlog.Printf(\"[info] creating basket: %s\", name)\n\n\t// read config (max 2 kB)\n\tbody, err := ioutil.ReadAll(io.LimitReader(r.Body, 2048))\n\tr.Body.Close()\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// default config\n\tconfig := BasketConfig{ForwardURL: \"\", Capacity: serverConfig.InitCapacity}\n\tif len(body) > 0 {\n\t\tif err = json.Unmarshal(body, &config); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err = validateBasketConfig(&config); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusUnprocessableEntity)\n\t\t\treturn\n\t\t}\n\t}\n\n\tauth, err := basketsDb.Create(name, config)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusConflict)\n\t} else {\n\t\tjson, err := json.Marshal(auth)\n\t\twriteJSON(w, http.StatusCreated, json, err)\n\t}\n}", "func_src_after": "func CreateBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tname := ps.ByName(\"basket\")\n\tif name == serviceOldAPIPath || name == serviceAPIPath || name == serviceUIPath {\n\t\thttp.Error(w, \"This basket name conflicts with reserved system path: \"+name, http.StatusForbidden)\n\t\treturn\n\t}\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tlog.Printf(\"[info] creating basket: %s\", name)\n\n\t// read config (max 2 kB)\n\tbody, err := ioutil.ReadAll(io.LimitReader(r.Body, 2048))\n\tr.Body.Close()\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// default config\n\tconfig := BasketConfig{ForwardURL: \"\", Capacity: serverConfig.InitCapacity}\n\tif len(body) > 0 {\n\t\tif err = json.Unmarshal(body, &config); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err = validateBasketConfig(&config); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusUnprocessableEntity)\n\t\t\treturn\n\t\t}\n\t}\n\n\tauth, err := basketsDb.Create(name, config)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusConflict)\n\t} else {\n\t\tjson, err := json.Marshal(auth)\n\t\twriteJSON(w, http.StatusCreated, json, err)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 348, "char_end": 472, "line": "\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}], "added": [{"line_no": 8, "char_start": 348, "char_end": 470, "line": "\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}]}, "char_changes": {"deleted": [{"char_start": 386, "char_end": 389, "chars": "[\"+"}, {"char_start": 393, "char_end": 396, "chars": "+\"]"}], "added": [{"char_start": 386, "char_end": 390, "chars": "the "}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go function to create a basket with a name and optional configuration, handling name validation and potential errors."}
{"func_name": "(anonymous)", "func_src_before": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n    });", "func_src_after": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n    });", "line_changes": {"deleted": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n"}], "added": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n"}]}, "char_changes": {"deleted": [{"char_start": 821, "char_end": 825, "chars": "html"}], "added": [{"char_start": 821, "char_end": 825, "chars": "text"}]}, "commit_link": "github.com/edmundoa/graylog2-server/commit/a88cae99955cd0ccdd5d99a1c6d506029eb15c60", "file_name": "streamrules.js", "vul_type": "cwe-079", "commit_msg": "use .text() not .html() in stream rule editor to prevent DOM XSS\n\nfixes #543", "description": "In JavaScript, write a jQuery event handler that updates text in a modal based on user input and selection changes, with special handling for an \"inverted\" checkbox state."}
{"func_name": "copy_over", "func_src_before": "def copy_over(source, dest):\n    \"\"\"\n    Copies from the source to the destination, removing the destination\n    if it exists and is a directory.\n    \"\"\"\n    if os.path.exists(dest) and os.path.isdir(dest):\n        shutil.rmtree(dest)\n    shutil.copytree(source, dest)\n    # mkdtemp will set the directory permissions to 700\n    # for the webserver to read them, we need 755\n    os.chmod(dest, stat.S_IRWXU | stat.S_IRGRP |\n             stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n    shutil.rmtree(source)", "func_src_after": "def copy_over(source, dest):\n    \"\"\"\n    Copies from the source to the destination, removing the destination\n    if it exists and is a directory.\n    \"\"\"\n    if os.path.exists(dest) and os.path.isdir(dest):\n        shutil.rmtree(dest)\n    shutil.copytree(force_bytes(source), force_bytes(dest))\n    # mkdtemp will set the directory permissions to 700\n    # for the webserver to read them, we need 755\n    os.chmod(dest, stat.S_IRWXU | stat.S_IRGRP |\n             stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n    shutil.rmtree(source)", "line_changes": {"deleted": [{"line_no": 8, "char_start": 235, "char_end": 269, "line": "    shutil.copytree(source, dest)\n"}], "added": [{"line_no": 8, "char_start": 235, "char_end": 295, "line": "    shutil.copytree(force_bytes(source), force_bytes(dest))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 255, "char_end": 267, "chars": "force_bytes("}, {"char_start": 273, "char_end": 274, "chars": ")"}, {"char_start": 276, "char_end": 288, "chars": "force_bytes("}, {"char_start": 293, "char_end": 294, "chars": ")"}]}, "commit_link": "github.com/mozilla/addons-server/commit/e8731de25ab5319c82efb9efbe0195ba95e5dc1e", "file_name": "utils.py", "vul_type": "cwe-022", "commit_msg": "Fix unicode error on copying over extracted files from zip. (#3874)\n\nFix unicode error on copying over extracted files from zip.\r\n\r\nRefs #3579\r\n\r\nThe problem here is that under very hard unit-testable/reproducable\r\ncircumstances a zip-file with unicode filenames get's extracted to a\r\ntemporary directory and while calling `copy_over` which calls\r\n`shutil.copytree` which fails on our production systems with a\r\nUnicodeDecodeError.\r\n\r\nReproducing this is something along the lines of\r\n\r\n>>> shutil.copytree(u'/tmp/tmp8WG6A8/', u'/tmp/tmp8WG6A8-2/')\r\n# doesn't error...\r\n>>> shutil.copytree('/tmp/tmp8WG6A8/', u'/tmp/tmp8WG6A8-2/')\r\nUnicodeDecodeError: 'ascii' codec can't decode \tbyte 0xd0 in ...\r\n\r\nChecking all relevant environment configs in our production systems, all\r\nLANG, LC_ALL and related configs are perfectly fine. It's not related to\r\nuwsgi, it's not related to EFS so it's something else I have absolutely\r\nno idea about :-/", "parent_commit": "18d3e83979a8c9616f6d1173f82f422da6f2e1c2", "description": "Write a Python function to replace a destination directory with a source directory, adjusting permissions for webserver access."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, library):\n        \"\"\"\n        Build the wrapper\n        \"\"\"\n        self._lib = ctypes.CDLL(library)\n        self._version, self._hexversion, self._cflags = get_version(self._lib)\n\n        self.pointer = ctypes.pointer\n        self.c_int = ctypes.c_int\n        self.byref = ctypes.byref\n        self.create_string_buffer = ctypes.create_string_buffer\n\n        self.BN_new = self._lib.BN_new\n        self.BN_new.restype = ctypes.c_void_p\n        self.BN_new.argtypes = []\n\n        self.BN_free = self._lib.BN_free\n        self.BN_free.restype = None\n        self.BN_free.argtypes = [ctypes.c_void_p]\n\n        self.BN_num_bits = self._lib.BN_num_bits\n        self.BN_num_bits.restype = ctypes.c_int\n        self.BN_num_bits.argtypes = [ctypes.c_void_p]\n\n        self.BN_bn2bin = self._lib.BN_bn2bin\n        self.BN_bn2bin.restype = ctypes.c_int\n        self.BN_bn2bin.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.BN_bin2bn = self._lib.BN_bin2bn\n        self.BN_bin2bn.restype = ctypes.c_void_p\n        self.BN_bin2bn.argtypes = [ctypes.c_void_p, ctypes.c_int,\n                                   ctypes.c_void_p]\n\n        self.EC_KEY_free = self._lib.EC_KEY_free\n        self.EC_KEY_free.restype = None\n        self.EC_KEY_free.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_new_by_curve_name = self._lib.EC_KEY_new_by_curve_name\n        self.EC_KEY_new_by_curve_name.restype = ctypes.c_void_p\n        self.EC_KEY_new_by_curve_name.argtypes = [ctypes.c_int]\n\n        self.EC_KEY_generate_key = self._lib.EC_KEY_generate_key\n        self.EC_KEY_generate_key.restype = ctypes.c_int\n        self.EC_KEY_generate_key.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_check_key = self._lib.EC_KEY_check_key\n        self.EC_KEY_check_key.restype = ctypes.c_int\n        self.EC_KEY_check_key.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_get0_private_key = self._lib.EC_KEY_get0_private_key\n        self.EC_KEY_get0_private_key.restype = ctypes.c_void_p\n        self.EC_KEY_get0_private_key.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_get0_public_key = self._lib.EC_KEY_get0_public_key\n        self.EC_KEY_get0_public_key.restype = ctypes.c_void_p\n        self.EC_KEY_get0_public_key.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_get0_group = self._lib.EC_KEY_get0_group\n        self.EC_KEY_get0_group.restype = ctypes.c_void_p\n        self.EC_KEY_get0_group.argtypes = [ctypes.c_void_p]\n\n        self.EC_POINT_get_affine_coordinates_GFp = self._lib.EC_POINT_get_affine_coordinates_GFp\n        self.EC_POINT_get_affine_coordinates_GFp.restype = ctypes.c_int\n        self.EC_POINT_get_affine_coordinates_GFp.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EC_KEY_set_private_key = self._lib.EC_KEY_set_private_key\n        self.EC_KEY_set_private_key.restype = ctypes.c_int\n        self.EC_KEY_set_private_key.argtypes = [ctypes.c_void_p,\n                                                ctypes.c_void_p]\n\n        self.EC_KEY_set_public_key = self._lib.EC_KEY_set_public_key\n        self.EC_KEY_set_public_key.restype = ctypes.c_int\n        self.EC_KEY_set_public_key.argtypes = [ctypes.c_void_p,\n                                               ctypes.c_void_p]\n\n        self.EC_KEY_set_group = self._lib.EC_KEY_set_group\n        self.EC_KEY_set_group.restype = ctypes.c_int\n        self.EC_KEY_set_group.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EC_POINT_set_affine_coordinates_GFp = self._lib.EC_POINT_set_affine_coordinates_GFp\n        self.EC_POINT_set_affine_coordinates_GFp.restype = ctypes.c_int\n        self.EC_POINT_set_affine_coordinates_GFp.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EC_POINT_new = self._lib.EC_POINT_new\n        self.EC_POINT_new.restype = ctypes.c_void_p\n        self.EC_POINT_new.argtypes = [ctypes.c_void_p]\n\n        self.EC_POINT_free = self._lib.EC_POINT_free\n        self.EC_POINT_free.restype = None\n        self.EC_POINT_free.argtypes = [ctypes.c_void_p]\n\n        self.BN_CTX_free = self._lib.BN_CTX_free\n        self.BN_CTX_free.restype = None\n        self.BN_CTX_free.argtypes = [ctypes.c_void_p]\n\n        self.EC_POINT_mul = self._lib.EC_POINT_mul\n        self.EC_POINT_mul.restype = None\n        self.EC_POINT_mul.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EC_KEY_set_private_key = self._lib.EC_KEY_set_private_key\n        self.EC_KEY_set_private_key.restype = ctypes.c_int\n        self.EC_KEY_set_private_key.argtypes = [ctypes.c_void_p,\n                                                ctypes.c_void_p]\n\n        if self._hexversion > 0x10100000:\n            self.EC_KEY_OpenSSL = self._lib.EC_KEY_OpenSSL\n            self._lib.EC_KEY_OpenSSL.restype = ctypes.c_void_p\n            self._lib.EC_KEY_OpenSSL.argtypes = []\n            \n            self.EC_KEY_set_method = self._lib.EC_KEY_set_method\n            self._lib.EC_KEY_set_method.restype = ctypes.c_int\n            self._lib.EC_KEY_set_method.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n        else:\n            self.ECDH_OpenSSL = self._lib.ECDH_OpenSSL\n            self._lib.ECDH_OpenSSL.restype = ctypes.c_void_p\n            self._lib.ECDH_OpenSSL.argtypes = []\n\n            self.ECDH_set_method = self._lib.ECDH_set_method\n            self._lib.ECDH_set_method.restype = ctypes.c_int\n            self._lib.ECDH_set_method.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.BN_CTX_new = self._lib.BN_CTX_new\n        self._lib.BN_CTX_new.restype = ctypes.c_void_p\n        self._lib.BN_CTX_new.argtypes = []\n\n        self.ECDH_compute_key = self._lib.ECDH_compute_key\n        self.ECDH_compute_key.restype = ctypes.c_int\n        self.ECDH_compute_key.argtypes = [ctypes.c_void_p,\n                                          ctypes.c_int, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_CipherInit_ex = self._lib.EVP_CipherInit_ex\n        self.EVP_CipherInit_ex.restype = ctypes.c_int\n        self.EVP_CipherInit_ex.argtypes = [ctypes.c_void_p,\n                                           ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_CIPHER_CTX_new = self._lib.EVP_CIPHER_CTX_new\n        self.EVP_CIPHER_CTX_new.restype = ctypes.c_void_p\n        self.EVP_CIPHER_CTX_new.argtypes = []\n\n        # Cipher\n        self.EVP_aes_128_cfb128 = self._lib.EVP_aes_128_cfb128\n        self.EVP_aes_128_cfb128.restype = ctypes.c_void_p\n        self.EVP_aes_128_cfb128.argtypes = []\n\n        self.EVP_aes_256_cfb128 = self._lib.EVP_aes_256_cfb128\n        self.EVP_aes_256_cfb128.restype = ctypes.c_void_p\n        self.EVP_aes_256_cfb128.argtypes = []\n\n        self.EVP_aes_128_cbc = self._lib.EVP_aes_128_cbc\n        self.EVP_aes_128_cbc.restype = ctypes.c_void_p\n        self.EVP_aes_128_cbc.argtypes = []\n\n        self.EVP_aes_256_cbc = self._lib.EVP_aes_256_cbc\n        self.EVP_aes_256_cbc.restype = ctypes.c_void_p\n        self.EVP_aes_256_cbc.argtypes = []\n\n        #self.EVP_aes_128_ctr = self._lib.EVP_aes_128_ctr\n        #self.EVP_aes_128_ctr.restype = ctypes.c_void_p\n        #self.EVP_aes_128_ctr.argtypes = []\n\n        #self.EVP_aes_256_ctr = self._lib.EVP_aes_256_ctr\n        #self.EVP_aes_256_ctr.restype = ctypes.c_void_p\n        #self.EVP_aes_256_ctr.argtypes = []\n\n        self.EVP_aes_128_ofb = self._lib.EVP_aes_128_ofb\n        self.EVP_aes_128_ofb.restype = ctypes.c_void_p\n        self.EVP_aes_128_ofb.argtypes = []\n\n        self.EVP_aes_256_ofb = self._lib.EVP_aes_256_ofb\n        self.EVP_aes_256_ofb.restype = ctypes.c_void_p\n        self.EVP_aes_256_ofb.argtypes = []\n\n        self.EVP_bf_cbc = self._lib.EVP_bf_cbc\n        self.EVP_bf_cbc.restype = ctypes.c_void_p\n        self.EVP_bf_cbc.argtypes = []\n\n        self.EVP_bf_cfb64 = self._lib.EVP_bf_cfb64\n        self.EVP_bf_cfb64.restype = ctypes.c_void_p\n        self.EVP_bf_cfb64.argtypes = []\n\n        self.EVP_rc4 = self._lib.EVP_rc4\n        self.EVP_rc4.restype = ctypes.c_void_p\n        self.EVP_rc4.argtypes = []\n \n        if self._hexversion > 0x10100000:\n            self.EVP_CIPHER_CTX_reset = self._lib.EVP_CIPHER_CTX_reset\n            self.EVP_CIPHER_CTX_reset.restype = ctypes.c_int\n            self.EVP_CIPHER_CTX_reset.argtypes = [ctypes.c_void_p]\n        else:\n            self.EVP_CIPHER_CTX_cleanup = self._lib.EVP_CIPHER_CTX_cleanup\n            self.EVP_CIPHER_CTX_cleanup.restype = ctypes.c_int\n            self.EVP_CIPHER_CTX_cleanup.argtypes = [ctypes.c_void_p]\n\n        self.EVP_CIPHER_CTX_free = self._lib.EVP_CIPHER_CTX_free\n        self.EVP_CIPHER_CTX_free.restype = None\n        self.EVP_CIPHER_CTX_free.argtypes = [ctypes.c_void_p]\n\n        self.EVP_CipherUpdate = self._lib.EVP_CipherUpdate\n        self.EVP_CipherUpdate.restype = ctypes.c_int\n        self.EVP_CipherUpdate.argtypes = [ctypes.c_void_p,\n                                          ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int]\n\n        self.EVP_CipherFinal_ex = self._lib.EVP_CipherFinal_ex\n        self.EVP_CipherFinal_ex.restype = ctypes.c_int\n        self.EVP_CipherFinal_ex.argtypes = [ctypes.c_void_p,\n                                            ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_DigestInit = self._lib.EVP_DigestInit\n        self.EVP_DigestInit.restype = ctypes.c_int\n        self._lib.EVP_DigestInit.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_DigestInit_ex = self._lib.EVP_DigestInit_ex\n        self.EVP_DigestInit_ex.restype = ctypes.c_int\n        self._lib.EVP_DigestInit_ex.argtypes = 3 * [ctypes.c_void_p]\n        \n        self.EVP_DigestUpdate = self._lib.EVP_DigestUpdate\n        self.EVP_DigestUpdate.restype = ctypes.c_int\n        self.EVP_DigestUpdate.argtypes = [ctypes.c_void_p,\n                                          ctypes.c_void_p, ctypes.c_int]\n\n        self.EVP_DigestFinal = self._lib.EVP_DigestFinal\n        self.EVP_DigestFinal.restype = ctypes.c_int\n        self.EVP_DigestFinal.argtypes = [ctypes.c_void_p,\n                                         ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_DigestFinal_ex = self._lib.EVP_DigestFinal_ex\n        self.EVP_DigestFinal_ex.restype = ctypes.c_int\n        self.EVP_DigestFinal_ex.argtypes = [ctypes.c_void_p,\n                                            ctypes.c_void_p, ctypes.c_void_p]\n        \n        self.ECDSA_sign = self._lib.ECDSA_sign\n        self.ECDSA_sign.restype = ctypes.c_int\n        self.ECDSA_sign.argtypes = [ctypes.c_int, ctypes.c_void_p,\n                                    ctypes.c_int, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.ECDSA_verify = self._lib.ECDSA_verify\n        self.ECDSA_verify.restype = ctypes.c_int\n        self.ECDSA_verify.argtypes = [ctypes.c_int, ctypes.c_void_p,\n                                      ctypes.c_int, ctypes.c_void_p, ctypes.c_int, ctypes.c_void_p]\n\n        if self._hexversion > 0x10100000:\n            self.EVP_MD_CTX_new = self._lib.EVP_MD_CTX_new\n            self.EVP_MD_CTX_new.restype = ctypes.c_void_p\n            self.EVP_MD_CTX_new.argtypes = []\n        \n            self.EVP_MD_CTX_reset = self._lib.EVP_MD_CTX_reset\n            self.EVP_MD_CTX_reset.restype = None\n            self.EVP_MD_CTX_reset.argtypes = [ctypes.c_void_p]\n\n            self.EVP_MD_CTX_free = self._lib.EVP_MD_CTX_free\n            self.EVP_MD_CTX_free.restype = None\n            self.EVP_MD_CTX_free.argtypes = [ctypes.c_void_p]\n\n            self.EVP_sha1 = self._lib.EVP_sha1\n            self.EVP_sha1.restype = ctypes.c_void_p\n            self.EVP_sha1.argtypes = []\n\n            self.digest_ecdsa_sha1 = self.EVP_sha1\n        else:\n            self.EVP_MD_CTX_create = self._lib.EVP_MD_CTX_create\n            self.EVP_MD_CTX_create.restype = ctypes.c_void_p\n            self.EVP_MD_CTX_create.argtypes = []\n \n            self.EVP_MD_CTX_init = self._lib.EVP_MD_CTX_init\n            self.EVP_MD_CTX_init.restype = None\n            self.EVP_MD_CTX_init.argtypes = [ctypes.c_void_p]\n \n            self.EVP_MD_CTX_destroy = self._lib.EVP_MD_CTX_destroy\n            self.EVP_MD_CTX_destroy.restype = None\n            self.EVP_MD_CTX_destroy.argtypes = [ctypes.c_void_p]\n\n            self.EVP_ecdsa = self._lib.EVP_ecdsa\n            self._lib.EVP_ecdsa.restype = ctypes.c_void_p\n            self._lib.EVP_ecdsa.argtypes = []\n\n            self.digest_ecdsa_sha1 = self.EVP_ecdsa\n\n        self.RAND_bytes = self._lib.RAND_bytes\n        self.RAND_bytes.restype = ctypes.c_int\n        self.RAND_bytes.argtypes = [ctypes.c_void_p, ctypes.c_int]\n\n        self.EVP_sha256 = self._lib.EVP_sha256\n        self.EVP_sha256.restype = ctypes.c_void_p\n        self.EVP_sha256.argtypes = []\n\n        self.i2o_ECPublicKey = self._lib.i2o_ECPublicKey\n        self.i2o_ECPublicKey.restype = ctypes.c_void_p\n        self.i2o_ECPublicKey.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_sha512 = self._lib.EVP_sha512\n        self.EVP_sha512.restype = ctypes.c_void_p\n        self.EVP_sha512.argtypes = []\n\n        self.HMAC = self._lib.HMAC\n        self.HMAC.restype = ctypes.c_void_p\n        self.HMAC.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int,\n                              ctypes.c_void_p, ctypes.c_int, ctypes.c_void_p, ctypes.c_void_p]\n\n        try:\n            self.PKCS5_PBKDF2_HMAC = self._lib.PKCS5_PBKDF2_HMAC\n        except:\n            # The above is not compatible with all versions of OSX.\n            self.PKCS5_PBKDF2_HMAC = self._lib.PKCS5_PBKDF2_HMAC_SHA1\n            \n        self.PKCS5_PBKDF2_HMAC.restype = ctypes.c_int\n        self.PKCS5_PBKDF2_HMAC.argtypes = [ctypes.c_void_p, ctypes.c_int,\n                                           ctypes.c_void_p, ctypes.c_int,\n                                           ctypes.c_int, ctypes.c_void_p,\n                                           ctypes.c_int, ctypes.c_void_p]\n\n        self._set_ciphers()\n        self._set_curves()", "func_src_after": "    def __init__(self, library):\n        \"\"\"\n        Build the wrapper\n        \"\"\"\n        self._lib = ctypes.CDLL(library)\n        self._version, self._hexversion, self._cflags = get_version(self._lib)\n\n        self.pointer = ctypes.pointer\n        self.c_int = ctypes.c_int\n        self.byref = ctypes.byref\n        self.create_string_buffer = ctypes.create_string_buffer\n\n        self.BN_new = self._lib.BN_new\n        self.BN_new.restype = ctypes.c_void_p\n        self.BN_new.argtypes = []\n\n        self.BN_free = self._lib.BN_free\n        self.BN_free.restype = None\n        self.BN_free.argtypes = [ctypes.c_void_p]\n\n        self.BN_num_bits = self._lib.BN_num_bits\n        self.BN_num_bits.restype = ctypes.c_int\n        self.BN_num_bits.argtypes = [ctypes.c_void_p]\n\n        self.BN_bn2bin = self._lib.BN_bn2bin\n        self.BN_bn2bin.restype = ctypes.c_int\n        self.BN_bn2bin.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.BN_bin2bn = self._lib.BN_bin2bn\n        self.BN_bin2bn.restype = ctypes.c_void_p\n        self.BN_bin2bn.argtypes = [ctypes.c_void_p, ctypes.c_int,\n                                   ctypes.c_void_p]\n\n        self.EC_KEY_free = self._lib.EC_KEY_free\n        self.EC_KEY_free.restype = None\n        self.EC_KEY_free.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_new_by_curve_name = self._lib.EC_KEY_new_by_curve_name\n        self.EC_KEY_new_by_curve_name.restype = ctypes.c_void_p\n        self.EC_KEY_new_by_curve_name.argtypes = [ctypes.c_int]\n\n        self.EC_KEY_generate_key = self._lib.EC_KEY_generate_key\n        self.EC_KEY_generate_key.restype = ctypes.c_int\n        self.EC_KEY_generate_key.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_check_key = self._lib.EC_KEY_check_key\n        self.EC_KEY_check_key.restype = ctypes.c_int\n        self.EC_KEY_check_key.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_get0_private_key = self._lib.EC_KEY_get0_private_key\n        self.EC_KEY_get0_private_key.restype = ctypes.c_void_p\n        self.EC_KEY_get0_private_key.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_get0_public_key = self._lib.EC_KEY_get0_public_key\n        self.EC_KEY_get0_public_key.restype = ctypes.c_void_p\n        self.EC_KEY_get0_public_key.argtypes = [ctypes.c_void_p]\n\n        self.EC_KEY_get0_group = self._lib.EC_KEY_get0_group\n        self.EC_KEY_get0_group.restype = ctypes.c_void_p\n        self.EC_KEY_get0_group.argtypes = [ctypes.c_void_p]\n\n        self.EC_POINT_get_affine_coordinates_GFp = self._lib.EC_POINT_get_affine_coordinates_GFp\n        self.EC_POINT_get_affine_coordinates_GFp.restype = ctypes.c_int\n        self.EC_POINT_get_affine_coordinates_GFp.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EC_KEY_set_private_key = self._lib.EC_KEY_set_private_key\n        self.EC_KEY_set_private_key.restype = ctypes.c_int\n        self.EC_KEY_set_private_key.argtypes = [ctypes.c_void_p,\n                                                ctypes.c_void_p]\n\n        self.EC_KEY_set_public_key = self._lib.EC_KEY_set_public_key\n        self.EC_KEY_set_public_key.restype = ctypes.c_int\n        self.EC_KEY_set_public_key.argtypes = [ctypes.c_void_p,\n                                               ctypes.c_void_p]\n\n        self.EC_KEY_set_group = self._lib.EC_KEY_set_group\n        self.EC_KEY_set_group.restype = ctypes.c_int\n        self.EC_KEY_set_group.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EC_POINT_set_affine_coordinates_GFp = self._lib.EC_POINT_set_affine_coordinates_GFp\n        self.EC_POINT_set_affine_coordinates_GFp.restype = ctypes.c_int\n        self.EC_POINT_set_affine_coordinates_GFp.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EC_POINT_new = self._lib.EC_POINT_new\n        self.EC_POINT_new.restype = ctypes.c_void_p\n        self.EC_POINT_new.argtypes = [ctypes.c_void_p]\n\n        self.EC_POINT_free = self._lib.EC_POINT_free\n        self.EC_POINT_free.restype = None\n        self.EC_POINT_free.argtypes = [ctypes.c_void_p]\n\n        self.BN_CTX_free = self._lib.BN_CTX_free\n        self.BN_CTX_free.restype = None\n        self.BN_CTX_free.argtypes = [ctypes.c_void_p]\n\n        self.EC_POINT_mul = self._lib.EC_POINT_mul\n        self.EC_POINT_mul.restype = None\n        self.EC_POINT_mul.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EC_KEY_set_private_key = self._lib.EC_KEY_set_private_key\n        self.EC_KEY_set_private_key.restype = ctypes.c_int\n        self.EC_KEY_set_private_key.argtypes = [ctypes.c_void_p,\n                                                ctypes.c_void_p]\n\n        if self._hexversion >= 0x10100000:\n            self.EC_KEY_OpenSSL = self._lib.EC_KEY_OpenSSL\n            self._lib.EC_KEY_OpenSSL.restype = ctypes.c_void_p\n            self._lib.EC_KEY_OpenSSL.argtypes = []\n            \n            self.EC_KEY_set_method = self._lib.EC_KEY_set_method\n            self._lib.EC_KEY_set_method.restype = ctypes.c_int\n            self._lib.EC_KEY_set_method.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n        else:\n            self.ECDH_OpenSSL = self._lib.ECDH_OpenSSL\n            self._lib.ECDH_OpenSSL.restype = ctypes.c_void_p\n            self._lib.ECDH_OpenSSL.argtypes = []\n\n            self.ECDH_set_method = self._lib.ECDH_set_method\n            self._lib.ECDH_set_method.restype = ctypes.c_int\n            self._lib.ECDH_set_method.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.BN_CTX_new = self._lib.BN_CTX_new\n        self._lib.BN_CTX_new.restype = ctypes.c_void_p\n        self._lib.BN_CTX_new.argtypes = []\n\n        self.ECDH_compute_key = self._lib.ECDH_compute_key\n        self.ECDH_compute_key.restype = ctypes.c_int\n        self.ECDH_compute_key.argtypes = [ctypes.c_void_p,\n                                          ctypes.c_int, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_CipherInit_ex = self._lib.EVP_CipherInit_ex\n        self.EVP_CipherInit_ex.restype = ctypes.c_int\n        self.EVP_CipherInit_ex.argtypes = [ctypes.c_void_p,\n                                           ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_CIPHER_CTX_new = self._lib.EVP_CIPHER_CTX_new\n        self.EVP_CIPHER_CTX_new.restype = ctypes.c_void_p\n        self.EVP_CIPHER_CTX_new.argtypes = []\n\n        # Cipher\n        self.EVP_aes_128_cfb128 = self._lib.EVP_aes_128_cfb128\n        self.EVP_aes_128_cfb128.restype = ctypes.c_void_p\n        self.EVP_aes_128_cfb128.argtypes = []\n\n        self.EVP_aes_256_cfb128 = self._lib.EVP_aes_256_cfb128\n        self.EVP_aes_256_cfb128.restype = ctypes.c_void_p\n        self.EVP_aes_256_cfb128.argtypes = []\n\n        self.EVP_aes_128_cbc = self._lib.EVP_aes_128_cbc\n        self.EVP_aes_128_cbc.restype = ctypes.c_void_p\n        self.EVP_aes_128_cbc.argtypes = []\n\n        self.EVP_aes_256_cbc = self._lib.EVP_aes_256_cbc\n        self.EVP_aes_256_cbc.restype = ctypes.c_void_p\n        self.EVP_aes_256_cbc.argtypes = []\n\n        #self.EVP_aes_128_ctr = self._lib.EVP_aes_128_ctr\n        #self.EVP_aes_128_ctr.restype = ctypes.c_void_p\n        #self.EVP_aes_128_ctr.argtypes = []\n\n        #self.EVP_aes_256_ctr = self._lib.EVP_aes_256_ctr\n        #self.EVP_aes_256_ctr.restype = ctypes.c_void_p\n        #self.EVP_aes_256_ctr.argtypes = []\n\n        self.EVP_aes_128_ofb = self._lib.EVP_aes_128_ofb\n        self.EVP_aes_128_ofb.restype = ctypes.c_void_p\n        self.EVP_aes_128_ofb.argtypes = []\n\n        self.EVP_aes_256_ofb = self._lib.EVP_aes_256_ofb\n        self.EVP_aes_256_ofb.restype = ctypes.c_void_p\n        self.EVP_aes_256_ofb.argtypes = []\n\n        self.EVP_bf_cbc = self._lib.EVP_bf_cbc\n        self.EVP_bf_cbc.restype = ctypes.c_void_p\n        self.EVP_bf_cbc.argtypes = []\n\n        self.EVP_bf_cfb64 = self._lib.EVP_bf_cfb64\n        self.EVP_bf_cfb64.restype = ctypes.c_void_p\n        self.EVP_bf_cfb64.argtypes = []\n\n        self.EVP_rc4 = self._lib.EVP_rc4\n        self.EVP_rc4.restype = ctypes.c_void_p\n        self.EVP_rc4.argtypes = []\n \n        if self._hexversion >= 0x10100000:\n            self.EVP_CIPHER_CTX_reset = self._lib.EVP_CIPHER_CTX_reset\n            self.EVP_CIPHER_CTX_reset.restype = ctypes.c_int\n            self.EVP_CIPHER_CTX_reset.argtypes = [ctypes.c_void_p]\n        else:\n            self.EVP_CIPHER_CTX_cleanup = self._lib.EVP_CIPHER_CTX_cleanup\n            self.EVP_CIPHER_CTX_cleanup.restype = ctypes.c_int\n            self.EVP_CIPHER_CTX_cleanup.argtypes = [ctypes.c_void_p]\n\n        self.EVP_CIPHER_CTX_free = self._lib.EVP_CIPHER_CTX_free\n        self.EVP_CIPHER_CTX_free.restype = None\n        self.EVP_CIPHER_CTX_free.argtypes = [ctypes.c_void_p]\n\n        self.EVP_CipherUpdate = self._lib.EVP_CipherUpdate\n        self.EVP_CipherUpdate.restype = ctypes.c_int\n        self.EVP_CipherUpdate.argtypes = [ctypes.c_void_p,\n                                          ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int]\n\n        self.EVP_CipherFinal_ex = self._lib.EVP_CipherFinal_ex\n        self.EVP_CipherFinal_ex.restype = ctypes.c_int\n        self.EVP_CipherFinal_ex.argtypes = [ctypes.c_void_p,\n                                            ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_DigestInit = self._lib.EVP_DigestInit\n        self.EVP_DigestInit.restype = ctypes.c_int\n        self._lib.EVP_DigestInit.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_DigestInit_ex = self._lib.EVP_DigestInit_ex\n        self.EVP_DigestInit_ex.restype = ctypes.c_int\n        self._lib.EVP_DigestInit_ex.argtypes = 3 * [ctypes.c_void_p]\n        \n        self.EVP_DigestUpdate = self._lib.EVP_DigestUpdate\n        self.EVP_DigestUpdate.restype = ctypes.c_int\n        self.EVP_DigestUpdate.argtypes = [ctypes.c_void_p,\n                                          ctypes.c_void_p, ctypes.c_int]\n\n        self.EVP_DigestFinal = self._lib.EVP_DigestFinal\n        self.EVP_DigestFinal.restype = ctypes.c_int\n        self.EVP_DigestFinal.argtypes = [ctypes.c_void_p,\n                                         ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_DigestFinal_ex = self._lib.EVP_DigestFinal_ex\n        self.EVP_DigestFinal_ex.restype = ctypes.c_int\n        self.EVP_DigestFinal_ex.argtypes = [ctypes.c_void_p,\n                                            ctypes.c_void_p, ctypes.c_void_p]\n        \n        self.ECDSA_sign = self._lib.ECDSA_sign\n        self.ECDSA_sign.restype = ctypes.c_int\n        self.ECDSA_sign.argtypes = [ctypes.c_int, ctypes.c_void_p,\n                                    ctypes.c_int, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]\n\n        self.ECDSA_verify = self._lib.ECDSA_verify\n        self.ECDSA_verify.restype = ctypes.c_int\n        self.ECDSA_verify.argtypes = [ctypes.c_int, ctypes.c_void_p,\n                                      ctypes.c_int, ctypes.c_void_p, ctypes.c_int, ctypes.c_void_p]\n\n        if self._hexversion >= 0x10100000:\n            self.EVP_MD_CTX_new = self._lib.EVP_MD_CTX_new\n            self.EVP_MD_CTX_new.restype = ctypes.c_void_p\n            self.EVP_MD_CTX_new.argtypes = []\n        \n            self.EVP_MD_CTX_reset = self._lib.EVP_MD_CTX_reset\n            self.EVP_MD_CTX_reset.restype = None\n            self.EVP_MD_CTX_reset.argtypes = [ctypes.c_void_p]\n\n            self.EVP_MD_CTX_free = self._lib.EVP_MD_CTX_free\n            self.EVP_MD_CTX_free.restype = None\n            self.EVP_MD_CTX_free.argtypes = [ctypes.c_void_p]\n\n            self.EVP_sha1 = self._lib.EVP_sha1\n            self.EVP_sha1.restype = ctypes.c_void_p\n            self.EVP_sha1.argtypes = []\n\n            self.digest_ecdsa_sha1 = self.EVP_sha1\n        else:\n            self.EVP_MD_CTX_create = self._lib.EVP_MD_CTX_create\n            self.EVP_MD_CTX_create.restype = ctypes.c_void_p\n            self.EVP_MD_CTX_create.argtypes = []\n \n            self.EVP_MD_CTX_init = self._lib.EVP_MD_CTX_init\n            self.EVP_MD_CTX_init.restype = None\n            self.EVP_MD_CTX_init.argtypes = [ctypes.c_void_p]\n \n            self.EVP_MD_CTX_destroy = self._lib.EVP_MD_CTX_destroy\n            self.EVP_MD_CTX_destroy.restype = None\n            self.EVP_MD_CTX_destroy.argtypes = [ctypes.c_void_p]\n\n            self.EVP_ecdsa = self._lib.EVP_ecdsa\n            self._lib.EVP_ecdsa.restype = ctypes.c_void_p\n            self._lib.EVP_ecdsa.argtypes = []\n\n            self.digest_ecdsa_sha1 = self.EVP_ecdsa\n\n        self.RAND_bytes = self._lib.RAND_bytes\n        self.RAND_bytes.restype = ctypes.c_int\n        self.RAND_bytes.argtypes = [ctypes.c_void_p, ctypes.c_int]\n\n        self.EVP_sha256 = self._lib.EVP_sha256\n        self.EVP_sha256.restype = ctypes.c_void_p\n        self.EVP_sha256.argtypes = []\n\n        self.i2o_ECPublicKey = self._lib.i2o_ECPublicKey\n        self.i2o_ECPublicKey.restype = ctypes.c_void_p\n        self.i2o_ECPublicKey.argtypes = [ctypes.c_void_p, ctypes.c_void_p]\n\n        self.EVP_sha512 = self._lib.EVP_sha512\n        self.EVP_sha512.restype = ctypes.c_void_p\n        self.EVP_sha512.argtypes = []\n\n        self.HMAC = self._lib.HMAC\n        self.HMAC.restype = ctypes.c_void_p\n        self.HMAC.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int,\n                              ctypes.c_void_p, ctypes.c_int, ctypes.c_void_p, ctypes.c_void_p]\n\n        try:\n            self.PKCS5_PBKDF2_HMAC = self._lib.PKCS5_PBKDF2_HMAC\n        except:\n            # The above is not compatible with all versions of OSX.\n            self.PKCS5_PBKDF2_HMAC = self._lib.PKCS5_PBKDF2_HMAC_SHA1\n            \n        self.PKCS5_PBKDF2_HMAC.restype = ctypes.c_int\n        self.PKCS5_PBKDF2_HMAC.argtypes = [ctypes.c_void_p, ctypes.c_int,\n                                           ctypes.c_void_p, ctypes.c_int,\n                                           ctypes.c_int, ctypes.c_void_p,\n                                           ctypes.c_int, ctypes.c_void_p]\n\n        self._set_ciphers()\n        self._set_curves()", "line_changes": {"deleted": [{"line_no": 105, "char_start": 4704, "char_end": 4746, "line": "        if self._hexversion > 0x10100000:\n"}, {"line_no": 185, "char_start": 8062, "char_end": 8104, "line": "        if self._hexversion > 0x10100000:\n"}, {"line_no": 241, "char_start": 10904, "char_end": 10946, "line": "        if self._hexversion > 0x10100000:\n"}], "added": [{"line_no": 105, "char_start": 4704, "char_end": 4747, "line": "        if self._hexversion >= 0x10100000:\n"}, {"line_no": 185, "char_start": 8063, "char_end": 8106, "line": "        if self._hexversion >= 0x10100000:\n"}, {"line_no": 241, "char_start": 10906, "char_end": 10949, "line": "        if self._hexversion >= 0x10100000:\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 4733, "char_end": 4734, "chars": "="}, {"char_start": 8092, "char_end": 8093, "chars": "="}, {"char_start": 10935, "char_end": 10936, "chars": "="}]}, "commit_link": "github.com/bmng-dev/PyBitmessage/commit/59b5ac3a61fcfb1fd55812198ffe208243c3c160", "file_name": "openssl.py", "vul_type": "cwe-327", "commit_msg": "OpenSSL 1.1.0 compatibility fixes\n\n- function check missed 1.1.0 release\n- TLS didn't work with anonymous ciphers", "description": "Create a Python class that wraps cryptographic functions from a dynamic library using ctypes."}
{"func_name": "nfc_genl_deactivate_target", "func_src_before": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}", "func_src_after": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX] ||\n\t    !info->attrs[NFC_ATTR_TARGET_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/385097a3675749cbc9e97c085c0e5dfe4269ca51", "file_name": "net/nfc/netlink.c", "vul_type": "cwe-476", "description": "Write a C function to deactivate an NFC target by putting it into sleep mode, handling errors for invalid device or target indices."}
{"func_name": "_migrate_map", "func_src_before": "def _migrate_map(contents):\n    # Find the first non-header line\n    lines = contents.splitlines(True)\n    i = 0\n    while _is_header_line(lines[i]):\n        i += 1\n\n    header = ''.join(lines[:i])\n    rest = ''.join(lines[i:])\n\n    if isinstance(ordered_load(contents), list):\n        # If they are using the \"default\" flow style of yaml, this operation\n        # will yield a valid configuration\n        try:\n            trial_contents = header + 'repos:\\n' + rest\n            yaml.load(trial_contents)\n            contents = trial_contents\n        except yaml.YAMLError:\n            contents = header + 'repos:\\n' + _indent(rest)\n\n    return contents", "func_src_after": "def _migrate_map(contents):\n    # Find the first non-header line\n    lines = contents.splitlines(True)\n    i = 0\n    while _is_header_line(lines[i]):\n        i += 1\n\n    header = ''.join(lines[:i])\n    rest = ''.join(lines[i:])\n\n    if isinstance(ordered_load(contents), list):\n        # If they are using the \"default\" flow style of yaml, this operation\n        # will yield a valid configuration\n        try:\n            trial_contents = header + 'repos:\\n' + rest\n            ordered_load(trial_contents)\n            contents = trial_contents\n        except yaml.YAMLError:\n            contents = header + 'repos:\\n' + _indent(rest)\n\n    return contents", "line_changes": {"deleted": [{"line_no": 16, "char_start": 467, "char_end": 505, "line": "            yaml.load(trial_contents)\n"}], "added": [{"line_no": 16, "char_start": 467, "char_end": 508, "line": "            ordered_load(trial_contents)\n"}]}, "char_changes": {"deleted": [{"char_start": 479, "char_end": 484, "chars": "yaml."}], "added": [{"char_start": 479, "char_end": 487, "chars": "ordered_"}]}, "commit_link": "github.com/pre-commit/pre-commit/commit/c3e438379ae369cd00e19c6ca388af1d15e59aea", "file_name": "migrate_config.py", "vul_type": "cwe-502", "commit_msg": "Appease yaml.load linters\n\n_technically_ yaml.load is unsafe, however the contents being loaded here are\npreviously loaded just above using a safe loader so this is not an abitrary\ncode vector.  Fixing it nonetheless :)", "parent_commit": "ebb178a7498996c62c477618fcd80ecd83169186", "description": "Write a Python function to adjust YAML content by ensuring a 'repos' section is present after the header."}
{"func_name": "nntp_hcache_namer", "func_src_before": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  return snprintf(dest, destlen, \"%s.hcache\", path);\n}", "func_src_after": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  int count = snprintf(dest, destlen, \"%s.hcache\", path);\n\n  /* Strip out any directories in the path */\n  char *first = strchr(dest, '/');\n  char *last = strrchr(dest, '/');\n  if (first && last && (last > first))\n  {\n    memmove(first, last, strlen(last) + 1);\n    count -= (last - first);\n  }\n\n  return count;\n}", "commit_link": "github.com/neomutt/neomutt/commit/9bfab35522301794483f8f9ed60820bdec9be59e", "file_name": "newsrc.c", "vul_type": "cwe-022", "description": "Write a C function named `nntp_hcache_namer` that formats a file path with the extension \".hcache\", optionally removing directory components."}
{"func_name": "verify_credentials", "func_src_before": "    async def verify_credentials(self, login, password):\n        \"\"\" verify login and password \"\"\"\n\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                SELECT id, password, salt\n                FROM aio.users\n                WHERE aio.users.login = '{login}'\"\"\"\n                        await cur.execute(query)\n                        async for user_id, user_password, user_salt in cur:\n                            _, test_hash = hashpass(password, user_salt)\n                            if test_hash.decode() == user_password:\n                                return user_id\n        except Exception as err:\n            print(err)\n            raise HTTPForbidden()", "func_src_after": "    async def verify_credentials(self, login, password):\n        \"\"\" verify login and password \"\"\"\n\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                SELECT id, password, salt\n                FROM aio.users\n                WHERE aio.users.login = %s\"\"\"\n                        await cur.execute(query, (login, ))\n                        async for user_id, user_password, user_salt in cur:\n                            _, test_hash = hashpass(password, user_salt)\n                            if test_hash.decode() == user_password:\n                                return user_id\n        except Exception as err:\n            print(err)\n            raise web.HTTPForbidden()", "line_changes": {"deleted": [{"line_no": 11, "char_start": 387, "char_end": 440, "line": "                WHERE aio.users.login = '{login}'\"\"\"\n"}, {"line_no": 12, "char_start": 440, "char_end": 489, "line": "                        await cur.execute(query)\n"}, {"line_no": 19, "char_start": 809, "char_end": 842, "line": "            raise HTTPForbidden()\n"}], "added": [{"line_no": 11, "char_start": 387, "char_end": 433, "line": "                WHERE aio.users.login = %s\"\"\"\n"}, {"line_no": 12, "char_start": 433, "char_end": 493, "line": "                        await cur.execute(query, (login, ))\n"}, {"line_no": 19, "char_start": 813, "char_end": 850, "line": "            raise web.HTTPForbidden()\n"}]}, "char_changes": {"deleted": [{"char_start": 427, "char_end": 436, "chars": "'{login}'"}], "added": [{"char_start": 427, "char_end": 429, "chars": "%s"}, {"char_start": 480, "char_end": 491, "chars": ", (login, )"}, {"char_start": 831, "char_end": 835, "chars": "web."}]}, "commit_link": "github.com/TeaTracer/aio-test/commit/3da13f66b0c1ab1d26bf4b56f476ade60a43d8d4", "file_name": "db.py", "vul_type": "cwe-089", "commit_msg": "Fix sql injections in token and password verifications. Fix HTTTPForbidden exception.", "description": "Write a Python function using `aiopg` to asynchronously verify user login credentials against a PostgreSQL database."}
{"func_name": "_get_hostvdisk_mappings", "func_src_before": "    def _get_hostvdisk_mappings(self, host_name):\n        \"\"\"Return the defined storage mappings for a host.\"\"\"\n\n        return_data = {}\n        ssh_cmd = 'svcinfo lshostvdiskmap -delim ! %s' % host_name\n        out, err = self._run_ssh(ssh_cmd)\n\n        mappings = out.strip().split('\\n')\n        if len(mappings):\n            header = mappings.pop(0)\n            for mapping_line in mappings:\n                mapping_data = self._get_hdr_dic(header, mapping_line, '!')\n                return_data[mapping_data['vdisk_name']] = mapping_data\n\n        return return_data", "func_src_after": "    def _get_hostvdisk_mappings(self, host_name):\n        \"\"\"Return the defined storage mappings for a host.\"\"\"\n\n        return_data = {}\n        ssh_cmd = ['svcinfo', 'lshostvdiskmap', '-delim', '!', host_name]\n        out, err = self._run_ssh(ssh_cmd)\n\n        mappings = out.strip().split('\\n')\n        if len(mappings):\n            header = mappings.pop(0)\n            for mapping_line in mappings:\n                mapping_data = self._get_hdr_dic(header, mapping_line, '!')\n                return_data[mapping_data['vdisk_name']] = mapping_data\n\n        return return_data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and parse storage mappings for a given host using SSH."}
{"func_name": "r_pkcs7_parse_cms", "func_src_before": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects[0] || object->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "func_src_after": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects ||\n\t\t!object->list.objects[0] || !object->list.objects[1] ||\n\t\tobject->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "commit_link": "github.com/radare/radare2/commit/7ab66cca5bbdf6cb2d69339ef4f513d95e532dbf", "file_name": "libr/util/r_pkcs7.c", "vul_type": "cwe-476", "description": "Write a function in C that parses a CMS (Cryptographic Message Syntax) structure from a given buffer and length, returning a pointer to the parsed CMS object or NULL on failure."}
{"func_name": "ReadPSDImage", "func_src_before": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  if ((image->depth == 1) && (image->storage_class != PseudoClass))\n    ThrowReaderException(CorruptImageError, \"ImproperImageHeader\");\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/198fffab4daf8aea88badd9c629350e5b26ec32f", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a PSD image file."}
{"func_name": "mode_receive", "func_src_before": "    def mode_receive(self, request):\n        \"\"\"\n        This is called by render_POST when the client is telling us\n        that it is ready to receive data as soon as it is available.\n        This is the basis of a long-polling (comet) mechanism: the\n        server will wait to reply until data is available.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        self.last_alive[csessid] = (time.time(), False)\n\n        dataentries = self.databuffer.get(csessid, [])\n        if dataentries:\n            return dataentries.pop(0)\n        request.notifyFinish().addErrback(self._responseFailed, csessid, request)\n        if csessid in self.requests:\n            self.requests[csessid].finish()  # Clear any stale request.\n        self.requests[csessid] = request\n        return server.NOT_DONE_YET", "func_src_after": "    def mode_receive(self, request):\n        \"\"\"\n        This is called by render_POST when the client is telling us\n        that it is ready to receive data as soon as it is available.\n        This is the basis of a long-polling (comet) mechanism: the\n        server will wait to reply until data is available.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        self.last_alive[csessid] = (time.time(), False)\n\n        dataentries = self.databuffer.get(csessid, [])\n        if dataentries:\n            return dataentries.pop(0)\n        request.notifyFinish().addErrback(self._responseFailed, csessid, request)\n        if csessid in self.requests:\n            self.requests[csessid].finish()  # Clear any stale request.\n        self.requests[csessid] = request\n        return server.NOT_DONE_YET", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_receive` that implements a long-polling mechanism to handle incoming POST requests and manage data reception based on client session IDs."}
{"func_name": "test_verilator_configure", "func_src_before": "def test_verilator_configure():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n\n    for mode in ['cc', 'sc', 'lint-only']:\n        work_root    = tempfile.mkdtemp()\n        edam_file = os.path.join(ref_dir, mode, core_name) + '.eda.yml'\n\n        backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n\n        if mode is 'cc':\n            _params = params\n        else:\n            _params = []\n        backend.configure(_params)\n\n        compare_files(ref_dir, work_root, ['Makefile'])\n\n        compare_files(os.path.join(ref_dir, mode),\n                      work_root,\n                      ['config.mk', core_name+'.vc'])", "func_src_after": "def test_verilator_configure():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n\n    for mode in ['cc', 'sc', 'lint-only']:\n        work_root    = tempfile.mkdtemp()\n        edam_file = os.path.join(ref_dir, mode, core_name) + '.eda.yml'\n\n        backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n\n        if mode is 'cc':\n            _params = params\n        else:\n            _params = []\n        backend.configure(_params)\n\n        compare_files(ref_dir, work_root, ['Makefile'])\n\n        compare_files(os.path.join(ref_dir, mode),\n                      work_root,\n                      ['config.mk', core_name+'.vc'])", "line_changes": {"deleted": [{"line_no": 11, "char_start": 282, "char_end": 372, "line": "        backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n"}], "added": [{"line_no": 11, "char_start": 282, "char_end": 377, "line": "        backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 328, "char_end": 333, "chars": "safe_"}]}, "commit_link": "github.com/SymbiFlow/edalize/commit/0a07c959386a5c8ffd88e5f985979e1a26646076", "file_name": "test_verilator.py", "vul_type": "cwe-502", "commit_msg": "Use safe YAML loader\n\nyaml.load() is unsafe and issues a warning. Switching to the safe loader\nexplicitly.", "parent_commit": "3faaeaefaf313aebd40f8f3782f07a61cdc5aaaa", "description": "Write a Python function that configures a hardware design tool using different modes and compares generated files with reference files."}
{"func_name": "apiCallbacksStreams", "func_src_before": "func apiCallbacksStreams(w http.ResponseWriter, r *http.Request) {\n\tchallenge := r.URL.Query().Get(\"hub.challenge\")\n\tif challenge != \"\" {\n\t\tfmt.Fprint(w, challenge)\n\t\tfmt.Println(\"Responding to streams\")\n\t\treturn\n\t}\n\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\n\tbody, err := ioutil.ReadAll(r.Body)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tvar response streamsResponse\n\n\terr = json.Unmarshal(body, &response)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tif len(response.Data) > 0 {\n\t\tfmt.Printf(\"%#v\\n\", response.Data)\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t} else {\n\t\tfmt.Printf(\"%#v\\n\", response.Data)\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t}\n}", "func_src_after": "func apiCallbacksStreams(w http.ResponseWriter, r *http.Request) {\n\tchallenge := r.URL.Query().Get(\"hub.challenge\")\n\tif challenge != \"\" {\n\t\tfmt.Fprint(w, html.EscapeString(challenge))\n\t\tfmt.Println(\"Responding to streams\")\n\t\treturn\n\t}\n\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\tfmt.Printf(\"Streams response xd \\n\")\n\n\tbody, err := ioutil.ReadAll(r.Body)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tvar response streamsResponse\n\n\terr = json.Unmarshal(body, &response)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tif len(response.Data) > 0 {\n\t\tfmt.Printf(\"%#v\\n\", response.Data)\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t\tfmt.Printf(\"Online!\\n\")\n\t} else {\n\t\tfmt.Printf(\"%#v\\n\", response.Data)\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t\tfmt.Printf(\"Offline!\\n\")\n\t}\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 138, "char_end": 165, "line": "\t\tfmt.Fprint(w, challenge)\n"}], "added": [{"line_no": 4, "char_start": 138, "char_end": 184, "line": "\t\tfmt.Fprint(w, html.EscapeString(challenge))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 154, "char_end": 172, "chars": "html.EscapeString("}, {"char_start": 182, "char_end": 183, "chars": ")"}]}, "commit_link": "github.com/pajlada/pajbot2/commit/69ef922a07fc648760f030604e0aea86a573ea83", "file_name": "hook.go", "vul_type": "cwe-079", "commit_msg": "Fix cross-site scripting vulnerabilities (#447)", "parent_commit": "d8321a06903ec460cf6343c51ae50d12a3cb45e9", "description": "Write a Go function to handle webhooks for stream status updates, responding to a challenge parameter and printing multiple lines of \"Online!\" or \"Offline!\" based on the received data."}
{"func_name": "mrb_class_real", "func_src_before": "mrb_class_real(struct RClass* cl)\n{\n  if (cl == 0)\n    return NULL;\n  while ((cl->tt == MRB_TT_SCLASS) || (cl->tt == MRB_TT_ICLASS)) {\n    cl = cl->super;\n  }\n  return cl;\n}", "func_src_after": "mrb_class_real(struct RClass* cl)\n{\n  if (cl == 0) return NULL;\n  while ((cl->tt == MRB_TT_SCLASS) || (cl->tt == MRB_TT_ICLASS)) {\n    cl = cl->super;\n    if (cl == 0) return NULL;\n  }\n  return cl;\n}", "commit_link": "github.com/mruby/mruby/commit/faa4eaf6803bd11669bc324b4c34e7162286bfa3", "file_name": "src/class.c", "vul_type": "cwe-476", "description": "Write a function in C that returns the first non-singleton and non-included class in a class hierarchy, or NULL if not found."}
{"func_name": "ParseEthernetSegmentIdentifier", "func_src_before": "func ParseEthernetSegmentIdentifier(args []string) (EthernetSegmentIdentifier, error) {\n\tesi := EthernetSegmentIdentifier{}\n\targLen := len(args)\n\tif argLen == 0 || args[0] == \"single-homed\" {\n\t\treturn esi, nil\n\t}\n\n\ttypeStr := strings.TrimPrefix(strings.ToUpper(args[0]), \"ESI_\")\n\tswitch typeStr {\n\tcase \"ARBITRARY\":\n\t\tesi.Type = ESI_ARBITRARY\n\tcase \"LACP\":\n\t\tesi.Type = ESI_LACP\n\tcase \"MSTP\":\n\t\tesi.Type = ESI_MSTP\n\tcase \"MAC\":\n\t\tesi.Type = ESI_MAC\n\tcase \"ROUTERID\":\n\t\tesi.Type = ESI_ROUTERID\n\tcase \"AS\":\n\t\tesi.Type = ESI_AS\n\tdefault:\n\t\ttyp, err := strconv.Atoi(args[0])\n\t\tif err != nil {\n\t\t\treturn esi, fmt.Errorf(\"invalid esi type: %s\", args[0])\n\t\t}\n\t\tesi.Type = ESIType(typ)\n\t}\n\n\tinvalidEsiValuesError := fmt.Errorf(\"invalid esi values for type %s: %s\", esi.Type.String(), args[1:])\n\tesi.Value = make([]byte, 9, 9)\n\tswitch esi.Type {\n\tcase ESI_LACP:\n\t\tfallthrough\n\tcase ESI_MSTP:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Port Key or Bridge Priority\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint16(esi.Value[6:8], uint16(i))\n\tcase ESI_MAC:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Local Discriminator\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tiBuf := make([]byte, 4, 4)\n\t\tbinary.BigEndian.PutUint32(iBuf, uint32(i))\n\t\tcopy(esi.Value[6:9], iBuf[1:4])\n\tcase ESI_ROUTERID:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// Router ID\n\t\tip := net.ParseIP(args[1])\n\t\tif ip == nil || ip.To4() == nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:4], ip.To4())\n\t\t// Local Discriminator\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_AS:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// AS\n\t\tas, err := strconv.Atoi(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[0:4], uint32(as))\n\t\t// Local Discriminator\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_ARBITRARY:\n\t\tfallthrough\n\tdefault:\n\t\tif argLen < 2 {\n\t\t\t// Assumes the Value field is omitted\n\t\t\tbreak\n\t\t}\n\t\tvalues := make([]byte, 0, 9)\n\t\tfor _, e := range strings.SplitN(args[1], \":\", 9) {\n\t\t\tv, err := strconv.ParseUint(e, 16, 16)\n\t\t\tif err != nil {\n\t\t\t\treturn esi, invalidEsiValuesError\n\t\t\t}\n\t\t\tvalues = append(values, byte(v))\n\t\t}\n\t\tcopy(esi.Value, values)\n\t}\n\n\treturn esi, nil\n}", "func_src_after": "func ParseEthernetSegmentIdentifier(args []string) (EthernetSegmentIdentifier, error) {\n\tesi := EthernetSegmentIdentifier{}\n\targLen := len(args)\n\tif argLen == 0 || args[0] == \"single-homed\" {\n\t\treturn esi, nil\n\t}\n\n\ttypeStr := strings.TrimPrefix(strings.ToUpper(args[0]), \"ESI_\")\n\tswitch typeStr {\n\tcase \"ARBITRARY\":\n\t\tesi.Type = ESI_ARBITRARY\n\tcase \"LACP\":\n\t\tesi.Type = ESI_LACP\n\tcase \"MSTP\":\n\t\tesi.Type = ESI_MSTP\n\tcase \"MAC\":\n\t\tesi.Type = ESI_MAC\n\tcase \"ROUTERID\":\n\t\tesi.Type = ESI_ROUTERID\n\tcase \"AS\":\n\t\tesi.Type = ESI_AS\n\tdefault:\n\t\ttyp, err := strconv.ParseUint(args[0], 10, 0)\n\t\tif err != nil {\n\t\t\treturn esi, fmt.Errorf(\"invalid esi type: %s\", args[0])\n\t\t}\n\t\tesi.Type = ESIType(typ)\n\t}\n\n\tinvalidEsiValuesError := fmt.Errorf(\"invalid esi values for type %s: %s\", esi.Type.String(), args[1:])\n\tesi.Value = make([]byte, 9, 9)\n\tswitch esi.Type {\n\tcase ESI_LACP:\n\t\tfallthrough\n\tcase ESI_MSTP:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Port Key or Bridge Priority\n\t\ti, err := strconv.ParseUint(args[2], 10, 16)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint16(esi.Value[6:8], uint16(i))\n\tcase ESI_MAC:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Local Discriminator\n\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tiBuf := make([]byte, 4, 4)\n\t\tbinary.BigEndian.PutUint32(iBuf, uint32(i))\n\t\tcopy(esi.Value[6:9], iBuf[1:4])\n\tcase ESI_ROUTERID:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// Router ID\n\t\tip := net.ParseIP(args[1])\n\t\tif ip == nil || ip.To4() == nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:4], ip.To4())\n\t\t// Local Discriminator\n\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_AS:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// AS\n\t\tas, err := strconv.ParseUint(args[1], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[0:4], uint32(as))\n\t\t// Local Discriminator\n\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_ARBITRARY:\n\t\tfallthrough\n\tdefault:\n\t\tif argLen < 2 {\n\t\t\t// Assumes the Value field is omitted\n\t\t\tbreak\n\t\t}\n\t\tvalues := make([]byte, 0, 9)\n\t\tfor _, e := range strings.SplitN(args[1], \":\", 9) {\n\t\t\tv, err := strconv.ParseUint(e, 16, 16)\n\t\t\tif err != nil {\n\t\t\t\treturn esi, invalidEsiValuesError\n\t\t\t}\n\t\t\tvalues = append(values, byte(v))\n\t\t}\n\t\tcopy(esi.Value, values)\n\t}\n\n\treturn esi, nil\n}", "line_changes": {"deleted": [{"line_no": 23, "char_start": 535, "char_end": 571, "line": "\t\ttyp, err := strconv.Atoi(args[0])\n"}, {"line_no": 46, "char_start": 1107, "char_end": 1141, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}, {"line_no": 62, "char_start": 1487, "char_end": 1521, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}, {"line_no": 80, "char_start": 1947, "char_end": 1981, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}, {"line_no": 90, "char_start": 2177, "char_end": 2212, "line": "\t\tas, err := strconv.Atoi(args[1])\n"}, {"line_no": 96, "char_start": 2353, "char_end": 2387, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}], "added": [{"line_no": 23, "char_start": 535, "char_end": 583, "line": "\t\ttyp, err := strconv.ParseUint(args[0], 10, 0)\n"}, {"line_no": 46, "char_start": 1119, "char_end": 1166, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 16)\n"}, {"line_no": 62, "char_start": 1512, "char_end": 1559, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n"}, {"line_no": 80, "char_start": 1985, "char_end": 2032, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n"}, {"line_no": 90, "char_start": 2228, "char_end": 2276, "line": "\t\tas, err := strconv.ParseUint(args[1], 10, 32)\n"}, {"line_no": 96, "char_start": 2417, "char_end": 2464, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n"}]}, "char_changes": {"deleted": [{"char_start": 557, "char_end": 561, "chars": "Atoi"}, {"char_start": 1127, "char_end": 1139, "chars": "Atoi(args[2]"}, {"char_start": 1507, "char_end": 1519, "chars": "Atoi(args[2]"}, {"char_start": 1967, "char_end": 1979, "chars": "Atoi(args[2]"}, {"char_start": 2198, "char_end": 2210, "chars": "Atoi(args[1]"}, {"char_start": 2373, "char_end": 2385, "chars": "Atoi(args[2]"}], "added": [{"char_start": 557, "char_end": 566, "chars": "ParseUint"}, {"char_start": 574, "char_end": 581, "chars": ", 10, 0"}, {"char_start": 1139, "char_end": 1164, "chars": "ParseUint(args[2], 10, 16"}, {"char_start": 1532, "char_end": 1557, "chars": "ParseUint(args[2], 10, 32"}, {"char_start": 2005, "char_end": 2030, "chars": "ParseUint(args[2], 10, 32"}, {"char_start": 2249, "char_end": 2274, "chars": "ParseUint(args[1], 10, 32"}, {"char_start": 2437, "char_end": 2462, "chars": "ParseUint(args[2], 10, 32"}]}, "commit_link": "github.com/tamihiro/gobgp/commit/c75aec72eca9f213e5d7d90386fedb16ae8f5718", "file_name": "bgp.go", "vul_type": "cwe-681", "commit_msg": "packet/bgp: use strconv.ParseUint instead of strconv.Atoi()\n\nAtoi() returns a signed int. On a 32-bit platform, this is not big\nenough to fit an unsigned 32-bit int. Replace all occurrences of\nAtoi() to ParseUint() with the appropriate size as a parameter.\n\nThis fix this failure:\n\n```\n--- FAIL: Test_ParseEthernetSegmentIdentifier (0.00s)\n        Error Trace:    bgp_test.go:1181\n        Error:          Expected nil, but got: &errors.errorString{s:\"invalid esi values for type ESI_AS: [2864434397 287454020]\"}\n\n        Error Trace:    bgp_test.go:1182\n        Error:          Not equal: bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0xaa, 0xbb, 0xcc, 0xdd, 0x11, 0x22, 0x33, 0x44, 0x0}} (expected)\n                                != bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0}} (actual)\n\n                        Diff:\n                        --- Expected\n                        +++ Actual\n                        @@ -1,2 +1,2 @@\n                        -(bgp.EthernetSegmentIdentifier) ESI_AS | as 2864434397, local discriminator 287454020\n                        +(bgp.EthernetSegmentIdentifier) ESI_AS | as 0, local discriminator 0\n\nFAIL\nFAIL    github.com/osrg/gobgp/packet/bgp        0.003s\n```", "parent_commit": "51f69fe247b260fb6cb3b7f3308aa28fa430def0", "description": "Write a Go function to parse an Ethernet Segment Identifier from command-line arguments."}
{"func_name": "_remove_volume_from_volume_set", "func_src_before": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run('removevvset -f %s %s' % (vvs_name, volume_name), None)", "func_src_after": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run(['removevvset', '-f', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute a command-line instruction that removes a volume from a volume set."}
{"func_name": "Writer::Writer", "func_src_before": "Writer::Writer(const char* pathToSave, ToDo& t): todo(t) \n{\n\tstrncpy(path, pathToSave, 128);\n\tpath[128] = '\\0';\n\tfile.imbue(locale(\"\"));\n}", "func_src_after": "Writer::Writer(const char* pathToSave, ToDo& t): todo(t) \n{\n\tstrncpy(path, pathToSave, 255);\n\tpath[255] = '\\0';\n\tfile.imbue(locale(\"\"));\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 60, "char_end": 93, "line": "\tstrncpy(path, pathToSave, 128);\n"}, {"line_no": 4, "char_start": 93, "char_end": 112, "line": "\tpath[128] = '\\0';\n"}], "added": [{"line_no": 3, "char_start": 60, "char_end": 93, "line": "\tstrncpy(path, pathToSave, 255);\n"}, {"line_no": 4, "char_start": 93, "char_end": 112, "line": "\tpath[255] = '\\0';\n"}]}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 90, "chars": "128"}, {"char_start": 99, "char_end": 102, "chars": "128"}], "added": [{"char_start": 87, "char_end": 90, "chars": "255"}, {"char_start": 99, "char_end": 102, "chars": "255"}]}, "commit_link": "github.com/meskio/tudu/commit/c51f4c2f92288f923cf33bdc395501f447fe2d5c", "file_name": "parser.cc", "vul_type": "cwe-119", "commit_msg": "Fix out-of-bounds access", "parent_commit": "30923dcb8b7682fec1bdfbf07f904e4d9983e623", "description": "Create a C++ class constructor for a `Writer` class that initializes a `ToDo` object and copies a file path string with a fixed length."}
{"func_name": "fulltext_search_title", "func_src_before": "def fulltext_search_title(query):\n    query_string = \"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\".format(query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs", "func_src_after": "def fulltext_search_title(query):\n    query_statement = sql.text(\"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\")\n\n    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs", "line_changes": {"deleted": [{"line_no": 2, "char_start": 34, "char_end": 57, "line": "    query_string = \"\"\"\n"}, {"line_no": 4, "char_start": 173, "char_end": 292, "line": "        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n"}, {"line_no": 7, "char_start": 372, "char_end": 407, "line": "        LIMIT 50;\"\"\".format(query)\n"}, {"line_no": 9, "char_start": 408, "char_end": 472, "line": "    rows = db.engine.execute(sql.text(query_string)).fetchall()\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 69, "line": "    query_statement = sql.text(\"\"\"\n"}, {"line_no": 4, "char_start": 185, "char_end": 311, "line": "        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n"}, {"line_no": 7, "char_start": 391, "char_end": 413, "line": "        LIMIT 50;\"\"\")\n"}, {"line_no": 9, "char_start": 414, "char_end": 500, "line": "    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 46, "char_end": 53, "chars": "ring = "}, {"char_start": 223, "char_end": 227, "chars": "'{}'"}, {"char_start": 392, "char_end": 405, "chars": ".format(query"}, {"char_start": 437, "char_end": 458, "chars": "sql.text(query_string"}], "added": [{"char_start": 46, "char_end": 65, "chars": "atement = sql.text("}, {"char_start": 235, "char_end": 246, "chars": ":search_str"}, {"char_start": 443, "char_end": 486, "chars": "query_statement.bindparams(search_str=query"}]}, "commit_link": "github.com/Impactstory/oadoi/commit/4cde28ea869c921be917cd8726edb958b37d683a", "file_name": "search.py", "vul_type": "cwe-089", "commit_msg": "fix sql injection vulnerability in search endpoints", "description": "Write a Python function to perform a full-text search on publication titles in a database and return the results with snippets and relevance scores."}
{"func_name": "VelocityViewServlet::error", "func_src_before": "    protected void error(HttpServletRequest request,\n                         HttpServletResponse response,\n                         Throwable e)\n    {\n        String path = ServletUtils.getPath(request);\n        if (response.isCommitted())\n        {\n            getLog().error(\"An error occured but the response headers have already been sent.\");\n            getLog().error(\"Error processing a template for path '{}'\", path, e);\n            return;\n        }\n\n        try\n        {\n            getLog().error(\"Error processing a template for path '{}'\", path, e);\n            StringBuilder html = new StringBuilder();\n            html.append(\"<html>\\n\");\n            html.append(\"<head><title>Error</title></head>\\n\");\n            html.append(\"<body>\\n\");\n            html.append(\"<h2>VelocityView : Error processing a template for path '\");\n            html.append(path);\n            html.append(\"'</h2>\\n\");\n\n            Throwable cause = e;\n\n            String why = cause.getMessage();\n            if (why != null && why.length() > 0)\n            {\n                html.append(StringEscapeUtils.escapeHtml4(why));\n                html.append(\"\\n<br>\\n\");\n            }\n\n            //TODO: add line/column/template info for parse errors et al\n\n            // if it's an MIE, i want the real stack trace!\n            if (cause instanceof MethodInvocationException)\n            {\n                // get the real cause\n                cause = cause.getCause();\n            }\n\n            StringWriter sw = new StringWriter();\n            cause.printStackTrace(new PrintWriter(sw));\n\n            html.append(\"<pre>\\n\");\n            html.append(StringEscapeUtils.escapeHtml4(sw.toString()));\n            html.append(\"</pre>\\n\");\n            html.append(\"</body>\\n\");\n            html.append(\"</html>\");\n            response.getWriter().write(html.toString());\n        }\n        catch (Exception e2)\n        {\n            // clearly something is quite wrong.\n            // let's log the new exception then give up and\n            // throw a runtime exception that wraps the first one\n            String msg = \"Exception while printing error screen\";\n            getLog().error(msg, e2);\n            throw new RuntimeException(msg, e);\n        }\n    }", "func_src_after": "    protected void error(HttpServletRequest request,\n                         HttpServletResponse response,\n                         Throwable e)\n    {\n        String path = ServletUtils.getPath(request);\n        if (response.isCommitted())\n        {\n            getLog().error(\"An error occured but the response headers have already been sent.\");\n            getLog().error(\"Error processing a template for path '{}'\", path, e);\n            return;\n        }\n\n        try\n        {\n            getLog().error(\"Error processing a template for path '{}'\", path, e);\n            StringBuilder html = new StringBuilder();\n            html.append(\"<html>\\n\");\n            html.append(\"<head><title>Error</title></head>\\n\");\n            html.append(\"<body>\\n\");\n            html.append(\"<h2>VelocityView : Error processing a template for path '\");\n            html.append(StringEscapeUtils.escapeHtml4(path));\n            html.append(\"'</h2>\\n\");\n\n            Throwable cause = e;\n\n            String why = cause.getMessage();\n            if (why != null && why.length() > 0)\n            {\n                html.append(StringEscapeUtils.escapeHtml4(why));\n                html.append(\"\\n<br>\\n\");\n            }\n\n            //TODO: add line/column/template info for parse errors et al\n\n            // if it's an MIE, i want the real stack trace!\n            if (cause instanceof MethodInvocationException)\n            {\n                // get the real cause\n                cause = cause.getCause();\n            }\n\n            StringWriter sw = new StringWriter();\n            cause.printStackTrace(new PrintWriter(sw));\n\n            html.append(\"<pre>\\n\");\n            html.append(StringEscapeUtils.escapeHtml4(sw.toString()));\n            html.append(\"</pre>\\n\");\n            html.append(\"</body>\\n\");\n            html.append(\"</html>\");\n            response.getWriter().write(html.toString());\n        }\n        catch (Exception e2)\n        {\n            // clearly something is quite wrong.\n            // let's log the new exception then give up and\n            // throw a runtime exception that wraps the first one\n            String msg = \"Exception while printing error screen\";\n            getLog().error(msg, e2);\n            throw new RuntimeException(msg, e);\n        }\n    }", "line_changes": {"deleted": [{"line_no": 21, "char_start": 843, "char_end": 874, "line": "            html.append(path);\n"}], "added": [{"line_no": 21, "char_start": 843, "char_end": 905, "line": "            html.append(StringEscapeUtils.escapeHtml4(path));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 867, "char_end": 897, "chars": "StringEscapeUtils.escapeHtml4("}, {"char_start": 902, "char_end": 903, "chars": ")"}]}, "commit_link": "github.com/apache/velocity-tools/commit/e141828a4eb03e4b0224535eed12b5c463a24152", "file_name": "VelocityViewServlet.java", "vul_type": "cwe-079", "commit_msg": "Fixed Reflected XSS Vuln\n\nVelocity Tools has an automatically generated error page, which echoes back the file name unescaped. This commit sanitizes user input and fixes the XSS Vulnerability!\n\nUpdated XSS Vuln fix (used StringEscapeUtils)", "parent_commit": "33248041dcb7091ac98787fea432bc253f4d67a8", "description": "Write a Java function to display an error page with a stack trace when an exception occurs during web request processing."}
{"func_name": "add_language", "func_src_before": "    def add_language(self, language):\n        \"\"\"\"Add new language for item translations.\"\"\"\n        if self.connection:\n            self.cursor.execute('insert into itemlanguage (language) values (\"%s\")' % language[0])\n            self.connection.commit()", "func_src_after": "    def add_language(self, language):\n        \"\"\"\"Add new language for item translations.\"\"\"\n        if self.connection:\n            t = (language[0], )\n            self.cursor.execute('insert into itemlanguage (language) values (?)', t)\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new language into a database table for item translations, using parameter substitution."}
{"func_name": "_inject_admin_password_into_fs", "func_src_before": "def _inject_admin_password_into_fs(admin_passwd, fs, execute=None):\n    \"\"\"Set the root password to admin_passwd\n\n    admin_password is a root password\n    fs is the path to the base of the filesystem into which to inject\n    the key.\n\n    This method modifies the instance filesystem directly,\n    and does not require a guest agent running in the instance.\n\n    \"\"\"\n    # The approach used here is to copy the password and shadow\n    # files from the instance filesystem to local files, make any\n    # necessary changes, and then copy them back.\n\n    admin_user = 'root'\n\n    fd, tmp_passwd = tempfile.mkstemp()\n    os.close(fd)\n    fd, tmp_shadow = tempfile.mkstemp()\n    os.close(fd)\n\n    utils.execute('cp', os.path.join(fs, 'etc', 'passwd'), tmp_passwd,\n                  run_as_root=True)\n    utils.execute('cp', os.path.join(fs, 'etc', 'shadow'), tmp_shadow,\n                  run_as_root=True)\n    _set_passwd(admin_user, admin_passwd, tmp_passwd, tmp_shadow)\n    utils.execute('cp', tmp_passwd, os.path.join(fs, 'etc', 'passwd'),\n                  run_as_root=True)\n    os.unlink(tmp_passwd)\n    utils.execute('cp', tmp_shadow, os.path.join(fs, 'etc', 'shadow'),\n                  run_as_root=True)\n    os.unlink(tmp_shadow)", "func_src_after": "def _inject_admin_password_into_fs(admin_passwd, fs, execute=None):\n    \"\"\"Set the root password to admin_passwd\n\n    admin_password is a root password\n    fs is the path to the base of the filesystem into which to inject\n    the key.\n\n    This method modifies the instance filesystem directly,\n    and does not require a guest agent running in the instance.\n\n    \"\"\"\n    # The approach used here is to copy the password and shadow\n    # files from the instance filesystem to local files, make any\n    # necessary changes, and then copy them back.\n\n    admin_user = 'root'\n\n    fd, tmp_passwd = tempfile.mkstemp()\n    os.close(fd)\n    fd, tmp_shadow = tempfile.mkstemp()\n    os.close(fd)\n\n    passwd_path = _join_and_check_path_within_fs(fs, 'etc', 'passwd')\n    shadow_path = _join_and_check_path_within_fs(fs, 'etc', 'shadow')\n\n    utils.execute('cp', passwd_path, tmp_passwd, run_as_root=True)\n    utils.execute('cp', shadow_path, tmp_shadow, run_as_root=True)\n    _set_passwd(admin_user, admin_passwd, tmp_passwd, tmp_shadow)\n    utils.execute('cp', tmp_passwd, passwd_path, run_as_root=True)\n    os.unlink(tmp_passwd)\n    utils.execute('cp', tmp_shadow, shadow_path, run_as_root=True)\n    os.unlink(tmp_shadow)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Provide a Python function to set the root password on a filesystem without using a guest agent."}
{"func_name": "pref_get", "func_src_before": "@app.route(\"/api/preferences/get/<key>\")\ndef pref_get(key):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    if key in get_preferences():\n        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n    else:\n        return Response(json.dumps({'key': key, 'error': 'novalue'}))", "func_src_after": "@app.route(\"/api/preferences/get/<key>\")\ndef pref_get(key):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    if key in get_preferences():\n        return Response(\n            json.dumps({'key': key, 'value': get_preferences()[key]}),\n            mimetype='application/json'\n        )\n    else:\n        return Response(\n            json.dumps({'key': key, 'error': 'novalue'}),\n            mimetype='application/json'\n        )", "line_changes": {"deleted": [{"line_no": 7, "char_start": 167, "char_end": 250, "line": "        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n"}, {"line_no": 9, "char_start": 260, "char_end": 329, "line": "        return Response(json.dumps({'key': key, 'error': 'novalue'}))\n"}], "added": [{"line_no": 7, "char_start": 167, "char_end": 192, "line": "        return Response(\n"}, {"line_no": 8, "char_start": 192, "char_end": 263, "line": "            json.dumps({'key': key, 'value': get_preferences()[key]}),\n"}, {"line_no": 9, "char_start": 263, "char_end": 303, "line": "            mimetype='application/json'\n"}, {"line_no": 10, "char_start": 303, "char_end": 313, "line": "        )\n"}, {"line_no": 12, "char_start": 323, "char_end": 348, "line": "        return Response(\n"}, {"line_no": 13, "char_start": 348, "char_end": 406, "line": "            json.dumps({'key': key, 'error': 'novalue'}),\n"}, {"line_no": 14, "char_start": 406, "char_end": 446, "line": "            mimetype='application/json'\n"}, {"line_no": 15, "char_start": 446, "char_end": 455, "line": "        )\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 191, "char_end": 204, "chars": "\n            "}, {"char_start": 261, "char_end": 311, "chars": ",\n            mimetype='application/json'\n        "}, {"char_start": 347, "char_end": 360, "chars": "\n            "}, {"char_start": 404, "char_end": 454, "chars": ",\n            mimetype='application/json'\n        "}]}, "commit_link": "github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "file_name": "app.py", "vul_type": "cwe-079", "commit_msg": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "description": "Create a Python Flask endpoint to retrieve a user's preference by key, returning JSON responses and requiring user authentication."}
{"func_name": "mongoStore", "func_src_before": "        store: new mongoStore({ mongooseConnection: mongoose.connection })\n    }));\n\n    server.use(passport.initialize());\n    server.use(passport.session());\n    server.use(flash());\n    server.use(csrf());\n    server.use(function(req, res, callback) {\n        // Make user object available in templates.\n        res.locals.user = req.user;\n        res.locals.site = {\n            title: config.app.title,\n            url: config.server.host,\n            dbHost: config.database,\n            mailHost: config.mailer\n        };\n        callback();\n    });\n\n    // for nginx proxy\n    if (mode == 'production') {\n        server.enable('trust proxy');  // using Express behind nginx\n    }\n\n    server.use(function(req, res, callback) {\n        // Remember original destination before login.\n        var path = req.path.split('/')[1];\n\n        if (/auth|api|login|logout|signup|components|css|img|js|favicon/i.test(path) || path == '') {\n            return callback();\n        }\n        req.session.returnTo = req.path;\n\n        callback();\n    });\n\n    var HOUR = 3600000;\n    var DAY = HOUR * 24;\n    var WEEK = DAY * 7;\n\n    server.use(express.static(path.join(__dirname, 'public'), { maxAge: WEEK }));\n\n    // Route Point\n    var home = require('../route/home');\n    var stat = require('../route/stat');\n    var account = require('../route/account');\n    var dashboard = require('../route/dashboard');\n\n    server.use(home);\n    server.use(stat);\n    server.use(account);\n    server.use(dashboard);\n\n    // globalMiddleware\n    // api counter for ip district\n    // haroo cloud api document page\n    // dummy testing\n    // version specified api for only feature test\n    // commonMiddleware\n    // header parameter test\n    // for account\n    // districtMiddleware\n    // district test\n    // for token\n    // for api version\n    // for users\n    // for documents\n\n    // 500 Error Handler\n    server.use(errorHandler());\n\n    callback(server);\n}", "func_src_after": "        store: new mongoStore({ mongooseConnection: mongoose.connection })\n    }));\n\n    server.use(passport.initialize());\n    server.use(passport.session());\n    server.use(flash());\n    server.use(lusca.csrf());\n    server.use(function(req, res, callback) {\n        // Make user object available in templates.\n        res.locals.user = req.user;\n        res.locals.site = {\n            title: config.app.title,\n            url: config.server.host,\n            dbHost: config.database,\n            mailHost: config.mailer\n        };\n        callback();\n    });\n\n    // for nginx proxy\n    if (mode == 'production') {\n        server.enable('trust proxy');  // using Express behind nginx\n    }\n\n    server.use(function(req, res, callback) {\n        // Remember original destination before login.\n        var path = req.path.split('/')[1];\n\n        if (/auth|api|login|logout|signup|components|css|img|js|favicon/i.test(path) || path == '') {\n            return callback();\n        }\n        req.session.returnTo = req.path;\n\n        callback();\n    });\n\n    var HOUR = 3600000;\n    var DAY = HOUR * 24;\n    var WEEK = DAY * 7;\n\n    server.use(express.static(path.join(__dirname, 'public'), { maxAge: WEEK }));\n\n    // Route Point\n    var home = require('../route/home');\n    var stat = require('../route/stat');\n    var account = require('../route/account');\n    var dashboard = require('../route/dashboard');\n\n    server.use(home);\n    server.use(stat);\n    server.use(account);\n    server.use(dashboard);\n\n    // globalMiddleware\n    // api counter for ip district\n    // haroo cloud api document page\n    // dummy testing\n    // version specified api for only feature test\n    // commonMiddleware\n    // header parameter test\n    // for account\n    // districtMiddleware\n    // district test\n    // for token\n    // for api version\n    // for users\n    // for documents\n\n    // 500 Error Handler\n    server.use(errorHandler());\n\n    callback(server);\n}", "line_changes": {"deleted": [{"line_no": 7, "char_start": 185, "char_end": 209, "line": "    server.use(csrf());\n"}], "added": [{"line_no": 7, "char_start": 185, "char_end": 215, "line": "    server.use(lusca.csrf());\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 200, "char_end": 206, "chars": "lusca."}]}, "commit_link": "github.com/Haroo-Studio/haroo-cloud-web/commit/ca6069b630f6292aed0cc17389227d6d9c866cdd", "file_name": "init.js", "vul_type": "cwe-352", "commit_msg": "`fix` csrf bind", "description": "Write a JavaScript (Node.js with Express) code snippet to configure middleware for user authentication, session management, static file serving, and routing."}
{"func_name": "avr_op_analyze", "func_src_before": "static OPCODE_DESC* avr_op_analyze(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *buf, int len, CPU_MODEL *cpu) {\n\tOPCODE_DESC *opcode_desc;\n\tut16 ins = (buf[1] << 8) | buf[0];\n\tint fail;\n\tchar *t;\n\n\t// initialize op struct\n\tmemset (op, 0, sizeof (RAnalOp));\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->jump = UT64_MAX;\n\tr_strbuf_init (&op->esil);\n\n\t// process opcode\n\tfor (opcode_desc = opcodes; opcode_desc->handler; opcode_desc++) {\n\t\tif ((ins & opcode_desc->mask) == opcode_desc->selector) {\n\t\t\tfail = 0;\n\n\t\t\t// copy default cycles/size values\n\t\t\top->cycles = opcode_desc->cycles;\n\t\t\top->size = opcode_desc->size;\n\t\t\top->type = opcode_desc->type;\n\t\t\top->jump = UT64_MAX;\n\t\t\top->fail = UT64_MAX;\n\t\t\t// op->fail = addr + op->size;\n\t\t\top->addr = addr;\n\n\t\t\t// start void esil expression\n\t\t\tr_strbuf_setf (&op->esil, \"\");\n\n\t\t\t// handle opcode\n\t\t\topcode_desc->handler (anal, op, buf, len, &fail, cpu);\n\t\t\tif (fail) {\n\t\t\t\tgoto INVALID_OP;\n\t\t\t}\n\t\t\tif (op->cycles <= 0) {\n\t\t\t\t// eprintf (\"opcode %s @%\"PFMT64x\" returned 0 cycles.\\n\", opcode_desc->name, op->addr);\n\t\t\t\topcode_desc->cycles = 2;\n\t\t\t}\n\t\t\top->nopcode = (op->type == R_ANAL_OP_TYPE_UNK);\n\n\t\t\t// remove trailing coma (COMETE LA COMA)\n\t\t\tt = r_strbuf_get (&op->esil);\n\t\t\tif (t && strlen (t) > 1) {\n\t\t\t\tt += strlen (t) - 1;\n\t\t\t\tif (*t == ',') {\n\t\t\t\t\t*t = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn opcode_desc;\n\t\t}\n\t}\n\n\t// ignore reserved opcodes (if they have not been caught by the previous loop)\n\tif ((ins & 0xff00) == 0xff00 && (ins & 0xf) > 7) {\n\t\tgoto INVALID_OP;\n\t}\n\nINVALID_OP:\n\t// An unknown or invalid option has appeared.\n\t//  -- Throw pokeball!\n\top->family = R_ANAL_OP_FAMILY_UNKNOWN;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->addr = addr;\n\top->fail = UT64_MAX;\n\top->jump = UT64_MAX;\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->nopcode = 1;\n\top->cycles = 1;\n\top->size = 2;\n\t// launch esil trap (for communicating upper layers about this weird\n\t// and stinky situation\n\tr_strbuf_set (&op->esil, \"1,$\");\n\n\treturn NULL;\n}", "func_src_after": "static OPCODE_DESC* avr_op_analyze(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *buf, int len, CPU_MODEL *cpu) {\n\tOPCODE_DESC *opcode_desc;\n\tif (len < 2) {\n\t\treturn NULL;\n\t}\n\tut16 ins = (buf[1] << 8) | buf[0];\n\tint fail;\n\tchar *t;\n\n\t// initialize op struct\n\tmemset (op, 0, sizeof (RAnalOp));\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->jump = UT64_MAX;\n\tr_strbuf_init (&op->esil);\n\n\t// process opcode\n\tfor (opcode_desc = opcodes; opcode_desc->handler; opcode_desc++) {\n\t\tif ((ins & opcode_desc->mask) == opcode_desc->selector) {\n\t\t\tfail = 0;\n\n\t\t\t// copy default cycles/size values\n\t\t\top->cycles = opcode_desc->cycles;\n\t\t\top->size = opcode_desc->size;\n\t\t\top->type = opcode_desc->type;\n\t\t\top->jump = UT64_MAX;\n\t\t\top->fail = UT64_MAX;\n\t\t\t// op->fail = addr + op->size;\n\t\t\top->addr = addr;\n\n\t\t\t// start void esil expression\n\t\t\tr_strbuf_setf (&op->esil, \"\");\n\n\t\t\t// handle opcode\n\t\t\topcode_desc->handler (anal, op, buf, len, &fail, cpu);\n\t\t\tif (fail) {\n\t\t\t\tgoto INVALID_OP;\n\t\t\t}\n\t\t\tif (op->cycles <= 0) {\n\t\t\t\t// eprintf (\"opcode %s @%\"PFMT64x\" returned 0 cycles.\\n\", opcode_desc->name, op->addr);\n\t\t\t\topcode_desc->cycles = 2;\n\t\t\t}\n\t\t\top->nopcode = (op->type == R_ANAL_OP_TYPE_UNK);\n\n\t\t\t// remove trailing coma (COMETE LA COMA)\n\t\t\tt = r_strbuf_get (&op->esil);\n\t\t\tif (t && strlen (t) > 1) {\n\t\t\t\tt += strlen (t) - 1;\n\t\t\t\tif (*t == ',') {\n\t\t\t\t\t*t = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn opcode_desc;\n\t\t}\n\t}\n\n\t// ignore reserved opcodes (if they have not been caught by the previous loop)\n\tif ((ins & 0xff00) == 0xff00 && (ins & 0xf) > 7) {\n\t\tgoto INVALID_OP;\n\t}\n\nINVALID_OP:\n\t// An unknown or invalid option has appeared.\n\t//  -- Throw pokeball!\n\top->family = R_ANAL_OP_FAMILY_UNKNOWN;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->addr = addr;\n\top->fail = UT64_MAX;\n\top->jump = UT64_MAX;\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->nopcode = 1;\n\top->cycles = 1;\n\top->size = 2;\n\t// launch esil trap (for communicating upper layers about this weird\n\t// and stinky situation\n\tr_strbuf_set (&op->esil, \"1,$\");\n\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/b35530fa0681b27eba084de5527037ebfb397422", "file_name": "libr/anal/p/anal_avr.c", "vul_type": "cwe-125", "description": "Write a C function named `avr_op_analyze` for analyzing AVR opcodes and updating the analysis structure."}
{"func_name": "Html5ReportGenerator::unzipApp", "func_src_before": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "func_src_after": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "line_changes": {"deleted": [], "added": [{"line_no": 12, "char_start": 549, "char_end": 633, "line": "            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n"}, {"line_no": 13, "char_start": 633, "char_end": 694, "line": "                throw new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 14, "char_start": 694, "char_end": 708, "line": "            }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 548, "char_end": 707, "chars": "\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }"}]}, "commit_link": "github.com/TNG/JGiven/commit/e701fe690501e7301f7c923adc1881d308806c46", "file_name": "Html5ReportGenerator.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to unzip a file named 'app.zip' from the resources of the `Html5ReportGenerator` class into a specified directory."}
{"func_name": "rds_cmsg_atomic", "func_src_before": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "func_src_after": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\trm->atomic.op_active = 0;\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7d11f77f84b27cef452cee332f4e469503084737", "file_name": "net/rds/rdma.c", "vul_type": "cwe-476", "description": "Write a C function named `rds_cmsg_atomic` that processes atomic operations in RDS messages."}
{"func_name": "allow_plugins?", "func_src_before": "  def allow_plugins?\n    safe_mode = params[\"safe_mode\"]\n    !(safe_mode && safe_mode.include?(\"no_plugins\"))\n  end", "func_src_after": "  def allow_plugins?\n    safe_mode = params[SAFE_MODE]\n    !(safe_mode && safe_mode.include?(NO_PLUGINS))\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 21, "char_end": 57, "line": "    safe_mode = params[\"safe_mode\"]\n"}, {"line_no": 3, "char_start": 57, "char_end": 110, "line": "    !(safe_mode && safe_mode.include?(\"no_plugins\"))\n"}], "added": [{"line_no": 2, "char_start": 21, "char_end": 55, "line": "    safe_mode = params[SAFE_MODE]\n"}, {"line_no": 3, "char_start": 55, "char_end": 106, "line": "    !(safe_mode && safe_mode.include?(NO_PLUGINS))\n"}]}, "char_changes": {"deleted": [{"char_start": 44, "char_end": 55, "chars": "\"safe_mode\""}, {"char_start": 95, "char_end": 107, "chars": "\"no_plugins\""}], "added": [{"char_start": 44, "char_end": 53, "chars": "SAFE_MODE"}, {"char_start": 93, "char_end": 103, "chars": "NO_PLUGINS"}]}, "commit_link": "github.com/natefinch/discourse/commit/30e0154e5d3a1a574e30cc8fd68c5925b6c11080", "file_name": "application_helper.rb", "vul_type": "cwe-079", "commit_msg": "SECURITY: fix reflected XSS with safe_mode param\n\n(only applies to beta and master)", "description": "Write a Ruby function named `allow_plugins?` that checks a parameter to determine if plugins should be allowed."}
{"func_name": "handle", "func_src_before": "    def handle(self, keepalive=True, initial_timeout=None):\n        # we are requested to skip processing and keep the previous values\n        if self.skip:\n            return self.response.handle()\n\n        # default to no keepalive in case something happens while even trying ensure we have a request\n        self.keepalive = False\n\n        self.headers = HTTPHeaders()\n\n        # if initial_timeout is set, only wait that long for the initial request line\n        if initial_timeout:\n            self.connection.settimeout(initial_timeout)\n        else:\n            self.connection.settimeout(self.timeout)\n\n        # get request line\n        try:\n            # ignore empty lines waiting on request\n            request = '\\r\\n'\n            while request == '\\r\\n':\n                request = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n        # if read hits timeout or has some other error, ignore the request\n        except Exception:\n            return True\n\n        # ignore empty requests\n        if not request:\n            return True\n\n        # we have a request, go back to normal timeout\n        if initial_timeout:\n            self.connection.settimeout(self.timeout)\n\n        # remove \\r\\n from the end\n        self.request_line = request[:-2]\n\n        # set some reasonable defaults in case the worst happens and we need to tell the client\n        self.method = ''\n        self.resource = '/'\n\n        try:\n            # HTTP Status 414\n            if len(request) > max_line_size:\n                raise HTTPError(414)\n\n            # HTTP Status 400\n            if request[-2:] != '\\r\\n':\n                raise HTTPError(400)\n\n            # try the request line and error out if can't parse it\n            try:\n                self.method, self.resource, self.request_http = self.request_line.split()\n            # HTTP Status 400\n            except ValueError:\n                raise HTTPError(400)\n\n            # HTTP Status 505\n            if self.request_http != http_version:\n                raise HTTPError(505)\n\n            # read and parse request headers\n            while True:\n                line = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n\n                # hit end of headers\n                if line == '\\r\\n':\n                    break\n\n                self.headers.add(line)\n\n            # if we are requested to close the connection after we finish, do so\n            if self.headers.get('Connection') == 'close':\n                self.keepalive = False\n            # else since we are sure we have a request and have read all of the request data, keepalive for more later (if allowed)\n            else:\n                self.keepalive = keepalive\n\n            # find a matching regex to handle the request with\n            for regex, handler in self.server.routes.items():\n                match = regex.match(self.resource)\n                if match:\n                    # create a dictionary of groups\n                    groups = match.groupdict()\n                    values = groups.values()\n\n                    for idx, group in enumerate(match.groups()):\n                        if group not in values:\n                            groups[idx] = group\n\n                    # create handler\n                    self.handler = handler(self, self.response, groups)\n                    break\n            # HTTP Status 404\n            # if loop is not broken (handler is not found), raise a 404\n            else:\n                raise HTTPError(404)\n        # use DummyHandler so the error is raised again when ready for response\n        except Exception as error:\n            self.handler = DummyHandler(self, self.response, (), error)\n        finally:\n            # we finished listening and handling early errors and so let a response class now finish up the job of talking\n            return self.response.handle()", "func_src_after": "    def handle(self, keepalive=True, initial_timeout=None):\n        # we are requested to skip processing and keep the previous values\n        if self.skip:\n            return self.response.handle()\n\n        # default to no keepalive in case something happens while even trying ensure we have a request\n        self.keepalive = False\n\n        self.headers = HTTPHeaders()\n\n        # if initial_timeout is set, only wait that long for the initial request line\n        if initial_timeout:\n            self.connection.settimeout(initial_timeout)\n        else:\n            self.connection.settimeout(self.timeout)\n\n        # get request line\n        try:\n            # ignore empty lines waiting on request\n            request = '\\r\\n'\n            while request == '\\r\\n':\n                request = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n        # if read hits timeout or has some other error, ignore the request\n        except Exception:\n            return True\n\n        # ignore empty requests\n        if not request:\n            return True\n\n        # we have a request, go back to normal timeout\n        if initial_timeout:\n            self.connection.settimeout(self.timeout)\n\n        # remove \\r\\n from the end\n        self.request_line = request[:-2]\n\n        # set some reasonable defaults in case the worst happens and we need to tell the client\n        self.method = ''\n        self.resource = '/'\n\n        try:\n            # HTTP Status 414\n            if len(request) > max_line_size:\n                raise HTTPError(414)\n\n            # HTTP Status 400\n            if request[-2:] != '\\r\\n':\n                raise HTTPError(400)\n\n            # try the request line and error out if can't parse it\n            try:\n                self.method, resource, self.request_http = self.request_line.split()\n                self.resource = urllib.parse.unquote(resource)\n            # HTTP Status 400\n            except ValueError:\n                raise HTTPError(400)\n\n            # HTTP Status 505\n            if self.request_http != http_version:\n                raise HTTPError(505)\n\n            # read and parse request headers\n            while True:\n                line = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n\n                # hit end of headers\n                if line == '\\r\\n':\n                    break\n\n                self.headers.add(line)\n\n            # if we are requested to close the connection after we finish, do so\n            if self.headers.get('Connection') == 'close':\n                self.keepalive = False\n            # else since we are sure we have a request and have read all of the request data, keepalive for more later (if allowed)\n            else:\n                self.keepalive = keepalive\n\n            # find a matching regex to handle the request with\n            for regex, handler in self.server.routes.items():\n                match = regex.match(self.resource)\n                if match:\n                    # create a dictionary of groups\n                    groups = match.groupdict()\n                    values = groups.values()\n\n                    for idx, group in enumerate(match.groups()):\n                        if group not in values:\n                            groups[idx] = group\n\n                    # create handler\n                    self.handler = handler(self, self.response, groups)\n                    break\n            # HTTP Status 404\n            # if loop is not broken (handler is not found), raise a 404\n            else:\n                raise HTTPError(404)\n        # use DummyHandler so the error is raised again when ready for response\n        except Exception as error:\n            self.handler = DummyHandler(self, self.response, (), error)\n        finally:\n            # we finished listening and handling early errors and so let a response class now finish up the job of talking\n            return self.response.handle()", "commit_link": "github.com/fkmclane/python-fooster-web/commit/80202a6d3788ad1212a162d19785c600025e6aa4", "file_name": "fooster/web/web.py", "vul_type": "cwe-022", "description": "Write a Python function to handle HTTP requests with optional keepalive and initial timeout parameters."}
{"func_name": "get_paths", "func_src_before": "def get_paths(base_path: pathlib.Path):\n    data_file = pathlib.Path(str(base_path) + \".data\")\n    metadata_file = pathlib.Path(str(base_path) + \".meta\")\n\n    return data_file, metadata_file", "func_src_after": "def get_paths(root: str, sub_path: str) \\\n        -> typing.Tuple[pathlib.Path, pathlib.Path]:\n    base_path = flask.safe_join(root, sub_path)\n    data_file = pathlib.Path(base_path + \".data\")\n    metadata_file = pathlib.Path(base_path + \".meta\")\n\n    return data_file, metadata_file", "commit_link": "github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75", "file_name": "xhu.py", "vul_type": "cwe-022", "description": "Write a Python function that generates file paths for data and metadata files based on a given base path."}
{"func_name": "save_accepted_transaction", "func_src_before": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\"%(money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\" % (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, %s, now(), 'accepted' )\" % (project_id, user_id, money))\n        self.db.commit()", "func_src_after": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\", (money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\", (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, \"\n                            \"%s, now(), 'accepted' )\", (project_id, user_id, money))\n        self.db.commit()", "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089", "description": "Write a Python function to update user and project balances and record an accepted transaction in the database."}
{"func_name": "megasas_alloc_cmds", "func_src_before": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/bcf3b67d16a4c8ffae0aa79de5853435e683945c", "file_name": "drivers/scsi/megaraid/megaraid_sas_base.c", "vul_type": "cwe-476", "description": "Write a C function named `megasas_alloc_cmds` that allocates command structures for a `megasas_instance` and initializes a frame pool."}
{"func_name": "tar_directory_for_file", "func_src_before": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t\tdir = GSF_INFILE_TAR (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "func_src_after": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\tdir = GSF_IS_INFILE_TAR (subdir)\n\t\t\t\t\t? GSF_INFILE_TAR (subdir)\n\t\t\t\t\t: dir;\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "commit_link": "github.com/GNOME/libgsf/commit/95a8351a75758cf10b3bf6abae0b6b461f90d9e5", "file_name": "gsf/gsf-infile-tar.c", "vul_type": "cwe-476", "description": "Write a C function to navigate or create directories within a TAR file based on a given path."}
{"func_name": "mrb_io_initialize_copy", "func_src_before": "mrb_io_initialize_copy(mrb_state *mrb, mrb_value copy)\n{\n  mrb_value orig;\n  mrb_value buf;\n  struct mrb_io *fptr_copy;\n  struct mrb_io *fptr_orig;\n  mrb_bool failed = TRUE;\n\n  mrb_get_args(mrb, \"o\", &orig);\n  fptr_copy = (struct mrb_io *)DATA_PTR(copy);\n  if (fptr_copy != NULL) {\n    fptr_finalize(mrb, fptr_copy, FALSE);\n    mrb_free(mrb, fptr_copy);\n  }\n  fptr_copy = (struct mrb_io *)mrb_io_alloc(mrb);\n  fptr_orig = io_get_open_fptr(mrb, orig);\n\n  DATA_TYPE(copy) = &mrb_io_type;\n  DATA_PTR(copy) = fptr_copy;\n\n  buf = mrb_iv_get(mrb, orig, mrb_intern_cstr(mrb, \"@buf\"));\n  mrb_iv_set(mrb, copy, mrb_intern_cstr(mrb, \"@buf\"), buf);\n\n  fptr_copy->fd = mrb_dup(mrb, fptr_orig->fd, &failed);\n  if (failed) {\n    mrb_sys_fail(mrb, 0);\n  }\n  mrb_fd_cloexec(mrb, fptr_copy->fd);\n\n  if (fptr_orig->fd2 != -1) {\n    fptr_copy->fd2 = mrb_dup(mrb, fptr_orig->fd2, &failed);\n    if (failed) {\n      close(fptr_copy->fd);\n      mrb_sys_fail(mrb, 0);\n    }\n    mrb_fd_cloexec(mrb, fptr_copy->fd2);\n  }\n\n  fptr_copy->pid = fptr_orig->pid;\n  fptr_copy->readable = fptr_orig->readable;\n  fptr_copy->writable = fptr_orig->writable;\n  fptr_copy->sync = fptr_orig->sync;\n  fptr_copy->is_socket = fptr_orig->is_socket;\n\n  return copy;\n}", "func_src_after": "mrb_io_initialize_copy(mrb_state *mrb, mrb_value copy)\n{\n  mrb_value orig;\n  mrb_value buf;\n  struct mrb_io *fptr_copy;\n  struct mrb_io *fptr_orig;\n  mrb_bool failed = TRUE;\n\n  mrb_get_args(mrb, \"o\", &orig);\n  fptr_orig = io_get_open_fptr(mrb, orig);\n  fptr_copy = (struct mrb_io *)DATA_PTR(copy);\n  if (fptr_copy != NULL) {\n    fptr_finalize(mrb, fptr_copy, FALSE);\n    mrb_free(mrb, fptr_copy);\n  }\n  fptr_copy = (struct mrb_io *)mrb_io_alloc(mrb);\n\n  DATA_TYPE(copy) = &mrb_io_type;\n  DATA_PTR(copy) = fptr_copy;\n\n  buf = mrb_iv_get(mrb, orig, mrb_intern_cstr(mrb, \"@buf\"));\n  mrb_iv_set(mrb, copy, mrb_intern_cstr(mrb, \"@buf\"), buf);\n\n  fptr_copy->fd = mrb_dup(mrb, fptr_orig->fd, &failed);\n  if (failed) {\n    mrb_sys_fail(mrb, 0);\n  }\n  mrb_fd_cloexec(mrb, fptr_copy->fd);\n\n  if (fptr_orig->fd2 != -1) {\n    fptr_copy->fd2 = mrb_dup(mrb, fptr_orig->fd2, &failed);\n    if (failed) {\n      close(fptr_copy->fd);\n      mrb_sys_fail(mrb, 0);\n    }\n    mrb_fd_cloexec(mrb, fptr_copy->fd2);\n  }\n\n  fptr_copy->pid = fptr_orig->pid;\n  fptr_copy->readable = fptr_orig->readable;\n  fptr_copy->writable = fptr_orig->writable;\n  fptr_copy->sync = fptr_orig->sync;\n  fptr_copy->is_socket = fptr_orig->is_socket;\n\n  return copy;\n}", "commit_link": "github.com/mruby/mruby/commit/b51b21fc63c9805862322551387d9036f2b63433", "file_name": "mrbgems/mruby-io/src/io.c", "vul_type": "cwe-416", "description": "Write a C function for the MRuby language that duplicates an IO object, including its file descriptors and instance variables."}
{"func_name": "dateproto_setUTCMilliseconds", "func_src_before": "func (r *Runtime) dateproto_setUTCMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := int(call.Argument(0).ToInteger())\n\t\t\tt := d.time.In(time.UTC)\n\t\t\td.time = time.Date(t.Year(), t.Month(), t.Day(), t.Hour(), t.Minute(), t.Second(), msec*1e6, time.UTC).In(time.Local)\n\t\t\treturn intToValue(timeToMsec(d.time))\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setUTCMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "func_src_after": "func (r *Runtime) dateproto_setUTCMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := call.Argument(0).ToInteger()\n\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m)\n\t\t\treturn intToValue(m)\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setUTCMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 161, "char_end": 206, "line": "\t\t\tmsec := int(call.Argument(0).ToInteger())\n"}, {"line_no": 6, "char_start": 206, "char_end": 234, "line": "\t\t\tt := d.time.In(time.UTC)\n"}, {"line_no": 7, "char_start": 234, "char_end": 355, "line": "\t\t\td.time = time.Date(t.Year(), t.Month(), t.Day(), t.Hour(), t.Minute(), t.Second(), msec*1e6, time.UTC).In(time.Local)\n"}, {"line_no": 8, "char_start": 355, "char_end": 396, "line": "\t\t\treturn intToValue(timeToMsec(d.time))\n"}], "added": [{"line_no": 5, "char_start": 161, "char_end": 201, "line": "\t\t\tmsec := call.Argument(0).ToInteger()\n"}, {"line_no": 6, "char_start": 201, "char_end": 268, "line": "\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n"}, {"line_no": 7, "char_start": 268, "char_end": 296, "line": "\t\t\td.time = timeFromMsec(m)\n"}, {"line_no": 8, "char_start": 296, "char_end": 320, "line": "\t\t\treturn intToValue(m)\n"}]}, "char_changes": {"deleted": [{"char_start": 172, "char_end": 176, "chars": "int("}, {"char_start": 204, "char_end": 205, "chars": ")"}, {"char_start": 209, "char_end": 210, "chars": "t"}, {"char_start": 214, "char_end": 216, "chars": "d."}, {"char_start": 220, "char_end": 353, "chars": ".In(time.UTC)\n\t\t\td.time = time.Date(t.Year(), t.Month(), t.Day(), t.Hour(), t.Minute(), t.Second(), msec*1e6, time.UTC).In(time.Local"}, {"char_start": 376, "char_end": 394, "chars": "timeToMsec(d.time)"}], "added": [{"char_start": 204, "char_end": 205, "chars": "m"}, {"char_start": 213, "char_end": 294, "chars": "ToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m"}, {"char_start": 317, "char_end": 318, "chars": "m"}]}, "commit_link": "github.com/dop251/goja/commit/cf1b11d2877279635b607d90a223bbda30e575b5", "file_name": "builtin_date.go", "vul_type": "cwe-681", "commit_msg": "Avoid integer overflow in Date.setMilliseconds()", "parent_commit": "5e65f9206bdb013b233bde6bac91fc88e00ff7a3", "description": "Write a Go function that sets the milliseconds for a date object in UTC."}
{"func_name": "_get_flashcopy_mapping_attributes", "func_src_before": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = 'svcinfo lsfcmap -filtervalue id=%s -delim !' % \\\n            fc_map_id\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "func_src_after": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = ['svcinfo', 'lsfcmap', '-filtervalue',\n                         'id=%s' % fc_map_id, '-delim', '!']\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and parse FlashCopy mapping attributes using SSH commands."}
{"func_name": "deleteKey", "func_src_before": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal BAD_REQUEST\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\n\tif re.search('[^a-zA-Z0-9]', token_data['key']):\n\t\traise FoxlockError(BAD_REQUEST, 'Invalid key requested')\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "func_src_after": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateKeyName(token_data['key'])\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function named `deleteKey` that removes a client's key file and handles the case where the key does not exist."}
{"func_name": "IsBlacklistedArg", "func_src_before": "bool IsBlacklistedArg(const base::CommandLine::CharType* arg) {\n#if defined(OS_WIN)\n  const auto converted = base::WideToUTF8(arg);\n  const char* a = converted.c_str();\n#else\n  const char* a = arg;\n#endif\n\n  static const char* prefixes[] = {\"--\", \"-\", \"/\"};\n\n  int prefix_length = 0;\n  for (auto& prefix : prefixes) {\n    if (base::StartsWith(a, prefix, base::CompareCase::SENSITIVE)) {\n      prefix_length = strlen(prefix);\n      break;\n    }\n  }\n\n  if (prefix_length > 0) {\n    a += prefix_length;\n    std::string switch_name(a, strcspn(a, \"=\"));\n    auto* iter = std::lower_bound(std::begin(kBlacklist), std::end(kBlacklist),\n                                  switch_name);\n    if (iter != std::end(kBlacklist) && switch_name == *iter) {\n      return true;\n    }\n  }\n\n  return false;\n}", "func_src_after": "bool IsBlacklistedArg(const base::CommandLine::CharType* arg) {\n#if defined(OS_WIN)\n  const auto converted = base::WideToUTF8(arg);\n  const char* a = converted.c_str();\n#else\n  const char* a = arg;\n#endif\n\n  static const char* prefixes[] = {\"--\", \"-\", \"/\"};\n\n  int prefix_length = 0;\n  for (auto& prefix : prefixes) {\n    if (base::StartsWith(a, prefix, base::CompareCase::SENSITIVE)) {\n      prefix_length = strlen(prefix);\n      break;\n    }\n  }\n\n  if (prefix_length > 0) {\n    a += prefix_length;\n    std::string switch_name =\n        base::ToLowerASCII(base::StringPiece(a, strcspn(a, \"=\")));\n    auto* iter = std::lower_bound(std::begin(kBlacklist), std::end(kBlacklist),\n                                  switch_name);\n    if (iter != std::end(kBlacklist) && switch_name == *iter) {\n      return true;\n    }\n  }\n\n  return false;\n}", "commit_link": "github.com/electron/electron/commit/ce361a12e355f9e1e99c989f1ea056c9e502dbe7", "file_name": "atom/app/command_line_args.cc", "vul_type": "cwe-078", "description": "Write a C++ function to check if a command-line argument is blacklisted, considering platform-specific character encoding and argument prefixes."}
{"func_name": "cs_winkernel_malloc", "func_src_before": "void * CAPSTONE_API cs_winkernel_malloc(size_t size)\n{\n\t// Disallow zero length allocation because they waste pool header space and,\n\t// in many cases, indicate a potential validation issue in the calling code.\n\tNT_ASSERT(size);\n\n\t// FP; a use of NonPagedPool is required for Windows 7 support\n#pragma prefast(suppress : 30030)\t\t// Allocating executable POOL_TYPE memory\n\tCS_WINKERNEL_MEMBLOCK *block = (CS_WINKERNEL_MEMBLOCK *)ExAllocatePoolWithTag(\n\t\t\tNonPagedPool, size + sizeof(CS_WINKERNEL_MEMBLOCK), CS_WINKERNEL_POOL_TAG);\n\tif (!block) {\n\t\treturn NULL;\n\t}\n\tblock->size = size;\n\n\treturn block->data;\n}", "func_src_after": "void * CAPSTONE_API cs_winkernel_malloc(size_t size)\n{\n\t// Disallow zero length allocation because they waste pool header space and,\n\t// in many cases, indicate a potential validation issue in the calling code.\n\tNT_ASSERT(size);\n\n\t// FP; a use of NonPagedPool is required for Windows 7 support\n#pragma prefast(suppress : 30030)\t\t// Allocating executable POOL_TYPE memory\n\tsize_t number_of_bytes = 0;\n\tCS_WINKERNEL_MEMBLOCK *block = NULL;\n\t// A specially crafted size value can trigger the overflow.\n\t// If the sum in a value that overflows or underflows the capacity of the type,\n\t// the function returns NULL.\n\tif (!NT_SUCCESS(RtlSizeTAdd(size, sizeof(CS_WINKERNEL_MEMBLOCK), &number_of_bytes))) {\n\t\treturn NULL;\n\t}\n\tblock = (CS_WINKERNEL_MEMBLOCK *)ExAllocatePoolWithTag(\n\t\t\tNonPagedPool, number_of_bytes, CS_WINKERNEL_POOL_TAG);\n\tif (!block) {\n\t\treturn NULL;\n\t}\n\tblock->size = size;\n\n\treturn block->data;\n}", "commit_link": "github.com/aquynh/capstone/commit/6fe86eef621b9849f51a5e1e5d73258a93440403", "file_name": "windows/winkernel_mm.c", "vul_type": "cwe-190", "description": "Write a C function named `cs_winkernel_malloc` that allocates memory in the Windows kernel, ensuring it's non-zero and handles potential size overflows."}
{"func_name": "SpliceImage", "func_src_before": "MagickExport Image *SpliceImage(const Image *image,\n  const RectangleInfo *geometry,ExceptionInfo *exception)\n{\n#define SpliceImageTag  \"Splice/Image\"\n\n  CacheView\n    *image_view,\n    *splice_view;\n\n  Image\n    *splice_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  RectangleInfo\n    splice_geometry;\n\n  ssize_t\n    y;\n\n  /*\n    Allocate splice image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(geometry != (const RectangleInfo *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  splice_geometry=(*geometry);\n  splice_image=CloneImage(image,image->columns+splice_geometry.width,\n    image->rows+splice_geometry.height,MagickTrue,exception);\n  if (splice_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(splice_image,DirectClass,exception) == MagickFalse)\n    {\n      splice_image=DestroyImage(splice_image);\n      return((Image *) NULL);\n    }\n  if ((IsPixelInfoGray(&splice_image->background_color) == MagickFalse) &&\n      (IsGrayColorspace(splice_image->colorspace) != MagickFalse))\n    (void) SetImageColorspace(splice_image,sRGBColorspace,exception);\n  if ((splice_image->background_color.alpha_trait != UndefinedPixelTrait) &&\n      (splice_image->alpha_trait == UndefinedPixelTrait))\n    (void) SetImageAlpha(splice_image,OpaqueAlpha,exception);\n  (void) SetImageBackgroundColor(splice_image,exception);\n  /*\n    Respect image geometry.\n  */\n  switch (image->gravity)\n  {\n    default:\n    case UndefinedGravity:\n    case NorthWestGravity:\n      break;\n    case NorthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case NorthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      break;\n    }\n    case WestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case CenterGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case EastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case SouthWestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n  }\n  /*\n    Splice image.\n  */\n  status=MagickTrue;\n  progress=0;\n  image_view=AcquireVirtualCacheView(image,exception);\n  splice_view=AcquireAuthenticCacheView(splice_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=0; y < (ssize_t) splice_geometry.y; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,image->columns,1,exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < splice_geometry.x; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=(ssize_t) (splice_geometry.y+splice_geometry.height);\n       y < (ssize_t) splice_image->rows; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y-(ssize_t) splice_geometry.height,\n      image->columns,1,exception);\n    if ((y < 0) || (y >= (ssize_t) splice_image->rows))\n      continue;\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < splice_geometry.x; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  splice_view=DestroyCacheView(splice_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    splice_image=DestroyImage(splice_image);\n  return(splice_image);\n}", "func_src_after": "MagickExport Image *SpliceImage(const Image *image,\n  const RectangleInfo *geometry,ExceptionInfo *exception)\n{\n#define SpliceImageTag  \"Splice/Image\"\n\n  CacheView\n    *image_view,\n    *splice_view;\n\n  Image\n    *splice_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  RectangleInfo\n    splice_geometry;\n\n  ssize_t\n    columns,\n    y;\n\n  /*\n    Allocate splice image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(geometry != (const RectangleInfo *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  splice_geometry=(*geometry);\n  splice_image=CloneImage(image,image->columns+splice_geometry.width,\n    image->rows+splice_geometry.height,MagickTrue,exception);\n  if (splice_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(splice_image,DirectClass,exception) == MagickFalse)\n    {\n      splice_image=DestroyImage(splice_image);\n      return((Image *) NULL);\n    }\n  if ((IsPixelInfoGray(&splice_image->background_color) == MagickFalse) &&\n      (IsGrayColorspace(splice_image->colorspace) != MagickFalse))\n    (void) SetImageColorspace(splice_image,sRGBColorspace,exception);\n  if ((splice_image->background_color.alpha_trait != UndefinedPixelTrait) &&\n      (splice_image->alpha_trait == UndefinedPixelTrait))\n    (void) SetImageAlpha(splice_image,OpaqueAlpha,exception);\n  (void) SetImageBackgroundColor(splice_image,exception);\n  /*\n    Respect image geometry.\n  */\n  switch (image->gravity)\n  {\n    default:\n    case UndefinedGravity:\n    case NorthWestGravity:\n      break;\n    case NorthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case NorthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      break;\n    }\n    case WestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case CenterGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case EastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case SouthWestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n  }\n  /*\n    Splice image.\n  */\n  status=MagickTrue;\n  progress=0;\n  columns=MagickMin(splice_geometry.x,(ssize_t) splice_image->columns);\n  image_view=AcquireVirtualCacheView(image,exception);\n  splice_view=AcquireAuthenticCacheView(splice_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=0; y < (ssize_t) splice_geometry.y; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,splice_image->columns,1,\n      exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=(ssize_t) (splice_geometry.y+splice_geometry.height);\n       y < (ssize_t) splice_image->rows; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    if ((y < 0) || (y >= (ssize_t)splice_image->rows))\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y-(ssize_t) splice_geometry.height,\n      splice_image->columns,1,exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  splice_view=DestroyCacheView(splice_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    splice_image=DestroyImage(splice_image);\n  return(splice_image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/7b1cf5784b5bcd85aa9293ecf56769f68c037231", "file_name": "MagickCore/transform.c", "vul_type": "cwe-125", "description": "Write a C function to splice an image with a given geometry in ImageMagick."}
{"func_name": "zmi_page_request", "func_src_before": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "func_src_after": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if self.getDocumentElement().id in path and len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "commit_link": "github.com/zms-publishing/zms4/commit/3f28620d475220dfdb06f79787158ac50727c61a", "file_name": "ZMSItem.py", "vul_type": "cwe-022", "description": "Write a Python function named `zmi_page_request` that modifies HTTP response headers, manages session variables, and redirects to a normalized URL if necessary."}
{"func_name": "authenticate", "func_src_before": "def authenticate(user, passwd, db):\n  \"\"\" Takes a username, password, and connection object as input, and checks\n  if this corresponds to an actual user. Salts the password as necessary. \"\"\"\n  # get salt and add to password if necessary\n  saltQuery = db.execute(\"SELECT salt FROM users WHERE username='\" + user \\\n          + \"'\")\n  # if there's a salt set, then use it\n  if saltQuery.returns_rows:\n    salt = saltQuery.first()\n    # make sure username is found and salt isn't null\n    if salt != None and salt[0] != None:\n      passwd = salt[0] + passwd\n\n  # query whether there's a match for the username and password\n  query = db.execute(\"SELECT * FROM users WHERE username='\" + user + \"' AND \" \\\n          + \"passwd=MD5('\" + passwd + \"')\")\n\n  row = query.first()\n  if (query.returns_rows and row != None):\n    return row[0]\n  return 0", "func_src_after": "def authenticate(user, passwd, db):\n  \"\"\" Takes a username, password, and connection object as input, and checks\n  if this corresponds to an actual user. Salts the password as necessary. \"\"\"\n  # get salt and add to password if necessary\n  saltQuery = db.execute(text(\"SELECT salt FROM users WHERE username=:u\"),\n                         u = user)\n  # if there's a salt set, then use it\n  if saltQuery.returns_rows:\n    salt = saltQuery.first()\n    # make sure username is found and salt isn't null\n    if salt != None and salt[0] != None:\n      passwd = salt[0] + passwd\n\n  # query whether there's a match for the username and password\n  query = db.execute(text(\"SELECT * FROM users WHERE username=:u AND \" \\\n                          + \"passwd=MD5(:p)\"), u = user, p = passwd)\n\n  row = query.first()\n  if (query.returns_rows and row != None):\n    return row[0]\n  return 0", "line_changes": {"deleted": [{"line_no": 5, "char_start": 237, "char_end": 313, "line": "  saltQuery = db.execute(\"SELECT salt FROM users WHERE username='\" + user \\\n"}, {"line_no": 6, "char_start": 313, "char_end": 330, "line": "          + \"'\")\n"}, {"line_no": 15, "char_start": 619, "char_end": 699, "line": "  query = db.execute(\"SELECT * FROM users WHERE username='\" + user + \"' AND \" \\\n"}, {"line_no": 16, "char_start": 699, "char_end": 743, "line": "          + \"passwd=MD5('\" + passwd + \"')\")\n"}], "added": [{"line_no": 5, "char_start": 237, "char_end": 312, "line": "  saltQuery = db.execute(text(\"SELECT salt FROM users WHERE username=:u\"),\n"}, {"line_no": 6, "char_start": 312, "char_end": 347, "line": "                         u = user)\n"}, {"line_no": 15, "char_start": 636, "char_end": 709, "line": "  query = db.execute(text(\"SELECT * FROM users WHERE username=:u AND \" \\\n"}, {"line_no": 16, "char_start": 709, "char_end": 778, "line": "                          + \"passwd=MD5(:p)\"), u = user, p = passwd)\n"}]}, "char_changes": {"deleted": [{"char_start": 301, "char_end": 328, "chars": "'\" + user \\\n          + \"'\""}, {"char_start": 676, "char_end": 690, "chars": "'\" + user + \"'"}, {"char_start": 709, "char_end": 741, "chars": "+ \"passwd=MD5('\" + passwd + \"')\""}], "added": [{"char_start": 262, "char_end": 267, "chars": "text("}, {"char_start": 306, "char_end": 345, "chars": ":u\"),\n                         u = user"}, {"char_start": 657, "char_end": 662, "chars": "text("}, {"char_start": 698, "char_end": 700, "chars": ":u"}, {"char_start": 719, "char_end": 776, "chars": "                + \"passwd=MD5(:p)\"), u = user, p = passwd"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "auth.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python function to verify a user's credentials against a database, including password salting."}
{"func_name": "process_packet_tail", "func_src_before": "void process_packet_tail(struct msg_digest *md)\n{\n\tstruct state *st = md->st;\n\tenum state_kind from_state = md->v1_from_state;\n\tconst struct state_v1_microcode *smc = md->smc;\n\tbool new_iv_set = md->new_iv_set;\n\tbool self_delete = FALSE;\n\n\tif (md->hdr.isa_flags & ISAKMP_FLAGS_v1_ENCRYPTION) {\n\t\tendpoint_buf b;\n\t\tdbg(\"received encrypted packet from %s\", str_endpoint(&md->sender, &b));\n\n\t\tif (st == NULL) {\n\t\t\tlibreswan_log(\n\t\t\t\t\"discarding encrypted message for an unknown ISAKMP SA\");\n\t\t\treturn;\n\t\t}\n\t\tif (st->st_skeyid_e_nss == NULL) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\"discarding encrypted message because we haven't yet negotiated keying material\");\n\t\t\treturn;\n\t\t}\n\n\t\t/* Mark as encrypted */\n\t\tmd->encrypted = TRUE;\n\n\t\t/* do the specified decryption\n\t\t *\n\t\t * IV is from st->st_iv or (if new_iv_set) st->st_new_iv.\n\t\t * The new IV is placed in st->st_new_iv\n\t\t *\n\t\t * See RFC 2409 \"IKE\" Appendix B\n\t\t *\n\t\t * XXX The IV should only be updated really if the packet\n\t\t * is successfully processed.\n\t\t * We should keep this value, check for a success return\n\t\t * value from the parsing routines and then replace.\n\t\t *\n\t\t * Each post phase 1 exchange generates IVs from\n\t\t * the last phase 1 block, not the last block sent.\n\t\t */\n\t\tconst struct encrypt_desc *e = st->st_oakley.ta_encrypt;\n\n\t\tif (pbs_left(&md->message_pbs) % e->enc_blocksize != 0) {\n\t\t\tloglog(RC_LOG_SERIOUS, \"malformed message: not a multiple of encryption blocksize\");\n\t\t\treturn;\n\t\t}\n\n\t\t/* XXX Detect weak keys */\n\n\t\t/* grab a copy of raw packet (for duplicate packet detection) */\n\t\tmd->raw_packet = clone_bytes_as_chunk(md->packet_pbs.start,\n\t\t\t\t\t\t      pbs_room(&md->packet_pbs),\n\t\t\t\t\t\t      \"raw packet\");\n\n\t\t/* Decrypt everything after header */\n\t\tif (!new_iv_set) {\n\t\t\tif (st->st_v1_iv.len == 0) {\n\t\t\t\tinit_phase2_iv(st, &md->hdr.isa_msgid);\n\t\t\t} else {\n\t\t\t\t/* use old IV */\n\t\t\t\trestore_new_iv(st, st->st_v1_iv);\n\t\t\t}\n\t\t}\n\n\t\tpassert(st->st_v1_new_iv.len >= e->enc_blocksize);\n\t\tst->st_v1_new_iv.len = e->enc_blocksize;   /* truncate */\n\n\t\tif (DBGP(DBG_CRYPT)) {\n\t\t\tDBG_log(\"decrypting %u bytes using algorithm %s\",\n\t\t\t\t(unsigned) pbs_left(&md->message_pbs),\n\t\t\t\tst->st_oakley.ta_encrypt->common.fqn);\n\t\t\tDBG_dump_hunk(\"IV before:\", st->st_v1_new_iv);\n\t\t}\n\t\te->encrypt_ops->do_crypt(e, md->message_pbs.cur,\n\t\t\t\t\t pbs_left(&md->message_pbs),\n\t\t\t\t\t st->st_enc_key_nss,\n\t\t\t\t\t st->st_v1_new_iv.ptr, FALSE);\n\t\tif (DBGP(DBG_CRYPT)) {\n\t\t\tDBG_dump_hunk(\"IV after:\", st->st_v1_new_iv);\n\t\t\tDBG_log(\"decrypted payload (starts at offset %td):\",\n\t\t\t\tmd->message_pbs.cur - md->message_pbs.roof);\n\t\t\tDBG_dump(NULL, md->message_pbs.start,\n\t\t\t\t md->message_pbs.roof - md->message_pbs.start);\n\t\t}\n\t} else {\n\t\t/* packet was not encryped -- should it have been? */\n\n\t\tif (smc->flags & SMF_INPUT_ENCRYPTED) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"packet rejected: should have been encrypted\");\n\t\t\tSEND_NOTIFICATION(INVALID_FLAGS);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Digest the message.\n\t * Padding must be removed to make hashing work.\n\t * Padding comes from encryption (so this code must be after decryption).\n\t * Padding rules are described before the definition of\n\t * struct isakmp_hdr in packet.h.\n\t */\n\t{\n\t\tenum next_payload_types_ikev1 np = md->hdr.isa_np;\n\t\tlset_t needed = smc->req_payloads;\n\t\tconst char *excuse =\n\t\t\tLIN(SMF_PSK_AUTH | SMF_FIRST_ENCRYPTED_INPUT,\n\t\t\t    smc->flags) ?\n\t\t\t\"probable authentication failure (mismatch of preshared secrets?): \"\n\t\t\t:\n\t\t\t\"\";\n\n\t\twhile (np != ISAKMP_NEXT_NONE) {\n\t\t\tstruct_desc *sd = v1_payload_desc(np);\n\n\t\t\tif (md->digest_roof >= elemsof(md->digest)) {\n\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t       \"more than %zu payloads in message; ignored\",\n\t\t\t\t       elemsof(md->digest));\n\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tstruct payload_digest *const pd = md->digest + md->digest_roof;\n\n\t\t\t/*\n\t\t\t * only do this in main mode. In aggressive mode, there\n\t\t\t * is no negotiation of NAT-T method. Get it right.\n\t\t\t */\n\t\t\tif (st != NULL && st->st_connection != NULL &&\n\t\t\t    (st->st_connection->policy & POLICY_AGGRESSIVE) == LEMPTY)\n\t\t\t{\n\t\t\t\tswitch (np) {\n\t\t\t\tcase ISAKMP_NEXT_NATD_RFC:\n\t\t\t\tcase ISAKMP_NEXT_NATOA_RFC:\n\t\t\t\t\tif ((st->hidden_variables.st_nat_traversal & NAT_T_WITH_RFC_VALUES) == LEMPTY) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * don't accept NAT-D/NAT-OA reloc directly in message,\n\t\t\t\t\t\t * unless we're using NAT-T RFC\n\t\t\t\t\t\t */\n\t\t\t\t\t\tDBG(DBG_NATT,\n\t\t\t\t\t\t    DBG_log(\"st_nat_traversal was: %s\",\n\t\t\t\t\t\t\t    bitnamesof(natt_bit_names,\n\t\t\t\t\t\t\t\t       st->hidden_variables.st_nat_traversal)));\n\t\t\t\t\t\tsd = NULL;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (sd == NULL) {\n\t\t\t\t/* payload type is out of range or requires special handling */\n\t\t\t\tswitch (np) {\n\t\t\t\tcase ISAKMP_NEXT_ID:\n\t\t\t\t\t/* ??? two kinds of ID payloads */\n\t\t\t\t\tsd = (IS_PHASE1(from_state) ||\n\t\t\t\t\t      IS_PHASE15(from_state)) ?\n\t\t\t\t\t\t&isakmp_identification_desc :\n\t\t\t\t\t\t&isakmp_ipsec_identification_desc;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_NATD_DRAFTS: /* out of range */\n\t\t\t\t\t/*\n\t\t\t\t\t * ISAKMP_NEXT_NATD_DRAFTS was a private use type before RFC-3947.\n\t\t\t\t\t * Since it has the same format as ISAKMP_NEXT_NATD_RFC,\n\t\t\t\t\t * just rewrite np and sd, and carry on.\n\t\t\t\t\t */\n\t\t\t\t\tnp = ISAKMP_NEXT_NATD_RFC;\n\t\t\t\t\tsd = &isakmp_nat_d_drafts;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_NATOA_DRAFTS: /* out of range */\n\t\t\t\t\t/* NAT-OA was a private use type before RFC-3947 -- same format */\n\t\t\t\t\tnp = ISAKMP_NEXT_NATOA_RFC;\n\t\t\t\t\tsd = &isakmp_nat_oa_drafts;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_SAK: /* or ISAKMP_NEXT_NATD_BADDRAFTS */\n\t\t\t\t\t/*\n\t\t\t\t\t * Official standards say that this is ISAKMP_NEXT_SAK,\n\t\t\t\t\t * a part of Group DOI, something we don't implement.\n\t\t\t\t\t * Old non-updated Cisco gear abused this number in ancient NAT drafts.\n\t\t\t\t\t * We ignore (rather than reject) this in support of people\n\t\t\t\t\t * with crufty Cisco machines.\n\t\t\t\t\t */\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage with unsupported payload ISAKMP_NEXT_SAK (or ISAKMP_NEXT_NATD_BADDRAFTS) ignored\",\n\t\t\t\t\t\texcuse);\n\t\t\t\t\t/*\n\t\t\t\t\t * Hack to discard payload, whatever it was.\n\t\t\t\t\t * Since we are skipping the rest of the loop\n\t\t\t\t\t * body we must do some things ourself:\n\t\t\t\t\t * - demarshall the payload\n\t\t\t\t\t * - grab the next payload number (np)\n\t\t\t\t\t * - don't keep payload (don't increment pd)\n\t\t\t\t\t * - skip rest of loop body\n\t\t\t\t\t */\n\t\t\t\t\tif (!in_struct(&pd->payload, &isakmp_ignore_desc, &md->message_pbs,\n\t\t\t\t\t\t       &pd->pbs)) {\n\t\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t       \"%smalformed payload in packet\",\n\t\t\t\t\t\t       excuse);\n\t\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tnp = pd->payload.generic.isag_np;\n\t\t\t\t\t/* NOTE: we do not increment pd! */\n\t\t\t\t\tcontinue;  /* skip rest of the loop */\n\n\t\t\t\tdefault:\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage ignored because it contains an unknown or unexpected payload type (%s) at the outermost level\",\n\t\t\t\t\t       excuse,\n\t\t\t\t\t       enum_show(&ikev1_payload_names, np));\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(INVALID_PAYLOAD_TYPE);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tpassert(sd != NULL);\n\t\t\t}\n\n\t\t\tpassert(np < LELEM_ROOF);\n\n\t\t\t{\n\t\t\t\tlset_t s = LELEM(np);\n\n\t\t\t\tif (LDISJOINT(s,\n\t\t\t\t\t      needed | smc->opt_payloads |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_VID) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_N) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_D) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_CR) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_CERT))) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage ignored because it contains a payload type (%s) unexpected by state %s\",\n\t\t\t\t\t\texcuse,\n\t\t\t\t\t\tenum_show(&ikev1_payload_names, np),\n\t\t\t\t\t\tst->st_state->name);\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(INVALID_PAYLOAD_TYPE);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tDBG(DBG_PARSING,\n\t\t\t\t    DBG_log(\"got payload 0x%\" PRIxLSET\"  (%s) needed: 0x%\" PRIxLSET \" opt: 0x%\" PRIxLSET,\n\t\t\t\t\t    s, enum_show(&ikev1_payload_names, np),\n\t\t\t\t\t    needed, smc->opt_payloads));\n\t\t\t\tneeded &= ~s;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Read in the payload recording what type it\n\t\t\t * should be\n\t\t\t */\n\t\t\tpd->payload_type = np;\n\t\t\tif (!in_struct(&pd->payload, sd, &md->message_pbs,\n\t\t\t\t       &pd->pbs)) {\n\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t       \"%smalformed payload in packet\",\n\t\t\t\t       excuse);\n\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t/* do payload-type specific debugging */\n\t\t\tswitch (np) {\n\t\t\tcase ISAKMP_NEXT_ID:\n\t\t\tcase ISAKMP_NEXT_NATOA_RFC:\n\t\t\t\t/* dump ID section */\n\t\t\t\tDBG(DBG_PARSING,\n\t\t\t\t    DBG_dump(\"     obj: \", pd->pbs.cur,\n\t\t\t\t\t     pbs_left(&pd->pbs)));\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\n\t\t\t/*\n\t\t\t * Place payload at the end of the chain for this type.\n\t\t\t * This code appears in ikev1.c and ikev2.c.\n\t\t\t */\n\t\t\t{\n\t\t\t\t/* np is a proper subscript for chain[] */\n\t\t\t\tpassert(np < elemsof(md->chain));\n\t\t\t\tstruct payload_digest **p = &md->chain[np];\n\n\t\t\t\twhile (*p != NULL)\n\t\t\t\t\tp = &(*p)->next;\n\t\t\t\t*p = pd;\n\t\t\t\tpd->next = NULL;\n\t\t\t}\n\n\t\t\tnp = pd->payload.generic.isag_np;\n\t\t\tmd->digest_roof++;\n\n\t\t\t/* since we've digested one payload happily, it is probably\n\t\t\t * the case that any decryption worked.  So we will not suggest\n\t\t\t * encryption failure as an excuse for subsequent payload\n\t\t\t * problems.\n\t\t\t */\n\t\t\texcuse = \"\";\n\t\t}\n\n\t\tDBG(DBG_PARSING, {\n\t\t\t    if (pbs_left(&md->message_pbs) != 0)\n\t\t\t\t    DBG_log(\"removing %d bytes of padding\",\n\t\t\t\t\t    (int) pbs_left(&md->message_pbs));\n\t\t    });\n\n\t\tmd->message_pbs.roof = md->message_pbs.cur;\n\n\t\t/* check that all mandatory payloads appeared */\n\n\t\tif (needed != 0) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"message for %s is missing payloads %s\",\n\t\t\t       finite_states[from_state]->name,\n\t\t\t       bitnamesof(payload_name_ikev1, needed));\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (!check_v1_HASH(smc->hash_type, smc->message, st, md)) {\n\t\t/*SEND_NOTIFICATION(INVALID_HASH_INFORMATION);*/\n\t\treturn;\n\t}\n\n\t/* more sanity checking: enforce most ordering constraints */\n\n\tif (IS_PHASE1(from_state) || IS_PHASE15(from_state)) {\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5 Exchanges:\n\t\t * \"The SA payload MUST precede all other payloads in a phase 1 exchange.\"\n\t\t */\n\t\tif (md->chain[ISAKMP_NEXT_SA] != NULL &&\n\t\t    md->hdr.isa_np != ISAKMP_NEXT_SA) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"malformed Phase 1 message: does not start with an SA payload\");\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t} else if (IS_QUICK(from_state)) {\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5.5 Phase 2 - Quick Mode\n\t\t *\n\t\t * \"In Quick Mode, a HASH payload MUST immediately follow the ISAKMP\n\t\t *  header and a SA payload MUST immediately follow the HASH.\"\n\t\t * [NOTE: there may be more than one SA payload, so this is not\n\t\t *  totally reasonable.  Probably all SAs should be so constrained.]\n\t\t *\n\t\t * \"If ISAKMP is acting as a client negotiator on behalf of another\n\t\t *  party, the identities of the parties MUST be passed as IDci and\n\t\t *  then IDcr.\"\n\t\t *\n\t\t * \"With the exception of the HASH, SA, and the optional ID payloads,\n\t\t *  there are no payload ordering restrictions on Quick Mode.\"\n\t\t */\n\n\t\tif (md->hdr.isa_np != ISAKMP_NEXT_HASH) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"malformed Quick Mode message: does not start with a HASH payload\");\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\n\t\t{\n\t\t\tstruct payload_digest *p;\n\t\t\tint i;\n\n\t\t\tp = md->chain[ISAKMP_NEXT_SA];\n\t\t\ti = 1;\n\t\t\twhile (p != NULL) {\n\t\t\t\tif (p != &md->digest[i]) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t       \"malformed Quick Mode message: SA payload is in wrong position\");\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tp = p->next;\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5.5 Phase 2 - Quick Mode:\n\t\t * \"If ISAKMP is acting as a client negotiator on behalf of another\n\t\t *  party, the identities of the parties MUST be passed as IDci and\n\t\t *  then IDcr.\"\n\t\t */\n\t\t{\n\t\t\tstruct payload_digest *id = md->chain[ISAKMP_NEXT_ID];\n\n\t\t\tif (id != NULL) {\n\t\t\t\tif (id->next == NULL ||\n\t\t\t\t    id->next->next != NULL) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"malformed Quick Mode message: if any ID payload is present, there must be exactly two\");\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif (id + 1 != id->next) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"malformed Quick Mode message: the ID payloads are not adjacent\");\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * Ignore payloads that we don't handle:\n\t */\n\t/* XXX Handle Notifications */\n\t{\n\t\tstruct payload_digest *p = md->chain[ISAKMP_NEXT_N];\n\n\t\twhile (p != NULL) {\n\t\t\tswitch (p->payload.notification.isan_type) {\n\t\t\tcase R_U_THERE:\n\t\t\tcase R_U_THERE_ACK:\n\t\t\tcase ISAKMP_N_CISCO_LOAD_BALANCE:\n\t\t\tcase PAYLOAD_MALFORMED:\n\t\t\tcase INVALID_MESSAGE_ID:\n\t\t\tcase IPSEC_RESPONDER_LIFETIME:\n\t\t\t\tif (md->hdr.isa_xchg == ISAKMP_XCHG_INFO) {\n\t\t\t\t\t/* these are handled later on in informational() */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/* FALL THROUGH */\n\t\t\tdefault:\n\t\t\t\tif (st == NULL) {\n\t\t\t\t\tDBG(DBG_CONTROL, DBG_log(\n\t\t\t\t\t       \"ignoring informational payload %s, no corresponding state\",\n\t\t\t\t\t       enum_show(& ikev1_notify_names,\n\t\t\t\t\t\t\t p->payload.notification.isan_type)));\n\t\t\t\t} else {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t       \"ignoring informational payload %s, msgid=%08\" PRIx32 \", length=%d\",\n\t\t\t\t\t       enum_show(&ikev1_notify_names,\n\t\t\t\t\t\t\t p->payload.notification.isan_type),\n\t\t\t\t\t       st->st_v1_msgid.id,\n\t\t\t\t\t       p->payload.notification.isan_length);\n\t\t\t\t\tDBG_dump_pbs(&p->pbs);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (DBGP(DBG_BASE)) {\n\t\t\t\tDBG_dump(\"info:\", p->pbs.cur,\n\t\t\t\t\t pbs_left(&p->pbs));\n\t\t\t}\n\n\t\t\tp = p->next;\n\t\t}\n\n\t\tp = md->chain[ISAKMP_NEXT_D];\n\t\twhile (p != NULL) {\n\t\t\tself_delete |= accept_delete(md, p);\n\t\t\tif (DBGP(DBG_BASE)) {\n\t\t\t\tDBG_dump(\"del:\", p->pbs.cur,\n\t\t\t\t\t pbs_left(&p->pbs));\n\t\t\t}\n\t\t\tif (md->st != st) {\n\t\t\t\tpexpect(md->st == NULL);\n\t\t\t\tdbg(\"zapping ST as accept_delete() zapped MD.ST\");\n\t\t\t\tst = md->st;\n\t\t\t}\n\t\t\tp = p->next;\n\t\t}\n\n\t\tp = md->chain[ISAKMP_NEXT_VID];\n\t\twhile (p != NULL) {\n\t\t\thandle_vendorid(md, (char *)p->pbs.cur,\n\t\t\t\t\tpbs_left(&p->pbs), FALSE);\n\t\t\tp = p->next;\n\t\t}\n\t}\n\n\tif (self_delete) {\n\t\taccept_self_delete(md);\n\t\tst = md->st;\n\t\t/* note: st ought to be NULL from here on */\n\t}\n\n\tpexpect(st == md->st);\n\tstatetime_t start = statetime_start(md->st);\n\t/*\n\t * XXX: danger - the .informational() processor deletes ST;\n\t * and then tunnels this loss through MD.ST.\n\t */\n\tcomplete_v1_state_transition(md, smc->processor(st, md));\n\tstatetime_stop(&start, \"%s()\", __func__);\n\t/* our caller will release_any_md(mdp); */\n}", "func_src_after": "void process_packet_tail(struct msg_digest *md)\n{\n\tstruct state *st = md->st;\n\tenum state_kind from_state = md->v1_from_state;\n\tconst struct state_v1_microcode *smc = md->smc;\n\tbool new_iv_set = md->new_iv_set;\n\tbool self_delete = FALSE;\n\n\tif (md->hdr.isa_flags & ISAKMP_FLAGS_v1_ENCRYPTION) {\n\t\tendpoint_buf b;\n\t\tdbg(\"received encrypted packet from %s\", str_endpoint(&md->sender, &b));\n\n\t\tif (st == NULL) {\n\t\t\tlibreswan_log(\n\t\t\t\t\"discarding encrypted message for an unknown ISAKMP SA\");\n\t\t\treturn;\n\t\t}\n\t\tif (st->st_skeyid_e_nss == NULL) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\"discarding encrypted message because we haven't yet negotiated keying material\");\n\t\t\treturn;\n\t\t}\n\n\t\t/* Mark as encrypted */\n\t\tmd->encrypted = TRUE;\n\n\t\t/* do the specified decryption\n\t\t *\n\t\t * IV is from st->st_iv or (if new_iv_set) st->st_new_iv.\n\t\t * The new IV is placed in st->st_new_iv\n\t\t *\n\t\t * See RFC 2409 \"IKE\" Appendix B\n\t\t *\n\t\t * XXX The IV should only be updated really if the packet\n\t\t * is successfully processed.\n\t\t * We should keep this value, check for a success return\n\t\t * value from the parsing routines and then replace.\n\t\t *\n\t\t * Each post phase 1 exchange generates IVs from\n\t\t * the last phase 1 block, not the last block sent.\n\t\t */\n\t\tconst struct encrypt_desc *e = st->st_oakley.ta_encrypt;\n\n\t\tif (pbs_left(&md->message_pbs) % e->enc_blocksize != 0) {\n\t\t\tloglog(RC_LOG_SERIOUS, \"malformed message: not a multiple of encryption blocksize\");\n\t\t\treturn;\n\t\t}\n\n\t\t/* XXX Detect weak keys */\n\n\t\t/* grab a copy of raw packet (for duplicate packet detection) */\n\t\tmd->raw_packet = clone_bytes_as_chunk(md->packet_pbs.start,\n\t\t\t\t\t\t      pbs_room(&md->packet_pbs),\n\t\t\t\t\t\t      \"raw packet\");\n\n\t\t/* Decrypt everything after header */\n\t\tif (!new_iv_set) {\n\t\t\tif (st->st_v1_iv.len == 0) {\n\t\t\t\tinit_phase2_iv(st, &md->hdr.isa_msgid);\n\t\t\t} else {\n\t\t\t\t/* use old IV */\n\t\t\t\trestore_new_iv(st, st->st_v1_iv);\n\t\t\t}\n\t\t}\n\n\t\tpassert(st->st_v1_new_iv.len >= e->enc_blocksize);\n\t\tst->st_v1_new_iv.len = e->enc_blocksize;   /* truncate */\n\n\t\tif (DBGP(DBG_CRYPT)) {\n\t\t\tDBG_log(\"decrypting %u bytes using algorithm %s\",\n\t\t\t\t(unsigned) pbs_left(&md->message_pbs),\n\t\t\t\tst->st_oakley.ta_encrypt->common.fqn);\n\t\t\tDBG_dump_hunk(\"IV before:\", st->st_v1_new_iv);\n\t\t}\n\t\te->encrypt_ops->do_crypt(e, md->message_pbs.cur,\n\t\t\t\t\t pbs_left(&md->message_pbs),\n\t\t\t\t\t st->st_enc_key_nss,\n\t\t\t\t\t st->st_v1_new_iv.ptr, FALSE);\n\t\tif (DBGP(DBG_CRYPT)) {\n\t\t\tDBG_dump_hunk(\"IV after:\", st->st_v1_new_iv);\n\t\t\tDBG_log(\"decrypted payload (starts at offset %td):\",\n\t\t\t\tmd->message_pbs.cur - md->message_pbs.roof);\n\t\t\tDBG_dump(NULL, md->message_pbs.start,\n\t\t\t\t md->message_pbs.roof - md->message_pbs.start);\n\t\t}\n\t} else {\n\t\t/* packet was not encryped -- should it have been? */\n\n\t\tif (smc->flags & SMF_INPUT_ENCRYPTED) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"packet rejected: should have been encrypted\");\n\t\t\tSEND_NOTIFICATION(INVALID_FLAGS);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Digest the message.\n\t * Padding must be removed to make hashing work.\n\t * Padding comes from encryption (so this code must be after decryption).\n\t * Padding rules are described before the definition of\n\t * struct isakmp_hdr in packet.h.\n\t */\n\t{\n\t\tenum next_payload_types_ikev1 np = md->hdr.isa_np;\n\t\tlset_t needed = smc->req_payloads;\n\t\tconst char *excuse =\n\t\t\tLIN(SMF_PSK_AUTH | SMF_FIRST_ENCRYPTED_INPUT,\n\t\t\t    smc->flags) ?\n\t\t\t\"probable authentication failure (mismatch of preshared secrets?): \"\n\t\t\t:\n\t\t\t\"\";\n\n\t\twhile (np != ISAKMP_NEXT_NONE) {\n\t\t\tstruct_desc *sd = v1_payload_desc(np);\n\n\t\t\tif (md->digest_roof >= elemsof(md->digest)) {\n\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t       \"more than %zu payloads in message; ignored\",\n\t\t\t\t       elemsof(md->digest));\n\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tstruct payload_digest *const pd = md->digest + md->digest_roof;\n\n\t\t\t/*\n\t\t\t * only do this in main mode. In aggressive mode, there\n\t\t\t * is no negotiation of NAT-T method. Get it right.\n\t\t\t */\n\t\t\tif (st != NULL && st->st_connection != NULL &&\n\t\t\t    (st->st_connection->policy & POLICY_AGGRESSIVE) == LEMPTY)\n\t\t\t{\n\t\t\t\tswitch (np) {\n\t\t\t\tcase ISAKMP_NEXT_NATD_RFC:\n\t\t\t\tcase ISAKMP_NEXT_NATOA_RFC:\n\t\t\t\t\tif ((st->hidden_variables.st_nat_traversal & NAT_T_WITH_RFC_VALUES) == LEMPTY) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * don't accept NAT-D/NAT-OA reloc directly in message,\n\t\t\t\t\t\t * unless we're using NAT-T RFC\n\t\t\t\t\t\t */\n\t\t\t\t\t\tDBG(DBG_NATT,\n\t\t\t\t\t\t    DBG_log(\"st_nat_traversal was: %s\",\n\t\t\t\t\t\t\t    bitnamesof(natt_bit_names,\n\t\t\t\t\t\t\t\t       st->hidden_variables.st_nat_traversal)));\n\t\t\t\t\t\tsd = NULL;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (sd == NULL) {\n\t\t\t\t/* payload type is out of range or requires special handling */\n\t\t\t\tswitch (np) {\n\t\t\t\tcase ISAKMP_NEXT_ID:\n\t\t\t\t\t/* ??? two kinds of ID payloads */\n\t\t\t\t\tsd = (IS_PHASE1(from_state) ||\n\t\t\t\t\t      IS_PHASE15(from_state)) ?\n\t\t\t\t\t\t&isakmp_identification_desc :\n\t\t\t\t\t\t&isakmp_ipsec_identification_desc;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_NATD_DRAFTS: /* out of range */\n\t\t\t\t\t/*\n\t\t\t\t\t * ISAKMP_NEXT_NATD_DRAFTS was a private use type before RFC-3947.\n\t\t\t\t\t * Since it has the same format as ISAKMP_NEXT_NATD_RFC,\n\t\t\t\t\t * just rewrite np and sd, and carry on.\n\t\t\t\t\t */\n\t\t\t\t\tnp = ISAKMP_NEXT_NATD_RFC;\n\t\t\t\t\tsd = &isakmp_nat_d_drafts;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_NATOA_DRAFTS: /* out of range */\n\t\t\t\t\t/* NAT-OA was a private use type before RFC-3947 -- same format */\n\t\t\t\t\tnp = ISAKMP_NEXT_NATOA_RFC;\n\t\t\t\t\tsd = &isakmp_nat_oa_drafts;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ISAKMP_NEXT_SAK: /* or ISAKMP_NEXT_NATD_BADDRAFTS */\n\t\t\t\t\t/*\n\t\t\t\t\t * Official standards say that this is ISAKMP_NEXT_SAK,\n\t\t\t\t\t * a part of Group DOI, something we don't implement.\n\t\t\t\t\t * Old non-updated Cisco gear abused this number in ancient NAT drafts.\n\t\t\t\t\t * We ignore (rather than reject) this in support of people\n\t\t\t\t\t * with crufty Cisco machines.\n\t\t\t\t\t */\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage with unsupported payload ISAKMP_NEXT_SAK (or ISAKMP_NEXT_NATD_BADDRAFTS) ignored\",\n\t\t\t\t\t\texcuse);\n\t\t\t\t\t/*\n\t\t\t\t\t * Hack to discard payload, whatever it was.\n\t\t\t\t\t * Since we are skipping the rest of the loop\n\t\t\t\t\t * body we must do some things ourself:\n\t\t\t\t\t * - demarshall the payload\n\t\t\t\t\t * - grab the next payload number (np)\n\t\t\t\t\t * - don't keep payload (don't increment pd)\n\t\t\t\t\t * - skip rest of loop body\n\t\t\t\t\t */\n\t\t\t\t\tif (!in_struct(&pd->payload, &isakmp_ignore_desc, &md->message_pbs,\n\t\t\t\t\t\t       &pd->pbs)) {\n\t\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t       \"%smalformed payload in packet\",\n\t\t\t\t\t\t       excuse);\n\t\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tnp = pd->payload.generic.isag_np;\n\t\t\t\t\t/* NOTE: we do not increment pd! */\n\t\t\t\t\tcontinue;  /* skip rest of the loop */\n\n\t\t\t\tdefault:\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage ignored because it contains an unknown or unexpected payload type (%s) at the outermost level\",\n\t\t\t\t\t       excuse,\n\t\t\t\t\t       enum_show(&ikev1_payload_names, np));\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(INVALID_PAYLOAD_TYPE);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tpassert(sd != NULL);\n\t\t\t}\n\n\t\t\tpassert(np < LELEM_ROOF);\n\n\t\t\t{\n\t\t\t\tlset_t s = LELEM(np);\n\n\t\t\t\tif (LDISJOINT(s,\n\t\t\t\t\t      needed | smc->opt_payloads |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_VID) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_N) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_D) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_CR) |\n\t\t\t\t\t      LELEM(ISAKMP_NEXT_CERT))) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"%smessage ignored because it contains a payload type (%s) unexpected by state %s\",\n\t\t\t\t\t\texcuse,\n\t\t\t\t\t\tenum_show(&ikev1_payload_names, np),\n\t\t\t\t\t\tfinite_states[smc->state]->name);\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(INVALID_PAYLOAD_TYPE);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tDBG(DBG_PARSING,\n\t\t\t\t    DBG_log(\"got payload 0x%\" PRIxLSET\"  (%s) needed: 0x%\" PRIxLSET \" opt: 0x%\" PRIxLSET,\n\t\t\t\t\t    s, enum_show(&ikev1_payload_names, np),\n\t\t\t\t\t    needed, smc->opt_payloads));\n\t\t\t\tneeded &= ~s;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Read in the payload recording what type it\n\t\t\t * should be\n\t\t\t */\n\t\t\tpd->payload_type = np;\n\t\t\tif (!in_struct(&pd->payload, sd, &md->message_pbs,\n\t\t\t\t       &pd->pbs)) {\n\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t       \"%smalformed payload in packet\",\n\t\t\t\t       excuse);\n\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t/* do payload-type specific debugging */\n\t\t\tswitch (np) {\n\t\t\tcase ISAKMP_NEXT_ID:\n\t\t\tcase ISAKMP_NEXT_NATOA_RFC:\n\t\t\t\t/* dump ID section */\n\t\t\t\tDBG(DBG_PARSING,\n\t\t\t\t    DBG_dump(\"     obj: \", pd->pbs.cur,\n\t\t\t\t\t     pbs_left(&pd->pbs)));\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\n\t\t\t/*\n\t\t\t * Place payload at the end of the chain for this type.\n\t\t\t * This code appears in ikev1.c and ikev2.c.\n\t\t\t */\n\t\t\t{\n\t\t\t\t/* np is a proper subscript for chain[] */\n\t\t\t\tpassert(np < elemsof(md->chain));\n\t\t\t\tstruct payload_digest **p = &md->chain[np];\n\n\t\t\t\twhile (*p != NULL)\n\t\t\t\t\tp = &(*p)->next;\n\t\t\t\t*p = pd;\n\t\t\t\tpd->next = NULL;\n\t\t\t}\n\n\t\t\tnp = pd->payload.generic.isag_np;\n\t\t\tmd->digest_roof++;\n\n\t\t\t/* since we've digested one payload happily, it is probably\n\t\t\t * the case that any decryption worked.  So we will not suggest\n\t\t\t * encryption failure as an excuse for subsequent payload\n\t\t\t * problems.\n\t\t\t */\n\t\t\texcuse = \"\";\n\t\t}\n\n\t\tDBG(DBG_PARSING, {\n\t\t\t    if (pbs_left(&md->message_pbs) != 0)\n\t\t\t\t    DBG_log(\"removing %d bytes of padding\",\n\t\t\t\t\t    (int) pbs_left(&md->message_pbs));\n\t\t    });\n\n\t\tmd->message_pbs.roof = md->message_pbs.cur;\n\n\t\t/* check that all mandatory payloads appeared */\n\n\t\tif (needed != 0) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"message for %s is missing payloads %s\",\n\t\t\t       finite_states[from_state]->name,\n\t\t\t       bitnamesof(payload_name_ikev1, needed));\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (!check_v1_HASH(smc->hash_type, smc->message, st, md)) {\n\t\t/*SEND_NOTIFICATION(INVALID_HASH_INFORMATION);*/\n\t\treturn;\n\t}\n\n\t/* more sanity checking: enforce most ordering constraints */\n\n\tif (IS_PHASE1(from_state) || IS_PHASE15(from_state)) {\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5 Exchanges:\n\t\t * \"The SA payload MUST precede all other payloads in a phase 1 exchange.\"\n\t\t */\n\t\tif (md->chain[ISAKMP_NEXT_SA] != NULL &&\n\t\t    md->hdr.isa_np != ISAKMP_NEXT_SA) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"malformed Phase 1 message: does not start with an SA payload\");\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t} else if (IS_QUICK(from_state)) {\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5.5 Phase 2 - Quick Mode\n\t\t *\n\t\t * \"In Quick Mode, a HASH payload MUST immediately follow the ISAKMP\n\t\t *  header and a SA payload MUST immediately follow the HASH.\"\n\t\t * [NOTE: there may be more than one SA payload, so this is not\n\t\t *  totally reasonable.  Probably all SAs should be so constrained.]\n\t\t *\n\t\t * \"If ISAKMP is acting as a client negotiator on behalf of another\n\t\t *  party, the identities of the parties MUST be passed as IDci and\n\t\t *  then IDcr.\"\n\t\t *\n\t\t * \"With the exception of the HASH, SA, and the optional ID payloads,\n\t\t *  there are no payload ordering restrictions on Quick Mode.\"\n\t\t */\n\n\t\tif (md->hdr.isa_np != ISAKMP_NEXT_HASH) {\n\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t       \"malformed Quick Mode message: does not start with a HASH payload\");\n\t\t\tif (!md->encrypted) {\n\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\n\t\t{\n\t\t\tstruct payload_digest *p;\n\t\t\tint i;\n\n\t\t\tp = md->chain[ISAKMP_NEXT_SA];\n\t\t\ti = 1;\n\t\t\twhile (p != NULL) {\n\t\t\t\tif (p != &md->digest[i]) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t       \"malformed Quick Mode message: SA payload is in wrong position\");\n\t\t\t\t\tif (!md->encrypted) {\n\t\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tp = p->next;\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\n\t\t/* rfc2409: The Internet Key Exchange (IKE), 5.5 Phase 2 - Quick Mode:\n\t\t * \"If ISAKMP is acting as a client negotiator on behalf of another\n\t\t *  party, the identities of the parties MUST be passed as IDci and\n\t\t *  then IDcr.\"\n\t\t */\n\t\t{\n\t\t\tstruct payload_digest *id = md->chain[ISAKMP_NEXT_ID];\n\n\t\t\tif (id != NULL) {\n\t\t\t\tif (id->next == NULL ||\n\t\t\t\t    id->next->next != NULL) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"malformed Quick Mode message: if any ID payload is present, there must be exactly two\");\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif (id + 1 != id->next) {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t\t\"malformed Quick Mode message: the ID payloads are not adjacent\");\n\t\t\t\t\tSEND_NOTIFICATION(PAYLOAD_MALFORMED);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * Ignore payloads that we don't handle:\n\t */\n\t/* XXX Handle Notifications */\n\t{\n\t\tstruct payload_digest *p = md->chain[ISAKMP_NEXT_N];\n\n\t\twhile (p != NULL) {\n\t\t\tswitch (p->payload.notification.isan_type) {\n\t\t\tcase R_U_THERE:\n\t\t\tcase R_U_THERE_ACK:\n\t\t\tcase ISAKMP_N_CISCO_LOAD_BALANCE:\n\t\t\tcase PAYLOAD_MALFORMED:\n\t\t\tcase INVALID_MESSAGE_ID:\n\t\t\tcase IPSEC_RESPONDER_LIFETIME:\n\t\t\t\tif (md->hdr.isa_xchg == ISAKMP_XCHG_INFO) {\n\t\t\t\t\t/* these are handled later on in informational() */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/* FALL THROUGH */\n\t\t\tdefault:\n\t\t\t\tif (st == NULL) {\n\t\t\t\t\tDBG(DBG_CONTROL, DBG_log(\n\t\t\t\t\t       \"ignoring informational payload %s, no corresponding state\",\n\t\t\t\t\t       enum_show(& ikev1_notify_names,\n\t\t\t\t\t\t\t p->payload.notification.isan_type)));\n\t\t\t\t} else {\n\t\t\t\t\tloglog(RC_LOG_SERIOUS,\n\t\t\t\t\t       \"ignoring informational payload %s, msgid=%08\" PRIx32 \", length=%d\",\n\t\t\t\t\t       enum_show(&ikev1_notify_names,\n\t\t\t\t\t\t\t p->payload.notification.isan_type),\n\t\t\t\t\t       st->st_v1_msgid.id,\n\t\t\t\t\t       p->payload.notification.isan_length);\n\t\t\t\t\tDBG_dump_pbs(&p->pbs);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (DBGP(DBG_BASE)) {\n\t\t\t\tDBG_dump(\"info:\", p->pbs.cur,\n\t\t\t\t\t pbs_left(&p->pbs));\n\t\t\t}\n\n\t\t\tp = p->next;\n\t\t}\n\n\t\tp = md->chain[ISAKMP_NEXT_D];\n\t\twhile (p != NULL) {\n\t\t\tself_delete |= accept_delete(md, p);\n\t\t\tif (DBGP(DBG_BASE)) {\n\t\t\t\tDBG_dump(\"del:\", p->pbs.cur,\n\t\t\t\t\t pbs_left(&p->pbs));\n\t\t\t}\n\t\t\tif (md->st != st) {\n\t\t\t\tpexpect(md->st == NULL);\n\t\t\t\tdbg(\"zapping ST as accept_delete() zapped MD.ST\");\n\t\t\t\tst = md->st;\n\t\t\t}\n\t\t\tp = p->next;\n\t\t}\n\n\t\tp = md->chain[ISAKMP_NEXT_VID];\n\t\twhile (p != NULL) {\n\t\t\thandle_vendorid(md, (char *)p->pbs.cur,\n\t\t\t\t\tpbs_left(&p->pbs), FALSE);\n\t\t\tp = p->next;\n\t\t}\n\t}\n\n\tif (self_delete) {\n\t\taccept_self_delete(md);\n\t\tst = md->st;\n\t\t/* note: st ought to be NULL from here on */\n\t}\n\n\tpexpect(st == md->st);\n\tstatetime_t start = statetime_start(md->st);\n\t/*\n\t * XXX: danger - the .informational() processor deletes ST;\n\t * and then tunnels this loss through MD.ST.\n\t */\n\tcomplete_v1_state_transition(md, smc->processor(st, md));\n\tstatetime_stop(&start, \"%s()\", __func__);\n\t/* our caller will release_any_md(mdp); */\n}", "commit_link": "github.com/libreswan/libreswan/commit/471a3e41a449d7c753bc4edbba4239501bb62ba8", "file_name": "programs/pluto/ikev1.c", "vul_type": "cwe-125", "description": "Write a C function named `process_packet_tail` that processes an ISAKMP packet's tail end, handling encryption, payload digestion, and state transitions."}
{"func_name": "fetch_resultSet", "func_src_before": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = '%s', expires = '%s' \"\n                 \"WHERE identifier = '%s';\" %\n                 (self.table, nowStr, expiresStr, sid)\n                 )\n        self._query(query)\n        return rset", "func_src_after": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = $1, expires = $2 \"\n                 \"WHERE identifier = $3;\" % (self.table)\n                 )\n        self._query(query, nowStr, expiresStr, sid)\n        return rset", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and updates a record from a database using either string formatting or parameterized queries."}
{"func_name": "create_event", "func_src_before": "    def create_event(self, title, start_time, time_zone, server_id, description):\n        sql = \"\"\"INSERT INTO events (title, start_time, time_zone, server_id, description)\n                 VALUES ('{0}', '{1}', '{2}', '{3}', '{4}')\n                 \"\"\".format(title, start_time, time_zone, server_id, description)\n        self.cur.execute(sql)\n        self.conn.commit()", "func_src_after": "    def create_event(self, title, start_time, time_zone, server_id, description):\n        sql = \"\"\"\n              INSERT INTO events (title, start_time, time_zone, server_id, description)\n              VALUES (%s, %s, %s, %s, %s)\n              \"\"\"\n        self.cur.execute(sql, (title, start_time, time_zone, server_id, description))\n        self.conn.commit()", "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089", "description": "Write a Python function to insert an event with details into a database."}
{"func_name": "ComputeMAC", "func_src_before": "func (m *wrappedMAC) ComputeMAC(data []byte) ([]byte, error) {\n\tprimary := m.ps.Primary\n\tprimitive, ok := (primary.Primitive).(tink.MAC)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"mac_factory: not a MAC primitive\")\n\t}\n\tif m.ps.Primary.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\td := data\n\t\tif len(d) == maxInt {\n\t\t\treturn nil, fmt.Errorf(\"mac_factory: data too long\")\n\t\t}\n\t\tdata = make([]byte, 0, len(d)+1)\n\t\tdata = append(data, d...)\n\t\tdata = append(data, byte(0))\n\t}\n\tmac, err := primitive.ComputeMAC(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn append([]byte(primary.Prefix), mac...), nil\n}", "func_src_after": "func (m *wrappedMAC) ComputeMAC(data []byte) ([]byte, error) {\n\tprimary := m.ps.Primary\n\tprimitive, ok := (primary.Primitive).(tink.MAC)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"mac_factory: not a MAC primitive\")\n\t}\n\tif m.ps.Primary.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\td := data\n\t\tif len(d) >= maxInt {\n\t\t\treturn nil, fmt.Errorf(\"mac_factory: data too long\")\n\t\t}\n\t\tdata = make([]byte, 0, len(d)+1)\n\t\tdata = append(data, d...)\n\t\tdata = append(data, byte(0))\n\t}\n\tmac, err := primitive.ComputeMAC(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn append([]byte(primary.Prefix), mac...), nil\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 287, "char_end": 311, "line": "\t\tif len(d) == maxInt {\n"}], "added": [{"line_no": 9, "char_start": 287, "char_end": 311, "line": "\t\tif len(d) >= maxInt {\n"}]}, "char_changes": {"deleted": [{"char_start": 299, "char_end": 300, "chars": "="}], "added": [{"char_start": 299, "char_end": 300, "chars": ">"}]}, "commit_link": "github.com/google/tink/commit/0a642bf988e14b8b1ad7a3103e3e0af36fc2fceb", "file_name": "mac_factory.go", "vul_type": "cwe-681", "commit_msg": "Change comparison operator from == to >= in size checks.\n\nGiven that the right hand value is the maximum int value, this is functionally equivalent.\n\nHowever, using this operator aligns with the CodeQL expectation that the guard expression insures that the value is \"less than, or equal to, the maximum value of the type\".\n\nReferences:\nhttps://github.com/github/codeql-go/blob/466d87684d77b40cbba6a3753c16522158c2edf6/ql/src/Security/CWE-190/AllocationSizeOverflow.qhelp#L26-L27\n\nhttps://github.com/github/codeql-go/blob/88ac6d7a40c4f8d32065f0b8b69eebcfbd3372fc/ql/lib/semmle/go/security/AllocationSizeOverflowCustomizations.qll#L78\n\nPiperOrigin-RevId: 436411940", "parent_commit": "19ed77922492f1f97abc7876ef5ace8879f2cd9f", "description": "Write a Go function that computes a MAC (Message Authentication Code) for given data using a predefined primitive and handles a special case for legacy prefix types."}
{"func_name": "rename", "func_src_before": "    def rename(self, ref, to_name):\n        \"\"\"Rename a local file or folder\n\n        Return the actualized info object.\n\n        \"\"\"\n        new_name = safe_filename(to_name)\n        source_os_path = self._abspath(ref)\n        parent = ref.rsplit(u'/', 1)[0]\n        old_name = ref.rsplit(u'/', 1)[1]\n        parent = u'/' if parent == '' else parent\n        locker = self.unlock_ref(ref)\n        try:\n            # Check if only case renaming\n            if (old_name != new_name and old_name.lower() == new_name.lower()\n                and not self.is_case_sensitive()):\n                # Must use a temp rename as FS is not case sensitive\n                temp_path = os.tempnam(self._abspath(parent),\n                                       LocalClient.CASE_RENAME_PREFIX + old_name + '_')\n                if AbstractOSIntegration.is_windows():\n                    import ctypes\n                    ctypes.windll.kernel32.SetFileAttributesW(\n                                                unicode(temp_path), 2)\n                os.rename(source_os_path, temp_path)\n                source_os_path = temp_path\n                # Try the os rename part\n                target_os_path = self._abspath(os.path.join(parent, new_name))\n            else:\n                target_os_path, new_name = self._abspath_deduped(parent,\n                                                                new_name, old_name)\n            if old_name != new_name:\n                os.rename(source_os_path, target_os_path)\n            if AbstractOSIntegration.is_windows():\n                import ctypes\n                # See http://msdn.microsoft.com/en-us/library/aa365535%28v=vs.85%29.aspx\n                ctypes.windll.kernel32.SetFileAttributesW(\n                                            unicode(target_os_path), 128)\n            new_ref = self.get_children_ref(parent, new_name)\n            return self.get_info(new_ref)\n        finally:\n            self.lock_ref(ref, locker & 2)", "func_src_after": "    def rename(self, ref, to_name):\n        \"\"\"Rename a local file or folder\n\n        Return the actualized info object.\n\n        \"\"\"\n        new_name = safe_filename(to_name)\n        source_os_path = self._abspath(ref)\n        parent = ref.rsplit(u'/', 1)[0]\n        old_name = ref.rsplit(u'/', 1)[1]\n        parent = u'/' if parent == '' else parent\n        locker = self.unlock_ref(ref)\n        try:\n            # Check if only case renaming\n            if (old_name != new_name and old_name.lower() == new_name.lower()\n                and not self.is_case_sensitive()):\n                # Must use a temp rename as FS is not case sensitive\n                prefix = LocalClient.CASE_RENAME_PREFIX + old_name + '_'\n                _, temp_path = tempfile.mkstemp(dir=self._abspath(parent),\n                                                prefix=prefix)\n                if AbstractOSIntegration.is_windows():\n                    import ctypes\n                    ctypes.windll.kernel32.SetFileAttributesW(\n                                                unicode(temp_path), 2)\n                os.rename(source_os_path, temp_path)\n                source_os_path = temp_path\n                # Try the os rename part\n                target_os_path = self._abspath(os.path.join(parent, new_name))\n            else:\n                target_os_path, new_name = self._abspath_deduped(parent,\n                                                                new_name, old_name)\n            if old_name != new_name:\n                os.rename(source_os_path, target_os_path)\n            if AbstractOSIntegration.is_windows():\n                import ctypes\n                # See http://msdn.microsoft.com/en-us/library/aa365535%28v=vs.85%29.aspx\n                ctypes.windll.kernel32.SetFileAttributesW(\n                                            unicode(target_os_path), 128)\n            new_ref = self.get_children_ref(parent, new_name)\n            return self.get_info(new_ref)\n        finally:\n            self.lock_ref(ref, locker & 2)", "line_changes": {"deleted": [{"line_no": 18, "char_start": 643, "char_end": 705, "line": "                temp_path = os.tempnam(self._abspath(parent),\n"}, {"line_no": 19, "char_start": 705, "char_end": 793, "line": "                                       LocalClient.CASE_RENAME_PREFIX + old_name + '_')\n"}], "added": [{"line_no": 18, "char_start": 643, "char_end": 716, "line": "                prefix = LocalClient.CASE_RENAME_PREFIX + old_name + '_'\n"}, {"line_no": 19, "char_start": 716, "char_end": 791, "line": "                _, temp_path = tempfile.mkstemp(dir=self._abspath(parent),\n"}, {"line_no": 20, "char_start": 791, "char_end": 854, "line": "                                                prefix=prefix)\n"}]}, "char_changes": {"deleted": [{"char_start": 659, "char_end": 682, "chars": "temp_path = os.tempnam("}, {"char_start": 744, "char_end": 791, "chars": "LocalClient.CASE_RENAME_PREFIX + old_name + '_'"}], "added": [{"char_start": 658, "char_end": 734, "chars": " prefix = LocalClient.CASE_RENAME_PREFIX + old_name + '_'\n                _,"}, {"char_start": 751, "char_end": 768, "chars": "file.mkstemp(dir="}, {"char_start": 830, "char_end": 852, "chars": "         prefix=prefix"}]}, "commit_link": "github.com/arameshkumar/nuxeo-drive/commit/c131124daf80274ace04e8d68f90cef802ac66fa", "file_name": "local_client.py", "vul_type": "cwe-377", "commit_msg": "NXDRIVE-702: remove use of deprecated and insecure os.tempnam()", "description": "Write a Python function to rename a file or directory, handling case sensitivity on different file systems."}
{"func_name": "test_verilator_run", "func_src_before": "def test_verilator_run():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n    ref_dir_cc = os.path.join(ref_dir, 'cc')\n\n    work_root    = tempfile.mkdtemp()\n    edam_file = os.path.join(ref_dir_cc, core_name)+ '.eda.yml'\n    backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n    dummy_exe = 'V'+backend.tool_options['top_module']\n    shutil.copy(os.path.join(ref_dir, dummy_exe),\n                os.path.join(work_root, dummy_exe))\n\n    backend.run(params)\n\n    compare_files(ref_dir, work_root, ['run.cmd'])", "func_src_after": "def test_verilator_run():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n    ref_dir_cc = os.path.join(ref_dir, 'cc')\n\n    work_root    = tempfile.mkdtemp()\n    edam_file = os.path.join(ref_dir_cc, core_name)+ '.eda.yml'\n    backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n    dummy_exe = 'V'+backend.tool_options['top_module']\n    shutil.copy(os.path.join(ref_dir, dummy_exe),\n                os.path.join(work_root, dummy_exe))\n\n    backend.run(params)\n\n    compare_files(ref_dir, work_root, ['run.cmd'])", "line_changes": {"deleted": [{"line_no": 10, "char_start": 265, "char_end": 351, "line": "    backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n"}], "added": [{"line_no": 10, "char_start": 265, "char_end": 356, "line": "    backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 307, "char_end": 312, "chars": "safe_"}]}, "commit_link": "github.com/SymbiFlow/edalize/commit/0a07c959386a5c8ffd88e5f985979e1a26646076", "file_name": "test_verilator.py", "vul_type": "cwe-502", "commit_msg": "Use safe YAML loader\n\nyaml.load() is unsafe and issues a warning. Switching to the safe loader\nexplicitly.", "parent_commit": "3faaeaefaf313aebd40f8f3782f07a61cdc5aaaa", "description": "Write a Python function that sets up and runs a hardware simulation tool using configuration from a YAML file."}
{"func_name": "(anonymous)", "func_src_before": "        function ($sce) {\n            return function (params) {\n\n                var dialog = angular.element(document.getElementById('prompt-modal')),\n                    scope = dialog.scope(), cls, local_backdrop;\n                \n                scope.promptHeader = params.hdr;\n                scope.promptBody = $sce.trustAsHtml(params.body);\n                scope.promptAction = params.action;\n\n                local_backdrop = (params.backdrop === undefined) ? \"static\" : params.backdrop;\n\n                cls = (params['class'] === null || params['class'] === undefined) ? 'btn-danger' : params['class'];\n\n                $('#prompt_action_btn').removeClass(cls).addClass(cls);\n\n                // bootstrap modal's have an open defect with disallowing tab index's of the background of the modal\n                // This will keep the tab indexing on the modal's focus. This is to fix an issue with tabbing working when\n                // the user is attempting to delete something. Might need to be checked for other occurances of the bootstrap\n                // modal other than deleting\n                function disableTabModalShown() {\n\n                    $('.modal').on('shown.bs.modal', function() {\n\n                        var modal = $(this),\n                        focusableChildren = modal.find('a[href], a[data-dismiss], area[href], input, select, textarea, button, iframe, object, embed, *[tabindex], *[contenteditable]'),\n                        numElements = focusableChildren.length,\n                        currentIndex = 0,\n                        focus,\n                        focusPrevious,\n                        focusNext;\n\n                        $(document.activeElement).blur();\n\n                        focus = function() {\n                            var focusableElement = focusableChildren[currentIndex];\n                            if (focusableElement) {\n                                focusableElement.focus();\n                            }\n                        };\n\n                        focusPrevious = function () {\n                            currentIndex--;\n                            if (currentIndex < 0) {\n                                currentIndex = numElements - 1;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        focusNext = function () {\n                            currentIndex++;\n                            if (currentIndex >= numElements) {\n                                currentIndex = 0;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        $(document).on('keydown', function (e) {\n\n                            if (e.keyCode === 9 && e.shiftKey) {\n                                e.preventDefault();\n                                focusPrevious();\n                            }\n                            else if (e.keyCode === 9) {\n                                e.preventDefault();\n                                focusNext();\n                            }\n                        });\n\n                        $(this).focus();\n                    });\n\n                    $('.modal').on('hidden.bs.modal', function() {\n                        $(document).unbind('keydown');\n                    });\n                }\n\n\n                $('#prompt-modal').off('hidden.bs.modal');\n                $('#prompt-modal').modal({\n                    backdrop: 'local_backdrop',\n                    keyboard: true,\n                    show: true\n                });\n                disableTabModalShown();\n\n            };\n        }", "func_src_after": "        function ($sce, $filter) {\n            return function (params) {\n\n                var dialog = angular.element(document.getElementById('prompt-modal')),\n                    scope = dialog.scope(), cls, local_backdrop;\n\n                scope.promptHeader = params.hdr;\n                scope.promptBody = $filter('sanitize')(params.body);\n                scope.promptAction = params.action;\n\n                local_backdrop = (params.backdrop === undefined) ? \"static\" : params.backdrop;\n\n                cls = (params['class'] === null || params['class'] === undefined) ? 'btn-danger' : params['class'];\n\n                $('#prompt_action_btn').removeClass(cls).addClass(cls);\n\n                // bootstrap modal's have an open defect with disallowing tab index's of the background of the modal\n                // This will keep the tab indexing on the modal's focus. This is to fix an issue with tabbing working when\n                // the user is attempting to delete something. Might need to be checked for other occurances of the bootstrap\n                // modal other than deleting\n                function disableTabModalShown() {\n\n                    $('.modal').on('shown.bs.modal', function() {\n\n                        var modal = $(this),\n                        focusableChildren = modal.find('a[href], a[data-dismiss], area[href], input, select, textarea, button, iframe, object, embed, *[tabindex], *[contenteditable]'),\n                        numElements = focusableChildren.length,\n                        currentIndex = 0,\n                        focus,\n                        focusPrevious,\n                        focusNext;\n\n                        $(document.activeElement).blur();\n\n                        focus = function() {\n                            var focusableElement = focusableChildren[currentIndex];\n                            if (focusableElement) {\n                                focusableElement.focus();\n                            }\n                        };\n\n                        focusPrevious = function () {\n                            currentIndex--;\n                            if (currentIndex < 0) {\n                                currentIndex = numElements - 1;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        focusNext = function () {\n                            currentIndex++;\n                            if (currentIndex >= numElements) {\n                                currentIndex = 0;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        $(document).on('keydown', function (e) {\n\n                            if (e.keyCode === 9 && e.shiftKey) {\n                                e.preventDefault();\n                                focusPrevious();\n                            }\n                            else if (e.keyCode === 9) {\n                                e.preventDefault();\n                                focusNext();\n                            }\n                        });\n\n                        $(this).focus();\n                    });\n\n                    $('.modal').on('hidden.bs.modal', function() {\n                        $(document).unbind('keydown');\n                    });\n                }\n\n\n                $('#prompt-modal').off('hidden.bs.modal');\n                $('#prompt-modal').modal({\n                    backdrop: 'local_backdrop',\n                    keyboard: true,\n                    show: true\n                });\n                disableTabModalShown();\n\n            };\n        }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 218, "char_end": 235, "line": "                \n"}, {"line_no": 8, "char_start": 284, "char_end": 350, "line": "                scope.promptBody = $sce.trustAsHtml(params.body);\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 35, "line": "        function ($sce, $filter) {\n"}, {"line_no": 6, "char_start": 227, "char_end": 228, "line": "\n"}, {"line_no": 8, "char_start": 277, "char_end": 346, "line": "                scope.promptBody = $filter('sanitize')(params.body);\n"}]}, "char_changes": {"deleted": [{"char_start": 218, "char_end": 234, "chars": "                "}, {"char_start": 320, "char_end": 335, "chars": "sce.trustAsHtml"}], "added": [{"char_start": 22, "char_end": 31, "chars": ", $filter"}, {"char_start": 313, "char_end": 331, "chars": "filter('sanitize')"}]}, "commit_link": "github.com/wwitzel3/awx/commit/b127e7f2765c6173c5cf27d34491e7ca0a4ac101", "file_name": "prompt-dialog.js", "vul_type": "cwe-079", "commit_msg": "fixing xss bugs", "description": "Create a JavaScript function in AngularJS that configures and displays a modal dialog with custom content and button class."}
{"func_name": "error", "func_src_before": "                error: function() {\n                    // Fail message\n                    $('#success').html(\"<div class='alert alert-danger'>\");\n                    $('#success > .alert-danger').html(\"<button type='button' class='close' data-dismiss='alert' aria-hidden='true'>&times;\")\n                        .append(\"</button>\");\n                    $('#success > .alert-danger').append(\"<strong>Sorry \" + firstName + \", it seems that my mail server is not responding. Please try again later!\");\n                    $('#success > .alert-danger').append('</div>');\n                    //clear all fields\n                    $('#contactForm').trigger(\"reset\");\n                },", "func_src_after": "                error: function() {\n                    // Fail message\n                    $('#success').html(\"<div class='alert alert-danger'>\");\n                    $('#success > .alert-danger').html(\"<button type='button' class='close' data-dismiss='alert' aria-hidden='true'>&times;\")\n                        .append(\"</button>\");\n                    $('#success > .alert-danger').append($(\"<strong>\").text(\"Sorry \" + firstName + \", it seems that my mail server is not responding. Please try again later!\"));\n                    $('#success > .alert-danger').append('</div>');\n                    //clear all fields\n                    $('#contactForm').trigger(\"reset\");\n                },", "line_changes": {"deleted": [{"line_no": 6, "char_start": 336, "char_end": 502, "line": "                    $('#success > .alert-danger').append(\"<strong>Sorry \" + firstName + \", it seems that my mail server is not responding. Please try again later!\");\n"}], "added": [{"line_no": 6, "char_start": 336, "char_end": 514, "line": "                    $('#success > .alert-danger').append($(\"<strong>\").text(\"Sorry \" + firstName + \", it seems that my mail server is not responding. Please try again later!\"));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 393, "char_end": 395, "chars": "$("}, {"char_start": 404, "char_end": 413, "chars": "\").text(\""}, {"char_start": 511, "char_end": 512, "chars": ")"}]}, "commit_link": "github.com/EmmavanKampen/What-sgood/commit/0d233641de67563a42ad58925dd6da7483062637", "file_name": "contact_me.js", "vul_type": "cwe-079", "commit_msg": "Fix xss issue", "description": "Write a JavaScript function to display an error message and reset a form when an AJAX request fails."}
{"func_name": "oidc_handle_session_management_iframe_rp", "func_src_before": "static int oidc_handle_session_management_iframe_rp(request_rec *r, oidc_cfg *c,\n\t\toidc_session_t *session, const char *client_id,\n\t\tconst char *check_session_iframe) {\n\n\toidc_debug(r, \"enter\");\n\n\tconst char *java_script =\n\t\t\t\"    <script type=\\\"text/javascript\\\">\\n\"\n\t\t\t\"      var targetOrigin  = '%s';\\n\"\n\t\t\t\"      var message = '%s' + ' ' + '%s';\\n\"\n\t\t\t\"\t   var timerID;\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function checkSession() {\\n\"\n\t\t\t\"        console.debug('checkSession: posting ' + message + ' to ' + targetOrigin);\\n\"\n\t\t\t\"        var win = window.parent.document.getElementById('%s').contentWindow;\\n\"\n\t\t\t\"        win.postMessage( message, targetOrigin);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function setTimer() {\\n\"\n\t\t\t\"        checkSession();\\n\"\n\t\t\t\"        timerID = setInterval('checkSession()', %s);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function receiveMessage(e) {\\n\"\n\t\t\t\"        console.debug('receiveMessage: ' + e.data + ' from ' + e.origin);\\n\"\n\t\t\t\"        if (e.origin !== targetOrigin ) {\\n\"\n\t\t\t\"          console.debug('receiveMessage: cross-site scripting attack?');\\n\"\n\t\t\t\"          return;\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"        if (e.data != 'unchanged') {\\n\"\n\t\t\t\"          clearInterval(timerID);\\n\"\n\t\t\t\"          if (e.data == 'changed') {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=check';\\n\"\n\t\t\t\"          } else {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=logout';\\n\"\n\t\t\t\"          }\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      window.addEventListener('message', receiveMessage, false);\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"    </script>\\n\";\n\n\t/* determine the origin for the check_session_iframe endpoint */\n\tchar *origin = apr_pstrdup(r->pool, check_session_iframe);\n\tapr_uri_t uri;\n\tapr_uri_parse(r->pool, check_session_iframe, &uri);\n\tchar *p = strstr(origin, uri.path);\n\t*p = '\\0';\n\n\t/* the element identifier for the OP iframe */\n\tconst char *op_iframe_id = \"openidc-op\";\n\n\t/* restore the OP session_state from the session */\n\tconst char *session_state = oidc_session_get_session_state(r, session);\n\tif (session_state == NULL) {\n\t\toidc_warn(r,\n\t\t\t\t\"no session_state found in the session; the OP does probably not support session management!?\");\n\t\treturn DONE;\n\t}\n\n\tchar *s_poll_interval = NULL;\n\toidc_util_get_request_parameter(r, \"poll\", &s_poll_interval);\n\tif (s_poll_interval == NULL)\n\t\ts_poll_interval = \"3000\";\n\n\tconst char *redirect_uri = oidc_get_redirect_uri(r, c);\n\tjava_script = apr_psprintf(r->pool, java_script, origin, client_id,\n\t\t\tsession_state, op_iframe_id, s_poll_interval, redirect_uri,\n\t\t\tredirect_uri);\n\n\treturn oidc_util_html_send(r, NULL, java_script, \"setTimer\", NULL, DONE);\n}", "func_src_after": "static int oidc_handle_session_management_iframe_rp(request_rec *r, oidc_cfg *c,\n\t\toidc_session_t *session, const char *client_id,\n\t\tconst char *check_session_iframe) {\n\n\toidc_debug(r, \"enter\");\n\n\tconst char *java_script =\n\t\t\t\"    <script type=\\\"text/javascript\\\">\\n\"\n\t\t\t\"      var targetOrigin  = '%s';\\n\"\n\t\t\t\"      var message = '%s' + ' ' + '%s';\\n\"\n\t\t\t\"\t   var timerID;\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function checkSession() {\\n\"\n\t\t\t\"        console.debug('checkSession: posting ' + message + ' to ' + targetOrigin);\\n\"\n\t\t\t\"        var win = window.parent.document.getElementById('%s').contentWindow;\\n\"\n\t\t\t\"        win.postMessage( message, targetOrigin);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function setTimer() {\\n\"\n\t\t\t\"        checkSession();\\n\"\n\t\t\t\"        timerID = setInterval('checkSession()', %d);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function receiveMessage(e) {\\n\"\n\t\t\t\"        console.debug('receiveMessage: ' + e.data + ' from ' + e.origin);\\n\"\n\t\t\t\"        if (e.origin !== targetOrigin ) {\\n\"\n\t\t\t\"          console.debug('receiveMessage: cross-site scripting attack?');\\n\"\n\t\t\t\"          return;\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"        if (e.data != 'unchanged') {\\n\"\n\t\t\t\"          clearInterval(timerID);\\n\"\n\t\t\t\"          if (e.data == 'changed') {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=check';\\n\"\n\t\t\t\"          } else {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=logout';\\n\"\n\t\t\t\"          }\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      window.addEventListener('message', receiveMessage, false);\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"    </script>\\n\";\n\n\t/* determine the origin for the check_session_iframe endpoint */\n\tchar *origin = apr_pstrdup(r->pool, check_session_iframe);\n\tapr_uri_t uri;\n\tapr_uri_parse(r->pool, check_session_iframe, &uri);\n\tchar *p = strstr(origin, uri.path);\n\t*p = '\\0';\n\n\t/* the element identifier for the OP iframe */\n\tconst char *op_iframe_id = \"openidc-op\";\n\n\t/* restore the OP session_state from the session */\n\tconst char *session_state = oidc_session_get_session_state(r, session);\n\tif (session_state == NULL) {\n\t\toidc_warn(r,\n\t\t\t\t\"no session_state found in the session; the OP does probably not support session management!?\");\n\t\treturn DONE;\n\t}\n\n\tchar *s_poll_interval = NULL;\n\toidc_util_get_request_parameter(r, \"poll\", &s_poll_interval);\n\tint poll_interval = s_poll_interval ? strtol(s_poll_interval, NULL, 10) : 0;\n\tif ((poll_interval <= 0) || (poll_interval > 3600 * 24))\n\t\tpoll_interval = 3000;\n\n\tconst char *redirect_uri = oidc_get_redirect_uri(r, c);\n\tjava_script = apr_psprintf(r->pool, java_script, origin, client_id,\n\t\t\tsession_state, op_iframe_id, poll_interval, redirect_uri,\n\t\t\tredirect_uri);\n\n\treturn oidc_util_html_send(r, NULL, java_script, \"setTimer\", NULL, DONE);\n}", "commit_link": "github.com/zmartzone/mod_auth_openidc/commit/132a4111bf3791e76437619a66336dce2ce4c79b", "file_name": "src/mod_auth_openidc.c", "vul_type": "cwe-079", "description": "In C, write a function to handle session management using an iframe for OpenID Connect, including JavaScript for client-side checks and redirection based on session state changes."}
{"func_name": "ares_parse_a_reply", "func_src_before": "int ares_parse_a_reply(const unsigned char *abuf, int alen,\n\t\t       struct hostent **host)\n{\n  unsigned int qdcount, ancount;\n  int status, i, rr_type, rr_class, rr_len, naddrs;\n  long int len;\n  int naliases;\n  const unsigned char *aptr;\n  char *hostname, *rr_name, *rr_data, **aliases;\n  struct in_addr *addrs;\n  struct hostent *hostent;\n\n  /* Set *host to NULL for all failure cases. */\n  *host = NULL;\n\n  /* Give up if abuf doesn't have room for a header. */\n  if (alen < HFIXEDSZ)\n    return ARES_EBADRESP;\n\n  /* Fetch the question and answer count from the header. */\n  qdcount = DNS_HEADER_QDCOUNT(abuf);\n  ancount = DNS_HEADER_ANCOUNT(abuf);\n  if (qdcount != 1)\n    return ARES_EBADRESP;\n\n  /* Expand the name from the question, and skip past the question. */\n  aptr = abuf + HFIXEDSZ;\n  status = ares_expand_name(aptr, abuf, alen, &hostname, &len);\n  if (status != ARES_SUCCESS)\n    return status;\n  if (aptr + len + QFIXEDSZ > abuf + alen)\n    {\n      free(hostname);\n      return ARES_EBADRESP;\n    }\n  aptr += len + QFIXEDSZ;\n\n  /* Allocate addresses and aliases; ancount gives an upper bound for both. */\n  addrs = malloc(ancount * sizeof(struct in_addr));\n  if (!addrs)\n    {\n      free(hostname);\n      return ARES_ENOMEM;\n    }\n  aliases = malloc((ancount + 1) * sizeof(char *));\n  if (!aliases)\n    {\n      free(hostname);\n      free(addrs);\n      return ARES_ENOMEM;\n    }\n  naddrs = 0;\n  naliases = 0;\n\n  /* Examine each answer resource record (RR) in turn. */\n  for (i = 0; i < (int)ancount; i++)\n    {\n      /* Decode the RR up to the data field. */\n      status = ares_expand_name(aptr, abuf, alen, &rr_name, &len);\n      if (status != ARES_SUCCESS)\n\tbreak;\n      aptr += len;\n      if (aptr + RRFIXEDSZ > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n      rr_type = DNS_RR_TYPE(aptr);\n      rr_class = DNS_RR_CLASS(aptr);\n      rr_len = DNS_RR_LEN(aptr);\n      aptr += RRFIXEDSZ;\n\n      if (rr_class == C_IN && rr_type == T_A\n\t  && rr_len == sizeof(struct in_addr)\n\t  && strcasecmp(rr_name, hostname) == 0)\n\t{\n\t  memcpy(&addrs[naddrs], aptr, sizeof(struct in_addr));\n\t  naddrs++;\n\t  status = ARES_SUCCESS;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_CNAME)\n\t{\n\t  /* Record the RR name as an alias. */\n\t  aliases[naliases] = rr_name;\n\t  naliases++;\n\n\t  /* Decode the RR data and replace the hostname with it. */\n\t  status = ares_expand_name(aptr, abuf, alen, &rr_data, &len);\n\t  if (status != ARES_SUCCESS)\n\t    break;\n\t  free(hostname);\n\t  hostname = rr_data;\n\t}\n      else\n\tfree(rr_name);\n\n      aptr += rr_len;\n      if (aptr > abuf + alen)\n\t{\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n    }\n\n  if (status == ARES_SUCCESS && naddrs == 0)\n    status = ARES_ENODATA;\n  if (status == ARES_SUCCESS)\n    {\n      /* We got our answer.  Allocate memory to build the host entry. */\n      aliases[naliases] = NULL;\n      hostent = malloc(sizeof(struct hostent));\n      if (hostent)\n\t{\n\t  hostent->h_addr_list = malloc((naddrs + 1) * sizeof(char *));\n\t  if (hostent->h_addr_list)\n\t    {\n\t      /* Fill in the hostent and return successfully. */\n\t      hostent->h_name = hostname;\n\t      hostent->h_aliases = aliases;\n\t      hostent->h_addrtype = AF_INET;\n\t      hostent->h_length = sizeof(struct in_addr);\n\t      for (i = 0; i < naddrs; i++)\n\t\thostent->h_addr_list[i] = (char *) &addrs[i];\n\t      hostent->h_addr_list[naddrs] = NULL;\n\t      *host = hostent;\n\t      return ARES_SUCCESS;\n\t    }\n\t  free(hostent);\n\t}\n      status = ARES_ENOMEM;\n    }\n  for (i = 0; i < naliases; i++)\n    free(aliases[i]);\n  free(aliases);\n  free(addrs);\n  free(hostname);\n  return status;\n}", "func_src_after": "int ares_parse_a_reply(const unsigned char *abuf, int alen,\n\t\t       struct hostent **host)\n{\n  unsigned int qdcount, ancount;\n  int status, i, rr_type, rr_class, rr_len, naddrs;\n  long int len;\n  int naliases;\n  const unsigned char *aptr;\n  char *hostname, *rr_name, *rr_data, **aliases;\n  struct in_addr *addrs;\n  struct hostent *hostent;\n\n  /* Set *host to NULL for all failure cases. */\n  *host = NULL;\n\n  /* Give up if abuf doesn't have room for a header. */\n  if (alen < HFIXEDSZ)\n    return ARES_EBADRESP;\n\n  /* Fetch the question and answer count from the header. */\n  qdcount = DNS_HEADER_QDCOUNT(abuf);\n  ancount = DNS_HEADER_ANCOUNT(abuf);\n  if (qdcount != 1)\n    return ARES_EBADRESP;\n\n  /* Expand the name from the question, and skip past the question. */\n  aptr = abuf + HFIXEDSZ;\n  status = ares_expand_name(aptr, abuf, alen, &hostname, &len);\n  if (status != ARES_SUCCESS)\n    return status;\n  if (aptr + len + QFIXEDSZ > abuf + alen)\n    {\n      free(hostname);\n      return ARES_EBADRESP;\n    }\n  aptr += len + QFIXEDSZ;\n\n  /* Allocate addresses and aliases; ancount gives an upper bound for both. */\n  addrs = malloc(ancount * sizeof(struct in_addr));\n  if (!addrs)\n    {\n      free(hostname);\n      return ARES_ENOMEM;\n    }\n  aliases = malloc((ancount + 1) * sizeof(char *));\n  if (!aliases)\n    {\n      free(hostname);\n      free(addrs);\n      return ARES_ENOMEM;\n    }\n  naddrs = 0;\n  naliases = 0;\n\n  /* Examine each answer resource record (RR) in turn. */\n  for (i = 0; i < (int)ancount; i++)\n    {\n      /* Decode the RR up to the data field. */\n      status = ares_expand_name(aptr, abuf, alen, &rr_name, &len);\n      if (status != ARES_SUCCESS)\n\tbreak;\n      aptr += len;\n      if (aptr + RRFIXEDSZ > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n      rr_type = DNS_RR_TYPE(aptr);\n      rr_class = DNS_RR_CLASS(aptr);\n      rr_len = DNS_RR_LEN(aptr);\n      aptr += RRFIXEDSZ;\n      if (aptr + rr_len > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_A\n\t  && rr_len == sizeof(struct in_addr)\n\t  && strcasecmp(rr_name, hostname) == 0)\n\t{\n\t  memcpy(&addrs[naddrs], aptr, sizeof(struct in_addr));\n\t  naddrs++;\n\t  status = ARES_SUCCESS;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_CNAME)\n\t{\n\t  /* Record the RR name as an alias. */\n\t  aliases[naliases] = rr_name;\n\t  naliases++;\n\n\t  /* Decode the RR data and replace the hostname with it. */\n\t  status = ares_expand_name(aptr, abuf, alen, &rr_data, &len);\n\t  if (status != ARES_SUCCESS)\n\t    break;\n\t  free(hostname);\n\t  hostname = rr_data;\n\t}\n      else\n\tfree(rr_name);\n\n      aptr += rr_len;\n      if (aptr > abuf + alen)\n\t{\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n    }\n\n  if (status == ARES_SUCCESS && naddrs == 0)\n    status = ARES_ENODATA;\n  if (status == ARES_SUCCESS)\n    {\n      /* We got our answer.  Allocate memory to build the host entry. */\n      aliases[naliases] = NULL;\n      hostent = malloc(sizeof(struct hostent));\n      if (hostent)\n\t{\n\t  hostent->h_addr_list = malloc((naddrs + 1) * sizeof(char *));\n\t  if (hostent->h_addr_list)\n\t    {\n\t      /* Fill in the hostent and return successfully. */\n\t      hostent->h_name = hostname;\n\t      hostent->h_aliases = aliases;\n\t      hostent->h_addrtype = AF_INET;\n\t      hostent->h_length = sizeof(struct in_addr);\n\t      for (i = 0; i < naddrs; i++)\n\t\thostent->h_addr_list[i] = (char *) &addrs[i];\n\t      hostent->h_addr_list[naddrs] = NULL;\n\t      *host = hostent;\n\t      return ARES_SUCCESS;\n\t    }\n\t  free(hostent);\n\t}\n      status = ARES_ENOMEM;\n    }\n  for (i = 0; i < naliases; i++)\n    free(aliases[i]);\n  free(aliases);\n  free(addrs);\n  free(hostname);\n  return status;\n}", "commit_link": "github.com/resiprocate/resiprocate/commit/d67a9ca6fd06ca65d23e313bdbad1ef4dd3aa0df", "file_name": "rutil/dns/ares/ares_parse_a_reply.c", "vul_type": "cwe-125", "description": "In C, write a function to parse a DNS response and populate a hostent structure with the results."}
{"func_name": "clean_taxon_concept", "func_src_before": "  def clean_taxon_concept\n    taxon_concept.gsub(\"\\n\",\" \").gsub(\"\\'\", \"\\\\\\'\")\n  end", "func_src_after": "  def clean_taxon_concept\n    taxon_concept.gsub(\"\\n\", ' ').gsub(\"\\'\", \"\\\\\\'\")\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 78, "line": "    taxon_concept.gsub(\"\\n\",\" \").gsub(\"\\'\", \"\\\\\\'\")\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 79, "line": "    taxon_concept.gsub(\"\\n\", ' ').gsub(\"\\'\", \"\\\\\\'\")\n"}]}, "char_changes": {"deleted": [{"char_start": 54, "char_end": 57, "chars": "\" \""}], "added": [{"char_start": 54, "char_end": 58, "chars": " ' '"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Write a Ruby function named `clean_taxon_concept` that replaces newline characters with spaces and escapes single quotes in a string."}
{"func_name": "(anonymous)", "func_src_before": "      this.idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            self.$noresults.html('<p>No results matching your query:<code>' + originalQuery + '<code><p>');\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "func_src_after": "      this.idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            self.$noresults.html('<p>No results matching your query:<code>' + $('<div />').text(originalQuery).html() + '<code><p>');\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "line_changes": {"deleted": [{"line_no": 8, "char_start": 247, "char_end": 355, "line": "            self.$noresults.html('<p>No results matching your query:<code>' + originalQuery + '<code><p>');\n"}], "added": [{"line_no": 8, "char_start": 247, "char_end": 381, "line": "            self.$noresults.html('<p>No results matching your query:<code>' + $('<div />').text(originalQuery).html() + '<code><p>');\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 325, "char_end": 343, "chars": "$('<div />').text("}, {"char_start": 356, "char_end": 364, "chars": ").html()"}]}, "commit_link": "github.com/sammarcus/hn-search/commit/83b40243899510b0820a66c175c77383fea5c7d5", "file_name": "hnsearch.beta.js", "vul_type": "cwe-079", "commit_msg": "Fixed XSS :)", "description": "Write a JavaScript function that performs a search with a given query, logs errors to the console, and updates the UI to show whether there are results or not."}
{"func_name": "(anonymous)", "func_src_before": "    connection.query('SELECT soc FROM occupation ORDER BY RAND() LIMIT 1;', function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0].soc);\n        }\n        else {\n            errNext(err);\n        }\n    });", "func_src_after": "    connection.query('SELECT soc FROM Occupation ORDER BY RAND() LIMIT 1;', function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0].soc);\n        }\n        else {\n            errNext(err);\n        }\n    });", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 106, "line": "    connection.query('SELECT soc FROM occupation ORDER BY RAND() LIMIT 1;', function(err, rows, fields) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 106, "line": "    connection.query('SELECT soc FROM Occupation ORDER BY RAND() LIMIT 1;', function(err, rows, fields) {\n"}]}, "char_changes": {"deleted": [{"char_start": 38, "char_end": 39, "chars": "o"}], "added": [{"char_start": 38, "char_end": 39, "chars": "O"}]}, "commit_link": "github.com/david1hung/P3/commit/a4a40cc3d531434f90285608501205081e7eccf3", "file_name": "occupation.js", "vul_type": "cwe-089", "commit_msg": "Fixed random career not working. Cleaned up a few potential SQL injection vulnerabilities.", "description": "Write a JavaScript function that randomly selects a single 'soc' value from an 'occupation' table in a database and handles the result or error."}
{"func_name": "fpm_log_write", "func_src_before": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/php/php-src/commit/2721a0148649e07ed74468f097a28899741eb58f", "file_name": "sapi/fpm/fpm/fpm_log.c", "vul_type": "cwe-125", "description": "Write a C function named `fpm_log_write` that processes a log format string and writes the formatted log entry to a file."}
{"func_name": "move", "func_src_before": "def move(path, dest, replace=False):\n    \"\"\"Rename a file. `dest` may not be a directory. If `dest` already\n    exists, raises an OSError unless `replace` is True. Has no effect if\n    `path` is the same as `dest`. If the paths are on different\n    filesystems (or the rename otherwise fails), a copy is attempted\n    instead, in which case metadata will *not* be preserved. Paths are\n    translated to system paths.\n    \"\"\"\n    if os.path.isdir(path):\n        raise FilesystemError(u'source is directory', 'move', (path, dest))\n    if os.path.isdir(dest):\n        raise FilesystemError(u'destination is directory', 'move',\n                              (path, dest))\n    if samefile(path, dest):\n        return\n    path = syspath(path)\n    dest = syspath(dest)\n    if os.path.exists(dest) and not replace:\n        raise FilesystemError('file exists', 'rename', (path, dest))\n\n    # First, try renaming the file.\n    try:\n        os.replace(path, dest)\n    except OSError:\n        tmp = tempfile.mktemp(suffix='.beets',\n                              prefix=py3_path(b'.' + os.path.basename(dest)),\n                              dir=py3_path(os.path.dirname(dest)))\n        tmp = syspath(tmp)\n        try:\n            shutil.copyfile(path, tmp)\n            os.replace(tmp, dest)\n            tmp = None\n            os.remove(path)\n        except OSError as exc:\n            raise FilesystemError(exc, 'move', (path, dest),\n                                  traceback.format_exc())\n        finally:\n            if tmp is not None:\n                os.remove(tmp)", "func_src_after": "def move(path, dest, replace=False):\n    \"\"\"Rename a file. `dest` may not be a directory. If `dest` already\n    exists, raises an OSError unless `replace` is True. Has no effect if\n    `path` is the same as `dest`. If the paths are on different\n    filesystems (or the rename otherwise fails), a copy is attempted\n    instead, in which case metadata will *not* be preserved. Paths are\n    translated to system paths.\n    \"\"\"\n    if os.path.isdir(path):\n        raise FilesystemError(u'source is directory', 'move', (path, dest))\n    if os.path.isdir(dest):\n        raise FilesystemError(u'destination is directory', 'move',\n                              (path, dest))\n    if samefile(path, dest):\n        return\n    path = syspath(path)\n    dest = syspath(dest)\n    if os.path.exists(dest) and not replace:\n        raise FilesystemError('file exists', 'rename', (path, dest))\n\n    # First, try renaming the file.\n    try:\n        os.replace(path, dest)\n    except OSError:\n        # Copy the file to a temporary destination.\n        tmp = tempfile.NamedTemporaryFile(suffix=b'.beets',\n                                          prefix=b'.' + os.path.basename(dest),\n                                          dir=os.path.dirname(dest),\n                                          delete=False)\n        try:\n            with open(path, 'rb') as f:\n                shutil.copyfileobj(f, tmp)\n        finally:\n            tmp.close()\n\n        # Move the copied file into place.\n        try:\n            os.replace(tmp.name, dest)\n            tmp = None\n            os.remove(path)\n        except OSError as exc:\n            raise FilesystemError(exc, 'move', (path, dest),\n                                  traceback.format_exc())\n        finally:\n            if tmp is not None:\n                os.remove(tmp)", "line_changes": {"deleted": [{"line_no": 25, "char_start": 973, "char_end": 1020, "line": "        tmp = tempfile.mktemp(suffix='.beets',\n"}, {"line_no": 26, "char_start": 1020, "char_end": 1098, "line": "                              prefix=py3_path(b'.' + os.path.basename(dest)),\n"}, {"line_no": 27, "char_start": 1098, "char_end": 1165, "line": "                              dir=py3_path(os.path.dirname(dest)))\n"}, {"line_no": 28, "char_start": 1165, "char_end": 1192, "line": "        tmp = syspath(tmp)\n"}, {"line_no": 30, "char_start": 1205, "char_end": 1244, "line": "            shutil.copyfile(path, tmp)\n"}, {"line_no": 31, "char_start": 1244, "char_end": 1278, "line": "            os.replace(tmp, dest)\n"}], "added": [{"line_no": 26, "char_start": 1025, "char_end": 1085, "line": "        tmp = tempfile.NamedTemporaryFile(suffix=b'.beets',\n"}, {"line_no": 27, "char_start": 1085, "char_end": 1165, "line": "                                          prefix=b'.' + os.path.basename(dest),\n"}, {"line_no": 28, "char_start": 1165, "char_end": 1234, "line": "                                          dir=os.path.dirname(dest),\n"}, {"line_no": 29, "char_start": 1234, "char_end": 1290, "line": "                                          delete=False)\n"}, {"line_no": 31, "char_start": 1303, "char_end": 1343, "line": "            with open(path, 'rb') as f:\n"}, {"line_no": 32, "char_start": 1343, "char_end": 1386, "line": "                shutil.copyfileobj(f, tmp)\n"}, {"line_no": 33, "char_start": 1386, "char_end": 1403, "line": "        finally:\n"}, {"line_no": 34, "char_start": 1403, "char_end": 1427, "line": "            tmp.close()\n"}, {"line_no": 35, "char_start": 1427, "char_end": 1428, "line": "\n"}, {"line_no": 37, "char_start": 1471, "char_end": 1484, "line": "        try:\n"}, {"line_no": 38, "char_start": 1484, "char_end": 1523, "line": "            os.replace(tmp.name, dest)\n"}]}, "char_changes": {"deleted": [{"char_start": 981, "char_end": 1002, "chars": "tmp = tempfile.mktemp"}, {"char_start": 1050, "char_end": 1066, "chars": "prefix=py3_path("}, {"char_start": 1095, "char_end": 1096, "chars": ")"}, {"char_start": 1132, "char_end": 1141, "chars": "py3_path("}, {"char_start": 1162, "char_end": 1164, "chars": "))"}, {"char_start": 1173, "char_end": 1243, "chars": "tmp = syspath(tmp)\n        try:\n            shutil.copyfile(path, tmp)"}], "added": [{"char_start": 981, "char_end": 1066, "chars": "# Copy the file to a temporary destination.\n        tmp = tempfile.NamedTemporaryFile"}, {"char_start": 1074, "char_end": 1075, "chars": "b"}, {"char_start": 1115, "char_end": 1134, "chars": "            prefix="}, {"char_start": 1165, "char_end": 1177, "chars": "            "}, {"char_start": 1232, "char_end": 1233, "chars": ","}, {"char_start": 1242, "char_end": 1483, "chars": "                                  delete=False)\n        try:\n            with open(path, 'rb') as f:\n                shutil.copyfileobj(f, tmp)\n        finally:\n            tmp.close()\n\n        # Move the copied file into place.\n        try:"}, {"char_start": 1510, "char_end": 1515, "chars": ".name"}]}, "commit_link": "github.com/beetbox/beets/commit/4bb695bcdbada9c8153442688e8494199f015f04", "file_name": "__init__.py", "vul_type": "cwe-377", "commit_msg": "Fix copying for atomic file moves\n\nFixes #4168. Also closes #4192, which it supersedes.\n\nThe original problem is that this implementation used bytestrings\nincorrectly to invoke `mktemp`. However, `mktemp` is deprecated, so this\nPR just avoids it altogether. Fortunately, the non-deprecated APIs in\n`tempfile` support all-bytes arguments.", "description": "Write a Python function named `move` that renames a file, with an option to replace the destination file if it already exists."}
{"func_name": "run", "func_src_before": "func run() error {\n\tpriv, err := rsa.GenerateKey(rand.Reader, 1024)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tprivf, err := os.OpenFile(\"priv.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer privf.Close()\n\n\tprivblock := &pem.Block{\n\t\tType:  \"RSA PRIVATE KEY\",\n\t\tBytes: x509.MarshalPKCS1PrivateKey(priv),\n\t}\n\n\tif err := pem.Encode(privf, privblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpub, err := x509.MarshalPKIXPublicKey(priv.Public())\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpubf, err := os.OpenFile(\"pub.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\tdefer pubf.Close()\n\n\tpubblock := &pem.Block{\n\t\tType:  \"PUBLIC KEY\",\n\t\tBytes: pub,\n\t}\n\n\tif err := pem.Encode(pubf, pubblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\tos.Remove(pubf.Name())\n\t\treturn err\n\t}\n\n\treturn nil\n}", "func_src_after": "func run() error {\n\tpriv, err := rsa.GenerateMultiPrimeKey(rand.Reader, 3, 2048)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tprivf, err := os.OpenFile(\"priv.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer privf.Close()\n\n\tprivblock := &pem.Block{\n\t\tType:  \"RSA PRIVATE KEY\",\n\t\tBytes: x509.MarshalPKCS1PrivateKey(priv),\n\t}\n\n\tif err := pem.Encode(privf, privblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpub, err := x509.MarshalPKIXPublicKey(priv.Public())\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpubf, err := os.OpenFile(\"pub.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\tdefer pubf.Close()\n\n\tpubblock := &pem.Block{\n\t\tType:  \"PUBLIC KEY\",\n\t\tBytes: pub,\n\t}\n\n\tif err := pem.Encode(pubf, pubblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\tos.Remove(pubf.Name())\n\t\treturn err\n\t}\n\n\treturn nil\n}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 19, "char_end": 68, "line": "\tpriv, err := rsa.GenerateKey(rand.Reader, 1024)\n"}], "added": [{"line_no": 2, "char_start": 19, "char_end": 81, "line": "\tpriv, err := rsa.GenerateMultiPrimeKey(rand.Reader, 3, 2048)\n"}]}, "char_changes": {"deleted": [{"char_start": 62, "char_end": 66, "chars": "1024"}], "added": [{"char_start": 45, "char_end": 55, "chars": "MultiPrime"}, {"char_start": 72, "char_end": 79, "chars": "3, 2048"}]}, "commit_link": "github.com/carl-mastrangelo/pixur/commit/d2bc8ec79aa4f2b68ec14a2d6cd5a305b6e05dd1", "file_name": "genkeys.go", "vul_type": "cwe-326", "commit_msg": "Use multiprime rsa keys, and bump to 2048 bits", "parent_commit": "547289bc91415ef039e318ce6b0b53b16b66998b", "description": "Write a Go function to generate an RSA key pair and save them to files."}
{"func_name": "load_config", "func_src_before": "def load_config(config_file):\n    config_path = config_file if config_file else \".ansible-lint\"\n\n    if os.path.exists(config_path):\n        with open(config_path, \"r\") as stream:\n            try:\n                return yaml.load(stream)\n            except yaml.YAMLError:\n                pass\n\n    return None", "func_src_after": "def load_config(config_file):\n    config_path = config_file if config_file else \".ansible-lint\"\n\n    if os.path.exists(config_path):\n        with open(config_path, \"r\") as stream:\n            try:\n                return yaml.safe_load(stream)\n            except yaml.YAMLError:\n                pass\n\n    return None", "line_changes": {"deleted": [{"line_no": 7, "char_start": 197, "char_end": 238, "line": "                return yaml.load(stream)\n"}], "added": [{"line_no": 7, "char_start": 197, "char_end": 243, "line": "                return yaml.safe_load(stream)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 225, "char_end": 230, "chars": "safe_"}]}, "commit_link": "github.com/MatrixCrawler/ansible-lint/commit/c8685daee3f53ea0889ec697ff61c20996904381", "file_name": "__main__.py", "vul_type": "cwe-502", "commit_msg": "Use yaml.safe_load rather than yaml.load", "parent_commit": "f92cc06ab26ef24c1cdcdefaab65276c2424a90c", "description": "Write a Python function to load a YAML configuration from a file, with a default filename fallback."}
{"func_name": "take_bug_report", "func_src_before": "    def take_bug_report(self, test_name, begin_time):\n        \"\"\"Takes a bug report on the device and stores it in a file.\n\n        Args:\n            test_name: Name of the test case that triggered this bug report.\n            begin_time: Logline format timestamp taken when the test started.\n        \"\"\"\n        new_br = True\n        try:\n            stdout = self.adb.shell('bugreportz -v').decode('utf-8')\n            # This check is necessary for builds before N, where adb shell's ret\n            # code and stderr are not propagated properly.\n            if 'not found' in stdout:\n                new_br = False\n        except adb.AdbError:\n            new_br = False\n        br_path = os.path.join(self.log_path, 'BugReports')\n        utils.create_dir(br_path)\n        base_name = ',%s,%s.txt' % (begin_time, self.serial)\n        if new_br:\n            base_name = base_name.replace('.txt', '.zip')\n        test_name_len = utils.MAX_FILENAME_LEN - len(base_name)\n        out_name = test_name[:test_name_len] + base_name\n        full_out_path = os.path.join(br_path, out_name.replace(' ', r'\\ '))\n        # in case device restarted, wait for adb interface to return\n        self.wait_for_boot_completion()\n        self.log.info('Taking bugreport for %s.', test_name)\n        if new_br:\n            out = self.adb.shell('bugreportz').decode('utf-8')\n            if not out.startswith('OK'):\n                raise DeviceError(self, 'Failed to take bugreport: %s' % out)\n            br_out_path = out.split(':')[1].strip()\n            self.adb.pull('%s %s' % (br_out_path, full_out_path))\n        else:\n            self.adb.bugreport(' > %s' % full_out_path)\n        self.log.info('Bugreport for %s taken at %s.', test_name,\n                      full_out_path)", "func_src_after": "    def take_bug_report(self, test_name, begin_time):\n        \"\"\"Takes a bug report on the device and stores it in a file.\n\n        Args:\n            test_name: Name of the test case that triggered this bug report.\n            begin_time: Logline format timestamp taken when the test started.\n        \"\"\"\n        new_br = True\n        try:\n            stdout = self.adb.shell('bugreportz -v').decode('utf-8')\n            # This check is necessary for builds before N, where adb shell's ret\n            # code and stderr are not propagated properly.\n            if 'not found' in stdout:\n                new_br = False\n        except adb.AdbError:\n            new_br = False\n        br_path = os.path.join(self.log_path, 'BugReports')\n        utils.create_dir(br_path)\n        base_name = ',%s,%s.txt' % (begin_time, self.serial)\n        if new_br:\n            base_name = base_name.replace('.txt', '.zip')\n        test_name_len = utils.MAX_FILENAME_LEN - len(base_name)\n        out_name = test_name[:test_name_len] + base_name\n        full_out_path = os.path.join(br_path, out_name.replace(' ', r'\\ '))\n        # in case device restarted, wait for adb interface to return\n        self.wait_for_boot_completion()\n        self.log.info('Taking bugreport for %s.', test_name)\n        if new_br:\n            out = self.adb.shell('bugreportz').decode('utf-8')\n            if not out.startswith('OK'):\n                raise DeviceError(self, 'Failed to take bugreport: %s' % out)\n            br_out_path = out.split(':')[1].strip()\n            self.adb.pull([br_out_path, full_out_path])\n        else:\n            # shell=True as this command redirects the stdout to a local file\n            # using shell redirection.\n            self.adb.bugreport(' > %s' % full_out_path, shell=True)\n        self.log.info('Bugreport for %s taken at %s.', test_name,\n                      full_out_path)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device.py", "vul_type": "cwe-078", "description": "Write a Python function to capture a bug report from a device, save it to a file, and handle different versions of the bug reporting tool."}
{"func_name": "getSeriesDateFromDatabase", "func_src_before": "def getSeriesDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = '\" + str(getTitle(submission)) + \"'\").fetchone()[0]\n    database.close()", "func_src_after": "def getSeriesDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = ?\", [getTitle(submission)]).fetchone()[0]\n    database.close()", "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the start date of a series from an SQLite database using the series title."}
{"func_name": "ac_circ_buf_popm", "func_src_before": "int ac_circ_buf_popm(ac_circ_buf_t *cbuf, void *buf, u32 count)\n{\n\tif (circ_count_to_end(cbuf) < count)\n\t\treturn -1;\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(buf, cbuf->buf.ptr_buf + cbuf->tail,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(buf, cbuf->buf.cpy_buf + cbuf->tail,\n\t\t       count * cbuf->elem_sz);\n\n\tcbuf->tail = (cbuf->tail + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "func_src_after": "int ac_circ_buf_popm(ac_circ_buf_t *cbuf, void *buf, u32 count)\n{\n\tif (circ_count_to_end(cbuf) < count)\n\t\treturn -1;\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(buf, cbuf->buf.ptr_buf + cbuf->tail,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(buf, cbuf->buf.cpy_buf + cbuf->tail,\n\t\t       (size_t)count * cbuf->elem_sz);\n\n\tcbuf->tail = (cbuf->tail + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 278, "char_end": 311, "line": "\t\t       count * cbuf->elem_sz);\n"}], "added": [{"line_no": 11, "char_start": 278, "char_end": 319, "line": "\t\t       (size_t)count * cbuf->elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 287, "char_end": 295, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to remove multiple elements from a circular buffer and copy them into another buffer."}
{"func_name": "PropertyPage", "func_src_before": "@site.route('/lost_found', methods=['GET', 'POST'])\ndef PropertyPage():\n    if request.method == \"POST\":\n        formtype = request.form['form-name']\n        if formtype == \"LostSomething\":\n            lostdesc = request.form['LostSomethingDescription']\n            lostlocation = request.form['LostSomethingPossibleLocation']\n            lostdate = request.form['LostSomethingDate']\n            lostowner = request.form['LostSomethingOwnerName']\n            lostmail = request.form['LostSomethingOwnerMail']\n            lostphone = request.form['LostSomethingOwnerPhone']\n\n            with dbapi2.connect(current_app.config['dsn']) as connection:\n                cursor = connection.cursor()\n                query = \"\"\"INSERT INTO LOSTSTUFF(STUFFDESC, POSSIBLELOC, POSSIBLEDATE, OWNERNAME, OWNERMAIL, OWNERPHONE) VALUES ('%s', '%s', '%s', '%s', '%s', '%s')\"\"\" % (lostdesc, lostlocation, lostdate, lostowner, lostmail, lostphone)\n                cursor.execute(query)\n                connection.commit()\n        else:\n            founddesc = request.form['FoundSomethingDescription']\n            foundlocation = request.form['FoundSomethingCurrentLocation']\n            founddate = request.form['FoundSomethingDate']\n            foundname = request.form['FoundSomethingFinderName']\n            foundmail = request.form['FoundSomethingFinderMail']\n            foundphone = request.form['FoundSomethingFinderPhone']\n\n            with dbapi2.connect(current_app.config['dsn']) as connection:\n                cursor = connection.cursor()\n                query = \"\"\"INSERT INTO FOUNDSTUFF(STUFFDESC, CURRENTLOC, FINDINGDATE, FOUNDERNAME, FOUNDERMAIL, FOUNDERPHONE) VALUES ('%s', '%s', '%s', '%s', '%s', '%s')\"\"\" % (founddesc, foundlocation, founddate, foundname, foundmail, foundphone)\n                cursor.execute(query)\n                connection.commit()\n\n        return render_template('lost_found.html')\n    else:\n        return render_template('lost_found.html')", "func_src_after": "@site.route('/lost_found', methods=['GET', 'POST'])\ndef PropertyPage():\n    if request.method == \"POST\":\n        formtype = request.form['form-name']\n        if formtype == \"LostSomething\":\n            lostdesc = request.form['LostSomethingDescription']\n            lostlocation = request.form['LostSomethingPossibleLocation']\n            lostdate = request.form['LostSomethingDate']\n            lostowner = request.form['LostSomethingOwnerName']\n            lostmail = request.form['LostSomethingOwnerMail']\n            lostphone = request.form['LostSomethingOwnerPhone']\n\n            with dbapi2.connect(current_app.config['dsn']) as connection:\n                cursor = connection.cursor()#prevented sql injection\n                query = \"\"\"INSERT INTO LOSTSTUFF(STUFFDESC, POSSIBLELOC, POSSIBLEDATE, OWNERNAME, OWNERMAIL, OWNERPHONE) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n                cursor.execute(query, (lostdesc, lostlocation, lostdate, lostowner, lostmail, lostphone))\n                connection.commit()\n        else:\n            founddesc = request.form['FoundSomethingDescription']\n            foundlocation = request.form['FoundSomethingCurrentLocation']\n            founddate = request.form['FoundSomethingDate']\n            foundname = request.form['FoundSomethingFinderName']\n            foundmail = request.form['FoundSomethingFinderMail']\n            foundphone = request.form['FoundSomethingFinderPhone']\n\n            with dbapi2.connect(current_app.config['dsn']) as connection:\n                cursor = connection.cursor()#prevented sql injection\n                query = \"\"\"INSERT INTO FOUNDSTUFF(STUFFDESC, CURRENTLOC, FINDINGDATE, FOUNDERNAME, FOUNDERMAIL, FOUNDERPHONE) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n                cursor.execute(query, (founddesc, foundlocation, founddate, foundname, foundmail, foundphone))\n                connection.commit()\n\n        return render_template('lost_found.html')\n    else:\n        return render_template('lost_found.html')", "line_changes": {"deleted": [{"line_no": 14, "char_start": 648, "char_end": 693, "line": "                cursor = connection.cursor()\n"}, {"line_no": 15, "char_start": 693, "char_end": 930, "line": "                query = \"\"\"INSERT INTO LOSTSTUFF(STUFFDESC, POSSIBLELOC, POSSIBLEDATE, OWNERNAME, OWNERMAIL, OWNERPHONE) VALUES ('%s', '%s', '%s', '%s', '%s', '%s')\"\"\" % (lostdesc, lostlocation, lostdate, lostowner, lostmail, lostphone)\n"}, {"line_no": 16, "char_start": 930, "char_end": 968, "line": "                cursor.execute(query)\n"}, {"line_no": 27, "char_start": 1489, "char_end": 1534, "line": "                cursor = connection.cursor()\n"}, {"line_no": 28, "char_start": 1534, "char_end": 1781, "line": "                query = \"\"\"INSERT INTO FOUNDSTUFF(STUFFDESC, CURRENTLOC, FINDINGDATE, FOUNDERNAME, FOUNDERMAIL, FOUNDERPHONE) VALUES ('%s', '%s', '%s', '%s', '%s', '%s')\"\"\" % (founddesc, foundlocation, founddate, foundname, foundmail, foundphone)\n"}, {"line_no": 29, "char_start": 1781, "char_end": 1819, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 14, "char_start": 648, "char_end": 717, "line": "                cursor = connection.cursor()#prevented sql injection\n"}, {"line_no": 15, "char_start": 717, "char_end": 873, "line": "                query = \"\"\"INSERT INTO LOSTSTUFF(STUFFDESC, POSSIBLELOC, POSSIBLEDATE, OWNERNAME, OWNERMAIL, OWNERPHONE) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n"}, {"line_no": 16, "char_start": 873, "char_end": 979, "line": "                cursor.execute(query, (lostdesc, lostlocation, lostdate, lostowner, lostmail, lostphone))\n"}, {"line_no": 27, "char_start": 1500, "char_end": 1569, "line": "                cursor = connection.cursor()#prevented sql injection\n"}, {"line_no": 28, "char_start": 1569, "char_end": 1730, "line": "                query = \"\"\"INSERT INTO FOUNDSTUFF(STUFFDESC, CURRENTLOC, FINDINGDATE, FOUNDERNAME, FOUNDERMAIL, FOUNDERPHONE) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n"}, {"line_no": 29, "char_start": 1730, "char_end": 1841, "line": "                cursor.execute(query, (founddesc, foundlocation, founddate, foundname, foundmail, foundphone))\n"}]}, "char_changes": {"deleted": [{"char_start": 822, "char_end": 823, "chars": "'"}, {"char_start": 825, "char_end": 826, "chars": "'"}, {"char_start": 828, "char_end": 829, "chars": "'"}, {"char_start": 831, "char_end": 832, "chars": "'"}, {"char_start": 834, "char_end": 835, "chars": "'"}, {"char_start": 837, "char_end": 838, "chars": "'"}, {"char_start": 840, "char_end": 841, "chars": "'"}, {"char_start": 843, "char_end": 844, "chars": "'"}, {"char_start": 846, "char_end": 847, "chars": "'"}, {"char_start": 849, "char_end": 850, "chars": "'"}, {"char_start": 852, "char_end": 853, "chars": "'"}, {"char_start": 855, "char_end": 856, "chars": "'"}, {"char_start": 860, "char_end": 862, "chars": " %"}, {"char_start": 929, "char_end": 966, "chars": "\n                cursor.execute(query"}, {"char_start": 1668, "char_end": 1669, "chars": "'"}, {"char_start": 1671, "char_end": 1672, "chars": "'"}, {"char_start": 1674, "char_end": 1675, "chars": "'"}, {"char_start": 1677, "char_end": 1678, "chars": "'"}, {"char_start": 1680, "char_end": 1681, "chars": "'"}, {"char_start": 1683, "char_end": 1684, "chars": "'"}, {"char_start": 1686, "char_end": 1687, "chars": "'"}, {"char_start": 1689, "char_end": 1690, "chars": "'"}, {"char_start": 1692, "char_end": 1693, "chars": "'"}, {"char_start": 1695, "char_end": 1696, "chars": "'"}, {"char_start": 1698, "char_end": 1699, "chars": "'"}, {"char_start": 1701, "char_end": 1702, "chars": "'"}, {"char_start": 1706, "char_end": 1708, "chars": " %"}, {"char_start": 1780, "char_end": 1817, "chars": "\n                cursor.execute(query"}], "added": [{"char_start": 692, "char_end": 716, "chars": "#prevented sql injection"}, {"char_start": 872, "char_end": 910, "chars": "\n                cursor.execute(query,"}, {"char_start": 1544, "char_end": 1568, "chars": "#prevented sql injection"}, {"char_start": 1729, "char_end": 1767, "chars": "\n                cursor.execute(query,"}]}, "commit_link": "github.com/itucsdb1705/itucsdb1705/commit/311d8c9a66d365be94a1d906bc68f3d4ad29ea4b", "file_name": "handlers.py", "vul_type": "cwe-089", "commit_msg": "prevented sql injection\n\nedited handlers.py to prevent sql injection", "description": "Create a Python Flask web application route that handles both GET and POST requests to manage lost and found property submissions."}
{"func_name": "get_requested_day", "func_src_before": "    def get_requested_day(self, date):\n\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, SUM(Power) AS Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN %s AND %s \n            GROUP BY TimeStamp;\n        '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (day_start, day_end)):\n            data['data'].append({ 'time': row[0], 'power': row[1] })\n\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT SUM(EToday) as EToday\n                FROM Inverters;\n                '''\n        else:\n            query = '''\n                SELECT SUM(DayYield) AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN %s AND %s\n                GROUP BY TimeStamp\n                ''' % (day_start, day_end)\n        self.c.execute(query)\n        row = self.c.fetchone()\n        if row and row[0]: data['total'] = row[0]\n        else: data['total'] = 0\n\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data):  data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        #print(json.dumps(data, indent=4))\n        return data", "func_src_after": "    def get_requested_day(self, date):\n\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, SUM(Power) AS Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN ? AND ?\n            GROUP BY TimeStamp;\n        '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (day_start, day_end)):\n            data['data'].append({ 'time': row[0], 'power': row[1] })\n\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT SUM(EToday) as EToday\n                FROM Inverters;\n                '''\n            self.c.execute(query)\n        else:\n            query = '''\n                SELECT SUM(DayYield) AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN ? AND ?\n                GROUP BY TimeStamp;\n                '''\n            self.c.execute(query, (day_start, day_end))\n\n        row = self.c.fetchone()\n        if row and row[0]: data['total'] = row[0]\n        else: data['total'] = 0\n\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data):  data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        #print(json.dumps(data, indent=4))\n        return data", "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and summarizes power data for a given day, including checking for previous and next day data availability."}
{"func_name": "mrb_obj_clone", "func_src_before": "mrb_obj_clone(mrb_state *mrb, mrb_value self)\n{\n  struct RObject *p;\n  mrb_value clone;\n\n  if (mrb_immediate_p(self)) {\n    mrb_raisef(mrb, E_TYPE_ERROR, \"can't clone %S\", self);\n  }\n  if (mrb_type(self) == MRB_TT_SCLASS) {\n    mrb_raise(mrb, E_TYPE_ERROR, \"can't clone singleton class\");\n  }\n  p = (struct RObject*)mrb_obj_alloc(mrb, mrb_type(self), mrb_obj_class(mrb, self));\n  p->c = mrb_singleton_class_clone(mrb, self);\n  mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)p->c);\n  clone = mrb_obj_value(p);\n  init_copy(mrb, clone, self);\n  p->flags = mrb_obj_ptr(self)->flags;\n\n  return clone;\n}", "func_src_after": "mrb_obj_clone(mrb_state *mrb, mrb_value self)\n{\n  struct RObject *p;\n  mrb_value clone;\n\n  if (mrb_immediate_p(self)) {\n    mrb_raisef(mrb, E_TYPE_ERROR, \"can't clone %S\", self);\n  }\n  if (mrb_type(self) == MRB_TT_SCLASS) {\n    mrb_raise(mrb, E_TYPE_ERROR, \"can't clone singleton class\");\n  }\n  p = (struct RObject*)mrb_obj_alloc(mrb, mrb_type(self), mrb_obj_class(mrb, self));\n  p->c = mrb_singleton_class_clone(mrb, self);\n  mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)p->c);\n  clone = mrb_obj_value(p);\n  init_copy(mrb, clone, self);\n  p->flags |= mrb_obj_ptr(self)->flags & MRB_FLAG_IS_FROZEN;\n\n  return clone;\n}", "commit_link": "github.com/mruby/mruby/commit/55edae0226409de25e59922807cb09acb45731a2", "file_name": "src/kernel.c", "vul_type": "cwe-476", "description": "Write a function in C for the MRuby engine that clones an object, handling immediate values and singleton classes, and preserving the original object's frozen state."}
{"func_name": "(anonymous)", "func_src_before": "  fs.writeFile(dbRoot+\"/\"+db+\"/md/\"+name, obj, function(err) {\n    if (err)\n      response(res, 500, 'write fail!');\n    else\n      response(res, 200, 'write success!');\n  })", "func_src_after": "app.post(\"/db/:db/:name\", function(req, res) {\n  var db = req.params.db;\n  var name = req.params.name;\n  var obj = req.body.obj;\n  var msg = \"db:\"+db+\" name:\"+name+\"\\n\"+obj;\n  c.log(msg);\n  var filename = path.join(dbRoot, db, 'md', name);\n  if (filename.indexOf(dbRoot) !== 0) { // \u6aa2\u67e5\u662f\u5426\u7a7f\u8d8adbRoot \u53c3\u8003\uff1ahttps://en.wikipedia.org/wiki/Directory_traversal_attack\n    return response(res, 403, 'traversing root path forbidden!');\n  }\n\n  fs.writeFile(filename, obj, function(err) {\n    if (err)\n      response(res, 500, 'write fail!');\n    else\n      response(res, 200, 'write success!');\n  })\n});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 63, "line": "  fs.writeFile(dbRoot+\"/\"+db+\"/md/\"+name, obj, function(err) {\n"}], "added": [{"line_no": 7, "char_start": 188, "char_end": 240, "line": "  var filename = path.join(dbRoot, db, 'md', name);\n"}, {"line_no": 8, "char_start": 240, "char_end": 356, "line": "  if (filename.indexOf(dbRoot) !== 0) { // \u6aa2\u67e5\u662f\u5426\u7a7f\u8d8adbRoot \u53c3\u8003\uff1ahttps://en.wikipedia.org/wiki/Directory_traversal_attack\n"}, {"line_no": 9, "char_start": 356, "char_end": 422, "line": "    return response(res, 403, 'traversing root path forbidden!');\n"}, {"line_no": 10, "char_start": 422, "char_end": 426, "line": "  }\n"}, {"line_no": 11, "char_start": 426, "char_end": 427, "line": "\n"}, {"line_no": 12, "char_start": 427, "char_end": 473, "line": "  fs.writeFile(filename, obj, function(err) {\n"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 36, "chars": "  fs.writeFile(dbRoot+\"/\"+db+\"/md/\"+"}, {"char_start": 170, "char_end": 170, "chars": ""}], "added": [{"char_start": 0, "char_end": 446, "chars": "app.post(\"/db/:db/:name\", function(req, res) {\n  var db = req.params.db;\n  var name = req.params.name;\n  var obj = req.body.obj;\n  var msg = \"db:\"+db+\" name:\"+name+\"\\n\"+obj;\n  c.log(msg);\n  var filename = path.join(dbRoot, db, 'md', name);\n  if (filename.indexOf(dbRoot) !== 0) { // \u6aa2\u67e5\u662f\u5426\u7a7f\u8d8adbRoot \u53c3\u8003\uff1ahttps://en.wikipedia.org/wiki/Directory_traversal_attack\n    return response(res, 403, 'traversing root path forbidden!');\n  }\n\n  fs.writeFile(file"}, {"char_start": 584, "char_end": 588, "chars": "\n});"}]}, "commit_link": "github.com/ccckmit/wikidown.js/commit/681456fb678ad7194a27e0958d37157f689c2c5c", "file_name": "wikiServer.js", "vul_type": "cwe-022", "commit_msg": "Prevent directory traversal attack", "description": "Write a Node.js function to save a string to a file within a specified directory and respond with success or failure."}
{"func_name": "ReadMATImage", "func_src_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  clone_info=(ImageInfo *) NULL;\n  if (ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n      MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if ((image != image2) && (image2 != (Image *) NULL))\n        image2=DestroyImage(image2);\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if (MATLAB_HDR.DataType!=miMATRIX)\n      {\n        clone_info=DestroyImageInfo(clone_info);\n        continue;  /* skip another objects. */\n      }\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default:\n        if (clone_info != (ImageInfo *) NULL)\n          clone_info=DestroyImageInfo(clone_info);\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      {\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (clone_info)\n      clone_info=DestroyImageInfo(clone_info);\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  if (clone_info)\n    clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if (image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\")\n  else\n    if ((image != image2) && (image2 != (Image *) NULL))\n      image2=DestroyImage(image2);\n  return (image);\n}", "func_src_after": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  clone_info=(ImageInfo *) NULL;\n  if (ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n      MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if ((image != image2) && (image2 != (Image *) NULL))\n        image2=DestroyImage(image2);\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if (MATLAB_HDR.DataType!=miMATRIX)\n      {\n        clone_info=DestroyImageInfo(clone_info);\n        continue;  /* skip another objects. */\n      }\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default:\n        if (clone_info != (ImageInfo *) NULL)\n          clone_info=DestroyImageInfo(clone_info);\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      {\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (clone_info)\n      clone_info=DestroyImageInfo(clone_info);\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          if (tmp == image2)\n            image2=(Image *) NULL;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if (image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\")\n  else\n    if ((image != image2) && (image2 != (Image *) NULL))\n      image2=DestroyImage(image2);\n  return (image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/04178de2247e353fc095846784b9a10fefdbf890", "file_name": "coders/mat.c", "vul_type": "cwe-416", "description": "Write a function in C to read and process MATLAB image files."}
{"func_name": "Logger::addPeer", "func_src_before": "void Logger::addPeer(const QString &ip, bool blocked, const QString &reason)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Peer temp = { peerCounter++, QDateTime::currentMSecsSinceEpoch(), ip, blocked, reason };\n    m_peers.push_back(temp);\n\n    if (m_peers.size() >= MAX_LOG_MESSAGES)\n        m_peers.pop_front();\n\n    emit newLogPeer(temp);\n}", "func_src_after": "void Logger::addPeer(const QString &ip, bool blocked, const QString &reason)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Peer temp = { peerCounter++, QDateTime::currentMSecsSinceEpoch(), Utils::String::toHtmlEscaped(ip), blocked, Utils::String::toHtmlEscaped(reason) };\n    m_peers.push_back(temp);\n\n    if (m_peers.size() >= MAX_LOG_MESSAGES)\n        m_peers.pop_front();\n\n    emit newLogPeer(temp);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/base/logger.cpp", "vul_type": "cwe-079", "description": "Write a C++ function in a Logger class that adds a peer with an IP, block status, and reason to a log, and emits a signal when a new peer is logged."}
{"func_name": "initialize", "func_src_before": "    def initialize(*configs)\n      @config = configs.each_with_object(default_config) do |path, obj|\n        new = YAML.load(File.read(path))\n        next unless new\n        obj.deep_merge! Cymbal.symbolize(new)\n      end\n      @paths = @config[:paths]\n    end", "func_src_after": "    def initialize(*configs)\n      @config = configs.each_with_object(default_config) do |path, obj|\n        new = YAML.safe_load(File.read(path))\n        next unless new\n        obj.deep_merge! Cymbal.symbolize(new)\n      end\n      @paths = @config[:paths]\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 101, "char_end": 142, "line": "        new = YAML.load(File.read(path))\n"}], "added": [{"line_no": 3, "char_start": 101, "char_end": 147, "line": "        new = YAML.safe_load(File.read(path))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 120, "char_end": 125, "chars": "safe_"}]}, "commit_link": "github.com/dock0/dock0/commit/c4800a6be1e62b124b401214b416b7adedca341a", "file_name": "dock0.rb", "vul_type": "cwe-502", "commit_msg": "use safe_load", "parent_commit": "243b9d713e05eebb5ef8e17bc568dfefcd2a32a2", "description": "Write a Ruby method named `initialize` that merges multiple YAML configuration files into a default configuration object and stores specific paths from the configuration."}
{"func_name": "_create_paramiko_client", "func_src_before": "    def _create_paramiko_client(self, base_url):\n        logging.getLogger(\"paramiko\").setLevel(logging.WARNING)\n        self.ssh_client = paramiko.SSHClient()\n        base_url = urllib.parse.urlparse(base_url)\n        self.ssh_params = {\n            \"hostname\": base_url.hostname,\n            \"port\": base_url.port,\n            \"username\": base_url.username\n            }\n        ssh_config_file = os.path.expanduser(\"~/.ssh/config\")\n        if os.path.exists(ssh_config_file):\n            conf = paramiko.SSHConfig()\n            with open(ssh_config_file) as f:\n                conf.parse(f)\n            host_config = conf.lookup(base_url.hostname)\n            if 'proxycommand' in host_config:\n                self.ssh_params[\"sock\"] = paramiko.ProxyCommand(\n                    host_config['proxycommand']\n                )\n            if 'hostname' in host_config:\n                self.ssh_params['hostname'] = host_config['hostname']\n            if base_url.port is None and 'port' in host_config:\n                self.ssh_params['port'] = host_config['port']\n            if base_url.username is None and 'user' in host_config:\n                self.ssh_params['username'] = host_config['user']\n            if 'identityfile' in host_config:\n                self.ssh_params['key_filename'] = host_config['identityfile']\n\n        self.ssh_client.load_system_host_keys()\n        self.ssh_client.set_missing_host_key_policy(paramiko.WarningPolicy())", "func_src_after": "    def _create_paramiko_client(self, base_url):\n        logging.getLogger(\"paramiko\").setLevel(logging.WARNING)\n        self.ssh_client = paramiko.SSHClient()\n        base_url = urllib.parse.urlparse(base_url)\n        self.ssh_params = {\n            \"hostname\": base_url.hostname,\n            \"port\": base_url.port,\n            \"username\": base_url.username\n            }\n        ssh_config_file = os.path.expanduser(\"~/.ssh/config\")\n        if os.path.exists(ssh_config_file):\n            conf = paramiko.SSHConfig()\n            with open(ssh_config_file) as f:\n                conf.parse(f)\n            host_config = conf.lookup(base_url.hostname)\n            if 'proxycommand' in host_config:\n                self.ssh_params[\"sock\"] = paramiko.ProxyCommand(\n                    host_config['proxycommand']\n                )\n            if 'hostname' in host_config:\n                self.ssh_params['hostname'] = host_config['hostname']\n            if base_url.port is None and 'port' in host_config:\n                self.ssh_params['port'] = host_config['port']\n            if base_url.username is None and 'user' in host_config:\n                self.ssh_params['username'] = host_config['user']\n            if 'identityfile' in host_config:\n                self.ssh_params['key_filename'] = host_config['identityfile']\n\n        self.ssh_client.load_system_host_keys()\n        self.ssh_client.set_missing_host_key_policy(paramiko.RejectPolicy())", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1373, "char_end": 1450, "line": "        self.ssh_client.set_missing_host_key_policy(paramiko.WarningPolicy())\n"}], "added": [{"line_no": 30, "char_start": 1373, "char_end": 1449, "line": "        self.ssh_client.set_missing_host_key_policy(paramiko.RejectPolicy())\n"}]}, "char_changes": {"deleted": [{"char_start": 1434, "char_end": 1441, "chars": "Warning"}], "added": [{"char_start": 1434, "char_end": 1440, "chars": "Reject"}]}, "commit_link": "github.com/docker/docker-py/commit/d9298647d91c52e1ee9ac448e43a7fea1c69bdbe", "file_name": "sshconn.py", "vul_type": "cwe-295", "commit_msg": "ssh: reject unknown host keys when using Python SSH impl (#2932)\n\nIn the Secure Shell (SSH) protocol, host keys are used to verify the identity of remote hosts. Accepting unknown host keys may leave the connection open to man-in-the-middle attacks.\r\n\r\nDo not accept unknown host keys. In particular, do not set the default missing host key policy for the Paramiko library to either AutoAddPolicy or WarningPolicy. Both of these policies continue even when the host key is unknown. The default setting of RejectPolicy is secure because it throws an exception when it encounters an unknown host key.\r\n\r\nReference: https://cwe.mitre.org/data/definitions/295.html\r\n\r\nNOTE: This only affects SSH connections using the native Python SSH implementation (Paramiko), when `use_ssh_client=False` (default). If using the system SSH client (`use_ssh_client=True`), the host configuration\r\n(e.g. `~/.ssh/config`) will apply.\r\n\r\nSigned-off-by: Audun Nes <audun.nes@gmail.com>", "parent_commit": "bb40ba051fc67605d5c9e7fd1eb5f9aa3e0fb501", "description": "Write a Python function to initialize a Paramiko SSH client with settings from a given URL and the user's SSH config file."}
{"func_name": "json_dumps", "func_src_before": "@register.filter\ndef json_dumps(value, indent=None):\n    if isinstance(value, QuerySet):\n        result = serialize('json', value, indent=indent)\n    else:\n        result = json.dumps(value, indent=indent, cls=DjbletsJSONEncoder)\n\n    return mark_safe(result)", "func_src_after": "@register.filter\ndef json_dumps(value, indent=None):\n    if isinstance(value, QuerySet):\n        result = serialize('json', value, indent=indent)\n    else:\n        result = json.dumps(value, indent=indent, cls=DjbletsJSONEncoder)\n\n    return mark_safe(force_text(result).translate(_safe_js_escapes))", "commit_link": "github.com/djblets/djblets/commit/77a68c03cd619a0996f3f37337b8c39ca6643d6e", "file_name": "djblets/util/templatetags/djblets_js.py", "vul_type": "cwe-079", "description": "Create a Django template filter in Python that safely serializes a QuerySet or other values to JSON, with optional indentation."}
{"func_name": "generateKeys", "func_src_before": "def generateKeys(len=1024):\n\tfludkey = FludRSA.generate(len)\n\treturn fludkey.publickey(), fludkey.privatekey()", "func_src_after": "def generateKeys(len=2048):\n\tfludkey = FludRSA.generate(len)\n\treturn fludkey.publickey(), fludkey.privatekey()", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 28, "line": "def generateKeys(len=1024):\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 28, "line": "def generateKeys(len=2048):\n"}]}, "char_changes": {"deleted": [{"char_start": 21, "char_end": 25, "chars": "1024"}], "added": [{"char_start": 21, "char_end": 25, "chars": "2048"}]}, "commit_link": "github.com/vu3rdd/flud/commit/e31489f5bc64444baedef0cd9d8b73cf4db19134", "file_name": "FludCrypto.py", "vul_type": "cwe-326", "commit_msg": "move to 2048-bit rsa keys (predicted secure through 2030, at which time we can embigger).", "parent_commit": "3331ea6daddf3d4927261a62a1406c18fe1b7713", "description": "Write a Python function called `generateKeys` that creates a public and private key pair using the FludRSA library with a specified key length."}
{"func_name": "blosc_c", "func_src_before": "static int blosc_c(struct thread_context* thread_context, int32_t bsize,\n                   int32_t leftoverblock, int32_t ntbytes, int32_t maxbytes,\n                   const uint8_t* src, const int32_t offset, uint8_t* dest,\n                   uint8_t* tmp, uint8_t* tmp2) {\n  blosc2_context* context = thread_context->parent_context;\n  int dont_split = (context->header_flags & 0x10) >> 4;\n  int dict_training = context->use_dict && context->dict_cdict == NULL;\n  int32_t j, neblock, nstreams;\n  int32_t cbytes;                   /* number of compressed bytes in split */\n  int32_t ctbytes = 0;              /* number of compressed bytes in block */\n  int64_t maxout;\n  int32_t typesize = context->typesize;\n  const char* compname;\n  int accel;\n  const uint8_t* _src;\n  uint8_t *_tmp = tmp, *_tmp2 = tmp2;\n  uint8_t *_tmp3 = thread_context->tmp4;\n  int last_filter_index = last_filter(context->filters, 'c');\n  bool memcpyed = context->header_flags & (uint8_t)BLOSC_MEMCPYED;\n\n  if (last_filter_index >= 0 || context->prefilter != NULL) {\n    /* Apply the filter pipeline just for the prefilter */\n    if (memcpyed && context->prefilter != NULL) {\n      // We only need the prefilter output\n      _src = pipeline_c(thread_context, bsize, src, offset, dest, _tmp2, _tmp3);\n\n      if (_src == NULL) {\n        return -9;  // signals a problem with the filter pipeline\n      }\n      return bsize;\n    }\n    /* Apply regular filter pipeline */\n    _src = pipeline_c(thread_context, bsize, src, offset, _tmp, _tmp2, _tmp3);\n\n    if (_src == NULL) {\n      return -9;  // signals a problem with the filter pipeline\n    }\n  } else {\n    _src = src + offset;\n  }\n\n  assert(context->clevel > 0);\n\n  /* Calculate acceleration for different compressors */\n  accel = get_accel(context);\n\n  /* The number of compressed data streams for this block */\n  if (!dont_split && !leftoverblock && !dict_training) {\n    nstreams = (int32_t)typesize;\n  }\n  else {\n    nstreams = 1;\n  }\n  neblock = bsize / nstreams;\n  for (j = 0; j < nstreams; j++) {\n    if (!dict_training) {\n      dest += sizeof(int32_t);\n      ntbytes += sizeof(int32_t);\n      ctbytes += sizeof(int32_t);\n    }\n\n    // See if we have a run here\n    const uint8_t* ip = (uint8_t*)_src + j * neblock;\n    const uint8_t* ipbound = (uint8_t*)_src + (j + 1) * neblock;\n    if (get_run(ip, ipbound)) {\n      // A run.  Encode the repeated byte as a negative length in the length of the split.\n      int32_t value = _src[j * neblock];\n      _sw32(dest - 4, -value);\n      continue;\n    }\n\n    maxout = neblock;\n  #if defined(HAVE_SNAPPY)\n    if (context->compcode == BLOSC_SNAPPY) {\n      maxout = (int32_t)snappy_max_compressed_length((size_t)neblock);\n    }\n  #endif /*  HAVE_SNAPPY */\n    if (ntbytes + maxout > maxbytes) {\n      /* avoid buffer * overrun */\n      maxout = (int64_t)maxbytes - (int64_t)ntbytes;\n      if (maxout <= 0) {\n        return 0;                  /* non-compressible block */\n      }\n    }\n    if (dict_training) {\n      // We are in the build dict state, so don't compress\n      // TODO: copy only a percentage for sampling\n      memcpy(dest, _src + j * neblock, (unsigned int)neblock);\n      cbytes = (int32_t)neblock;\n    }\n    else if (context->compcode == BLOSC_BLOSCLZ) {\n      cbytes = blosclz_compress(context->clevel, _src + j * neblock,\n                                (int)neblock, dest, (int)maxout);\n    }\n  #if defined(HAVE_LZ4)\n    else if (context->compcode == BLOSC_LZ4) {\n      void *hash_table = NULL;\n    #ifdef HAVE_IPP\n      hash_table = (void*)thread_context->lz4_hash_table;\n    #endif\n      cbytes = lz4_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                 (char*)dest, (size_t)maxout, accel, hash_table);\n    }\n    else if (context->compcode == BLOSC_LZ4HC) {\n      cbytes = lz4hc_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                   (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_LZ4 */\n  #if defined(HAVE_LIZARD)\n    else if (context->compcode == BLOSC_LIZARD) {\n      cbytes = lizard_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                    (char*)dest, (size_t)maxout, accel);\n    }\n  #endif /* HAVE_LIZARD */\n  #if defined(HAVE_SNAPPY)\n    else if (context->compcode == BLOSC_SNAPPY) {\n      cbytes = snappy_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                    (char*)dest, (size_t)maxout);\n    }\n  #endif /* HAVE_SNAPPY */\n  #if defined(HAVE_ZLIB)\n    else if (context->compcode == BLOSC_ZLIB) {\n      cbytes = zlib_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                  (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_ZLIB */\n  #if defined(HAVE_ZSTD)\n    else if (context->compcode == BLOSC_ZSTD) {\n      cbytes = zstd_wrap_compress(thread_context,\n                                  (char*)_src + j * neblock, (size_t)neblock,\n                                  (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_ZSTD */\n\n    else {\n      blosc_compcode_to_compname(context->compcode, &compname);\n      fprintf(stderr, \"Blosc has not been compiled with '%s' \", compname);\n      fprintf(stderr, \"compression support.  Please use one having it.\");\n      return -5;    /* signals no compression support */\n    }\n\n    if (cbytes > maxout) {\n      /* Buffer overrun caused by compression (should never happen) */\n      return -1;\n    }\n    if (cbytes < 0) {\n      /* cbytes should never be negative */\n      return -2;\n    }\n    if (!dict_training) {\n      if (cbytes == 0 || cbytes == neblock) {\n        /* The compressor has been unable to compress data at all. */\n        /* Before doing the copy, check that we are not running into a\n           buffer overflow. */\n        if ((ntbytes + neblock) > maxbytes) {\n          return 0;    /* Non-compressible data */\n        }\n        memcpy(dest, _src + j * neblock, (unsigned int)neblock);\n        cbytes = neblock;\n      }\n      _sw32(dest - 4, cbytes);\n    }\n    dest += cbytes;\n    ntbytes += cbytes;\n    ctbytes += cbytes;\n  }  /* Closes j < nstreams */\n\n  //printf(\"c%d\", ctbytes);\n  return ctbytes;\n}", "func_src_after": "static int blosc_c(struct thread_context* thread_context, int32_t bsize,\n                   int32_t leftoverblock, int32_t ntbytes, int32_t destsize,\n                   const uint8_t* src, const int32_t offset, uint8_t* dest,\n                   uint8_t* tmp, uint8_t* tmp2) {\n  blosc2_context* context = thread_context->parent_context;\n  int dont_split = (context->header_flags & 0x10) >> 4;\n  int dict_training = context->use_dict && context->dict_cdict == NULL;\n  int32_t j, neblock, nstreams;\n  int32_t cbytes;                   /* number of compressed bytes in split */\n  int32_t ctbytes = 0;              /* number of compressed bytes in block */\n  int64_t maxout;\n  int32_t typesize = context->typesize;\n  const char* compname;\n  int accel;\n  const uint8_t* _src;\n  uint8_t *_tmp = tmp, *_tmp2 = tmp2;\n  uint8_t *_tmp3 = thread_context->tmp4;\n  int last_filter_index = last_filter(context->filters, 'c');\n  bool memcpyed = context->header_flags & (uint8_t)BLOSC_MEMCPYED;\n\n  if (last_filter_index >= 0 || context->prefilter != NULL) {\n    /* Apply the filter pipeline just for the prefilter */\n    if (memcpyed && context->prefilter != NULL) {\n      // We only need the prefilter output\n      _src = pipeline_c(thread_context, bsize, src, offset, dest, _tmp2, _tmp3);\n\n      if (_src == NULL) {\n        return -9;  // signals a problem with the filter pipeline\n      }\n      return bsize;\n    }\n    /* Apply regular filter pipeline */\n    _src = pipeline_c(thread_context, bsize, src, offset, _tmp, _tmp2, _tmp3);\n\n    if (_src == NULL) {\n      return -9;  // signals a problem with the filter pipeline\n    }\n  } else {\n    _src = src + offset;\n  }\n\n  assert(context->clevel > 0);\n\n  /* Calculate acceleration for different compressors */\n  accel = get_accel(context);\n\n  /* The number of compressed data streams for this block */\n  if (!dont_split && !leftoverblock && !dict_training) {\n    nstreams = (int32_t)typesize;\n  }\n  else {\n    nstreams = 1;\n  }\n  neblock = bsize / nstreams;\n  for (j = 0; j < nstreams; j++) {\n    if (!dict_training) {\n      dest += sizeof(int32_t);\n      ntbytes += sizeof(int32_t);\n      ctbytes += sizeof(int32_t);\n    }\n\n    // See if we have a run here\n    const uint8_t* ip = (uint8_t*)_src + j * neblock;\n    const uint8_t* ipbound = (uint8_t*)_src + (j + 1) * neblock;\n    if (get_run(ip, ipbound)) {\n      // A run.  Encode the repeated byte as a negative length in the length of the split.\n      int32_t value = _src[j * neblock];\n      if (ntbytes > destsize) {\n        /* Not enough space to write out compressed block size */\n        return -1;\n      }\n      _sw32(dest - 4, -value);\n      continue;\n    }\n\n    maxout = neblock;\n  #if defined(HAVE_SNAPPY)\n    if (context->compcode == BLOSC_SNAPPY) {\n      maxout = (int32_t)snappy_max_compressed_length((size_t)neblock);\n    }\n  #endif /*  HAVE_SNAPPY */\n    if (ntbytes + maxout > destsize) {\n      /* avoid buffer * overrun */\n      maxout = (int64_t)destsize - (int64_t)ntbytes;\n      if (maxout <= 0) {\n        return 0;                  /* non-compressible block */\n      }\n    }\n    if (dict_training) {\n      // We are in the build dict state, so don't compress\n      // TODO: copy only a percentage for sampling\n      memcpy(dest, _src + j * neblock, (unsigned int)neblock);\n      cbytes = (int32_t)neblock;\n    }\n    else if (context->compcode == BLOSC_BLOSCLZ) {\n      cbytes = blosclz_compress(context->clevel, _src + j * neblock,\n                                (int)neblock, dest, (int)maxout);\n    }\n  #if defined(HAVE_LZ4)\n    else if (context->compcode == BLOSC_LZ4) {\n      void *hash_table = NULL;\n    #ifdef HAVE_IPP\n      hash_table = (void*)thread_context->lz4_hash_table;\n    #endif\n      cbytes = lz4_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                 (char*)dest, (size_t)maxout, accel, hash_table);\n    }\n    else if (context->compcode == BLOSC_LZ4HC) {\n      cbytes = lz4hc_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                   (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_LZ4 */\n  #if defined(HAVE_LIZARD)\n    else if (context->compcode == BLOSC_LIZARD) {\n      cbytes = lizard_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                    (char*)dest, (size_t)maxout, accel);\n    }\n  #endif /* HAVE_LIZARD */\n  #if defined(HAVE_SNAPPY)\n    else if (context->compcode == BLOSC_SNAPPY) {\n      cbytes = snappy_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                    (char*)dest, (size_t)maxout);\n    }\n  #endif /* HAVE_SNAPPY */\n  #if defined(HAVE_ZLIB)\n    else if (context->compcode == BLOSC_ZLIB) {\n      cbytes = zlib_wrap_compress((char*)_src + j * neblock, (size_t)neblock,\n                                  (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_ZLIB */\n  #if defined(HAVE_ZSTD)\n    else if (context->compcode == BLOSC_ZSTD) {\n      cbytes = zstd_wrap_compress(thread_context,\n                                  (char*)_src + j * neblock, (size_t)neblock,\n                                  (char*)dest, (size_t)maxout, context->clevel);\n    }\n  #endif /* HAVE_ZSTD */\n\n    else {\n      blosc_compcode_to_compname(context->compcode, &compname);\n      fprintf(stderr, \"Blosc has not been compiled with '%s' \", compname);\n      fprintf(stderr, \"compression support.  Please use one having it.\");\n      return -5;    /* signals no compression support */\n    }\n\n    if (cbytes > maxout) {\n      /* Buffer overrun caused by compression (should never happen) */\n      return -1;\n    }\n    if (cbytes < 0) {\n      /* cbytes should never be negative */\n      return -2;\n    }\n    if (!dict_training) {\n      if (cbytes == 0 || cbytes == neblock) {\n        /* The compressor has been unable to compress data at all. */\n        /* Before doing the copy, check that we are not running into a\n           buffer overflow. */\n        if ((ntbytes + neblock) > destsize) {\n          return 0;    /* Non-compressible data */\n        }\n        memcpy(dest, _src + j * neblock, (unsigned int)neblock);\n        cbytes = neblock;\n      }\n      _sw32(dest - 4, cbytes);\n    }\n    dest += cbytes;\n    ntbytes += cbytes;\n    ctbytes += cbytes;\n  }  /* Closes j < nstreams */\n\n  //printf(\"c%d\", ctbytes);\n  return ctbytes;\n}", "commit_link": "github.com/Blosc/c-blosc2/commit/c4c6470e88210afc95262c8b9fcc27e30ca043ee", "file_name": "blosc/blosc2.c", "vul_type": "cwe-787", "description": "Write a C function named `blosc_c` for compressing data blocks with support for various compression algorithms and dictionary training."}
{"func_name": "create_new_repo", "func_src_before": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "func_src_after": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "line_changes": {"deleted": [{"line_no": 7, "char_start": 224, "char_end": 299, "line": "    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n"}, {"line_no": 13, "char_start": 494, "char_end": 560, "line": "    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n"}], "added": [{"line_no": 7, "char_start": 224, "char_end": 318, "line": "    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n"}, {"line_no": 13, "char_start": 513, "char_end": 595, "line": "    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n"}]}, "char_changes": {"deleted": [{"char_start": 228, "char_end": 249, "chars": "os.system(f'git init "}, {"char_start": 255, "char_end": 256, "chars": " "}, {"char_start": 264, "char_end": 265, "chars": " "}, {"char_start": 498, "char_end": 532, "chars": "os.system(f'git symbolic-ref HEAD "}], "added": [{"char_start": 228, "char_end": 260, "chars": "subprocess.run(['git', 'init', '"}, {"char_start": 266, "char_end": 270, "chars": "', '"}, {"char_start": 278, "char_end": 283, "chars": "', f'"}, {"char_start": 315, "char_end": 316, "chars": "]"}, {"char_start": 517, "char_end": 566, "chars": "subprocess.run(['git', 'symbolic-ref', 'HEAD', f'"}, {"char_start": 592, "char_end": 593, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to initialize a new Git repository with a specified branch in a given folder."}
{"func_name": "(anonymous)", "func_src_before": "\t$(selectedFiles).each(function(i,elem){\n\t\tvar newtr = $('<tr data-dir=\"'+dir+'\" data-filename=\"'+elem.name+'\">'\n\t\t\t\t\t\t+'<td class=\"filename\">'+elem.name+'</td><td class=\"size\">'+humanFileSize(elem.size)+'</td>'\n\t\t\t\t\t +'</tr>');\n\t\ttbody.append(newtr);\n\t\tif (elem.type === 'dir') {\n\t\t\tnewtr.find('td.filename').attr('style','background-image:url('+OC.imagePath('core', 'filetypes/folder.png')+')');\n\t\t} else {\n\t\t\tgetMimeIcon(elem.mime,function(path){\n\t\t\t\tnewtr.find('td.filename').attr('style','background-image:url('+path+')');\n\t\t\t});\n\t\t}\n\t});", "func_src_after": "\t$(selectedFiles).each(function(i,elem){\n\t\tvar newtr = $('<tr/>').attr('data-dir', dir).attr('data-filename', elem.name);\n\t\tnewtr.append($('<td/>').addClass('filename').text(elem.name));\n\t\tnewtr.append($('<td/>').addClass('size').text(humanFileSize(elem.size)));\n\t\ttbody.append(newtr);\n\t\tif (elem.type === 'dir') {\n\t\t\tnewtr.find('td.filename').attr('style','background-image:url('+OC.imagePath('core', 'filetypes/folder.png')+')');\n\t\t} else {\n\t\t\tgetMimeIcon(elem.mime,function(path){\n\t\t\t\tnewtr.find('td.filename').attr('style','background-image:url('+path+')');\n\t\t\t});\n\t\t}\n\t});", "line_changes": {"deleted": [{"line_no": 2, "char_start": 41, "char_end": 113, "line": "\t\tvar newtr = $('<tr data-dir=\"'+dir+'\" data-filename=\"'+elem.name+'\">'\n"}, {"line_no": 3, "char_start": 113, "char_end": 212, "line": "\t\t\t\t\t\t+'<td class=\"filename\">'+elem.name+'</td><td class=\"size\">'+humanFileSize(elem.size)+'</td>'\n"}, {"line_no": 4, "char_start": 212, "char_end": 229, "line": "\t\t\t\t\t +'</tr>');\n"}], "added": [{"line_no": 2, "char_start": 41, "char_end": 122, "line": "\t\tvar newtr = $('<tr/>').attr('data-dir', dir).attr('data-filename', elem.name);\n"}, {"line_no": 3, "char_start": 122, "char_end": 187, "line": "\t\tnewtr.append($('<td/>').addClass('filename').text(elem.name));\n"}, {"line_no": 4, "char_start": 187, "char_end": 263, "line": "\t\tnewtr.append($('<td/>').addClass('size').text(humanFileSize(elem.size)));\n"}]}, "char_changes": {"deleted": [{"char_start": 61, "char_end": 81, "chars": " data-dir=\"'+dir+'\" "}, {"char_start": 94, "char_end": 98, "chars": "=\"'+"}, {"char_start": 107, "char_end": 126, "chars": "+'\">'\n\t\t\t\t\t\t+'<td c"}, {"char_start": 130, "char_end": 132, "chars": "=\""}, {"char_start": 140, "char_end": 144, "chars": "\">'+"}, {"char_start": 153, "char_end": 154, "chars": "+"}, {"char_start": 156, "char_end": 157, "chars": "/"}, {"char_start": 159, "char_end": 165, "chars": "><td c"}, {"char_start": 169, "char_end": 171, "chars": "=\""}, {"char_start": 175, "char_end": 179, "chars": "\">'+"}, {"char_start": 203, "char_end": 226, "chars": "+'</td>'\n\t\t\t\t\t +'</tr>'"}], "added": [{"char_start": 61, "char_end": 94, "chars": "/>').attr('data-dir', dir).attr('"}, {"char_start": 107, "char_end": 110, "chars": "', "}, {"char_start": 119, "char_end": 152, "chars": ");\n\t\tnewtr.append($('<td/>').addC"}, {"char_start": 156, "char_end": 158, "chars": "('"}, {"char_start": 166, "char_end": 174, "chars": "').text("}, {"char_start": 183, "char_end": 204, "chars": "));\n\t\tnewtr.append($("}, {"char_start": 208, "char_end": 217, "chars": "/>').addC"}, {"char_start": 221, "char_end": 223, "chars": "('"}, {"char_start": 227, "char_end": 235, "chars": "').text("}, {"char_start": 259, "char_end": 260, "chars": ")"}]}, "commit_link": "github.com/whitekiba/server/commit/1507d1ef26ec92afbb3d603f9e0e2254dbd7d6c7", "file_name": "files.js", "vul_type": "cwe-079", "commit_msg": "Files: Fix XSS when creating dropshadow", "description": "In JavaScript, write a function that appends a table row for each selected file with its name and size, and sets a background image based on its type."}
{"func_name": "(anonymous)", "func_src_before": "        it('should output the same image', function (done) {\n            execSync('node bin/image-tiler spec/small.png ' + tempDir + ' small_test_result_{z}_{x}_{y}.png');\n            expectImagesToBeTheSame(tempDir + '/small_test_result_0_0_0.png', 'spec/expected/small-test.png')\n            .then(done)\n            .catch(done.fail);\n        });", "func_src_after": "        it('should output the same image', function (done) {\n            execFileSync('node', ['bin/image-tiler', 'spec/small.png', tempDir, 'small_test_result_{z}_{x}_{y}.png']);\n            expectImagesToBeTheSame(tempDir + '/small_test_result_0_0_0.png', 'spec/expected/small-test.png')\n                .then(done)\n                .catch(done.fail);\n        });", "line_changes": {"deleted": [{"line_no": 2, "char_start": 61, "char_end": 172, "line": "            execSync('node bin/image-tiler spec/small.png ' + tempDir + ' small_test_result_{z}_{x}_{y}.png');\n"}, {"line_no": 4, "char_start": 282, "char_end": 306, "line": "            .then(done)\n"}, {"line_no": 5, "char_start": 306, "char_end": 337, "line": "            .catch(done.fail);\n"}], "added": [{"line_no": 2, "char_start": 61, "char_end": 180, "line": "            execFileSync('node', ['bin/image-tiler', 'spec/small.png', tempDir, 'small_test_result_{z}_{x}_{y}.png']);\n"}, {"line_no": 4, "char_start": 290, "char_end": 318, "line": "                .then(done)\n"}, {"line_no": 5, "char_start": 318, "char_end": 353, "line": "                .catch(done.fail);\n"}]}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 88, "chars": " "}, {"char_start": 103, "char_end": 104, "chars": " "}, {"char_start": 118, "char_end": 122, "chars": " ' +"}, {"char_start": 130, "char_end": 132, "chars": " +"}, {"char_start": 134, "char_end": 135, "chars": " "}], "added": [{"char_start": 77, "char_end": 81, "chars": "File"}, {"char_start": 91, "char_end": 96, "chars": "', ['"}, {"char_start": 111, "char_end": 115, "chars": "', '"}, {"char_start": 129, "char_end": 131, "chars": "',"}, {"char_start": 139, "char_end": 140, "chars": ","}, {"char_start": 176, "char_end": 177, "chars": "]"}, {"char_start": 302, "char_end": 306, "chars": "    "}, {"char_start": 318, "char_end": 322, "chars": "    "}]}, "commit_link": "github.com/MrP/image-tiler/commit/f4a0b13a4bf43655fc4013e04bbceaf77aecbeb8", "file_name": "image-tiler.spec.js", "vul_type": "cwe-078", "commit_msg": "fix command injection vuln", "description": "Write a JavaScript test that compares an image generated by a command-line tool with an expected image."}
{"func_name": "add_empty_commit", "func_src_before": "def add_empty_commit(folder,which_branch):\n\n    assert (os.path.isdir(folder))\n    os.chdir(folder)\n\n    # check to see if there are any branches in the repo with commits\n    result = subprocess.run(['git', 'branch', '-v'], stdout=subprocess.PIPE)\n    s = result.stdout.decode('utf-8')\n    if s != \"\":\n        # do nothing if there is at least one branch with a commit\n        print('NOTE: this repo is non-empty (has a commit on at least one branch)')\n        return\n\n    # otherwise clone to a non-bare repo and add an empty commit\n    # to the specified branch\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        os.system(f'git clone {folder} {tmpdirname}')\n        os.chdir(tmpdirname)\n        os.system(f'git checkout -b {which_branch}')\n        os.system(\"git \" +\n                  \"-c user.name=submitty -c user.email=submitty@example.com commit \" +\n                  \"--allow-empty -m 'initial empty commit' \" +\n                  \"--author='submitty <submitty@example.com>'\")\n        os.system(f'git push origin {which_branch}')\n\n    print(f'Made new empty commit on branch {which_branch} in repo {folder}')", "func_src_after": "def add_empty_commit(folder,which_branch):\n\n    assert (os.path.isdir(folder))\n    os.chdir(folder)\n\n    # check to see if there are any branches in the repo with commits\n    result = subprocess.run(['git', 'branch', '-v'], stdout=subprocess.PIPE)\n    s = result.stdout.decode('utf-8')\n    if s != \"\":\n        # do nothing if there is at least one branch with a commit\n        print('NOTE: this repo is non-empty (has a commit on at least one branch)')\n        return\n\n    # otherwise clone to a non-bare repo and add an empty commit\n    # to the specified branch\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        subprocess.run(['git', 'clone', folder, tmpdirname])\n        os.chdir(tmpdirname)\n        subprocess.run(['git', 'checkout', '-b', which_branch])\n        subprocess.run(['git',\n            '-c', 'user.name=submitty',\n            '-c', 'user.email=submitty@example.com',\n            'commit', '--allow-empty',\n            '-m', 'initial empty commit',\n            '--author=submitty <submitty@example.com>'])\n        subprocess.run(['git', 'push', 'origin', which_branch])\n\n    print(f'Made new empty commit on branch {which_branch} in repo {folder}')", "line_changes": {"deleted": [{"line_no": 17, "char_start": 618, "char_end": 672, "line": "        os.system(f'git clone {folder} {tmpdirname}')\n"}, {"line_no": 19, "char_start": 701, "char_end": 754, "line": "        os.system(f'git checkout -b {which_branch}')\n"}, {"line_no": 20, "char_start": 754, "char_end": 781, "line": "        os.system(\"git \" +\n"}, {"line_no": 21, "char_start": 781, "char_end": 868, "line": "                  \"-c user.name=submitty -c user.email=submitty@example.com commit \" +\n"}, {"line_no": 22, "char_start": 868, "char_end": 931, "line": "                  \"--allow-empty -m 'initial empty commit' \" +\n"}, {"line_no": 23, "char_start": 931, "char_end": 995, "line": "                  \"--author='submitty <submitty@example.com>'\")\n"}, {"line_no": 24, "char_start": 995, "char_end": 1048, "line": "        os.system(f'git push origin {which_branch}')\n"}], "added": [{"line_no": 17, "char_start": 618, "char_end": 679, "line": "        subprocess.run(['git', 'clone', folder, tmpdirname])\n"}, {"line_no": 19, "char_start": 708, "char_end": 772, "line": "        subprocess.run(['git', 'checkout', '-b', which_branch])\n"}, {"line_no": 20, "char_start": 772, "char_end": 803, "line": "        subprocess.run(['git',\n"}, {"line_no": 21, "char_start": 803, "char_end": 843, "line": "            '-c', 'user.name=submitty',\n"}, {"line_no": 22, "char_start": 843, "char_end": 896, "line": "            '-c', 'user.email=submitty@example.com',\n"}, {"line_no": 23, "char_start": 896, "char_end": 935, "line": "            'commit', '--allow-empty',\n"}, {"line_no": 24, "char_start": 935, "char_end": 977, "line": "            '-m', 'initial empty commit',\n"}, {"line_no": 25, "char_start": 977, "char_end": 1034, "line": "            '--author=submitty <submitty@example.com>'])\n"}, {"line_no": 26, "char_start": 1034, "char_end": 1098, "line": "        subprocess.run(['git', 'push', 'origin', which_branch])\n"}]}, "char_changes": {"deleted": [{"char_start": 626, "char_end": 642, "chars": "os.system(f'git "}, {"char_start": 648, "char_end": 649, "chars": "{"}, {"char_start": 655, "char_end": 658, "chars": "} {"}, {"char_start": 668, "char_end": 670, "chars": "}'"}, {"char_start": 709, "char_end": 738, "chars": "os.system(f'git checkout -b {"}, {"char_start": 750, "char_end": 752, "chars": "}'"}, {"char_start": 762, "char_end": 785, "chars": "os.system(\"git \" +\n    "}, {"char_start": 797, "char_end": 803, "chars": "  \"-c "}, {"char_start": 821, "char_end": 825, "chars": " -c "}, {"char_start": 856, "char_end": 867, "chars": " commit \" +"}, {"char_start": 880, "char_end": 887, "chars": "      \""}, {"char_start": 900, "char_end": 903, "chars": " -m"}, {"char_start": 926, "char_end": 934, "chars": " \" +\n   "}, {"char_start": 946, "char_end": 950, "chars": "   \""}, {"char_start": 959, "char_end": 960, "chars": "'"}, {"char_start": 992, "char_end": 993, "chars": "\""}, {"char_start": 1003, "char_end": 1024, "chars": "os.system(f'git push "}, {"char_start": 1031, "char_end": 1032, "chars": "{"}, {"char_start": 1044, "char_end": 1046, "chars": "}'"}], "added": [{"char_start": 626, "char_end": 650, "chars": "subprocess.run(['git', '"}, {"char_start": 655, "char_end": 657, "chars": "',"}, {"char_start": 664, "char_end": 666, "chars": ", "}, {"char_start": 676, "char_end": 677, "chars": "]"}, {"char_start": 716, "char_end": 757, "chars": "subprocess.run(['git', 'checkout', '-b', "}, {"char_start": 769, "char_end": 770, "chars": "]"}, {"char_start": 780, "char_end": 802, "chars": "subprocess.run(['git',"}, {"char_start": 815, "char_end": 822, "chars": "'-c', '"}, {"char_start": 840, "char_end": 862, "chars": "',\n            '-c', '"}, {"char_start": 893, "char_end": 896, "chars": "',\n"}, {"char_start": 908, "char_end": 919, "chars": "'commit', '"}, {"char_start": 932, "char_end": 952, "chars": "',\n            '-m',"}, {"char_start": 975, "char_end": 976, "chars": ","}, {"char_start": 989, "char_end": 990, "chars": "'"}, {"char_start": 1031, "char_end": 1032, "chars": "]"}, {"char_start": 1042, "char_end": 1074, "chars": "subprocess.run(['git', 'push', '"}, {"char_start": 1080, "char_end": 1082, "chars": "',"}, {"char_start": 1095, "char_end": 1096, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to create an empty commit on a specified branch in a Git repository if the repository has no commits."}
{"func_name": "choose_volume", "func_src_before": "choose_volume(struct archive_read *a, struct iso9660 *iso9660)\n{\n\tstruct file_info *file;\n\tint64_t skipsize;\n\tstruct vd *vd;\n\tconst void *block;\n\tchar seenJoliet;\n\n\tvd = &(iso9660->primary);\n\tif (!iso9660->opt_support_joliet)\n\t\tiso9660->seenJoliet = 0;\n\tif (iso9660->seenJoliet &&\n\t\tvd->location > iso9660->joliet.location)\n\t\t/* This condition is unlikely; by way of caution. */\n\t\tvd = &(iso9660->joliet);\n\n\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n\tskipsize = __archive_read_consume(a, skipsize);\n\tif (skipsize < 0)\n\t\treturn ((int)skipsize);\n\tiso9660->current_position = skipsize;\n\n\tblock = __archive_read_ahead(a, vd->size, NULL);\n\tif (block == NULL) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Failed to read full block when scanning \"\n\t\t    \"ISO9660 directory list\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\t/*\n\t * While reading Root Directory, flag seenJoliet must be zero to\n\t * avoid converting special name 0x00(Current Directory) and\n\t * next byte to UCS2.\n\t */\n\tseenJoliet = iso9660->seenJoliet;/* Save flag. */\n\tiso9660->seenJoliet = 0;\n\tfile = parse_file_info(a, NULL, block);\n\tif (file == NULL)\n\t\treturn (ARCHIVE_FATAL);\n\tiso9660->seenJoliet = seenJoliet;\n\n\t/*\n\t * If the iso image has both RockRidge and Joliet, we preferentially\n\t * use RockRidge Extensions rather than Joliet ones.\n\t */\n\tif (vd == &(iso9660->primary) && iso9660->seenRockridge\n\t    && iso9660->seenJoliet)\n\t\tiso9660->seenJoliet = 0;\n\n\tif (vd == &(iso9660->primary) && !iso9660->seenRockridge\n\t    && iso9660->seenJoliet) {\n\t\t/* Switch reading data from primary to joliet. */\n\t\tvd = &(iso9660->joliet);\n\t\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n\t\tskipsize -= iso9660->current_position;\n\t\tskipsize = __archive_read_consume(a, skipsize);\n\t\tif (skipsize < 0)\n\t\t\treturn ((int)skipsize);\n\t\tiso9660->current_position += skipsize;\n\n\t\tblock = __archive_read_ahead(a, vd->size, NULL);\n\t\tif (block == NULL) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Failed to read full block when scanning \"\n\t\t\t    \"ISO9660 directory list\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tiso9660->seenJoliet = 0;\n\t\tfile = parse_file_info(a, NULL, block);\n\t\tif (file == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tiso9660->seenJoliet = seenJoliet;\n\t}\n\n\t/* Store the root directory in the pending list. */\n\tif (add_entry(a, iso9660, file) != ARCHIVE_OK)\n\t\treturn (ARCHIVE_FATAL);\n\tif (iso9660->seenRockridge) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660_ROCKRIDGE;\n\t\ta->archive.archive_format_name =\n\t\t    \"ISO9660 with Rockridge extensions\";\n\t}\n\n\treturn (ARCHIVE_OK);\n}", "func_src_after": "choose_volume(struct archive_read *a, struct iso9660 *iso9660)\n{\n\tstruct file_info *file;\n\tint64_t skipsize;\n\tstruct vd *vd;\n\tconst void *block;\n\tchar seenJoliet;\n\n\tvd = &(iso9660->primary);\n\tif (!iso9660->opt_support_joliet)\n\t\tiso9660->seenJoliet = 0;\n\tif (iso9660->seenJoliet &&\n\t\tvd->location > iso9660->joliet.location)\n\t\t/* This condition is unlikely; by way of caution. */\n\t\tvd = &(iso9660->joliet);\n\n\tskipsize = LOGICAL_BLOCK_SIZE * (int64_t)vd->location;\n\tskipsize = __archive_read_consume(a, skipsize);\n\tif (skipsize < 0)\n\t\treturn ((int)skipsize);\n\tiso9660->current_position = skipsize;\n\n\tblock = __archive_read_ahead(a, vd->size, NULL);\n\tif (block == NULL) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Failed to read full block when scanning \"\n\t\t    \"ISO9660 directory list\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\t/*\n\t * While reading Root Directory, flag seenJoliet must be zero to\n\t * avoid converting special name 0x00(Current Directory) and\n\t * next byte to UCS2.\n\t */\n\tseenJoliet = iso9660->seenJoliet;/* Save flag. */\n\tiso9660->seenJoliet = 0;\n\tfile = parse_file_info(a, NULL, block);\n\tif (file == NULL)\n\t\treturn (ARCHIVE_FATAL);\n\tiso9660->seenJoliet = seenJoliet;\n\n\t/*\n\t * If the iso image has both RockRidge and Joliet, we preferentially\n\t * use RockRidge Extensions rather than Joliet ones.\n\t */\n\tif (vd == &(iso9660->primary) && iso9660->seenRockridge\n\t    && iso9660->seenJoliet)\n\t\tiso9660->seenJoliet = 0;\n\n\tif (vd == &(iso9660->primary) && !iso9660->seenRockridge\n\t    && iso9660->seenJoliet) {\n\t\t/* Switch reading data from primary to joliet. */\n\t\tvd = &(iso9660->joliet);\n\t\tskipsize = LOGICAL_BLOCK_SIZE * (int64_t)vd->location;\n\t\tskipsize -= iso9660->current_position;\n\t\tskipsize = __archive_read_consume(a, skipsize);\n\t\tif (skipsize < 0)\n\t\t\treturn ((int)skipsize);\n\t\tiso9660->current_position += skipsize;\n\n\t\tblock = __archive_read_ahead(a, vd->size, NULL);\n\t\tif (block == NULL) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Failed to read full block when scanning \"\n\t\t\t    \"ISO9660 directory list\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tiso9660->seenJoliet = 0;\n\t\tfile = parse_file_info(a, NULL, block);\n\t\tif (file == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tiso9660->seenJoliet = seenJoliet;\n\t}\n\n\t/* Store the root directory in the pending list. */\n\tif (add_entry(a, iso9660, file) != ARCHIVE_OK)\n\t\treturn (ARCHIVE_FATAL);\n\tif (iso9660->seenRockridge) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660_ROCKRIDGE;\n\t\ta->archive.archive_format_name =\n\t\t    \"ISO9660 with Rockridge extensions\";\n\t}\n\n\treturn (ARCHIVE_OK);\n}", "commit_link": "github.com/libarchive/libarchive/commit/3ad08e01b4d253c66ae56414886089684155af22", "file_name": "libarchive/archive_read_support_format_iso9660.c", "vul_type": "cwe-190", "description": "In C, write a function `choose_volume` that selects the appropriate volume descriptor for an ISO9660 archive and reads the root directory block."}
{"func_name": "_read_clouds", "func_src_before": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "func_src_after": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.safe_load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 98, "char_end": 152, "line": "                self._clouds = yaml.load(clouds_file)\n"}], "added": [{"line_no": 4, "char_start": 98, "char_end": 157, "line": "                self._clouds = yaml.safe_load(clouds_file)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 134, "char_end": 139, "chars": "safe_"}]}, "commit_link": "github.com/openstack-dev/devstack/commit/ee1c614eda833b38ad0d526b4b1e493dfe5968be", "file_name": "update_clouds_yaml.py", "vul_type": "cwe-502", "commit_msg": "Fix use of yaml.load()\n\nThe use of this function has been deprecated for a long time[0]. With\nPyYAML==6.0 the call is now failing, so replace it with the safe\nversion.\n\n[0] https://msg.pyyaml.org/load\n\nSigned-off-by: Jens Harbott <frickler@offenerstapel.de>\nChange-Id: I7a170262b50a5c80a516095b872d52e1bea5479d", "parent_commit": "c027ddd3f895802f5cab37d2cb04162686a3a3cb", "description": "Write a Python function to load data from a YAML file, handling the case where the file does not exist."}
{"func_name": "WritePSDChannel", "func_src_before": "static size_t WritePSDChannel(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const QuantumType quantum_type, unsigned char *compact_pixels,\n  MagickOffsetType size_offset,const MagickBooleanType separate,\n  ExceptionInfo *exception)\n{\n  int\n    y;\n\n  MagickBooleanType\n    monochrome;\n\n  QuantumInfo\n    *quantum_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count,\n    length;\n\n  unsigned char\n    *pixels;\n\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n\n#define CHUNK 16384\n\n  int\n    flush,\n    level;\n\n  unsigned char\n    *compressed_pixels;\n\n  z_stream\n    stream;\n\n  compressed_pixels=(unsigned char *) NULL;\n  flush=Z_NO_FLUSH;\n#endif\n  count=0;\n  if (separate != MagickFalse)\n    {\n      size_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,1);\n    }\n  if (next_image->depth > 8)\n    next_image->depth=16;\n  monochrome=IsImageMonochrome(image) && (image->depth == 1) ?\n    MagickTrue : MagickFalse;\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    return(0);\n  pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      compressed_pixels=(unsigned char *) AcquireQuantumMemory(CHUNK,\n        sizeof(*compressed_pixels));\n      if (compressed_pixels == (unsigned char *) NULL)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n      ResetMagickMemory(&stream,0,sizeof(stream));\n      stream.data_type=Z_BINARY;\n      level=Z_DEFAULT_COMPRESSION;\n      if ((image_info->quality > 0 && image_info->quality < 10))\n        level=(int) image_info->quality;\n      if (deflateInit(&stream,level) != Z_OK)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n    }\n#endif\n  for (y=0; y < (ssize_t) next_image->rows; y++)\n  {\n    p=GetVirtualPixels(next_image,0,y,next_image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    length=ExportQuantumPixels(next_image,(CacheView *) NULL,quantum_info,\n      quantum_type,pixels,exception);\n    if (monochrome != MagickFalse)\n      for (i=0; i < (ssize_t) length; i++)\n        pixels[i]=(~pixels[i]);\n    if (next_image->compression == RLECompression)\n      {\n        length=PSDPackbitsEncodeImage(image,length,pixels,compact_pixels,\n          exception);\n        count+=WriteBlob(image,length,compact_pixels);\n        size_offset+=WritePSDOffset(psd_info,image,length,size_offset);\n      }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n    else if (next_image->compression == ZipCompression)\n      {\n        stream.avail_in=(uInt) length;\n        stream.next_in=(Bytef *) pixels;\n        if (y == (ssize_t) next_image->rows-1)\n          flush=Z_FINISH;\n        do {\n            stream.avail_out=(uInt) CHUNK;\n            stream.next_out=(Bytef *) compressed_pixels;\n            if (deflate(&stream,flush) == Z_STREAM_ERROR)\n              break;\n            length=(size_t) CHUNK-stream.avail_out;\n            if (length > 0)\n              count+=WriteBlob(image,length,compressed_pixels);\n        } while (stream.avail_out == 0);\n      }\n#endif\n    else\n      count+=WriteBlob(image,length,pixels);\n  }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      (void) deflateEnd(&stream);\n      compressed_pixels=(unsigned char *) RelinquishMagickMemory(\n        compressed_pixels);\n    }\n#endif\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  return(count);\n}", "func_src_after": "static size_t WritePSDChannel(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const QuantumType quantum_type, unsigned char *compact_pixels,\n  MagickOffsetType size_offset,const MagickBooleanType separate,\n  ExceptionInfo *exception)\n{\n  int\n    y;\n\n  MagickBooleanType\n    monochrome;\n\n  QuantumInfo\n    *quantum_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count,\n    length;\n\n  unsigned char\n    *pixels;\n\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n\n#define CHUNK 16384\n\n  int\n    flush,\n    level;\n\n  unsigned char\n    *compressed_pixels;\n\n  z_stream\n    stream;\n\n  compressed_pixels=(unsigned char *) NULL;\n  flush=Z_NO_FLUSH;\n#endif\n  count=0;\n  if (separate != MagickFalse)\n    {\n      size_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,1);\n    }\n  if (next_image->depth > 8)\n    next_image->depth=16;\n  monochrome=IsImageMonochrome(image) && (image->depth == 1) ?\n    MagickTrue : MagickFalse;\n  quantum_info=AcquireQuantumInfo(image_info,next_image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    return(0);\n  pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      compressed_pixels=(unsigned char *) AcquireQuantumMemory(CHUNK,\n        sizeof(*compressed_pixels));\n      if (compressed_pixels == (unsigned char *) NULL)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n      ResetMagickMemory(&stream,0,sizeof(stream));\n      stream.data_type=Z_BINARY;\n      level=Z_DEFAULT_COMPRESSION;\n      if ((image_info->quality > 0 && image_info->quality < 10))\n        level=(int) image_info->quality;\n      if (deflateInit(&stream,level) != Z_OK)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n    }\n#endif\n  for (y=0; y < (ssize_t) next_image->rows; y++)\n  {\n    p=GetVirtualPixels(next_image,0,y,next_image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    length=ExportQuantumPixels(next_image,(CacheView *) NULL,quantum_info,\n      quantum_type,pixels,exception);\n    if (monochrome != MagickFalse)\n      for (i=0; i < (ssize_t) length; i++)\n        pixels[i]=(~pixels[i]);\n    if (next_image->compression == RLECompression)\n      {\n        length=PSDPackbitsEncodeImage(image,length,pixels,compact_pixels,\n          exception);\n        count+=WriteBlob(image,length,compact_pixels);\n        size_offset+=WritePSDOffset(psd_info,image,length,size_offset);\n      }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n    else if (next_image->compression == ZipCompression)\n      {\n        stream.avail_in=(uInt) length;\n        stream.next_in=(Bytef *) pixels;\n        if (y == (ssize_t) next_image->rows-1)\n          flush=Z_FINISH;\n        do {\n            stream.avail_out=(uInt) CHUNK;\n            stream.next_out=(Bytef *) compressed_pixels;\n            if (deflate(&stream,flush) == Z_STREAM_ERROR)\n              break;\n            length=(size_t) CHUNK-stream.avail_out;\n            if (length > 0)\n              count+=WriteBlob(image,length,compressed_pixels);\n        } while (stream.avail_out == 0);\n      }\n#endif\n    else\n      count+=WriteBlob(image,length,pixels);\n  }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      (void) deflateEnd(&stream);\n      compressed_pixels=(unsigned char *) RelinquishMagickMemory(\n        compressed_pixels);\n    }\n#endif\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  return(count);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/91cc3f36f2ccbd485a0456bab9aebe63b635da88", "file_name": "coders/psd.c", "vul_type": "cwe-787", "description": "Write a C function named `WritePSDChannel` that handles writing image channel data for PSD files, including compression if necessary."}
{"func_name": "testPrintTensorsToFile", "func_src_before": "  def testPrintTensorsToFile(self):\n    tmpfile_name = tempfile.mktemp(\".printv2_test\")\n    tensor_0 = math_ops.range(0, 10)\n    print_op_0 = logging_ops.print_v2(tensor_0,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_0)\n    tensor_1 = math_ops.range(11, 20)\n    print_op_1 = logging_ops.print_v2(tensor_1,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_1)\n    try:\n      f = open(tmpfile_name, \"r\")\n      line_0 = f.readline()\n      expected_0 = \"[0 1 2 ... 7 8 9]\"\n      self.assertTrue(expected_0 in line_0)\n      line_1 = f.readline()\n      expected_1 = \"[11 12 13 ... 17 18 19]\"\n      self.assertTrue(expected_1 in line_1)\n      f.close()\n      os.remove(tmpfile_name)\n    except IOError as e:\n      self.fail(e)", "func_src_after": "  def testPrintTensorsToFile(self):\n    _, tmpfile_name = tempfile.mkstemp(\n        \".printv2_test\")  # safe to ignore fd here\n    tensor_0 = math_ops.range(0, 10)\n    print_op_0 = logging_ops.print_v2(tensor_0,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_0)\n    tensor_1 = math_ops.range(11, 20)\n    print_op_1 = logging_ops.print_v2(tensor_1,\n                                      output_stream=\"file://\"+tmpfile_name)\n    self.evaluate(print_op_1)\n    try:\n      f = open(tmpfile_name, \"r\")\n      line_0 = f.readline()\n      expected_0 = \"[0 1 2 ... 7 8 9]\"\n      self.assertTrue(expected_0 in line_0)\n      line_1 = f.readline()\n      expected_1 = \"[11 12 13 ... 17 18 19]\"\n      self.assertTrue(expected_1 in line_1)\n      f.close()\n      os.remove(tmpfile_name)\n    except IOError as e:\n      self.fail(e)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 36, "char_end": 88, "line": "    tmpfile_name = tempfile.mktemp(\".printv2_test\")\n"}], "added": [{"line_no": 2, "char_start": 36, "char_end": 76, "line": "    _, tmpfile_name = tempfile.mkstemp(\n"}, {"line_no": 3, "char_start": 76, "char_end": 127, "line": "        \".printv2_test\")  # safe to ignore fd here\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 39, "char_end": 42, "chars": " _,"}, {"char_start": 69, "char_end": 70, "chars": "s"}, {"char_start": 75, "char_end": 84, "chars": "\n        "}, {"char_start": 100, "char_end": 126, "chars": "  # safe to ignore fd here"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/247aaafbe7f689492797d92430e77443b011876c", "file_name": "logging_ops_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420360036\nChange-Id: I13eb94736af3397261cf0d46214ddb5a2af9d92b", "description": "Write a Python function to print two ranges of numbers to a temporary file and verify the output."}
{"func_name": "tensorflow::GraphConstructor::MakeEdge", "func_src_before": "Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                  int input_index) {\n  DataType src_out = src->output_type(output_index);\n  DataType dst_in = dst->input_type(input_index);\n  if (!TypesCompatible(dst_in, src_out)) {\n    return errors::InvalidArgument(\n        \"Input \", input_index, \" of node \", dst->name(), \" was passed \",\n        DataTypeString(src_out), \" from \", src->name(), \":\", output_index,\n        \" incompatible with expected \", DataTypeString(dst_in), \".\");\n  }\n  g_->AddEdge(src, output_index, dst, input_index);\n  return Status::OK();\n}", "func_src_after": "Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                  int input_index) {\n  if (output_index >= src->num_outputs()) {\n    return errors::InvalidArgument(\n        \"Output \", output_index, \" of node \", src->name(),\n        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");\n  }\n  if (input_index >= dst->num_inputs()) {\n    return errors::InvalidArgument(\n        \"Input \", input_index, \" of node \", dst->name(),\n        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");\n  }\n\n  DataType src_out = src->output_type(output_index);\n  DataType dst_in = dst->input_type(input_index);\n  if (!TypesCompatible(dst_in, src_out)) {\n    return errors::InvalidArgument(\n        \"Input \", input_index, \" of node \", dst->name(), \" was passed \",\n        DataTypeString(src_out), \" from \", src->name(), \":\", output_index,\n        \" incompatible with expected \", DataTypeString(dst_in), \".\");\n  }\n  g_->AddEdge(src, output_index, dst, input_index);\n  return Status::OK();\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/0cc38aaa4064fd9e79101994ce9872c6d91f816b", "file_name": "tensorflow/core/common_runtime/graph_constructor.cc", "vul_type": "cwe-125", "description": "Write a C++ function `MakeEdge` that connects two nodes in a graph, checking for type compatibility and the existence of specified input and output indices."}
{"func_name": "handle_file", "func_src_before": "def handle_file(u: Profile, headline: str, category: str, text: str, file):\n    m: Media = Media()\n    upload_base_path: str = 'uploads/' + str(date.today().year)\n    high_res_file_name = upload_base_path + '/HIGHRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    low_res_file_name = upload_base_path + '/LOWRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    if not os.path.exists(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path):\n        os.makedirs(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path)\n    with open(high_res_file_name, 'wb+') as destination:\n        for chunk in file.chunks():\n            destination.write(chunk)\n    # TODO crop image\n    original = Image.open(high_res_file_name)\n    width, height = original.size\n    diameter = math.sqrt(math.pow(width, 2) + math.pow(height, 2))\n    width /= diameter\n    height /= diameter\n    width *= IMAGE_SCALE\n    height *= IMAGE_SCALE\n    cropped = original.resize((int(width), int(height)), PIL.Image.LANCZOS)\n    cropped.save(low_res_file_name)\n    m.text = text\n    m.cachedText = compile_markdown(text)\n    m.category = category\n    m.highResFile = \"/\" + high_res_file_name\n    m.lowResFile = \"/\" + low_res_file_name\n    m.headline = headline\n    m.save()\n    mu: MediaUpload = MediaUpload()\n    mu.UID = u\n    mu.MID = m\n    mu.save()\n    logging.info(\"Uploaded file '\" + str(file.name) + \"' and cropped it. The resulting PK is \" + str(m.pk))", "func_src_after": "def handle_file(u: Profile, headline: str, category: str, text: str, file):\n    m: Media = Media()\n    upload_base_path: str = 'uploads/' + str(date.today().year)\n    high_res_file_name = upload_base_path + '/HIGHRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    low_res_file_name = upload_base_path + '/LOWRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    if not os.path.exists(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path):\n        os.makedirs(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path)\n    with open(high_res_file_name, 'wb+') as destination:\n        for chunk in file.chunks():\n            destination.write(chunk)\n    # TODO crop image\n    original = Image.open(high_res_file_name)\n    width, height = original.size\n    diameter = math.sqrt(math.pow(width, 2) + math.pow(height, 2))\n    width /= diameter\n    height /= diameter\n    width *= IMAGE_SCALE\n    height *= IMAGE_SCALE\n    cropped = original.resize((int(width), int(height)), PIL.Image.LANCZOS)\n    cropped.save(low_res_file_name)\n    m.text = escape(text)\n    m.cachedText = compile_markdown(escape(text))\n    m.category = escape(category)\n    m.highResFile = \"/\" + high_res_file_name\n    m.lowResFile = \"/\" + low_res_file_name\n    m.headline = escape(headline)\n    m.save()\n    mu: MediaUpload = MediaUpload()\n    mu.UID = u\n    mu.MID = m\n    mu.save()\n    logging.info(\"Uploaded file '\" + str(file.name) + \"' and cropped it. The resulting PK is \" + str(m.pk))", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/mediatools/media_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle media file uploads, including image resizing and metadata processing."}
{"func_name": "get_top_popular", "func_src_before": "def get_top_popular(top_num):\r\n    \"\"\" query the top(top_num) popular articles\r\n        top_num => list of [title, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT title, views FROM articles\r\n             INNER JOIN (\r\n             SELECT path, count(path) AS views\r\n             FROM log GROUP BY log.path\r\n             ) AS log\r\n             ON log.path = '/article/' || articles.slug\r\n             ORDER BY views DESC\r\n             LIMIT {}\"\"\".format(top_num)\r\n    return execute_query(cmd)", "func_src_after": "def get_top_popular(top_num):\r\n    \"\"\" query the top(top_num) popular articles\r\n        top_num => list of [title, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT title, views FROM articles\r\n             INNER JOIN (\r\n             SELECT path, count(path) AS views\r\n             FROM log GROUP BY log.path\r\n             ) AS log\r\n             ON log.path = '/article/' || articles.slug\r\n             ORDER BY views DESC\r\n             LIMIT %s\"\"\"\r\n    data = [top_num, ]\r\n    return execute_query(cmd, data)", "commit_link": "github.com/thugasin/udacity-homework-logAnalyzer/commit/506f25f9a1caee7f17034adf7c75e0efbc88082b", "file_name": "logAnalyzerDb.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the top N most viewed articles from a database, using SQL queries with parameter substitution."}
{"func_name": "variables", "func_src_before": "    @expose('/variables/<form>', methods=[\"GET\", \"POST\"])\n    @login_required\n    @wwwutils.action_logging\n    def variables(self, form):\n        try:\n            if request.method == 'POST':\n                data = request.json\n                if data:\n                    session = settings.Session()\n                    var = models.Variable(key=form, val=json.dumps(data))\n                    session.add(var)\n                    session.commit()\n                return \"\"\n            else:\n                return self.render(\n                    'airflow/variables/{}.html'.format(form)\n                )\n        except:\n            return (\"Error: form airflow/variables/{}.html \"\n                    \"not found.\").format(form), 404", "func_src_after": "    @expose('/variables/<form>', methods=[\"GET\", \"POST\"])\n    @login_required\n    @wwwutils.action_logging\n    def variables(self, form):\n        try:\n            if request.method == 'POST':\n                data = request.json\n                if data:\n                    session = settings.Session()\n                    var = models.Variable(key=form, val=json.dumps(data))\n                    session.add(var)\n                    session.commit()\n                return \"\"\n            else:\n                return self.render(\n                    'airflow/variables/{}.html'.format(form)\n                )\n        except:\n            # prevent XSS\n            form = escape(form)\n            return (\"Error: form airflow/variables/{}.html \"\n                    \"not found.\").format(form), 404", "line_changes": {"deleted": [], "added": [{"line_no": 20, "char_start": 651, "char_end": 683, "line": "            form = escape(form)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 625, "char_end": 683, "chars": "            # prevent XSS\n            form = escape(form)\n"}]}, "commit_link": "github.com/Twistbioscience/incubator-airflow/commit/e1a2d74c0045c9231f7a5365c956b8e048dd6af3", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "[AIRFLOW-1617] Fix XSS vulnerability in Variable endpoint\n\nIn case a Variable form was accessed by a get request and\nthe form did not exist as a template, the input was\nreturned as is to the user.\n\nCloses #2611 from bolkedebruin/xss_fix", "parent_commit": "d8da8bec4fdcae29a89606ba1bd2c4bdd292d8d5", "description": "Create a Python Flask web handler for managing variables that allows users to submit data via POST and view a form via GET, with user authentication and action logging."}
{"func_name": "test", "func_src_before": "@mod.route('/test', methods=['GET', 'POST'])\ndef test():\n    user_id = session['logged_id']\n    sql = 'SELECT * FROM message where user_id = %d ORDER BY c_time DESC' \\\n        % (user_id)\n    cursor.execute(sql)\n    m = cursor.fetchall()\n    print(m)", "func_src_after": "@mod.route('/test', methods=['GET', 'POST'])\ndef test():\n    user_id = session['logged_id']\n    cursor.execute('SELECT * FROM message where user_id = %s ORDER BY c_time DESC', (user_id,))\n    m = cursor.fetchall()\n    print(m)", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089", "description": "Create a Python Flask route function that retrieves and prints all messages for the logged-in user, ordered by creation time in descending order."}
{"func_name": "update_date_modified", "func_src_before": "  def update_date_modified(self):\n    sql = \"UPDATE jdk_entries \" + \\\n      \"SET date_last_modified = \" + CURRENT_DATESTAMP + \" \" + \\\n      \"WHERE jdk_entries.id = '\" + self.entry_id + \"';\"\n    \n    db_execute(sql)\n\n    return None", "func_src_after": "  def update_date_modified(self):\n    quote_tuple = CURRENT_DATESTAMP, self.entry_id\n\n    sql = \"UPDATE jdk_entries \" + \\\n      \"SET date_last_modified = ? \" + \\\n      \"WHERE jdk_entries.id = ?;\"\n    \n    db_execute(sql, quote_tuple)\n\n    return None", "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089", "description": "Write a Python function to update the 'date_last_modified' field of a 'jdk_entries' table for a specific entry ID using SQL."}
{"func_name": "test_get_iscsi_ip", "func_src_before": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = 'showvlun -a -host fakehost'\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = 'showvlun -a -showcols Port'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "func_src_after": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = ['showvlun', '-a', '-host', 'fakehost']\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = ['showvlun', '-a', '-showcols', 'Port']\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands to retrieve iSCSI IP information and asserts the expected IP address."}
{"func_name": "change_pass", "func_src_before": "    def change_pass(self, new_pass, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET password = '{}'\n            WHERE client_id = '{}'\n        \"\"\".format(new_pass, logged_user.get_client_id())\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql)\n        self.__conn.commit()", "func_src_after": "    def change_pass(self, new_pass, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET password = ?\n            WHERE client_id = ?\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql, (new_pass, logged_user.get_client_id()))\n        self.__conn.commit()", "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089", "description": "Write a Python function to update a client's password in the database given a new password and the logged-in user object."}
{"func_name": "gen_signed_cert", "func_src_before": "def gen_signed_cert(domain, ca_crt, ca_key, ca_pass, certs_folder):\n    \"\"\"\n    This function takes a domain name as a parameter and then creates a certificate and key with the\n    domain name(replacing dots by underscores), finally signing the certificate using specified CA and\n    returns the path of key and cert files. If you are yet to generate a CA then check the top comments\n    \"\"\"\n    key_path = os.path.join(certs_folder, re.sub('[^-0-9a-zA-Z_]', '_', domain) + \".key\")\n    cert_path = os.path.join(certs_folder, re.sub('[^-0-9a-zA-Z_]', '_', domain) + \".crt\")\n\n    # The first conditions checks if file exists, and does nothing if true\n    # If file doenst exist lock is obtained for writing (Other processes in race must wait)\n    # After obtaining lock another check to handle race conditions gracefully\n    if os.path.exists(key_path) and os.path.exists(cert_path):\n        pass\n    else:\n        with FileLock(cert_path, timeout=2):\n            # Check happens if the certificate and key pair already exists for a domain\n            if os.path.exists(key_path) and os.path.exists(cert_path):\n                pass\n            else:\n                # Serial Generation - Serial number must be unique for each certificate,\n                # so serial is generated based on domain name\n                md5_hash = hashlib.md5()\n                md5_hash.update(domain)\n                serial = int(md5_hash.hexdigest(), 36)\n\n                # The CA stuff is loaded from the same folder as this script\n                ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM, open(ca_crt).read())\n                # The last parameter is the password for your CA key file\n                ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, open(ca_key).read(), ca_pass)\n\n                key = crypto.PKey()\n                key.generate_key(crypto.TYPE_RSA, 2048)\n\n                cert = crypto.X509()\n                cert.get_subject().C = \"IN\"\n                cert.get_subject().ST = \"AP\"\n                cert.get_subject().L = \"127.0.0.1\"\n                cert.get_subject().O = \"OWTF\"\n                cert.get_subject().OU = \"Inbound-Proxy\"\n                cert.get_subject().CN = domain\n                cert.gmtime_adj_notBefore(0)\n                cert.gmtime_adj_notAfter(365 * 24 * 60 * 60)\n                cert.set_serial_number(serial)\n                cert.set_issuer(ca_cert.get_subject())\n                cert.set_pubkey(key)\n                cert.sign(ca_key, \"sha1\")\n\n                # The key and cert files are dumped and their paths are returned\n                domain_key = open(key_path, \"w\")\n                domain_key.write(crypto.dump_privatekey(crypto.FILETYPE_PEM, key))\n\n                domain_cert = open(cert_path, \"w\")\n                domain_cert.write(crypto.dump_certificate(crypto.FILETYPE_PEM, cert))\n    return key_path, cert_path", "func_src_after": "def gen_signed_cert(domain, ca_crt, ca_key, ca_pass, certs_folder):\n    \"\"\"\n    This function takes a domain name as a parameter and then creates a certificate and key with the\n    domain name(replacing dots by underscores), finally signing the certificate using specified CA and\n    returns the path of key and cert files. If you are yet to generate a CA then check the top comments\n    \"\"\"\n    key_path = os.path.join(certs_folder, re.sub('[^-0-9a-zA-Z_]', '_', domain) + \".key\")\n    cert_path = os.path.join(certs_folder, re.sub('[^-0-9a-zA-Z_]', '_', domain) + \".crt\")\n\n    # The first conditions checks if file exists, and does nothing if true\n    # If file doenst exist lock is obtained for writing (Other processes in race must wait)\n    # After obtaining lock another check to handle race conditions gracefully\n    if os.path.exists(key_path) and os.path.exists(cert_path):\n        pass\n    else:\n        with FileLock(cert_path, timeout=2):\n            # Check happens if the certificate and key pair already exists for a domain\n            if os.path.exists(key_path) and os.path.exists(cert_path):\n                pass\n            else:\n                # Serial Generation - Serial number must be unique for each certificate,\n                # so serial is generated based on domain name\n                md5_hash = hashlib.md5()\n                md5_hash.update(domain)\n                serial = int(md5_hash.hexdigest(), 36)\n\n                # The CA stuff is loaded from the same folder as this script\n                ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM, open(ca_crt, 'rb').read())\n                # The last parameter is the password for your CA key file\n                ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, open(ca_key, 'rb').read(), passphrase=ca_pass)\n\n                key = crypto.PKey()\n                key.generate_key(crypto.TYPE_RSA, 2048)\n\n                cert = crypto.X509()\n                cert.get_subject().C = \"IN\"\n                cert.get_subject().ST = \"AP\"\n                cert.get_subject().L = \"127.0.0.1\"\n                cert.get_subject().O = \"OWTF\"\n                cert.get_subject().OU = \"Inbound-Proxy\"\n                cert.get_subject().CN = domain\n                cert.gmtime_adj_notBefore(0)\n                cert.gmtime_adj_notAfter(365 * 24 * 60 * 60)\n                cert.set_serial_number(serial)\n                cert.set_issuer(ca_cert.get_subject())\n                cert.set_pubkey(key)\n                cert.sign(ca_key, \"sha1\")\n\n                # The key and cert files are dumped and their paths are returned\n                domain_key = open(key_path, \"w\")\n                domain_key.write(crypto.dump_privatekey(crypto.FILETYPE_PEM, key))\n\n                domain_cert = open(cert_path, \"w\")\n                domain_cert.write(crypto.dump_certificate(crypto.FILETYPE_PEM, cert))\n    return key_path, cert_path", "line_changes": {"deleted": [{"line_no": 28, "char_start": 1513, "char_end": 1605, "line": "                ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM, open(ca_crt).read())\n"}, {"line_no": 30, "char_start": 1679, "char_end": 1778, "line": "                ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, open(ca_key).read(), ca_pass)\n"}], "added": [{"line_no": 28, "char_start": 1513, "char_end": 1611, "line": "                ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM, open(ca_crt, 'rb').read())\n"}, {"line_no": 30, "char_start": 1685, "char_end": 1801, "line": "                ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, open(ca_key, 'rb').read(), passphrase=ca_pass)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1595, "char_end": 1601, "chars": ", 'rb'"}, {"char_start": 1765, "char_end": 1771, "chars": ", 'rb'"}, {"char_start": 1781, "char_end": 1792, "chars": "passphrase="}]}, "commit_link": "github.com/owtf/owtf/commit/e945dbde9b0c388b252e32eedbe94e1d20212a4d", "file_name": "gen_cert.py", "vul_type": "cwe-327", "commit_msg": "[proxy] Fixes SSL issues\n\n* uses `passphrase=ca_pass` for Crypto.load_private_key\n* Since Tornado 4.2, SSLIOStream.connect has validated SSL certificates\n  by default. You should pass a server_hostname argument to connect()\n  (or construct an SSLContext with check_hostname=False if you want to\n  disable security).\n\n Also, you shouldn't call ssl.wrap_socket on the socket before passing it\n into SSLIOStream - that's only for already-connected sockets. If you're\n calling connect(), Tornado will do the ssl wrapping for you.\n For more reference, see\n https://github.com/tornadoweb/tornado/issues/1672", "description": "In Python, write a function to generate and sign a domain-specific SSL certificate using a given CA."}
{"func_name": "self.get_taxon_concept_id", "func_src_before": "  def self.get_taxon_concept_id(hierarchy_entry_id)\n    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id};\")\n    if he.count > 0\n      return he.first.taxon_concept_id\n    else\n      return 0\n    end\n  end", "func_src_after": "  def self.get_taxon_concept_id(hierarchy_entry_id)\n    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id.to_i};\")\n    if he.count > 0\n      return he.first.taxon_concept_id\n    else\n      return 0\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 52, "char_end": 160, "line": "    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id};\")\n"}], "added": [{"line_no": 2, "char_start": 52, "char_end": 110, "line": "    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n"}, {"line_no": 3, "char_start": 110, "char_end": 223, "line": "    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id.to_i};\")\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 52, "char_end": 110, "chars": "    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n"}, {"char_start": 213, "char_end": 218, "chars": ".to_i"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Write a Ruby method to fetch a taxon concept ID from a database using a hierarchy entry ID."}
{"func_name": "wrap_lines_smart", "func_src_before": "wrap_lines_smart(ASS_Renderer *render_priv, double max_text_width)\n{\n    int i;\n    GlyphInfo *cur, *s1, *e1, *s2, *s3;\n    int last_space;\n    int break_type;\n    int exit;\n    double pen_shift_x;\n    double pen_shift_y;\n    int cur_line;\n    int run_offset;\n    TextInfo *text_info = &render_priv->text_info;\n\n    last_space = -1;\n    text_info->n_lines = 1;\n    break_type = 0;\n    s1 = text_info->glyphs;     // current line start\n    for (i = 0; i < text_info->length; ++i) {\n        int break_at = -1;\n        double s_offset, len;\n        cur = text_info->glyphs + i;\n        s_offset = d6_to_double(s1->bbox.xMin + s1->pos.x);\n        len = d6_to_double(cur->bbox.xMax + cur->pos.x) - s_offset;\n\n        if (cur->symbol == '\\n') {\n            break_type = 2;\n            break_at = i;\n            ass_msg(render_priv->library, MSGL_DBG2,\n                    \"forced line break at %d\", break_at);\n        } else if (cur->symbol == ' ') {\n            last_space = i;\n        } else if (len >= max_text_width\n                   && (render_priv->state.wrap_style != 2)) {\n            break_type = 1;\n            break_at = last_space;\n            if (break_at >= 0)\n                ass_msg(render_priv->library, MSGL_DBG2, \"line break at %d\",\n                        break_at);\n        }\n\n        if (break_at != -1) {\n            // need to use one more line\n            // marking break_at+1 as start of a new line\n            int lead = break_at + 1;    // the first symbol of the new line\n            if (text_info->n_lines >= text_info->max_lines) {\n                // Raise maximum number of lines\n                text_info->max_lines *= 2;\n                text_info->lines = realloc(text_info->lines,\n                                           sizeof(LineInfo) *\n                                           text_info->max_lines);\n            }\n            if (lead < text_info->length) {\n                text_info->glyphs[lead].linebreak = break_type;\n                last_space = -1;\n                s1 = text_info->glyphs + lead;\n                text_info->n_lines++;\n            }\n        }\n    }\n#define DIFF(x,y) (((x) < (y)) ? (y - x) : (x - y))\n    exit = 0;\n    while (!exit && render_priv->state.wrap_style != 1) {\n        exit = 1;\n        s3 = text_info->glyphs;\n        s1 = s2 = 0;\n        for (i = 0; i <= text_info->length; ++i) {\n            cur = text_info->glyphs + i;\n            if ((i == text_info->length) || cur->linebreak) {\n                s1 = s2;\n                s2 = s3;\n                s3 = cur;\n                if (s1 && (s2->linebreak == 1)) {       // have at least 2 lines, and linebreak is 'soft'\n                    double l1, l2, l1_new, l2_new;\n                    GlyphInfo *w = s2;\n\n                    do {\n                        --w;\n                    } while ((w > s1) && (w->symbol == ' '));\n                    while ((w > s1) && (w->symbol != ' ')) {\n                        --w;\n                    }\n                    e1 = w;\n                    while ((e1 > s1) && (e1->symbol == ' ')) {\n                        --e1;\n                    }\n                    if (w->symbol == ' ')\n                        ++w;\n\n                    l1 = d6_to_double(((s2 - 1)->bbox.xMax + (s2 - 1)->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2 = d6_to_double(((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (s2->bbox.xMin + s2->pos.x));\n                    l1_new = d6_to_double(\n                        (e1->bbox.xMax + e1->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2_new = d6_to_double(\n                        ((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (w->bbox.xMin + w->pos.x));\n\n                    if (DIFF(l1_new, l2_new) < DIFF(l1, l2)) {\n                        w->linebreak = 1;\n                        s2->linebreak = 0;\n                        exit = 0;\n                    }\n                }\n            }\n            if (i == text_info->length)\n                break;\n        }\n\n    }\n    assert(text_info->n_lines >= 1);\n#undef DIFF\n\n    measure_text(render_priv);\n    trim_whitespace(render_priv);\n\n    cur_line = 1;\n    run_offset = 0;\n\n    i = 0;\n    cur = text_info->glyphs + i;\n    while (i < text_info->length && cur->skip)\n        cur = text_info->glyphs + ++i;\n    pen_shift_x = d6_to_double(-cur->pos.x);\n    pen_shift_y = 0.;\n\n    for (i = 0; i < text_info->length; ++i) {\n        cur = text_info->glyphs + i;\n        if (cur->linebreak) {\n            while (i < text_info->length && cur->skip && cur->symbol != '\\n')\n                cur = text_info->glyphs + ++i;\n            double height =\n                text_info->lines[cur_line - 1].desc +\n                text_info->lines[cur_line].asc;\n            text_info->lines[cur_line - 1].len = i -\n                text_info->lines[cur_line - 1].offset;\n            text_info->lines[cur_line].offset = i;\n            cur_line++;\n            run_offset++;\n            pen_shift_x = d6_to_double(-cur->pos.x);\n            pen_shift_y += height + render_priv->settings.line_spacing;\n        }\n        cur->pos.x += double_to_d6(pen_shift_x);\n        cur->pos.y += double_to_d6(pen_shift_y);\n    }\n    text_info->lines[cur_line - 1].len =\n        text_info->length - text_info->lines[cur_line - 1].offset;\n\n#if 0\n    // print line info\n    for (i = 0; i < text_info->n_lines; i++) {\n        printf(\"line %d offset %d length %d\\n\", i, text_info->lines[i].offset,\n                text_info->lines[i].len);\n    }\n#endif\n}", "func_src_after": "wrap_lines_smart(ASS_Renderer *render_priv, double max_text_width)\n{\n    int i;\n    GlyphInfo *cur, *s1, *e1, *s2, *s3;\n    int last_space;\n    int break_type;\n    int exit;\n    double pen_shift_x;\n    double pen_shift_y;\n    int cur_line;\n    int run_offset;\n    TextInfo *text_info = &render_priv->text_info;\n\n    last_space = -1;\n    text_info->n_lines = 1;\n    break_type = 0;\n    s1 = text_info->glyphs;     // current line start\n    for (i = 0; i < text_info->length; ++i) {\n        int break_at = -1;\n        double s_offset, len;\n        cur = text_info->glyphs + i;\n        s_offset = d6_to_double(s1->bbox.xMin + s1->pos.x);\n        len = d6_to_double(cur->bbox.xMax + cur->pos.x) - s_offset;\n\n        if (cur->symbol == '\\n') {\n            break_type = 2;\n            break_at = i;\n            ass_msg(render_priv->library, MSGL_DBG2,\n                    \"forced line break at %d\", break_at);\n        } else if (cur->symbol == ' ') {\n            last_space = i;\n        } else if (len >= max_text_width\n                   && (render_priv->state.wrap_style != 2)) {\n            break_type = 1;\n            break_at = last_space;\n            if (break_at >= 0)\n                ass_msg(render_priv->library, MSGL_DBG2, \"line break at %d\",\n                        break_at);\n        }\n\n        if (break_at != -1) {\n            // need to use one more line\n            // marking break_at+1 as start of a new line\n            int lead = break_at + 1;    // the first symbol of the new line\n            if (text_info->n_lines >= text_info->max_lines) {\n                // Raise maximum number of lines\n                text_info->max_lines *= 2;\n                text_info->lines = realloc(text_info->lines,\n                                           sizeof(LineInfo) *\n                                           text_info->max_lines);\n            }\n            if (lead < text_info->length) {\n                text_info->glyphs[lead].linebreak = break_type;\n                last_space = -1;\n                s1 = text_info->glyphs + lead;\n                text_info->n_lines++;\n            }\n        }\n    }\n#define DIFF(x,y) (((x) < (y)) ? (y - x) : (x - y))\n    exit = 0;\n    while (!exit && render_priv->state.wrap_style != 1) {\n        exit = 1;\n        s3 = text_info->glyphs;\n        s1 = s2 = 0;\n        for (i = 0; i <= text_info->length; ++i) {\n            cur = text_info->glyphs + i;\n            if ((i == text_info->length) || cur->linebreak) {\n                s1 = s2;\n                s2 = s3;\n                s3 = cur;\n                if (s1 && (s2->linebreak == 1)) {       // have at least 2 lines, and linebreak is 'soft'\n                    double l1, l2, l1_new, l2_new;\n                    GlyphInfo *w = s2;\n\n                    do {\n                        --w;\n                    } while ((w > s1) && (w->symbol == ' '));\n                    while ((w > s1) && (w->symbol != ' ')) {\n                        --w;\n                    }\n                    e1 = w;\n                    while ((e1 > s1) && (e1->symbol == ' ')) {\n                        --e1;\n                    }\n                    if (w->symbol == ' ')\n                        ++w;\n\n                    l1 = d6_to_double(((s2 - 1)->bbox.xMax + (s2 - 1)->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2 = d6_to_double(((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (s2->bbox.xMin + s2->pos.x));\n                    l1_new = d6_to_double(\n                        (e1->bbox.xMax + e1->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2_new = d6_to_double(\n                        ((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (w->bbox.xMin + w->pos.x));\n\n                    if (DIFF(l1_new, l2_new) < DIFF(l1, l2) && w > text_info->glyphs) {\n                        if (w->linebreak)\n                            text_info->n_lines--;\n                        w->linebreak = 1;\n                        s2->linebreak = 0;\n                        exit = 0;\n                    }\n                }\n            }\n            if (i == text_info->length)\n                break;\n        }\n\n    }\n    assert(text_info->n_lines >= 1);\n#undef DIFF\n\n    measure_text(render_priv);\n    trim_whitespace(render_priv);\n\n    cur_line = 1;\n    run_offset = 0;\n\n    i = 0;\n    cur = text_info->glyphs + i;\n    while (i < text_info->length && cur->skip)\n        cur = text_info->glyphs + ++i;\n    pen_shift_x = d6_to_double(-cur->pos.x);\n    pen_shift_y = 0.;\n\n    for (i = 0; i < text_info->length; ++i) {\n        cur = text_info->glyphs + i;\n        if (cur->linebreak) {\n            while (i < text_info->length && cur->skip && cur->symbol != '\\n')\n                cur = text_info->glyphs + ++i;\n            double height =\n                text_info->lines[cur_line - 1].desc +\n                text_info->lines[cur_line].asc;\n            text_info->lines[cur_line - 1].len = i -\n                text_info->lines[cur_line - 1].offset;\n            text_info->lines[cur_line].offset = i;\n            cur_line++;\n            run_offset++;\n            pen_shift_x = d6_to_double(-cur->pos.x);\n            pen_shift_y += height + render_priv->settings.line_spacing;\n        }\n        cur->pos.x += double_to_d6(pen_shift_x);\n        cur->pos.y += double_to_d6(pen_shift_y);\n    }\n    text_info->lines[cur_line - 1].len =\n        text_info->length - text_info->lines[cur_line - 1].offset;\n\n#if 0\n    // print line info\n    for (i = 0; i < text_info->n_lines; i++) {\n        printf(\"line %d offset %d length %d\\n\", i, text_info->lines[i].offset,\n                text_info->lines[i].len);\n    }\n#endif\n}", "commit_link": "github.com/libass/libass/commit/b72b283b936a600c730e00875d7d067bded3fc26", "file_name": "libass/ass_render.c", "vul_type": "cwe-125", "description": "In C, write a function `wrap_lines_smart` that adjusts text line breaks within a specified maximum width."}
{"func_name": "dd_exist", "func_src_before": "int dd_exist(const struct dump_dir *dd, const char *path)\n{\n    char *full_path = concat_path_file(dd->dd_dirname, path);\n    int ret = exist_file_dir(full_path);\n    free(full_path);\n    return ret;\n}", "func_src_after": "int dd_exist(const struct dump_dir *dd, const char *path)\n{\n    if (!str_is_correct_filename(path))\n        error_msg_and_die(\"Cannot test existence. '%s' is not a valid file name\", path);\n\n    char *full_path = concat_path_file(dd->dd_dirname, path);\n    int ret = exist_file_dir(full_path);\n    free(full_path);\n    return ret;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_exist` that checks if a file exists within a directory structure represented by a `dump_dir` structure, and handles invalid filenames with an error message."}
{"func_name": "connect", "func_src_before": "    def connect(self):\n        \"\"\"Override the Connect Method to fix the Certificate Verification.\"\"\"\n        # Add certificate verification\n        conn = self._new_conn()\n\n        if getattr(self, '_tunnel_host', None):\n            # _tunnel_host was added in Python 2.6.3\n            # (See: http://hg.python.org/cpython/rev/0f57b30a152f)\n\n            self.sock = conn\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            #\n            # disable pylint because pylint doesn't support importing\n            # from six.moves yet. see:\n            # https://bitbucket.org/logilab/pylint/issue/550/\n            self._tunnel()  # pylint: disable=E1101\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n        # The RECENT_DATE is originally taken from requests. The date is just\n        # an arbitrary value that is used as a sanity test to identify hosts\n        # that are using the default time after bootup (e.g. 1970), and\n        # provides information for debugging\n        RECENT_DATE = datetime.date(2014, 1, 1)\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            LOG.warning('System time is way off (before %s). This will '\n                        'probably lead to SSL verification errors.',\n                        RECENT_DATE)\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        self.sock = ssl.wrap_socket(conn)\n\n        self._verify_cert(self.sock, self.ca_certs)\n        self.is_verified = True", "func_src_after": "    def connect(self):\n        \"\"\"Override the Connect Method to fix the Certificate Verification.\"\"\"\n        # Add certificate verification\n        conn = self._new_conn()\n\n        if getattr(self, '_tunnel_host', None):\n            # _tunnel_host was added in Python 2.6.3\n            # (See: http://hg.python.org/cpython/rev/0f57b30a152f)\n\n            self.sock = conn\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            #\n            # disable pylint because pylint doesn't support importing\n            # from six.moves yet. see:\n            # https://bitbucket.org/logilab/pylint/issue/550/\n            self._tunnel()  # pylint: disable=E1101\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n        # The RECENT_DATE is originally taken from requests. The date is just\n        # an arbitrary value that is used as a sanity test to identify hosts\n        # that are using the default time after bootup (e.g. 1970), and\n        # provides information for debugging\n        RECENT_DATE = datetime.date(2014, 1, 1)\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            LOG.warning('System time is way off (before %s). This will '\n                        'probably lead to SSL verification errors.',\n                        RECENT_DATE)\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        self.sock = ssl.SSLContext.wrap_socket(conn)\n\n        self._verify_cert(self.sock, self.ca_certs)\n        self.is_verified = True", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1464, "char_end": 1506, "line": "        self.sock = ssl.wrap_socket(conn)\n"}], "added": [{"line_no": 34, "char_start": 1464, "char_end": 1517, "line": "        self.sock = ssl.SSLContext.wrap_socket(conn)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1488, "char_end": 1499, "chars": "SSLContext."}]}, "commit_link": "github.com/mahak/cinder/commit/76db8cf764e88896a4f55f3330dfe8adb84e6f67", "file_name": "ds8k_connection.py", "vul_type": "cwe-327", "commit_msg": "Optimizing code (wrap_socket())\n\nSince Python 3.2 and 2.7.9, it is recommended\nto use the SSLContext.wrap_socket() instead of\nwrap_socket().\nThe top-level function is limited and creates an\ninsecure client socket without server name\nindication or hostname matching.\n\nRef : https://docs.python.org/3/library/ssl.html#ssl.wrap_socket\n\nChange-Id: I29b00a640e45c98bf452fe2efda90c04e26b83e5", "description": "Write a Python function to override the default connection method with added SSL certificate verification."}
{"func_name": "decode_pointer_field", "func_src_before": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                (*size)++;\n                if (!allocate_field(stream, field->pField, field->data_size, *size))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size - 1);\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "func_src_after": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                if (!allocate_field(stream, field->pField, field->data_size, (size_t)(*size + 1)))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size);\n                (*size)++;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "commit_link": "github.com/nanopb/nanopb/commit/45582f1f97f49e2abfdba1463d1e1027682d9856", "file_name": "pb_decode.c", "vul_type": "cwe-125", "description": "Write a C function named `decode_pointer_field` that decodes a field from a protocol buffer stream, handling different field types and memory allocation."}
{"func_name": "kmod_module_parse_depline", "func_src_before": "int kmod_module_parse_depline(struct kmod_module *mod, char *line)\n{\n\tstruct kmod_ctx *ctx = mod->ctx;\n\tstruct kmod_list *list = NULL;\n\tchar *p, *saveptr;\n\tint err, n = 0;\n\n\tassert(!mod->init.dep && mod->dep == NULL);\n\tmod->init.dep = true;\n\n\tp = strchr(line, ':');\n\tif (p == NULL)\n\t\treturn 0;\n\n\t*p = '\\0';\n\tif (mod->path == NULL)\n\t\tmod->path = strdup(line);\n\n\tp++;\n\n\tfor (p = strtok_r(p, \" \\t\", &saveptr); p != NULL;\n\t\t\t\t\tp = strtok_r(NULL, \" \\t\", &saveptr)) {\n\t\tconst char *modname = path_to_modname(p, NULL, NULL);\n\t\tstruct kmod_module *depmod;\n\n\t\terr = kmod_module_new_from_name(ctx, modname, &depmod);\n\t\tif (err < 0) {\n\t\t\tERR(ctx, \"ctx=%p modname=%s error=%s\\n\",\n\t\t\t\t\t\tctx, modname, strerror(-err));\n\t\t\tgoto fail;\n\t\t}\n\n\t\tDBG(ctx, \"add dep: %s\\n\", modname);\n\n\t\tlist = kmod_list_append(list, depmod);\n\t\tn++;\n\t}\n\n\tDBG(ctx, \"%d dependencies for %s\\n\", n, mod->name);\n\n\tmod->dep = list;\n\treturn n;\n\nfail:\n\tkmod_module_unref_list(list);\n\tmod->init.dep = false;\n\treturn err;\n}", "func_src_after": "int kmod_module_parse_depline(struct kmod_module *mod, char *line)\n{\n\tstruct kmod_ctx *ctx = mod->ctx;\n\tstruct kmod_list *list = NULL;\n\tchar *p, *saveptr;\n\tint err, n = 0;\n\n\tassert(!mod->init.dep && mod->dep == NULL);\n\tmod->init.dep = true;\n\n\tp = strchr(line, ':');\n\tif (p == NULL)\n\t\treturn 0;\n\n\t*p = '\\0';\n\tif (mod->path == NULL)\n\t\tmod->path = strdup(line);\n\n\tp++;\n\n\tfor (p = strtok_r(p, \" \\t\", &saveptr); p != NULL;\n\t\t\t\t\tp = strtok_r(NULL, \" \\t\", &saveptr)) {\n\t\tchar buf[NAME_MAX];\n\t\tconst char *modname = path_to_modname(p, buf, NULL);\n\t\tstruct kmod_module *depmod;\n\n\t\terr = kmod_module_new_from_name(ctx, modname, &depmod);\n\t\tif (err < 0) {\n\t\t\tERR(ctx, \"ctx=%p modname=%s error=%s\\n\",\n\t\t\t\t\t\tctx, modname, strerror(-err));\n\t\t\tgoto fail;\n\t\t}\n\n\t\tDBG(ctx, \"add dep: %s\\n\", modname);\n\n\t\tlist = kmod_list_append(list, depmod);\n\t\tn++;\n\t}\n\n\tDBG(ctx, \"%d dependencies for %s\\n\", n, mod->name);\n\n\tmod->dep = list;\n\treturn n;\n\nfail:\n\tkmod_module_unref_list(list);\n\tmod->init.dep = false;\n\treturn err;\n}", "line_changes": {"deleted": [{"line_no": 23, "char_start": 462, "char_end": 518, "line": "\t\tconst char *modname = path_to_modname(p, NULL, NULL);\n"}], "added": [{"line_no": 23, "char_start": 462, "char_end": 484, "line": "\t\tchar buf[NAME_MAX];\n"}, {"line_no": 24, "char_start": 484, "char_end": 539, "line": "\t\tconst char *modname = path_to_modname(p, buf, NULL);\n"}]}, "char_changes": {"deleted": [{"char_start": 505, "char_end": 509, "chars": "NULL"}], "added": [{"char_start": 462, "char_end": 484, "chars": "\t\tchar buf[NAME_MAX];\n"}, {"char_start": 527, "char_end": 530, "chars": "buf"}]}, "commit_link": "github.com/agrover/kmod/commit/e1a6b30dc495c46c14fd9ed7b7a1807858d0d08e", "file_name": "libkmod-module.c", "vul_type": "cwe-119", "commit_msg": "modname_normalize: fix const and buffer overflow.\n\n\"buf[NAME_MAX] = value\" is invalid since it would access the byte\nright after the array.\n\nAlso fix the const of modname, do not mess with it to avoid mistakes.", "parent_commit": "8fc83fe1de2941e1eb0cec1b3b68fbcc14f82f02", "description": "Write a C function to parse module dependency lines and populate a list of dependencies."}
{"func_name": "create_cf_base", "func_src_before": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table \" + i + \" (problems INTEGER, diff CHAR)\")\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "func_src_after": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table ? (problems INTEGER, diff CHAR)\", (i,))\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createcfbase.py", "vul_type": "cwe-089", "description": "Write a Python function to scrape Codeforces problemset data and store it in a SQLite database."}
{"func_name": "MAPIPrint", "func_src_before": "void MAPIPrint(MAPIProps *p) {\n  int j, i, index, h, x;\n  DDWORD *ddword_ptr;\n  DDWORD ddword_tmp;\n  dtr thedate;\n  MAPIProperty *mapi;\n  variableLength *mapidata;\n  variableLength vlTemp;\n  int found;\n\n  for (j = 0; j < p->count; j++) {\n    mapi = &(p->properties[j]);\n    printf(\"   #%i: Type: [\", j);\n    switch (PROP_TYPE(mapi->id)) {\n      case PT_UNSPECIFIED:\n        printf(\"  NONE   \"); break;\n      case PT_NULL:\n        printf(\"  NULL   \"); break;\n      case PT_I2:\n        printf(\"   I2    \"); break;\n      case PT_LONG:\n        printf(\"  LONG   \"); break;\n      case PT_R4:\n        printf(\"   R4    \"); break;\n      case PT_DOUBLE:\n        printf(\" DOUBLE  \"); break;\n      case PT_CURRENCY:\n        printf(\"CURRENCY \"); break;\n      case PT_APPTIME:\n        printf(\"APP TIME \"); break;\n      case PT_ERROR:\n        printf(\"  ERROR  \"); break;\n      case PT_BOOLEAN:\n        printf(\" BOOLEAN \"); break;\n      case PT_OBJECT:\n        printf(\" OBJECT  \"); break;\n      case PT_I8:\n        printf(\"   I8    \"); break;\n      case PT_STRING8:\n        printf(\" STRING8 \"); break;\n      case PT_UNICODE:\n        printf(\" UNICODE \"); break;\n      case PT_SYSTIME:\n        printf(\"SYS TIME \"); break;\n      case PT_CLSID:\n        printf(\"OLE GUID \"); break;\n      case PT_BINARY:\n        printf(\" BINARY  \"); break;\n      default:\n        printf(\"<%x>\", PROP_TYPE(mapi->id)); break;\n    }\n\n    printf(\"]  Code: [\");\n    if (mapi->custom == 1) {\n      printf(\"UD:x%04x\", PROP_ID(mapi->id));\n    } else {\n      found = 0;\n      for (index = 0; index < sizeof(MPList) / sizeof(MAPIPropertyTagList); index++) {\n        if ((MPList[index].id == PROP_ID(mapi->id)) && (found == 0)) {\n          printf(\"%s\", MPList[index].name);\n          found = 1;\n        }\n      }\n      if (found == 0) {\n        printf(\"0x%04x\", PROP_ID(mapi->id));\n      }\n    }\n    printf(\"]\\n\");\n    if (mapi->namedproperty > 0) {\n      for (i = 0; i < mapi->namedproperty; i++) {\n        printf(\"    Name: %s\\n\", mapi->propnames[i].data);\n      }\n    }\n    for (i = 0; i < mapi->count; i++) {\n      mapidata = &(mapi->data[i]);\n      if (mapi->count > 1) {\n        printf(\"    [%i/%u] \", i, mapi->count);\n      } else {\n        printf(\"    \");\n      }\n      printf(\"Size: %i\", mapidata->size);\n      switch (PROP_TYPE(mapi->id)) {\n        case PT_SYSTIME:\n          MAPISysTimetoDTR(mapidata->data, &thedate);\n          printf(\"    Value: \");\n          ddword_tmp = *((DDWORD *)mapidata->data);\n          TNEFPrintDate(thedate);\n          printf(\" [HEX: \");\n          for (x = 0; x < sizeof(ddword_tmp); x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"] (%llu)\\n\", ddword_tmp);\n          break;\n        case PT_LONG:\n          printf(\"    Value: %li\\n\", *((long*)mapidata->data));\n          break;\n        case PT_I2:\n          printf(\"    Value: %hi\\n\", *((short int*)mapidata->data));\n          break;\n        case PT_BOOLEAN:\n          if (mapi->data->data[0] != 0) {\n            printf(\"    Value: True\\n\");\n          } else {\n            printf(\"    Value: False\\n\");\n          }\n          break;\n        case PT_OBJECT:\n          printf(\"\\n\");\n          break;\n        case PT_BINARY:\n          if (IsCompressedRTF(mapidata) == 1) {\n            printf(\"    Detected Compressed RTF. \");\n            printf(\"Decompressed text follows\\n\");\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n            if ((vlTemp.data = (BYTE*)DecompressRTF(mapidata, &(vlTemp.size))) != NULL) {\n              printf(\"%s\\n\", vlTemp.data);\n              free(vlTemp.data);\n            }\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n          } else {\n            printf(\"    Value: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_STRING8:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n          if (strlen((char*)mapidata->data) != mapidata->size - 1) {\n            printf(\"Detected Hidden data: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_CLSID:\n          printf(\"    Value: \");\n          printf(\"[HEX: \");\n          for(x=0; x< 16; x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"]\\n\");\n          break;\n        default:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n      }\n    }\n  }\n}", "func_src_after": "void MAPIPrint(MAPIProps *p) {\n  int j, i, index, h, x;\n  DDWORD *ddword_ptr;\n  DDWORD ddword_tmp;\n  dtr thedate;\n  MAPIProperty *mapi;\n  variableLength *mapidata;\n  variableLength vlTemp;\n  int found;\n\n  for (j = 0; j < p->count; j++) {\n    mapi = &(p->properties[j]);\n    printf(\"   #%i: Type: [\", j);\n    switch (PROP_TYPE(mapi->id)) {\n      case PT_UNSPECIFIED:\n        printf(\"  NONE   \"); break;\n      case PT_NULL:\n        printf(\"  NULL   \"); break;\n      case PT_I2:\n        printf(\"   I2    \"); break;\n      case PT_LONG:\n        printf(\"  LONG   \"); break;\n      case PT_R4:\n        printf(\"   R4    \"); break;\n      case PT_DOUBLE:\n        printf(\" DOUBLE  \"); break;\n      case PT_CURRENCY:\n        printf(\"CURRENCY \"); break;\n      case PT_APPTIME:\n        printf(\"APP TIME \"); break;\n      case PT_ERROR:\n        printf(\"  ERROR  \"); break;\n      case PT_BOOLEAN:\n        printf(\" BOOLEAN \"); break;\n      case PT_OBJECT:\n        printf(\" OBJECT  \"); break;\n      case PT_I8:\n        printf(\"   I8    \"); break;\n      case PT_STRING8:\n        printf(\" STRING8 \"); break;\n      case PT_UNICODE:\n        printf(\" UNICODE \"); break;\n      case PT_SYSTIME:\n        printf(\"SYS TIME \"); break;\n      case PT_CLSID:\n        printf(\"OLE GUID \"); break;\n      case PT_BINARY:\n        printf(\" BINARY  \"); break;\n      default:\n        printf(\"<%x>\", PROP_TYPE(mapi->id)); break;\n    }\n\n    printf(\"]  Code: [\");\n    if (mapi->custom == 1) {\n      printf(\"UD:x%04x\", PROP_ID(mapi->id));\n    } else {\n      found = 0;\n      for (index = 0; index < sizeof(MPList) / sizeof(MAPIPropertyTagList); index++) {\n        if ((MPList[index].id == PROP_ID(mapi->id)) && (found == 0)) {\n          printf(\"%s\", MPList[index].name);\n          found = 1;\n        }\n      }\n      if (found == 0) {\n        printf(\"0x%04x\", PROP_ID(mapi->id));\n      }\n    }\n    printf(\"]\\n\");\n    if (mapi->namedproperty > 0) {\n      for (i = 0; i < mapi->namedproperty; i++) {\n        printf(\"    Name: %s\\n\", mapi->propnames[i].data);\n      }\n    }\n    for (i = 0; i < mapi->count; i++) {\n      mapidata = &(mapi->data[i]);\n      if (mapi->count > 1) {\n        printf(\"    [%i/%u] \", i, mapi->count);\n      } else {\n        printf(\"    \");\n      }\n      printf(\"Size: %i\", mapidata->size);\n      switch (PROP_TYPE(mapi->id)) {\n        case PT_SYSTIME:\n          MAPISysTimetoDTR(mapidata->data, &thedate);\n          printf(\"    Value: \");\n          ddword_tmp = *((DDWORD *)mapidata->data);\n          TNEFPrintDate(thedate);\n          printf(\" [HEX: \");\n          for (x = 0; x < sizeof(ddword_tmp); x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"] (%llu)\\n\", ddword_tmp);\n          break;\n        case PT_LONG:\n          printf(\"    Value: %i\\n\", *((int*)mapidata->data));\n          break;\n        case PT_I2:\n          printf(\"    Value: %hi\\n\", *((short int*)mapidata->data));\n          break;\n        case PT_BOOLEAN:\n          if (mapi->data->data[0] != 0) {\n            printf(\"    Value: True\\n\");\n          } else {\n            printf(\"    Value: False\\n\");\n          }\n          break;\n        case PT_OBJECT:\n          printf(\"\\n\");\n          break;\n        case PT_BINARY:\n          if (IsCompressedRTF(mapidata) == 1) {\n            printf(\"    Detected Compressed RTF. \");\n            printf(\"Decompressed text follows\\n\");\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n            if ((vlTemp.data = (BYTE*)DecompressRTF(mapidata, &(vlTemp.size))) != NULL) {\n              printf(\"%s\\n\", vlTemp.data);\n              free(vlTemp.data);\n            }\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n          } else {\n            printf(\"    Value: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_STRING8:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n          if (strlen((char*)mapidata->data) != mapidata->size - 1) {\n            printf(\"Detected Hidden data: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_CLSID:\n          printf(\"    Value: \");\n          printf(\"[HEX: \");\n          for(x=0; x< 16; x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"]\\n\");\n          break;\n        default:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n      }\n    }\n  }\n}", "commit_link": "github.com/Yeraze/ytnef/commit/f98f5d4adc1c4bd4033638f6167c1bb95d642f89", "file_name": "lib/ytnef.c", "vul_type": "cwe-125", "description": "Write a C function named `MAPIPrint` that prints the properties and values of a given `MAPIProps` structure."}
{"func_name": "parse_str", "func_src_before": "module.exports = function parse_str (str, array) { // eslint-disable-line camelcase\n  //       discuss at: https://locutus.io/php/parse_str/\n  //      original by: Cagri Ekin\n  //      improved by: Michael White (https://getsprink.com)\n  //      improved by: Jack\n  //      improved by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: Onno Marsman (https://twitter.com/onnomarsman)\n  //      bugfixed by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: stag019\n  //      bugfixed by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: MIO_KODUKI (https://mio-koduki.blogspot.com/)\n  // reimplemented by: stag019\n  //         input by: Dreamer\n  //         input by: Zaide (https://zaidesthings.com/)\n  //         input by: David Pesta (https://davidpesta.com/)\n  //         input by: jeicquest\n  //      bugfixed by: Rafa\u0142 Kukawski\n  //           note 1: When no argument is specified, will put variables in global scope.\n  //           note 1: When a particular argument has been passed, and the\n  //           note 1: returned value is different parse_str of PHP.\n  //           note 1: For example, a=b=c&d====c\n  //        example 1: var $arr = {}\n  //        example 1: parse_str('first=foo&second=bar', $arr)\n  //        example 1: var $result = $arr\n  //        returns 1: { first: 'foo', second: 'bar' }\n  //        example 2: var $arr = {}\n  //        example 2: parse_str('str_a=Jack+and+Jill+didn%27t+see+the+well.', $arr)\n  //        example 2: var $result = $arr\n  //        returns 2: { str_a: \"Jack and Jill didn't see the well.\" }\n  //        example 3: var $abc = {3:'a'}\n  //        example 3: parse_str('a[b][\"c\"]=def&a[q]=t+5', $abc)\n  //        example 3: var $result = $abc\n  //        returns 3: {\"3\":\"a\",\"a\":{\"b\":{\"c\":\"def\"},\"q\":\"t 5\"}}\n  //        example 4: var $arr = {}\n  //        example 4: parse_str('a[][]=value', $arr)\n  //        example 4: var $result = $arr\n  //        returns 4: {\"a\":{\"0\":{\"0\":\"value\"}}}\n  //        example 5: var $arr = {}\n  //        example 5: parse_str('a=1&a[]=2', $arr)\n  //        example 5: var $result = $arr\n  //        returns 5: {\"a\":{\"0\":\"2\"}}\n\n  var strArr = String(str).replace(/^&/, '').replace(/&$/, '').split('&')\n  var sal = strArr.length\n  var i\n  var j\n  var ct\n  var p\n  var lastObj\n  var obj\n  var chr\n  var tmp\n  var key\n  var value\n  var postLeftBracketPos\n  var keys\n  var keysLen\n\n  var _fixStr = function (str) {\n    return decodeURIComponent(str.replace(/\\+/g, '%20'))\n  }\n\n  var $global = (typeof window !== 'undefined' ? window : global)\n  $global.$locutus = $global.$locutus || {}\n  var $locutus = $global.$locutus\n  $locutus.php = $locutus.php || {}\n\n  if (!array) {\n    array = $global\n  }\n\n  for (i = 0; i < sal; i++) {\n    tmp = strArr[i].split('=')\n    key = _fixStr(tmp[0])\n    value = (tmp.length < 2) ? '' : _fixStr(tmp[1])\n\n    while (key.charAt(0) === ' ') {\n      key = key.slice(1)\n    }\n\n    if (key.indexOf('\\x00') > -1) {\n      key = key.slice(0, key.indexOf('\\x00'))\n    }\n\n    if (key && key.charAt(0) !== '[') {\n      keys = []\n      postLeftBracketPos = 0\n\n      for (j = 0; j < key.length; j++) {\n        if (key.charAt(j) === '[' && !postLeftBracketPos) {\n          postLeftBracketPos = j + 1\n        } else if (key.charAt(j) === ']') {\n          if (postLeftBracketPos) {\n            if (!keys.length) {\n              keys.push(key.slice(0, postLeftBracketPos - 1))\n            }\n\n            keys.push(key.substr(postLeftBracketPos, j - postLeftBracketPos))\n            postLeftBracketPos = 0\n\n            if (key.charAt(j + 1) !== '[') {\n              break\n            }\n          }\n        }\n      }\n\n      if (!keys.length) {\n        keys = [key]\n      }\n\n      for (j = 0; j < keys[0].length; j++) {\n        chr = keys[0].charAt(j)\n\n        if (chr === ' ' || chr === '.' || chr === '[') {\n          keys[0] = keys[0].substr(0, j) + '_' + keys[0].substr(j + 1)\n        }\n\n        if (chr === '[') {\n          break\n        }\n      }\n\n      obj = array\n\n      for (j = 0, keysLen = keys.length; j < keysLen; j++) {\n        key = keys[j].replace(/^['\"]/, '').replace(/['\"]$/, '')\n        lastObj = obj\n\n        if ((key === '' || key === ' ') && j !== 0) {\n          // Insert new dimension\n          ct = -1\n\n          for (p in obj) {\n            if (obj.hasOwnProperty(p)) {\n              if (+p > ct && p.match(/^\\d+$/g)) {\n                ct = +p\n              }\n            }\n          }\n\n          key = ct + 1\n        }\n\n        // if primitive value, replace with object\n        if (Object(obj[key]) !== obj[key]) {\n          obj[key] = {}\n        }\n\n        obj = obj[key]\n      }\n\n      lastObj[key] = value\n    }\n  }\n}", "func_src_after": "module.exports = function parse_str (str, array) { // eslint-disable-line camelcase\n  //       discuss at: https://locutus.io/php/parse_str/\n  //      original by: Cagri Ekin\n  //      improved by: Michael White (https://getsprink.com)\n  //      improved by: Jack\n  //      improved by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: Onno Marsman (https://twitter.com/onnomarsman)\n  //      bugfixed by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: stag019\n  //      bugfixed by: Brett Zamir (https://brett-zamir.me)\n  //      bugfixed by: MIO_KODUKI (https://mio-koduki.blogspot.com/)\n  // reimplemented by: stag019\n  //         input by: Dreamer\n  //         input by: Zaide (https://zaidesthings.com/)\n  //         input by: David Pesta (https://davidpesta.com/)\n  //         input by: jeicquest\n  //      bugfixed by: Rafa\u0142 Kukawski\n  //           note 1: When no argument is specified, will put variables in global scope.\n  //           note 1: When a particular argument has been passed, and the\n  //           note 1: returned value is different parse_str of PHP.\n  //           note 1: For example, a=b=c&d====c\n  //        example 1: var $arr = {}\n  //        example 1: parse_str('first=foo&second=bar', $arr)\n  //        example 1: var $result = $arr\n  //        returns 1: { first: 'foo', second: 'bar' }\n  //        example 2: var $arr = {}\n  //        example 2: parse_str('str_a=Jack+and+Jill+didn%27t+see+the+well.', $arr)\n  //        example 2: var $result = $arr\n  //        returns 2: { str_a: \"Jack and Jill didn't see the well.\" }\n  //        example 3: var $abc = {3:'a'}\n  //        example 3: parse_str('a[b][\"c\"]=def&a[q]=t+5', $abc)\n  //        example 3: var $result = $abc\n  //        returns 3: {\"3\":\"a\",\"a\":{\"b\":{\"c\":\"def\"},\"q\":\"t 5\"}}\n  //        example 4: var $arr = {}\n  //        example 4: parse_str('a[][]=value', $arr)\n  //        example 4: var $result = $arr\n  //        returns 4: {\"a\":{\"0\":{\"0\":\"value\"}}}\n  //        example 5: var $arr = {}\n  //        example 5: parse_str('a=1&a[]=2', $arr)\n  //        example 5: var $result = $arr\n  //        returns 5: {\"a\":{\"0\":\"2\"}}\n\n  var strArr = String(str).replace(/^&/, '').replace(/&$/, '').split('&')\n  var sal = strArr.length\n  var i\n  var j\n  var ct\n  var p\n  var lastObj\n  var obj\n  var chr\n  var tmp\n  var key\n  var value\n  var postLeftBracketPos\n  var keys\n  var keysLen\n\n  var _fixStr = function (str) {\n    return decodeURIComponent(str.replace(/\\+/g, '%20'))\n  }\n\n  var $global = (typeof window !== 'undefined' ? window : global)\n  $global.$locutus = $global.$locutus || {}\n  var $locutus = $global.$locutus\n  $locutus.php = $locutus.php || {}\n\n  if (!array) {\n    array = $global\n  }\n\n  for (i = 0; i < sal; i++) {\n    tmp = strArr[i].split('=')\n    key = _fixStr(tmp[0])\n    value = (tmp.length < 2) ? '' : _fixStr(tmp[1])\n\n    if (key.includes('__proto__') || key.includes('constructor') || key.includes('prototype')) {\n      break;\n    }\n\n    while (key.charAt(0) === ' ') {\n      key = key.slice(1)\n    }\n\n    if (key.indexOf('\\x00') > -1) {\n      key = key.slice(0, key.indexOf('\\x00'))\n    }\n\n    if (key && key.charAt(0) !== '[') {\n      keys = []\n      postLeftBracketPos = 0\n\n      for (j = 0; j < key.length; j++) {\n        if (key.charAt(j) === '[' && !postLeftBracketPos) {\n          postLeftBracketPos = j + 1\n        } else if (key.charAt(j) === ']') {\n          if (postLeftBracketPos) {\n            if (!keys.length) {\n              keys.push(key.slice(0, postLeftBracketPos - 1))\n            }\n\n            keys.push(key.substr(postLeftBracketPos, j - postLeftBracketPos))\n            postLeftBracketPos = 0\n\n            if (key.charAt(j + 1) !== '[') {\n              break\n            }\n          }\n        }\n      }\n\n      if (!keys.length) {\n        keys = [key]\n      }\n\n      for (j = 0; j < keys[0].length; j++) {\n        chr = keys[0].charAt(j)\n\n        if (chr === ' ' || chr === '.' || chr === '[') {\n          keys[0] = keys[0].substr(0, j) + '_' + keys[0].substr(j + 1)\n        }\n\n        if (chr === '[') {\n          break\n        }\n      }\n\n      obj = array\n\n      for (j = 0, keysLen = keys.length; j < keysLen; j++) {\n        key = keys[j].replace(/^['\"]/, '').replace(/['\"]$/, '')\n        lastObj = obj\n\n        if ((key === '' || key === ' ') && j !== 0) {\n          // Insert new dimension\n          ct = -1\n\n          for (p in obj) {\n            if (obj.hasOwnProperty(p)) {\n              if (+p > ct && p.match(/^\\d+$/g)) {\n                ct = +p\n              }\n            }\n          }\n\n          key = ct + 1\n        }\n\n        // if primitive value, replace with object\n        if (Object(obj[key]) !== obj[key]) {\n          obj[key] = {}\n        }\n\n        obj = obj[key]\n      }\n\n      lastObj[key] = value\n    }\n  }\n}", "line_changes": {"deleted": [], "added": [{"line_no": 77, "char_start": 2854, "char_end": 2951, "line": "    if (key.includes('__proto__') || key.includes('constructor') || key.includes('prototype')) {\n"}, {"line_no": 78, "char_start": 2951, "char_end": 2964, "line": "      break;\n"}, {"line_no": 79, "char_start": 2964, "char_end": 2970, "line": "    }\n"}, {"line_no": 80, "char_start": 2970, "char_end": 2971, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2854, "char_end": 2971, "chars": "    if (key.includes('__proto__') || key.includes('constructor') || key.includes('prototype')) {\n      break;\n    }\n\n"}]}, "commit_link": "github.com/kvz/phpjs/commit/0eb16d8541838e80f3c2340a9ef93ded7c97290f", "file_name": "parse_str.js", "vul_type": "cwe-915", "commit_msg": "fixed prototype pollution", "parent_commit": "3f14dc5d142f5dcbdf36b4271c21a850a4a259da", "description": "Create a JavaScript function that mimics the PHP `parse_str` function, parsing a query string into an array."}
{"func_name": "tflite::GetOptionalInputTensor", "func_src_before": "const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                           const TfLiteNode* node, int index) {\n  const bool use_tensor = index < node->inputs->size &&\n                          node->inputs->data[index] != kTfLiteOptionalTensor;\n  if (use_tensor) {\n    return GetMutableInput(context, node, index);\n  }\n  return nullptr;\n}", "func_src_after": "const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                           const TfLiteNode* node, int index) {\n  return GetInput(context, node, index);\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/00302787b788c5ff04cb6f62aed5a74d936e86c0", "file_name": "tensorflow/lite/kernels/kernel_util.cc", "vul_type": "cwe-125", "description": "Write a C++ function named `GetOptionalInputTensor` that retrieves an optional input tensor from a TensorFlow Lite node if it exists, or returns null otherwise."}
{"func_name": "main", "func_src_before": "def main(_):\n  # Import data\n  if FLAGS.fake_data:\n    imgs = tf.random.uniform(maxval=256, shape=(10, 28, 28), dtype=tf.int32)\n    labels = tf.random.uniform(maxval=10, shape=(10,), dtype=tf.int32)\n    mnist_train = imgs, labels\n    mnist_test = imgs, labels\n  else:\n    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n\n  def format_example(imgs, labels):\n    imgs = tf.reshape(imgs, [-1, 28 * 28])\n    imgs = tf.cast(imgs, tf.float32) / 255.0\n    labels = tf.one_hot(labels, depth=10, dtype=tf.float32)\n    return imgs, labels\n\n  ds_train = tf.data.Dataset.from_tensor_slices(mnist_train)\n  ds_train = ds_train.shuffle(\n      1000, seed=RAND_SEED).repeat().batch(FLAGS.train_batch_size)\n  ds_train = ds_train.map(format_example)\n  it_train = ds_train.make_initializable_iterator()\n\n  ds_test = tf.data.Dataset.from_tensors(mnist_test).repeat()\n  ds_test = ds_test.map(format_example)\n  it_test = ds_test.make_initializable_iterator()\n\n  sess = tf.InteractiveSession()\n\n  # Create the MNIST neural network graph.\n\n  # Input placeholders.\n  with tf.name_scope(\"input\"):\n    handle = tf.placeholder(tf.string, shape=())\n\n    iterator = tf.data.Iterator.from_string_handle(\n        handle, (tf.float32, tf.float32),\n        ((None, IMAGE_SIZE * IMAGE_SIZE), (None, 10)))\n\n    x, y_ = iterator.get_next()\n\n  def weight_variable(shape):\n    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n    initial = tf.truncated_normal(shape, stddev=0.1, seed=RAND_SEED)\n    return tf.Variable(initial)\n\n  def bias_variable(shape):\n    \"\"\"Create a bias variable with appropriate initialization.\"\"\"\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n    \"\"\"Reusable code for making a simple neural net layer.\"\"\"\n    # Adding a name scope ensures logical grouping of the layers in the graph.\n    with tf.name_scope(layer_name):\n      # This Variable will hold the state of the weights for the layer\n      with tf.name_scope(\"weights\"):\n        weights = weight_variable([input_dim, output_dim])\n      with tf.name_scope(\"biases\"):\n        biases = bias_variable([output_dim])\n      with tf.name_scope(\"Wx_plus_b\"):\n        preactivate = tf.matmul(input_tensor, weights) + biases\n\n      activations = act(preactivate)\n      return activations\n\n  hidden = nn_layer(x, IMAGE_SIZE**2, HIDDEN_SIZE, \"hidden\")\n  logits = nn_layer(hidden, HIDDEN_SIZE, NUM_LABELS, \"output\", tf.identity)\n  y = tf.nn.softmax(logits)\n\n  with tf.name_scope(\"cross_entropy\"):\n    # The following line is the culprit of the bad numerical values that appear\n    # during training of this graph. Log of zero gives inf, which is first seen\n    # in the intermediate tensor \"cross_entropy/Log:0\" during the 4th run()\n    # call. A multiplication of the inf values with zeros leads to nans,\n    # which is first in \"cross_entropy/mul:0\".\n    #\n    # You can use the built-in, numerically-stable implementation to fix this\n    # issue:\n    #   diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits)\n\n    diff = -(y_ * tf.log(y))\n    with tf.name_scope(\"total\"):\n      cross_entropy = tf.reduce_mean(diff)\n\n  with tf.name_scope(\"train\"):\n    train_step = tf.train.AdamOptimizer(\n        FLAGS.learning_rate).minimize(cross_entropy)\n\n  with tf.name_scope(\"accuracy\"):\n    with tf.name_scope(\"correct_prediction\"):\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    with tf.name_scope(\"accuracy\"):\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n  sess.run(tf.global_variables_initializer())\n  sess.run(it_train.initializer)\n  sess.run(it_test.initializer)\n  train_handle = sess.run(it_train.string_handle())\n  test_handle = sess.run(it_test.string_handle())\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  if FLAGS.debug:\n    config_file_path = (\n        tempfile.mktemp(\".tfdbg_config\")\n        if FLAGS.use_random_config_path else None)\n    sess = tf_debug.LocalCLIDebugWrapperSession(\n        sess, ui_type=FLAGS.ui_type, config_file_path=config_file_path)\n  elif FLAGS.tensorboard_debug_address:\n    sess = tf_debug.TensorBoardDebugWrapperSession(\n        sess, FLAGS.tensorboard_debug_address)\n\n  # Add this point, sess is a debug wrapper around the actual Session if\n  # FLAGS.debug is true. In that case, calling run() will launch the CLI.\n  for i in range(FLAGS.max_steps):\n    acc = sess.run(accuracy, feed_dict={handle: test_handle})\n    print(\"Accuracy at step %d: %s\" % (i, acc))\n\n    sess.run(train_step, feed_dict={handle: train_handle})", "func_src_after": "def main(_):\n  # Import data\n  if FLAGS.fake_data:\n    imgs = tf.random.uniform(maxval=256, shape=(10, 28, 28), dtype=tf.int32)\n    labels = tf.random.uniform(maxval=10, shape=(10,), dtype=tf.int32)\n    mnist_train = imgs, labels\n    mnist_test = imgs, labels\n  else:\n    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n\n  def format_example(imgs, labels):\n    imgs = tf.reshape(imgs, [-1, 28 * 28])\n    imgs = tf.cast(imgs, tf.float32) / 255.0\n    labels = tf.one_hot(labels, depth=10, dtype=tf.float32)\n    return imgs, labels\n\n  ds_train = tf.data.Dataset.from_tensor_slices(mnist_train)\n  ds_train = ds_train.shuffle(\n      1000, seed=RAND_SEED).repeat().batch(FLAGS.train_batch_size)\n  ds_train = ds_train.map(format_example)\n  it_train = ds_train.make_initializable_iterator()\n\n  ds_test = tf.data.Dataset.from_tensors(mnist_test).repeat()\n  ds_test = ds_test.map(format_example)\n  it_test = ds_test.make_initializable_iterator()\n\n  sess = tf.InteractiveSession()\n\n  # Create the MNIST neural network graph.\n\n  # Input placeholders.\n  with tf.name_scope(\"input\"):\n    handle = tf.placeholder(tf.string, shape=())\n\n    iterator = tf.data.Iterator.from_string_handle(\n        handle, (tf.float32, tf.float32),\n        ((None, IMAGE_SIZE * IMAGE_SIZE), (None, 10)))\n\n    x, y_ = iterator.get_next()\n\n  def weight_variable(shape):\n    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n    initial = tf.truncated_normal(shape, stddev=0.1, seed=RAND_SEED)\n    return tf.Variable(initial)\n\n  def bias_variable(shape):\n    \"\"\"Create a bias variable with appropriate initialization.\"\"\"\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n    \"\"\"Reusable code for making a simple neural net layer.\"\"\"\n    # Adding a name scope ensures logical grouping of the layers in the graph.\n    with tf.name_scope(layer_name):\n      # This Variable will hold the state of the weights for the layer\n      with tf.name_scope(\"weights\"):\n        weights = weight_variable([input_dim, output_dim])\n      with tf.name_scope(\"biases\"):\n        biases = bias_variable([output_dim])\n      with tf.name_scope(\"Wx_plus_b\"):\n        preactivate = tf.matmul(input_tensor, weights) + biases\n\n      activations = act(preactivate)\n      return activations\n\n  hidden = nn_layer(x, IMAGE_SIZE**2, HIDDEN_SIZE, \"hidden\")\n  logits = nn_layer(hidden, HIDDEN_SIZE, NUM_LABELS, \"output\", tf.identity)\n  y = tf.nn.softmax(logits)\n\n  with tf.name_scope(\"cross_entropy\"):\n    # The following line is the culprit of the bad numerical values that appear\n    # during training of this graph. Log of zero gives inf, which is first seen\n    # in the intermediate tensor \"cross_entropy/Log:0\" during the 4th run()\n    # call. A multiplication of the inf values with zeros leads to nans,\n    # which is first in \"cross_entropy/mul:0\".\n    #\n    # You can use the built-in, numerically-stable implementation to fix this\n    # issue:\n    #   diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits)\n\n    diff = -(y_ * tf.log(y))\n    with tf.name_scope(\"total\"):\n      cross_entropy = tf.reduce_mean(diff)\n\n  with tf.name_scope(\"train\"):\n    train_step = tf.train.AdamOptimizer(\n        FLAGS.learning_rate).minimize(cross_entropy)\n\n  with tf.name_scope(\"accuracy\"):\n    with tf.name_scope(\"correct_prediction\"):\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    with tf.name_scope(\"accuracy\"):\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n  sess.run(tf.global_variables_initializer())\n  sess.run(it_train.initializer)\n  sess.run(it_test.initializer)\n  train_handle = sess.run(it_train.string_handle())\n  test_handle = sess.run(it_test.string_handle())\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  if FLAGS.debug:\n    if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n    else:\n      config_file_path = None\n    sess = tf_debug.LocalCLIDebugWrapperSession(\n        sess, ui_type=FLAGS.ui_type, config_file_path=config_file_path)\n  elif FLAGS.tensorboard_debug_address:\n    sess = tf_debug.TensorBoardDebugWrapperSession(\n        sess, FLAGS.tensorboard_debug_address)\n\n  # Add this point, sess is a debug wrapper around the actual Session if\n  # FLAGS.debug is true. In that case, calling run() will launch the CLI.\n  for i in range(FLAGS.max_steps):\n    acc = sess.run(accuracy, feed_dict={handle: test_handle})\n    print(\"Accuracy at step %d: %s\" % (i, acc))\n\n    sess.run(train_step, feed_dict={handle: train_handle})", "line_changes": {"deleted": [{"line_no": 106, "char_start": 3998, "char_end": 4023, "line": "    config_file_path = (\n"}, {"line_no": 107, "char_start": 4023, "char_end": 4064, "line": "        tempfile.mktemp(\".tfdbg_config\")\n"}, {"line_no": 108, "char_start": 4064, "char_end": 4115, "line": "        if FLAGS.use_random_config_path else None)\n"}], "added": [{"line_no": 106, "char_start": 3998, "char_end": 4035, "line": "    if FLAGS.use_random_config_path:\n"}, {"line_no": 108, "char_start": 4088, "char_end": 4150, "line": "      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n"}, {"line_no": 109, "char_start": 4150, "char_end": 4160, "line": "    else:\n"}, {"line_no": 110, "char_start": 4160, "char_end": 4190, "line": "      config_file_path = None\n"}]}, "char_changes": {"deleted": [{"char_start": 4020, "char_end": 4030, "chars": " (\n       "}, {"char_start": 4068, "char_end": 4092, "chars": "    if FLAGS.use_random_"}, {"char_start": 4104, "char_end": 4108, "chars": "else"}, {"char_start": 4113, "char_end": 4114, "chars": ")"}], "added": [{"char_start": 4002, "char_end": 4097, "chars": "if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, "}, {"char_start": 4127, "char_end": 4128, "chars": "s"}, {"char_start": 4154, "char_end": 4166, "chars": "else:\n      "}, {"char_start": 4173, "char_end": 4178, "chars": "file_"}, {"char_start": 4183, "char_end": 4184, "chars": "="}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/b5150106a7829c45892927562b7eed101581ea95", "file_name": "debug_mnist_v1.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359231\nChange-Id: If2049dbeb46fb8ff6df7c8e077cee8be3872e5b4", "description": "Write a Python TensorFlow script that trains a neural network on the MNIST dataset with options for fake data and debugging."}
{"func_name": "print_c_function", "func_src_before": "static void print_c_function(const state st) {\n  const char TYPE[] = \"__m256i \";\n  char buf[10];\n  printf(\"static inline void sbox(const %sin0, const %sin1, const %sin2, const %sin3,\\n\"\n      \"const %sin4, const %sin5, const %sin6, const %sin7, %s*out0,\\n\"\n      \"%s*out1, %s*out2, %s*out3, %s*out4, %s*out5, %s*out6,\\n\"\n      \"%s*out7) {\\n\", TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE,\n      TYPE, TYPE, TYPE);\n  for (uint8_t gate = 8; gate < st.num_gates; gate++) {\n    bool ret = get_c_variable_name(st, gate, buf);\n    printf(\"  %s%s = \", ret == true ? TYPE : \"\", buf);\n    get_c_variable_name(st, st.gates[gate].in1, buf);\n    if (st.gates[gate].type == NOT) {\n      printf(\"~%s;\\n\", buf);\n      continue;\n    }\n    printf(\"%s \", buf);\n    switch (st.gates[gate].type) {\n      case AND:\n        printf(\"& \");\n        break;\n      case OR:\n        printf(\"| \");\n        break;\n      case XOR:\n        printf(\"^ \");\n        break;\n      default:\n        assert(false);\n    }\n    get_c_variable_name(st, st.gates[gate].in2, buf);\n    printf(\"%s;\\n\", buf);\n  }\n  printf(\"}\\n\");\n}", "func_src_after": "static void print_c_function(const state st) {\n  const char TYPE[] = \"__m256i \";\n  char buf[10];\n  printf(\"static inline void sbox(const %sin0, const %sin1, const %sin2, const %sin3,\\n\"\n      \"const %sin4, const %sin5, const %sin6, const %sin7, %s*out0,\\n\"\n      \"%s*out1, %s*out2, %s*out3, %s*out4, %s*out5, %s*out6,\\n\"\n      \"%s*out7) {\\n\", TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE,\n      TYPE, TYPE, TYPE);\n  for (uint64_t gate = 8; gate < st.num_gates; gate++) {\n    bool ret = get_c_variable_name(st, gate, buf);\n    printf(\"  %s%s = \", ret == true ? TYPE : \"\", buf);\n    get_c_variable_name(st, st.gates[gate].in1, buf);\n    if (st.gates[gate].type == NOT) {\n      printf(\"~%s;\\n\", buf);\n      continue;\n    }\n    printf(\"%s \", buf);\n    switch (st.gates[gate].type) {\n      case AND:\n        printf(\"& \");\n        break;\n      case OR:\n        printf(\"| \");\n        break;\n      case XOR:\n        printf(\"^ \");\n        break;\n      default:\n        assert(false);\n    }\n    get_c_variable_name(st, st.gates[gate].in2, buf);\n    printf(\"%s;\\n\", buf);\n  }\n  printf(\"}\\n\");\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 446, "char_end": 502, "line": "  for (uint8_t gate = 8; gate < st.num_gates; gate++) {\n"}], "added": [{"line_no": 9, "char_start": 446, "char_end": 503, "line": "  for (uint64_t gate = 8; gate < st.num_gates; gate++) {\n"}]}, "char_changes": {"deleted": [{"char_start": 457, "char_end": 458, "chars": "8"}], "added": [{"char_start": 457, "char_end": 459, "chars": "64"}]}, "commit_link": "github.com/dansarie/sboxgates/commit/5dffb1e61a9f28ef596684d6e401c3ee166bb4eb", "file_name": "sboxgates.c", "vul_type": "cwe-190", "commit_msg": "Fix integer overflow when generating C source code.", "parent_commit": "7cb0a30fe10f56e862b3d62973f65d8c3222e67a", "description": "Write a C function that prints the definition of an inline function for a substitution box (s-box) with input and output parameters, and a loop that generates bitwise operations based on a given state structure."}
{"func_name": "vips_foreign_load_gif_scan_image", "func_src_before": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\tColorMapObject *map = file->Image.ColorMap ?\n\t\tfile->Image.ColorMap : file->SColorMap;\n\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "func_src_after": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\n\tColorMapObject *map;\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tmap = file->Image.ColorMap ? file->Image.ColorMap : file->SColorMap;\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "commit_link": "github.com/libvips/libvips/commit/ce684dd008532ea0bf9d4a1d89bacb35f4a83f4d", "file_name": "libvips/foreign/gifload.c", "vul_type": "cwe-416", "description": "Write a C function to scan and validate a GIF image frame for the Vips image processing library."}
{"func_name": "get_request", "func_src_before": "        def get_request(self):\n            socket, client_address = HTTPServer.get_request(self)\n            socket = ssl.wrap_socket(socket,\n                                     keyfile=HttpsTestServerLayer.CERT_FILE,\n                                     certfile=HttpsTestServerLayer.CERT_FILE,\n                                     cert_reqs=ssl.CERT_OPTIONAL,\n                                     ca_certs=HttpsTestServerLayer.CACERT_FILE,\n                                     server_side=True)\n            return socket, client_address", "func_src_after": "        def get_request(self):\n\n            # Prepare SSL context.\n            context = ssl._create_unverified_context(\n                protocol=ssl.PROTOCOL_TLS_SERVER,\n                cert_reqs=ssl.CERT_OPTIONAL,\n                check_hostname=False,\n                purpose=ssl.Purpose.CLIENT_AUTH,\n                certfile=HttpsTestServerLayer.CERT_FILE,\n                keyfile=HttpsTestServerLayer.CERT_FILE,\n                cafile=HttpsTestServerLayer.CACERT_FILE)\n\n            # Set minimum protocol version, TLSv1 and TLSv1.1 are unsafe.\n            context.minimum_version = ssl.TLSVersion.TLSv1_2\n\n            # Wrap TLS encryption around socket.\n            socket, client_address = HTTPServer.get_request(self)\n            socket = context.wrap_socket(socket, server_side=True)\n\n            return socket, client_address", "line_changes": {"deleted": [{"line_no": 3, "char_start": 97, "char_end": 142, "line": "            socket = ssl.wrap_socket(socket,\n"}, {"line_no": 4, "char_start": 142, "char_end": 219, "line": "                                     keyfile=HttpsTestServerLayer.CERT_FILE,\n"}, {"line_no": 5, "char_start": 219, "char_end": 297, "line": "                                     certfile=HttpsTestServerLayer.CERT_FILE,\n"}, {"line_no": 6, "char_start": 297, "char_end": 363, "line": "                                     cert_reqs=ssl.CERT_OPTIONAL,\n"}, {"line_no": 7, "char_start": 363, "char_end": 443, "line": "                                     ca_certs=HttpsTestServerLayer.CACERT_FILE,\n"}, {"line_no": 8, "char_start": 443, "char_end": 498, "line": "                                     server_side=True)\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 32, "line": "\n"}, {"line_no": 4, "char_start": 67, "char_end": 121, "line": "            context = ssl._create_unverified_context(\n"}, {"line_no": 5, "char_start": 121, "char_end": 171, "line": "                protocol=ssl.PROTOCOL_TLS_SERVER,\n"}, {"line_no": 6, "char_start": 171, "char_end": 216, "line": "                cert_reqs=ssl.CERT_OPTIONAL,\n"}, {"line_no": 7, "char_start": 216, "char_end": 254, "line": "                check_hostname=False,\n"}, {"line_no": 8, "char_start": 254, "char_end": 303, "line": "                purpose=ssl.Purpose.CLIENT_AUTH,\n"}, {"line_no": 9, "char_start": 303, "char_end": 360, "line": "                certfile=HttpsTestServerLayer.CERT_FILE,\n"}, {"line_no": 10, "char_start": 360, "char_end": 416, "line": "                keyfile=HttpsTestServerLayer.CERT_FILE,\n"}, {"line_no": 11, "char_start": 416, "char_end": 473, "line": "                cafile=HttpsTestServerLayer.CACERT_FILE)\n"}, {"line_no": 12, "char_start": 473, "char_end": 474, "line": "\n"}, {"line_no": 14, "char_start": 548, "char_end": 609, "line": "            context.minimum_version = ssl.TLSVersion.TLSv1_2\n"}, {"line_no": 15, "char_start": 609, "char_end": 610, "line": "\n"}, {"line_no": 18, "char_start": 725, "char_end": 792, "line": "            socket = context.wrap_socket(socket, server_side=True)\n"}, {"line_no": 19, "char_start": 792, "char_end": 793, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 43, "char_end": 182, "chars": "socket, client_address = HTTPServer.get_request(self)\n            socket = ssl.wrap_socket(socket,\n                                     key"}, {"char_start": 235, "char_end": 240, "chars": "     "}, {"char_start": 257, "char_end": 260, "chars": "ert"}, {"char_start": 295, "char_end": 296, "chars": ","}, {"char_start": 309, "char_end": 479, "chars": "                         cert_reqs=ssl.CERT_OPTIONAL,\n                                     ca_certs=HttpsTestServerLayer.CACERT_FILE,\n                                    "}], "added": [{"char_start": 31, "char_end": 32, "chars": "\n"}, {"char_start": 44, "char_end": 323, "chars": "# Prepare SSL context.\n            context = ssl._create_unverified_context(\n                protocol=ssl.PROTOCOL_TLS_SERVER,\n                cert_reqs=ssl.CERT_OPTIONAL,\n                check_hostname=False,\n                purpose=ssl.Purpose.CLIENT_AUTH,\n                cert"}, {"char_start": 376, "char_end": 416, "chars": "keyfile=HttpsTestServerLayer.CERT_FILE,\n"}, {"char_start": 433, "char_end": 434, "chars": "a"}, {"char_start": 460, "char_end": 462, "chars": "CA"}, {"char_start": 471, "char_end": 473, "chars": ")\n"}, {"char_start": 486, "char_end": 773, "chars": "# Set minimum protocol version, TLSv1 and TLSv1.1 are unsafe.\n            context.minimum_version = ssl.TLSVersion.TLSv1_2\n\n            # Wrap TLS encryption around socket.\n            socket, client_address = HTTPServer.get_request(self)\n            socket = context.wrap_socket(socket,"}, {"char_start": 792, "char_end": 793, "chars": "\n"}]}, "commit_link": "github.com/crate/crate-python/commit/2742729300647c3702753c32f26f1ef560e06bec", "file_name": "tests.py", "vul_type": "cwe-327", "commit_msg": "Tests: Stop using deprecated `ssl.wrap_socket`\n\nUse `context.wrap_socket` instead. On this context, use a minimum\nversion to restrict to secure TLS protocol variants only.\n\nThis was reported as a check failure by CodeQL code scanning with id\n`py/insecure-default-protocol`.\n\nhttps://github.com/github/codeql/blob/main/python/ql/src/Security/CWE-327/InsecureDefaultProtocol.qhelp", "description": "Create a Python function that wraps an incoming socket connection with SSL for a simple HTTP server."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        self.config = yaml.load(blob)", "func_src_after": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        yaml=YAML(typ='safe')\n        self.config = yaml.load(blob)", "line_changes": {"deleted": [], "added": [{"line_no": 6, "char_start": 181, "char_end": 211, "line": "        yaml=YAML(typ='safe')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 181, "char_end": 211, "chars": "        yaml=YAML(typ='safe')\n"}]}, "commit_link": "github.com/royrapoport/destalinator/commit/660ccd202e627cc8938a47532c7607edc676963f", "file_name": "config.py", "vul_type": "cwe-502", "commit_msg": "fix for YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe.", "parent_commit": "ef4a53784cd0026947df3f58cab3657a24e91112", "description": "Write a Python class initializer that reads a configuration file using YAML."}
{"func_name": "extract_file", "func_src_before": "static bool extract_file(Unshield* unshield, const char* prefix, int index)\n{\n  bool success;\n  char dirname[256];\n  char filename[256];\n  char* p;\n  int directory = unshield_file_directory(unshield, index);\n  char real_output_directory[256];\n  char real_filename[256];\n\n  strcpy(dirname, output_directory);\n  strcat(dirname, \"/\");\n\n  if (prefix && prefix[0])\n  {\n    strcat(dirname, prefix);\n    strcat(dirname, \"/\");\n  }\n\n  if (!junk_paths && directory >= 0)\n  {\n    const char* tmp = unshield_directory_name(unshield, directory);\n    if (tmp && tmp[0])\n    {\n      strcat(dirname, tmp);\n      strcat(dirname, \"/\");\n    }\n  }\n\n  for (p = dirname + strlen(output_directory); *p != '\\0'; p++)\n  {\n    switch (*p)\n    {\n      case '\\\\':\n        *p = '/';\n        break;\n\n      case ' ':\n      case '<':\n      case '>':\n      case '[':\n      case ']':\n        *p = '_';\n        break;\n\n      default:\n        if (!raw_filename)\n        {  \n          if (!isprint(*p))\n            *p = '_';\n          else if (make_lowercase)\n            *p = tolower(*p);\n        }\n        break;;\n    }\n  }\n\n#ifdef HAVE_ICONV\n  if (!convert_encoding(dirname, sizeof(dirname)))\n  {\n    success = false;\n    goto exit;\n  }\n#endif\n\n\n#if 0\n  if (dirname[strlen(dirname)-1] != '/')\n    strcat(dirname, \"/\");\n#endif\n\n  make_sure_directory_exists(dirname);\n\n  snprintf(filename, sizeof(filename), \"%s%s\", \n      dirname, unshield_file_name(unshield, index));\n\n  for (p = filename + strlen(dirname); *p != '\\0'; p++)\n  {\n    if (!raw_filename)\n    {\n      if (!isprint(*p))\n        *p = '_';\n      else if (make_lowercase)\n        *p = tolower(*p);\n    }\n  }\n\n#ifdef HAVE_ICONV\n  if (!convert_encoding(filename + strlen(dirname),\n      sizeof(filename) - strlen(dirname)))\n  {\n    success = false;\n    goto exit;\n  }\n#endif\n\n  realpath(output_directory, real_output_directory);\n  realpath(filename, real_filename);\n  if (real_filename == NULL || strncmp(real_filename,\n                                       real_output_directory,\n                                       strlen(real_output_directory)) != 0)\n  {\n    fprintf(stderr, \"\\n\\nExtraction failed.\\n\");\n    fprintf(stderr, \"Possible directory traversal attack for: %s\\n\", filename);\n    fprintf(stderr, \"To be placed at: %s\\n\\n\", real_filename);\n    exit_status = 1;\n    success = false;\n    return success;\n  }\n\n  printf(\"  extracting: %s\\n\", filename);\n  switch (format)\n  {\n    case FORMAT_NEW:\n      success = unshield_file_save(unshield, index, filename);\n      break;\n    case FORMAT_OLD:\n      success = unshield_file_save_old(unshield, index, filename);\n      break;\n    case FORMAT_RAW:\n      success = unshield_file_save_raw(unshield, index, filename);\n      break;\n  }\n\nexit:\n  if (!success)\n  {\n    fprintf(stderr, \"Failed to extract file '%s'.%s\\n\", \n        unshield_file_name(unshield, index),\n        (log_level < 3) ? \"Run unshield again with -D 3 for more information.\" : \"\");\n    unlink(filename);\n    exit_status = 1;\n  }\n\n  return success;\n}", "func_src_after": "static bool extract_file(Unshield* unshield, const char* prefix, int index)\n{\n  bool success;\n  char dirname[256];\n  char filename[256];\n  char* p;\n  int directory = unshield_file_directory(unshield, index);\n  long int path_max;\n  char* real_output_directory;\n  char* real_filename;\n\n  #ifdef PATH_MAX\n    path_max = PATH_MAX;\n  #else\n    path_max = pathconf(path, _PC_PATH_MAX);\n    if (path_max <= 0)\n      path_max = 4096;\n  #endif\n\n  real_output_directory = malloc(path_max);\n  real_filename = malloc(path_max);\n  if (real_output_directory == NULL || real_filename == NULL)\n  {\n    fprintf(stderr,\"Unable to allocate memory.\");\n    success=false;\n    goto exit;\n  }\n\n  strcpy(dirname, output_directory);\n  strcat(dirname, \"/\");\n\n  if (prefix && prefix[0])\n  {\n    strcat(dirname, prefix);\n    strcat(dirname, \"/\");\n  }\n\n  if (!junk_paths && directory >= 0)\n  {\n    const char* tmp = unshield_directory_name(unshield, directory);\n    if (tmp && tmp[0])\n    {\n      strcat(dirname, tmp);\n      strcat(dirname, \"/\");\n    }\n  }\n\n  for (p = dirname + strlen(output_directory); *p != '\\0'; p++)\n  {\n    switch (*p)\n    {\n      case '\\\\':\n        *p = '/';\n        break;\n\n      case ' ':\n      case '<':\n      case '>':\n      case '[':\n      case ']':\n        *p = '_';\n        break;\n\n      default:\n        if (!raw_filename)\n        {  \n          if (!isprint(*p))\n            *p = '_';\n          else if (make_lowercase)\n            *p = tolower(*p);\n        }\n        break;;\n    }\n  }\n\n#ifdef HAVE_ICONV\n  if (!convert_encoding(dirname, sizeof(dirname)))\n  {\n    success = false;\n    goto exit;\n  }\n#endif\n\n\n#if 0\n  if (dirname[strlen(dirname)-1] != '/')\n    strcat(dirname, \"/\");\n#endif\n\n  make_sure_directory_exists(dirname);\n\n  snprintf(filename, sizeof(filename), \"%s%s\", \n      dirname, unshield_file_name(unshield, index));\n\n  for (p = filename + strlen(dirname); *p != '\\0'; p++)\n  {\n    if (!raw_filename)\n    {\n      if (!isprint(*p))\n        *p = '_';\n      else if (make_lowercase)\n        *p = tolower(*p);\n    }\n  }\n\n#ifdef HAVE_ICONV\n  if (!convert_encoding(filename + strlen(dirname),\n      sizeof(filename) - strlen(dirname)))\n  {\n    success = false;\n    goto exit;\n  }\n#endif\n\n  /* use GNU extension to return non-existing files to real_output_directory */\n  realpath(output_directory, real_output_directory);\n  realpath(filename, real_filename);\n  if (real_filename == NULL || strncmp(real_filename,\n                                       real_output_directory,\n                                       strlen(real_output_directory)) != 0)\n  {\n    fprintf(stderr, \"\\n\\nExtraction failed.\\n\");\n    fprintf(stderr, \"Possible directory traversal attack for: %s\\n\", filename);\n    fprintf(stderr, \"To be placed at: %s\\n\\n\", real_filename);\n    exit_status = 1;\n    success = false;\n    free(real_filename);\n    free(real_output_directory);\n    return success;\n  }\n\n  printf(\"  extracting: %s\\n\", filename);\n  switch (format)\n  {\n    case FORMAT_NEW:\n      success = unshield_file_save(unshield, index, filename);\n      break;\n    case FORMAT_OLD:\n      success = unshield_file_save_old(unshield, index, filename);\n      break;\n    case FORMAT_RAW:\n      success = unshield_file_save_raw(unshield, index, filename);\n      break;\n  }\n\nexit:\n  if (!success)\n  {\n    fprintf(stderr, \"Failed to extract file '%s'.%s\\n\", \n        unshield_file_name(unshield, index),\n        (log_level < 3) ? \"Run unshield again with -D 3 for more information.\" : \"\");\n    unlink(filename);\n    exit_status = 1;\n  }\n  free(real_filename);\n  free(real_output_directory);\n  return success;\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 208, "char_end": 243, "line": "  char real_output_directory[256];\n"}, {"line_no": 9, "char_start": 243, "char_end": 270, "line": "  char real_filename[256];\n"}, {"line_no": 134, "char_start": 2973, "char_end": 2974, "line": "\n"}], "added": [{"line_no": 8, "char_start": 208, "char_end": 229, "line": "  long int path_max;\n"}, {"line_no": 9, "char_start": 229, "char_end": 260, "line": "  char* real_output_directory;\n"}, {"line_no": 10, "char_start": 260, "char_end": 283, "line": "  char* real_filename;\n"}, {"line_no": 11, "char_start": 283, "char_end": 284, "line": "\n"}, {"line_no": 13, "char_start": 302, "char_end": 327, "line": "    path_max = PATH_MAX;\n"}, {"line_no": 15, "char_start": 335, "char_end": 380, "line": "    path_max = pathconf(path, _PC_PATH_MAX);\n"}, {"line_no": 16, "char_start": 380, "char_end": 403, "line": "    if (path_max <= 0)\n"}, {"line_no": 17, "char_start": 403, "char_end": 426, "line": "      path_max = 4096;\n"}, {"line_no": 19, "char_start": 435, "char_end": 436, "line": "\n"}, {"line_no": 20, "char_start": 436, "char_end": 480, "line": "  real_output_directory = malloc(path_max);\n"}, {"line_no": 21, "char_start": 480, "char_end": 516, "line": "  real_filename = malloc(path_max);\n"}, {"line_no": 22, "char_start": 516, "char_end": 578, "line": "  if (real_output_directory == NULL || real_filename == NULL)\n"}, {"line_no": 23, "char_start": 578, "char_end": 582, "line": "  {\n"}, {"line_no": 24, "char_start": 582, "char_end": 632, "line": "    fprintf(stderr,\"Unable to allocate memory.\");\n"}, {"line_no": 25, "char_start": 632, "char_end": 651, "line": "    success=false;\n"}, {"line_no": 26, "char_start": 651, "char_end": 666, "line": "    goto exit;\n"}, {"line_no": 27, "char_start": 666, "char_end": 670, "line": "  }\n"}, {"line_no": 115, "char_start": 2199, "char_end": 2279, "line": "  /* use GNU extension to return non-existing files to real_output_directory */\n"}, {"line_no": 127, "char_start": 2799, "char_end": 2824, "line": "    free(real_filename);\n"}, {"line_no": 128, "char_start": 2824, "char_end": 2857, "line": "    free(real_output_directory);\n"}, {"line_no": 155, "char_start": 3511, "char_end": 3534, "line": "  free(real_filename);\n"}, {"line_no": 156, "char_start": 3534, "char_end": 3565, "line": "  free(real_output_directory);\n"}]}, "char_changes": {"deleted": [{"char_start": 236, "char_end": 241, "chars": "[256]"}, {"char_start": 263, "char_end": 269, "chars": "[256];"}], "added": [{"char_start": 208, "char_end": 229, "chars": "  long int path_max;\n"}, {"char_start": 235, "char_end": 236, "chars": "*"}, {"char_start": 258, "char_end": 669, "chars": ";\n  char* real_filename;\n\n  #ifdef PATH_MAX\n    path_max = PATH_MAX;\n  #else\n    path_max = pathconf(path, _PC_PATH_MAX);\n    if (path_max <= 0)\n      path_max = 4096;\n  #endif\n\n  real_output_directory = malloc(path_max);\n  real_filename = malloc(path_max);\n  if (real_output_directory == NULL || real_filename == NULL)\n  {\n    fprintf(stderr,\"Unable to allocate memory.\");\n    success=false;\n    goto exit;\n  }"}, {"char_start": 2199, "char_end": 2279, "chars": "  /* use GNU extension to return non-existing files to real_output_directory */\n"}, {"char_start": 2799, "char_end": 2857, "chars": "    free(real_filename);\n    free(real_output_directory);\n"}, {"char_start": 3511, "char_end": 3564, "chars": "  free(real_filename);\n  free(real_output_directory);"}]}, "commit_link": "github.com/twogood/unshield/commit/f329309c4785d3bb55fe0fbe1cfabb64350bf543", "file_name": "unshield.c", "vul_type": "cwe-787", "commit_msg": "protect against buffer overflow if PATH_MAX is large", "parent_commit": "206167bf74a23b0fcbc8e138945c73148ec42d0b", "description": "Write a C function named `extract_file` that takes an `Unshield` pointer, a string `prefix`, and an integer `index`, and extracts a file from an archive."}
{"func_name": "search", "func_src_before": "  def search\n\n  \tselectTerm = \"id, name, info_one, info_one_red, info_two, info_two_red, info_three, info_three_red, updated_at, last_user, avatar_upload, updated_at\";\n  \twhereSearchTerm  = \"name LIKE '%#{params[:query]}%'\"\n\t\twhereSearchTerm += \"OR description LIKE '%#{params[:query]}%'\"\n\t\twhereSearchTerm += \"OR info_one LIKE '%#{params[:query]}%'\"\n\t\twhereSearchTerm += \"OR info_two LIKE '%#{params[:query]}%'\"\n\t\twhereSearchTerm += \"OR info_three LIKE '%#{params[:query]}%'\"\n\n  \tif params[:state] == \"posters\"\n\t  \tif params[:query] == \"\"\n\t  \t\t@posters = Poster.select(selectTerm).where('updated_at < ?', 7.days.ago).order(updated_at: :desc).limit(params[:limit])\n\t  \telse\n\t  \t\t@posters = Poster.select(selectTerm).where('updated_at < ?', 7.days.ago).where(whereSearchTerm).order(updated_at: :desc).limit(params[:limit])\n\t  \tend\n\t  elsif params[:state] == \"latest\"\n\t  \tif params[:query] == \"\"\n\t  \t\t@posters = Poster.where('updated_at >= ?', 7.days.ago).order(updated_at: :desc)\n\t  \telse\n\t  \t\t@posters = Poster.where('updated_at >= ?', 7.days.ago).where(whereSearchTerm).order(updated_at: :desc)\n\t  \tend\n\t  elsif params[:state] == \"my-posters\"\n\t  \tif params[:query] == \"\"\n\t\t\t\t@posters = Poster.select(selectTerm).where('user_id = ?', current_user.id).order(updated_at: :desc).limit(params[:limit])\n\t  \telse\n\t  \t\t@posters = Poster.select(selectTerm).where('user_id = ?', current_user.id).where(whereSearchTerm).order(updated_at: :desc).limit(params[:limit])\n\t  \tend\n\t  end\n\n  \trender :json => @posters\n\n  end", "func_src_after": "  def search\n\n  \tselectTerm = \"id, name, info_one, info_one_red, info_two, info_two_red, info_three, info_three_red, updated_at, last_user, avatar_upload, updated_at\";\n  \twhereSearchTerm  = \"name LIKE ?\"\n\t\twhereSearchTerm += \"OR description LIKE ?\"\n\t\twhereSearchTerm += \"OR info_one LIKE ?\"\n\t\twhereSearchTerm += \"OR info_two LIKE ?\"\n\t\twhereSearchTerm += \"OR info_three LIKE ?\"\n\n\t\tunless params[:query].empty?\n\t\t\tparams[:query] = '%' + params[:query] + '%'\n\t\tend\n\n  \tif params[:state] == \"posters\"\n\t  \tif params[:query] == \"\"\n\t  \t\t@posters = Poster.select(selectTerm).where('updated_at < ?', 7.days.ago).order(updated_at: :desc).limit(params[:limit])\n\t  \telse\n\t  \t\t@posters = Poster.select(selectTerm).where('updated_at < ?', 7.days.ago).where(whereSearchTerm, params[:query], params[:query], params[:query], params[:query], params[:query]).order(updated_at: :desc).limit(params[:limit])\n\t  \tend\n\t  elsif params[:state] == \"latest\"\n\t  \tif params[:query] == \"\"\n\t  \t\t@posters = Poster.where('updated_at >= ?', 7.days.ago).order(updated_at: :desc)\n\t  \telse\n\t  \t\t@posters = Poster.where('updated_at >= ?', 7.days.ago).where(whereSearchTerm, params[:query], params[:query], params[:query], params[:query], params[:query]).order(updated_at: :desc)\n\t  \tend\n\t  elsif params[:state] == \"my-posters\"\n\t  \tif params[:query] == \"\"\n\t\t\t\t@posters = Poster.select(selectTerm).where('user_id = ?', current_user.id).order(updated_at: :desc).limit(params[:limit])\n\t  \telse\n\t  \t\t@posters = Poster.select(selectTerm).where('user_id = ?', current_user.id).where(whereSearchTerm, params[:query], params[:query], params[:query], params[:query], params[:query]).order(updated_at: :desc).limit(params[:limit])\n\t  \tend\n\t  end\n\n  \trender :json => @posters\n\n  end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 168, "char_end": 224, "line": "  \twhereSearchTerm  = \"name LIKE '%#{params[:query]}%'\"\n"}, {"line_no": 5, "char_start": 224, "char_end": 289, "line": "\t\twhereSearchTerm += \"OR description LIKE '%#{params[:query]}%'\"\n"}, {"line_no": 6, "char_start": 289, "char_end": 351, "line": "\t\twhereSearchTerm += \"OR info_one LIKE '%#{params[:query]}%'\"\n"}, {"line_no": 7, "char_start": 351, "char_end": 413, "line": "\t\twhereSearchTerm += \"OR info_two LIKE '%#{params[:query]}%'\"\n"}, {"line_no": 8, "char_start": 413, "char_end": 477, "line": "\t\twhereSearchTerm += \"OR info_three LIKE '%#{params[:query]}%'\"\n"}, {"line_no": 14, "char_start": 674, "char_end": 822, "line": "\t  \t\t@posters = Poster.select(selectTerm).where('updated_at < ?', 7.days.ago).where(whereSearchTerm).order(updated_at: :desc).limit(params[:limit])\n"}, {"line_no": 20, "char_start": 988, "char_end": 1096, "line": "\t  \t\t@posters = Poster.where('updated_at >= ?', 7.days.ago).where(whereSearchTerm).order(updated_at: :desc)\n"}, {"line_no": 26, "char_start": 1307, "char_end": 1457, "line": "\t  \t\t@posters = Poster.select(selectTerm).where('user_id = ?', current_user.id).where(whereSearchTerm).order(updated_at: :desc).limit(params[:limit])\n"}], "added": [{"line_no": 4, "char_start": 168, "char_end": 204, "line": "  \twhereSearchTerm  = \"name LIKE ?\"\n"}, {"line_no": 5, "char_start": 204, "char_end": 249, "line": "\t\twhereSearchTerm += \"OR description LIKE ?\"\n"}, {"line_no": 6, "char_start": 249, "char_end": 291, "line": "\t\twhereSearchTerm += \"OR info_one LIKE ?\"\n"}, {"line_no": 7, "char_start": 291, "char_end": 333, "line": "\t\twhereSearchTerm += \"OR info_two LIKE ?\"\n"}, {"line_no": 8, "char_start": 333, "char_end": 377, "line": "\t\twhereSearchTerm += \"OR info_three LIKE ?\"\n"}, {"line_no": 9, "char_start": 377, "char_end": 378, "line": "\n"}, {"line_no": 10, "char_start": 378, "char_end": 409, "line": "\t\tunless params[:query].empty?\n"}, {"line_no": 11, "char_start": 409, "char_end": 456, "line": "\t\t\tparams[:query] = '%' + params[:query] + '%'\n"}, {"line_no": 12, "char_start": 456, "char_end": 462, "line": "\t\tend\n"}, {"line_no": 18, "char_start": 659, "char_end": 887, "line": "\t  \t\t@posters = Poster.select(selectTerm).where('updated_at < ?', 7.days.ago).where(whereSearchTerm, params[:query], params[:query], params[:query], params[:query], params[:query]).order(updated_at: :desc).limit(params[:limit])\n"}, {"line_no": 24, "char_start": 1053, "char_end": 1241, "line": "\t  \t\t@posters = Poster.where('updated_at >= ?', 7.days.ago).where(whereSearchTerm, params[:query], params[:query], params[:query], params[:query], params[:query]).order(updated_at: :desc)\n"}, {"line_no": 30, "char_start": 1452, "char_end": 1682, "line": "\t  \t\t@posters = Poster.select(selectTerm).where('user_id = ?', current_user.id).where(whereSearchTerm, params[:query], params[:query], params[:query], params[:query], params[:query]).order(updated_at: :desc).limit(params[:limit])\n"}]}, "char_changes": {"deleted": [{"char_start": 201, "char_end": 222, "chars": "'%#{params[:query]}%'"}, {"char_start": 266, "char_end": 287, "chars": "'%#{params[:query]}%'"}, {"char_start": 328, "char_end": 349, "chars": "'%#{params[:query]}%'"}, {"char_start": 390, "char_end": 411, "chars": "'%#{params[:query]}%'"}, {"char_start": 454, "char_end": 458, "chars": "'%#{"}, {"char_start": 472, "char_end": 476, "chars": "}%'\""}], "added": [{"char_start": 201, "char_end": 202, "chars": "?"}, {"char_start": 246, "char_end": 247, "chars": "?"}, {"char_start": 288, "char_end": 289, "chars": "?"}, {"char_start": 330, "char_end": 331, "chars": "?"}, {"char_start": 374, "char_end": 435, "chars": "?\"\n\n\t\tunless params[:query].empty?\n\t\t\tparams[:query] = '%' + "}, {"char_start": 449, "char_end": 461, "chars": " + '%'\n\t\tend"}, {"char_start": 758, "char_end": 838, "chars": ", params[:query], params[:query], params[:query], params[:query], params[:query]"}, {"char_start": 1134, "char_end": 1214, "chars": ", params[:query], params[:query], params[:query], params[:query], params[:query]"}, {"char_start": 1553, "char_end": 1633, "chars": ", params[:query], params[:query], params[:query], params[:query], params[:query]"}]}, "commit_link": "github.com/IOH/ioh-cover-maker/commit/ac636ca90521050a07b3f24ed4994594e369630e", "file_name": "posters_controller.rb", "vul_type": "cwe-089", "commit_msg": "prevent sql injection in search", "description": "Write a Ruby method to search and filter posters based on a query and state, returning the results as JSON."}
{"func_name": "ecall_restore", "func_src_before": "int ecall_restore(const char *input, uint64_t input_len, char **output,\n                  uint64_t *output_len) {\n  if (!asylo::primitives::TrustedPrimitives::IsOutsideEnclave(input,\n                                                              input_len) ||\n      !asylo::primitives::TrustedPrimitives::IsOutsideEnclave(\n          output_len, sizeof(uint64_t))) {\n    asylo::primitives::TrustedPrimitives::BestEffortAbort(\n        \"ecall_restore: input/output found to not be in untrusted memory.\");\n  }\n  int result = 0;\n  size_t tmp_output_len;\n  try {\n    result = asylo::Restore(input, static_cast<size_t>(input_len), output,\n                            &tmp_output_len);\n  } catch (...) {\n    LOG(FATAL) << \"Uncaught exception in enclave\";\n  }\n\n  if (output_len) {\n    *output_len = static_cast<uint64_t>(tmp_output_len);\n  }\n  return result;\n}", "func_src_after": "int ecall_restore(const char *input, uint64_t input_len, char **output,\n                  uint64_t *output_len) {\n  if (!asylo::primitives::TrustedPrimitives::IsOutsideEnclave(input,\n                                                              input_len) ||\n      !asylo::primitives::TrustedPrimitives::IsOutsideEnclave(\n          output_len, sizeof(uint64_t)) ||\n      !asylo::primitives::TrustedPrimitives::IsOutsideEnclave(output,\n                                                              *output_len)) {\n    asylo::primitives::TrustedPrimitives::BestEffortAbort(\n        \"ecall_restore: input/output found to not be in untrusted memory.\");\n  }\n  int result = 0;\n  size_t tmp_output_len;\n  try {\n    result = asylo::Restore(input, static_cast<size_t>(input_len), output,\n                            &tmp_output_len);\n  } catch (...) {\n    LOG(FATAL) << \"Uncaught exception in enclave\";\n  }\n\n  if (output_len) {\n    *output_len = static_cast<uint64_t>(tmp_output_len);\n  }\n  return result;\n}", "commit_link": "github.com/google/asylo/commit/382da2b8b09cbf928668a2445efb778f76bd9c8a", "file_name": "asylo/platform/primitives/sgx/ecalls.cc", "vul_type": "cwe-787", "description": "Write a C++ function named `ecall_restore` that checks if input and output buffers are outside enclave memory and performs a restore operation using Asylo primitives."}
{"func_name": "load", "func_src_before": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n        return PGMPomegranate(pgm_model)", "func_src_after": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(f.read())\n        return PGMPomegranate(pgm_model)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 413, "char_end": 483, "line": "                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n"}], "added": [{"line_no": 10, "char_start": 413, "char_end": 477, "line": "                pgm_model = BayesianNetwork.from_json(f.read())\n"}]}, "char_changes": {"deleted": [{"char_start": 467, "char_end": 476, "chars": "pickle.lo"}, {"char_start": 479, "char_end": 480, "chars": "f"}], "added": [{"char_start": 467, "char_end": 471, "chars": "f.re"}]}, "commit_link": "github.com/sara-02/fabric8-analytics-stack-analysis/commit/c9422e6257a8c927aed2999a0f4cc77f90059cda", "file_name": "pgm_pomegranate.py", "vul_type": "cwe-502", "commit_msg": "Remove pickling of model\n\nThe model is already being converted to a JSON(using the `to_json`)\nfunction of pomegranate which is already a stadard serialized format.\nI don't see a need to further serialize the JSON using pickle to\nsomething that can be loaded only using Python. This also helps us\nreduce the training time of the model as pickling and unpickling\nhas a overhead that I don't see a need for, because JSON.", "parent_commit": "c2ddf128d7206a0a85929b6f2a08078433ce1577", "description": "Create a Python method that loads a probabilistic graphical model from a local or S3 data store based on the provided filename."}
{"func_name": "test_fluent_safe", "func_src_before": "def test_fluent_safe():\n    hostname = 'www.python.org'\n    context = SSL.Context(SSL.SSLv23_METHOD)\n    context.set_options(SSL.OP_NO_TLSv1)\n    context.set_options(SSL.OP_NO_TLSv1_1)\n\n    conn = SSL.Connection(context, socket.socket(socket.AF_INET, socket.SOCK_STREAM))\n    r = conn.connect((hostname, 443))\n    print(r, conn.get_protocol_version_name())", "func_src_after": "def test_fluent_safe():\n    hostname = 'www.python.org'\n    context = SSL.Context(SSL.SSLv23_METHOD)\n    context.set_options(SSL.OP_NO_SSLv2)\n    context.set_options(SSL.OP_NO_SSLv3)\n    context.set_options(SSL.OP_NO_TLSv1)\n    context.set_options(SSL.OP_NO_TLSv1_1)\n\n    conn = SSL.Connection(context, socket.socket(socket.AF_INET, socket.SOCK_STREAM))\n    r = conn.connect((hostname, 443))\n    print(r, conn.get_protocol_version_name())", "line_changes": {"deleted": [], "added": [{"line_no": 4, "char_start": 101, "char_end": 142, "line": "    context.set_options(SSL.OP_NO_SSLv2)\n"}, {"line_no": 5, "char_start": 142, "char_end": 183, "line": "    context.set_options(SSL.OP_NO_SSLv3)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 101, "char_end": 183, "chars": "    context.set_options(SSL.OP_NO_SSLv2)\n    context.set_options(SSL.OP_NO_SSLv3)\n"}]}, "commit_link": "github.com/github/codeql/commit/54dad57cf4a22a9d01a434d0633606fa8adf7c8f", "file_name": "pyOpenSSL_fluent.py", "vul_type": "cwe-327", "commit_msg": "Update python/ql/test/query-tests/Security/CWE-327/pyOpenSSL_fluent.py\n\nCo-authored-by: Rasmus Wriedt Larsen <rasmuswriedtlarsen@gmail.com>", "parent_commit": "62a0775cf69c8bda45aeb9b0cdf60f28dafd9c72", "description": "Write a Python function that establishes a secure connection to a specified hostname and prints the connection result and protocol version."}
{"func_name": "gf_m2ts_process_pmt", "func_src_before": "static void gf_m2ts_process_pmt(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *pmt, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tu32 info_length, pos, desc_len, evt_type, nb_es,i;\n\tu32 nb_sections;\n\tu32 data_size;\n\tu32 nb_hevc, nb_hevc_temp, nb_shvc, nb_shvc_temp, nb_mhvc, nb_mhvc_temp;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\tGF_Err e = GF_OK;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\tnb_es = 0;\n\n\t/*skip if already received but no update detected (eg same data) */\n\tif ((status&GF_M2TS_TABLE_REPEAT) && !(status&GF_M2TS_TABLE_UPDATE))  {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t\treturn;\n\t}\n\n\tif (pmt->sec->demux_restarted) {\n\t\tpmt->sec->demux_restarted = 0;\n\t\treturn;\n\t}\n\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PMT Found or updated\\n\"));\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PMT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tpmt->program->pcr_pid = ((data[0] & 0x1f) << 8) | data[1];\n\n\tinfo_length = ((data[2]&0xf)<<8) | data[3];\n\tif (info_length != 0) {\n\t\t/* ...Read Descriptors ... */\n\t\tu8 tag, len;\n\t\tu32 first_loop_len = 0;\n\t\ttag = data[4];\n\t\tlen = data[5];\n\t\twhile (info_length > first_loop_len) {\n\t\t\tif (tag == GF_M2TS_MPEG4_IOD_DESCRIPTOR) {\n\t\t\t\tu32 size;\n\t\t\t\tGF_BitStream *iod_bs;\n\t\t\t\tiod_bs = gf_bs_new((char *)data+8, len-2, GF_BITSTREAM_READ);\n\t\t\t\tif (pmt->program->pmt_iod) gf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\te = gf_odf_parse_descriptor(iod_bs , (GF_Descriptor **) &pmt->program->pmt_iod, &size);\n\t\t\t\tgf_bs_del(iod_bs );\n\t\t\t\tif (e==GF_OK) {\n\t\t\t\t\t/*remember program number for service/program selection*/\n\t\t\t\t\tif (pmt->program->pmt_iod) pmt->program->pmt_iod->ServiceID = pmt->program->number;\n\t\t\t\t\t/*if empty IOD (freebox case), discard it and use dynamic declaration of object*/\n\t\t\t\t\tif (!gf_list_count(pmt->program->pmt_iod->ESDescriptors)) {\n\t\t\t\t\t\tgf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\t\t\tpmt->program->pmt_iod = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (tag == GF_M2TS_METADATA_POINTER_DESCRIPTOR) {\n\t\t\t\tGF_BitStream *metadatapd_bs;\n\t\t\t\tGF_M2TS_MetadataPointerDescriptor *metapd;\n\t\t\t\tmetadatapd_bs = gf_bs_new((char *)data+6, len, GF_BITSTREAM_READ);\n\t\t\t\tmetapd = gf_m2ts_read_metadata_pointer_descriptor(metadatapd_bs, len);\n\t\t\t\tgf_bs_del(metadatapd_bs);\n\t\t\t\tif (metapd->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->carriage_flag == METADATA_CARRIAGE_SAME_TS) {\n\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\tpmt->program->metadata_pointer_descriptor = metapd;\n\t\t\t\t} else {\n\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\tgf_m2ts_metadata_pointer_descriptor_del(metapd);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Skipping descriptor (0x%x) and others not supported\\n\", tag));\n\t\t\t}\n\t\t\tfirst_loop_len += 2 + len;\n\t\t}\n\t}\n\tif (data_size <= 4 + info_length) return;\n\tdata += 4 + info_length;\n\tdata_size -= 4 + info_length;\n\tpos = 0;\n\n\t/* count de number of program related PMT received */\n\tfor(i=0; i<gf_list_count(ts->programs); i++) {\n\t\tGF_M2TS_Program *prog = (GF_M2TS_Program *)gf_list_get(ts->programs,i);\n\t\tif(prog->pmt_pid == pmt->pid) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tnb_hevc = nb_hevc_temp = nb_shvc = nb_shvc_temp = nb_mhvc = nb_mhvc_temp = 0;\n\twhile (pos<data_size) {\n\t\tGF_M2TS_PES *pes = NULL;\n\t\tGF_M2TS_SECTION_ES *ses = NULL;\n\t\tGF_M2TS_ES *es = NULL;\n\t\tBool inherit_pcr = 0;\n\t\tu32 pid, stream_type, reg_desc_format;\n\n\t\tstream_type = data[0];\n\t\tpid = ((data[1] & 0x1f) << 8) | data[2];\n\t\tdesc_len = ((data[3] & 0xf) << 8) | data[4];\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"stream_type :%d \\n\",stream_type));\n\t\tswitch (stream_type) {\n\n\t\t/* PES */\n\t\tcase GF_M2TS_VIDEO_MPEG1:\n\t\tcase GF_M2TS_VIDEO_MPEG2:\n\t\tcase GF_M2TS_VIDEO_DCII:\n\t\tcase GF_M2TS_VIDEO_MPEG4:\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_PES:\n\t\tcase GF_M2TS_VIDEO_H264:\n\t\tcase GF_M2TS_VIDEO_SVC:\n\t\tcase GF_M2TS_VIDEO_MVCD:\n\t\tcase GF_M2TS_VIDEO_HEVC:\n\t\tcase GF_M2TS_VIDEO_HEVC_MCTS:\n\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\tinherit_pcr = 1;\n\t\tcase GF_M2TS_AUDIO_MPEG1:\n\t\tcase GF_M2TS_AUDIO_MPEG2:\n\t\tcase GF_M2TS_AUDIO_AAC:\n\t\tcase GF_M2TS_AUDIO_LATM_AAC:\n\t\tcase GF_M2TS_AUDIO_AC3:\n\t\tcase GF_M2TS_AUDIO_DTS:\n\t\tcase GF_M2TS_MHAS_MAIN:\n\t\tcase GF_M2TS_MHAS_AUX:\n\t\tcase GF_M2TS_SUBTITLE_DVB:\n\t\tcase GF_M2TS_METADATA_PES:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tif (inherit_pcr)\n\t\t\t\tpes->flags |= GF_M2TS_INHERIT_PCR;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\tcase GF_M2TS_PRIVATE_DATA:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\t/* Sections */\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_SECTIONS:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\t/* carriage of ISO_IEC_14496 data in sections */\n\t\t\tif (stream_type == GF_M2TS_SYSTEMS_MPEG4_SECTIONS) {\n\t\t\t\t/*MPEG-4 sections need to be fully checked: if one section is lost, this means we lost\n\t\t\t\tone SL packet in the AU so we must wait for the complete section again*/\n\t\t\t\tses->sec = gf_m2ts_section_filter_new(gf_m2ts_process_mpeg4section, 0);\n\t\t\t\t/*create OD container*/\n\t\t\t\tif (!pmt->program->additional_ods) {\n\t\t\t\t\tpmt->program->additional_ods = gf_list_new();\n\t\t\t\t\tts->has_4on2 = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_13818_6_ANNEX_A:\n\t\tcase GF_M2TS_13818_6_ANNEX_B:\n\t\tcase GF_M2TS_13818_6_ANNEX_C:\n\t\tcase GF_M2TS_13818_6_ANNEX_D:\n\t\tcase GF_M2TS_PRIVATE_SECTION:\n\t\tcase GF_M2TS_QUALITY_SEC:\n\t\tcase GF_M2TS_MORE_SEC:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\tes->pid = pid;\n\t\t\tes->service_id = pmt->program->number;\n\t\t\tif (stream_type == GF_M2TS_PRIVATE_SECTION) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"AIT sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_QUALITY_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Quality metadata sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_MORE_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"MORE sections on pid %d\\n\", pid));\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type DSM CC user private sections on pid %d \\n\", pid));\n\t\t\t}\n\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t//ses->sec->service_id = pmt->program->number;\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_MPE_SECTIONS:\n\t\t\tif (! ts->prefix_present) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type MPE found : pid = %d \\n\", pid));\n#ifdef GPAC_ENABLE_MPE\n\t\t\t\tes = gf_dvb_mpe_section_new();\n\t\t\t\tif (es->flags & GF_M2TS_ES_IS_SECTION) {\n\t\t\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\t\t\t((GF_M2TS_SECTION_ES*)es)->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t}\n#endif\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\t//GF_LOG(/*GF_LOG_WARNING*/GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\tbreak;\n\t\t}\n\n\t\tif (es) {\n\t\t\tes->stream_type = (stream_type==GF_M2TS_PRIVATE_DATA) ? 0 : stream_type;\n\t\t\tes->program = pmt->program;\n\t\t\tes->pid = pid;\n\t\t\tes->component_tag = -1;\n\t\t}\n\n\t\tpos += 5;\n\t\tdata += 5;\n\n\t\twhile (desc_len) {\n\t\t\tu8 tag = data[0];\n\t\t\tu32 len = data[1];\n\t\t\tif (es) {\n\t\t\t\tswitch (tag) {\n\t\t\t\tcase GF_M2TS_ISO_639_LANGUAGE_DESCRIPTOR:\n\t\t\t\t\tif (pes)\n\t\t\t\t\t\tpes->lang = GF_4CC(' ', data[2], data[3], data[4]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_MPEG4_SL_DESCRIPTOR:\n\t\t\t\t\tes->mpeg4_es_id = ( (u32) data[2] & 0x1f) << 8  | data[3];\n\t\t\t\t\tes->flags |= GF_M2TS_ES_IS_SL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_REGISTRATION_DESCRIPTOR:\n\t\t\t\t\treg_desc_format = GF_4CC(data[2], data[3], data[4], data[5]);\n\t\t\t\t\t/*cf http://www.smpte-ra.org/mpegreg/mpegreg.html*/\n\t\t\t\t\tswitch (reg_desc_format) {\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_AC3:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_AC3;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_VC1:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_VIDEO_VC1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_GPAC:\n\t\t\t\t\t\tif (len==8) {\n\t\t\t\t\t\t\tes->stream_type = GF_4CC(data[6], data[7], data[8], data[9]);\n\t\t\t\t\t\t\tes->flags |= GF_M2TS_GPAC_CODEC_ID;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Unknown registration descriptor %s\\n\", gf_4cc_to_str(reg_desc_format) ));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_EAC3_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_EC3;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_DATA_BROADCAST_ID_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tu32 id = data[2]<<8 | data[3];\n\t\t\t\t\tif ((id == 0xB) && ses && !ses->sec) {\n\t\t\t\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_SUBTITLING_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tpes->sub.language[0] = data[2];\n\t\t\t\t\t\tpes->sub.language[1] = data[3];\n\t\t\t\t\t\tpes->sub.language[2] = data[4];\n\t\t\t\t\t\tpes->sub.type = data[5];\n\t\t\t\t\t\tpes->sub.composition_page_id = (data[6]<<8) | data[7];\n\t\t\t\t\t\tpes->sub.ancillary_page_id = (data[8]<<8) | data[9];\n\t\t\t\t\t}\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_SUBTITLE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_STREAM_IDENTIFIER_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tes->component_tag = data[2];\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"Component Tag: %d on Program %d\\n\", es->component_tag, es->program->number));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_TELETEXT_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_TELETEXT;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_VBI_DATA_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_VBI;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_HIERARCHY_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tu8 hierarchy_embedded_layer_index;\n\t\t\t\t\t\tGF_BitStream *hbs = gf_bs_new((const char *)data, data_size, GF_BITSTREAM_READ);\n\t\t\t\t\t\t/*u32 skip = */gf_bs_read_int(hbs, 16);\n\t\t\t\t\t\t/*u8 res1 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 temp_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 spatial_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 quality_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 hierarchy_type = */gf_bs_read_int(hbs, 4);\n\t\t\t\t\t\t/*u8 res2 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_layer_index = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 tref_not_present = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 res3 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\thierarchy_embedded_layer_index = gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 res4 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_channel = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\tgf_bs_del(hbs);\n\n\t\t\t\t\t\tpes->depends_on_pid = 1+hierarchy_embedded_layer_index;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_METADATA_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tGF_BitStream *metadatad_bs;\n\t\t\t\t\tGF_M2TS_MetadataDescriptor *metad;\n\t\t\t\t\tmetadatad_bs = gf_bs_new((char *)data+2, len, GF_BITSTREAM_READ);\n\t\t\t\t\tmetad = gf_m2ts_read_metadata_descriptor(metadatad_bs, len);\n\t\t\t\t\tgf_bs_del(metadatad_bs);\n\t\t\t\t\tif (metad->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t\t        metad->format_identifier == GF_M2TS_META_ID3) {\n\t\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\t\tif (pes) {\n\t\t\t\t\t\t\tpes->metadata_descriptor = metad;\n\t\t\t\t\t\t\tpes->stream_type = GF_M2TS_METADATA_ID3_HLS;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\t\tgf_m2ts_metadata_descriptor_del(metad);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] skipping descriptor (0x%x) not supported\\n\", tag));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdata += len+2;\n\t\t\tpos += len+2;\n\t\t\tif (desc_len < len+2) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Invalid PMT es descriptor size for PID %d\\n\", pid ) );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdesc_len-=len+2;\n\t\t}\n\n\t\tif (es && !es->stream_type) {\n\t\t\tgf_free(es);\n\t\t\tes = NULL;\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Private Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t}\n\n\t\tif (!es) continue;\n\n\t\tif (ts->ess[pid]) {\n\t\t\t//this is component reuse across programs, overwrite the previously declared stream ...\n\t\t\tif (status & GF_M2TS_TABLE_FOUND) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PID %d reused across programs %d and %d, not completely supported\\n\", pid, ts->ess[pid]->program->number, es->program->number ) );\n\n\t\t\t\t//add stream to program but don't reassign the pid table until the stream is playing (>GF_M2TS_PES_FRAMING_SKIP)\n\t\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\t\tnb_es++;\n\t\t\t\t//skip assignment below\n\t\t\t\tes = NULL;\n\t\t\t}\n\t\t\t/*watchout for pmt update - FIXME this likely won't work in most cases*/\n\t\t\telse {\n\n\t\t\t\tGF_M2TS_ES *o_es = ts->ess[es->pid];\n\n\t\t\t\tif ((o_es->stream_type == es->stream_type)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK) == (es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK))\n\t\t\t\t        && (o_es->mpeg4_es_id == es->mpeg4_es_id)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_IS_SECTION) || ((GF_M2TS_PES *)o_es)->lang == ((GF_M2TS_PES *)es)->lang)\n\t\t\t\t   ) {\n\t\t\t\t\tgf_free(es);\n\t\t\t\t\tes = NULL;\n\t\t\t\t} else {\n\t\t\t\t\tgf_m2ts_es_del(o_es, ts);\n\t\t\t\t\tts->ess[es->pid] = NULL;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (es) {\n\t\t\tts->ess[es->pid] = es;\n\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\tnb_es++;\n\t\t}\n\n\t\tif (es->stream_type == GF_M2TS_VIDEO_HEVC) nb_hevc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_HEVC_TEMPORAL) nb_hevc_temp++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC) nb_shvc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC_TEMPORAL) nb_shvc_temp++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC) nb_mhvc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC_TEMPORAL) nb_mhvc_temp++;\n\t}\n\n\t//Table 2-139, implied hierarchy indexes\n\tif (nb_hevc_temp + nb_shvc + nb_shvc_temp + nb_mhvc+ nb_mhvc_temp) {\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (es->depends_on_pid) continue;\n\n\t\t\tswitch (es->stream_type) {\n\t\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 1;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 2;\n\t\t\t\telse es->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nb_es) {\n\t\tu32 i;\n\n\t\t//translate hierarchy descriptors indexes into PIDs - check whether the PMT-index rules are the same for HEVC\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *an_es = NULL;\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (!es->depends_on_pid) continue;\n\n\t\t\t//fixeme we are not always assured that hierarchy_layer_index matches the stream index...\n\t\t\t//+1 is because our first stream is the PMT\n\t\t\tan_es =  (GF_M2TS_PES *)gf_list_get(pmt->program->streams, es->depends_on_pid);\n\t\t\tif (an_es) {\n\t\t\t\tes->depends_on_pid = an_es->pid;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[M2TS] Wrong dependency index in hierarchy descriptor, assuming non-scalable stream\\n\"));\n\t\t\t\tes->depends_on_pid = 0;\n\t\t\t}\n\t\t}\n\n\t\tevt_type = (status&GF_M2TS_TABLE_FOUND) ? GF_M2TS_EVT_PMT_FOUND : GF_M2TS_EVT_PMT_UPDATE;\n\t\tif (ts->on_event) ts->on_event(ts, evt_type, pmt->program);\n\t} else {\n\t\t/* if we found no new ES it's simply a repeat of the PMT */\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t}\n}", "func_src_after": "static void gf_m2ts_process_pmt(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *pmt, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tu32 info_length, pos, desc_len, evt_type, nb_es,i;\n\tu32 nb_sections;\n\tu32 data_size;\n\tu32 nb_hevc, nb_hevc_temp, nb_shvc, nb_shvc_temp, nb_mhvc, nb_mhvc_temp;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\tGF_Err e = GF_OK;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\tnb_es = 0;\n\n\t/*skip if already received but no update detected (eg same data) */\n\tif ((status&GF_M2TS_TABLE_REPEAT) && !(status&GF_M2TS_TABLE_UPDATE))  {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t\treturn;\n\t}\n\n\tif (pmt->sec->demux_restarted) {\n\t\tpmt->sec->demux_restarted = 0;\n\t\treturn;\n\t}\n\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PMT Found or updated\\n\"));\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PMT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tpmt->program->pcr_pid = ((data[0] & 0x1f) << 8) | data[1];\n\n\tinfo_length = ((data[2]&0xf)<<8) | data[3];\n\tif (info_length != 0) {\n\t\t/* ...Read Descriptors ... */\n\t\tu8 tag, len;\n\t\tu32 first_loop_len = 0;\n\t\ttag = data[4];\n\t\tlen = data[5];\n\t\twhile (info_length > first_loop_len) {\n\t\t\tif (tag == GF_M2TS_MPEG4_IOD_DESCRIPTOR) {\n\t\t\t\tu32 size;\n\t\t\t\tGF_BitStream *iod_bs;\n\t\t\t\tiod_bs = gf_bs_new((char *)data+8, len-2, GF_BITSTREAM_READ);\n\t\t\t\tif (pmt->program->pmt_iod) gf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\te = gf_odf_parse_descriptor(iod_bs , (GF_Descriptor **) &pmt->program->pmt_iod, &size);\n\t\t\t\tgf_bs_del(iod_bs );\n\t\t\t\tif (e==GF_OK) {\n\t\t\t\t\t/*remember program number for service/program selection*/\n\t\t\t\t\tif (pmt->program->pmt_iod) pmt->program->pmt_iod->ServiceID = pmt->program->number;\n\t\t\t\t\t/*if empty IOD (freebox case), discard it and use dynamic declaration of object*/\n\t\t\t\t\tif (!gf_list_count(pmt->program->pmt_iod->ESDescriptors)) {\n\t\t\t\t\t\tgf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\t\t\tpmt->program->pmt_iod = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (tag == GF_M2TS_METADATA_POINTER_DESCRIPTOR) {\n\t\t\t\tGF_BitStream *metadatapd_bs;\n\t\t\t\tGF_M2TS_MetadataPointerDescriptor *metapd;\n\t\t\t\tmetadatapd_bs = gf_bs_new((char *)data+6, len, GF_BITSTREAM_READ);\n\t\t\t\tmetapd = gf_m2ts_read_metadata_pointer_descriptor(metadatapd_bs, len);\n\t\t\t\tgf_bs_del(metadatapd_bs);\n\t\t\t\tif (metapd->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->carriage_flag == METADATA_CARRIAGE_SAME_TS) {\n\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\tpmt->program->metadata_pointer_descriptor = metapd;\n\t\t\t\t} else {\n\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\tgf_m2ts_metadata_pointer_descriptor_del(metapd);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Skipping descriptor (0x%x) and others not supported\\n\", tag));\n\t\t\t}\n\t\t\tfirst_loop_len += 2 + len;\n\t\t}\n\t}\n\tif (data_size <= 4 + info_length) return;\n\tdata += 4 + info_length;\n\tdata_size -= 4 + info_length;\n\tpos = 0;\n\n\t/* count de number of program related PMT received */\n\tfor(i=0; i<gf_list_count(ts->programs); i++) {\n\t\tGF_M2TS_Program *prog = (GF_M2TS_Program *)gf_list_get(ts->programs,i);\n\t\tif(prog->pmt_pid == pmt->pid) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tnb_hevc = nb_hevc_temp = nb_shvc = nb_shvc_temp = nb_mhvc = nb_mhvc_temp = 0;\n\twhile (pos<data_size) {\n\t\tGF_M2TS_PES *pes = NULL;\n\t\tGF_M2TS_SECTION_ES *ses = NULL;\n\t\tGF_M2TS_ES *es = NULL;\n\t\tBool inherit_pcr = 0;\n\t\tu32 pid, stream_type, reg_desc_format;\n\n\t\tstream_type = data[0];\n\t\tpid = ((data[1] & 0x1f) << 8) | data[2];\n\t\tdesc_len = ((data[3] & 0xf) << 8) | data[4];\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"stream_type :%d \\n\",stream_type));\n\t\tswitch (stream_type) {\n\n\t\t/* PES */\n\t\tcase GF_M2TS_VIDEO_MPEG1:\n\t\tcase GF_M2TS_VIDEO_MPEG2:\n\t\tcase GF_M2TS_VIDEO_DCII:\n\t\tcase GF_M2TS_VIDEO_MPEG4:\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_PES:\n\t\tcase GF_M2TS_VIDEO_H264:\n\t\tcase GF_M2TS_VIDEO_SVC:\n\t\tcase GF_M2TS_VIDEO_MVCD:\n\t\tcase GF_M2TS_VIDEO_HEVC:\n\t\tcase GF_M2TS_VIDEO_HEVC_MCTS:\n\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\tinherit_pcr = 1;\n\t\tcase GF_M2TS_AUDIO_MPEG1:\n\t\tcase GF_M2TS_AUDIO_MPEG2:\n\t\tcase GF_M2TS_AUDIO_AAC:\n\t\tcase GF_M2TS_AUDIO_LATM_AAC:\n\t\tcase GF_M2TS_AUDIO_AC3:\n\t\tcase GF_M2TS_AUDIO_DTS:\n\t\tcase GF_M2TS_MHAS_MAIN:\n\t\tcase GF_M2TS_MHAS_AUX:\n\t\tcase GF_M2TS_SUBTITLE_DVB:\n\t\tcase GF_M2TS_METADATA_PES:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tif (inherit_pcr)\n\t\t\t\tpes->flags |= GF_M2TS_INHERIT_PCR;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\tcase GF_M2TS_PRIVATE_DATA:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\t/* Sections */\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_SECTIONS:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\t/* carriage of ISO_IEC_14496 data in sections */\n\t\t\tif (stream_type == GF_M2TS_SYSTEMS_MPEG4_SECTIONS) {\n\t\t\t\t/*MPEG-4 sections need to be fully checked: if one section is lost, this means we lost\n\t\t\t\tone SL packet in the AU so we must wait for the complete section again*/\n\t\t\t\tses->sec = gf_m2ts_section_filter_new(gf_m2ts_process_mpeg4section, 0);\n\t\t\t\t/*create OD container*/\n\t\t\t\tif (!pmt->program->additional_ods) {\n\t\t\t\t\tpmt->program->additional_ods = gf_list_new();\n\t\t\t\t\tts->has_4on2 = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_13818_6_ANNEX_A:\n\t\tcase GF_M2TS_13818_6_ANNEX_B:\n\t\tcase GF_M2TS_13818_6_ANNEX_C:\n\t\tcase GF_M2TS_13818_6_ANNEX_D:\n\t\tcase GF_M2TS_PRIVATE_SECTION:\n\t\tcase GF_M2TS_QUALITY_SEC:\n\t\tcase GF_M2TS_MORE_SEC:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\tes->pid = pid;\n\t\t\tes->service_id = pmt->program->number;\n\t\t\tif (stream_type == GF_M2TS_PRIVATE_SECTION) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"AIT sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_QUALITY_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Quality metadata sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_MORE_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"MORE sections on pid %d\\n\", pid));\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type DSM CC user private sections on pid %d \\n\", pid));\n\t\t\t}\n\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t//ses->sec->service_id = pmt->program->number;\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_MPE_SECTIONS:\n\t\t\tif (! ts->prefix_present) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type MPE found : pid = %d \\n\", pid));\n#ifdef GPAC_ENABLE_MPE\n\t\t\t\tes = gf_dvb_mpe_section_new();\n\t\t\t\tif (es->flags & GF_M2TS_ES_IS_SECTION) {\n\t\t\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\t\t\t((GF_M2TS_SECTION_ES*)es)->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t}\n#endif\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\t//GF_LOG(/*GF_LOG_WARNING*/GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\tbreak;\n\t\t}\n\n\t\tif (es) {\n\t\t\tes->stream_type = (stream_type==GF_M2TS_PRIVATE_DATA) ? 0 : stream_type;\n\t\t\tes->program = pmt->program;\n\t\t\tes->pid = pid;\n\t\t\tes->component_tag = -1;\n\t\t}\n\n\t\tpos += 5;\n\t\tdata += 5;\n\n\t\twhile (desc_len) {\n\t\t\tu8 tag = data[0];\n\t\t\tu32 len = data[1];\n\t\t\tif (es) {\n\t\t\t\tswitch (tag) {\n\t\t\t\tcase GF_M2TS_ISO_639_LANGUAGE_DESCRIPTOR:\n\t\t\t\t\tif (pes)\n\t\t\t\t\t\tpes->lang = GF_4CC(' ', data[2], data[3], data[4]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_MPEG4_SL_DESCRIPTOR:\n\t\t\t\t\tes->mpeg4_es_id = ( (u32) data[2] & 0x1f) << 8  | data[3];\n\t\t\t\t\tes->flags |= GF_M2TS_ES_IS_SL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_REGISTRATION_DESCRIPTOR:\n\t\t\t\t\treg_desc_format = GF_4CC(data[2], data[3], data[4], data[5]);\n\t\t\t\t\t/*cf http://www.smpte-ra.org/mpegreg/mpegreg.html*/\n\t\t\t\t\tswitch (reg_desc_format) {\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_AC3:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_AC3;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_VC1:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_VIDEO_VC1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_GPAC:\n\t\t\t\t\t\tif (len==8) {\n\t\t\t\t\t\t\tes->stream_type = GF_4CC(data[6], data[7], data[8], data[9]);\n\t\t\t\t\t\t\tes->flags |= GF_M2TS_GPAC_CODEC_ID;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Unknown registration descriptor %s\\n\", gf_4cc_to_str(reg_desc_format) ));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_EAC3_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_EC3;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_DATA_BROADCAST_ID_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tu32 id = data[2]<<8 | data[3];\n\t\t\t\t\tif ((id == 0xB) && ses && !ses->sec) {\n\t\t\t\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_SUBTITLING_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tpes->sub.language[0] = data[2];\n\t\t\t\t\t\tpes->sub.language[1] = data[3];\n\t\t\t\t\t\tpes->sub.language[2] = data[4];\n\t\t\t\t\t\tpes->sub.type = data[5];\n\t\t\t\t\t\tpes->sub.composition_page_id = (data[6]<<8) | data[7];\n\t\t\t\t\t\tpes->sub.ancillary_page_id = (data[8]<<8) | data[9];\n\t\t\t\t\t}\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_SUBTITLE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_STREAM_IDENTIFIER_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tes->component_tag = data[2];\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"Component Tag: %d on Program %d\\n\", es->component_tag, es->program->number));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_TELETEXT_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_TELETEXT;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_VBI_DATA_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_VBI;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_HIERARCHY_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tu8 hierarchy_embedded_layer_index;\n\t\t\t\t\t\tGF_BitStream *hbs = gf_bs_new((const char *)data, data_size, GF_BITSTREAM_READ);\n\t\t\t\t\t\t/*u32 skip = */gf_bs_read_int(hbs, 16);\n\t\t\t\t\t\t/*u8 res1 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 temp_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 spatial_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 quality_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 hierarchy_type = */gf_bs_read_int(hbs, 4);\n\t\t\t\t\t\t/*u8 res2 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_layer_index = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 tref_not_present = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 res3 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\thierarchy_embedded_layer_index = gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 res4 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_channel = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\tgf_bs_del(hbs);\n\n\t\t\t\t\t\tpes->depends_on_pid = 1+hierarchy_embedded_layer_index;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_METADATA_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tGF_BitStream *metadatad_bs;\n\t\t\t\t\tGF_M2TS_MetadataDescriptor *metad;\n\t\t\t\t\tmetadatad_bs = gf_bs_new((char *)data+2, len, GF_BITSTREAM_READ);\n\t\t\t\t\tmetad = gf_m2ts_read_metadata_descriptor(metadatad_bs, len);\n\t\t\t\t\tgf_bs_del(metadatad_bs);\n\t\t\t\t\tif (metad->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t\t        metad->format_identifier == GF_M2TS_META_ID3) {\n\t\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\t\tif (pes) {\n\t\t\t\t\t\t\tpes->metadata_descriptor = metad;\n\t\t\t\t\t\t\tpes->stream_type = GF_M2TS_METADATA_ID3_HLS;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\t\tgf_m2ts_metadata_descriptor_del(metad);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] skipping descriptor (0x%x) not supported\\n\", tag));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdata += len+2;\n\t\t\tpos += len+2;\n\t\t\tif (desc_len < len+2) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Invalid PMT es descriptor size for PID %d\\n\", pid ) );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdesc_len-=len+2;\n\t\t}\n\n\t\tif (es && !es->stream_type) {\n\t\t\tgf_free(es);\n\t\t\tes = NULL;\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Private Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t}\n\n\t\tif (!es) continue;\n\n\t\tif (ts->ess[pid]) {\n\t\t\t//this is component reuse across programs, overwrite the previously declared stream ...\n\t\t\tif (status & GF_M2TS_TABLE_FOUND) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PID %d reused across programs %d and %d, not completely supported\\n\", pid, ts->ess[pid]->program->number, es->program->number ) );\n\n\t\t\t\t//add stream to program but don't reassign the pid table until the stream is playing (>GF_M2TS_PES_FRAMING_SKIP)\n\t\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\t\tnb_es++;\n\t\t\t\t//skip assignment below\n\t\t\t\tes = NULL;\n\t\t\t}\n\t\t\t/*watchout for pmt update - FIXME this likely won't work in most cases*/\n\t\t\telse {\n\n\t\t\t\tGF_M2TS_ES *o_es = ts->ess[es->pid];\n\n\t\t\t\tif ((o_es->stream_type == es->stream_type)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK) == (es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK))\n\t\t\t\t        && (o_es->mpeg4_es_id == es->mpeg4_es_id)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_IS_SECTION) || ((GF_M2TS_PES *)o_es)->lang == ((GF_M2TS_PES *)es)->lang)\n\t\t\t\t   ) {\n\t\t\t\t\tgf_free(es);\n\t\t\t\t\tes = NULL;\n\t\t\t\t} else {\n\t\t\t\t\tgf_m2ts_es_del(o_es, ts);\n\t\t\t\t\tts->ess[es->pid] = NULL;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (es) {\n\t\t\tts->ess[es->pid] = es;\n\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\tnb_es++;\n\n\t\t\tif (es->stream_type == GF_M2TS_VIDEO_HEVC) nb_hevc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_HEVC_TEMPORAL) nb_hevc_temp++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC) nb_shvc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC_TEMPORAL) nb_shvc_temp++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC) nb_mhvc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC_TEMPORAL) nb_mhvc_temp++;\n\t\t}\n\t}\n\n\t//Table 2-139, implied hierarchy indexes\n\tif (nb_hevc_temp + nb_shvc + nb_shvc_temp + nb_mhvc+ nb_mhvc_temp) {\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (es->depends_on_pid) continue;\n\n\t\t\tswitch (es->stream_type) {\n\t\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 1;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 2;\n\t\t\t\telse es->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nb_es) {\n\t\tu32 i;\n\n\t\t//translate hierarchy descriptors indexes into PIDs - check whether the PMT-index rules are the same for HEVC\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *an_es = NULL;\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (!es->depends_on_pid) continue;\n\n\t\t\t//fixeme we are not always assured that hierarchy_layer_index matches the stream index...\n\t\t\t//+1 is because our first stream is the PMT\n\t\t\tan_es =  (GF_M2TS_PES *)gf_list_get(pmt->program->streams, es->depends_on_pid);\n\t\t\tif (an_es) {\n\t\t\t\tes->depends_on_pid = an_es->pid;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[M2TS] Wrong dependency index in hierarchy descriptor, assuming non-scalable stream\\n\"));\n\t\t\t\tes->depends_on_pid = 0;\n\t\t\t}\n\t\t}\n\n\t\tevt_type = (status&GF_M2TS_TABLE_FOUND) ? GF_M2TS_EVT_PMT_FOUND : GF_M2TS_EVT_PMT_UPDATE;\n\t\tif (ts->on_event) ts->on_event(ts, evt_type, pmt->program);\n\t} else {\n\t\t/* if we found no new ES it's simply a repeat of the PMT */\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t}\n}", "commit_link": "github.com/gpac/gpac/commit/2320eb73afba753b39b7147be91f7be7afc0eeb7", "file_name": "src/media_tools/mpegts.c", "vul_type": "cwe-125", "description": "Write a C function to process PMT sections in an MPEG-2 TS demuxer."}
{"func_name": "PeerListWidget::addPeer", "func_src_before": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), peer.client());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "func_src_after": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), Utils::String::toHtmlEscaped(peer.client()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/gui/properties/peerlistwidget.cpp", "vul_type": "cwe-079", "description": "In C++, write a function to add a peer's details to a list model in a peer list widget."}
{"func_name": "add_translationname", "func_src_before": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (\"%s\", \"%s\", \"%s\")' % (item[0], trname[1], trname[2]))\n            self.connection.commit()", "func_src_after": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                t = (item[0], trname[1], trname[2], )\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (?, ?, ?)', t)\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new translation into a database given an item name and translation details."}
{"func_name": "test_create_modify_host", "func_src_before": "    def test_create_modify_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack(NO_FC_HOST_RET), ''])\n\n        create_host_cmd = ('createhost -add fakehost '\n                           '123456789012345 123456789054321')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_modify_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack(NO_FC_HOST_RET), ''])\n\n        create_host_cmd = ['createhost', '-add', 'fakehost', '123456789012345',\n                           '123456789054321']\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying a host in an HP 3PAR storage system."}
{"func_name": "ExtractPostscript", "func_src_before": "static Image *ExtractPostscript(Image *image,const ImageInfo *image_info,\n  MagickOffsetType PS_Offset,ssize_t PS_Size,ExceptionInfo *exception)\n{\n  char\n    postscript_file[MaxTextExtent];\n\n  const MagicInfo\n    *magic_info;\n\n  FILE\n    *ps_file;\n\n  ImageInfo\n    *clone_info;\n\n  Image\n    *image2;\n\n  unsigned char\n    magick[2*MaxTextExtent];\n\n\n  if ((clone_info=CloneImageInfo(image_info)) == NULL)\n    return(image);\n  clone_info->blob=(void *) NULL;\n  clone_info->length=0;\n\n  /* Obtain temporary file */\n  (void) AcquireUniqueFilename(postscript_file);\n  ps_file=fopen_utf8(postscript_file,\"wb\");\n  if (ps_file == (FILE *) NULL)\n    goto FINISH;\n\n  /* Copy postscript to temporary file */\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  (void) ReadBlob(image, 2*MaxTextExtent, magick);\n\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  while(PS_Size-- > 0)\n    {\n      (void) fputc(ReadBlobByte(image),ps_file);\n    }\n  (void) fclose(ps_file);\n\n    /* Detect file format - Check magic.mgk configuration file. */\n  magic_info=GetMagicInfo(magick,2*MaxTextExtent,exception);\n  if(magic_info == (const MagicInfo *) NULL) goto FINISH_UNL;\n  /*     printf(\"Detected:%s  \\n\",magic_info->name); */\n  if(exception->severity != UndefinedException) goto FINISH_UNL;\n  if(magic_info->name == (char *) NULL) goto FINISH_UNL;\n\n  (void) CopyMagickMemory(clone_info->magick,magic_info->name,MaxTextExtent);\n\n    /* Read nested image */\n  /*FormatString(clone_info->filename,\"%s:%s\",magic_info->name,postscript_file);*/\n  FormatLocaleString(clone_info->filename,MaxTextExtent,\"%s\",postscript_file);\n  image2=ReadImage(clone_info,exception);\n\n  if (!image2)\n    goto FINISH_UNL;\n\n  /*\n    Replace current image with new image while copying base image\n    attributes.\n  */\n  (void) CopyMagickMemory(image2->filename,image->filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick_filename,image->magick_filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick,image->magick,MaxTextExtent);\n  image2->depth=image->depth;\n  DestroyBlob(image2);\n  image2->blob=ReferenceBlob(image->blob);\n\n  if ((image->rows == 0) || (image->columns == 0))\n    DeleteImageFromList(&image);\n\n  AppendImageToList(&image,image2);\n\n FINISH_UNL:\n  (void) RelinquishUniqueFileResource(postscript_file);\n FINISH:\n  DestroyImageInfo(clone_info);\n  return(image);\n}", "func_src_after": "static Image *ExtractPostscript(Image *image,const ImageInfo *image_info,\n  MagickOffsetType PS_Offset,ssize_t PS_Size,ExceptionInfo *exception)\n{\n  char\n    postscript_file[MaxTextExtent];\n\n  const MagicInfo\n    *magic_info;\n\n  FILE\n    *ps_file;\n\n  ImageInfo\n    *clone_info;\n\n  Image\n    *image2;\n\n  unsigned char\n    magick[2*MaxTextExtent];\n\n\n  if ((clone_info=CloneImageInfo(image_info)) == NULL)\n    return(image);\n  clone_info->blob=(void *) NULL;\n  clone_info->length=0;\n\n  /* Obtain temporary file */\n  (void) AcquireUniqueFilename(postscript_file);\n  ps_file=fopen_utf8(postscript_file,\"wb\");\n  if (ps_file == (FILE *) NULL)\n    goto FINISH;\n\n  /* Copy postscript to temporary file */\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  (void) ReadBlob(image, 2*MaxTextExtent, magick);\n\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  while(PS_Size-- > 0)\n    {\n      (void) fputc(ReadBlobByte(image),ps_file);\n    }\n  (void) fclose(ps_file);\n\n    /* Detect file format - Check magic.mgk configuration file. */\n  magic_info=GetMagicInfo(magick,2*MaxTextExtent,exception);\n  if(magic_info == (const MagicInfo *) NULL) goto FINISH_UNL;\n  /*     printf(\"Detected:%s  \\n\",magic_info->name); */\n  if(exception->severity != UndefinedException) goto FINISH_UNL;\n  if(magic_info->name == (char *) NULL) goto FINISH_UNL;\n\n  (void) strncpy(clone_info->magick,magic_info->name,MaxTextExtent);\n\n    /* Read nested image */\n  /*FormatString(clone_info->filename,\"%s:%s\",magic_info->name,postscript_file);*/\n  FormatLocaleString(clone_info->filename,MaxTextExtent,\"%s\",postscript_file);\n  image2=ReadImage(clone_info,exception);\n\n  if (!image2)\n    goto FINISH_UNL;\n\n  /*\n    Replace current image with new image while copying base image\n    attributes.\n  */\n  (void) CopyMagickMemory(image2->filename,image->filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick_filename,image->magick_filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick,image->magick,MaxTextExtent);\n  image2->depth=image->depth;\n  DestroyBlob(image2);\n  image2->blob=ReferenceBlob(image->blob);\n\n  if ((image->rows == 0) || (image->columns == 0))\n    DeleteImageFromList(&image);\n\n  AppendImageToList(&image,image2);\n\n FINISH_UNL:\n  (void) RelinquishUniqueFileResource(postscript_file);\n FINISH:\n  DestroyImageInfo(clone_info);\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/a251039393f423c7858e63cab6aa98d17b8b7a41", "file_name": "coders/wpg.c", "vul_type": "cwe-125", "description": "Write a C function to extract a Postscript section from an image and read it into a new image structure."}
{"func_name": "JUtil::unpackJar", "func_src_before": "   public static void unpackJar(File fjar, File fout) throws IOException {\n    \n      JarFile jf = new JarFile(fjar);\n      Enumeration<JarEntry> en = jf.entries();\n\n      while (en.hasMoreElements()) {\n         JarEntry je = en.nextElement();\n         java.io.File f = new File(fout,  je.getName());\n         if (je.isDirectory()) {\n            f.mkdirs();\n            continue;\n\n         } else {\n            // f.getParentFile().mkdirs();\n\n            if (f.getPath().indexOf(\"META-INF\") >= 0) {\n               // skip it\n            } else {\n            f.getParentFile().mkdirs();\n            java.io.InputStream is = jf.getInputStream(je);\n            java.io.FileOutputStream fos = new FileOutputStream(f);\n\n            // EFF - buffering, file channels??\n            while (is.available() > 0) {\n               fos.write(is.read());\n            }\n            fos.close();\n            is.close();\n         }\n         }\n      }\n\n    //  E.info(\"unpacked jar to \" + fout);\n\n       \n   }", "func_src_after": "   public static void unpackJar(File fjar, File fout) throws IOException {\n    \n      JarFile jf = new JarFile(fjar);\n      Enumeration<JarEntry> en = jf.entries();\n\n      while (en.hasMoreElements()) {\n         JarEntry je = en.nextElement();\n         java.io.File f = new File(fout,  je.getName());\n\t\t\t\t\t\t\tif (!f.toPath().normalize().startsWith(fout.toPath().normalize())) {\n\t\t\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t\t\t\t}\n         if (je.isDirectory()) {\n            f.mkdirs();\n            continue;\n\n         } else {\n            // f.getParentFile().mkdirs();\n\n            if (f.getPath().indexOf(\"META-INF\") >= 0) {\n               // skip it\n            } else {\n            f.getParentFile().mkdirs();\n            java.io.InputStream is = jf.getInputStream(je);\n            java.io.FileOutputStream fos = new FileOutputStream(f);\n\n            // EFF - buffering, file channels??\n            while (is.available() > 0) {\n               fos.write(is.read());\n            }\n            fos.close();\n            is.close();\n         }\n         }\n      }\n\n    //  E.info(\"unpacked jar to \" + fout);\n\n       \n   }", "line_changes": {"deleted": [], "added": [{"line_no": 9, "char_start": 301, "char_end": 377, "line": "\t\t\t\t\t\t\tif (!f.toPath().normalize().startsWith(fout.toPath().normalize())) {\n"}, {"line_no": 10, "char_start": 377, "char_end": 430, "line": "\t\t\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 11, "char_start": 430, "char_end": 439, "line": "\t\t\t\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 301, "char_end": 439, "chars": "\t\t\t\t\t\t\tif (!f.toPath().normalize().startsWith(fout.toPath().normalize())) {\n\t\t\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t\t\t\t}\n"}]}, "commit_link": "github.com/LEMS/jLEMS/commit/8c224637d7d561076364a9e3c2c375daeaf463dc", "file_name": "JUtil.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to extract the contents of a JAR file to a specified directory, excluding META-INF directory."}
